file_path,api_count,code
fastai/setup.py,0,"b'\n# coding: utf-8\n\n"""""" Setup script for installing fastai """"""\n\n#from distutils.core import setup\nfrom setuptools import setup\n\nsetup(\n    name = ""fastai"",\n    packages = [\'fastai\', \'fastai/models\', \'fastai/models/cifar10\'],\n    version = \'0.7.0\',\n    description = ""The fastai deep learning and machine learning library."",\n    author = ""Jeremy Howard and contributors"",\n    author_email = ""info@fast.ai"",\n    license = ""Apache License 2.0"",\n    url = ""https://github.com/fastai/fastai"",\n    download_url =  \'https://github.com/fastai/fastai/archive/0.7.0.tar.gz\',\n    install_requires =\n     [\'bcolz\', \'bleach\', \'certifi\', \'cycler\', \'decorator\', \'entrypoints\', \'feather-format\', \'graphviz\', \'html5lib\',\n      \'ipykernel\', \'ipython\', \'ipython-genutils\', \'ipywidgets\', \'isoweek\', \'jedi\', \'Jinja2\', \'jsonschema\', \'jupyter\',\n      \'MarkupSafe\', \'matplotlib\', \'numpy\', \'opencv-python\', \'pandas\',\n      \'pandas_summary\', \'pickleshare\', \'Pillow\', \'plotnine\',\n      \'ptyprocess\', \'Pygments\', \'pyparsing\', \'python-dateutil\', \'pytz\', \'PyYAML\', \'pyzmq\', \'scipy\',\n      \'seaborn\', \'simplegeneric\', \'sklearn_pandas\', \'testpath\', \'torch<0.4\', \'torchtext\', \'torchvision\', \'tornado\', \'tqdm\',\n      \'traitlets\', \'wcwidth\', \'webencodings\', \'widgetsnbextension\'],\n    keywords = [\'deeplearning\', \'pytorch\', \'machinelearning\'],\n    classifiers = [\'Development Status :: 3 - Alpha\',\n                   \'Programming Language :: Python\',\n                   \'Programming Language :: Python :: 3.6\',\n                   \'Topic :: Scientific/Engineering :: Artificial Intelligence\']\n)\n\n'"
notebooks/general_utils.py,0,"b'from pathlib import Path\nimport logging\nimport wget\nimport pickle\nfrom typing import List, Callable, Union, Any\nfrom more_itertools import chunked\nfrom itertools import chain\nimport nmslib\nfrom pathos.multiprocessing import Pool, cpu_count\nfrom math import ceil\n\n\ndef save_file_pickle(fname:str, obj:Any):\n    with open(fname, \'wb\') as f:\n        pickle.dump(obj, f)\n\n\ndef load_file_pickle(fname:str):\n    with open(fname, \'rb\') as f:\n        obj = pickle.load(f)\n        return obj\n\n\ndef read_training_files(data_path:str):\n    """"""\n    Read data from directory\n    """"""\n    PATH = Path(data_path)\n\n    with open(PATH/\'train.function\', \'r\') as f:\n        t_enc = f.readlines()\n\n    with open(PATH/\'valid.function\', \'r\') as f:\n        v_enc = f.readlines()\n\n    # combine train and validation and let keras split it randomly for you\n    tv_enc = t_enc + v_enc\n\n    with open(PATH/\'test.function\', \'r\') as f:\n        h_enc = f.readlines()\n\n    with open(PATH/\'train.docstring\', \'r\') as f:\n        t_dec = f.readlines()\n\n    with open(PATH/\'valid.docstring\', \'r\') as f:\n        v_dec = f.readlines()\n\n    # combine train and validation and let keras split it randomly for you\n    tv_dec = t_dec + v_dec\n\n    with open(PATH/\'test.docstring\', \'r\') as f:\n        h_dec = f.readlines()\n\n    logging.warning(f\'Num rows for encoder training + validation input: {len(tv_enc):,}\')\n    logging.warning(f\'Num rows for encoder holdout input: {len(h_enc):,}\')\n\n    logging.warning(f\'Num rows for decoder training + validation input: {len(tv_dec):,}\')\n    logging.warning(f\'Num rows for decoder holdout input: {len(h_dec):,}\')\n\n    return tv_enc, h_enc, tv_dec, h_dec\n\n\ndef apply_parallel(func: Callable,\n                   data: List[Any],\n                   cpu_cores: int = None) -> List[Any]:\n    """"""\n    Apply function to list of elements.\n    Automatically determines the chunk size.\n    """"""\n    if not cpu_cores:\n        cpu_cores = cpu_count()\n\n    try:\n        chunk_size = ceil(len(data) / cpu_cores)\n        pool = Pool(cpu_cores)\n        transformed_data = pool.map(func, chunked(data, chunk_size), chunksize=1)\n    finally:\n        pool.close()\n        pool.join()\n        return transformed_data\n\n\ndef flattenlist(listoflists:List[List[Any]]):\n    return list(chain.from_iterable(listoflists))\n\n\nprocessed_data_filenames = [\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/test.docstring\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/test.function\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/test.lineage\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/test_original_function.json.gz\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/train.docstring\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/train.function\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/train.lineage\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/train_original_function.json.gz\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.docstring\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.function\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.lineage\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/valid_original_function.json.gz\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.function\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.lineage\',\n\'https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings_original_function.json.gz\']\n\n\ndef get_step2_prerequisite_files(output_directory):\n    outpath = Path(output_directory)\n    assert not list(outpath.glob(\'*\')), f\'There are files in {str(outpath.absolute())}, please clear files or specify an empty folder.\'\n    outpath.mkdir(exist_ok=True)\n    print(f\'Saving files to {str(outpath.absolute())}\')\n    for url in processed_data_filenames:\n        print(f\'downloading {url}\')\n        wget.download(url, out=str(outpath.absolute()))\n\n\ndef create_nmslib_search_index(numpy_vectors):\n    """"""Create search index using nmslib.\n\n    Parameters\n    ==========\n    numpy_vectors : numpy.array\n        The matrix of vectors\n\n    Returns\n    =======\n    nmslib object that has index of numpy_vectors\n    """"""\n\n    search_index = nmslib.init(method=\'hnsw\', space=\'cosinesimil\')\n    search_index.addDataPointBatch(numpy_vectors)\n    search_index.createIndex({\'post\': 2}, print_progress=True)\n    return search_index\n'"
notebooks/lang_model_utils.py,1,"b'from pathlib import Path\nimport logging\nfrom typing import List, Any\nfrom tqdm import tqdm_notebook\nfrom keras.preprocessing.sequence import pad_sequences\nimport torch\nimport spacy\nfrom fastai.text import *\nEN = spacy.load(\'en\')\n\n\ndef list_flatten(l: List[List[Any]]) -> List[Any]:\n    ""List[List] --> List""\n    return [item for sublist in l for item in sublist]\n\n\ndef _dd():\n    ""Helper function for defaultdict.""\n    return 1\n\n\ndef load_lm_vocab(lm_vocab_file: str):\n    """"""load vm_vocab object.""""""\n    with open(lm_vocab_file, \'rb\') as f:\n        info = pickle.load(f)\n\n    v = lm_vocab()\n    v.itos = info[\'itos\']\n    v.stoi = info[\'stoi\']\n    v.vocab_size = len(v.itos)\n    v.max_vocab = info[\'max_vocab\']\n    v.min_freq = info[\'min_freq\']\n    v.bos_token = info[\'bos_token\']\n    logging.warning(f\'Loaded vocab of size {v.vocab_size:,}\')\n    return v\n\n\nclass lm_vocab:\n    def __init__(self,\n                 max_vocab: int = 50000,\n                 min_freq: int = 15,\n                 bos_token: str = \'_xbos_\'):\n        """"""\n        Builds vocabulary and indexes string for FastAI language model.\n\n        Parameters\n        ==========\n        max_vocab : int\n            Maximum sie of vocabulary.\n\n        min_freq : int\n            Minimum frequency threshold for token to be included in vocabulary.\n\n        bos_token : str\n            Beginning of string token\n        """"""\n        self.max_vocab = max_vocab\n        self.min_freq = min_freq\n        self.bos_token = bos_token\n\n    def fit(self, data: List) -> None:\n        ""Fit vocabulary to a list of documents.""\n        logging.warning(f\'Processing {len(data):,} rows\')\n        # build vocab\n        trn = list_flatten([(self.bos_token + \' \' + x).split() for x in data])\n        freq = Counter(trn)\n        itos = [o for o, c in freq.most_common(self.max_vocab) if c > self.min_freq]\n\n        # insert placeholder tokens\n        itos.insert(0, \'_pad_\')\n        itos.insert(0, \'_unk_\')\n        self.vocab_size = len(itos)\n        logging.warning(f\'Vocab Size {self.vocab_size:,}\')\n\n        # build reverse index\n        stoi = collections.defaultdict(_dd, {v: k for k, v in enumerate(itos)})\n\n        # save vocabulary\n        self.itos = dict(enumerate(itos))\n        self.stoi = stoi\n\n    def transform_flattened(self, data: List[str], dedup:bool = True) -> List[int]:\n        """"""Tokenizes, indexes and flattens list of strings for fastai language model.""""""\n        n = len(data)\n        logging.warning(f\'Transforming {n:,} rows.\')\n        if dedup:\n            data = list(set(data))\n            n2 = len(data)\n            logging.warning(f\'Removed {n-n2:,} duplicate rows.\')\n\n        tok_trn = list_flatten([(self.bos_token + \' \' + x).split() for x in data])\n        return np.array([self.stoi[s] for s in tok_trn])\n\n    def fit_transform_flattened(self, data: List[str]) -> List[int]:\n        ""Applies `fit` then `transform_flattened` methods sequentially.""\n        self.fit(data)\n        return self.transform_flattened(data)\n\n    def transform(self,\n                 data: List[str],\n                 padding: bool = True,\n                 max_seq_len: int = 60) -> List[List[int]]:\n        """"""Tokenizes, and indexes list of strings without flattening.\n\n        Parameters\n        ==========\n        data : List[str]\n            List of documents (sentences) that you want to transform.\n        max_seq_len : int\n            The maximum length of any sequence allowed.  Sequences will be truncated\n            and pre-padded to this length.\n        """"""\n        logging.warning(f\'Processing {len(data):,} rows\')\n        idx_docs = [[self.stoi[self.bos_token]] + [self.stoi[word] for word in sent.split()[:max_seq_len]] for sent in data]\n        # default keras pad_sequences pre-pads to max length with zero\n        if padding:\n            # because padding currently wrecks hidden state of lang model, so\n            # by putting padding after (post) sequence we can just ignore the padding hidden states.\n            return pad_sequences(idx_docs, padding=\'post\')\n        elif not padding:\n            return idx_docs\n\n    def save(self, destination_file: str) -> None:\n        dest = Path(destination_file)\n        info = {\'stoi\': self.stoi,\n                \'itos\': self.itos,\n                \'max_vocab\': self.max_vocab,\n                \'min_freq\': self.min_freq,\n                \'bos_token\': self.bos_token}\n        with open(dest, \'wb\') as f:\n            pickle.dump(info, f)\n        logging.warning(f\'Saved vocab to {str(dest)}\')\n\n\n\ndef train_lang_model(model_path: int,\n                     trn_indexed: List[int],\n                     val_indexed: List[int],\n                     vocab_size: int,\n                     lr: float,\n                     n_cycle: int = 2,\n                     cycle_len: int =3,\n                     cycle_mult : int =1,\n                     em_sz: int = 400,\n                     nh: int = 400,\n                     nl: int = 3,\n                     bptt: int = 20,\n                     wd: int = 1e-7,\n                     bs: int = 32):\n    """"""\n    Train fast.ai language model.\n\n    Parameters\n    ==========\n    model_path : str\n        Path where you want to save model artifacts.\n    trn_indexed : List[int]\n        flattened training data indexed\n    val_indexed : List[int]\n        flattened validation data indexed\n    vocab_size : int\n        size of vocab\n    n_cycle : int\n        Number of cycles to train model.\n    em_sz : int\n        Word embedding size.\n    nh : int\n        Dimension of hidden units in RNN\n    nl : int\n        Number of RNN layers\n    bptt : int\n        Sequence length for back-propigation through time.\n    wd : int\n        Weight decay\n    bs : int\n        Batch size\n\n\n    Returns\n    =======\n    Tuple(fastai.learner, pytorch.model)\n\n    Also saves best model weights in file `langmodel_best.torch`\n    """"""\n    mpath = Path(model_path)\n    mpath.mkdir(exist_ok=True)\n\n    # create data loaders\n    trn_dl = LanguageModelLoader(trn_indexed, bs, bptt)\n    val_dl = LanguageModelLoader(val_indexed, bs, bptt)\n\n    # create lang model data\n    md = LanguageModelData(mpath, 1, vocab_size, trn_dl, val_dl, bs=bs, bptt=bptt)\n\n    # build learner\n    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n    drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15]) * 0.7\n\n    learner = md.get_model(opt_fn, em_sz, nh, nl,\n                           dropouti=drops[0],\n                           dropout=drops[1],\n                           wdrop=drops[2],\n                           dropoute=drops[3],\n                           dropouth=drops[4])\n\n    # borrowed these parameters from fastai\n    learner.fit(lr,\n                n_cycle=n_cycle,\n                wds=wd,\n                cycle_len=cycle_len,\n                use_clr=(32, 10),\n                cycle_mult=cycle_mult,\n                best_save_name=\'langmodel_best\')\n\n    # eval sets model to inference mode (turns off dropout, etc.)\n    model = learner.model.eval()\n    # defensively calling reset to clear model state (b/c its a stateful model)\n    model.reset()\n\n    state_dict_dest = mpath/\'models/langmodel_best.h5\'\n    logging.warning(f\'State dict for the best model saved here:\\n{str(state_dict_dest)}\')\n    return learner, model\n\n\ndef list2arr(l):\n    ""Convert list into pytorch Variable.""\n    return V(np.expand_dims(np.array(l), -1)).cpu()\n\n\ndef make_prediction_from_list(model, l):\n    """"""\n    Encode a list of integers that represent a sequence of tokens.  The\n    purpose is to encode a sentence or phrase.\n\n    Parameters\n    -----------\n    model : fastai language model\n    l : list\n        list of integers, representing a sequence of tokens that you want to encode\n\n    """"""\n    arr = list2arr(l)# turn list into pytorch Variable with bs=1\n    model.reset()  # language model is stateful, so you must reset upon each prediction\n    hidden_states = model(arr)[-1][-1] # RNN Hidden Layer output is last output, and only need the last layer\n\n    #return avg-pooling, max-pooling, and last hidden state\n    return hidden_states.mean(0), hidden_states.max(0)[0], hidden_states[-1]\n\n\ndef get_embeddings(lm_model, list_list_int):\n    """"""\n    Vectorize a list of sequences List[List[int]] using a fast.ai language model.\n\n    Paramters\n    ---------\n    lm_model : fastai language model\n    list_list_int : List[List[int]]\n        A list of sequences to encode\n\n    Returns\n    -------\n    tuple: (avg, mean, last)\n        A tuple that returns the average-pooling, max-pooling over time steps as well as the last time step.\n    """"""\n    n_rows = len(list_list_int)\n    n_dim = lm_model[0].nhid\n    avgarr = np.empty((n_rows, n_dim))\n    maxarr = np.empty((n_rows, n_dim))\n    lastarr = np.empty((n_rows, n_dim))\n\n    for i in tqdm_notebook(range(len(list_list_int))):\n        avg_, max_, last_ = make_prediction_from_list(lm_model, list_list_int[i])\n        avgarr[i,:] = avg_.data.numpy()\n        maxarr[i,:] = max_.data.numpy()\n        lastarr[i,:] = last_.data.numpy()\n\n    return avgarr, maxarr, lastarr\n\n\ndef tokenize_docstring(text):\n    ""Apply tokenization using spacy to docstrings.""\n    tokens = EN.tokenizer(text)\n    return [token.text.lower() for token in tokens if not token.is_space]\n\n\nclass Query2Emb:\n    ""Assists in turning natural language phrases into sentence embeddings from a language model.""\n    def __init__(self, lang_model, vocab):\n        self.lang_model = lang_model\n        self.lang_model.eval()\n        self.lang_model.reset()\n        self.vocab = vocab\n        self.stoi = vocab.stoi\n        self.ndim = self._str2emb(\'This is test to get the dimensionality.\').shape[-1]\n\n    def _str2arr(self, str_inp):\n        raw_str = \' \'.join(tokenize_docstring(str_inp))\n        raw_arr = self.vocab.transform([raw_str])[0]\n        arr = np.expand_dims(np.array(raw_arr), -1)\n        return V(T(arr))\n\n    def _str2emb(self, str_inp):\n        v_arr = self._str2arr(str_inp).cpu()\n        self.lang_model.reset()\n        hidden_states = self.lang_model(v_arr)[-1][-1]\n        return hidden_states\n\n    def emb_mean(self, str_inp):\n        return self._str2emb(str_inp).mean(0).data.numpy()\n\n    def emb_max(self, str_inp):\n        return self._str2emb(str_inp).max(0)[0].data.numpy()\n\n    def emb_last(self, str_inp):\n        return self._str2emb(str_inp)[-1].data.numpy()\n\n    def emb_cat(self, str_inp):\n        return np.concatenate([self.emb_mean(str_inp), self.emb_max(str_inp), self.emb_last(str_inp)], axis=1)\n'"
notebooks/seq2seq_utils.py,0,"b'from matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, BatchNormalization\nfrom IPython.display import SVG, display\nfrom keras.utils.vis_utils import model_to_dot\nimport logging\nimport numpy as np\nimport dill as dpickle\nfrom annoy import AnnoyIndex\nfrom tqdm import tqdm, tqdm_notebook\nfrom random import random\nfrom nltk.translate.bleu_score import corpus_bleu\n\n\ndef build_seq2seq_model(word_emb_dim,\n                        hidden_state_dim,\n                        encoder_seq_len,\n                        num_encoder_tokens,\n                        num_decoder_tokens):\n    """"""\n    Builds architecture for sequence to sequence model.\n\n    Encoder and Decoder layer consist of one GRU Layer each.  User\n    can specify the dimensionality of the word embedding and the hidden state.\n\n    Parameters\n    ----------\n    word_emb_dim : int\n        dimensionality of the word embeddings\n    hidden_state_dim : int\n        dimensionality of the hidden state in the encoder and decoder.\n    encoder_seq_len : int\n        the length of the sequences that are input into the encoder.  The\n        sequences are expected to all be padded to the same size.\n    num_encoder_tokens : int\n        the vocabulary size of the corpus relevant to the encoder.\n    num_decoder_tokens : int\n        the vocabulary size of the corpus relevant to the decoder.\n\n    Returns\n    -------\n    Keras.models.Model\n    """"""\n\n    #### Encoder Model ####\n    encoder_inputs = Input(shape=(encoder_seq_len,), name=\'Encoder-Input\')\n\n    # Word embeding for encoder (ex: Issue Titles, Code)\n    x = Embedding(num_encoder_tokens, word_emb_dim, name=\'Body-Word-Embedding\', mask_zero=False)(encoder_inputs)\n    x = BatchNormalization(name=\'Encoder-Batchnorm-1\')(x)\n\n    # We do not need the `encoder_output` just the hidden state.\n    _, state_h = GRU(hidden_state_dim, return_state=True, name=\'Encoder-Last-GRU\', dropout=.5)(x)\n\n    # Encapsulate the encoder as a separate entity so we can just\n    #  encode without decoding if we want to.\n    encoder_model = Model(inputs=encoder_inputs, outputs=state_h, name=\'Encoder-Model\')\n\n    seq2seq_encoder_out = encoder_model(encoder_inputs)\n\n    #### Decoder Model ####\n    decoder_inputs = Input(shape=(None,), name=\'Decoder-Input\')  # for teacher forcing\n\n    # Word Embedding For Decoder (ex: Issue Titles, Docstrings)\n    dec_emb = Embedding(num_decoder_tokens, word_emb_dim, name=\'Decoder-Word-Embedding\', mask_zero=False)(decoder_inputs)\n    dec_bn = BatchNormalization(name=\'Decoder-Batchnorm-1\')(dec_emb)\n\n    # Set up the decoder, using `decoder_state_input` as initial state.\n    decoder_gru = GRU(hidden_state_dim, return_state=True, return_sequences=True, name=\'Decoder-GRU\', dropout=.5)\n    decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\n    x = BatchNormalization(name=\'Decoder-Batchnorm-2\')(decoder_gru_output)\n\n    # Dense layer for prediction\n    decoder_dense = Dense(num_decoder_tokens, activation=\'softmax\', name=\'Final-Output-Dense\')\n    decoder_outputs = decoder_dense(x)\n\n    #### Seq2Seq Model ####\n    seq2seq_Model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n    return seq2seq_Model\n\n\ndef load_text_processor(fname=\'title_pp.dpkl\'):\n    """"""\n    Load preprocessors from disk.\n\n    Parameters\n    ----------\n    fname: str\n        file name of ktext.proccessor object\n\n    Returns\n    -------\n    num_tokens : int\n        size of vocabulary loaded into ktext.processor\n    pp : ktext.processor\n        the processor you are trying to load\n\n    Typical Usage:\n    -------------\n\n    num_decoder_tokens, title_pp = load_text_processor(fname=\'title_pp.dpkl\')\n    num_encoder_tokens, body_pp = load_text_processor(fname=\'body_pp.dpkl\')\n\n    """"""\n    # Load files from disk\n    with open(fname, \'rb\') as f:\n        pp = dpickle.load(f)\n\n    num_tokens = max(pp.id2token.keys()) + 1\n    print(f\'Size of vocabulary for {fname}: {num_tokens:,}\')\n    return num_tokens, pp\n\n\ndef load_decoder_inputs(decoder_np_vecs=\'train_title_vecs.npy\'):\n    """"""\n    Load decoder inputs.\n\n    Parameters\n    ----------\n    decoder_np_vecs : str\n        filename of serialized numpy.array of decoder input (issue title)\n\n    Returns\n    -------\n    decoder_input_data : numpy.array\n        The data fed to the decoder as input during training for teacher forcing.\n        This is the same as `decoder_np_vecs` except the last position.\n    decoder_target_data : numpy.array\n        The data that the decoder data is trained to generate (issue title).\n        Calculated by sliding `decoder_np_vecs` one position forward.\n\n    """"""\n    vectorized_title = np.load(decoder_np_vecs)\n    # For Decoder Input, you don\'t need the last word as that is only for prediction\n    # when we are training using Teacher Forcing.\n    decoder_input_data = vectorized_title[:, :-1]\n\n    # Decoder Target Data Is Ahead By 1 Time Step From Decoder Input Data (Teacher Forcing)\n    decoder_target_data = vectorized_title[:, 1:]\n\n    print(f\'Shape of decoder input: {decoder_input_data.shape}\')\n    print(f\'Shape of decoder target: {decoder_target_data.shape}\')\n    return decoder_input_data, decoder_target_data\n\n\ndef load_encoder_inputs(encoder_np_vecs=\'train_body_vecs.npy\'):\n    """"""\n    Load variables & data that are inputs to encoder.\n\n    Parameters\n    ----------\n    encoder_np_vecs : str\n        filename of serialized numpy.array of encoder input (issue title)\n\n    Returns\n    -------\n    encoder_input_data : numpy.array\n        The issue body\n    doc_length : int\n        The standard document length of the input for the encoder after padding\n        the shape of this array will be (num_examples, doc_length)\n\n    """"""\n    vectorized_body = np.load(encoder_np_vecs)\n    # Encoder input is simply the body of the issue text\n    encoder_input_data = vectorized_body\n    doc_length = encoder_input_data.shape[1]\n    print(f\'Shape of encoder input: {encoder_input_data.shape}\')\n    return encoder_input_data, doc_length\n\n\ndef viz_model_architecture(model):\n    """"""Visualize model architecture in Jupyter notebook.""""""\n    display(SVG(model_to_dot(model).create(prog=\'dot\', format=\'svg\')))\n\n\ndef free_gpu_mem():\n    """"""Attempt to free gpu memory.""""""\n    K.get_session().close()\n    cfg = K.tf.ConfigProto()\n    cfg.gpu_options.allow_growth = True\n    K.set_session(K.tf.Session(config=cfg))\n\n\ndef test_gpu():\n    """"""Run a toy computation task in tensorflow to test GPU.""""""\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    session = tf.Session(config=config)\n    hello = tf.constant(\'Hello, TensorFlow!\')\n    print(session.run(hello))\n\n\ndef plot_model_training_history(history_object):\n    """"""Plots model train vs. validation loss.""""""\n    plt.title(\'model accuracy\')\n    plt.ylabel(\'accuracy\')\n    plt.xlabel(\'epoch\')\n    plt.plot(history_object.history[\'loss\'])\n    plt.plot(history_object.history[\'val_loss\'])\n    plt.legend([\'train\', \'test\'], loc=\'upper left\')\n    plt.show()\n\n\ndef extract_encoder_model(model):\n    """"""\n    Extract the encoder from the original Sequence to Sequence Model.\n\n    Returns a keras model object that has one input (body of issue) and one\n    output (encoding of issue, which is the last hidden state).\n\n    Input:\n    -----\n    model: keras model object\n\n    Returns:\n    -----\n    keras model object\n\n    """"""\n    encoder_model = model.get_layer(\'Encoder-Model\')\n    return encoder_model\n\n\ndef extract_decoder_model(model):\n    """"""\n    Extract the decoder from the original model.\n\n    Inputs:\n    ------\n    model: keras model object\n\n    Returns:\n    -------\n    A Keras model object with the following inputs and outputs:\n\n    Inputs of Keras Model That Is Returned:\n    1: the embedding index for the last predicted word or the <Start> indicator\n    2: the last hidden state, or in the case of the first word the hidden state from the encoder\n\n    Outputs of Keras Model That Is Returned:\n    1.  Prediction (class probabilities) for the next word\n    2.  The hidden state of the decoder, to be fed back into the decoder at the next time step\n\n    Implementation Notes:\n    ----------------------\n    Must extract relevant layers and reconstruct part of the computation graph\n    to allow for different inputs as we are not going to use teacher forcing at\n    inference time.\n\n    """"""\n    # the latent dimension is the dmeinsion of the hidden state passed from the encoder to the decoder.\n    latent_dim = model.get_layer(\'Encoder-Model\').output_shape[-1]\n\n    # Reconstruct the input into the decoder\n    decoder_inputs = model.get_layer(\'Decoder-Input\').input\n    dec_emb = model.get_layer(\'Decoder-Word-Embedding\')(decoder_inputs)\n    dec_bn = model.get_layer(\'Decoder-Batchnorm-1\')(dec_emb)\n\n    # Instead of setting the intial state from the encoder and forgetting about it, during inference\n    # we are not doing teacher forcing, so we will have to have a feedback loop from predictions back into\n    # the GRU, thus we define this input layer for the state so we can add this capability\n    gru_inference_state_input = Input(shape=(latent_dim,), name=\'hidden_state_input\')\n\n    # we need to reuse the weights that is why we are getting this\n    # If you inspect the decoder GRU that we created for training, it will take as input\n    # 2 tensors -> (1) is the embedding layer output for the teacher forcing\n    #                  (which will now be the last step\'s prediction, and will be _start_ on the first time step)\n    #              (2) is the state, which we will initialize with the encoder on the first time step, but then\n    #                   grab the state after the first prediction and feed that back in again.\n    gru_out, gru_state_out = model.get_layer(\'Decoder-GRU\')([dec_bn, gru_inference_state_input])\n\n    # Reconstruct dense layers\n    dec_bn2 = model.get_layer(\'Decoder-Batchnorm-2\')(gru_out)\n    dense_out = model.get_layer(\'Final-Output-Dense\')(dec_bn2)\n    decoder_model = Model([decoder_inputs, gru_inference_state_input],\n                          [dense_out, gru_state_out])\n    return decoder_model\n\n\nclass Seq2Seq_Inference(object):\n    def __init__(self,\n                 encoder_preprocessor,\n                 decoder_preprocessor,\n                 seq2seq_model):\n\n        self.enc_pp = encoder_preprocessor\n        self.dec_pp = decoder_preprocessor\n        self.seq2seq_model = seq2seq_model\n        self.encoder_model = extract_encoder_model(seq2seq_model)\n        self.decoder_model = extract_decoder_model(seq2seq_model)\n        self.default_max_len = self.dec_pp.padding_maxlen\n        self.nn = None\n        self.rec_df = None\n\n    def predict(self,\n                raw_input_text,\n                max_len=None):\n        """"""\n        Use the seq2seq model to generate a output given the input.\n\n        Inputs\n        ------\n        raw_input: str\n            The body of what is to be summarized or translated.\n\n        max_len: int (optional)\n            The maximum length of the output\n\n        """"""\n        if max_len is None:\n            max_len = self.default_max_len\n        # get the encoder\'s features for the decoder\n        raw_tokenized = self.enc_pp.transform([raw_input_text])\n        encoding = self.encoder_model.predict(raw_tokenized)\n        # we want to save the encoder\'s embedding before its updated by decoder\n        #   because we can use that as an embedding for other tasks.\n        original_encoding = encoding\n        state_value = np.array(self.dec_pp.token2id[\'_start_\']).reshape(1, 1)\n\n        decoded_sentence = []\n        stop_condition = False\n        while not stop_condition:\n            preds, st = self.decoder_model.predict([state_value, encoding])\n\n            # We are going to ignore indices 0 (padding) and indices 1 (unknown)\n            # Argmax will return the integer index corresponding to the\n            #  prediction + 2 b/c we chopped off first two\n            pred_idx = np.argmax(preds[:, :, 2:]) + 2\n\n            # retrieve word from index prediction\n            pred_word_str = self.dec_pp.id2token[pred_idx]\n\n            if pred_word_str == \'_end_\' or len(decoded_sentence) >= max_len:\n                stop_condition = True\n                break\n            decoded_sentence.append(pred_word_str)\n\n            # update the decoder for the next word\n            encoding = st\n            state_value = np.array(pred_idx).reshape(1, 1)\n\n        return original_encoding, \' \'.join(decoded_sentence)\n\n\n    def print_example(self,\n                      i,\n                      input_text,\n                      output_text,\n                      url,\n                      threshold):\n        """"""\n        Prints an example of the model\'s prediction for manual inspection.\n        """"""\n        if i:\n            print(\'\\n\\n==============================================\')\n            print(f\'============== Example # {i} =================\\n\')\n\n        if url:\n            print(url)\n\n        print(f""Original Input:\\n {input_text} \\n"")\n\n        if output_text:\n            print(f""Original Output:\\n {output_text}"")\n\n        emb, gen_title = self.predict(input_text)\n        print(f""\\n****** Predicted Output ******:\\n {gen_title}"")\n\n\n    def demo_model_predictions(self,\n                               n,\n                               df,\n                               threshold=1,\n                               input_col=\'code\',\n                               output_col=\'comment\',\n                               ref_col=\'ref\'):\n        """"""\n        Pick n random Issues and display predictions.\n\n        Input:\n        ------\n        n : int\n            Number of examples to display from\n        df : pandas DataFrame\n        threshold : float\n            distance threshold for recommendation of similar issues.\n\n        Returns:\n        --------\n        None\n            Prints the original issue body and the model\'s prediction.\n        """"""\n        # Extract input and output from DF\n        input_text = df[input_col].tolist()\n        output_text = df[output_col].tolist()\n        url = df[ref_col].tolist()\n\n        demo_list = np.random.randint(low=1, high=len(input_text), size=n)\n        for i in demo_list:\n            self.print_example(i,\n                               input_text=input_text[i],\n                               output_text=output_text[i],\n                               url=url[i],\n                               threshold=threshold)\n\n    def evaluate_model(self, input_strings, output_strings, max_len):\n        """"""\n        Method for calculating BLEU Score.\n\n        Parameters\n        ----------\n        input_strings : List[str]\n            These are the issue bodies that we want to summarize\n        output_strings : List[str]\n            This is the ground truth we are trying to predict --> issue titles\n\n        Returns\n        -------\n        bleu : float\n            The BLEU Score\n\n        """"""\n        self.actual, self.predicted = list(), list()\n        assert len(input_strings) == len(output_strings)\n        num_examples = len(input_strings)\n\n        logging.warning(\'Generating predictions.\')\n        # step over the whole set TODO: parallelize this\n        for i in tqdm_notebook(range(num_examples)):\n            _, yhat = self.predict(input_strings[i], max_len)\n\n            self.actual.append(self.dec_pp.process_text([output_strings[i]])[0])\n            self.predicted.append(self.dec_pp.process_text([yhat])[0])\n        # calculate BLEU score\n        logging.warning(\'Calculating BLEU.\')\n        bleu = corpus_bleu([[a] for a in self.actual], self.predicted)\n        return bleu\n'"
fastai/docs/__init__.py,0,b''
fastai/docs/gen_ascii_docs.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport os\nimport ast\nimport re\nimport contextlib\nfrom pathlib import Path\nimport subprocess\nfrom .templates import *\nimport fire\n\n\ndef get_cls_str(ps):\n    cls_name = ps[0]\n    return f""Class {cls_name}""\n\ndef get_sub_arg(ps):\n    arg_name, arg_type, arg_default = \'\'.join(ps).split(\',\', 2)\n    if arg_type and arg_default:\n        return f\'*{arg_name}* (type {arg_type}, default {arg_default})\'\n    elif arg_type:\n        return f\'*{arg_name}* (type {arg_type})\'\n    elif arg_default:\n        return f\'*{arg_name}* (default {arg_default})\'\n    else:\n        return f\'*{arg_name}*\'\n\ndef get_xref_str(ps):\n    xref_id, xref_cap = ps if len(ps) == 2 else ps*2\n    return f""xref:{xref_id}[{xref_cap}]""\n\ndef get_method_str(ps):\n    method_name, doc_string = \'\'.join(ps).split(\',\', 1)\n    result = f\'*{method_name}*\'\n\n    if doc_string:\n        result += f\':: {doc_string}\' if doc_string else \'\'\n    return result\n\ndef parse_tmpl(s):\n    inner = s.group(1)\n    fn_name,*params = inner.split(\' \', 1)\n    fn = _fn_lu[fn_name]\n    return fn(params)\n\ndef parse_module(file_path):\n    module = ast.parse(file_path.read_text())\n    tmpl_str = HEADER.format(file_path.name.rsplit(\'.\',1)[0])\n    cls_defs = [node for node in module.body if isinstance(node, ast.ClassDef)]\n    mod_func_defs = [node for node in module.body if isinstance(node, ast.FunctionDef)]\n    for cls_def in cls_defs:\n        cls_name = cls_def.name\n        cls_bases = \',\'.join([parse(each) for each in cls_def.bases])\n        tmpl_str += f\'== {{{{class {cls_name}{"":"" + cls_bases if cls_bases else """"}}}}}\\n\\n\'\n        method_str = None\n        for fn_def in (fn_def for fn_def in cls_def.body if isinstance(fn_def, ast.FunctionDef)):\n            if fn_def.name == \'__init__\':\n                tmpl_str += ""=== Arguments\\n"" + parse_args(fn_def.args) + ""\\n\\n""\n            else:\n                if not method_str:\n                    method_str = \'=== Methods\\n\\n\'\n                doc_str = ast.get_docstring(fn_def)\n                method_str += f\'{{{{method {fn_def.name},{doc_str if doc_str else """"}}}}}\\n\\n\'\n        tmpl_str += method_str if method_str else \'\'\n    method_str = None\n    for fn_def in mod_func_defs:\n        if not method_str:\n            method_str = \'== Module Functions\\n\\n\'\n        doc_str = ast.get_docstring(fn_def)\n        method_str += f\'{{{{method {fn_def.name},{doc_str if doc_str else """"}}}}}\\n\\n\'\n    tmpl_str += method_str if method_str else \'\'\n    return tmpl_str\n\ndef parse_args(args):\n    arg_strs = [f\'{arg.arg},{arg.annotation.id if arg.annotation else """"}\' for arg in args.args if arg.arg != \'self\']\n    defaults = parse_defaults(args.defaults)\n    defaults = [None]*(len(arg_strs)-len(defaults)) + defaults\n    return \'\\n\\n\'.join([\'{{\' + f\'arg {arg},{default if default else """"}\' + \'}}\' for arg, default in zip(arg_strs, defaults)])\n\ndef parse_defaults(defs):\n    return [parse(each) for each in defs]\n\ndef parse_num(o):\n    return str(o.n)\n\ndef parse_str(o):\n    return o.s\n\ndef parse_call(o):\n    return o.func.id + \'()\'\n\ndef parse(o):\n    return _parser_dict.get(type(o), lambda x: str(x))(o)\n\n@contextlib.contextmanager\ndef working_directory(path):\n    prev_cwd = Path.cwd()\n    os.chdir(str(path))\n    try:\n        yield\n    finally:\n        os.chdir(str(prev_cwd))\n\ndef gen_ascii_docs(src=\'fastai\'):\n    """"""Generate documentation for fastai library in HTML (asciidoctor required)\n    :param str src: The absolute/relative path of source file/dir\n    """"""\n    os.chdir(Path(__file__).absolute().parent)\n    with working_directory(\'..\'):\n        path = Path(src)\n        if path.is_dir():\n            file_paths = list(path.glob(\'**/*.py\'))\n        else:\n            file_paths = [path]\n\n    pat = re.compile(\'^(?!__init__).*.py\\Z\')\n    for file_path in file_paths:\n        if pat.match(file_path.name):\n            file_path.parent.mkdir(parents=True, exist_ok=True)\n            with working_directory(\'..\'):\n                tmpl_str = parse_module(file_path)\n\n            (file_path.parent/(file_path.name.rsplit(\'.\',1)[0] + \'.adoc.tmpl\')).write_text(tmpl_str)\n            (file_path.parent/(file_path.name.rsplit(\'.\',1)[0] + \'.adoc\')).write_text(re.sub(r""{{(.*?)}}"", parse_tmpl, tmpl_str, flags=re.DOTALL))\n    if path.is_dir():\n        subprocess.call([\'asciidoctor\', str(path) + \'/**/*.adoc\'])\n    else:\n        subprocess.call([\'asciidoctor\', str(path).rsplit(\'.\',1)[0] + \'.adoc\'])\n\n\n_fn_lu = {\n    \'class\': get_cls_str,\n     \'arg\': get_sub_arg,\n     \'xref\': get_xref_str,\n     \'method\': get_method_str\n}\n\n_parser_dict = {\n    ast.Dict:lambda x: \'{}\',\n    ast.arguments: parse_args,\n    ast.Call: parse_call,\n    ast.Num: parse_num,\n    ast.Str: parse_str,\n    ast.Name: lambda x: x.id,\n    ast.NameConstant: lambda x: str(x.value),\n    ast.Attribute: lambda x: x.attr,\n    ast.List: lambda x: \'[]\',\n    list: lambda x: list(map(parse, x))\n}\n\nif __name__ == \'__main__\':\n    fire.Fire(gen_ascii_docs)'"
fastai/docs/md_expander.py,0,"b'import sys\r\nimport re\r\n\r\n\r\n\r\n\r\ndef expand(filename):\r\n\r\n    f = open(filename, ""r"")\r\n    contents = f.read()\r\n\r\n    regex_inside = r""\\{\\{(.*?)\\}\\}""\r\n    regex_outside = r""(^|\\}\\})(.*?)(\\{\\{|$)""\r\n\r\n    within = re.finditer(regex_inside, contents, re.MULTILINE | re.DOTALL)\r\n    outside = re.finditer(regex_outside, contents, re.MULTILINE | re.DOTALL) \r\n\r\n    for matchNum, match in enumerate(within):\r\n        for groupNum in range(0, len(match.groups())):\r\n            group = match.group(1)\r\n            if group.startswith(""class""):\r\n                classname = re.search(r"" (.*?),"", group).groups()[0]\r\n                params = re.search(r"",(.*)"", group).groups()[0]\r\n                print(\'<h2 id=""\' + classname + \'"" class=""class"">Class: \' + classname + \'(<span class=""params"">\' + params + \'</span></h2>\')\r\n\r\n            print (match.group(1))\r\n\r\n#    split = re.split(regex_inside, contents)\r\n#\r\n#    for i, item in enumerate(split):\r\n\r\n\r\n\r\nif __name__ == \'__main__\':\r\n\r\n    expand(sys.argv[1])\r\n\r\n'"
fastai/docs/templates.py,0,"b""HEADER = '''\n= fastai.{}\n\n== Introduction and overview\n\n```\n...example...\n```\n\n\n'''"""
fastai/fastai/__init__.py,0,b''
fastai/fastai/adaptive_softmax.py,1,"b'from .lm_rnn import *\n\nclass AdaptiveSoftmax(nn.Module):\n    def __init__(self, input_size, cutoff):\n        super().__init__()\n        self.input_size,self.cutoff = input_size,cutoff\n        self.output_size = cutoff[0] + len(cutoff) - 1\n        self.head = nn.Linear(input_size, self.output_size)\n        self.tail = nn.ModuleList()\n        for i in range(len(cutoff) - 1):\n            seq = nn.Sequential(nn.Linear(input_size, input_size // 4 ** i, False),\n                nn.Linear(input_size // 4 ** i, cutoff[i + 1] - cutoff[i], False))\n            self.tail.append(seq)\n\n    def reset(self):\n        nn.init.xavier_normal(self.head.weight)\n        for tail in self.tail:\n            nn.init.xavier_normal(tail[0].weight)\n            nn.init.xavier_normal(tail[1].weight)\n\n    def set_target(self, target):\n        self.id = []\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            if mask.sum() > 0:\n                self.id.append(Variable(mask.float().nonzero().squeeze(1)))\n            else: self.id.append(None)\n\n    def forward(self, input):\n        output = [self.head(input)]\n        for i in range(len(self.id)):\n            if self.id[i] is not None:\n                output.append(self.tail[i](input.index_select(0, self.id[i])))\n            else: output.append(None)\n        return output\n\n    def log_prob(self, input):\n        lsm = nn.LogSoftmax().cuda()\n        head_out = self.head(input)\n        batch_size = head_out.size(0)\n        prob = torch.zeros(batch_size, self.cutoff[-1]).cuda()\n        lsm_head = lsm(head_out)\n        prob.narrow(1, 0, self.output_size).add_(lsm_head.narrow(1, 0, self.output_size).data)\n        for i in range(len(self.tail)):\n            pos = self.cutoff[i]\n            i_size = self.cutoff[i + 1] - pos\n            buffer = lsm_head.narrow(1, self.cutoff[0] + i, 1)\n            buffer = buffer.expand(batch_size, i_size)\n            lsm_tail = lsm(self.tail[i](input))\n            prob.narrow(1, pos, i_size).copy_(buffer.data).add_(lsm_tail.data)\n        return prob\n\n\nclass AdaptiveLoss(nn.Module):\n    def __init__(self, cutoff):\n        super().__init__()\n        self.cutoff = cutoff\n        self.criterions = nn.ModuleList([nn.CrossEntropyLoss(size_average=False) for i in self.cutoff])\n\n    def remap_target(self, target):\n        new_target = [target.clone()]\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            new_target[0][mask] = self.cutoff[0] + i\n            if mask.sum() > 0: new_target.append(target[mask].add(-self.cutoff[i]))\n            else: new_target.append(None)\n        return new_target\n\n    def forward(self, input, target):\n        batch_size = input[0].size(0)\n        target = self.remap_target(target.data)\n        output = 0.0\n        for i in range(len(input)):\n            if input[i] is not None:\n                assert(target[i].min() >= 0 and target[i].max() <= input[i].size(1))\n                criterion = self.criterions[i]\n                output += criterion(input[i], Variable(target[i]))\n        output /= batch_size\n        return output\n\n'"
fastai/fastai/column_data.py,2,"b'from .imports import *\nfrom .torch_imports import *\nfrom .dataset import *\nfrom .learner import *\n\n\nclass PassthruDataset(Dataset):\n    def __init__(self,*args, is_reg=True, is_multi=False):\n        *xs,y=args\n        self.xs,self.y = xs,y\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n    def __getitem__(self, idx): return [o[idx] for o in self.xs] + [self.y[idx]]\n\n    @classmethod\n    def from_data_frame(cls, df, cols_x, col_y, is_reg=True, is_multi=False):\n        cols = [df[o] for o in cols_x+[col_y]]\n        return cls(*cols, is_reg=is_reg, is_multi=is_multi)\n\n\nclass ColumnarDataset(Dataset):\n    def __init__(self, cats, conts, y, is_reg, is_multi):\n        n = len(cats[0]) if cats else len(conts[0])\n        self.cats = np.stack(cats, 1).astype(np.int64) if cats else np.zeros((n,1))\n        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n        self.y = np.zeros((n,1)) if y is None else y\n        if is_reg:\n            self.y =  self.y[:,None]\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n\n    def __getitem__(self, idx):\n        return [self.cats[idx], self.conts[idx], self.y[idx]]\n\n    @classmethod\n    def from_data_frames(cls, df_cat, df_cont, y=None, is_reg=True, is_multi=False):\n        cat_cols = [c.values for n,c in df_cat.items()]\n        cont_cols = [c.values for n,c in df_cont.items()]\n        return cls(cat_cols, cont_cols, y, is_reg, is_multi)\n\n    @classmethod\n    def from_data_frame(cls, df, cat_flds, y=None, is_reg=True, is_multi=False):\n        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y, is_reg, is_multi)\n\n\nclass ColumnarModelData(ModelData):\n    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n            DataLoader(val_ds, bs*2, shuffle=False, num_workers=1), test_dl)\n\n    @classmethod\n    def from_arrays(cls, path, val_idxs, xs, y, is_reg=True, is_multi=False, bs=64, test_xs=None, shuffle=True):\n        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs), is_reg=is_reg, is_multi=is_multi) if test_xs is not None else None\n        return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n                   PassthruDataset(*(val_xs.T), val_y, is_reg=is_reg, is_multi=is_multi),\n                   bs=bs, shuffle=shuffle, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=None):\n        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, None, is_reg, is_multi) if test_df is not None else None\n        return cls(path, ColumnarDataset.from_data_frame(trn_df, cat_flds, trn_y, is_reg, is_multi),\n                    ColumnarDataset.from_data_frame(val_df, cat_flds, val_y, is_reg, is_multi), bs, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, is_reg=True, is_multi=False, test_df=None):\n        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=test_df)\n\n    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                    y_range=None, use_bn=False, **kwargs):\n        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn, self.is_reg, self.is_multi)\n        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n\n\ndef emb_init(x):\n    x = x.weight.data\n    sc = 2/(x.size(1)+1)\n    x.uniform_(-sc,sc)\n\n\nclass MixedInputModel(nn.Module):\n    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                 y_range=None, use_bn=False, is_reg=True, is_multi=False):\n        super().__init__()\n        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n        for emb in self.embs: emb_init(emb)\n        n_emb = sum(e.embedding_dim for e in self.embs)\n        self.n_emb, self.n_cont=n_emb, n_cont\n        \n        szs = [n_emb+n_cont] + szs\n        self.lins = nn.ModuleList([\n            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n        self.bns = nn.ModuleList([\n            nn.BatchNorm1d(sz) for sz in szs[1:]])\n        for o in self.lins: kaiming_normal(o.weight.data)\n        self.outp = nn.Linear(szs[-1], out_sz)\n        kaiming_normal(self.outp.weight.data)\n\n        self.emb_drop = nn.Dropout(emb_drop)\n        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n        self.bn = nn.BatchNorm1d(n_cont)\n        self.use_bn,self.y_range = use_bn,y_range\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def forward(self, x_cat, x_cont):\n        if self.n_emb != 0:\n            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n            x = torch.cat(x, 1)\n            x = self.emb_drop(x)\n        if self.n_cont != 0:\n            x2 = self.bn(x_cont)\n            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n        for l,d,b in zip(self.lins, self.drops, self.bns):\n            x = F.relu(l(x))\n            if self.use_bn: x = b(x)\n            x = d(x)\n        x = self.outp(x)\n        if not self.is_reg:\n            if self.is_multi:\n                x = F.sigmoid(x)\n            else:\n                x = F.log_softmax(x)\n        elif self.y_range:\n            x = F.sigmoid(x)\n            x = x*(self.y_range[1] - self.y_range[0])\n            x = x+self.y_range[0]\n        return x\n\n\nclass StructuredLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    def summary(self): return model_summary(self.model, [(self.data.trn_ds.cats.shape[1], ), (self.data.trn_ds.conts.shape[1], )])\n\n\nclass StructuredModel(BasicModel):\n    def get_layer_groups(self):\n        m=self.model\n        return [m.embs, children(m.lins)+children(m.bns), m.outp]\n\n\nclass CollabFilterDataset(Dataset):\n    def __init__(self, path, user_col, item_col, ratings):\n        self.ratings,self.path = ratings.values.astype(np.float32),path\n        self.n = len(ratings)\n        (self.users,self.user2idx,self.user_col,self.n_users) = self.proc_col(user_col)\n        (self.items,self.item2idx,self.item_col,self.n_items) = self.proc_col(item_col)\n        self.min_score,self.max_score = min(ratings),max(ratings)\n        self.cols = [self.user_col,self.item_col,self.ratings]\n\n    @classmethod\n    def from_data_frame(cls, path, df, user_name, item_name, rating_name):\n        return cls(path, df[user_name], df[item_name], df[rating_name])\n\n    @classmethod\n    def from_csv(cls, path, csv, user_name, item_name, rating_name):\n        df = pd.read_csv(os.path.join(path,csv))\n        return cls.from_data_frame(path, df, user_name, item_name, rating_name)\n\n    def proc_col(self,col):\n        uniq = col.unique()\n        name2idx = {o:i for i,o in enumerate(uniq)}\n        return (uniq, name2idx, np.array([name2idx[x] for x in col]), len(uniq))\n\n    def __len__(self): return self.n\n    def __getitem__(self, idx): return [o[idx] for o in self.cols]\n\n    def get_data(self, val_idxs, bs):\n        val, trn = zip(*split_by_idx(val_idxs, *self.cols))\n        return ColumnarModelData(self.path, PassthruDataset(*trn), PassthruDataset(*val), bs)\n\n    def get_model(self, n_factors):\n        model = EmbeddingDotBias(n_factors, self.n_users, self.n_items, self.min_score, self.max_score)\n        return CollabFilterModel(to_gpu(model))\n\n    def get_learner(self, n_factors, val_idxs, bs, **kwargs):\n        return CollabFilterLearner(self.get_data(val_idxs, bs), self.get_model(n_factors), **kwargs)\n\n\ndef get_emb(ni,nf):\n    e = nn.Embedding(ni, nf)\n    e.weight.data.uniform_(-0.05,0.05)\n    return e\n\n\nclass EmbeddingDotBias(nn.Module):\n    def __init__(self, n_factors, n_users, n_items, min_score, max_score):\n        super().__init__()\n        self.min_score,self.max_score = min_score,max_score\n        (self.u, self.i, self.ub, self.ib) = [get_emb(*o) for o in [\n            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n        ]]\n\n    def forward(self, users, items):\n        um = self.u(users)* self.i(items)\n        res = um.sum(1) + self.ub(users).squeeze() + self.ib(items).squeeze()\n        return F.sigmoid(res) * (self.max_score-self.min_score) + self.min_score\n\n\nclass CollabFilterLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n\nclass CollabFilterModel(BasicModel):\n    def get_layer_groups(self): return self.model\n\n'"
fastai/fastai/conv_learner.py,0,"b'from .core import *\nfrom .layers import *\nfrom .learner import *\nfrom .initializers import *\n\nmodel_meta = {\n    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n    vgg16:[0,22], vgg19:[0,22],\n    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n}\nmodel_features = {inception_4: 3072, dn121: 2048, dn161: 4416,} # nasnetalarge: 4032*2}\n\nclass ConvnetBuilder():\n    """"""Class representing a convolutional network.\n\n    Arguments:\n        f: a model creation function (e.g. resnet34, vgg16, etc)\n        c (int): size of the last layer\n        is_multi (bool): is multilabel classification?\n            (def here http://scikit-learn.org/stable/modules/multiclass.html)\n        is_reg (bool): is a regression?\n        ps (float or array of float): dropout parameters\n        xtra_fc (list of ints): list of hidden layers with # hidden neurons\n        xtra_cut (int): # layers earlier than default to cut the model, default is 0\n        custom_head : add custom model classes that are inherited from nn.modules at the end of the model\n                      that is mentioned on Argument \'f\' \n    """"""\n\n    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, pretrained=True):\n        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n        if xtra_fc is None: xtra_fc = [512]\n        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n        self.ps,self.xtra_fc = ps,xtra_fc\n\n        if f in model_meta: cut,self.lr_cut = model_meta[f]\n        else: cut,self.lr_cut = 0,0\n        cut-=xtra_cut\n        layers = cut_model(f(pretrained), cut)\n        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n        self.top_model = nn.Sequential(*layers)\n\n        n_fc = len(self.xtra_fc)+1\n        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n\n        if custom_head: fc_layers = [custom_head]\n        else: fc_layers = self.get_fc_layers()\n        self.n_fc = len(fc_layers)\n        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n\n    @property\n    def name(self): return f\'{self.f.__name__}_{self.xtra_cut}\'\n\n    def create_fc_layer(self, ni, nf, p, actn=None):\n        res=[nn.BatchNorm1d(num_features=ni)]\n        if p: res.append(nn.Dropout(p=p))\n        res.append(nn.Linear(in_features=ni, out_features=nf))\n        if actn: res.append(actn)\n        return res\n\n    def get_fc_layers(self):\n        res=[]\n        ni=self.nf\n        for i,nf in enumerate(self.xtra_fc):\n            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n            ni=nf\n        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n        if self.is_reg: final_actn = None\n        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n        return res\n\n    def get_layer_groups(self, do_fc=False):\n        if do_fc:\n            return [self.fc_model]\n        idxs = [self.lr_cut]\n        c = children(self.top_model)\n        if len(c)==3: c = children(c[0])+c[1:]\n        lgs = list(split_by_idxs(c,idxs))\n        return lgs+[self.fc_model]\n\n\nclass ConvLearner(Learner):\n    """"""\n    Class used to train a chosen supported covnet model. Eg. ResNet-34, etc.\n    Arguments:\n        data: training data for model\n        models: model architectures to base learner\n        precompute: bool to reuse precomputed activations\n        **kwargs: parameters from Learner() class\n    """"""\n    def __init__(self, data, models, precompute=False, **kwargs):\n        self.precompute = False\n        super().__init__(data, models, **kwargs)\n        if hasattr(data, \'is_multi\') and not data.is_reg and self.metrics is None:\n            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n        if precompute: self.save_fc1()\n        self.freeze()\n        self.precompute = precompute\n\n    def _get_crit(self, data):\n        if not hasattr(data, \'is_multi\'): return super()._get_crit(data)\n\n        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    @classmethod\n    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                   pretrained=True, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n        return cls(data, models, precompute, **kwargs)\n\n    @classmethod\n    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n        convlearn=cls(data, models, precompute, **kwargs)\n        convlearn.lsuv_init()\n        return convlearn\n    \n    @property\n    def model(self): return self.models.fc_model if self.precompute else self.models.model\n\n    @property\n    def data(self): return self.fc_data if self.precompute else self.data_\n\n    def create_empty_bcolz(self, n, name):\n        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode=\'w\', rootdir=name)\n\n    def set_data(self, data, precompute=False):\n        super().set_data(data)\n        if precompute:\n            self.unfreeze()\n            self.save_fc1()\n            self.freeze()\n            self.precompute = True\n        else:\n            self.freeze()\n\n    def get_layer_groups(self):\n        return self.models.get_layer_groups(self.precompute)\n\n    def summary(self):\n        precompute = self.precompute\n        self.precompute = False\n        res = super().summary()\n        self.precompute = precompute\n        return res\n\n    def get_activations(self, force=False):\n        tmpl = f\'_{self.models.name}_{self.data.sz}.bc\'\n        # TODO: Somehow check that directory names haven\'t changed (e.g. added test set)\n        names = [os.path.join(self.tmp_path, p+tmpl) for p in (\'x_act\', \'x_act_val\', \'x_act_test\')]\n        if os.path.exists(names[0]) and not force:\n            self.activations = [bcolz.open(p) for p in names]\n        else:\n            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n\n    def save_fc1(self):\n        self.get_activations()\n        act, val_act, test_act = self.activations\n        m=self.models.top_model\n        if len(self.activations[0])!=len(self.data.trn_ds):\n            predict_to_bcolz(m, self.data.fix_dl, act)\n        if len(self.activations[1])!=len(self.data.val_ds):\n            predict_to_bcolz(m, self.data.val_dl, val_act)\n        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n\n        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n                test = test_act if self.data.test_dl else None, num_workers=8)\n\n    def freeze(self):\n        """""" Freeze all but the very last layer.\n\n        Make all layers untrainable (i.e. frozen) except for the last layer.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(-1)\n\n    def unfreeze(self):\n        """""" Unfreeze all layers.\n\n        Make all layers trainable by unfreezing. This will also set the `precompute` to `False` since we can\n        no longer pre-calculate the activation of frozen layers.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(0)\n        self.precompute = False\n'"
fastai/fastai/core.py,11,"b'from .imports import *\nfrom .torch_imports import *\n\ndef sum_geom(a,r,n): return a*n if r==1 else math.ceil(a*(1-r**n)/(1-r))\n\ndef is_listy(x): return isinstance(x, (list,tuple))\ndef is_iter(x): return isinstance(x, collections.Iterable)\ndef map_over(x, f): return [f(o) for o in x] if is_listy(x) else f(x)\ndef map_none(x, f): return None if x is None else f(x)\n\nconv_dict = {np.dtype(\'int8\'): torch.LongTensor, np.dtype(\'int16\'): torch.LongTensor,\n    np.dtype(\'int32\'): torch.LongTensor, np.dtype(\'int64\'): torch.LongTensor,\n    np.dtype(\'float32\'): torch.FloatTensor, np.dtype(\'float64\'): torch.FloatTensor}\n\ndef A(*a):\n    """"""convert iterable object into numpy array""""""\n    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]\n\ndef T(a, half=False, cuda=True):\n    """"""\n    Convert numpy array into a pytorch tensor. \n    if Cuda is available and USE_GPU=ture, store resulting tensor in GPU.\n    """"""\n    if not torch.is_tensor(a):\n        a = np.array(np.ascontiguousarray(a))\n        if a.dtype in (np.int8, np.int16, np.int32, np.int64):\n            a = torch.LongTensor(a.astype(np.int64))\n        elif a.dtype in (np.float32, np.float64):\n            a = torch.cuda.HalfTensor(a) if half else torch.FloatTensor(a)\n        else: raise NotImplementedError(a.dtype)\n    if cuda: a = to_gpu(a, async=True)\n    return a\n\ndef create_variable(x, volatile, requires_grad=False):\n    if type (x) != Variable:\n        if IS_TORCH_04: x = Variable(T(x), requires_grad=requires_grad)\n        else:           x = Variable(T(x), requires_grad=requires_grad, volatile=volatile)\n    return x\n\ndef V_(x, requires_grad=False, volatile=False):\n    \'\'\'equivalent to create_variable, which creates a pytorch tensor\'\'\'\n    return create_variable(x, volatile=volatile, requires_grad=requires_grad)\ndef V(x, requires_grad=False, volatile=False):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, lambda o: V_(o, requires_grad, volatile))\n\ndef VV_(x): \n    \'\'\'creates a volatile tensor, which does not require gradients. \'\'\'\n    return create_variable(x, True)\n\ndef VV(x):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, VV_)\n\ndef to_np(v):\n    \'\'\'returns an np.array object given an input of np.array, list, tuple, torch variable or tensor.\'\'\'\n    if isinstance(v, (np.ndarray, np.generic)): return v\n    if isinstance(v, (list,tuple)): return [to_np(o) for o in v]\n    if isinstance(v, Variable): v=v.data\n    if isinstance(v, torch.cuda.HalfTensor): v=v.float()\n    return v.cpu().numpy()\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\nUSE_GPU = torch.cuda.is_available()\ndef to_gpu(x, *args, **kwargs):\n    \'\'\'puts pytorch variable to gpu, if cuda is avaialble and USE_GPU is set to true. \'\'\'\n    return x.cuda(*args, **kwargs) if USE_GPU else x\n\ndef noop(*args, **kwargs): return\n\ndef split_by_idxs(seq, idxs):\n    \'\'\'A generator that returns sequence pieces, seperated by indexes specified in idxs. \'\'\'\n    last = 0\n    for idx in idxs:\n        yield seq[last:idx]\n        last = idx\n    yield seq[last:]\n\ndef trainable_params_(m):\n    \'\'\'Returns a list of trainable parameters in the model m. (i.e., those that require gradients.)\'\'\'\n    return [p for p in m.parameters() if p.requires_grad]\n\ndef chain_params(p):\n    if is_listy(p):\n        return list(chain(*[trainable_params_(o) for o in p]))\n    return trainable_params_(p)\n\ndef set_trainable_attr(m,b):\n    m.trainable=b\n    for p in m.parameters(): p.requires_grad=b\n\ndef apply_leaf(m, f):\n    c = children(m)\n    if isinstance(m, nn.Module): f(m)\n    if len(c)>0:\n        for l in c: apply_leaf(l,f)\n\ndef set_trainable(l, b):\n    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n\ndef SGD_Momentum(momentum):\n    return lambda *args, **kwargs: optim.SGD(*args, momentum=momentum, **kwargs)\n\ndef one_hot(a,c): return np.eye(c)[a]\n\ndef partition(a, sz): \n    """"""splits iterables a in equal parts of size sz""""""\n    return [a[i:i+sz] for i in range(0, len(a), sz)]\n\ndef partition_by_cores(a):\n    return partition(a, len(a)//num_cpus() + 1)\n\ndef num_cpus():\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n\n\nclass BasicModel():\n    def __init__(self,model,name=\'unnamed\'): self.model,self.name = model,name\n    def get_layer_groups(self, do_fc=False): return children(self.model)\n\nclass SingleModel(BasicModel):\n    def get_layer_groups(self): return [self.model]\n\nclass SimpleNet(nn.Module):\n    def __init__(self, layers):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return F.log_softmax(l_x, dim=-1)\n\n\ndef save(fn, a): \n    """"""Utility function that savess model, function, etc as pickle""""""    \n    pickle.dump(a, open(fn,\'wb\'))\ndef load(fn): \n    """"""Utility function that loads model, function, etc as pickle""""""\n    return pickle.load(open(fn,\'rb\'))\ndef load2(fn):\n    """"""Utility funciton allowing model piclking across Python2 and Python3""""""\n    return pickle.load(open(fn,\'rb\'), encoding=\'iso-8859-1\')\n\ndef load_array(fname): \n    \'\'\'\n    Load array using bcolz, which is based on numpy, for fast array saving and loading operations. \n    https://github.com/Blosc/bcolz\n    \'\'\'\n    return bcolz.open(fname)[:]\n\n\ndef chunk_iter(iterable, chunk_size):\n    \'\'\'A generator that yields chunks of iterable, chunk_size at a time. \'\'\'\n    while True:\n        chunk = []\n        try:\n            for _ in range(chunk_size): chunk.append(next(iterable))\n            yield chunk\n        except StopIteration:\n            if chunk: yield chunk\n            break\n\ndef set_grad_enabled(mode): return torch.set_grad_enabled(mode) if IS_TORCH_04 else contextlib.suppress()\n\ndef no_grad_context(): return torch.no_grad() if IS_TORCH_04 else contextlib.suppress()\n'"
fastai/fastai/dataloader.py,1,"b'import torch, queue\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler\nfrom .imports import *\nfrom .core import *\nimport collections,sys,traceback,threading\n\nstring_classes = (str, bytes)\n\n\ndef get_tensor(batch, pin, half=False):\n    if isinstance(batch, (np.ndarray, np.generic)):\n        batch = T(batch, half=half, cuda=False).contiguous()\n        if pin: batch = batch.pin_memory()\n        return to_gpu(batch)\n    elif isinstance(batch, string_classes):\n        return batch\n    elif isinstance(batch, collections.Mapping):\n        return {k: get_tensor(sample, pin, half) for k, sample in batch.items()}\n    elif isinstance(batch, collections.Sequence):\n        return [get_tensor(sample, pin, half) for sample in batch]\n    raise TypeError(f""batch must contain numbers, dicts or lists; found {type(batch)}"")\n\n\nclass DataLoader(object):\n    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, pad_idx=0,\n                 num_workers=None, pin_memory=False, drop_last=False, pre_pad=True, half=False,\n                 transpose=False, transpose_y=False):\n        self.dataset,self.batch_size,self.num_workers = dataset,batch_size,num_workers\n        self.pin_memory,self.drop_last,self.pre_pad = pin_memory,drop_last,pre_pad\n        self.transpose,self.transpose_y,self.pad_idx,self.half = transpose,transpose_y,pad_idx,half\n\n        if batch_sampler is not None:\n            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n                raise ValueError(\'batch_sampler is mutually exclusive with \'\n                                 \'batch_size, shuffle, sampler, and drop_last\')\n\n        if sampler is not None and shuffle:\n            raise ValueError(\'sampler is mutually exclusive with shuffle\')\n\n        if batch_sampler is None:\n            if sampler is None:\n                sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n\n        if num_workers is None:\n            self.num_workers = num_cpus()\n\n        self.sampler = sampler\n        self.batch_sampler = batch_sampler\n\n    def __len__(self): return len(self.batch_sampler)\n\n    def jag_stack(self, b):\n        if len(b[0].shape) not in (1,2): return np.stack(b)\n        ml = max(len(o) for o in b)\n        if min(len(o) for o in b)==ml: return np.stack(b)\n        res = np.zeros((len(b), ml), dtype=b[0].dtype) + self.pad_idx\n        for i,o in enumerate(b):\n            if self.pre_pad: res[i, -len(o):] = o\n            else:            res[i,  :len(o)] = o\n        return res\n\n    def np_collate(self, batch):\n        b = batch[0]\n        if isinstance(b, (np.ndarray, np.generic)): return self.jag_stack(batch)\n        elif isinstance(b, (int, float)): return np.array(batch)\n        elif isinstance(b, string_classes): return batch\n        elif isinstance(b, collections.Mapping):\n            return {key: self.np_collate([d[key] for d in batch]) for key in b}\n        elif isinstance(b, collections.Sequence):\n            return [self.np_collate(samples) for samples in zip(*batch)]\n        raise TypeError((""batch must contain numbers, dicts or lists; found {}"".format(type(b))))\n\n    def get_batch(self, indices):\n        res = self.np_collate([self.dataset[i] for i in indices])\n        if self.transpose:   res[0] = res[0].T\n        if self.transpose_y: res[1] = res[1].T\n        return res\n\n    def __iter__(self):\n        if self.num_workers==0:\n            for batch in map(self.get_batch, iter(self.batch_sampler)):\n                yield get_tensor(batch, self.pin_memory, self.half)\n        else:\n            with ThreadPoolExecutor(max_workers=self.num_workers) as e:\n                # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n                for c in chunk_iter(iter(self.batch_sampler), self.num_workers*10):\n                    for batch in e.map(self.get_batch, c):\n                        yield get_tensor(batch, self.pin_memory, self.half)\n\n'"
fastai/fastai/dataset.py,1,"b'import csv\n\nfrom .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .layer_optimizer import *\nfrom .dataloader import DataLoader\n\ndef get_cv_idxs(n, cv_idx=0, val_pct=0.2, seed=42):\n    """""" Get a list of index values for Validation set from a dataset\n    \n    Arguments:\n        n : int, Total number of elements in the data set.\n        cv_idx : int, starting index [idx_start = cv_idx*int(val_pct*n)] \n        val_pct : (int, float), validation set percentage \n        seed : seed value for RandomState\n        \n    Returns:\n        list of indexes \n    """"""\n    np.random.seed(seed)\n    n_val = int(val_pct*n)\n    idx_start = cv_idx*n_val\n    idxs = np.random.permutation(n)\n    return idxs[idx_start:idx_start+n_val]\n\ndef resize_img(fname, targ, path, new_path):\n    """"""\n    Enlarge or shrink a single image to scale, such that the smaller of the height or width dimension is equal to targ.\n    """"""\n    dest = os.path.join(path,new_path,str(targ),fname)\n    if os.path.exists(dest): return\n    im = Image.open(os.path.join(path, fname)).convert(\'RGB\')\n    r,c = im.size\n    ratio = targ/min(r,c)\n    sz = (scale_to(r, ratio, targ), scale_to(c, ratio, targ))\n    os.makedirs(os.path.split(dest)[0], exist_ok=True)\n    im.resize(sz, Image.LINEAR).save(dest)\n\ndef resize_imgs(fnames, targ, path, new_path):\n    """"""\n    Enlarge or shrink a set of images in the same directory to scale, such that the smaller of the height or width dimension is equal to targ.\n    Note: \n    -- This function is multithreaded for efficiency. \n    -- When destination file or folder already exist, function exists without raising an error. \n    """"""\n    if not os.path.exists(os.path.join(path,new_path,str(targ),fnames[0])):\n        with ThreadPoolExecutor(8) as e:\n            ims = e.map(lambda x: resize_img(x, targ, path, new_path), fnames)\n            for x in tqdm(ims, total=len(fnames), leave=False): pass\n    return os.path.join(path,new_path,str(targ))\n\ndef read_dir(path, folder):\n    """""" Returns a list of relative file paths to `path` for all files within `folder` """"""\n    full_path = os.path.join(path, folder)\n    fnames = glob(f""{full_path}/*.*"")\n    if any(fnames):\n        return [os.path.relpath(f,path) for f in fnames]\n    else:\n        raise FileNotFoundError(""{} folder doesn\'t exist or is empty"".format(folder))\n\ndef read_dirs(path, folder):\n    \'\'\'\n    Fetches name of all files in path in long form, and labels associated by extrapolation of directory names. \n    \'\'\'\n    lbls, fnames, all_lbls = [], [], []\n    full_path = os.path.join(path, folder)\n    for lbl in sorted(os.listdir(full_path)):\n        if lbl not in (\'.ipynb_checkpoints\',\'.DS_Store\'):\n            all_lbls.append(lbl)\n            for fname in os.listdir(os.path.join(full_path, lbl)):\n                fnames.append(os.path.join(folder, lbl, fname))\n                lbls.append(lbl)\n    return fnames, lbls, all_lbls\n\ndef n_hot(ids, c):\n    \'\'\'\n    one hot encoding by index. Returns array of length c, where all entries are 0, except for the indecies in ids\n    \'\'\'\n    res = np.zeros((c,), dtype=np.float32)\n    res[ids] = 1\n    return res\n\ndef folder_source(path, folder):\n    """"""\n    Returns the filenames and labels for a folder within a path\n    \n    Returns:\n    -------\n    fnames: a list of the filenames within `folder`\n    all_lbls: a list of all of the labels in `folder`, where the # of labels is determined by the # of directories within `folder`\n    lbl_arr: a numpy array of the label indices in `all_lbls`\n    """"""\n    fnames, lbls, all_lbls = read_dirs(path, folder)\n    lbl2idx = {lbl:idx for idx,lbl in enumerate(all_lbls)}\n    idxs = [lbl2idx[lbl] for lbl in lbls]\n    lbl_arr = np.array(idxs, dtype=int)\n    return fnames, lbl_arr, all_lbls\n\ndef parse_csv_labels(fn, skip_header=True, cat_separator = \' \'):\n    """"""Parse filenames and label sets from a CSV file.\n\n    This method expects that the csv file at path :fn: has two columns. If it\n    has a header, :skip_header: should be set to True. The labels in the\n    label set are expected to be space separated.\n\n    Arguments:\n        fn: Path to a CSV file.\n        skip_header: A boolean flag indicating whether to skip the header.\n\n    Returns:\n        a four-tuple of (\n            sorted image filenames,\n            a dictionary of filenames and corresponding labels,\n            a sorted set of unique labels,\n            a dictionary of labels to their corresponding index, which will\n            be one-hot encoded.\n        )\n    .\n    :param cat_separator: the separator for the categories column\n    """"""\n    df = pd.read_csv(fn, index_col=0, header=0 if skip_header else None, dtype=str)\n    fnames = df.index.values\n    df.iloc[:,0] = df.iloc[:,0].str.split(cat_separator)\n    return sorted(fnames), list(df.to_dict().values())[0]\n\ndef nhot_labels(label2idx, csv_labels, fnames, c):\n    \n    all_idx = {k: n_hot([label2idx[o] for o in v], c)\n               for k,v in csv_labels.items()}\n    return np.stack([all_idx[o] for o in fnames])\n\ndef csv_source(folder, csv_file, skip_header=True, suffix=\'\', continuous=False):\n    fnames,csv_labels = parse_csv_labels(csv_file, skip_header)\n    return dict_source(folder, fnames, csv_labels, suffix, continuous)\n\ndef dict_source(folder, fnames, csv_labels, suffix=\'\', continuous=False):\n    all_labels = sorted(list(set(p for o in csv_labels.values() for p in o)))\n    full_names = [os.path.join(folder,str(fn)+suffix) for fn in fnames]\n    if continuous:\n        label_arr = np.array([np.array(csv_labels[i]).astype(np.float32)\n                for i in fnames])\n    else:\n        label2idx = {v:k for k,v in enumerate(all_labels)}\n        label_arr = nhot_labels(label2idx, csv_labels, fnames, len(all_labels))\n        is_single = np.all(label_arr.sum(axis=1)==1)\n        if is_single: label_arr = np.argmax(label_arr, axis=1)\n    return full_names, label_arr, all_labels\n\nclass BaseDataset(Dataset):\n    """"""An abstract class representing a fastai dataset, it extends torch.utils.data.Dataset.""""""\n    def __init__(self, transform=None):\n        self.transform = transform\n        self.n = self.get_n()\n        self.c = self.get_c()\n        self.sz = self.get_sz()\n\n    def get1item(self, idx):\n        x,y = self.get_x(idx),self.get_y(idx)\n        return self.get(self.transform, x, y)\n\n    def __getitem__(self, idx):\n        if isinstance(idx,slice):\n            xs,ys = zip(*[self.get1item(i) for i in range(*idx.indices(self.n))])\n            return np.stack(xs),ys\n        return self.get1item(idx)\n\n    def __len__(self): return self.n\n\n    def get(self, tfm, x, y):\n        return (x,y) if tfm is None else tfm(x,y)\n\n    @abstractmethod\n    def get_n(self):\n        """"""Return number of elements in the dataset == len(self).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_c(self):\n        """"""Return number of classes in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_sz(self):\n        """"""Return maximum size of an image in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_x(self, i):\n        """"""Return i-th example (image, wav, etc).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_y(self, i):\n        """"""Return i-th label.""""""\n        raise NotImplementedError\n\n    @property\n    def is_multi(self):\n        """"""Returns true if this data set contains multiple labels per sample.""""""\n        return False\n\n    @property\n    def is_reg(self):\n        """"""True if the data set is used to train regression models.""""""\n        return False\n\ndef open_image(fn):\n    """""" Opens an image using OpenCV given the file path.\n\n    Arguments:\n        fn: the file path of the image\n\n    Returns:\n        The image in RGB format as numpy array of floats normalized to range between 0.0 - 1.0\n    """"""\n    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n    if not os.path.exists(fn):\n        raise OSError(\'No such file or directory: {}\'.format(fn))\n    elif os.path.isdir(fn):\n        raise OSError(\'Is a directory: {}\'.format(fn))\n    else:\n        #res = np.array(Image.open(fn), dtype=np.float32)/255\n        #if len(res.shape)==2: res = np.repeat(res[...,None],3,2)\n        #return res\n        try:\n            im = cv2.imread(str(fn), flags).astype(np.float32)/255\n            if im is None: raise OSError(f\'File not recognized by opencv: {fn}\')\n            return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        except Exception as e:\n            raise OSError(\'Error handling image at: {}\'.format(fn)) from e\n\nclass FilesDataset(BaseDataset):\n    def __init__(self, fnames, transform, path):\n        self.path,self.fnames = path,fnames\n        super().__init__(transform)\n    def get_sz(self): return self.transform.sz\n    def get_x(self, i): return open_image(os.path.join(self.path, self.fnames[i]))\n    def get_n(self): return len(self.fnames)\n\n    def resize_imgs(self, targ, new_path):\n        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n        return self.__class__(self.fnames, self.y, self.transform, dest)\n\n    def denorm(self,arr):\n        """"""Reverse the normalization done to a batch of images.\n\n        Arguments:\n            arr: of shape/size (N,3,sz,sz)\n        """"""\n        if type(arr) is not np.ndarray: arr = to_np(arr)\n        if len(arr.shape)==3: arr = arr[None]\n        return self.transform.denorm(np.rollaxis(arr,1,4))\n\n\nclass FilesArrayDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    def get_y(self, i): return self.y[i]\n    def get_c(self):\n        return self.y.shape[1] if len(self.y.shape)>1 else 0\n\nclass FilesIndexArrayDataset(FilesArrayDataset):\n    def get_c(self): return int(self.y.max())+1\n\n\nclass FilesNhotArrayDataset(FilesArrayDataset):\n    @property\n    def is_multi(self): return True\n\n\nclass FilesIndexArrayRegressionDataset(FilesArrayDataset):\n    def is_reg(self): return True\n\nclass ArraysDataset(BaseDataset):\n    def __init__(self, x, y, transform):\n        self.x,self.y=x,y\n        assert(len(x)==len(y))\n        super().__init__(transform)\n    def get_x(self, i): return self.x[i]\n    def get_y(self, i): return self.y[i]\n    def get_n(self): return len(self.y)\n    def get_sz(self): return self.x.shape[1]\n\n\nclass ArraysIndexDataset(ArraysDataset):\n    def get_c(self): return int(self.y.max())+1\n    def get_y(self, i): return self.y[i]\n\n\nclass ArraysNhotDataset(ArraysDataset):\n    def get_c(self): return self.y.shape[1]\n    @property\n    def is_multi(self): return True\n\n\nclass ModelData():\n    def __init__(self, path, trn_dl, val_dl, test_dl=None):\n        self.path,self.trn_dl,self.val_dl,self.test_dl = path,trn_dl,val_dl,test_dl\n\n    @classmethod\n    def from_dls(cls, path,trn_dl,val_dl,test_dl=None):\n        #trn_dl,val_dl = DataLoader(trn_dl),DataLoader(val_dl)\n        #if test_dl: test_dl = DataLoader(test_dl)\n        return cls(path, trn_dl, val_dl, test_dl)\n\n    @property\n    def is_reg(self): return self.trn_ds.is_reg\n    @property\n    def is_multi(self): return self.trn_ds.is_multi\n    @property\n    def trn_ds(self): return self.trn_dl.dataset\n    @property\n    def val_ds(self): return self.val_dl.dataset\n    @property\n    def test_ds(self): return self.test_dl.dataset\n    @property\n    def trn_y(self): return self.trn_ds.y\n    @property\n    def val_y(self): return self.val_ds.y\n\n\nclass ImageData(ModelData):\n    def __init__(self, path, datasets, bs, num_workers, classes):\n        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n            self.get_dl(ds,shuf) for ds,shuf in [\n                (trn_ds,True),(val_ds,False),(fix_ds,False),(aug_ds,False),\n                (test_ds,False),(test_aug_ds,False)\n            ]\n        ]\n\n    def get_dl(self, ds, shuffle):\n        if ds is None: return None\n        return DataLoader(ds, batch_size=self.bs, shuffle=shuffle,\n            num_workers=self.num_workers, pin_memory=False)\n\n    @property\n    def sz(self): return self.trn_ds.sz\n    @property\n    def c(self): return self.trn_ds.c\n\n    def resized(self, dl, targ, new_path):\n        return dl.dataset.resize_imgs(targ,new_path) if dl else None\n\n    def resize(self, targ_sz, new_path=\'tmp\'):\n        new_ds = []\n        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n        else: dls += [None,None]\n        t = tqdm_notebook(dls)\n        for dl in t: new_ds.append(self.resized(dl, targ_sz, new_path))\n        t.close()\n        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)\n\n    @staticmethod\n    def get_ds(fn, trn, val, tfms, test=None, **kwargs):\n        res = [\n            fn(trn[0], trn[1], tfms[0], **kwargs), # train\n            fn(val[0], val[1], tfms[1], **kwargs), # val\n            fn(trn[0], trn[1], tfms[1], **kwargs), # fix\n            fn(val[0], val[1], tfms[0], **kwargs)  # aug\n        ]\n        if test is not None:\n            if isinstance(test, tuple):\n                test_lbls = test[1]\n                test = test[0]\n            else:\n                test_lbls = np.zeros((len(test),1))\n            res += [\n                fn(test, test_lbls, tfms[1], **kwargs), # test\n                fn(test, test_lbls, tfms[0], **kwargs)  # test_aug\n            ]\n        else: res += [None,None]\n        return res\n\n\nclass ImageClassifierData(ImageData):\n    @classmethod\n    def from_arrays(cls, path, trn, val, bs=64, tfms=(None,None), classes=None, num_workers=4, test=None):\n        """""" Read in images and their labels given as numpy arrays\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            trn: a tuple of training data matrix and target label/classification array (e.g. `trn=(x,y)` where `x` has the\n                shape of `(5000, 784)` and `y` has the shape of `(5000,)`)\n            val: a tuple of validation data matrix and target label/classification array.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            classes: a list of all labels/classifications\n            num_workers: a number of workers\n            test: a matrix of test data (the shape should match `trn[0]`)\n\n        Returns:\n            ImageClassifierData\n        """"""\n        datasets = cls.get_ds(ArraysIndexDataset, trn, val, tfms, test=test)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\n    @classmethod\n    def from_paths(cls, path, bs=64, tfms=(None,None), trn_name=\'train\', val_name=\'valid\', test_name=None, test_with_labels=False, num_workers=8):\n        """""" Read in images and their labels given as sub-folder names\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            trn_name: a name of the folder that contains training images.\n            val_name:  a name of the folder that contains validation images.\n            test_name:  a name of the folder that contains test images.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not(tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        trn,val = [folder_source(path, o) for o in (trn_name, val_name)]\n        if test_name:\n            test = folder_source(path, test_name) if test_with_labels else read_dir(path, test_name)\n        else: test = None\n        datasets = cls.get_ds(FilesIndexArrayDataset, trn, val, tfms, path=path, test=test)\n        return cls(path, datasets, bs, num_workers, classes=trn[2])\n\n    @classmethod\n    def from_csv(cls, path, folder, csv_fname, bs=64, tfms=(None,None),\n               val_idxs=None, suffix=\'\', test_name=None, continuous=False, skip_header=True, num_workers=8):\n        """""" Read in images and their labels given as a CSV file.\n\n        This method should be used when training image labels are given in an CSV file as opposed to\n        sub-directories with label names.\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            folder: a name of the folder in which training images are contained.\n            csv_fname: a name of the CSV file which contains target labels.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            val_idxs: index of images to be used for validation. e.g. output of `get_cv_idxs`.\n                If None, default arguments to get_cv_idxs are used.\n            suffix: suffix to add to image names in CSV file (sometimes CSV only contains the file name without file\n                    extension e.g. \'.jpg\' - in which case, you can set suffix as \'.jpg\')\n            test_name: a name of the folder which contains test images.\n            continuous: TODO\n            skip_header: skip the first row of the CSV file.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not (tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        assert not (os.path.isabs(folder)), ""folder needs to be a relative path""\n        fnames,y,classes = csv_source(folder, csv_fname, skip_header, suffix, continuous=continuous)\n        return cls.from_names_and_array(path, fnames, y, classes, val_idxs, test_name,\n                num_workers=num_workers, suffix=suffix, tfms=tfms, bs=bs, continuous=continuous)\n\n    @classmethod\n    def from_names_and_array(cls, path, fnames,y,classes, val_idxs=None, test_name=None,\n            num_workers=8, suffix=\'\', tfms=(None,None), bs=64, continuous=False):\n        val_idxs = get_cv_idxs(len(fnames)) if val_idxs is None else val_idxs\n        ((val_fnames,trn_fnames),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), y)\n\n        test_fnames = read_dir(path, test_name) if test_name else None\n        if continuous: f = FilesIndexArrayRegressionDataset\n        else:\n            f = FilesIndexArrayDataset if len(trn_y.shape)==1 else FilesNhotArrayDataset\n        datasets = cls.get_ds(f, (trn_fnames,trn_y), (val_fnames,val_y), tfms,\n                               path=path, test=test_fnames)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\ndef split_by_idx(idxs, *a):\n    """"""\n    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n    This can be used to split multiple arrays containing training data to validation and training set.\n\n    :param idxs [int]: list of indexes selected\n    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n    :return: list of tuples, each containing a split of corresponding array from *a.\n            First element of each tuple is an array composed from elements selected by idxs,\n            second element is an array of remaining elements.\n    """"""\n    mask = np.zeros(len(a[0]),dtype=bool)\n    mask[np.array(idxs)] = True\n    return [(o[mask],o[~mask]) for o in a]\n\n'"
fastai/fastai/executors.py,0,"b'import collections\nimport itertools\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\nclass LazyThreadPoolExecutor(ThreadPoolExecutor):\n    def map(self, fn, *iterables, timeout=None, chunksize=1, prefetch=None):\n        """"""\n        Collects iterables lazily, rather than immediately.\n        Docstring same as parent: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor\n        Implmentation taken from this PR: https://github.com/python/cpython/pull/707\n        """"""\n        if timeout is not None: end_time = timeout + time.time()\n        if prefetch is None: prefetch = self._max_workers\n        if prefetch < 0: raise ValueError(""prefetch count may not be negative"")\n        argsiter = zip(*iterables)\n        fs = collections.deque(self.submit(fn, *args) for args in itertools.islice(argsiter, self._max_workers+prefetch))\n        # Yield must be hidden in closure so that the futures are submitted before the first iterator value is required.\n        def result_iterator():\n            nonlocal argsiter\n            try:\n                while fs:\n                    res = fs[0].result() if timeout is None else fs[0].result(end_time-time.time())\n                    # Got a result, future needn\'t be cancelled\n                    del fs[0]\n                    # Dispatch next task before yielding to keep pipeline full\n                    if argsiter:\n                        try:\n                            args = next(argsiter)\n                        except StopIteration:\n                            argsiter = None\n                        else:\n                            fs.append(self.submit(fn, *args))\n                    yield res\n            finally:\n                for future in fs: future.cancel()\n        return result_iterator()'"
fastai/fastai/fp16.py,2,"b'import torch\nimport torch.nn as nn\n\n\nclass FP16(nn.Module):\n    def __init__(self, module): \n        super(FP16, self).__init__()\n        self.module = batchnorm_to_fp32(module.half())\n        \n    def forward(self, input): \n        return self.module(input.half())\n    \n    def load_state_dict(self, *inputs, **kwargs):\n        self.module.load_state_dict(*inputs, **kwargs)\n\n    def state_dict(self, *inputs, **kwargs):\n        return self.module.state_dict(*inputs, **kwargs)\n\ndef batchnorm_to_fp32(module):\n    \'\'\'\n    BatchNorm layers to have parameters in single precision.\n    Find all layers and convert them back to float. This can\'t\n    be done with built in .apply as that function will apply\n    fn to all modules, parameters, and buffers. Thus we wouldn\'t\n    be able to guard the float conversion based on the module type.\n    \'\'\'\n    if isinstance(module, nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        batchnorm_to_fp32(child)\n    return module\n\ndef copy_model_to_fp32(m, optim):\n    """"""  Creates a fp32 copy of model parameters and sets optimizer parameters\n    """"""\n    fp32_params = [m_param.clone().type(torch.cuda.FloatTensor).detach() for m_param in m.parameters()]\n    optim_groups = [group[\'params\'] for group in optim.param_groups]\n    iter_fp32_params = iter(fp32_params)\n    for group_params in optim_groups:\n        for i in range(len(group_params)):\n            fp32_param = next(iter_fp32_params)\n            fp32_param.requires_grad = group_params[i].requires_grad\n            group_params[i] = fp32_param\n    return fp32_params\n\ndef copy_fp32_to_model(m, fp32_params):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        m_param.data.copy_(fp32_param.data)\n\ndef update_fp32_grads(fp32_params, m):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        if fp32_param.grad is None:\n            fp32_param.grad = nn.Parameter(fp32_param.data.new().resize_(*fp32_param.data.size()))\n        fp32_param.grad.data.copy_(m_param.grad.data)\n\n'"
fastai/fastai/imports.py,0,"b""from IPython.lib.deepreload import reload as dreload\nimport PIL, os, numpy as np, math, collections, threading, json, bcolz, random, scipy, cv2\nimport pandas as pd, pickle, sys, itertools, string, sys, re, datetime, time, shutil, copy\nimport seaborn as sns, matplotlib\nimport IPython, graphviz, sklearn_pandas, sklearn, warnings, pdb\nimport contextlib\nfrom abc import abstractmethod\nfrom glob import glob, iglob\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom itertools import chain\nfrom functools import partial\nfrom collections import Iterable, Counter, OrderedDict\nfrom isoweek import Week\nfrom pandas_summary import DataFrameSummary\nfrom IPython.lib.display import FileLink\nfrom PIL import Image, ImageEnhance, ImageOps\nfrom sklearn import metrics, ensemble, preprocessing\nfrom operator import itemgetter, attrgetter\nfrom pathlib import Path\nfrom distutils.version import LooseVersion\n\nfrom matplotlib import pyplot as plt, rcParams, animation\nfrom ipywidgets import interact, interactive, fixed, widgets\nmatplotlib.rc('animation', html='html5')\nnp.set_printoptions(precision=5, linewidth=110, suppress=True)\n\nfrom ipykernel.kernelapp import IPKernelApp\ndef in_notebook(): return IPKernelApp.initialized()\n\ndef in_ipynb():\n    try:\n        cls = get_ipython().__class__.__name__\n        return cls == 'ZMQInteractiveShell'\n    except NameError:\n        return False\n\nimport tqdm as tq\nfrom tqdm import tqdm_notebook, tnrange\n\ndef clear_tqdm():\n    inst = getattr(tq.tqdm, '_instances', None)\n    if not inst: return\n    try:\n        for i in range(len(inst)): inst.pop().close()\n    except Exception:\n        pass\n\nif in_notebook():\n    def tqdm(*args, **kwargs):\n        clear_tqdm()\n        return tq.tqdm(*args, file=sys.stdout, **kwargs)\n    def trange(*args, **kwargs):\n        clear_tqdm()\n        return tq.trange(*args, file=sys.stdout, **kwargs)\nelse:\n    from tqdm import tqdm, trange\n    tnrange=trange\n    tqdm_notebook=tqdm\n\n"""
fastai/fastai/initializers.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\ndef cond_init(m, init_fn):\n    if not isinstance(m, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):\n        if hasattr(m, 'weight'): init_fn(m.weight)\n        if hasattr(m, 'bias'): m.bias.data.fill_(0.)\n\ndef apply_init(m, init_fn):\n    m.apply(lambda x: cond_init(x, init_fn))\n\n\n"""
fastai/fastai/io.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\nimport gzip\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\n\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None: self.total = tsize\n        self.update(b * bsize - self.n)\n\ndef get_data(url, filename):\n    if not os.path.exists(filename):\n\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n\n"""
fastai/fastai/layer_optimizer.py,0,"b""from .imports import *\nfrom .torch_imports import *\nfrom .core import *\n\ndef opt_params(parm, lr, wd):\n    return {'params': chain_params(parm), 'lr':lr, 'weight_decay':wd}\n\nclass LayerOptimizer():\n    def __init__(self, opt_fn, layer_groups, lrs, wds=None):\n        if not isinstance(layer_groups, (list,tuple)): layer_groups=[layer_groups]\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(layer_groups)\n        if wds is None: wds=0.\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(layer_groups)\n        self.layer_groups,self.lrs,self.wds = layer_groups,lrs,wds\n        self.opt = opt_fn(self.opt_params())\n\n    def opt_params(self):\n        assert(len(self.layer_groups) == len(self.lrs))\n        assert(len(self.layer_groups) == len(self.wds))\n        params = list(zip(self.layer_groups,self.lrs,self.wds))\n        return [opt_params(*p) for p in params]\n\n    @property\n    def lr(self): return self.lrs[-1]\n\n    @property\n    def mom(self):\n        if 'betas' in self.opt.param_groups[0]:\n            return self.opt.param_groups[0]['betas'][0]\n        else:\n            return self.opt.param_groups[0]['momentum']\n\n    def set_lrs(self, lrs):\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(self.layer_groups)\n        set_lrs(self.opt, lrs)\n        self.lrs=lrs\n\n    def set_wds(self, wds):\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(self.layer_groups)\n        set_wds(self.opt, wds)\n        self.wds=wds\n    \n    def set_mom(self,momentum):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (momentum, pg['betas'][1])\n        else:\n            for pg in self.opt.param_groups: pg['momentum'] = momentum\n    \n    def set_beta(self,beta):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (pg['betas'][0],beta)\n        elif 'alpha' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['alpha'] = beta\n\n    def set_opt_fn(self, opt_fn):\n        if type(self.opt) != type(opt_fn(self.opt_params())):\n            self.opt = opt_fn(self.opt_params())\n\ndef zip_strict_(l, r):\n    assert(len(l) == len(r))\n    return zip(l, r)\n\ndef set_lrs(opt, lrs):\n    if not isinstance(lrs, Iterable): lrs=[lrs]\n    if len(lrs)==1: lrs=lrs*len(opt.param_groups)\n    for pg,lr in zip_strict_(opt.param_groups,lrs): pg['lr'] = lr\n\ndef set_wds(opt, wds):\n    if not isinstance(wds, Iterable): wds=[wds]\n    if len(wds)==1: wds=wds*len(opt.param_groups)\n    assert(len(opt.param_groups) == len(wds))\n    for pg,wd in zip_strict_(opt.param_groups,wds): pg['weight_decay'] = wd\n\n"""
fastai/fastai/layers.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1,1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n\nclass Lambda(nn.Module):\n    def __init__(self, f): super().__init__(); self.f=f\n    def forward(self, x): return self.f(x)\n\nclass Flatten(nn.Module):\n    def __init__(self): super().__init__()\n    def forward(self, x): return x.view(x.size(0), -1)\n\n'"
fastai/fastai/learner.py,1,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .model import *\nfrom .dataset import *\nfrom .sgdr import *\nfrom .layer_optimizer import *\nfrom .layers import *\nfrom .metrics import *\nfrom .losses import *\nfrom .swa import *\nfrom .fp16 import *\nfrom .lsuv_initializer import apply_lsuv_init\nimport time\n\n\nclass Learner():\n    def __init__(self, data, models, opt_fn=None, tmp_name=\'tmp\', models_name=\'models\', metrics=None, clip=None, crit=None):\n        """"""\n        Combines a ModelData object with a nn.Module object, such that you can train that\n        module.\n        data (ModelData): An instance of ModelData.\n        models(module): chosen neural architecture for solving a supported problem.\n        opt_fn(function): optimizer function, uses SGD with Momentum of .9 if none.\n        tmp_name(str): output name of the directory containing temporary files from training process\n        models_name(str): output name of the directory containing the trained model\n        metrics(list): array of functions for evaluating a desired metric. Eg. accuracy.\n        clip(float): gradient clip chosen to limit the change in the gradient to prevent exploding gradients Eg. .3\n        """"""\n        self.data_,self.models,self.metrics = data,models,metrics\n        self.sched=None\n        self.wd_sched = None\n        self.clip = None\n        self.opt_fn = opt_fn or SGD_Momentum(0.9)\n        self.tmp_path = tmp_name if os.path.isabs(tmp_name) else os.path.join(self.data.path, tmp_name)\n        self.models_path = models_name if os.path.isabs(models_name) else os.path.join(self.data.path, models_name)\n        os.makedirs(self.tmp_path, exist_ok=True)\n        os.makedirs(self.models_path, exist_ok=True)\n        self.crit = crit if crit else self._get_crit(data)\n        self.reg_fn = None\n        self.fp16 = False\n\n    @classmethod\n    def from_model_data(cls, m, data, **kwargs):\n        self = cls(data, BasicModel(to_gpu(m)), **kwargs)\n        self.unfreeze()\n        return self\n\n    def __getitem__(self,i): return self.children[i]\n\n    @property\n    def children(self): return children(self.model)\n\n    @property\n    def model(self): return self.models.model\n\n    @property\n    def data(self): return self.data_\n\n    def summary(self): return model_summary(self.model, [3,self.data.sz,self.data.sz])\n\n    def __repr__(self): return self.model.__repr__()\n    \n    def lsuv_init(self, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False):         \n        x = V(next(iter(self.data.trn_dl))[0])\n        self.models.model=apply_lsuv_init(self.model, x, needed_std=needed_std, std_tol=std_tol,\n                            max_attempts=max_attempts, do_orthonorm=do_orthonorm, \n                            cuda=USE_GPU and torch.cuda.is_available())\n\n    def set_bn_freeze(self, m, do_freeze):\n        if hasattr(m, \'running_mean\'): m.bn_freeze = do_freeze\n\n    def bn_freeze(self, do_freeze):\n        apply_leaf(self.model, lambda m: self.set_bn_freeze(m, do_freeze))\n\n    def freeze_to(self, n):\n        c=self.get_layer_groups()\n        for l in c:     set_trainable(l, False)\n        for l in c[n:]: set_trainable(l, True)\n\n    def freeze_all_but(self, n):\n        c=self.get_layer_groups()\n        for l in c: set_trainable(l, False)\n        set_trainable(c[n], True)\n\n    def unfreeze(self): self.freeze_to(0)\n\n    def get_model_path(self, name): return os.path.join(self.models_path,name)+\'.h5\'\n    \n    def save(self, name): \n        save_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): save_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n                       \n    def load(self, name): \n        load_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): load_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n\n    def set_data(self, data): self.data_ = data\n\n    def get_cycle_end(self, name):\n        if name is None: return None\n        return lambda sched, cycle: self.save_cycle(name, cycle)\n\n    def save_cycle(self, name, cycle): self.save(f\'{name}_cyc_{cycle}\')\n    def load_cycle(self, name, cycle): self.load(f\'{name}_cyc_{cycle}\')\n\n    def half(self):\n        if self.fp16: return\n        self.fp16 = True\n        if type(self.model) != FP16: self.models.model = FP16(self.model)\n    def float(self):\n        if not self.fp16: return\n        self.fp16 = False\n        if type(self.model) == FP16: self.models.model = self.model.module\n        self.model.float()\n\n    def fit_gen(self, model, data, layer_opt, n_cycle, cycle_len=None, cycle_mult=1, cycle_save_name=None, best_save_name=None,\n                use_clr=None, use_clr_beta=None, metrics=None, callbacks=None, use_wd_sched=False, norm_wds=False,             \n                wds_sched_mult=None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n\n        """"""Method does some preparation before finally delegating to the \'fit\' method for\n        fitting the model. Namely, if cycle_len is defined, it adds a \'Cosine Annealing\'\n        scheduler for varying the learning rate across iterations.\n\n        Method also computes the total number of epochs to fit based on provided \'cycle_len\',\n        \'cycle_mult\', and \'n_cycle\' parameters.\n\n        Args:\n            model (Learner):  Any neural architecture for solving a supported problem.\n                Eg. ResNet-34, RNN_Learner etc.\n\n            data (ModelData): An instance of ModelData.\n\n            layer_opt (LayerOptimizer): An instance of the LayerOptimizer class\n\n            n_cycle (int): number of cycles\n\n            cycle_len (int):  number of cycles before lr is reset to the initial value.\n                E.g if cycle_len = 3, then the lr is varied between a maximum\n                and minimum value over 3 epochs.\n\n            cycle_mult (int): additional parameter for influencing how the lr resets over\n                the cycles. For an intuitive explanation, please see\n                https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb\n\n            cycle_save_name (str): use to save the weights at end of each cycle\n\n            best_save_name (str): use to save weights of best model during training.\n\n            metrics (function): some function for evaluating a desired metric. Eg. accuracy.\n\n            callbacks (list(Callback)): callbacks to apply during the training.\n\n            use_wd_sched (bool, optional): set to True to enable weight regularization using\n                the technique mentioned in https://arxiv.org/abs/1711.05101. When this is True\n                alone (see below), the regularization is detached from gradient update and\n                applied directly to the weights.\n\n            norm_wds (bool, optional): when this is set to True along with use_wd_sched, the\n                regularization factor is normalized with each training cycle.\n\n            wds_sched_mult (function, optional): when this is provided along with use_wd_sched\n                as True, the value computed by this function is multiplied with the regularization\n                strength. This function is passed the WeightDecaySchedule object. And example\n                function that can be passed is:\n                            f = lambda x: np.array(x.layer_opt.lrs) / x.init_lrs\n                            \n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work.\n                \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n                \n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n\n        Returns:\n            None\n        """"""\n\n        if callbacks is None: callbacks=[]\n        if metrics is None: metrics=self.metrics\n\n        if use_wd_sched:\n            # This needs to come before CosAnneal() because we need to read the initial learning rate from\n            # layer_opt.lrs - but CosAnneal() alters the layer_opt.lrs value initially (divides by 100)\n            if np.sum(layer_opt.wds) == 0:\n                print(\'fit() warning: use_wd_sched is set to True, but weight decay(s) passed are 0. Use wds to \'\n                      \'pass weight decay values.\')\n            batch_per_epoch = len(data.trn_dl)\n            cl = cycle_len if cycle_len else 1\n            self.wd_sched = WeightDecaySchedule(layer_opt, batch_per_epoch, cl, cycle_mult, n_cycle,\n                                                norm_wds, wds_sched_mult)\n            callbacks += [self.wd_sched]\n\n        if use_clr is not None:\n            clr_div,cut_div = use_clr[:2]\n            moms = use_clr[2:] if len(use_clr) > 2 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=clr_div, cut_div=cut_div,\n                                    momentums=moms)\n        elif use_clr_beta is not None:\n            div,pct = use_clr_beta[:2]\n            moms = use_clr_beta[2:] if len(use_clr_beta) > 3 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR_beta(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=div,\n                                    pct=pct, momentums=moms)\n        elif cycle_len:\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            cycle_batches = len(data.trn_dl)*cycle_len\n            self.sched = CosAnneal(layer_opt, cycle_batches, on_cycle_end=cycle_end, cycle_mult=cycle_mult)\n        elif not self.sched: self.sched=LossRecorder(layer_opt)\n        callbacks+=[self.sched]\n\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(model)\n            callbacks+=[SWA(model, self.swa_model, swa_start)]\n\n        n_epoch = int(sum_geom(cycle_len if cycle_len else 1, cycle_mult, n_cycle))\n        return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def get_layer_groups(self): return self.models.get_layer_groups()\n\n    def get_layer_opt(self, lrs, wds):\n\n        """"""Method returns an instance of the LayerOptimizer class, which\n        allows for setting differential learning rates for different\n        parts of the model.\n\n        An example of how a model maybe differentiated into different parts\n        for application of differential learning rates and weight decays is\n        seen in ../.../courses/dl1/fastai/conv_learner.py, using the dict\n        \'model_meta\'. Currently, this seems supported only for convolutional\n        networks such as VGG-19, ResNet-XX etc.\n\n        Args:\n            lrs (float or list(float)): learning rate(s) for the model\n\n            wds (float or list(float)): weight decay parameter(s).\n\n        Returns:\n            An instance of a LayerOptimizer\n        """"""\n        return LayerOptimizer(self.opt_fn, self.get_layer_groups(), lrs, wds)\n\n    def fit(self, lrs, n_cycle, wds=None, **kwargs):\n\n        """"""Method gets an instance of LayerOptimizer and delegates to self.fit_gen(..)\n\n        Note that one can specify a list of learning rates which, when appropriately\n        defined, will be applied to different segments of an architecture. This seems\n        mostly relevant to ImageNet-trained models, where we want to alter the layers\n        closest to the images by much smaller amounts.\n\n        Likewise, a single or list of weight decay parameters can be specified, which\n        if appropriate for a model, will apply variable weight decay parameters to\n        different segments of the model.\n\n        Args:\n            lrs (float or list(float)): learning rate for the model\n\n            n_cycle (int): number of cycles (or iterations) to fit the model for\n\n            wds (float or list(float)): weight decay parameter(s).\n\n            kwargs: other arguments\n\n        Returns:\n            None\n        """"""\n        self.sched = None\n        layer_opt = self.get_layer_opt(lrs, wds)\n        return self.fit_gen(self.model, self.data, layer_opt, n_cycle, **kwargs)\n\n    def warm_up(self, lr, wds=None):\n        layer_opt = self.get_layer_opt(lr/4, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), lr, linear=True)\n        return self.fit_gen(self.model, self.data, layer_opt, 1)\n\n    def lr_find(self, start_lr=1e-5, end_lr=10, wds=None, linear=False, **kwargs):\n        """"""Helps you find an optimal learning rate for a model.\n\n         It uses the technique developed in the 2015 paper\n         `Cyclical Learning Rates for Training Neural Networks`, where\n         we simply keep increasing the learning rate from a very small value,\n         until the loss starts decreasing.\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            wds (iterable/float)\n\n        Examples:\n            As training moves us closer to the optimal weights for a model,\n            the optimal learning rate will be smaller. We can take advantage of\n            that knowledge and provide lr_find() with a starting learning rate\n            1000x smaller than the model\'s current learning rate as such:\n\n            >> learn.lr_find(lr/1000)\n\n            >> lrs = np.array([ 1e-4, 1e-3, 1e-2 ])\n            >> learn.lr_find(lrs / 1000)\n\n        Notes:\n            lr_find() may finish before going through each batch of examples if\n            the loss decreases enough.\n\n        .. _Cyclical Learning Rates for Training Neural Networks:\n            http://arxiv.org/abs/1506.01186\n\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), end_lr, linear=linear)\n        self.fit_gen(self.model, self.data, layer_opt, 1, **kwargs)\n        self.load(\'tmp\')\n\n    def lr_find2(self, start_lr=1e-5, end_lr=10, num_it = 100, wds=None, linear=False, stop_dv=True, **kwargs):\n        """"""A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n        At each step, it computes the validation loss and the metrics on the next\n        batch of the validation data, so it\'s slower than lr_find().\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            num_it : the number of iterations you want it to run\n            wds (iterable/float)\n            stop_dv : stops (or not) when the losses starts to explode.\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder2(layer_opt, num_it, end_lr, linear=linear, metrics=self.metrics, stop_dv=stop_dv)\n        self.fit_gen(self.model, self.data, layer_opt, num_it//len(self.data.trn_dl) + 1, all_val=True, **kwargs)\n        self.load(\'tmp\')\n\n    def predict(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict(m, dl)\n\n    def predict_with_targs(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict_with_targs(m, dl)\n\n    def predict_dl(self, dl): return predict_with_targs(self.model, dl)[0]\n\n    def predict_array(self, arr):\n        self.model.eval()\n        return to_np(self.model(to_gpu(V(T(arr)))))\n\n    def TTA(self, n_aug=4, is_test=False):\n        """""" Predict with Test Time Augmentation (TTA)\n\n        Additional to the original test/validation images, apply image augmentation to them\n        (just like for training images) and calculate the mean of predictions. The intent\n        is to increase the accuracy of predictions by examining the images using multiple\n        perspectives.\n\n        Args:\n            n_aug: a number of augmentation images to use per original image\n            is_test: indicate to use test images; otherwise use validation images\n\n        Returns:\n            (tuple): a tuple containing:\n\n                log predictions (numpy.ndarray): log predictions (i.e. `np.exp(log_preds)` will return probabilities)\n                targs (numpy.ndarray): target values when `is_test==False`; zeros otherwise.\n        """"""\n        dl1 = self.data.test_dl     if is_test else self.data.val_dl\n        dl2 = self.data.test_aug_dl if is_test else self.data.aug_dl\n        preds1,targs = predict_with_targs(self.model, dl1)\n        preds1 = [preds1]*math.ceil(n_aug/4)\n        preds2 = [predict_with_targs(self.model, dl2)[0] for i in tqdm(range(n_aug), leave=False)]\n        return np.stack(preds1+preds2), targs\n\n    def fit_opt_sched(self, phases, cycle_save_name=None, best_save_name=None, stop_div=False, data_list=None, callbacks=None, \n                      cut = None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n        """"""Wraps us the content of phases to send them to model.fit(..)\n\n        This will split the training in several parts, each with their own learning rates/\n        wds/momentums/optimizer detailed in phases.\n\n        Additionaly we can add a list of different data objets in data_list to train\n        on different datasets (to change the size for instance) for each of these groups.\n\n        Args:\n            phases: a list of TrainingPhase objects\n            stop_div: when True, stops the training if the loss goes too high\n            data_list: a list of different Data objects.\n            kwargs: other arguments\n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work. \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n        Returns:\n            None\n        """"""\n        if data_list is None: data_list=[]\n        if callbacks is None: callbacks=[]\n        layer_opt = LayerOptimizer(phases[0].opt_fn, self.get_layer_groups(), 1e-2, phases[0].wds)\n        self.sched = OptimScheduler(layer_opt, phases, len(self.data.trn_dl), stop_div)\n        callbacks.append(self.sched)\n        metrics = self.metrics\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(self.model)\n            callbacks+=[SWA(self.model, self.swa_model, swa_start)]\n        n_epochs = [phase.epochs for phase in phases] if cut is None else cut\n        if len(data_list)==0: data_list = [self.data]\n        return fit(self.model, data_list, n_epochs,layer_opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n'"
fastai/fastai/lm_rnn.py,5,"b'import warnings\nfrom .imports import *\nfrom .torch_imports import *\nfrom .rnn_reg import LockedDropout,WeightDrop,EmbeddingDropout\nfrom .model import Stepper\nfrom .core import set_grad_enabled\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef seq2seq_reg(output, xtra, loss, alpha=0, beta=0):\n    hs,dropped_hs = xtra\n    if alpha:  # Activation Regularization\n        loss = loss + sum(alpha * dropped_hs[-1].pow(2).mean())\n    if beta:   # Temporal Activation Regularization (slowness)\n        h = hs[-1]\n        if len(h)>1: loss = loss + sum(beta * (h[1:] - h[:-1]).pow(2).mean())\n    return loss\n\n\ndef repackage_var(h):\n    """"""Wraps h in new Variables, to detach them from their history.""""""\n    if IS_TORCH_04: return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)\n    else: return Variable(h.data) if type(h) == Variable else tuple(repackage_var(v) for v in h)\n\n\nclass RNN_Encoder(nn.Module):\n\n    """"""A custom RNN encoder network that uses\n        - an embedding matrix to encode input,\n        - a stack of LSTM layers to drive the network, and\n        - variational dropouts in the embedding and LSTM layers\n\n        The architecture for this network was inspired by the work done in\n        ""Regularizing and Optimizing LSTM Language Models"".\n        (https://arxiv.org/pdf/1708.02182.pdf)\n    """"""\n\n    initrange=0.1\n\n    def __init__(self, ntoken, emb_sz, nhid, nlayers, pad_token, bidir=False,\n                 dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5):\n        """""" Default constructor for the RNN_Encoder class\n\n            Args:\n                bs (int): batch size of input data\n                ntoken (int): number of vocabulary (or tokens) in the source dataset\n                emb_sz (int): the embedding size to use to encode each token\n                nhid (int): number of hidden activation per LSTM layer\n                nlayers (int): number of LSTM layers to use in the architecture\n                pad_token (int): the int value used for padding text.\n                dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n                dropouti (float): dropout to apply to the input layer.\n                dropoute (float): dropout to apply to the embedding layer.\n                wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n\n            Returns:\n                None\n          """"""\n\n        super().__init__()\n        self.ndir = 2 if bidir else 1\n        self.bs = 1\n        self.encoder = nn.Embedding(ntoken, emb_sz, padding_idx=pad_token)\n        self.encoder_with_dropout = EmbeddingDropout(self.encoder)\n        self.rnns = [nn.LSTM(emb_sz if l == 0 else nhid, (nhid if l != nlayers - 1 else emb_sz)//self.ndir,\n             1, bidirectional=bidir) for l in range(nlayers)]\n        if wdrop: self.rnns = [WeightDrop(rnn, wdrop) for rnn in self.rnns]\n        self.rnns = torch.nn.ModuleList(self.rnns)\n        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n\n        self.emb_sz,self.nhid,self.nlayers,self.dropoute = emb_sz,nhid,nlayers,dropoute\n        self.dropouti = LockedDropout(dropouti)\n        self.dropouths = nn.ModuleList([LockedDropout(dropouth) for l in range(nlayers)])\n\n    def forward(self, input):\n        """""" Invoked during the forward propagation of the RNN_Encoder module.\n        Args:\n            input (Tensor): input of shape (sentence length x batch_size)\n\n        Returns:\n            raw_outputs (tuple(list (Tensor), list(Tensor)): list of tensors evaluated from each RNN layer without using\n            dropouth, list of tensors evaluated from each RNN layer using dropouth,\n        """"""\n        sl,bs = input.size()\n        if bs!=self.bs:\n            self.bs=bs\n            self.reset()\n        with set_grad_enabled(self.training):\n            emb = self.encoder_with_dropout(input, dropout=self.dropoute if self.training else 0)\n            emb = self.dropouti(emb)\n            raw_output = emb\n            new_hidden,raw_outputs,outputs = [],[],[]\n            for l, (rnn,drop) in enumerate(zip(self.rnns, self.dropouths)):\n                current_input = raw_output\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    raw_output, new_h = rnn(raw_output, self.hidden[l])\n                new_hidden.append(new_h)\n                raw_outputs.append(raw_output)\n                if l != self.nlayers - 1: raw_output = drop(raw_output)\n                outputs.append(raw_output)\n\n            self.hidden = repackage_var(new_hidden)\n        return raw_outputs, outputs\n\n    def one_hidden(self, l):\n        nh = (self.nhid if l != self.nlayers - 1 else self.emb_sz)//self.ndir\n        if IS_TORCH_04: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_())\n        else: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_(), volatile=not self.training)\n\n    def reset(self):\n        self.weights = next(self.parameters()).data\n        self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.nlayers)]\n\n\nclass MultiBatchRNN(RNN_Encoder):\n    def __init__(self, bptt, max_seq, *args, **kwargs):\n        self.max_seq,self.bptt = max_seq,bptt\n        super().__init__(*args, **kwargs)\n\n    def concat(self, arrs):\n        return [torch.cat([l[si] for l in arrs]) for si in range(len(arrs[0]))]\n\n    def forward(self, input):\n        sl,bs = input.size()\n        for l in self.hidden:\n            for h in l: h.data.zero_()\n        raw_outputs, outputs = [],[]\n        for i in range(0, sl, self.bptt):\n            r, o = super().forward(input[i: min(i+self.bptt, sl)])\n            if i>(sl-self.max_seq):\n                raw_outputs.append(r)\n                outputs.append(o)\n        return self.concat(raw_outputs), self.concat(outputs)\n\nclass LinearDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, n_out, nhid, dropout, tie_encoder=None):\n        super().__init__()\n        self.decoder = nn.Linear(nhid, n_out, bias=False)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.dropout = LockedDropout(dropout)\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = self.dropout(outputs[-1])\n        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n        result = decoded.view(-1, decoded.size(1))\n        return result, raw_outputs, outputs\n\n\nclass LinearBlock(nn.Module):\n    def __init__(self, ni, nf, drop):\n        super().__init__()\n        self.lin = nn.Linear(ni, nf)\n        self.drop = nn.Dropout(drop)\n        self.bn = nn.BatchNorm1d(ni)\n\n    def forward(self, x): return self.lin(self.drop(self.bn(x)))\n\n\nclass PoolingLinearClassifier(nn.Module):\n    def __init__(self, layers, drops):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            LinearBlock(layers[i], layers[i + 1], drops[i]) for i in range(len(layers) - 1)])\n\n    def pool(self, x, bs, is_max):\n        f = F.adaptive_max_pool1d if is_max else F.adaptive_avg_pool1d\n        return f(x.permute(1,2,0), (1,)).view(bs,-1)\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = outputs[-1]\n        sl,bs,_ = output.size()\n        avgpool = self.pool(output, bs, False)\n        mxpool = self.pool(output, bs, True)\n        x = torch.cat([output[-1], mxpool, avgpool], 1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return l_x, raw_outputs, outputs\n\n\nclass SequentialRNN(nn.Sequential):\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \'reset\'): c.reset()\n\n\ndef get_language_model(n_tok, emb_sz, nhid, nlayers, pad_token,\n                 dropout=0.4, dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5, tie_weights=True):\n    """"""Returns a SequentialRNN model.\n\n    A RNN_Encoder layer is instantiated using the parameters provided.\n\n    This is followed by the creation of a LinearDecoder layer.\n\n    Also by default (i.e. tie_weights = True), the embedding matrix used in the RNN_Encoder\n    is used to  instantiate the weights for the LinearDecoder layer.\n\n    The SequentialRNN layer is the native torch\'s Sequential wrapper that puts the RNN_Encoder and\n    LinearDecoder layers sequentially in the model.\n\n    Args:\n        n_tok (int): number of unique vocabulary words (or tokens) in the source dataset\n        emb_sz (int): the embedding size to use to encode each token\n        nhid (int): number of hidden activation per LSTM layer\n        nlayers (int): number of LSTM layers to use in the architecture\n        pad_token (int): the int value used for padding text.\n        dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n        dropouti (float): dropout to apply to the input layer.\n        dropoute (float): dropout to apply to the embedding layer.\n        wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n        tie_weights (bool): decide if the weights of the embedding matrix in the RNN encoder should be tied to the\n            weights of the LinearDecoder layer.\n    Returns:\n        A SequentialRNN model\n    """"""\n\n    rnn_enc = RNN_Encoder(n_tok, emb_sz, nhid=nhid, nlayers=nlayers, pad_token=pad_token,\n                 dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    enc = rnn_enc.encoder if tie_weights else None\n    return SequentialRNN(rnn_enc, LinearDecoder(n_tok, emb_sz, dropout, tie_encoder=enc))\n\n\ndef get_rnn_classifer(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n                      dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n    rnn_enc = MultiBatchRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir,\n                      dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    return SequentialRNN(rnn_enc, PoolingLinearClassifier(layers, drops))\n\n'"
fastai/fastai/losses.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\ndef fbeta_torch(y_true, y_pred, beta, threshold, eps=1e-9):\n    y_pred = (y_pred.float() > threshold).float()\n    y_true = y_true.float()\n    tp = (y_pred * y_true).sum(dim=1)\n    precision = tp / (y_pred.sum(dim=1)+eps)\n    recall = tp / (y_true.sum(dim=1)+eps)\n    return torch.mean(\n        precision*recall / (precision*(beta**2)+recall+eps) * (1+beta**2))\n\n'"
fastai/fastai/lsuv_initializer.py,4,"b'""""""\nFrom https://github.com/ducha-aiki/LSUV-pytorch\n\nCopyright (C) 2017, Dmytro Mishkin\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the\n   distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\nimport numpy as np\nimport torch\nimport torch.nn.init\nimport torch.nn as nn\n\ngg = {}\ngg[\'hook_position\'] = 0\ngg[\'total_fc_conv_layers\'] = 0\ngg[\'done_counter\'] = -1\ngg[\'hook\'] = None\ngg[\'act_dict\'] = {}\ngg[\'counter_to_apply_correction\'] = 0\ngg[\'correction_needed\'] = False\ngg[\'current_coef\'] = 1.0\n\n# Orthonorm init code is taked from Lasagne\n# https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\ndef svd_orthonormal(w):\n    shape = w.shape\n    if len(shape) < 2:\n        raise RuntimeError(""Only shapes of length 2 or more are supported."")\n    flat_shape = (shape[0], np.prod(shape[1:]))\n    a = np.random.normal(0.0, 1.0, flat_shape)#w;\n    u, _, v = np.linalg.svd(a, full_matrices=False)\n    q = u if u.shape == flat_shape else v\n    q = q.reshape(shape)\n    return q.astype(np.float32)\n\ndef store_activations(self, input, output):\n    gg[\'act_dict\'] = output.data.cpu().numpy();\n    return\n\ndef add_current_hook(m):\n    if gg[\'hook\'] is not None:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'hook_position\'] > gg[\'done_counter\']:\n            gg[\'hook\'] = m.register_forward_hook(store_activations)\n        else:\n            gg[\'hook_position\'] += 1\n    return\n\ndef count_conv_fc_layers(m):\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        gg[\'total_fc_conv_layers\'] +=1\n    return\n\ndef remove_hooks(hooks):\n    for h in hooks:\n        h.remove()\n    return\n\ndef orthogonal_weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        if hasattr(m, \'weight_v\'):\n            w_ortho = svd_orthonormal(m.weight_v.data.cpu().numpy())\n            m.weight_v.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n        else:\n            w_ortho = svd_orthonormal(m.weight.data.cpu().numpy())\n            m.weight.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n    return\n\ndef apply_weights_correction(m):\n    if gg[\'hook\'] is None:\n        return\n    if not gg[\'correction_needed\']:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'counter_to_apply_correction\'] < gg[\'hook_position\']:\n            gg[\'counter_to_apply_correction\'] += 1\n        else:\n            if hasattr(m, \'weight_g\'):\n                m.weight_g.data *= float(gg[\'current_coef\'])\n                gg[\'correction_needed\'] = False\n            else:\n                m.weight.data *= gg[\'current_coef\']\n                gg[\'correction_needed\'] = False\n            return\n    return\n\ndef apply_lsuv_init(model, data, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=True, cuda=True):\n    model.eval();\n    if cuda:\n        model=model.cuda()\n        data=data.cuda()\n    else:\n        model=model.cpu()\n        data=data.cpu()        \n        \n    model.apply(count_conv_fc_layers)\n    if do_orthonorm:\n        model.apply(orthogonal_weights_init)\n        if cuda:\n            model=model.cuda()\n    for layer_idx in range(gg[\'total_fc_conv_layers\']):\n        model.apply(add_current_hook)\n        out = model(data)\n        current_std = gg[\'act_dict\'].std()\n        attempts = 0\n        while (np.abs(current_std - needed_std) > std_tol):\n            gg[\'current_coef\'] =  needed_std / (current_std  + 1e-8);\n            gg[\'correction_needed\'] = True\n            model.apply(apply_weights_correction)\n            if cuda:\n                model=model.cuda()\n            out = model(data)\n            current_std = gg[\'act_dict\'].std()\n            attempts+=1\n            if attempts > max_attempts:\n                print(f\'Cannot converge in {max_attempts} iterations\')\n                break\n        if gg[\'hook\'] is not None:\n           gg[\'hook\'].remove()\n        gg[\'done_counter\']+=1\n        gg[\'counter_to_apply_correction\'] = 0\n        gg[\'hook_position\'] = 0\n        gg[\'hook\']  = None\n    if not cuda:\n        model=model.cpu()\n    return model\n'"
fastai/fastai/metrics.py,3,"b'from .imports import *\nfrom .torch_imports import *\n\ndef accuracy_np(preds, targs):\n    preds = np.argmax(preds, 1)\n    return (preds==targs).mean()\n\ndef accuracy(preds, targs):\n    preds = torch.max(preds, dim=1)[1]\n    return (preds==targs).float().mean()\n\ndef accuracy_thresh(thresh):\n    return lambda preds,targs: accuracy_multi(preds, targs, thresh)\n\ndef accuracy_multi(preds, targs, thresh):\n    return ((preds>thresh).float()==targs).float().mean()\n\ndef accuracy_multi_np(preds, targs, thresh):\n    return ((preds>thresh)==targs).mean()\n\ndef recall(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/targs.sum()\n\ndef precision(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/pred_pos.sum()\n\ndef fbeta(preds, targs, beta, thresh=0.5):\n    """"""Calculates the F-beta score (the weighted harmonic mean of precision and recall).\n    This is the micro averaged version where the true positives, false negatives and\n    false positives are calculated globally (as opposed to on a per label basis).\n\n    beta == 1 places equal weight on precision and recall, b < 1 emphasizes precision and\n    beta > 1 favors recall.\n    """"""\n    assert beta > 0, \'beta needs to be greater than 0\'\n    beta2 = beta ** 2\n    rec = recall(preds, targs, thresh)\n    prec = precision(preds, targs, thresh)\n    return (1 + beta2) * prec * rec / (beta2 * prec + rec)\n\ndef f1(preds, targs, thresh=0.5): return fbeta(preds, targs, 1, thresh)\n'"
fastai/fastai/model.py,8,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .layer_optimizer import *\nfrom .swa import *\nfrom .fp16 import *\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef cut_model(m, cut):\n    return list(m.children())[:cut] if cut else [m]\n\ndef predict_to_bcolz(m, gen, arr, workers=4):\n    arr.trim(len(arr))\n    lock=threading.Lock()\n    m.eval()\n    for x,*_ in tqdm(gen):\n        y = to_np(m(VV(x)).data)\n        with lock:\n            arr.append(y)\n            arr.flush()\n\ndef num_features(m):\n    c=children(m)\n    if len(c)==0: return None\n    for l in reversed(c):\n        if hasattr(l, \'num_features\'): return l.num_features\n        res = num_features(l)\n        if res is not None: return res\n\ndef torch_item(x): return x.item() if hasattr(x,\'item\') else x[0]\n\nclass Stepper():\n    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n        self.fp16 = fp16\n        self.reset(True)\n        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n        self.loss_scale = loss_scale\n\n    def reset(self, train=True):\n        if train: apply_leaf(self.m, set_train_mode)\n        else: self.m.eval()\n        if hasattr(self.m, \'reset\'):\n            self.m.reset()\n            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n\n    def step(self, xs, y, epoch):\n        xtra = []\n        output = self.m(*xs)\n        if isinstance(output,tuple): output,*xtra = output\n        if self.fp16: self.m.zero_grad()\n        else: self.opt.zero_grad() \n        loss = raw_loss = self.crit(output, y)\n        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n        loss.backward()\n        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n        if self.loss_scale != 1:\n            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n        if self.clip:   # Gradient clipping\n            if IS_TORCH_04: nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n            else: nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n        self.opt.step()\n        if self.fp16: \n            copy_fp32_to_model(self.m, self.fp32_params)\n            torch.cuda.synchronize()\n        return torch_item(raw_loss.data)\n\n    def evaluate(self, xs, y):\n        preds = self.m(*xs)\n        if isinstance(preds,tuple): preds=preds[0]\n        return preds, self.crit(preds, y)\n\ndef set_train_mode(m):\n    if (hasattr(m, \'running_mean\') and (getattr(m,\'bn_freeze\',False)\n              or not getattr(m,\'trainable\',False))): m.eval()\n    elif (getattr(m,\'drop_freeze\',False) and hasattr(m, \'p\')\n          and (\'drop\' in type(m).__name__.lower())): m.eval()\n    else: m.train()\n\ndef fit(model, data, n_epochs, opt, crit, metrics=None, callbacks=None, stepper=Stepper,\n        swa_model=None, swa_start=None, swa_eval_freq=None, **kwargs):\n    """""" Fits a model\n\n    Arguments:\n       model (model): any pytorch module\n           net = to_gpu(net)\n       data (ModelData): see ModelData class and subclasses (can be a list)\n       opts: an optimizer. Example: optim.Adam. \n       If n_epochs is a list, it needs to be the layer_optimizer to get the optimizer as it changes.\n       n_epochs(int or list): number of epochs (or list of number of epochs)\n       crit: loss function to optimize. Example: F.cross_entropy\n    """"""\n\n    all_val = kwargs.pop(\'all_val\') if \'all_val\' in kwargs else False\n    get_ep_vals = kwargs.pop(\'get_ep_vals\') if \'get_ep_vals\' in kwargs else False\n    metrics = metrics or []\n    callbacks = callbacks or []\n    avg_mom=0.98\n    batch_num,avg_loss=0,0.\n    for cb in callbacks: cb.on_train_begin()\n    names = [""epoch"", ""trn_loss"", ""val_loss""] + [f.__name__ for f in metrics]\n    if swa_model is not None:\n        swa_names = [\'swa_loss\'] + [f\'swa_{f.__name__}\' for f in metrics]\n        names += swa_names\n        # will use this to call evaluate later\n        swa_stepper = stepper(swa_model, None, crit, **kwargs)\n\n    layout = ""{!s:10} "" * len(names)\n    if not isinstance(n_epochs, Iterable): n_epochs=[n_epochs]\n    if not isinstance(data, Iterable): data = [data]\n    if len(data) == 1: data = data * len(n_epochs)\n    for cb in callbacks: cb.on_phase_begin()\n    model_stepper = stepper(model, opt.opt if hasattr(opt,\'opt\') else opt, crit, **kwargs)\n    ep_vals = collections.OrderedDict()\n    tot_epochs = int(np.ceil(np.array(n_epochs).sum()))\n    cnt_phases = np.array([ep * len(dat.trn_dl) for (ep,dat) in zip(n_epochs,data)]).cumsum()\n    phase = 0\n    for epoch in tnrange(tot_epochs, desc=\'Epoch\'):\n        model_stepper.reset(True)\n        cur_data = data[phase]\n        if hasattr(cur_data, \'trn_sampler\'): cur_data.trn_sampler.set_epoch(epoch)\n        if hasattr(cur_data, \'val_sampler\'): cur_data.val_sampler.set_epoch(epoch)\n        num_batch = len(cur_data.trn_dl)\n        t = tqdm(iter(cur_data.trn_dl), leave=False, total=num_batch)\n        if all_val: val_iter = IterBatch(cur_data.val_dl)\n\n        for (*x,y) in t:\n            batch_num += 1\n            for cb in callbacks: cb.on_batch_begin()\n            loss = model_stepper.step(V(x),V(y), epoch)\n            avg_loss = avg_loss * avg_mom + loss * (1-avg_mom)\n            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n            t.set_postfix(loss=debias_loss)\n            stop=False\n            los = debias_loss if not all_val else [debias_loss] + validate_next(model_stepper,metrics, val_iter)\n            for cb in callbacks: stop = stop or cb.on_batch_end(los)\n            if stop: return\n            if batch_num >= cnt_phases[phase]:\n                for cb in callbacks: cb.on_phase_end()\n                phase += 1\n                if phase >= len(n_epochs):\n                    t.close()\n                    break\n                for cb in callbacks: cb.on_phase_begin()\n                if isinstance(opt, LayerOptimizer): model_stepper.opt = opt.opt\n                if cur_data != data[phase]:\n                    t.close()\n                    break\n\n        if not all_val:\n            vals = validate(model_stepper, cur_data.val_dl, metrics)\n            stop=False\n            for cb in callbacks: stop = stop or cb.on_epoch_end(vals)\n            if swa_model is not None:\n                if (epoch + 1) >= swa_start and ((epoch + 1 - swa_start) % swa_eval_freq == 0 or epoch == tot_epochs - 1):\n                    fix_batchnorm(swa_model, cur_data.trn_dl)\n                    swa_vals = validate(swa_stepper, cur_data.val_dl, metrics)\n                    vals += swa_vals\n\n            if epoch == 0: print(layout.format(*names))\n            print_stats(epoch, [debias_loss] + vals)\n            ep_vals = append_stats(ep_vals, epoch, [debias_loss] + vals)\n        if stop: break\n    for cb in callbacks: cb.on_train_end()\n    if get_ep_vals: return vals, ep_vals\n    else: return vals\n\ndef append_stats(ep_vals, epoch, values, decimals=6):\n    ep_vals[epoch]=list(np.round(values, decimals))\n    return ep_vals\n\ndef print_stats(epoch, values, decimals=6):\n    layout = ""{!s:^10}"" + "" {!s:10}"" * len(values)\n    values = [epoch] + list(np.round(values, decimals))\n    print(layout.format(*values))\n\nclass IterBatch():\n    def __init__(self, dl):\n        self.idx = 0\n        self.dl = dl\n        self.iter = iter(dl)\n\n    def __iter__(self): return self\n\n    def next(self):\n        res = next(self.iter)\n        self.idx += 1\n        if self.idx == len(self.dl):\n            self.iter = iter(self.dl)\n            self.idx=0\n        return res\n\ndef validate_next(stepper, metrics, val_iter):\n    """"""Computes the loss on the next minibatch of the validation set.""""""\n    stepper.reset(False)\n    with no_grad_context():\n        (*x,y) = val_iter.next()\n        preds,l = stepper.evaluate(VV(x), VV(y))\n        res = [to_np(l)[0]]\n        res += [f(preds.data,y) for f in metrics]\n    stepper.reset(True)\n    return res\n\ndef validate(stepper, dl, metrics):\n    batch_cnts,loss,res = [],[],[]\n    stepper.reset(False)\n    with no_grad_context():\n        for (*x,y) in iter(dl):\n            preds, l = stepper.evaluate(VV(x), VV(y))\n            if isinstance(x,list): batch_cnts.append(len(x[0]))\n            else: batch_cnts.append(len(x))\n            loss.append(to_np(l))\n            res.append([f(preds.data, y) for f in metrics])\n    return [np.average(loss, 0, weights=batch_cnts)] + list(np.average(np.stack(res), 0, weights=batch_cnts))\n\ndef get_prediction(x):\n    if is_listy(x): x=x[0]\n    return x.data\n\ndef predict(m, dl):\n    preda,_ = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda))\n\ndef predict_batch(m, x):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    return m(VV(x))\n\ndef predict_with_targs_(m, dl):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    res = []\n    for *x,y in iter(dl): res.append([get_prediction(m(*VV(x))),y])\n    return zip(*res)\n\ndef predict_with_targs(m, dl):\n    preda,targa = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda)), to_np(torch.cat(targa))\n\n# From https://github.com/ncullen93/torchsample\ndef model_summary(m, input_size):\n    def register_hook(module):\n        def hook(module, input, output):\n            class_name = str(module.__class__).split(\'.\')[-1].split(""\'"")[0]\n            module_idx = len(summary)\n\n            m_key = \'%s-%i\' % (class_name, module_idx+1)\n            summary[m_key] = OrderedDict()\n            summary[m_key][\'input_shape\'] = list(input[0].size())\n            summary[m_key][\'input_shape\'][0] = -1\n            if is_listy(output):\n                summary[m_key][\'output_shape\'] = [[-1] + list(o.size())[1:] for o in output]\n            else:\n                summary[m_key][\'output_shape\'] = list(output.size())\n                summary[m_key][\'output_shape\'][0] = -1\n\n            params = 0\n            if hasattr(module, \'weight\'):\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n                summary[m_key][\'trainable\'] = module.weight.requires_grad\n            if hasattr(module, \'bias\') and module.bias is not None:\n                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n            summary[m_key][\'nb_params\'] = params\n\n        if (not isinstance(module, nn.Sequential) and\n           not isinstance(module, nn.ModuleList) and\n           not (module == m)):\n            hooks.append(module.register_forward_hook(hook))\n\n    summary = OrderedDict()\n    hooks = []\n    m.apply(register_hook)\n\n    if is_listy(input_size[0]):\n        x = [to_gpu(Variable(torch.rand(3,*in_size))) for in_size in input_size]\n    else: x = [to_gpu(Variable(torch.rand(3,*input_size)))]\n    m(*x)\n\n    for h in hooks: h.remove()\n    return summary\n\n'"
fastai/fastai/nlp.py,4,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .model import *\nfrom .dataset import *\nfrom .learner import *\nfrom .text import *\nfrom .lm_rnn import *\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.datasets import language_modeling\n\nclass DotProdNB(nn.Module):\n    def __init__(self, nf, ny, w_adj=0.4, r_adj=10):\n        super().__init__()\n        self.w_adj,self.r_adj = w_adj,r_adj\n        self.w = nn.Embedding(nf+1, 1, padding_idx=0)\n        self.w.weight.data.uniform_(-0.1,0.1)\n        self.r = nn.Embedding(nf+1, ny)\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        w = self.w(feat_idx)\n        r = self.r(feat_idx)\n        x = ((w+self.w_adj)*r/self.r_adj).sum(1)\n        return F.softmax(x)\n\nclass SimpleNB(nn.Module):\n    def __init__(self, nf, ny):\n        super().__init__()\n        self.r = nn.Embedding(nf+1, ny, padding_idx=0)\n        self.b = nn.Parameter(torch.zeros(ny,))\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        r = self.r(feat_idx)\n        x = r.sum(1)+self.b\n        return F.softmax(x)\n\nclass BOW_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.l1_loss\n\ndef calc_pr(y_i, x, y, b):\n    idx = np.argwhere((y==y_i)==b)\n    p = x[idx[:,0]].sum(0)+1\n    return p/((y==y_i)==b).sum()\n\ndef calc_r(y_i, x, y):\n    return np.log(calc_pr(y_i, x, y, True) / calc_pr(y_i, x, y, False))\n\nclass BOW_Dataset(Dataset):\n    def __init__(self, bow, y, max_len):\n        self.bow,self.max_len = bow,max_len\n        self.c = int(y.max())+1\n        self.n,self.vocab_size = bow.shape\n        self.y = one_hot(y,self.c).astype(np.float32)\n        x = self.bow.sign()\n        self.r = np.stack([calc_r(i, x, y).A1 for i in range(self.c)]).T\n\n    def __getitem__(self, i):\n        row = self.bow.getrow(i)\n\n        num_row_entries = row.indices.shape[0]\n        indices = (row.indices + 1).astype(np.int64)\n        data = (row.data).astype(np.int64)\n\n        if num_row_entries < self.max_len:\n            # If short, pad\n            indices = np.pad(indices, (self.max_len - num_row_entries, 0), mode=\'constant\')\n            data = np.pad(data, (self.max_len - num_row_entries, 0), mode=\'constant\')\n        else:\n            # If long, truncate\n            indices, data = indices[-self.max_len:], data[-self.max_len:]\n\n        return indices, data, min(self.max_len, num_row_entries), self.y[i]\n\n    def __len__(self): return len(self.bow.indptr)-1\n\n\nclass TextClassifierData(ModelData):\n    @property\n    def c(self): return self.trn_ds.c\n\n    @property\n    def r(self):\n        return torch.Tensor(np.concatenate([np.zeros((1,self.c)), self.trn_ds.r]))\n\n    def get_model(self, f, **kwargs):\n        m = to_gpu(f(self.trn_ds.vocab_size, self.c, **kwargs))\n        m.r.weight.data = to_gpu(self.r)\n        m.r.weight.requires_grad = False\n        model = BasicModel(m)\n        return BOW_Learner(self, model, metrics=[accuracy_thresh(0.5)], opt_fn=optim.Adam)\n\n    def dotprod_nb_learner(self, **kwargs): return self.get_model(DotProdNB, **kwargs)\n    def nb_learner(self, **kwargs): return self.get_model(SimpleNB, **kwargs)\n\n    @classmethod\n    def from_bow(cls, trn_bow, trn_y, val_bow, val_y, sl):\n        trn_ds = BOW_Dataset(trn_bow, trn_y, sl)\n        val_ds = BOW_Dataset(val_bow, val_y, sl)\n        trn_dl = DataLoader(trn_ds, 64, True)\n        val_dl = DataLoader(val_ds, 64, False)\n        return cls(\'.\', trn_dl, val_dl)\n\n\ndef flip_tensor(x, dim):\n    xsize = x.size()\n    dim = x.dim() + dim if dim < 0 else dim\n    x = x.view(-1, *xsize[dim:])\n    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1,\n                      -1, -1), (\'cpu\',\'cuda\')[x.is_cuda])().long(), :]\n    return x.view(xsize)\n\n\nclass LanguageModelLoader():\n\n    def __init__(self, ds, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        text = sum([o.text for o in ds], [])\n        fld = ds.fields[\'text\']\n        nums = fld.numericalize([text],device=None if torch.cuda.is_available() else -1)\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        return self\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def __next__(self):\n        if self.i >= self.n-1 or self.iter>=len(self): raise StopIteration\n        bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n        seq_len = max(5, int(np.random.normal(bptt, 5)))\n        res = self.get_batch(self.i, seq_len)\n        self.i += seq_len\n        self.iter += 1\n        return res\n\n    def batchify(self, data):\n        nb = data.size(0) // self.bs\n        data = data[:nb*self.bs]\n        data = data.view(self.bs, -1).t().contiguous()\n        if self.backwards: data=flip_tensor(data, 0)\n        return to_gpu(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass ConcatTextDataset(torchtext.data.Dataset):\n    def __init__(self, path, text_field, newline_eos=True, encoding=\'utf-8\', **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n        if os.path.isdir(path): paths=glob(f\'{path}/*.*\')\n        else: paths=[path]\n        for p in paths:\n            for line in open(p, encoding=encoding): text += text_field.preprocess(line)\n            if newline_eos: text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n        super().__init__(examples, fields, **kwargs)\n\n\nclass ConcatTextDatasetFromDataFrames(torchtext.data.Dataset):\n    def __init__(self, df, text_field, col, newline_eos=True, **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n\n        text += text_field.preprocess(df[col].str.cat(sep=\' <eos> \'))\n        if (newline_eos): text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n\n        super().__init__(examples, fields, **kwargs)\n\n    @classmethod\n    def splits(cls, train_df=None, val_df=None, test_df=None, keep_nones=False, **kwargs):\n        res = (\n            cls(train_df, **kwargs),\n            cls(val_df, **kwargs),\n            map_none(test_df, partial(cls, **kwargs)))  # not required\n        return res if keep_nones else tuple(d for d in res if d is not None)\n\n\nclass LanguageModelData():\n    """"""\n    This class provides the entry point for dealing with supported NLP tasks.\n    Usage:\n    1.  Use one of the factory constructors (from_dataframes, from_text_files) to\n        obtain an instance of the class.\n    2.  Use the get_model method to return a RNN_Learner instance (a network suited\n        for NLP tasks), then proceed with training.\n\n        Example:\n            >> TEXT = data.Field(lower=True, tokenize=spacy_tok)\n            >> FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n            >> md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=64, bptt=70, min_freq=10)\n\n            >> em_sz = 200  # size of each embedding vector\n            >> nh = 500     # number of hidden activations per layer\n            >> nl = 3       # number of layers\n\n            >> opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n            >> learner = md.get_model(opt_fn, em_sz, nh, nl,\n                           dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n            >> learner.reg_fn = seq2seq_reg\n            >> learner.clip=0.3\n\n            >> learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n\n    """"""\n    def __init__(self, path, field, trn_ds, val_ds, test_ds, bs, bptt, backwards=False, **kwargs):\n        """""" Constructor for the class. An important thing that happens here is\n            that the field\'s ""build_vocab"" method is invoked, which builds the vocabulary\n            for this NLP model.\n\n            Also, three instances of the LanguageModelLoader are constructed; one each\n            for training data (self.trn_dl), validation data (self.val_dl), and the\n            testing data (self.test_dl)\n\n            Args:\n                path (str): testing path\n                field (Field): torchtext field object\n                trn_ds (Dataset): training dataset\n                val_ds (Dataset): validation dataset\n                test_ds (Dataset): testing dataset\n                bs (int): batch size\n                bptt (int): back propagation through time\n                kwargs: other arguments\n        """"""\n        self.bs = bs\n        self.path = path\n        self.trn_ds = trn_ds; self.val_ds = val_ds; self.test_ds = test_ds\n        if not hasattr(field, \'vocab\'): field.build_vocab(self.trn_ds, **kwargs)\n\n        self.pad_idx = field.vocab.stoi[field.pad_token]\n        self.nt = len(field.vocab)\n\n        factory = lambda ds: LanguageModelLoader(ds, bs, bptt, backwards=backwards)\n        self.trn_dl = factory(self.trn_ds)\n        self.val_dl = factory(self.val_ds)\n        self.test_dl = map_none(self.test_ds, factory)  # not required\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        """""" Method returns a RNN_Learner object, that wraps an instance of the RNN_Encoder module.\n\n        Args:\n            opt_fn (Optimizer): the torch optimizer function to use\n            emb_sz (int): embedding size\n            n_hid (int): number of hidden inputs\n            n_layers (int): number of hidden layers\n            kwargs: other arguments\n\n        Returns:\n            An instance of the RNN_Learner class.\n\n        """"""\n        m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = SingleModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    @classmethod\n    def from_dataframes(cls, path, field, col, train_df, val_df, test_df=None, bs=64, bptt=70, **kwargs):\n        trn_ds, val_ds, test_ds = ConcatTextDatasetFromDataFrames.splits(\n            text_field=field, col=col, train_df=train_df, val_df=val_df, test_df=test_df, keep_nones=True)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n    @classmethod\n    def from_text_files(cls, path, field, train, validation, test=None, bs=64, bptt=70, **kwargs):\n        """""" Method used to instantiate a LanguageModelData object that can be used for a\n            supported nlp task.\n\n        Args:\n            path (str): the absolute path in which temporary model data will be saved\n            field (Field): torchtext field\n            train (str): file location of the training data\n            validation (str): file location of the validation data\n            test (str): file location of the testing data\n            bs (int): batch size to use\n            bptt (int): back propagation through time hyper-parameter\n            kwargs: other arguments\n\n        Returns:\n            a LanguageModelData instance, which most importantly, provides us the datasets for training,\n                validation, and testing\n\n        Note:\n            The train, validation, and test path can be pointed to any file (or folder) that contains a valid\n                text corpus.\n\n        """"""\n        trn_ds, val_ds, test_ds = ConcatTextDataset.splits(\n            path, text_field=field, train=train, validation=validation, test=test)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n\nclass TextDataLoader():\n    def __init__(self, src, x_fld, y_fld):\n        self.src,self.x_fld,self.y_fld = src,x_fld,y_fld\n\n    def __len__(self): return len(self.src)\n\n    def __iter__(self):\n        it = iter(self.src)\n        for i in range(len(self)):\n            b = next(it)\n            yield getattr(b, self.x_fld).data, getattr(b, self.y_fld).data\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n\nclass TextData(ModelData):\n    def create_td(self, it): return TextDataLoader(it, self.text_fld, self.label_fld)\n\n    @classmethod\n    def from_splits(cls, path, splits, bs, text_name=\'text\', label_name=\'label\'):\n        text_fld = splits[0].fields[text_name]\n        label_fld = splits[0].fields[label_name]\n        if hasattr(label_fld, \'build_vocab\'): label_fld.build_vocab(splits[0])\n        iters = torchtext.data.BucketIterator.splits(splits, batch_size=bs)\n        trn_iter,val_iter,test_iter = iters[0],iters[1],None\n        test_dl = None\n        if len(iters) == 3:\n            test_iter = iters[2]\n            test_dl = TextDataLoader(test_iter, text_name, label_name)\n        trn_dl = TextDataLoader(trn_iter, text_name, label_name)\n        val_dl = TextDataLoader(val_iter, text_name, label_name)\n        obj = cls.from_dls(path, trn_dl, val_dl, test_dl)\n        obj.bs = bs\n        obj.pad_idx = text_fld.vocab.stoi[text_fld.pad_token]\n        obj.nt = len(text_fld.vocab)\n        obj.c = (len(label_fld.vocab) if hasattr(label_fld, \'vocab\')\n                 else len(getattr(splits[0][0], label_name)))\n        return obj\n\n    def to_model(self, m, opt_fn):\n        model = TextModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    def get_model(self, opt_fn, max_sl, bptt, emb_sz, n_hid, n_layers, dropout, **kwargs):\n        m = get_rnn_classifer(bptt, max_sl, self.c, self.nt,\n              layers=[emb_sz*3, self.c], drops=[dropout],\n              emb_sz=emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=self.pad_idx, **kwargs)\n        return self.to_model(m, opt_fn)\n\n'"
fastai/fastai/plots.py,0,"b'from .imports import *\nfrom .torch_imports import *\nfrom sklearn.metrics import confusion_matrix\n\ndef ceildiv(a, b):\n    return -(-a // b)\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None, maintitle=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None:\n        plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else \'none\')\n\n\ndef plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n    """"""Plots images given image files.\n\n    Arguments:\n        im_paths (list): list of paths\n        figsize (tuple): figure size\n        rows (int): number of rows\n        titles (list): list of titles\n        maintitle (string): main title\n    """"""\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(imspaths)):\n        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        img = plt.imread(imspaths[i])\n        plt.imshow(img)\n\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title=\'Confusion matrix\', cmap=plt.cm.Blues, figsize=None):\n    """"""\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    (This function is copied from the scikit docs.)\n    """"""\n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize: cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=""center"", color=""white"" if cm[i, j] > thresh else ""black"")\n\n    plt.tight_layout()\n    plt.ylabel(\'True label\')\n    plt.xlabel(\'Predicted label\')\n\ndef plots_raw(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])\n\ndef load_img_id(ds, idx, path): return np.array(PIL.Image.open(os.path.join(path, ds.fnames[idx])))\n\n\nclass ImageModelResults():\n    """""" Visualize the results of an image model\n\n    Arguments:\n        ds (dataset): a dataset which contains the images\n        log_preds (numpy.ndarray): predictions for the dataset in log scale\n\n    Returns:\n        ImageModelResults\n    """"""\n    def __init__(self, ds, log_preds):\n        """"""Initialize an ImageModelResults class instance""""""\n        self.ds = ds\n        # returns the indices of the maximum value of predictions along axis 1, representing the predicted class\n        # log_preds.shape = (number_of_samples, number_of_classes);\n        # preds.shape = (number_of_samples,)\n        self.preds = np.argmax(log_preds, axis=1)\n        # computes the probabilities\n        self.probs = np.exp(log_preds)\n        # extracts the number of classes\n        self.num_classes = log_preds.shape[1]\n\n    def plot_val_with_title(self, idxs, y):\n        """""" Displays the images and their probabilities of belonging to a certain class\n\n            Arguments:\n                idxs (numpy.ndarray): indexes of the image samples from the dataset\n                y (int): the selected class\n\n            Returns:\n                Plots the images in n rows [rows = n]\n        """"""\n        # if there are any samples to be displayed\n        if len(idxs) > 0:\n            imgs = np.stack([self.ds[x][0] for x in idxs])\n            title_probs = [self.probs[x,y] for x in idxs]\n\n            return plots(self.ds.denorm(imgs), rows=1, titles=title_probs)\n        # if idxs is empty return false\n        else:\n            return False;\n\n    def most_by_mask(self, mask, y, mult):\n        """""" Extracts the first 4 most correct/incorrect indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n                mult (int): sets the ordering; -1 descending, 1 ascending\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        cnt = min(4, len(idxs))\n        return idxs[np.argsort(mult * self.probs[idxs,y])[:cnt]]\n\n    def most_uncertain_by_mask(self, mask, y):\n        """""" Extracts the first 4 most uncertain indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        # the most uncertain samples will have abs(probs-1/num_classes) close to 0;\n        return idxs[np.argsort(np.abs(self.probs[idxs,y]-(1/self.num_classes)))[:4]]\n\n    def most_by_correct(self, y, is_correct):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        # mult=-1 when the is_correct flag is true -> when we want to display the most correct classes we will make a descending sorting (argsort) because we want that the biggest probabilities to be displayed first.\n        # When is_correct is false, we want to display the most incorrect classes, so we want an ascending sorting since our interest is in the smallest probabilities.\n        mult = -1 if is_correct==True else 1\n        return self.most_by_mask(((self.preds == self.ds.y)==is_correct)\n                                 & (self.ds.y == y), y, mult)\n\n    def plot_by_correct(self, y, is_correct):\n        """""" Plots the images which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n        """"""\n        return self.plot_val_with_title(self.most_by_correct(y, is_correct), y)\n\n    def most_by_uncertain(self, y):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and have probabilities nearest to 1/number_of_classes (eg. 0.5 for 2 classes, 0.33 for 3 classes) for the selected class.\n\n            Arguments:\n                y (int): the selected class\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        return self.most_uncertain_by_mask((self.ds.y == y), y)\n\n    def plot_most_correct(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most correct.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, True)\n    def plot_most_incorrect(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most incorrect.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, False)\n    def plot_most_uncertain(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most uncertain i.e have probabilities nearest to 1/number_of_classes.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_val_with_title(self.most_by_uncertain(y), y)\n'"
fastai/fastai/rnn_reg.py,16,"b'from .torch_imports import *\nfrom .core import *\nfrom functools import wraps\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef dropout_mask(x, sz, dropout):\n    """""" Applies a dropout mask whose size is determined by passed argument \'sz\'.\n    Args:\n        x (nn.Variable): A torch Variable object\n        sz (tuple(int, int, int)): The expected size of the new tensor\n        dropout (float): The dropout fraction to apply\n\n    This method uses the bernoulli distribution to decide which activations to keep.\n    Additionally, the sampled activations is rescaled is using the factor 1/(1 - dropout).\n\n    In the example given below, one can see that approximately .8 fraction of the\n    returned tensors are zero. Rescaling with the factor 1/(1 - 0.8) returns a tensor\n    with 5\'s in the unit places.\n\n    The official link to the pytorch bernoulli function is here:\n        http://pytorch.org/docs/master/torch.html#torch.bernoulli\n\n    Examples:\n        >>> a_Var = torch.autograd.Variable(torch.Tensor(2, 3, 4).uniform_(0, 1), requires_grad=False)\n        >>> a_Var\n            Variable containing:\n            (0 ,.,.) =\n              0.6890  0.5412  0.4303  0.8918\n              0.3871  0.7944  0.0791  0.5979\n              0.4575  0.7036  0.6186  0.7217\n            (1 ,.,.) =\n              0.8354  0.1690  0.1734  0.8099\n              0.6002  0.2602  0.7907  0.4446\n              0.5877  0.7464  0.4257  0.3386\n            [torch.FloatTensor of size 2x3x4]\n        >>> a_mask = dropout_mask(a_Var.data, (1,a_Var.size(1),a_Var.size(2)), dropout=0.8)\n        >>> a_mask\n            (0 ,.,.) =\n              0  5  0  0\n              0  0  0  5\n              5  0  5  0\n            [torch.FloatTensor of size 1x3x4]\n    """"""\n    return x.new(*sz).bernoulli_(1-dropout)/(1-dropout)\n\n\nclass LockedDropout(nn.Module):\n    def __init__(self, p=0.5):\n        super().__init__()\n        self.p=p\n\n    def forward(self, x):\n        if not self.training or not self.p: return x\n        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n        return Variable(m, requires_grad=False) * x\n\n\nclass WeightDrop(torch.nn.Module):\n    """"""A custom torch layer that serves as a wrapper on another torch layer.\n    Primarily responsible for updating the weights in the wrapped module based\n    on a specified dropout.\n    """"""\n    def __init__(self, module, dropout, weights=[\'weight_hh_l0\']):\n        """""" Default constructor for the WeightDrop module\n\n        Args:\n            module (torch.nn.Module): A pytorch layer being wrapped\n            dropout (float): a dropout value to apply\n            weights (list(str)): the parameters of the wrapped **module**\n                which should be fractionally dropped.\n        """"""\n        super().__init__()\n        self.module,self.weights,self.dropout = module,weights,dropout\n        self._setup()\n\n    def _setup(self):\n        """""" for each string defined in self.weights, the corresponding\n        attribute in the wrapped module is referenced, then deleted, and subsequently\n        registered as a new parameter with a slightly modified name.\n\n        Args:\n            None\n\n         Returns:\n             None\n        """"""\n        if isinstance(self.module, torch.nn.RNNBase): self.module.flatten_parameters = noop\n        for name_w in self.weights:\n            w = getattr(self.module, name_w)\n            del self.module._parameters[name_w]\n            self.module.register_parameter(name_w + \'_raw\', nn.Parameter(w.data))\n\n\n    def _setweights(self):\n        """""" Uses pytorch\'s built-in dropout function to apply dropout to the parameters of\n        the wrapped module.\n\n        Args:\n            None\n        Returns:\n            None\n        """"""\n        for name_w in self.weights:\n            raw_w = getattr(self.module, name_w + \'_raw\')\n            w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n            setattr(self.module, name_w, w)\n\n    def forward(self, *args):\n        """""" updates weights and delegates the propagation of the tensor to the wrapped module\'s\n        forward method\n\n        Args:\n            *args: supplied arguments\n\n        Returns:\n            tensor obtained by running the forward method on the wrapped module.\n        """"""\n        self._setweights()\n        return self.module.forward(*args)\n\nclass EmbeddingDropout(nn.Module):\n\n    """""" Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\n    Uses the dropout_mask custom layer to achieve this.\n\n    Args:\n        embed (torch.nn.Embedding): An embedding torch layer\n        words (torch.nn.Variable): A torch variable\n        dropout (float): dropout fraction to apply to the embedding weights\n        scale (float): additional scaling to apply to the modified embedding weights\n\n    Returns:\n        tensor of size: (batch_size x seq_length x embedding_size)\n\n    Example:\n\n    >> embed = torch.nn.Embedding(10,3)\n    >> words = Variable(torch.LongTensor([[1,2,4,5] ,[4,3,2,9]]))\n    >> words.size()\n        (2,4)\n    >> embed_dropout_layer = EmbeddingDropout(embed)\n    >> dropout_out_ = embed_dropout_layer(embed, words, dropout=0.40)\n    >> dropout_out_\n        Variable containing:\n        (0 ,.,.) =\n          1.2549  1.8230  1.9367\n          0.0000 -0.0000  0.0000\n          2.2540 -0.1299  1.5448\n          0.0000 -0.0000 -0.0000\n\n        (1 ,.,.) =\n          2.2540 -0.1299  1.5448\n         -4.0457  2.4815 -0.2897\n          0.0000 -0.0000  0.0000\n          1.8796 -0.4022  3.8773\n        [torch.FloatTensor of size 2x4x3]\n    """"""\n\n    def __init__(self, embed):\n        super().__init__()\n        self.embed = embed\n\n    def forward(self, words, dropout=0.1, scale=None):\n        if dropout:\n            size = (self.embed.weight.size(0),1)\n            mask = Variable(dropout_mask(self.embed.weight.data, size, dropout))\n            masked_embed_weight = mask * self.embed.weight\n        else: masked_embed_weight = self.embed.weight\n\n        if scale: masked_embed_weight = scale * masked_embed_weight\n\n        padding_idx = self.embed.padding_idx\n        if padding_idx is None: padding_idx = -1\n\n        \n        if IS_TORCH_04:\n            X = F.embedding(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n        else:\n            X = self.embed._backend.Embedding.apply(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n\n        return X\n'"
fastai/fastai/rnn_train.py,2,b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom .core import *\n\n'
fastai/fastai/set_spawn.py,0,"b""from multiprocessing import set_start_method\nset_start_method('spawn')\n\n"""
fastai/fastai/sgdr.py,1,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\nimport copy\n\n\nclass Callback:\n    \'\'\'\n    An abstract class that all callback(e.g., LossRecorder) classes extends from. \n    Must be extended before usage.\n    \'\'\'\n    def on_train_begin(self): pass\n    def on_batch_begin(self): pass\n    def on_phase_begin(self): pass\n    def on_epoch_end(self, metrics): pass\n    def on_phase_end(self): pass\n    def on_batch_end(self, metrics): pass\n    def on_train_end(self): pass\n\n# Useful for maintaining status of a long-running job.\n# \n# Usage:\n# learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\nclass LoggingCallback(Callback):\n    \'\'\'\n    A class useful for maintaining status of a long-running job.\n    e.g.: learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\n    \'\'\'\n    def __init__(self, save_path):\n        super().__init__()\n        self.save_path=save_path\n    def on_train_begin(self):\n        self.batch = 0\n        self.epoch = 0\n        self.phase = 0\n        self.f = open(self.save_path, ""a"", 1)\n        self.log(""\\ton_train_begin"")\n    def on_batch_begin(self):\n        self.log(str(self.batch)+""\\ton_batch_begin"")\n    def on_phase_begin(self):\n        self.log(str(self.phase)+""\\ton_phase_begin"")\n    def on_epoch_end(self, metrics):\n        self.log(str(self.epoch)+""\\ton_epoch_end: ""+str(metrics))\n        self.epoch += 1\n    def on_phase_end(self):\n        self.log(str(self.phase)+""\\ton_phase_end"")\n        self.phase+=1\n    def on_batch_end(self, metrics):\n        self.log(str(self.batch)+""\\ton_batch_end: ""+str(metrics))\n        self.batch += 1\n    def on_train_end(self):\n        self.log(""\\ton_train_end"")\n        self.f.close()\n    def log(self, string):\n        self.f.write(time.strftime(""%Y-%m-%dT%H:%M:%S"")+""\\t""+string+""\\n"")\n        \nclass LossRecorder(Callback):\n    \'\'\'\n    Saves and displays loss functions and other metrics. \n    Default sched when none is specified in a learner. \n    \'\'\'\n    def __init__(self, layer_opt, save_path=\'\', record_mom=False, metrics=[]):\n        super().__init__()\n        self.layer_opt=layer_opt\n        self.init_lrs=np.array(layer_opt.lrs)\n        self.save_path, self.record_mom, self.metrics = save_path, record_mom, metrics\n\n    def on_train_begin(self):\n        self.losses,self.lrs,self.iterations = [],[],[]\n        self.val_losses, self.rec_metrics = [], []\n        if self.record_mom:\n            self.momentums = []\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n        self.save_metrics(metrics)\n\n    def on_batch_end(self, loss):\n        self.iteration += 1\n        self.lrs.append(self.layer_opt.lr)\n        self.iterations.append(self.iteration)\n        if isinstance(loss, list):\n            self.losses.append(loss[0])\n            self.save_metrics(loss[1:])\n        else: self.losses.append(loss)\n        if self.record_mom: self.momentums.append(self.layer_opt.mom)\n\n    def save_metrics(self,vals):\n        self.val_losses.append(vals[0][0] if isinstance(vals[0], Iterable) else vals[0])\n        if len(vals) > 2: self.rec_metrics.append(vals[1:])\n        elif len(vals) == 2: self.rec_metrics.append(vals[1])\n\n    def plot_loss(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        plots loss function as function of iterations. \n        When used in Jupyternotebook, plot will be displayed in notebook. Else, plot will be displayed in console and both plot and loss are saved in save_path. \n        \'\'\'\n        if not in_ipynb(): plt.switch_backend(\'agg\')\n        plt.plot(self.iterations[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'loss_plot.png\'))\n            np.save(os.path.join(self.save_path, \'losses.npy\'), self.losses[10:])\n\n    def plot_lr(self):\n        \'\'\'Plots learning rate in jupyter notebook or console, depending on the enviroment of the learner.\'\'\'\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        if self.record_mom:\n            fig, axs = plt.subplots(1,2,figsize=(12,4))\n            for i in range(0,2): axs[i].set_xlabel(\'iterations\')\n            axs[0].set_ylabel(\'learning rate\')\n            axs[1].set_ylabel(\'momentum\')\n            axs[0].plot(self.iterations,self.lrs)\n            axs[1].plot(self.iterations,self.momentums)   \n        else:\n            plt.xlabel(""iterations"")\n            plt.ylabel(""learning rate"")\n            plt.plot(self.iterations, self.lrs)\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n\n\nclass LR_Updater(LossRecorder):\n    \'\'\'\n    Abstract class where all Learning Rate updaters inherit from. (e.g., CirularLR)\n    Calculates and updates new learning rate and momentum at the end of each batch. \n    Have to be extended. \n    \'\'\'\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n\n    def on_batch_end(self, loss):\n        res = super().on_batch_end(loss)\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n        return res\n\n    def update_lr(self):\n        new_lrs = self.calc_lr(self.init_lrs)\n        self.layer_opt.set_lrs(new_lrs)\n    \n    def update_mom(self):\n        new_mom = self.calc_mom()\n        self.layer_opt.set_mom(new_mom)\n\n    @abstractmethod\n    def calc_lr(self, init_lrs): raise NotImplementedError\n    \n    @abstractmethod\n    def calc_mom(self): raise NotImplementedError\n\n\nclass LR_Finder(LR_Updater):\n    \'\'\'\n    Helps you find an optimal learning rate for a model, as per suggetion of 2015 CLR paper. \n    Learning rate is increased in linear or log scale, depending on user input, and the result of the loss funciton is retained and can be plotted later. \n    \'\'\'\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics = []):\n        self.linear, self.stop_dv = linear, True\n        ratio = end_lr/layer_opt.lr\n        self.lr_mult = (ratio/nb) if linear else ratio**(1/nb)\n        super().__init__(layer_opt,metrics=metrics)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.best=1e9\n\n    def calc_lr(self, init_lrs):\n        mult = self.lr_mult*self.iteration if self.linear else self.lr_mult**self.iteration\n        return init_lrs * mult\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_dv and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        return super().on_batch_end(metrics)\n\n    def plot(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        Plots the loss function with respect to learning rate, in log scale. \n        \'\'\'\n        plt.ylabel(""loss"")\n        plt.xlabel(""learning rate (log scale)"")\n        plt.plot(self.lrs[n_skip:-(n_skip_end+1)], self.losses[n_skip:-(n_skip_end+1)])\n        plt.xscale(\'log\')\n\nclass LR_Finder2(LR_Finder):\n    """"""\n        A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n    """"""\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics=[], stop_dv=True):\n        self.nb, self.metrics = nb, metrics\n        super().__init__(layer_opt, nb, end_lr, linear, metrics)\n        self.stop_dv = stop_dv\n\n    def on_batch_end(self, loss):\n        if self.iteration == self.nb:\n            return True\n        return super().on_batch_end(loss)\n\n    def plot(self, n_skip=10, n_skip_end=5, smoothed=True):\n        if self.metrics is None: self.metrics = []\n        n_plots = len(self.metrics)+2\n        fig, axs = plt.subplots(n_plots,figsize=(6,4*n_plots))\n        for i in range(0,n_plots): axs[i].set_xlabel(\'learning rate\')\n        axs[0].set_ylabel(\'training loss\')\n        axs[1].set_ylabel(\'validation loss\')\n        for i,m in enumerate(self.metrics): \n            axs[i+2].set_ylabel(m.__name__)\n            if len(self.metrics) == 1:\n                values = self.rec_metrics\n            else:\n                values = [rec[i] for rec in self.rec_metrics]\n            if smoothed: values = smooth_curve(values,0.98)\n            axs[i+2].plot(self.lrs[n_skip:-n_skip_end], values[n_skip:-n_skip_end])\n        plt_val_l = smooth_curve(self.val_losses, 0.98) if smoothed else self.val_losses\n        axs[0].plot(self.lrs[n_skip:-n_skip_end],self.losses[n_skip:-n_skip_end])\n        axs[1].plot(self.lrs[n_skip:-n_skip_end],plt_val_l[n_skip:-n_skip_end])\n\nclass CosAnneal(LR_Updater):\n    \'\'\' Learning rate scheduler that inpelements a cosine annealation schedule. \'\'\'\n    def __init__(self, layer_opt, nb, on_cycle_end=None, cycle_mult=1):\n        self.nb,self.on_cycle_end,self.cycle_mult = nb,on_cycle_end,cycle_mult\n        super().__init__(layer_opt)\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.iteration<self.nb/20:\n            self.cycle_iter += 1\n            return init_lrs/100.\n\n        cos_out = np.cos(np.pi*(self.cycle_iter)/self.nb) + 1\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            self.nb *= self.cycle_mult\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return init_lrs / 2 * cos_out\n\n\nclass CircularLR(LR_Updater):\n    \'\'\'\n    An learning rate updater that implements the CirularLearningRate (CLR) scheme. \n    Learning rate is increased then decreased linearly. \n    \'\'\'\n    def __init__(self, layer_opt, nb, div=4, cut_div=8, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.cut_div,self.on_cycle_end = nb,div,cut_div,on_cycle_end\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = 1 - (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = self.cycle_iter/cut_pt\n        res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n    \n    def calc_mom(self):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = 1 - self.cycle_iter/cut_pt\n        res = self.moms[1] + pct * (self.moms[0] - self.moms[1])\n        return res\n\nclass CircularLR_beta(LR_Updater):\n    def __init__(self, layer_opt, nb, div=10, pct=10, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.pct,self.on_cycle_end = nb,div,pct,on_cycle_end\n        self.cycle_nb = int(nb * (1-pct/100) / 2)\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.cycle_iter>2 * self.cycle_nb:\n            pct = (self.cycle_iter - 2*self.cycle_nb)/(self.nb - 2*self.cycle_nb)\n            res = init_lrs * (1 + (pct * (1-100)/100)) / self.div\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n\n    def calc_mom(self):\n        if self.cycle_iter>2*self.cycle_nb:\n            res = self.moms[0]\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        return res\n\n\nclass SaveBestModel(LossRecorder):\n    \n    """""" Save weights of the best model based during training.\n        If metrics are provided, the first metric in the list is used to\n        find the best model. \n        If no metrics are provided, the loss is used.\n        \n        Args:\n            model: the fastai model\n            lr: indicate to use test images; otherwise use validation images\n            name: the name of filename of the weights without \'.h5\'\n        \n        Usage:\n            Briefly, you have your model \'learn\' variable and call fit.\n            >>> learn.fit(lr, 2, cycle_len=2, cycle_mult=1, best_save_name=\'mybestmodel\')\n            ....\n            >>> learn.load(\'mybestmodel\')\n            \n            For more details see http://forums.fast.ai/t/a-code-snippet-to-save-the-best-model-during-training/12066\n \n    """"""\n    def __init__(self, model, layer_opt, metrics, name=\'best_model\'):\n        super().__init__(layer_opt)\n        self.name = name\n        self.model = model\n        self.best_loss = None\n        self.best_acc = None\n        self.save_method = self.save_when_only_loss if metrics==None else self.save_when_acc\n        \n    def save_when_only_loss(self, metrics):\n        loss = metrics[0]\n        if self.best_loss == None or loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n    \n    def save_when_acc(self, metrics):\n        loss, acc = metrics[0], metrics[1]\n        if self.best_acc == None or acc > self.best_acc:\n            self.best_acc = acc\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        elif acc == self.best_acc and  loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        \n    def on_epoch_end(self, metrics):\n        super().on_epoch_end(metrics)\n        self.save_method(metrics)\n\n\nclass WeightDecaySchedule(Callback):\n    def __init__(self, layer_opt, batch_per_epoch, cycle_len, cycle_mult, n_cycles, norm_wds=False, wds_sched_mult=None):\n        """"""\n        Implements the weight decay schedule as mentioned in https://arxiv.org/abs/1711.05101\n\n        :param layer_opt: The LayerOptimizer\n        :param batch_per_epoch: Num batches in 1 epoch\n        :param cycle_len: Num epochs in initial cycle. Subsequent cycle_len = previous cycle_len * cycle_mult\n        :param cycle_mult: Cycle multiplier\n        :param n_cycles: Number of cycles to be executed\n        """"""\n        super().__init__()\n\n        self.layer_opt = layer_opt\n        self.batch_per_epoch = batch_per_epoch\n        self.init_wds = np.array(layer_opt.wds)  # Weights as set by user\n        self.init_lrs = np.array(layer_opt.lrs)  # Learning rates as set by user\n        self.new_wds = None                      # Holds the new weight decay factors, calculated in on_batch_begin()\n        self.param_groups_old = None             # Caches the old parameter values in on_batch_begin()\n        self.iteration = 0\n        self.epoch = 0\n        self.wds_sched_mult = wds_sched_mult\n        self.norm_wds = norm_wds\n        self.wds_history = list()\n\n        # Pre calculating the number of epochs in the cycle of current running epoch\n        self.epoch_to_num_cycles, i = dict(), 0\n        for cycle in range(n_cycles):\n            for _ in range(cycle_len):\n                self.epoch_to_num_cycles[i] = cycle_len\n                i += 1\n            cycle_len *= cycle_mult\n\n    def on_train_begin(self):\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_batch_begin(self):\n        # Prepare for decay of weights\n\n        # Default weight decay (as provided by user)\n        wdn = self.init_wds\n\n        # Weight decay multiplier (The \'eta\' in the paper). Optional.\n        wdm = 1.0\n        if self.wds_sched_mult is not None:\n            wdm = self.wds_sched_mult(self)\n\n        # Weight decay normalized. Optional.\n        if self.norm_wds:\n            wdn = wdn / np.sqrt(self.batch_per_epoch * self.epoch_to_num_cycles[self.epoch])\n\n        # Final wds\n        self.new_wds = wdm * wdn\n\n        # Record the wds\n        self.wds_history.append(self.new_wds)\n\n        # Set weight_decay with zeros so that it is not applied in Adam, we will apply it outside in on_batch_end()\n        self.layer_opt.set_wds(torch.zeros(self.new_wds.size))\n        # We have to save the existing weights before the optimizer changes the values\n        self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n        self.iteration += 1\n\n    def on_batch_end(self, loss):\n        # Decay the weights\n        for group, group_old, wds in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.new_wds):\n            for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                if p.grad is None:\n                    continue\n                p.data = p.data.add(-wds, p_old.data)\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n\nclass DecayType(IntEnum):\n    \'\'\' Data class, each decay type is assigned a number. \'\'\'\n    NO = 1\n    LINEAR = 2\n    COSINE = 3\n    EXPONENTIAL = 4\n    POLYNOMIAL = 5\n\nclass DecayScheduler():\n    \'\'\'Given initial and endvalue, this class generates the next value depending on decay type and number of iterations. (by calling next_val().) \'\'\'\n\n    def __init__(self, dec_type, num_it, start_val, end_val=None, extra=None):\n        self.dec_type, self.nb, self.start_val, self.end_val, self.extra = dec_type, num_it, start_val, end_val, extra\n        self.it = 0\n        if self.end_val is None and not (self.dec_type in [1,4]): self.end_val = 0\n    \n    def next_val(self):\n        self.it += 1\n        if self.dec_type == DecayType.NO:\n            return self.start_val\n        elif self.dec_type == DecayType.LINEAR:\n            pct = self.it/self.nb\n            return self.start_val + pct * (self.end_val-self.start_val)\n        elif self.dec_type == DecayType.COSINE:\n            cos_out = np.cos(np.pi*(self.it)/self.nb) + 1\n            return self.end_val + (self.start_val-self.end_val) / 2 * cos_out\n        elif self.dec_type == DecayType.EXPONENTIAL:\n            ratio = self.end_val / self.start_val\n            return self.start_val * (ratio **  (self.it/self.nb))\n        elif self.dec_type == DecayType.POLYNOMIAL:\n            return self.end_val + (self.start_val-self.end_val) * (1 - self.it/self.nb)**self.extra\n        \n\nclass TrainingPhase():\n    \'\'\'\n    Object with training information for each phase, when multiple phases are involved during training.  \n    Used in fit_opt_sched in learner.py\n    \'\'\'\n    def __init__(self, epochs=1, opt_fn=optim.SGD, lr=1e-2, lr_decay=DecayType.NO, momentum=0.9,\n                momentum_decay=DecayType.NO, beta=None, wds=None, wd_loss=True):\n        """"""\n        Creates an object containing all the relevant informations for one part of a model training.\n\n        Args\n        epochs: number of epochs to train like this\n        opt_fn: an optimizer (example optim.Adam)\n        lr: one learning rate or a tuple of the form (start_lr,end_lr)\n          each of those can be a list/numpy array for differential learning rates\n        lr_decay: a DecayType object specifying how the learning rate should change\n        momentum: one momentum (or beta1 in case of Adam), or a tuple of the form (start_mom,end_mom)\n        momentum_decay: a DecayType object specifying how the momentum should change\n        beta: beta2 parameter of Adam or alpha parameter of RMSProp\n        wds: weight decay (can be an array for differential wds)\n        """"""\n        self.epochs, self.opt_fn, self.lr, self.momentum, self.beta, self.wds = epochs, opt_fn, lr, momentum, beta, wds\n        if isinstance(lr_decay,tuple): self.lr_decay, self.extra_lr = lr_decay\n        else: self.lr_decay, self.extra_lr = lr_decay, None\n        if isinstance(momentum_decay,tuple): self.mom_decay, self.extra_mom = momentum_decay\n        else: self.mom_decay, self.extra_mom = momentum_decay, None\n        self.wd_loss = wd_loss\n\n    def phase_begin(self, layer_opt, nb_batches):\n        self.layer_opt = layer_opt\n        if isinstance(self.lr, tuple): start_lr,end_lr = self.lr\n        else: start_lr, end_lr = self.lr, None\n        self.lr_sched = DecayScheduler(self.lr_decay, nb_batches * self.epochs, start_lr, end_lr, extra=self.extra_lr)\n        if isinstance(self.momentum, tuple): start_mom,end_mom = self.momentum\n        else: start_mom, end_mom = self.momentum, None\n        self.mom_sched = DecayScheduler(self.mom_decay, nb_batches * self.epochs, start_mom, end_mom, extra=self.extra_mom)\n        self.layer_opt.set_opt_fn(self.opt_fn)\n        self.layer_opt.set_lrs(start_lr)\n        self.layer_opt.set_mom(start_mom)\n        if self.beta is not None: self.layer_opt.set_beta(self.beta)\n        if self.wds is not None:\n            if not isinstance(self.wds, Iterable): self.wds=[self.wds]\n            if len(self.wds)==1: self.wds=self.wds*len(self.layer_opt.layer_groups) \n            if self.wd_loss: self.layer_opt.set_wds(self.wds)\n            else: self.layer_opt.set_wds([0] * len(self.wds))\n    \n    def on_batch_begin(self):\n        if not self.wd_loss: self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n\n    def update(self):\n        new_lr, new_mom = self.lr_sched.next_val(), self.mom_sched.next_val()\n        self.layer_opt.set_lrs(new_lr)\n        self.layer_opt.set_mom(new_mom)\n        if not self.wd_loss: # Decay the weights outside of the loss\n            if not isinstance(new_lr, Iterable): new_lr=[new_lr]\n            if len(new_lr)==1: new_lr=new_lr*len(self.layer_opt.layer_groups)\n            for group, group_old, wds, lr in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.wds, new_lr):\n                for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                    if p.grad is None: continue\n                    p.data = p.data.add(-wds*lr, p_old.data)\n    \n\nclass OptimScheduler(LossRecorder):\n    \'\'\'Learning rate Scheduler for training involving multiple phases.\'\'\'\n\n    def __init__(self, layer_opt, phases, nb_batches, stop_div = False):\n        self.phases, self.nb_batches, self.stop_div = phases, nb_batches, stop_div\n        super().__init__(layer_opt, record_mom=True)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.phase,self.best=0,1e9\n    \n    def on_batch_begin(self):\n        self.phases[self.phase].on_batch_begin()\n        super().on_batch_begin()\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_div and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        super().on_batch_end(metrics)\n        self.phases[self.phase].update()\n    \n    def on_phase_begin(self):\n        self.phases[self.phase].phase_begin(self.layer_opt, self.nb_batches)\n\n    def on_phase_end(self):\n        self.phase += 1\n\n    def plot_lr(self, show_text=True, show_moms=True):\n        """"""Plots the lr rate/momentum schedule""""""\n        phase_limits = [0]\n        for phase in self.phases:\n            phase_limits.append(phase_limits[-1] + self.nb_batches * phase.epochs)\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        np_plts = 2 if show_moms else 1\n        fig, axs = plt.subplots(1,np_plts,figsize=(6*np_plts,4))\n        if not show_moms: axs = [axs]\n        for i in range(np_plts): axs[i].set_xlabel(\'iterations\')\n        axs[0].set_ylabel(\'learning rate\')\n        axs[0].plot(self.iterations,self.lrs)\n        if show_moms:\n            axs[1].set_ylabel(\'momentum\')\n            axs[1].plot(self.iterations,self.momentums)\n        if show_text:   \n            for i, phase in enumerate(self.phases):\n                text = phase.opt_fn.__name__\n                if phase.wds is not None: text+=\'\\nwds=\'+str(phase.wds)\n                if phase.beta is not None: text+=\'\\nbeta=\'+str(phase.beta)\n                for k in range(np_plts):\n                    if i < len(self.phases)-1:\n                        draw_line(axs[k], phase_limits[i+1])\n                    draw_text(axs[k], (phase_limits[i]+phase_limits[i+1])/2, text) \n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n    \n    def plot(self, n_skip=10, n_skip_end=5, linear=None):\n        if linear is None: linear = self.phases[-1].lr_decay == DecayType.LINEAR\n        plt.ylabel(""loss"")\n        plt.plot(self.lrs[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if linear: plt.xlabel(""learning rate"")\n        else:\n            plt.xlabel(""learning rate (log scale)"")\n            plt.xscale(\'log\')\n\ndef draw_line(ax,x):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.plot([x,x],[ymin,ymax], color=\'red\', linestyle=\'dashed\')\n\ndef draw_text(ax,x, text):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.text(x,(ymin+ymax)/2,text, horizontalalignment=\'center\', verticalalignment=\'center\', fontsize=14, alpha=0.5)\n\ndef smooth_curve(vals, beta):\n    avg_val = 0\n    smoothed = []\n    for (i,v) in enumerate(vals):\n        avg_val = beta * avg_val + (1-beta) * v\n        smoothed.append(avg_val/(1-beta**(i+1)))\n    return smoothed\n'"
fastai/fastai/structured.py,0,"b'from .imports import *\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\n\ndef set_plot_sizes(sml, med, big):\n    plt.rc(\'font\', size=sml)          # controls default text sizes\n    plt.rc(\'axes\', titlesize=sml)     # fontsize of the axes title\n    plt.rc(\'axes\', labelsize=med)    # fontsize of the x and y labels\n    plt.rc(\'xtick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'ytick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'legend\', fontsize=sml)    # legend fontsize\n    plt.rc(\'figure\', titlesize=big)  # fontsize of the figure title\n\ndef parallel_trees(m, fn, n_jobs=8):\n        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    """""" Draws a representation of a random forest in IPython.\n\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    """"""\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub(\'Tree {\',\n       f\'Tree {{ size={size}; ratio={ratio}\', s)))\n\ndef combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = (\'<M8[Y]\', \'<m8[M]\', \'<m8[D]\', \'<m8[W]\', \'<m8[h]\',\n             \'<m8[m]\', \'<m8[s]\', \'<m8[ms]\', \'<m8[us]\', \'<m8[ns]\')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\ndef get_sample(df,n):\n    """""" Gets a random sample of n rows from df, without replacement.\n\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    >>> get_sample(df, 2)\n       col1 col2\n    1     2    b\n    2     3    a\n    """"""\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef add_datepart(df, fldname, drop=True, time=False):\n    """"""add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({ \'A\' : pd.to_datetime([\'3/11/2000\', \'3/12/2000\', \'3/13/2000\'], infer_datetime_format=False) })\n    >>> df\n\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n\n    >>> add_datepart(df, \'A\')\n    >>> df\n\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    """"""\n    fld = df[fldname]\n    if not np.issubdtype(fld.dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub(\'[Dd]ate$\', \'\', fldname)\n    attr = [\'Year\', \'Month\', \'Week\', \'Day\', \'Dayofweek\', \'Dayofyear\',\n            \'Is_month_end\', \'Is_month_start\', \'Is_quarter_end\', \'Is_quarter_start\', \'Is_year_end\', \'Is_year_start\']\n    if time: attr = attr + [\'Hour\', \'Minute\', \'Second\']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + \'Elapsed\'] = fld.astype(np.int64) // 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n\ndef is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n\ndef train_cats(df):\n    """"""Change any columns of strings in a panda\'s dataframe to a column of\n    catagorical values. This applies the changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category\n    """"""\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype(\'category\').cat.as_ordered()\n\ndef apply_cats(df, trn):\n    """"""Changes any columns of strings in df into categorical variables using trn as\n    a template for the category codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values. The category codes are determined by trn.\n\n    trn: A pandas dataframe. When creating a category for df, it looks up the\n        what the category\'s code were in trn and makes those the category codes\n        for df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category {a : 1, b : 2}\n\n    >>> df2 = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'b\', \'a\', \'a\']})\n    >>> apply_cats(df2, df)\n\n           col1 col2\n        0     1    b\n        1     2    a\n        2     3    a\n\n    now the type of col is category {a : 1, b : 2}\n    """"""\n    for n,c in df.items():\n        if (n in trn.columns) and (trn[n].dtype.name==\'category\'):\n            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n\ndef fix_missing(df, col, name, na_dict):\n    """""" Fill missing data in a column of df with the median, and add a {name}_na column\n    which specifies if the data was missing.\n\n    Parameters:\n    -----------\n    df: The data frame that will be changed.\n\n    col: The column of data to fix by filling in missing data.\n\n    name: The name of the new filled column in df.\n\n    na_dict: A dictionary of values to create na\'s of and the value to insert. If\n        name is not a key of na_dict the median will fill any missing data. Also\n        if name is not a key of na_dict and there is no missing data in col, then\n        no {name}_na column is not created.\n\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1     2    2    True\n    2     3    2   False\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col2\'], \'col2\', {})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {\'col1\' : 500})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1   500    2    True\n    2     3    2   False\n    """"""\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+\'_na\'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    """""" Changes the column col from a categorical type to it\'s integer codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. df[name] will be filled with the integer codes from\n        col.\n\n    col: The column you wish to change into the categories.\n    name: The column name you wish to insert into df. This column will hold the\n        integer codes.\n\n    max_n_cat: If col has more categories than max_n_cat it will not change the\n        it to its integer codes. If max_n_cat is None, then col will always be\n        converted.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> numericalize(df, df[\'col2\'], \'col3\', None)\n\n       col1 col2 col3\n    0     1    a    1\n    1     2    b    2\n    2     3    a    1\n    """"""\n    if not is_numeric_dtype(col) and ( max_n_cat is None or col.nunique()>max_n_cat):\n        df[name] = col.cat.codes+1\n\ndef scale_vars(df, mapper):\n    warnings.filterwarnings(\'ignore\', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper\n\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    """""" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n\n    y_fld: The name of the response variable\n\n    skip_flds: A list of fields that dropped from df.\n\n    ignore_flds: A list of fields that are ignored during processing.\n\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n\n    preproc_fn: A function that gets applied to df.\n\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n\n    subset: Takes a random subset of size subset from df.\n\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n\n        y: y is the response variable\n\n        nas: returns a dictionary of which nas it created, and the associated median.\n\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> x, y, nas = proc_df(df, \'col1\')\n    >>> x\n\n       col2\n    0     1\n    1     2\n    2     1\n\n    >>> data = DataFrame(pet=[""cat"", ""dog"", ""dog"", ""fish"", ""cat"", ""dog"", ""cat"", ""fish""],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    """"""\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    df = df.copy()\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({\'cols\':df.columns, \'imp\':m.feature_importances_}\n                       ).sort_values(\'imp\', ascending=False)\n\ndef set_rf_samples(n):\n    """""" Changes Scikit learn\'s random forests to give each tree a random sample of\n    n random rows.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    """""" Undoes the changes produced by set_rf_samples.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\ndef get_nn_mappers(df, cat_vars, contin_vars):\n    # Replace nulls with 0 for continuous, """" for categorical.\n    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n    for v in cat_vars: df[v].fillna(\'#NA#\', inplace=True)\n\n    # list of tuples, containing variable and instance of a transformer for that variable\n    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n    return DataFrameMapper(cat_maps).fit(df), DataFrameMapper(contin_maps).fit(df)\n'"
fastai/fastai/swa.py,3,"b'""""""\n    From the paper:\n        Averaging Weights Leads to Wider Optima and Better Generalization\n        Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, Andrew Gordon Wilson\n        https://arxiv.org/abs/1803.05407\n        2018\n        \n    Author\'s implementation: https://github.com/timgaripov/swa\n""""""\n\nimport torch\nfrom .sgdr import *\nfrom .core import *\n\n\nclass SWA(Callback):\n    def __init__(self, model, swa_model, swa_start):\n        super().__init__()\n        self.model,self.swa_model,self.swa_start=model,swa_model,swa_start\n        \n    def on_train_begin(self):\n        self.epoch = 0\n        self.swa_n = 0\n\n    def on_epoch_end(self, metrics):\n        if (self.epoch + 1) >= self.swa_start:\n            self.update_average_model()\n            self.swa_n += 1\n            \n        self.epoch += 1\n            \n    def update_average_model(self):\n        # update running average of parameters\n        model_params = self.model.parameters()\n        swa_params = self.swa_model.parameters()\n        for model_param, swa_param in zip(model_params, swa_params):\n            swa_param.data *= self.swa_n\n            swa_param.data += model_param.data\n            swa_param.data /= (self.swa_n + 1)            \n    \ndef collect_bn_modules(module, bn_modules):\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        bn_modules.append(module)\n\ndef fix_batchnorm(swa_model, train_dl):\n    """"""\n    During training, batch norm layers keep track of a running mean and\n    variance of the previous layer\'s activations. Because the parameters\n    of the SWA model are computed as the average of other models\' parameters,\n    the SWA model never sees the training data itself, and therefore has no\n    opportunity to compute the correct batch norm statistics. Before performing \n    inference with the SWA model, we perform a single pass over the training data\n    to calculate an accurate running mean and variance for each batch norm layer.\n    """"""\n    bn_modules = []\n    swa_model.apply(lambda module: collect_bn_modules(module, bn_modules))\n    \n    if not bn_modules: return\n\n    swa_model.train()\n\n    for module in bn_modules:\n        module.running_mean = torch.zeros_like(module.running_mean)\n        module.running_var = torch.ones_like(module.running_var)\n    \n    momenta = [m.momentum for m in bn_modules]\n\n    inputs_seen = 0\n\n    for (*x,y) in iter(train_dl):        \n        xs = V(x)\n        batch_size = xs[0].size(0)\n\n        momentum = batch_size / (inputs_seen + batch_size)\n        for module in bn_modules:\n            module.momentum = momentum\n                            \n        res = swa_model(*xs)        \n        \n        inputs_seen += batch_size\n                \n    for module, momentum in zip(bn_modules, momenta):\n        module.momentum = momentum    '"
fastai/fastai/text.py,1,"b'from .core import *\nfrom .learner import *\nfrom .lm_rnn import *\nfrom torch.utils.data.sampler import Sampler\nimport spacy\nfrom spacy.symbols import ORTH\n\nre_tok = re.compile(f\'([{string.punctuation}\xe2\x80\x9c\xe2\x80\x9d\xc2\xa8\xc2\xab\xc2\xbb\xc2\xae\xc2\xb4\xc2\xb7\xc2\xba\xc2\xbd\xc2\xbe\xc2\xbf\xc2\xa1\xc2\xa7\xc2\xa3\xe2\x82\xa4\xe2\x80\x98\xe2\x80\x99])\')\ndef tokenize(s): return re_tok.sub(r\' \\1 \', s).split()\n\ndef texts_labels_from_folders(path, folders):\n    texts,labels = [],[]\n    for idx,label in enumerate(folders):\n        for fname in glob(os.path.join(path, label, \'*.*\')):\n            texts.append(open(fname, \'r\').read())\n            labels.append(idx)\n    return texts, np.array(labels).astype(np.int64)\n\ndef numericalize_tok(tokens, max_vocab=50000, min_freq=0, unk_tok=""_unk_"", pad_tok=""_pad_"", bos_tok=""_bos_"", eos_tok=""_eos_""):\n    """"""Takes in text tokens and returns int2tok and tok2int converters\n\n        Arguments:\n        tokens(list): List of tokens. Can be a list of strings, or a list of lists of strings.\n        max_vocab(int): Number of tokens to return in the vocab (sorted by frequency)\n        min_freq(int): Minimum number of instances a token must be present in order to be preserved.\n        unk_tok(str): Token to use when unknown tokens are encountered in the source text.\n        pad_tok(str): Token to use when padding sequences.\n    """"""\n    if isinstance(tokens, str):\n        raise ValueError(""Expected to receive a list of tokens. Received a string instead"")\n    if isinstance(tokens[0], list):\n        tokens = [p for o in tokens for p in o]\n    freq = Counter(tokens)\n    int2tok = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n    unk_id = 3\n    int2tok.insert(0, bos_tok)\n    int2tok.insert(1, pad_tok)\n    int2tok.insert(2, eos_tok)\n    int2tok.insert(unk_id, unk_tok)\n    tok2int = collections.defaultdict(lambda:unk_id, {v:k for k,v in enumerate(int2tok)})\n    return int2tok, tok2int\n\nclass Tokenizer():\n    def __init__(self, lang=\'en\'):\n        self.re_br = re.compile(r\'<\\s*br\\s*/?>\', re.IGNORECASE)\n        self.tok = spacy.load(lang)\n        for w in (\'<eos>\',\'<bos>\',\'<unk>\'):\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\n\n    def sub_br(self,x): return self.re_br.sub(""\\n"", x)\n\n    def spacy_tok(self,x):\n        return [t.text for t in self.tok.tokenizer(self.sub_br(x))]\n\n    re_rep = re.compile(r\'(\\S)(\\1{3,})\')\n    re_word_rep = re.compile(r\'(\\b\\w+\\W+)(\\1{3,})\')\n\n    @staticmethod\n    def replace_rep(m):\n        TK_REP = \'tk_rep\'\n        c,cc = m.groups()\n        return f\' {TK_REP} {len(cc)+1} {c} \'\n\n    @staticmethod\n    def replace_wrep(m):\n        TK_WREP = \'tk_wrep\'\n        c,cc = m.groups()\n        return f\' {TK_WREP} {len(cc.split())+1} {c} \'\n\n    @staticmethod\n    def do_caps(ss):\n        TOK_UP,TOK_SENT,TOK_MIX = \' t_up \',\' t_st \',\' t_mx \'\n        res = []\n        prev=\'.\'\n        re_word = re.compile(\'\\w\')\n        re_nonsp = re.compile(\'\\S\')\n        for s in re.findall(r\'\\w+|\\W+\', ss):\n            res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n    #                 else [TOK_SENT,s.lower()] if (s.istitle() and re_word.search(prev))\n                    else [s.lower()])\n    #         if re_nonsp.search(s): prev = s\n        return \'\'.join(res)\n\n    def proc_text(self, s):\n        s = self.re_rep.sub(Tokenizer.replace_rep, s)\n        s = self.re_word_rep.sub(Tokenizer.replace_wrep, s)\n        s = Tokenizer.do_caps(s)\n        s = re.sub(r\'([/#])\', r\' \\1 \', s)\n        s = re.sub(\' {2,}\', \' \', s)\n        return self.spacy_tok(s)\n\n    @staticmethod\n    def proc_all(ss, lang):\n        tok = Tokenizer(lang)\n        return [tok.proc_text(s) for s in ss]\n\n    @staticmethod\n    def proc_all_mp(ss, lang=\'en\'):\n        ncpus = num_cpus()//2\n        with ProcessPoolExecutor(ncpus) as e:\n            return sum(e.map(Tokenizer.proc_all, ss, [lang]*len(ss)), [])\n\n\nclass TextDataset(Dataset):\n    def __init__(self, x, y, backwards=False, sos=None, eos=None):\n        self.x,self.y,self.backwards,self.sos,self.eos = x,y,backwards,sos,eos\n\n    def __getitem__(self, idx):\n        x = self.x[idx]\n        if self.backwards: x = list(reversed(x))\n        if self.eos is not None: x = x + [self.eos]\n        if self.sos is not None: x = [self.sos]+x\n        return np.array(x),self.y[idx]\n\n    def __len__(self): return len(self.x)\n\n\nclass SortSampler(Sampler):\n    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n    def __len__(self): return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range(len(self.data_source)), key=self.key, reverse=True))\n\n\nclass SortishSampler(Sampler):\n    """"""Returns an iterator that traverses the the data in randomly ordered batches that are approximately the same size.\n    The max key size batch is always returned in the first call because of pytorch cuda memory allocation sequencing.\n    Without that max key returned first multiple buffers may be allocated when the first created isn\'t large enough\n    to hold the next in the sequence.\n    """"""\n    def __init__(self, data_source, key, bs):\n        self.data_source,self.key,self.bs = data_source,key,bs\n\n    def __len__(self): return len(self.data_source)\n\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs*50\n        ck_idx = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n        sort_idx = np.concatenate([sorted(s, key=self.key, reverse=True) for s in ck_idx])\n        sz = self.bs\n        ck_idx = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n        max_ck = np.argmax([ck[0] for ck in ck_idx])  # find the chunk with the largest key,\n        ck_idx[0],ck_idx[max_ck] = ck_idx[max_ck],ck_idx[0]  # then make sure it goes first.\n        sort_idx = np.concatenate(np.random.permutation(ck_idx[1:]))\n        sort_idx = np.concatenate((ck_idx[0], sort_idx))\n        return iter(sort_idx)\n\n\nclass LanguageModelLoader():\n    """""" Returns a language model iterator that iterates through batches that are of length N(bptt,5)\n    The first batch returned is always bptt+25; the max possible width.  This is done because of they way that pytorch\n    allocates cuda memory in order to prevent multiple buffers from being created as the batch width grows.\n    """"""\n    def __init__(self, nums, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        while self.i < self.n-1 and self.iter<len(self):\n            if self.i == 0:\n                seq_len = self.bptt + 5 * 5\n            else:\n                bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n                seq_len = max(5, int(np.random.normal(bptt, 5)))\n            res = self.get_batch(self.i, seq_len)\n            self.i += seq_len\n            self.iter += 1\n            yield res\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def batchify(self, data):\n        nb = data.shape[0] // self.bs\n        data = np.array(data[:nb*self.bs])\n        data = data.reshape(self.bs, -1).T\n        if self.backwards: data=data[::-1]\n        return T(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass LanguageModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [*zip(m.rnns, m.dropouths), (self.model[1], m.dropouti)]\n\n\nclass LanguageModelData():\n    def __init__(self, path, pad_idx, n_tok, trn_dl, val_dl, test_dl=None, **kwargs):\n        self.path,self.pad_idx,self.n_tok = path,pad_idx,n_tok\n        self.trn_dl,self.val_dl,self.test_dl = trn_dl,val_dl,test_dl\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        m = get_language_model(self.n_tok, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = LanguageModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n'"
fastai/fastai/torch_imports.py,6,"b'import os\nimport torch, torchvision, torchtext\nfrom torch import nn, cuda, backends, FloatTensor, LongTensor, optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.nn.init import kaiming_uniform, kaiming_normal\nfrom torchvision.transforms import Compose\nfrom torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\nfrom torchvision.models import vgg16_bn, vgg19_bn\nfrom torchvision.models import densenet121, densenet161, densenet169, densenet201\n\nfrom .models.resnext_50_32x4d import resnext_50_32x4d\nfrom .models.resnext_101_32x4d import resnext_101_32x4d\nfrom .models.resnext_101_64x4d import resnext_101_64x4d\nfrom .models.wrn_50_2f import wrn_50_2f\nfrom .models.inceptionresnetv2 import InceptionResnetV2\nfrom .models.inceptionv4 import inceptionv4\nfrom .models.nasnet import nasnetalarge\nfrom .models.fa_resnet import *\n\nimport warnings\nwarnings.filterwarnings(\'ignore\', message=\'Implicit dimension choice\', category=UserWarning)\n\ndef children(m): return m if isinstance(m, (list, tuple)) else list(m.children())\ndef save_model(m, p): torch.save(m.state_dict(), p)\ndef load_model(m, p): m.load_state_dict(torch.load(p, map_location=lambda storage, loc: storage))\n\ndef load_pre(pre, f, fn):\n    m = f()\n    path = os.path.dirname(__file__)\n    if pre: load_model(m, f\'{path}/weights/{fn}.pth\')\n    return m\n\ndef _fastai_model(name, paper_title, paper_href):\n    def add_docs_wrapper(f):\n        f.__doc__ = f""""""{name} model from\n        `""{paper_title}"" <{paper_href}>`_\n\n        Args:\n           pre (bool): If True, returns a model pre-trained on ImageNet\n        """"""\n        return f\n    return add_docs_wrapper\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inception_4(pre): return children(inceptionv4(pretrained=pre))[0]\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inceptionresnet_2(pre): return load_pre(pre, InceptionResnetV2, \'inceptionresnetv2-d579a627\')\n\n@_fastai_model(\'ResNeXt 50\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext50(pre): return load_pre(pre, resnext_50_32x4d, \'resnext_50_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_32\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101(pre): return load_pre(pre, resnext_101_32x4d, \'resnext_101_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_64\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101_64(pre): return load_pre(pre, resnext_101_64x4d, \'resnext_101_64x4d\')\n\n@_fastai_model(\'Wide Residual Networks\', \'Wide Residual Networks\',\n               \'https://arxiv.org/pdf/1605.07146.pdf\')\ndef wrn(pre): return load_pre(pre, wrn_50_2f, \'wrn_50_2f\')\n\n@_fastai_model(\'Densenet-121\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn121(pre): return children(densenet121(pre))[0]\n\n@_fastai_model(\'Densenet-169\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn161(pre): return children(densenet161(pre))[0]\n\n@_fastai_model(\'Densenet-161\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn169(pre): return children(densenet169(pre))[0]\n\n@_fastai_model(\'Densenet-201\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn201(pre): return children(densenet201(pre))[0]\n\n@_fastai_model(\'Vgg-16 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg16(pre): return children(vgg16_bn(pre))[0]\n\n@_fastai_model(\'Vgg-19 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg19(pre): return children(vgg19_bn(pre))[0]\n\n'"
fastai/fastai/transforms.py,0,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\n\ndef scale_min(im, targ, interpolation=cv2.INTER_AREA):\n    """""" Scales the image so that the smallest axis is of size targ.\n\n    Arguments:\n        im (array): image\n        targ (int): target size\n    """"""\n    r,c,*_ = im.shape\n    ratio = targ/min(r,c)\n    sz = (scale_to(c, ratio, targ), scale_to(r, ratio, targ))\n    return cv2.resize(im, sz, interpolation=interpolation)\n\ndef zoom_cv(x,z):\n    \'\'\'zooms the center of image x, by a factor of z+1 while retaining the origal image size and proportion. \'\'\'\n    if z==0: return x\n    r,c,*_ = x.shape\n    M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)\n    return cv2.warpAffine(x,M,(c,r))\n\ndef stretch_cv(x,sr,sc,interpolation=cv2.INTER_AREA):\n    \'\'\'stretches image x horizontally by sr+1, and vertically by sc+1 while retaining the origal image size and proportion.\'\'\'\n    if sr==0 and sc==0: return x\n    r,c,*_ = x.shape\n    x = cv2.resize(x, None, fx=sr+1, fy=sc+1, interpolation=interpolation)\n    nr,nc,*_ = x.shape\n    cr = (nr-r)//2; cc = (nc-c)//2\n    return x[cr:r+cr, cc:c+cc]\n\ndef dihedral(x, dih):\n    \'\'\'performs any of 8 90 rotations or flips for image x.\n    \'\'\'\n    x = np.rot90(x, dih%4)\n    return x if dih<4 else np.fliplr(x)\n\ndef lighting(im, b, c):\n    \'\'\' adjusts image\'s balance and contrast\'\'\'\n    if b==0 and c==1: return im\n    mu = np.average(im)\n    return np.clip((im-mu)*c+mu+b,0.,1.).astype(np.float32)\n\ndef rotate_cv(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n    """""" Rotates an image by deg degrees\n\n    Arguments:\n        deg (float): degree to rotate.\n    """"""\n    r,c,*_ = im.shape\n    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n\ndef no_crop(im, min_sz=None, interpolation=cv2.INTER_AREA):\n    """""" Returns a squared resized image """"""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    return cv2.resize(im, (min_sz, min_sz), interpolation=interpolation)\n\ndef center_crop(im, min_sz=None):\n    """""" Returns a center crop of an image""""""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    start_r = math.ceil((r-min_sz)/2)\n    start_c = math.ceil((c-min_sz)/2)\n    return crop(im, start_r, start_c, min_sz)\n\ndef googlenet_resize(im, targ, min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p, interpolation=cv2.INTER_AREA):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ\n    \n    References:\n    1. https://arxiv.org/pdf/1409.4842.pdf\n    2. https://arxiv.org/pdf/1802.07888.pdf\n    """"""\n    h,w,*_ = im.shape\n    area = h*w\n    for _ in range(10):\n        targetArea = random.uniform(min_area_frac, 1.0) * area\n        aspectR = random.uniform(min_aspect_ratio, max_aspect_ratio)\n        ww = int(np.sqrt(targetArea * aspectR) + 0.5)\n        hh = int(np.sqrt(targetArea / aspectR) + 0.5)\n        if flip_hw_p:\n            ww, hh = hh, ww\n        if hh <= h and ww <= w:\n            x1 = 0 if w == ww else random.randint(0, w - ww)\n            y1 = 0 if h == hh else random.randint(0, h - hh)\n            out = im[y1:y1 + hh, x1:x1 + ww]\n            out = cv2.resize(out, (targ, targ), interpolation=interpolation)\n            return out\n    out = scale_min(im, targ, interpolation=interpolation)\n    out = center_crop(out)\n    return out\n\ndef cutout(im, n_holes, length):\n    \'\'\' cuts out n_holes number of square holes of size length in image at random locations. holes may be overlapping. \'\'\'\n    r,c,*_ = im.shape\n    mask = np.ones((r, c), np.int32)\n    for n in range(n_holes):\n        y = np.random.randint(length / 2, r - length / 2)\n        x = np.random.randint(length / 2, c - length / 2)\n\n        y1 = int(np.clip(y - length / 2, 0, r))\n        y2 = int(np.clip(y + length / 2, 0, r))\n        x1 = int(np.clip(x - length / 2, 0, c))\n        x2 = int(np.clip(x + length / 2, 0, c))\n        mask[y1: y2, x1: x2] = 0.\n    \n    mask = mask[:,:,None]\n    im = im * mask\n    return im\n\ndef scale_to(x, ratio, targ): \n    \'\'\'Calculate dimension of an image during scaling with aspect ratio\'\'\'\n    return max(math.floor(x*ratio), targ)\n\ndef crop(im, r, c, sz): \n    \'\'\'\n    crop image into a square of size sz, \n    \'\'\'\n    return im[r:r+sz, c:c+sz]\n\ndef det_dihedral(dih): return lambda x: dihedral(x, dih)\ndef det_stretch(sr, sc): return lambda x: stretch_cv(x, sr, sc)\ndef det_lighting(b, c): return lambda x: lighting(x, b, c)\ndef det_rotate(deg): return lambda x: rotate_cv(x, deg)\ndef det_zoom(zoom): return lambda x: zoom_cv(x, zoom)\n\ndef rand0(s): return random.random()*(s*2)-s\n\n\nclass TfmType(IntEnum):\n    """""" Type of transformation.\n    Parameters\n        IntEnum: predefined types of transformations\n            NO:    the default, y does not get transformed when x is transformed.\n            PIXEL: x and y are images and should be transformed in the same way.\n                   Example: image segmentation.\n            COORD: y are coordinates (i.e bounding boxes)\n            CLASS: y are class labels (same behaviour as PIXEL, except no normalization)\n    """"""\n    NO = 1\n    PIXEL = 2\n    COORD = 3\n    CLASS = 4\n\n\nclass Denormalize():\n    """""" De-normalizes an image, returning it to original format.\n    """"""\n    def __init__(self, m, s):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n    def __call__(self, x): return x*self.s+self.m\n\n\nclass Normalize():\n    """""" Normalizes an image to zero mean and unit standard deviation, given the mean m and std s of the original image """"""\n    def __init__(self, m, s, tfm_y=TfmType.NO):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n        self.tfm_y=tfm_y\n\n    def __call__(self, x, y=None):\n        x = (x-self.m)/self.s\n        if self.tfm_y==TfmType.PIXEL and y is not None: y = (y-self.m)/self.s\n        return x,y\n\nclass ChannelOrder():\n    \'\'\'\n    changes image array shape from (h, w, 3) to (3, h, w). \n    tfm_y decides the transformation done to the y element. \n    \'\'\'\n    def __init__(self, tfm_y=TfmType.NO): self.tfm_y=tfm_y\n\n    def __call__(self, x, y):\n        x = np.rollaxis(x, 2)\n        #if isinstance(y,np.ndarray) and (len(y.shape)==3):\n        if self.tfm_y==TfmType.PIXEL: y = np.rollaxis(y, 2)\n        elif self.tfm_y==TfmType.CLASS: y = y[...,0]\n        return x,y\n\n\ndef to_bb(YY, y=""deprecated""):\n    """"""Convert mask YY to a bounding box, assumes 0 as background nonzero object""""""\n    cols,rows = np.nonzero(YY)\n    if len(cols)==0: return np.zeros(4, dtype=np.float32)\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n\ndef coords2px(y, x):\n    """""" Transforming coordinates to pixels.\n\n    Arguments:\n        y : np array\n            vector in which (y[0], y[1]) and (y[2], y[3]) are the\n            the corners of a bounding box.\n        x : image\n            an image\n    Returns:\n        Y : image\n            of shape x.shape\n    """"""\n    rows = np.rint([y[0], y[0], y[2], y[2]]).astype(int)\n    cols = np.rint([y[1], y[3], y[1], y[3]]).astype(int)\n    r,c,*_ = x.shape\n    Y = np.zeros((r, c))\n    Y[rows, cols] = 1\n    return Y\n\n\nclass Transform():\n    """""" A class that represents a transform.\n\n    All other transforms should subclass it. All subclasses should override\n    do_transform.\n\n    Arguments\n    ---------\n        tfm_y : TfmType\n            type of transform\n    """"""\n    def __init__(self, tfm_y=TfmType.NO):\n        self.tfm_y=tfm_y\n        self.store = threading.local()\n\n    def set_state(self): pass\n    def __call__(self, x, y):\n        self.set_state()\n        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n                else self.transform_coord(x,y))\n        return x, y\n\n    def transform_coord(self, x, y): return self.transform(x),y\n\n    def transform(self, x, y=None):\n        x = self.do_transform(x,False)\n        return (x, self.do_transform(y,True)) if y is not None else x\n\n    @abstractmethod\n    def do_transform(self, x, is_y): raise NotImplementedError\n\n\nclass CoordTransform(Transform):\n    """""" A coordinate transform.  """"""\n\n    @staticmethod\n    def make_square(y, x):\n        r,c,*_ = x.shape\n        y1 = np.zeros((r, c))\n        y = y.astype(np.int)\n        y1[y[0]:y[2], y[1]:y[3]] = 1.\n        return y1\n\n    def map_y(self, y0, x):\n        y = CoordTransform.make_square(y0, x)\n        y_tr = self.do_transform(y, True)\n        return to_bb(y_tr)\n\n    def transform_coord(self, x, ys):\n        yp = partition(ys, 4)\n        y2 = [self.map_y(y,x) for y in yp]\n        x = self.do_transform(x, False)\n        return x, np.concatenate(y2)\n\n\nclass AddPadding(CoordTransform):\n    """""" A class that represents adding paddings to an image.\n\n    The default padding is border_reflect\n    Arguments\n    ---------\n        pad : int\n            size of padding on top, bottom, left and right\n        mode:\n            type of cv2 padding modes. (e.g., constant, reflect, wrap, replicate. etc. )\n    """"""\n    def __init__(self, pad, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.pad,self.mode = pad,mode\n\n    def do_transform(self, im, is_y):\n        return cv2.copyMakeBorder(im, self.pad, self.pad, self.pad, self.pad, self.mode)\n\nclass CenterCrop(CoordTransform):\n    """""" A class that represents a Center Crop.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        sz: int\n            size of the crop.\n        tfm_y : TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.min_sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        return center_crop(x, self.sz_y if is_y else self.min_sz)\n\n\nclass RandomCrop(CoordTransform):\n    """""" A class that represents a Random Crop transformation.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        targ: int\n            target size of the crop.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, targ_sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz,self.sz_y = targ_sz,sz_y\n\n    def set_state(self):\n        self.store.rand_r = random.uniform(0, 1)\n        self.store.rand_c = random.uniform(0, 1)\n\n    def do_transform(self, x, is_y):\n        r,c,*_ = x.shape\n        sz = self.sz_y if is_y else self.targ_sz\n        start_r = np.floor(self.store.rand_r*(r-sz)).astype(int)\n        start_c = np.floor(self.store.rand_c*(c-sz)).astype(int)\n        return crop(x, start_r, start_c, sz)\n\n\nclass NoCrop(CoordTransform):\n    """"""  A transformation that resize to a square image without cropping.\n\n    This transforms (optionally) resizes x,y at with the same parameters.\n    Arguments:\n        targ: int\n            target size of the crop.\n        tfm_y (TfmType): type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return no_crop(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return no_crop(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass Scale(CoordTransform):\n    """""" A transformation that scales the min size to sz.\n\n    Arguments:\n        sz: int\n            target size to scale minimum size.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass RandomScale(CoordTransform):\n    """""" Scales an image so that the min size is a random number between [sz, sz*max_zoom]\n\n    This transforms (optionally) scales x,y at with the same parameters.\n    Arguments:\n        sz: int\n            target size\n        max_zoom: float\n            float >= 1.0\n        p : float\n            a probability for doing the random sizing\n        tfm_y: TfmType\n            type of y transform\n    """"""\n    def __init__(self, sz, max_zoom, p=0.75, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.max_zoom,self.p,self.sz_y = sz,max_zoom,p,sz_y\n\n    def set_state(self):\n        min_z = 1.\n        max_z = self.max_zoom\n        if isinstance(self.max_zoom, collections.Iterable):\n            min_z, max_z = self.max_zoom\n        self.store.mult = random.uniform(min_z, max_z) if random.random()<self.p else 1\n        self.store.new_sz = int(self.store.mult*self.sz)\n        if self.sz_y is not None: self.store.new_sz_y = int(self.store.mult*self.sz_y)\n\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.store.new_sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.store.new_sz,   cv2.INTER_AREA   )\n\n\nclass RandomRotate(CoordTransform):\n    """""" Rotates images and (optionally) target y.\n\n    Rotating coordinates is treated differently for x and y on this\n    transform.\n     Arguments:\n        deg (float): degree to rotate.\n        p (float): probability of rotation\n        mode: type of border\n        tfm_y (TfmType): type of y transform\n    """"""\n    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.deg,self.p = deg,p\n        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n            self.modes = (mode,cv2.BORDER_CONSTANT)\n        else:\n            self.modes = (mode,mode)\n\n    def set_state(self):\n        self.store.rdeg = rand0(self.deg)\n        self.store.rp = random.random()<self.p\n\n    def do_transform(self, x, is_y):\n        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n                mode= self.modes[1] if is_y else self.modes[0],\n                interpolation=cv2.INTER_NEAREST if is_y else cv2.INTER_AREA)\n        return x\n\n\nclass RandomDihedral(CoordTransform):\n    """"""\n    Rotates images by random multiples of 90 degrees and/or reflection.\n    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n    """"""\n    def set_state(self):\n        self.store.rot_times = random.randint(0,3)\n        self.store.do_flip = random.random()<0.5\n\n    def do_transform(self, x, is_y):\n        x = np.rot90(x, self.store.rot_times)\n        return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomFlip(CoordTransform):\n    def __init__(self, tfm_y=TfmType.NO, p=0.5):\n        super().__init__(tfm_y=tfm_y)\n        self.p=p\n\n    def set_state(self): self.store.do_flip = random.random()<self.p\n    def do_transform(self, x, is_y): return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomLighting(Transform):\n    def __init__(self, b, c, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.b,self.c = b,c\n\n    def set_state(self):\n        self.store.b_rand = rand0(self.b)\n        self.store.c_rand = rand0(self.c)\n\n    def do_transform(self, x, is_y):\n        if is_y and self.tfm_y != TfmType.PIXEL: return x\n        b = self.store.b_rand\n        c = self.store.c_rand\n        c = -1/(c-1) if c<0 else c+1\n        x = lighting(x, b, c)\n        return x\n\nclass RandomRotateZoom(CoordTransform):\n    """""" \n        Selects between a rotate, zoom, stretch, or no transform.\n        Arguments:\n            deg - maximum degrees of rotation.\n            zoom - maximum fraction of zoom.\n            stretch - maximum fraction of stretch.\n            ps - probabilities for each transform. List of length 4. The order for these probabilities is as listed respectively (4th probability is \'no transform\'.\n    """"""\n    def __init__(self, deg, zoom, stretch, ps=None, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        if ps is None: ps = [0.25,0.25,0.25,0.25]\n        assert len(ps) == 4, \'does not have 4 probabilities for p, it has %d\' % len(ps)\n        self.transforms = RandomRotate(deg, p=1, mode=mode, tfm_y=tfm_y), RandomZoom(zoom, tfm_y=tfm_y), RandomStretch(stretch,tfm_y=tfm_y)\n        self.pass_t = PassThru()\n        self.cum_ps = np.cumsum(ps)\n        assert self.cum_ps[3]==1, \'probabilites do not sum to 1; they sum to %d\' % self.cum_ps[3]\n\n    def set_state(self):\n        self.store.trans = self.pass_t\n        self.store.choice = self.cum_ps[3]*random.random()\n        for i in range(len(self.transforms)):\n            if self.store.choice < self.cum_ps[i]:\n                self.store.trans = self.transforms[i]\n                break\n        self.store.trans.set_state()\n\n    def do_transform(self, x, is_y): return self.store.trans.do_transform(x, is_y)\n\nclass RandomZoom(CoordTransform):\n    def __init__(self, zoom_max, zoom_min=0, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.zoom_max, self.zoom_min = zoom_max, zoom_min\n\n    def set_state(self):\n        self.store.zoom = self.zoom_min+(self.zoom_max-self.zoom_min)*random.random()\n\n    def do_transform(self, x, is_y):\n        return zoom_cv(x, self.store.zoom)\n\nclass RandomStretch(CoordTransform):\n    def __init__(self, max_stretch, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.max_stretch = max_stretch\n\n    def set_state(self):\n        self.store.stretch = self.max_stretch*random.random()\n        self.store.stretch_dir = random.randint(0,1)\n\n    def do_transform(self, x, is_y):\n        if self.store.stretch_dir==0: x = stretch_cv(x, self.store.stretch, 0)\n        else:                         x = stretch_cv(x, 0, self.store.stretch)\n        return x\n\nclass PassThru(CoordTransform):\n    def do_transform(self, x, is_y):\n        return x\n\nclass RandomBlur(Transform):\n    """"""\n    Adds a gaussian blur to the image at chance.\n    Multiple blur strengths can be configured, one of them is used by random chance.\n    """"""\n\n    def __init__(self, blur_strengths=5, probability=0.5, tfm_y=TfmType.NO):\n        # Blur strength must be an odd number, because it is used as a kernel size.\n        super().__init__(tfm_y)\n        self.blur_strengths = (np.array(blur_strengths, ndmin=1) * 2) - 1\n        if np.any(self.blur_strengths < 0):\n            raise ValueError(""all blur_strengths must be > 0"")\n        self.probability = probability\n        self.apply_transform = False\n\n    def set_state(self):\n        self.store.apply_transform = random.random() < self.probability\n        kernel_size = np.random.choice(self.blur_strengths)\n        self.store.kernel = (kernel_size, kernel_size)\n\n    def do_transform(self, x, is_y):\n        return cv2.GaussianBlur(src=x, ksize=self.store.kernel, sigmaX=0) if self.apply_transform else x\n\nclass Cutout(Transform):\n    def __init__(self, n_holes, length, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.n_holes,self.length = n_holes,length\n\n    def do_transform(self, img, is_y):\n        return cutout(img, self.n_holes, self.length)\n\nclass GoogleNetResize(CoordTransform):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ \n    \n    Arguments:\n        targ_sz: int\n            target size\n        min_area_frac: float < 1.0\n            minimum area of the original image for cropping\n        min_aspect_ratio : float\n            minimum aspect ratio\n        max_aspect_ratio : float\n            maximum aspect ratio\n        flip_hw_p : float\n            probability for flipping magnitudes of height and width\n        tfm_y: TfmType\n            type of y transform\n    """"""\n\n    def __init__(self, targ_sz,\n                 min_area_frac=0.08, min_aspect_ratio=0.75, max_aspect_ratio=1.333, flip_hw_p=0.5,\n                 tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz, self.tfm_y, self.sz_y = targ_sz, tfm_y, sz_y\n        self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.flip_hw_p = min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p\n\n    def set_state(self):\n        # if self.random_state: random.seed(self.random_state)\n        self.store.fp = random.random()<self.flip_hw_p\n\n    def do_transform(self, x, is_y):\n        sz = self.sz_y if is_y else self.targ_sz\n        if is_y:\n            interpolation = cv2.INTER_NEAREST if self.tfm_y in (TfmType.COORD, TfmType.CLASS) else cv2.INTER_AREA\n        else:\n            interpolation = cv2.INTER_AREA\n        return googlenet_resize(x, sz, self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.store.fp, interpolation=interpolation)\n\n\ndef compose(im, y, fns):\n    """""" apply a collection of transformation functions fns to images\n    """"""\n    for fn in fns:\n        #pdb.set_trace()\n        im, y =fn(im, y)\n    return im if y is None else (im, y)\n\n\nclass CropType(IntEnum):\n    """""" Type of image cropping.\n    """"""\n    RANDOM = 1\n    CENTER = 2\n    NO = 3\n    GOOGLENET = 4\n\ncrop_fn_lu = {CropType.RANDOM: RandomCrop, CropType.CENTER: CenterCrop, CropType.NO: NoCrop, CropType.GOOGLENET: GoogleNetResize}\n\nclass Transforms():\n    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n                 tfm_y=TfmType.NO, sz_y=None):\n        if sz_y is None: sz_y = sz\n        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n        self.tfms = tfms\n        self.tfms.append(crop_tfm)\n        if normalizer is not None: self.tfms.append(normalizer)\n        self.tfms.append(ChannelOrder(tfm_y))\n\n    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n    def __repr__(self): return str(self.tfms)\n\n\ndef image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n    """"""\n    Generate a standard set of transformations\n\n    Arguments\n    ---------\n     normalizer :\n         image normalizing function\n     denorm :\n         image denormalizing function\n     sz :\n         size, sz_y = sz if not specified.\n     tfms :\n         iterable collection of transformation functions\n     max_zoom : float,\n         maximum zoom\n     pad : int,\n         padding on top, left, right and bottom\n     crop_type :\n         crop type\n     tfm_y :\n         y axis specific transformations\n     sz_y :\n         y size, height\n     pad_mode :\n         cv2 padding style: repeat, reflect, etc.\n\n    Returns\n    -------\n     type : ``Transforms``\n         transformer for specified image operations.\n\n    See Also\n    --------\n     Transforms: the transformer object returned by this function\n    """"""\n    if tfm_y is None: tfm_y=TfmType.NO\n    if tfms is None: tfms=[]\n    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n    if sz_y is None: sz_y = sz\n    if scale is None:\n        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n                 else Scale(sz, tfm_y, sz_y=sz_y)]\n    elif not is_listy(scale): scale = [scale]\n    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n                      tfm_y=tfm_y, sz_y=sz_y)\n\ndef noop(x):\n    """"""dummy function for do-nothing.\n    equivalent to: lambda x: x""""""\n    return x\n\ntransforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)]\ntransforms_side_on  = transforms_basic + [RandomFlip()]\ntransforms_top_down = transforms_basic + [RandomDihedral()]\n\nimagenet_stats = A([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n""""""Statistics pertaining to image data from image net. mean and std of the images of each color channel""""""\ninception_stats = A([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\ninception_models = (inception_4, inceptionresnet_2)\n\ndef tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Given the statistics of the training image sets, returns separate training and validation transform functions\n    """"""\n    if aug_tfms is None: aug_tfms=[]\n    tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n    tfm_denorm = Denormalize(*stats) if stats is not None else None\n    val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n    val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n            tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n    trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n            tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n    return trn_tfm, val_tfm\n\n\ndef tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Returns separate transformers of images for training and validation.\n    Transformers are constructed according to the image statistics given b y the model. (See tfms_from_stats)\n\n    Arguments:\n        f_model: model, pretrained or not pretrained\n    """"""\n    stats = inception_stats if f_model in inception_models else imagenet_stats\n    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)\n\n'"
fastai/fastai/transforms_pil.py,1,"b'import torch\nimport numpy as np\n\n\nclass Cutout(object):\n    """"""Randomly mask out one or more patches from an image.\n\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    """"""\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (Tensor): Tensor image of size (C, H, W).\n        Returns:\n            Tensor: Image with n_holes of dimension length x length cut out of it.\n        """"""\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length / 2, 0, h)\n            y2 = np.clip(y + self.length / 2, 0, h)\n            x1 = np.clip(x - self.length / 2, 0, w)\n            x2 = np.clip(x + self.length / 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n'"
fastai/fastai/utils.py,0,"b""import math, os, json, sys, re, numpy as np, pickle, PIL, scipy\nfrom PIL import Image\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom operator import itemgetter, attrgetter, methodcaller\nfrom collections import OrderedDict\nimport itertools\nfrom itertools import chain\n\nimport pandas as pd\nfrom numpy.random import random, permutation, randn, normal, uniform, choice\nfrom numpy import newaxis\nfrom scipy import misc, ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.manifold import TSNE\nimport bcolz\n\nfrom IPython.lib.display import FileLink\n\nimport keras\nfrom keras import backend as K\nfrom keras.utils.data_utils import get_file\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\nfrom keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\nfrom keras.layers import Flatten, Dense, Dropout, Lambda\nfrom keras.regularizers import l2, l1\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.layers import deserialize as layer_from_config\nfrom keras.metrics import categorical_crossentropy, categorical_accuracy\nfrom keras.layers.convolutional import *\nfrom keras.preprocessing import image, sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom vgg16 import Vgg16\nnp.set_printoptions(precision=4, linewidth=100)\n\n\nto_bw = np.array([0.299, 0.587, 0.114])\n\ndef gray(img): return np.rollaxis(img, 0, 1).dot(to_bw)\ndef to_plot(img): return np.rollaxis(img, 0, 1).astype(np.uint8)\ndef plot(img): plt.imshow(to_plot(img))\n\ndef floor(x): return int(math.floor(x))\ndef ceil(x): return int(math.ceil(x))\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    \n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n\n\ndef do_clip(arr, mx):\n    clipped = np.clip(arr, (1-mx)/1, mx)\n    return clipped/clipped.sum(axis=1)[:, np.newaxis]\n\n\ndef wrap_config(layer):\n    return {'class_name': layer.__class__.__name__, 'config': layer.get_config()}\n\ndef copy_layer(layer): return layer_from_config(wrap_config(layer))\n\ndef copy_layers(layers): return [copy_layer(layer) for layer in layers]\n\ndef copy_weights(from_layers, to_layers):\n    for from_layer,to_layer in zip(from_layers, to_layers):\n        to_layer.set_weights(from_layer.get_weights())\n\ndef save_array(fname, arr):\n    c=bcolz.carray(arr, rootdir=fname, mode='w')\n    c.flush()\n\ndef load_array(fname): return bcolz.open(fname)[:]\n\ndef get_classes(path):\n    batches = get_batches(path+'train', shuffle=False, batch_size=1)\n    val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n    test_batches = get_batches(path+'test', shuffle=False, batch_size=1)\n    return (val_batches.classes, batches.classes, onehot(val_batches.classes), onehot(batches.classes),\n        val_batches.filenames, batches.filenames, test_batches.filenames)\n\ndef limit_mem():\n    K.get_session().close()\n    cfg = K.tf.ConfigProto()\n    cfg.gpu_options.allow_growth = True\n    K.set_session(K.tf.Session(config=cfg))\n\nclass MixIterator(object):\n    def __init__(self, iters):\n        self.iters = iters\n        self.multi = type(iters) is list\n        if self.multi:\n            self.N = sum([it[0].N for it in self.iters])\n        else:\n            self.N = sum([it.N for it in self.iters])\n\n    def reset(self):\n        for it in self.iters: it.reset()\n\n    def __iter__(self):\n        return self\n\n    def next(self, *args, **kwargs):\n        if self.multi:\n            nexts = [[next(it) for it in o] for o in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n        else:\n            nexts = [next(it) for it in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n"""
fastai/tests/__init__.py,0,"b""import matplotlib\nmatplotlib.use('agg')\nimport cv2,torch\n\n# the above imports are fixing the TLS issue:\n# ```ImportError: dlopen: cannot load any more object with static TLS```\n# they were set after experimenting with the test sets on ubuntu 16.04\n"""
fastai/tests/test_core.py,0,"b'from fastai.core import partition\nimport pytest\n\ndef test_partition_functionality():\n  sz = 2\n  a = [1,2,3,4,5]\n  ex = [[1,2],[3,4],[5]]\n  result = partition(a, sz)\n  assert len(result) == len(ex)\n  assert all([a == b for a, b in zip(result, ex)])\n\n  sz = 3\n  ex = [[1,2,3],[4,5]]\n  result = partition(a, sz)\n  assert len(result) == len(ex)\n  assert all([a == b for a,b in zip(result, ex)])\n\n  sz = 1\n  ex = [[1],[2],[3],[4],[5]]\n  result = partition(a, sz)\n  assert len(result) == len(ex)\n  assert all([a == b for a,b in zip(result, ex)])\n\n  sz = 6\n  ex = [[1,2,3,4,5]]\n  result = partition(a, sz)\n  assert len(result) == len(ex)\n  assert all([a == b for a,b in zip(result, ex)])\n\n  sz = 3\n  a = []\n  result = partition(a, sz)\n  assert len(result) == 0\n\ndef test_partition_error_handling():\n  sz = 0\n  a = [1,2,3,4,5]\n  with pytest.raises(ValueError):\n    partition(a, sz)\n'"
fastai/tests/test_layer_optimizer.py,0,"b""import pytest\n\nfrom fastai.layer_optimizer import LayerOptimizer\n\n\nclass Par(object):\n    def __init__(self, x, grad=True):\n        self.x = x\n        self.requires_grad = grad\n    def parameters(self): return [self]\n\nclass FakeOpt(object):\n    def __init__(self, params): self.param_groups = params\n\ndef params_(*names): return [Par(nm) for nm in names]\n\ndef check_optimizer_(opt, expected):\n    actual = opt.param_groups\n    assert len(actual) == len(expected)\n    for (a, e) in zip(actual, expected): check_param_(a, *e)\n    \ndef check_param_(par, nm, lr, wd):\n    assert par['params'][0].x == nm\n    assert par['lr'] == lr\n    assert par['weight_decay'] == wd\n\n\ndef test_construction_with_singleton_lr_and_wd():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    check_optimizer_(lo.opt, [(nm, 1e-2, 1e-4) for nm in 'ABC'])\n\ndef test_construction_with_lists_of_lrs_and_wds():\n    lo = LayerOptimizer(\n        FakeOpt,\n        params_('A', 'B', 'C'),\n        (1e-2, 2e-2, 3e-2),\n        (9e-3, 8e-3, 7e-3),\n    )\n    check_optimizer_(\n        lo.opt,\n        [('A', 1e-2, 9e-3), ('B', 2e-2, 8e-3), ('C', 3e-2, 7e-3)],\n    )\n\ndef test_construction_with_too_few_lrs():\n    with pytest.raises(AssertionError):\n        LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), (1e-2, 2e-2), 1e-4)\n\ndef test_construction_with_too_few_wds():\n    with pytest.raises(AssertionError):\n        LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, (9e-3, 8e-3))\n\ndef test_set_lrs_with_single_value():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    lo.set_lrs(1e-3)\n    check_optimizer_(lo.opt, [(nm, 1e-3, 1e-4) for nm in 'ABC'])\n\ndef test_set_lrs_with_list_of_values():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    lo.set_lrs([2e-2, 3e-2, 4e-2])\n    check_optimizer_(\n        lo.opt,\n        [('A', 2e-2, 1e-4), ('B', 3e-2, 1e-4), ('C', 4e-2, 1e-4)],\n    )\n\ndef test_set_lrs_with_too_few_values():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    with pytest.raises(AssertionError):\n        lo.set_lrs([2e-2, 3e-2])\n    # Also make sure the optimizer didn't change.\n    check_optimizer_(lo.opt, [(nm, 1e-2, 1e-4) for nm in 'ABC'])\n    \ndef test_set_wds_with_single_value():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    lo.set_wds(1e-5)\n    check_optimizer_(lo.opt, [(nm, 1e-2, 1e-5) for nm in 'ABC'])\n\ndef test_set_wds_with_list_of_values():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    lo.set_wds([9e-3, 8e-3, 7e-3])\n    check_optimizer_(\n        lo.opt,\n        [('A', 1e-2, 9e-3), ('B', 1e-2, 8e-3), ('C', 1e-2, 7e-3)],\n    )\n\ndef test_set_wds_with_too_few_values():\n    lo = LayerOptimizer(FakeOpt, params_('A', 'B', 'C'), 1e-2, 1e-4)\n    with pytest.raises(AssertionError):\n        lo.set_wds([9e-3, 8e-3])\n    # Also make sure the optimizer didn't change.\n    check_optimizer_(lo.opt, [(nm, 1e-2, 1e-4) for nm in 'ABC'])\n"""
fastai/tests/test_lsuv_initializer.py,2,"b""import pytest\n\nfrom fastai.core import VV\nfrom fastai.lsuv_initializer import apply_lsuv_init\n\nimport cv2\nimport numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n\n@pytest.fixture\ndef image_data():\n    images_to_process = []\n    for img_fname in os.listdir('fastai/images'):\n        img = cv2.imread(os.path.join('fastai/images', img_fname))\n        images_to_process.append(np.transpose(cv2.resize(img, (224,224)), (2,0,1)))\n    data = np.array(images_to_process).astype(np.float32)\n    return VV(torch.from_numpy(data))\n\n\ndef add_hooks(m, fn):\n    hooks = []\n    def add_hook(m):\n        if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n            hooks.append(m.register_forward_hook(fn))\n    m.apply(add_hook)\n    return hooks\ndef remove_hooks(hooks): [h.remove() for h in hooks]\n\ndef run_with_capture(m, data):\n    activation_variances = []\n    def capture_hook(self, input, output):\n        activation_variances.append(np.var(output.data.cpu().numpy()))\n    hooks = add_hooks(m, capture_hook)\n    m(data)\n    remove_hooks(hooks)\n    return activation_variances\n\ndef test_fast_initialization_without_orthonormal(image_data):\n    alexnet = models.alexnet(pretrained=False)\n    pre_init_var = run_with_capture(alexnet, image_data)\n    assert pre_init_var[0] >= 1000  # the first few pre-init variances are huge,\n    assert pre_init_var[1] >= 100   # even larger than these conservative tests.\n\n    tol = 0.1\n    alexnet = apply_lsuv_init(alexnet, image_data, std_tol=tol, do_orthonorm=False, cuda=False)\n    *post_init_var, final_var = run_with_capture(alexnet, image_data)\n    for var in post_init_var:\n        assert 2 <= var <= 4\n    assert final_var == pytest.approx(1, tol**2)\n"""
fastai/tests/test_samplers.py,0,"b'import numpy as np\n\nfrom fastai.text import SortSampler, SortishSampler\n\n\ndef test_sort_sampler_sorts_all_descending():\n    bs = 4\n    n = bs*100\n    data = 2 * np.arange(n)\n    samp = list(SortSampler(data, lambda i: data[i]))\n\n    # The sample is a permutation of the indices.\n    assert sorted(samp) == list(range(n))\n    # And that ""permutation"" is for descending data order.\n    assert all(s1 > s2 for s1, s2 in zip(samp, samp[1:]))\n\n\ndef test_sortish_sampler_sorts_each_batch_descending():\n    bs = 4\n    n = bs*100\n    data = 2 * np.arange(n)\n    samp = list(SortishSampler(data, lambda i: data[i], bs))\n\n    # The sample is a permutation of the indices.\n    assert sorted(samp) == list(range(n))\n    # And that permutation is kind of reverse sorted.\n    assert all(\n        s1 > s2 or (i+1) % bs == 0  # don\'t check batch boundaries\n        for i, (s1, s2) in enumerate(zip(samp, samp[1:]))\n    )\n    assert samp[0] == max(samp)\n'"
fastai/tests/test_transform.py,0,"b'import numpy as np\nimport pytest\n\nfrom fastai.transforms import *\n\nt_rand_img128x128x1 = np.random.uniform(size=[128,128,1])\nt_rand_img128x128x3 = np.random.uniform(size=[128,128,3])\n#\n# # as per https://stackoverflow.com/questions/7100242/python-numpy-first-occurrence-of-subarray\n# def rolling_window(a, size):\n#     shape = a.shape[:-1] + (a.shape[-1] - size + 1, size)\n#     strides = a.strides + (a. strides[-1],)\n#     return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n\n\ndef test_scale_min_works_with_masks():\n    mask = np.ones([128, 256], dtype=np.float32)\n    mask[0:64,0:128] = 20\n\n    em = np.array([[20., 20., 1., 1.],\n                   [1., 1., 1., 1.]], dtype=np.float32)\n    msmall = scale_min(mask, 2, cv2.INTER_NEAREST)\n    np.testing.assert_equal(msmall, em, ""sacle_min can scale down a mask"")\n    \n    mlarge = scale_min(msmall, 128, cv2.INTER_NEAREST)\n    np.testing.assert_equal(mlarge, mask, ""sacle_min can scale up a mask"")\n\ndef test_scale_min_works_with_rgb():\n    r_layer = np.ones([128, 256], dtype=np.float32)\n    r_layer[0:64, 0:128] = 0.5\n    im = np.stack([r_layer, np.zeros_like(r_layer), np.ones_like(r_layer)], axis=-1)\n\n    r_layer_small = np.array([[0.5, 0.5, 1., 1.],\n                              [1., 1., 1., 1.]])\n    im_small = scale_min(im, 2, cv2.INTER_AREA)\n    np.testing.assert_equal(im_small[..., 0], r_layer_small, ""sacle_min can scale down an rgb image"")\n    assert im_small[..., 1].sum() == 0, ""sacle_min can scale down an rgb image""\n    assert im_small[..., 2].max() == im_small[..., 2].min() == 1, ""sacle_min can scale down an rgb image""\n\n    im_large = scale_min(im_small, 128, cv2.INTER_AREA)\n    np.testing.assert_equal(im_large[..., 0], r_layer, ""sacle_min can scale up an rgb image"")\n    assert im_large[..., 1].sum() == 0, ""sacle_min can scale down an rgb image""\n    assert im_large[..., 2].max() == im_large[..., 2].min() == 1, ""sacle_min can scale down an rgb image""\n    \n\ndef test_zoom_cv():\n    r_layer = np.array([[0, 0, 0, 0, 0],\n                        [0, 0, 0, 0, 0],\n                        [0, 0, 1, 0, 0],\n                        [0, 0, 0, 0, 0],\n                        [0, 0, 0, 0, 0], ], dtype=np.float32)\n    im = np.stack([r_layer, np.zeros_like(r_layer), np.ones_like(r_layer)], axis=-1)\n    np.testing.assert_equal(zoom_cv(im, 0), im, ""Z==0 leaves image unchanged"")\n    # TODO: Figure out why the circle is moved slightly to the top left corner.\n    expect = np.array([[0,      0,       0,       0,       0.],\n                       [0,      0.01562, 0.12109, 0.00391, 0.],\n                       [0,      0.12109, 0.93848, 0.03027, 0.],\n                       [0,      0.00391, 0.03027, 0.00098, 0.],\n                       [0,      0,       0,       0,       0.],], dtype=np.float32)\n    actual = zoom_cv(im, 0.1)[..., 0]\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\ndef test_stretch_cv():\n    im = np.array([[0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0],\n                   [0, 0, 1, 0, 0],\n                   [0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0], ], dtype=np.float32)\n    np.testing.assert_equal(stretch_cv(im, sr=0, sc=0), im, ""sr==0 && sc==0 leaves image unchanged"")\n\n    expect = np.array([[0,      0,      0,       0,       0.],\n                       [0,      0.,     0,       0,       0.],\n                       [0,      0.,     0.64,    0.24,    0.],\n                       [0,      0.,     0.24,    0.09,    0.],\n                       [0,      0,      0,       0,       0.],], dtype=np.float32)\n    actual = stretch_cv(im, 0.1, 0.1)\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\n    expect = np.array([[0, 0, 0, 0, 0],\n                       [0, 0, 0, 0, 0],\n                       [0, 0, 1, 1, 0],\n                       [0, 0, 0, 0, 0],\n                       [0, 0, 0, 0, 0], ], dtype=np.float32)\n    actual = stretch_cv(im, 1, 0)\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\n    expect = np.array([[0, 0, 0, 0, 0],\n                       [0, 0, 0, 0, 0],\n                       [0, 0, 1, 1, 0],\n                       [0, 0, 1, 1, 0],\n                       [0, 0, 0, 0, 0], ], dtype=np.float32)\n    actual = stretch_cv(im, 1, 1)\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\n    expect = np.array([[0, 0, 0, 0, 0],\n                       [0, 1, 1, 1, 0],\n                       [0, 1, 1, 1, 0],\n                       [0, 1, 1, 1, 0],\n                       [0, 0, 0, 0, 0], ], dtype=np.float32)\n    actual = stretch_cv(im, 2, 2)\n    print(actual)\n    np.testing.assert_array_almost_equal(actual, expect, decimal=5)\n\n@pytest.mark.skip(reason=""It does not work for some reason see #429"")\ndef test_zoom_cv_equals_stretch_cv():\n    im = np.array([[0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0],\n                   [0, 0, 1, 0, 0],\n                   [0, 0, 0, 0, 0],\n                   [0, 0, 0, 0, 0], ], dtype=np.float32)\n\n    np.testing.assert_array_almost_equal(zoom_cv(im, 2), stretch_cv(im, 2, 2), decimal=4)\n\ndef test_dihedral():\n    im = np.array([\n        [0.,   0.1,  0.,  ],\n        [0.01, 0.2,  0.03,],\n        [0.,   0.3,  0.,  ],])\n    e = im\n    a = dihedral(im, 0)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.03, 0.,  ],\n        [0.1,  0.2,  0.3, ],\n        [0.,   0.01, 0.,  ]])\n    a = dihedral(im, 1)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.3,  0.,  ],\n        [0.03, 0.2,  0.01,],\n        [0.,   0.1,  0.,  ]])\n    a = dihedral(im, 2)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.01, 0.,  ],\n        [0.3,  0.2,  0.1, ],\n        [0.,   0.03, 0.,  ]])\n    a = dihedral(im, 3)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.1,  0.,  ],\n        [0.03, 0.2,  0.01,],\n        [0.,   0.3,  0.,  ]])\n    a = dihedral(im, 4)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.03, 0.,  ],\n        [0.3,  0.2,  0.1, ],\n        [0.,   0.01, 0.,  ]])\n    a = dihedral(im, 5)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.3,  0.,  ],\n        [0.01, 0.2,  0.03,],\n        [0.,   0.1,  0.,  ]])\n    a = dihedral(im, 6)\n    np.testing.assert_array_equal(a, e)\n    e = np.array([\n        [0.,   0.01, 0.,  ],\n        [0.1,  0.2,  0.3, ],\n        [0.,   0.03, 0.,  ]])\n    a = dihedral(im, 7)\n    np.testing.assert_array_equal(a, e)\n\ndef test_lighting():\n    im = np.array([\n        [0.,   0.1,  0.,  ],\n        [0.01, 0.2,  0.03,],\n        [0.,   0.3,  0.,  ],])\n    e = im\n    a = lighting(im, 0, 1)\n    # TODO: better test taht allows for visual inspection\n    np.testing.assert_array_equal(a, e)\n    e =np.array([[0.5 , 0.6 , 0.5 ],\n                [0.51, 0.7 , 0.53],\n                [0.5 , 0.8 , 0.5 ]], dtype=np.float32)\n    a = lighting(im, 0.5, 1)\n    np.testing.assert_array_equal(a, e)\n\ndef test_rotate_cv():\n    im = np.array([\n        [0.,   0.1,  0., ],\n        [0.,   0.2,  0., ],\n        [0.,   0.3,  0., ],])\n    a = rotate_cv(im, 90)\n    e = np.array([[0. , 0. , 0. ],\n                  [0.1, 0.2, 0.3],\n                  [0. , 0. , 0. ],])\n    np.testing.assert_array_equal(a, e)\n\ndef test_rotate_cv_vs_dihedral():\n    im = np.array([\n        [0.,   0.1,  0., ],\n        [0.,   0.2,  0., ],\n        [0.,   0.3,  0., ],])\n    a = rotate_cv(im, 180)\n    e = dihedral(im, 6)\n    np.testing.assert_array_equal(a, e)\n\ndef test_no_crop():\n    im = np.array([\n        [0.,   0.1,  0., ],\n        [0.,   0.2,  0., ],])\n    a = no_crop(im, 4)\n    e = np.array([[0. , 0.066 , 0.066, 0 ],\n                  [0,   0.066,  0.066, 0 ],\n                  [0. , 0.133 , 0.133, 0 ],\n                  [0. , 0.133 , 0.133, 0 ]])\n    np.testing.assert_array_almost_equal(a, e, decimal=3)\n\ndef test_center_crop():\n    im = np.array([\n        [0.,   0.1,  0.,  ],\n        [0.01, 0.2,  0.03,],\n        [0.,   0.3,  0.,  ],])\n    a = center_crop(im, 1)\n    e = np.array([[0.2]])\n    np.testing.assert_array_equal(a, e)\n    im = np.array([\n        [0.,   0.1,  0.,  0],\n        [0.01, 0.2,  0.9, 0.04],\n        [0.,   0.3,  0.,  0],])\n    a = center_crop(im, 1)\n    e = np.array([[0.9]])\n    np.testing.assert_array_equal(a, e)\n\ndef test_googlenet_resize():\n    # TODO: figure out how to test this in a way it make sense\n    pass\n\ndef test_cutout():\n    im = np.ones([128,128,3], np.float32)\n    with_holes = cutout(im, 1, 10)\n    assert (with_holes == 0).sum() == 300, ""There is one cut out hole 10px x 10px in size (over 3 channels)""\n\ndef test_scale_to():\n    h=10\n    w=20\n    ratio = 127./h\n    assert scale_to(h, ratio, 127) == 127\n    assert scale_to(w, ratio, 127) == 254\n\ndef test_crop():\n    im = np.ones([128,128,3], np.float32)\n    assert crop(im, 1, 1, 10).shape == (10,10,3)\n\ndef test_to_bb():\n    im = np.array([[0, 0, 0, 0, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 1, 1, 1, 0],\n                   [0, 0, 0, 0, 0], ], dtype=np.float32)\n    expect = [1,1,3,3]\n    np.testing.assert_array_equal(to_bb(im, ""not used""), expect)\n\n### tests for transformation objects\ndef test_RandomCrop():\n    tfm = RandomCrop(23)\n    x = t_rand_img128x128x1\n    x2, cls = tfm(x, None)\n    assert x2.shape == (23,23,1)\n\ndef test_AddPadding():\n    tfm = AddPadding(1)\n    x = t_rand_img128x128x3\n    x2, cls = tfm(x, None)\n    assert x2.shape == (130,130,3)\n\ndef test_CenterCrop():\n    tfm = CenterCrop(10)\n    x = t_rand_img128x128x3\n    x2, cls = tfm(x, None)\n    assert x2.shape == (10,10,3)\n\ndef test_NoCrop():\n    tfm = NoCrop(10)\n    x = t_rand_img128x128x3\n    x2, cls = tfm(x, None)\n    assert x2.shape == (10,10,3)\n\ndef test_applying_tranfrom_multiple_times_reset_the_state():\n    tfm = RandomScale(10, 1000, p=1)\n    x1,_ = tfm(t_rand_img128x128x3, None)\n    x2,_ = tfm(t_rand_img128x128x3, None)\n    x3,_ = tfm(t_rand_img128x128x3, None)\n    assert x1.shape[0] != x2.shape[0] or x1.shape[0] != x3.shape[0], ""Each transfromation should give a bit different shape""\n    assert x1.shape[0] < 10000\n    assert x2.shape[0] < 10000\n    assert x3.shape[0] < 10000\n\nstats = inception_stats\ntfm_norm = Normalize(*stats, tfm_y=TfmType.COORD)\ntfm_denorm = Denormalize(*stats)\nbuggy_offset = 2  # This is a bug in the current transform_coord, I will fix it in the next commit\n\ndef test_transforms_works_with_coords(): # test of backward compatible behavior\n    sz = 16\n    transforms = image_gen(tfm_norm, tfm_denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=CropType.NO,\n              tfm_y=TfmType.COORD, sz_y=sz, pad_mode=cv2.BORDER_REFLECT)\n\n    x, y = transforms(t_rand_img128x128x3, np.array([0,0,128,128, 0,0,64,64]))\n    bbs = partition(y, 4)\n    assert x.shape[0] == 3, ""The image was converted from NHWC to NCHW (channle first pytorch format)""\n\n    h,w = x.shape[1:]\n    np.testing.assert_equal(bbs[0], [0, 0, h-buggy_offset, w-buggy_offset], ""The outer bounding box was converted correctly"")\n    np.testing.assert_equal(bbs[1], [0, 0, h/2-buggy_offset, w/2-buggy_offset], ""The inner bounding box was converted correctly"")\n'"
fastai/tutorials/__init__.py,0,"b""import sys\nsys.path.insert(0, '../')\n\n"""
fastai/tutorials/kmeans.py,0,"b'import tensorflow as tf\nimport math, numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef plot_data(centroids, data, n_samples):\n    colour = plt.cm.rainbow(np.linspace(0,1,len(centroids)))\n    for i, centroid in enumerate(centroids):\n        samples = data[i*n_samples:(i+1)*n_samples]\n        plt.scatter(samples[:,0], samples[:,1], c=colour[i], s=1)\n        plt.plot(centroid[0], centroid[1], markersize=10, marker=""x"", color=\'k\', mew=5)\n        plt.plot(centroid[0], centroid[1], markersize=5, marker=""x"", color=\'m\', mew=2)\n\n        \ndef all_distances(a, b):\n    diff = tf.squared_difference(tf.expand_dims(a, 0), tf.expand_dims(b,1))\n    return tf.reduce_sum(diff, axis=2)\n        \n        \nclass Kmeans(object):\n\n    def __init__(self, data, n_clusters):\n        self.n_data, self.n_dim = data.shape\n        self.n_clusters = n_clusters\n        self.data = data\n        self.v_data = tf.Variable(data)\n        self.n_samples = self.n_data//self.n_clusters\n\n    def run(self):\n        tf.global_variables_initializer().run()\n        initial_centroids = self.find_initial_centroids(self.n_clusters).eval()\n        curr_centroids = tf.Variable(initial_centroids)\n        nearest_indices = self.assign_to_nearest(curr_centroids)\n        updated_centroids = self.update_centroids(nearest_indices)\n        # Begin main algorithm\n        tf.global_variables_initializer().run()\n        c = initial_centroids\n        for i in range(10):\n            c2 = curr_centroids.assign(updated_centroids).eval()\n            if np.allclose(c,c2): break\n            c=c2\n        return c2\n\n\n    def find_initial_centroids(self, k):\n        r_index = tf.random_uniform([1], 0, self.n_data, dtype=tf.int32)\n        r = tf.expand_dims(self.v_data[tf.squeeze(r_index)], dim=1)\n        initial_centroids = []\n        for i in range(k):\n            dist = all_distances(self.v_data, r)\n            farthest_index = tf.argmax(tf.reduce_min(dist, axis=0), 0)\n            farthest_point = self.v_data[tf.to_int32(farthest_index)]\n            initial_centroids.append(farthest_point)\n            r = tf.stack(initial_centroids)\n        return r\n\n    def choose_random_centroids(self):\n        n_samples = tf.shape(v_data)[0]\n        random_indices = tf.random_shuffle(tf.range(0, n_samples))\n        centroid_indices = random_indices[:self.n_clusters]\n        return tf.gather(self.v_data, centroid_indices)\n\n    def assign_to_nearest(self, centroids):\n        return tf.argmin(all_distances(self.v_data, centroids), 0)\n\n    def update_centroids(self, nearest_indices):\n        partitions = tf.dynamic_partition(self.v_data, tf.to_int32(nearest_indices), self.n_clusters)\n        return tf.concat([tf.expand_dims(tf.reduce_mean(partition, 0), 0)\n                                      for partition in partitions], 0)\n   \n        '"
fastai/courses/dl1/planet.py,0,"b'from fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.dataset import *\nfrom sklearn.metrics import fbeta_score\nimport warnings\n\ndef f2(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"")\n        return max([fbeta_score(targs, (preds>th), 2, average=\'samples\')\n                    for th in np.arange(start,end,step)])\n\ndef opt_th(preds, targs, start=0.17, end=0.24, step=0.01):\n    ths = np.arange(start,end,step)\n    idx = np.argmax([fbeta_score(targs, (preds>th), 2, average=\'samples\')\n                for th in ths])\n    return ths[idx]\n\ndef get_data(path, tfms,bs,  n, cv_idx):\n    val_idxs = get_cv_idxs(n, cv_idx)\n    return ImageClassifierData.from_csv(path, \'train-jpg\', f\'{path}train_v2.csv\', bs, tfms,\n                                 suffix=\'.jpg\', val_idxs=val_idxs, test_name=\'test-jpg\')\n\ndef get_data_zoom(f_model, path, sz, bs, n, cv_idx):\n    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n    return get_data(path, tfms, bs, n, cv_idx)\n\ndef get_data_pad(f_model, path, sz, bs, n, cv_idx):\n    transforms_pt = [RandomRotateZoom(9, 0.18, 0.1), RandomLighting(0.05, 0.1), RandomDihedral()]\n    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_pt, pad=sz//12)\n    return get_data(path, tfms, bs, n, cv_idx)\n'"
fastai/courses/dl1/rossman_exp.py,0,"b'train_ratio=0.9\nuse_dict=True\nuse_scaler=False\ninit_emb=False\nsplit_contins=True\nsamp_size = 100000\n#samp_size = 0\n\nimport math, keras, datetime, pandas as pd, numpy as np, keras.backend as K\nimport matplotlib.pyplot as plt, xgboost, operator, random, pickle, os\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom keras.models import Model\nfrom keras.layers import merge, Input\nfrom keras.layers.core import Dense, Activation, Reshape, Flatten, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.optimizers import Adam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom keras import initializations\nnp.set_printoptions(4)\n\ncfg = K.tf.ConfigProto()\ncfg.gpu_options.allow_growth = True\nK.set_session(K.tf.Session(config=cfg))\n\nos.chdir(\'data/rossman\')\ncat_var_dict = {\'Store\': 50, \'DayOfWeek\': 6, \'Year\': 2, \'Month\': 6,\n    \'Day\': 10, \'StateHoliday\': 3, \'CompetitionMonthsOpen\': 2,\n    \'Promo2Weeks\': 1, \'StoreType\': 2, \'Assortment\': 3, \'PromoInterval\': 3,\n    \'CompetitionOpenSinceYear\': 4, \'Promo2SinceYear\': 4, \'State\': 6,\n    \'Week\': 2, \'Events\': 4, \'Promo_fw\': 1,\n    \'Promo_bw\': 1, \'StateHoliday_fw\': 1,\n    \'StateHoliday_bw\': 1, \'SchoolHoliday_fw\': 1,\n    \'SchoolHoliday_bw\': 1}\n\ncats, contins= [o for n,o in np.load(\'vars.npz\').items()]\ny = np.load(\'deps.npz\').items()[0][1]\n\nif samp_size != 0:\n    np.random.seed(42)\n    idxs = sorted(np.random.choice(len(y), samp_size, replace=False))\n    cats= cats[idxs]\n    contins= contins[idxs]\n    y= y[idxs]\n\nn=len(y)\ntrain_size = int(n*train_ratio)\n\ncontins_trn_orig, contins_val_orig = contins[:train_size], contins[train_size:]\ncats_trn, cats_val = cats[:train_size], cats[train_size:]\ny_trn, y_val = y[:train_size], y[train_size:]\n\ncontin_map_fit = pickle.load(open(\'contin_maps.pickle\', \'rb\'))\ncat_map_fit = pickle.load(open(\'cat_maps.pickle\', \'rb\'))\n\ndef cat_map_info(feat): return feat[0], len(feat[1].classes_)\n\nco_enc = StandardScaler().fit(contins_trn_orig)\ntf_contins_trn = co_enc.transform(contins_trn_orig)\ntf_contins_val = co_enc.transform(contins_val_orig)\n\n\n""""""\ndef rmspe(y_pred, targ = y_valid_orig):\n    return math.sqrt(np.square((targ - y_pred)/targ).mean())\ndef log_max_inv(preds, mx = max_log_y): return np.exp(preds * mx)\ndef normalize_inv(preds): return preds * ystd + ymean\n""""""\n\n\ndef split_cols(arr): return np.hsplit(arr,arr.shape[1])\n\n\ndef emb_init(shape, name=None):\n    return initializations.uniform(shape, scale=0.6/shape[1], name=name)\n\n\ndef get_emb(feat):\n    name, c = cat_map_info(feat)\n    if use_dict:\n        c2 = cat_var_dict[name]\n    else:\n        c2 = (c+2)//3\n        if c2>50: c2=50\n    inp = Input((1,), dtype=\'int64\', name=name+\'_in\')\n    if init_emb:\n        u = Flatten(name=name+\'_flt\')(Embedding(c, c2, input_length=1)(inp))\n    else:\n        u = Flatten(name=name+\'_flt\')(Embedding(c, c2, input_length=1, init=emb_init)(inp))\n    return inp,u\n\n\ndef get_contin(feat):\n    name = feat[0][0]\n    inp = Input((1,), name=name+\'_in\')\n    return inp, Dense(1, name=name+\'_d\')(inp)\n\n\ndef split_data():\n    if split_contins:\n        map_train = split_cols(cats_trn) + split_cols(contins_trn)\n        map_valid = split_cols(cats_val) + split_cols(contins_val)\n    else:\n        map_train = split_cols(cats_trn) + [contins_trn]\n        map_valid = split_cols(cats_val) + [contins_val]\n    return (map_train, map_valid)\n\n\ndef get_contin_one():\n    n_contin = contins_trn.shape[1]\n    contin_inp = Input((n_contin,), name=\'contin\')\n    contin_out = BatchNormalization()(contin_inp)\n    return contin_inp, contin_out\n\n\ndef train(model, map_train, map_valid,  bs=128, ne=10):\n    return model.fit(map_train, y_trn, batch_size=bs, nb_epoch=ne,\n                 verbose=0, validation_data=(map_valid, y_val))\n\n\ndef get_model():\n    if split_contins:\n        conts = [get_contin(feat) for feat in contin_map_fit.features]\n        cont_out = [d for inp,d in conts]\n        cont_inp = [inp for inp,d in conts]\n    else:\n        contin_inp, contin_out = get_contin_one()\n        cont_out = [contin_out]\n        cont_inp = [contin_inp]\n\n    embs = [get_emb(feat) for feat in cat_map_fit.features]\n    x = merge([emb for inp,emb in embs] + cont_out, mode=\'concat\')\n\n    x = Dropout(0.02)(x)\n    x = Dense(1000, activation=\'relu\', init=\'uniform\')(x)\n    x = Dense(500, activation=\'relu\', init=\'uniform\')(x)\n    x = Dense(1, activation=\'sigmoid\')(x)\n\n    model = Model([inp for inp,emb in embs] + cont_inp, x)\n    model.compile(\'adam\', \'mean_absolute_error\')\n    #model.compile(Adam(), \'mse\')\n    return model\n\nfor split_contins in [True, False]:\n    for use_dict in [True, False]:\n        for use_scaler in [True, False]:\n            for init_emb in [True, False]:\n                print ({\'split_contins\':split_contins, \'use_dict\':use_dict,\n                       \'use_scaler\':use_scaler, \'init_emb\':init_emb})\n                if use_scaler:\n                    contins_trn = tf_contins_trn\n                    contins_val = tf_contins_val\n                else:\n                    contins_trn = contins_trn_orig\n                    contins_val = contins_val_orig\n\n                map_train, map_valid = split_data()\n                model = get_model()\n                hist = np.array(train(model, map_train, map_valid, 128, 10)\n                                .history[\'val_loss\'])\n                print(hist)\n                print(hist.min())\n\n'"
fastai/courses/dl2/sampled_sm.py,4,"b'from fastai.learner import *\nfrom fastai.text import *\n\ndef resample_vocab(itos, trn, val, sz):\n    freqs = Counter(trn)\n    itos2 = [o for o,p in freqs.most_common()][:sz]\n    itos2.insert(0,1)\n    itos2.insert(0,0)\n    stoi2 = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos2)})\n\n    trn = np.array([stoi2[o] for o in trn])\n    val = np.array([stoi2[o] for o in val])\n\n    itos3 = [itos[o] for o in itos2]\n    stoi3 = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos3)})\n    return trn,val,itos3,stoi3\n\n\ndef get_prs(c, nt):\n    uni_counter = Counter(c)\n    uni_counts = np.array([uni_counter[o] for o in range(nt)])\n    return uni_counts/uni_counts.sum()\n\nclass LinearDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, n_out, nhid, dropout, tie_encoder=None, decode_train=True):\n        super().__init__()\n        self.decode_train = decode_train\n        self.decoder = nn.Linear(nhid, n_out, bias=False)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.dropout = LockedDropout(dropout)\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = self.dropout(outputs[-1])\n        output = output.view(output.size(0)*output.size(1), output.size(2))\n        if self.decode_train or not self.training:\n            decoded = self.decoder(output)\n            output = decoded.view(-1, decoded.size(1))\n        return output, raw_outputs, outputs\n\n\ndef get_language_model(n_tok, em_sz, nhid, nlayers, pad_token, decode_train=True, dropouts=None):\n    if dropouts is None: dropouts = [0.5,0.4,0.5,0.05,0.3]\n    rnn_enc = RNN_Encoder(n_tok, em_sz, nhid=nhid, nlayers=nlayers, pad_token=pad_token,\n                 dropouti=dropouts[0], wdrop=dropouts[2], dropoute=dropouts[3], dropouth=dropouts[4])\n    rnn_dec = LinearDecoder(n_tok, em_sz, dropouts[1], decode_train=decode_train, tie_encoder=rnn_enc.encoder)\n    return SequentialRNN(rnn_enc, rnn_dec)\n\n\ndef pt_sample(pr, ns):\n    w = -torch.log(cuda.FloatTensor(len(pr)).uniform_())/(pr+1e-10)\n    return torch.topk(w, ns, largest=False)[1]\n\n\nclass CrossEntDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, prs, decoder, n_neg=4000, sampled=True):\n        super().__init__()\n        self.prs,self.decoder,self.sampled = T(prs).cuda(),decoder,sampled\n        self.set_n_neg(n_neg)\n\n    def set_n_neg(self, n_neg): self.n_neg = n_neg\n\n    def get_rand_idxs(self): return pt_sample(self.prs, self.n_neg)\n\n    def sampled_softmax(self, input, target):\n        idxs = V(self.get_rand_idxs())\n        dw = self.decoder.weight\n        #db = self.decoder.bias\n        output = input @ dw[idxs].t() #+ db[idxs]\n        max_output = output.max()\n        output = output - max_output\n        num = (dw[target] * input).sum(1) - max_output\n        negs = torch.exp(num) + (torch.exp(output)*2).sum(1)\n        return (torch.log(negs) - num).mean()\n\n    def forward(self, input, target):\n        if self.decoder.training:\n            if self.sampled: return self.sampled_softmax(input, target)\n            else: input = self.decoder(input)\n        return F.cross_entropy(input, target)\n\ndef get_learner(drops, n_neg, sampled, md, em_sz, nh, nl, opt_fn, prs):\n    m = to_gpu(get_language_model(md.nt, em_sz, nh, nl, md.pad_idx, decode_train=False, dropouts=drops))\n    crit = CrossEntDecoder(prs, m[1].decoder, n_neg=n_neg, sampled=sampled).cuda()\n    learner = RNN_Learner(md, LanguageModel(m), opt_fn=opt_fn)\n    crit.dw = learner.model[0].encoder.weight\n    learner.crit = crit\n    learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n    learner.clip=0.3\n    return learner,crit\n\n'"
fastai/fastai/models/convert_torch.py,13,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.serialization import load_lua\n\nimport numpy as np\nimport os\nimport math\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        # result is Variables list [Variable1, Variable2, ...]\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        # result is a Variable\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef copy_param(m,n):\n    if m.weight is not None: n.weight.data.copy_(m.weight)\n    if m.bias is not None: n.bias.data.copy_(m.bias)\n    if hasattr(n,\'running_mean\'): n.running_mean.copy_(m.running_mean)\n    if hasattr(n,\'running_var\'): n.running_var.copy_(m.running_var)\n\ndef add_submodule(seq, *args):\n    for n in args:\n        seq.add_module(str(len(seq._modules)),n)\n\ndef lua_recursive_model(module,seq):\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            n = nn.Conv2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,bias=(m.bias is not None))\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'SpatialBatchNormalization\':\n            n = nn.BatchNorm2d(m.running_mean.size(0), m.eps, m.momentum, m.affine)\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'ReLU\':\n            n = nn.ReLU()\n            add_submodule(seq,n)\n        elif name == \'SpatialMaxPooling\':\n            n = nn.MaxPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialAveragePooling\':\n            n = nn.AvgPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialUpSamplingNearest\':\n            n = nn.UpsamplingNearest2d(scale_factor=m.scale_factor)\n            add_submodule(seq,n)\n        elif name == \'View\':\n            n = Lambda(lambda x: x.view(x.size(0),-1))\n            add_submodule(seq,n)\n        elif name == \'Linear\':\n            # Linear in pytorch only accept 2D input\n            n1 = Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\n            n2 = nn.Linear(m.weight.size(1),m.weight.size(0),bias=(m.bias is not None))\n            copy_param(m,n2)\n            n = nn.Sequential(n1,n2)\n            add_submodule(seq,n)\n        elif name == \'Dropout\':\n            m.inplace = False\n            n = nn.Dropout(m.p)\n            add_submodule(seq,n)\n        elif name == \'SoftMax\':\n            n = nn.Softmax()\n            add_submodule(seq,n)\n        elif name == \'Identity\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'SpatialFullConvolution\':\n            n = nn.ConvTranspose2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))\n            add_submodule(seq,n)\n        elif name == \'SpatialReplicationPadding\':\n            n = nn.ReplicationPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'SpatialReflectionPadding\':\n            n = nn.ReflectionPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'Copy\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'Narrow\':\n            n = Lambda(lambda x,a=(m.dimension,m.index,m.length): x.narrow(*a))\n            add_submodule(seq,n)\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = torch.legacy.nn.SpatialCrossMapLRN(m.size,m.alpha,m.beta,m.k)\n            n = Lambda(lambda x,lrn=lrn: Variable(lrn.forward(x.data)))\n            add_submodule(seq,n)\n        elif name == \'Sequential\':\n            n = nn.Sequential()\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'ConcatTable\': # output is list\n            n = LambdaMap(lambda x: x)\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'CAddTable\': # input is list\n            n = LambdaReduce(lambda x,y: x+y)\n            add_submodule(seq,n)\n        elif name == \'Concat\':\n            dim = m.dimension\n            n = LambdaReduce(lambda x,y,dim=dim: torch.cat((x,y),dim))\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'TorchObject\':\n            print(\'Not Implement\',name,real._typename)\n        else:\n            print(\'Not Implement\',name)\n\n\ndef lua_recursive_source(module):\n    s = []\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            s += [\'nn.Conv2d({},{},{},{},{},{},{},bias={}),#Conv2d\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,m.bias is not None)]\n        elif name == \'SpatialBatchNormalization\':\n            s += [\'nn.BatchNorm2d({},{},{},{}),#BatchNorm2d\'.format(m.running_mean.size(0), m.eps, m.momentum, m.affine)]\n        elif name == \'ReLU\':\n            s += [\'nn.ReLU()\']\n        elif name == \'SpatialMaxPooling\':\n            s += [\'nn.MaxPool2d({},{},{},ceil_mode={}),#MaxPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialAveragePooling\':\n            s += [\'nn.AvgPool2d({},{},{},ceil_mode={}),#AvgPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialUpSamplingNearest\':\n            s += [\'nn.UpsamplingNearest2d(scale_factor={})\'.format(m.scale_factor)]\n        elif name == \'View\':\n            s += [\'Lambda(lambda x: x.view(x.size(0),-1)), # View\']\n        elif name == \'Linear\':\n            s1 = \'Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\'\n            s2 = \'nn.Linear({},{},bias={})\'.format(m.weight.size(1),m.weight.size(0),(m.bias is not None))\n            s += [\'nn.Sequential({},{}),#Linear\'.format(s1,s2)]\n        elif name == \'Dropout\':\n            s += [\'nn.Dropout({})\'.format(m.p)]\n        elif name == \'SoftMax\':\n            s += [\'nn.Softmax()\']\n        elif name == \'Identity\':\n            s += [\'Lambda(lambda x: x), # Identity\']\n        elif name == \'SpatialFullConvolution\':\n            s += [\'nn.ConvTranspose2d({},{},{},{},{})\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))]\n        elif name == \'SpatialReplicationPadding\':\n            s += [\'nn.ReplicationPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'SpatialReflectionPadding\':\n            s += [\'nn.ReflectionPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'Copy\':\n            s += [\'Lambda(lambda x: x), # Copy\']\n        elif name == \'Narrow\':\n            s += [\'Lambda(lambda x,a={}: x.narrow(*a))\'.format((m.dimension,m.index,m.length))]\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = \'torch.legacy.nn.SpatialCrossMapLRN(*{})\'.format((m.size,m.alpha,m.beta,m.k))\n            s += [\'Lambda(lambda x,lrn={}: Variable(lrn.forward(x.data)))\'.format(lrn)]\n\n        elif name == \'Sequential\':\n            s += [\'nn.Sequential( # Sequential\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'ConcatTable\':\n            s += [\'LambdaMap(lambda x: x, # ConcatTable\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'CAddTable\':\n            s += [\'LambdaReduce(lambda x,y: x+y), # CAddTable\']\n        elif name == \'Concat\':\n            dim = m.dimension\n            s += [\'LambdaReduce(lambda x,y,dim={}: torch.cat((x,y),dim), # Concat\'.format(m.dimension)]\n            s += lua_recursive_source(m)\n            s += [\')\']\n        else:\n            s += \'# \' + name + \' Not Implement,\\n\'\n    s = map(lambda x: \'\\t{}\'.format(x),s)\n    return s\n\ndef simplify_source(s):\n    s = map(lambda x: x.replace(\',(1, 1),(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1e-05,0.1,True),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True)),#Linear\',\')), # Linear\'),s)\n    s = map(lambda x: x.replace(\')),#Linear\',\')), # Linear\'),s)\n    \n    s = map(lambda x: \'{},\\n\'.format(x),s)\n    s = map(lambda x: x[1:],s)\n    s = reduce(lambda x,y: x+y, s)\n    return s\n\ndef torch_to_pytorch(t7_filename,outputname=None):\n    model = load_lua(t7_filename,unknown_classes=True)\n    if type(model).__name__==\'hashable_uniq_dict\': model=model.model\n    model.gradInput = None\n    slist = lua_recursive_source(torch.legacy.nn.Sequential().add(model))\n    s = simplify_source(slist)\n    header = \'\'\'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\'\'\'\n    varname = t7_filename.replace(\'.t7\',\'\').replace(\'.\',\'_\').replace(\'-\',\'_\')\n    s = \'{}\\n\\n{} = {}\'.format(header,varname,s[:-2])\n\n    if outputname is None: outputname=varname\n    with open(outputname+\'.py\', ""w"") as pyfile:\n        pyfile.write(s)\n\n    n = nn.Sequential()\n    lua_recursive_model(model,n)\n    torch.save(n.state_dict(),outputname+\'.pth\')\n\n\nparser = argparse.ArgumentParser(description=\'Convert torch t7 model to pytorch\')\nparser.add_argument(\'--model\',\'-m\', type=str, required=True,\n                    help=\'torch model file in t7 format\')\nparser.add_argument(\'--output\', \'-o\', type=str, default=None,\n                    help=\'output file name prefix, xxx.py xxx.pth\')\nargs = parser.parse_args()\n\ntorch_to_pytorch(args.model,args.output)\n'"
fastai/fastai/models/darknet.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .layers import *\n\nclass ConvBN(nn.Module):\n    ""convolutional layer then batchnorm""\n\n    def __init__(self, ch_in, ch_out, kernel_size = 3, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(ch_out, momentum=0.01)\n        self.relu = nn.LeakyReLU(0.1, inplace=True)\n\n    def forward(self, x): return self.relu(self.bn(self.conv(x)))\n\nclass DarknetBlock(nn.Module):\n    def __init__(self, ch_in):\n        super().__init__()\n        ch_hid = ch_in//2\n        self.conv1 = ConvBN(ch_in, ch_hid, kernel_size=1, stride=1, padding=0)\n        self.conv2 = ConvBN(ch_hid, ch_in, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x): return self.conv2(self.conv1(x)) + x\n\nclass Darknet(nn.Module):\n    ""Replicates the darknet classifier from the YOLOv3 paper (table 1)""\n\n    def make_group_layer(self, ch_in, num_blocks, stride=1):\n        layers = [ConvBN(ch_in,ch_in*2,stride=stride)]\n        for i in range(num_blocks): layers.append(DarknetBlock(ch_in*2))\n        return layers\n\n    def __init__(self, num_blocks, num_classes=1000, start_nf=32):\n        super().__init__()\n        nf = start_nf\n        layers = [ConvBN(3, nf, kernel_size=3, stride=1, padding=1)]\n        for i,nb in enumerate(num_blocks):\n            layers += self.make_group_layer(nf, nb, stride=(1 if i==1 else 2))\n            nf *= 2\n        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x): return self.layers(x)\n\ndef darknet_53(num_classes=1000):    return Darknet([1,2,8,8,4], num_classes)\ndef darknet_small(num_classes=1000): return Darknet([1,2,4,8,4], num_classes)\ndef darknet_mini(num_classes=1000): return Darknet([1,2,4,4,2], num_classes, start_nf=24)\ndef darknet_mini2(num_classes=1000): return Darknet([1,2,8,8,4], num_classes, start_nf=16)\ndef darknet_mini3(num_classes=1000): return Darknet([1,2,4,4], num_classes)\n\n'"
fastai/fastai/models/fa_resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out += residual\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out += residual\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\ndef load(model, pre, name):\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    return model\n\ndef fa_resnet18(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [2, 2, 2, 2], **kwargs), pretrained, \'resnet18\')\ndef fa_resnet34(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [3, 4, 6, 3], **kwargs), pretrained, \'resnet34\')\ndef fa_resnet50(pretrained=False, **kwargs):  return load(ResNet(Bottleneck, [3, 4, 6, 3], **kwargs), pretrained, \'resnet50\')\ndef fa_resnet101(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 4, 23, 3], **kwargs), pretrained, \'resnet101\')\ndef fa_resnet152(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 8, 36, 3], **kwargs), pretrained, \'resnet152\')\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 ():  return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50():  return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck,[3, 4, 6, 3], k=1.125)\ndef vgg_resnet50():  return ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n\n'"
fastai/fastai/models/inceptionresnetv2.py,31,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'http://webia.lip6.fr/~cadene/Downloads/inceptionresnetv2-d579a627.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_5b(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5b, self).__init__()\n\n        self.branch0 = BasicConv2d(192, 96, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(192, 48, kernel_size=1, stride=1),\n            BasicConv2d(48, 64, kernel_size=5, stride=1, padding=2)\n        ) \n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(192, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(192, 64, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block35(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block35, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(320, 32, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 48, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(48, 64, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.conv2d = nn.Conv2d(128, 320, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_6a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_6a, self).__init__()\n        \n        self.branch0 = BasicConv2d(320, 384, kernel_size=3, stride=2)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Block17(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block17, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(1088, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 128, kernel_size=1, stride=1),\n            BasicConv2d(128, 160, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(160, 192, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.conv2d = nn.Conv2d(384, 1088, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_7a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_7a, self).__init__()\n        \n        self.branch0 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(288, 320, kernel_size=3, stride=2)\n        )\n\n        self.branch3 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block8(nn.Module):\n\n    def __init__(self, scale=1.0, noReLU=False):\n        super(Block8, self).__init__()\n\n        self.scale = scale\n        self.noReLU = noReLU\n\n        self.branch0 = BasicConv2d(2080, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(2080, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,3), stride=1, padding=(0,1)),\n            BasicConv2d(224, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        )\n\n        self.conv2d = nn.Conv2d(448, 2080, kernel_size=1, stride=1)\n        if not self.noReLU:\n            self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        if not self.noReLU:\n            out = self.relu(out)\n        return out\n\n\nclass InceptionResnetV2(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionResnetV2, self).__init__()\n        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n        self.maxpool_5a = nn.MaxPool2d(3, stride=2)\n        self.mixed_5b = Mixed_5b()\n        self.repeat = nn.Sequential(\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17)\n        )\n        self.mixed_6a = Mixed_6a()\n        self.repeat_1 = nn.Sequential(\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10)\n        )\n        self.mixed_7a = Mixed_7a()\n        self.repeat_2 = nn.Sequential(\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20)\n        )\n        self.block8 = Block8(noReLU=True)\n        self.conv2d_7b = BasicConv2d(2080, 1536, kernel_size=1, stride=1)\n        self.avgpool_1a = nn.AdaptiveAvgPool2d((1,1))\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.conv2d_1a(x)\n        x = self.conv2d_2a(x)\n        x = self.conv2d_2b(x)\n        x = self.maxpool_3a(x)\n        x = self.conv2d_3b(x)\n        x = self.conv2d_4a(x)\n        x = self.maxpool_5a(x)\n        x = self.mixed_5b(x)\n        x = self.repeat(x)\n        x = self.mixed_6a(x)\n        x = self.repeat_1(x)\n        x = self.mixed_7a(x)\n        x = self.repeat_2(x)\n        x = self.block8(x)\n        x = self.conv2d_7b(x)\n        x = self.avgpool_1a(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\ndef inceptionresnetv2(pretrained=True):\n    r""""""InceptionResnetV2 model architecture from the\n    `""InceptionV4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (\'string\'): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionResnetV2()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_conv2d_nobn(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_5b(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_5x5\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_block35(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_6a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_block17(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef load_block8(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_1a\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2a\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2b\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_3b\', name_tf=\'Conv2d_3b_1x1\')\n    load_conv2d(state_dict, name_pth=\'conv2d_4a\', name_tf=\'Conv2d_4a_3x3\')\n\n    load_mixed_5b(state_dict, name_pth=\'mixed_5b\', name_tf=\'Mixed_5b\')\n\n    for i in range(10):\n        load_block35(state_dict, name_pth=\'repeat.\'+str(i), name_tf=\'Repeat/block35_\'+str(i+1))\n\n    load_mixed_6a(state_dict, name_pth=\'mixed_6a\', name_tf=\'Mixed_6a\')\n\n    for i in range(20):\n        load_block17(state_dict, name_pth=\'repeat_1.\'+str(i), name_tf=\'Repeat_1/block17_\'+str(i+1))\n\n    load_mixed_7a(state_dict, name_pth=\'mixed_7a\', name_tf=\'Mixed_7a\')\n\n    for i in range(9):\n        load_block8(state_dict, name_pth=\'repeat_2.\'+str(i), name_tf=\'Repeat_2/block8_\'+str(i+1))\n\n    load_block8(state_dict, name_pth=\'block8\', name_tf=\'Block8\')\n    load_conv2d(state_dict, name_pth=\'conv2d_7b\', name_tf=\'Conv2d_7b_1x1\')\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.ones(1,299,299,3)\n    #inputs[0] = torch.from_numpy(img)\n\n    inputs[0,0,0,0] = -1\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n\n    print(inputs.mean())\n    print(inputs.std())\n\n    #inputs.sub_(0.5).div_(0.5)\n    #inputs.sub_(inputs)\n    # 1, 3, 299, 299\n\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionResnetV2/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(outputs.sum())\n    print(outputs[0])\n    print(outputs_tf.sum())\n    print(outputs_tf[0])\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf_conv = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf_conv.transpose_(1,3)\n    output_tf_conv.transpose_(2,3)\n    output_tf_relu = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf_relu.transpose_(1,3)\n    output_tf_relu.transpose_(2,3)\n    h5f.close()\n    def test_dist_conv(self, input, output):\n        print(name, \'conv\', torch.dist(output.data, output_tf_conv))\n    module.conv.register_forward_hook(test_dist_conv)\n    def test_dist_relu(self, input, output):\n        print(name, \'relu\', torch.dist(output.data, output_tf_relu))\n    module.relu.register_forward_hook(test_dist_relu)\n\ndef test_conv2d_nobn(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, \'conv+bias\', torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_5b(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_5x5\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d(module.branch3[1], name+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef test_block35(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_6a(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef test_block17(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_1a_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef test_block8(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_3x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionResnetV2()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n    model.eval()\n\n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionresnetv2.pth\')\n    torch.save(state_dict, \'save/inceptionresnetv2_state.pth\')\n\n    test_conv2d(model.conv2d_1a, \'Conv2d_1a_3x3\')\n    test_conv2d(model.conv2d_2a, \'Conv2d_2a_3x3\')\n    test_conv2d(model.conv2d_2b, \'Conv2d_2b_3x3\')\n    test_conv2d(model.conv2d_3b, \'Conv2d_3b_1x1\')\n    test_conv2d(model.conv2d_4a, \'Conv2d_4a_3x3\')\n\n    test_mixed_5b(model.mixed_5b, \'Mixed_5b\')\n\n    for i in range(len(model.repeat._modules)):\n        test_block35(model.repeat[i], \'Repeat/block35_\'+str(i+1))\n\n    test_mixed_6a(model.mixed_6a, \'Mixed_6a\')\n\n    for i in range(len(model.repeat_1._modules)):\n        test_block17(model.repeat_1[i], \'Repeat_1/block17_\'+str(i+1))\n\n    test_mixed_7a(model.mixed_7a, \'Mixed_7a\')\n\n    for i in range(len(model.repeat_2._modules)):\n        test_block8(model.repeat_2[i], \'Repeat_2/block8_\'+str(i+1))\n\n    test_block8(model.block8, \'Block8\')\n\n    test_conv2d(model.conv2d_7b, \'Conv2d_7b_1x1\')\n\n    outputs = test(model)\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    #test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n\n'"
fastai/fastai/models/inceptionv4.py,29,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'https://s3.amazonaws.com/pytorch/models/inceptionv4-58153ba9.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_3a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_3a, self).__init__()\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n\n    def forward(self, x):\n        x0 = self.maxpool(x)\n        x1 = self.conv(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_4a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_4a, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(64, 96, kernel_size=(3,3), stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_5a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5a, self).__init__()\n        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.conv(x)\n        x1 = self.maxpool(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Inception_A(nn.Module):\n\n    def __init__(self):\n        super(Inception_A, self).__init__()\n        self.block0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(384, 96, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_A(nn.Module):\n\n    def __init__(self):\n        super(Reduction_A, self).__init__()\n        self.block0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(224, 256, kernel_size=3, stride=2)\n        )\n        \n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_B(nn.Module):\n\n    def __init__(self):\n        super(Inception_B, self).__init__()\n        self.block0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n        \n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_B(nn.Module):\n\n    def __init__(self):\n        super(Reduction_B, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=3, stride=2)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(320, 320, kernel_size=3, stride=2)\n        )\n\n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_C(nn.Module):\n\n    def __init__(self):\n        super(Inception_C, self).__init__()\n        self.block0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        \n        self.block1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n        self.block2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3a = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3b = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        \n        x1_0 = self.block1_0(x)\n        x1_1a = self.block1_1a(x1_0)\n        x1_1b = self.block1_1b(x1_0)\n        x1 = torch.cat((x1_1a, x1_1b), 1)\n\n        x2_0 = self.block2_0(x)\n        x2_1 = self.block2_1(x2_0)\n        x2_2 = self.block2_2(x2_1)\n        x2_3a = self.block2_3a(x2_2)\n        x2_3b = self.block2_3b(x2_2)\n        x2 = torch.cat((x2_3a, x2_3b), 1)\n\n        x3 = self.block3(x)\n\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass InceptionV4(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionV4, self).__init__()\n        self.features = nn.Sequential(\n            BasicConv2d(3, 32, kernel_size=3, stride=2),\n            BasicConv2d(32, 32, kernel_size=3, stride=1),\n            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            Mixed_3a(),\n            Mixed_4a(),\n            Mixed_5a(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Reduction_A(), # Mixed_6a\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Reduction_B(), # Mixed_7a\n            Inception_C(),\n            Inception_C(),\n            Inception_C(),\n            nn.AdaptiveAvgPool2d((1,1))\n        )\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\n\ndef inceptionv4(pretrained=True):\n    r""""""InceptionV4 model architecture from the\n    `""Inception-v4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionV4()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_4a_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.3\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_mixed_5(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_6(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch2.3\', name_tf+\'/Branch_2/Conv2d_0d_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.4\', name_tf+\'/Branch_2/Conv2d_0e_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_7(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1a\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1b\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_1\', name_tf+\'/Branch_2/Conv2d_0b_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_2\', name_tf+\'/Branch_2/Conv2d_0c_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3a\', name_tf+\'/Branch_2/Conv2d_0d_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3b\', name_tf+\'/Branch_2/Conv2d_0e_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'features.0\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.1\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.2\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'features.3.conv\', name_tf=\'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.4\', name_tf=\'Mixed_4a\')\n\n    load_conv2d(state_dict, name_pth=\'features.5.conv\', name_tf=\'Mixed_5a/Branch_0/Conv2d_1a_3x3\')\n\n    load_mixed_5(state_dict, name_pth=\'features.6\', name_tf=\'Mixed_5b\')\n    load_mixed_5(state_dict, name_pth=\'features.7\', name_tf=\'Mixed_5c\')\n    load_mixed_5(state_dict, name_pth=\'features.8\', name_tf=\'Mixed_5d\')\n    load_mixed_5(state_dict, name_pth=\'features.9\', name_tf=\'Mixed_5e\')\n\n    load_conv2d(state_dict, name_pth=\'features.10.branch0\', name_tf=\'Mixed_6a/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.0\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.1\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.2\', name_tf=\'Mixed_6a/Branch_1/Conv2d_1a_3x3\')\n\n    load_mixed_6(state_dict, name_pth=\'features.11\', name_tf=\'Mixed_6b\')\n    load_mixed_6(state_dict, name_pth=\'features.12\', name_tf=\'Mixed_6c\')\n    load_mixed_6(state_dict, name_pth=\'features.13\', name_tf=\'Mixed_6d\')\n    load_mixed_6(state_dict, name_pth=\'features.14\', name_tf=\'Mixed_6e\')\n    load_mixed_6(state_dict, name_pth=\'features.15\', name_tf=\'Mixed_6f\')\n    load_mixed_6(state_dict, name_pth=\'features.16\', name_tf=\'Mixed_6g\')\n    load_mixed_6(state_dict, name_pth=\'features.17\', name_tf=\'Mixed_6h\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.18\', name_tf=\'Mixed_7a\')\n\n    load_mixed_7(state_dict, name_pth=\'features.19\', name_tf=\'Mixed_7b\')\n    load_mixed_7(state_dict, name_pth=\'features.20\', name_tf=\'Mixed_7c\')\n    load_mixed_7(state_dict, name_pth=\'features.21\', name_tf=\'Mixed_7d\')\n\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    model.eval()\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.zeros(1,299,299,3)\n    inputs[0] = torch.from_numpy(img)\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n    # 1, 3, 299, 299\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionV4/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionV4/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_4a_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d(module.branch1[3], name+\'/Branch_1/Conv2d_1a_3x3\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionV4()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n\n    # test_conv2d(model.features[0], \'Conv2d_1a_3x3\')\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    # test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n    \n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionv4.pth\')\n    torch.save(state_dict, \'save/inceptionv4_state.pth\')\n\n    outputs = test(model)\n\n\n'"
fastai/fastai/models/nasnet.py,12,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\npretrained_settings = {\n    \'nasnetalarge\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1000\n        },\n        \'imagenet+background\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1001\n        }\n    }\n}\n\nclass MaxPoolPad(nn.Module):\n\n    def __init__(self):\n        super(MaxPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass AvgPoolPad(nn.Module):\n\n    def __init__(self, stride=2, padding=1):\n        super(AvgPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass SeparableConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n                                          stride=dw_stride,\n                                          padding=dw_padding,\n                                          bias=bias,\n                                          groups=in_channels)\n        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise_conv2d(x)\n        x = self.pointwise_conv2d(x)\n        return x\n\n\nclass BranchSeparables(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparables, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesStem(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparablesStem, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesReduction(BranchSeparables):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.padding(x)\n        x = self.separable_1(x)\n        x = x[:, :, 1:, 1:].contiguous()\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass CellStem0(nn.Module):\n\n    def __init__(self):\n        super(CellStem0, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(42, 42, 5, 2, 2)\n        self.comb_iter_0_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparablesStem(96, 42, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(42, 42, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x1 = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n        x_comb_iter_0_right = self.comb_iter_0_right(x)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n        x_comb_iter_1_right = self.comb_iter_1_right(x)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n        x_comb_iter_2_right = self.comb_iter_2_right(x)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass CellStem1(nn.Module):\n\n    def __init__(self):\n        super(CellStem1, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(168, 84, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(84, 84, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x_conv0, x_stem_0):\n        x_left = self.conv_1x1(x_stem_0)\n\n        x_relu = self.relu(x_conv0)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass FirstCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(FirstCell, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_relu = self.relu(x_prev)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NormalCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(NormalCell, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell0(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell0, self).__init__() \n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = MaxPoolPad()\n        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = AvgPoolPad()\n        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = MaxPoolPad()\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell1(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell1, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NASNetALarge(nn.Module):\n\n    def __init__(self, use_classifer=False, num_classes=1001):\n        super(NASNetALarge, self).__init__()\n        self.use_classifer,self.num_classes = use_classifer,num_classes\n\n        self.conv0 = nn.Sequential()\n        self.conv0.add_module(\'conv\', nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, padding=0, stride=2,\n                                                bias=False))\n        self.conv0.add_module(\'bn\', nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True))\n\n        self.cell_stem_0 = CellStem0()\n        self.cell_stem_1 = CellStem1()\n\n        self.cell_0 = FirstCell(in_channels_left=168, out_channels_left=84,\n                                in_channels_right=336, out_channels_right=168)\n        self.cell_1 = NormalCell(in_channels_left=336, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_2 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_3 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_4 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_5 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n\n        self.reduction_cell_0 = ReductionCell0(in_channels_left=1008, out_channels_left=336,\n                                               in_channels_right=1008, out_channels_right=336)\n\n        self.cell_6 = FirstCell(in_channels_left=1008, out_channels_left=168,\n                                in_channels_right=1344, out_channels_right=336)\n        self.cell_7 = NormalCell(in_channels_left=1344, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_8 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_9 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_10 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n        self.cell_11 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n\n        self.reduction_cell_1 = ReductionCell1(in_channels_left=2016, out_channels_left=672,\n                                               in_channels_right=2016, out_channels_right=672)\n\n        self.cell_12 = FirstCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2688, out_channels_right=672)\n        self.cell_13 = NormalCell(in_channels_left=2688, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_14 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_15 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_16 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_17 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout()\n        self.last_linear = nn.Linear(4032, self.num_classes)\n\n    def features(self, x):\n        x_conv0 = self.conv0(x)\n        x_stem_0 = self.cell_stem_0(x_conv0)\n        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n\n        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n        x_cell_4 = self.cell_4(x_cell_3, x_cell_2)\n        x_cell_5 = self.cell_5(x_cell_4, x_cell_3)\n\n        x_reduction_cell_0 = self.reduction_cell_0(x_cell_5, x_cell_4)\n\n        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_4)\n        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n        x_cell_10 = self.cell_10(x_cell_9, x_cell_8)\n        x_cell_11 = self.cell_11(x_cell_10, x_cell_9)\n\n        x_reduction_cell_1 = self.reduction_cell_1(x_cell_11, x_cell_10)\n\n        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_10)\n        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n        x_cell_16 = self.cell_16(x_cell_15, x_cell_14)\n        x_cell_17 = self.cell_17(x_cell_16, x_cell_15)\n        return self.relu(x_cell_17)\n\n    def classifier(self, x):\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        return F.log_softmax(self.linear(x))\n\n    def forward(self, x):\n        x = self.features(x)\n        if self.use_classifer: x = self.classifier(x)\n        return x\n\n\ndef nasnetalarge(num_classes=1000, pretrained=\'imagenet\'):\n    r""""""NASNetALarge model architecture from the\n    `""NASNet"" <https://arxiv.org/abs/1707.07012>`_ paper.\n    """"""\n    if pretrained:\n        settings = pretrained_settings[\'nasnetalarge\'][pretrained]\n        assert num_classes == settings[\'num_classes\'], \\\n            ""num_classes should be {}, but is {}"".format(settings[\'num_classes\'], num_classes)\n\n        # both \'imagenet\'&\'imagenet+background\' are loaded from same parameters\n        model = NASNetALarge(num_classes=1001)\n        model.load_state_dict(model_zoo.load_url(settings[\'url\']))\n\n        if pretrained == \'imagenet\':\n            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n            model.last_linear = new_last_linear\n\n        model.input_space = settings[\'input_space\']\n        model.input_size = settings[\'input_size\']\n        model.input_range = settings[\'input_range\']\n\n        model.mean = settings[\'mean\']\n        model.std = settings[\'std\']\n    else:\n        model = NASNetALarge(num_classes=num_classes)\n    return model\n'"
fastai/fastai/models/resnet.py,4,"b""import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n__all__ = ['vgg_resnet50']\n\nmodel_urls = {\n    'vgg_resnet50': 'https://download.pytorch.org/models/vggresnet.pth',\n}\n\n\ndef conv(ni, nf, ks=3, stride=1):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, stride=stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out = residual + out\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out = residual + out\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [conv(3, 64, ks=7, stride=2)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv(self.inplanes, planes*block.expansion, ks=1, stride=stride),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 (): return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50(): return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck, [3, 4, 6, 3], k=1.125)\ndef vgg_resnet34(): return ResNet(BasicBlock, [3, 4, 6, 3], vgg_head=True)\ndef vgg_resnet50(pretrained=False):\n    model = ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n    if pretrained: model.load_state_dict(torch.load('/home/jhoward/.torch/models/vgg_resnet50.pth'))\n    return model\n\n"""
fastai/fastai/models/resnext_101_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/fastai/models/resnext_101_64x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_64x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/fastai/models/resnext_50_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_50_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AdaptiveAvgPool2d(1),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)\n'"
fastai/fastai/models/unet.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\n\ndef get_sfs_idxs(sfs, last=True):\n    """"""\n    Return the saved feature indexes that will be concatenated\n    Inputs:\n        sfs (list): saved features by hook function, in other words intermediate activations\n        last (bool): whether to concatenate only last different activation, or all from the encoder model\n    """"""\n    if last:\n        feature_szs = [sfs_feats.features.size()[-1] for sfs_feats in sfs]\n        sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n        if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n    else: sfs_idxs = list(range(len(sfs)))\n    return sfs_idxs\n\n\ndef conv_bn_relu(in_c, out_c, kernel_size, stride, padding):\n    return [\n        nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=stride, padding=padding),\n        nn.ReLU(),\n        nn.BatchNorm2d(out_c)]\n\n\nclass UnetBlock(nn.Module):\n    #TODO: ADAPT KERNEL SIZE, STRIDE AND PADDING SO THAT ANY SIZE DECAY WILL BE SUPPORTED\n    def __init__(self, up_in_c, x_in_c):\n        super().__init__()\n        self.upconv = nn.ConvTranspose2d(up_in_c, up_in_c // 2, 2, 2) # H, W -> 2H, 2W\n        self.conv1 = nn.Conv2d(x_in_c + up_in_c // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.conv2 = nn.Conv2d((x_in_c + up_in_c // 2) // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.bn = nn.BatchNorm2d((x_in_c + up_in_c // 2) // 2)\n\n    def forward(self, up_in, x_in):\n        up_out = self.upconv(up_in)\n        cat_x = torch.cat([up_out, x_in], dim=1)\n        x = F.relu(self.conv1(cat_x))\n        x = F.relu(self.conv2(x))\n        return self.bn(x)\n\nclass SaveFeatures():\n    """""" Extract pretrained activations""""""\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()\n\n\nclass DynamicUnet(nn.Module):\n    """"""\n    A dynamic implementation of Unet architecture, because calculating connections\n    and channels suck!. When an encoder is passed, this network will\n    automatically construct a decoder after the first single forward pass for any\n    given encoder architecture.\n\n    Decoder part is heavily based on the original Unet paper:\n    https://arxiv.org/abs/1505.04597.\n\n    Inputs:\n        encoder(nn.Module): Preferably a pretrained model, such as VGG or ResNet\n        last (bool): Whether to concat only last activation just before a size change\n        n_classes (int): Number of classes to output in final step of decoder\n\n    Important Note: If architecture directly reduces the dimension of an image as soon as the\n    first forward pass then output size will not be same as the input size, e.g. ResNet.\n    In order to resolve this problem architecture will add an additional extra conv transpose\n    layer. Also, currently Dynamic Unet expects size change to be H,W -> H/2, W/2. This is\n    not a problem for state-of-the-art architectures as they follow this pattern but it should\n    be changed for custom encoders that might have a different size decay.\n    """"""\n\n    def __init__(self, encoder, last=True, n_classes=3):\n        super().__init__()\n        self.encoder = encoder\n        self.n_children = len(list(encoder.children()))\n        self.sfs = [SaveFeatures(encoder[i]) for i in range(self.n_children)]\n        self.last = last\n        self.n_classes = n_classes\n\n    def forward(self, x):\n        # get imsize\n        imsize = x.size()[-2:]\n\n        # encoder output\n        x = F.relu(self.encoder(x))\n\n        # initialize sfs_idxs, sfs_szs, middle_in_c and middle_conv only once\n        if not hasattr(self, \'middle_conv\'):\n            self.sfs_szs = [sfs_feats.features.size() for sfs_feats in self.sfs]\n            self.sfs_idxs = get_sfs_idxs(self.sfs, self.last)\n            middle_in_c = self.sfs_szs[-1][1]\n            middle_conv = nn.Sequential(*conv_bn_relu(middle_in_c, middle_in_c * 2, 3, 1, 1),\n                                        *conv_bn_relu(middle_in_c * 2, middle_in_c, 3, 1, 1))\n            self.middle_conv = middle_conv\n\n        # middle conv\n        x = self.middle_conv(x)\n\n        # initialize upmodel, extra_block and 1x1 final conv\n        if not hasattr(self, \'upmodel\'):\n            x_copy = Variable(x.data, requires_grad=False)\n            upmodel = []\n            for idx in self.sfs_idxs[::-1]:\n                up_in_c, x_in_c = int(x_copy.size()[1]), int(self.sfs_szs[idx][1])\n                unet_block = UnetBlock(up_in_c, x_in_c)\n                upmodel.append(unet_block)\n                x_copy = unet_block(x_copy, self.sfs[idx].features)\n                self.upmodel = nn.Sequential(*upmodel)\n\n            if imsize != self.sfs_szs[0][-2:]:\n                extra_in_c = self.upmodel[-1].conv2.out_channels\n                self.extra_block = nn.ConvTranspose2d(extra_in_c, extra_in_c, 2, 2)\n\n            final_in_c = self.upmodel[-1].conv2.out_channels\n            self.final_conv = nn.Conv2d(final_in_c, self.n_classes, 1)\n\n        # run upsample\n        for block, idx in zip(self.upmodel, self.sfs_idxs[::-1]):\n            x = block(x, self.sfs[idx].features)\n        if hasattr(self, \'extra_block\'):\n            x = self.extra_block(x)\n\n        out = self.final_conv(x)\n        return out\n'"
fastai/fastai/models/wideresnet.py,3,"b'# https://github.com/uoguelph-mlrg/Cutout\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super().__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut: x   = self.relu1(self.bn1(x))\n        else:                   out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super().__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x): return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super().__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert((depth - 4) % 6 == 0)\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear): m.bias.data.zero_()\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.adaptive_avg_pool2d(out, 1)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n'"
fastai/fastai/models/wrn_50_2f.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef wrn_50_2f(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/tutorials/fastai/__init__.py,0,b''
fastai/tutorials/fastai/adaptive_softmax.py,1,"b'from .lm_rnn import *\n\nclass AdaptiveSoftmax(nn.Module):\n    def __init__(self, input_size, cutoff):\n        super().__init__()\n        self.input_size,self.cutoff = input_size,cutoff\n        self.output_size = cutoff[0] + len(cutoff) - 1\n        self.head = nn.Linear(input_size, self.output_size)\n        self.tail = nn.ModuleList()\n        for i in range(len(cutoff) - 1):\n            seq = nn.Sequential(nn.Linear(input_size, input_size // 4 ** i, False),\n                nn.Linear(input_size // 4 ** i, cutoff[i + 1] - cutoff[i], False))\n            self.tail.append(seq)\n\n    def reset(self):\n        nn.init.xavier_normal(self.head.weight)\n        for tail in self.tail:\n            nn.init.xavier_normal(tail[0].weight)\n            nn.init.xavier_normal(tail[1].weight)\n\n    def set_target(self, target):\n        self.id = []\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            if mask.sum() > 0:\n                self.id.append(Variable(mask.float().nonzero().squeeze(1)))\n            else: self.id.append(None)\n\n    def forward(self, input):\n        output = [self.head(input)]\n        for i in range(len(self.id)):\n            if self.id[i] is not None:\n                output.append(self.tail[i](input.index_select(0, self.id[i])))\n            else: output.append(None)\n        return output\n\n    def log_prob(self, input):\n        lsm = nn.LogSoftmax().cuda()\n        head_out = self.head(input)\n        batch_size = head_out.size(0)\n        prob = torch.zeros(batch_size, self.cutoff[-1]).cuda()\n        lsm_head = lsm(head_out)\n        prob.narrow(1, 0, self.output_size).add_(lsm_head.narrow(1, 0, self.output_size).data)\n        for i in range(len(self.tail)):\n            pos = self.cutoff[i]\n            i_size = self.cutoff[i + 1] - pos\n            buffer = lsm_head.narrow(1, self.cutoff[0] + i, 1)\n            buffer = buffer.expand(batch_size, i_size)\n            lsm_tail = lsm(self.tail[i](input))\n            prob.narrow(1, pos, i_size).copy_(buffer.data).add_(lsm_tail.data)\n        return prob\n\n\nclass AdaptiveLoss(nn.Module):\n    def __init__(self, cutoff):\n        super().__init__()\n        self.cutoff = cutoff\n        self.criterions = nn.ModuleList([nn.CrossEntropyLoss(size_average=False) for i in self.cutoff])\n\n    def remap_target(self, target):\n        new_target = [target.clone()]\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            new_target[0][mask] = self.cutoff[0] + i\n            if mask.sum() > 0: new_target.append(target[mask].add(-self.cutoff[i]))\n            else: new_target.append(None)\n        return new_target\n\n    def forward(self, input, target):\n        batch_size = input[0].size(0)\n        target = self.remap_target(target.data)\n        output = 0.0\n        for i in range(len(input)):\n            if input[i] is not None:\n                assert(target[i].min() >= 0 and target[i].max() <= input[i].size(1))\n                criterion = self.criterions[i]\n                output += criterion(input[i], Variable(target[i]))\n        output /= batch_size\n        return output\n\n'"
fastai/tutorials/fastai/column_data.py,2,"b'from .imports import *\nfrom .torch_imports import *\nfrom .dataset import *\nfrom .learner import *\n\n\nclass PassthruDataset(Dataset):\n    def __init__(self,*args, is_reg=True, is_multi=False):\n        *xs,y=args\n        self.xs,self.y = xs,y\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n    def __getitem__(self, idx): return [o[idx] for o in self.xs] + [self.y[idx]]\n\n    @classmethod\n    def from_data_frame(cls, df, cols_x, col_y, is_reg=True, is_multi=False):\n        cols = [df[o] for o in cols_x+[col_y]]\n        return cls(*cols, is_reg=is_reg, is_multi=is_multi)\n\n\nclass ColumnarDataset(Dataset):\n    def __init__(self, cats, conts, y, is_reg, is_multi):\n        n = len(cats[0]) if cats else len(conts[0])\n        self.cats = np.stack(cats, 1).astype(np.int64) if cats else np.zeros((n,1))\n        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n        self.y = np.zeros((n,1)) if y is None else y\n        if is_reg:\n            self.y =  self.y[:,None]\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n\n    def __getitem__(self, idx):\n        return [self.cats[idx], self.conts[idx], self.y[idx]]\n\n    @classmethod\n    def from_data_frames(cls, df_cat, df_cont, y=None, is_reg=True, is_multi=False):\n        cat_cols = [c.values for n,c in df_cat.items()]\n        cont_cols = [c.values for n,c in df_cont.items()]\n        return cls(cat_cols, cont_cols, y, is_reg, is_multi)\n\n    @classmethod\n    def from_data_frame(cls, df, cat_flds, y=None, is_reg=True, is_multi=False):\n        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y, is_reg, is_multi)\n\n\nclass ColumnarModelData(ModelData):\n    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n            DataLoader(val_ds, bs*2, shuffle=False, num_workers=1), test_dl)\n\n    @classmethod\n    def from_arrays(cls, path, val_idxs, xs, y, is_reg=True, is_multi=False, bs=64, test_xs=None, shuffle=True):\n        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs), is_reg=is_reg, is_multi=is_multi) if test_xs is not None else None\n        return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n                   PassthruDataset(*(val_xs.T), val_y, is_reg=is_reg, is_multi=is_multi),\n                   bs=bs, shuffle=shuffle, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=None):\n        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, None, is_reg, is_multi) if test_df is not None else None\n        return cls(path, ColumnarDataset.from_data_frame(trn_df, cat_flds, trn_y, is_reg, is_multi),\n                    ColumnarDataset.from_data_frame(val_df, cat_flds, val_y, is_reg, is_multi), bs, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, is_reg=True, is_multi=False, test_df=None):\n        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=test_df)\n\n    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                    y_range=None, use_bn=False, **kwargs):\n        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn, self.is_reg, self.is_multi)\n        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n\n\ndef emb_init(x):\n    x = x.weight.data\n    sc = 2/(x.size(1)+1)\n    x.uniform_(-sc,sc)\n\n\nclass MixedInputModel(nn.Module):\n    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                 y_range=None, use_bn=False, is_reg=True, is_multi=False):\n        super().__init__()\n        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n        for emb in self.embs: emb_init(emb)\n        n_emb = sum(e.embedding_dim for e in self.embs)\n        self.n_emb, self.n_cont=n_emb, n_cont\n        \n        szs = [n_emb+n_cont] + szs\n        self.lins = nn.ModuleList([\n            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n        self.bns = nn.ModuleList([\n            nn.BatchNorm1d(sz) for sz in szs[1:]])\n        for o in self.lins: kaiming_normal(o.weight.data)\n        self.outp = nn.Linear(szs[-1], out_sz)\n        kaiming_normal(self.outp.weight.data)\n\n        self.emb_drop = nn.Dropout(emb_drop)\n        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n        self.bn = nn.BatchNorm1d(n_cont)\n        self.use_bn,self.y_range = use_bn,y_range\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def forward(self, x_cat, x_cont):\n        if self.n_emb != 0:\n            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n            x = torch.cat(x, 1)\n            x = self.emb_drop(x)\n        if self.n_cont != 0:\n            x2 = self.bn(x_cont)\n            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n        for l,d,b in zip(self.lins, self.drops, self.bns):\n            x = F.relu(l(x))\n            if self.use_bn: x = b(x)\n            x = d(x)\n        x = self.outp(x)\n        if not self.is_reg:\n            if self.is_multi:\n                x = F.sigmoid(x)\n            else:\n                x = F.log_softmax(x)\n        elif self.y_range:\n            x = F.sigmoid(x)\n            x = x*(self.y_range[1] - self.y_range[0])\n            x = x+self.y_range[0]\n        return x\n\n\nclass StructuredLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    def summary(self): return model_summary(self.model, [(self.data.trn_ds.cats.shape[1], ), (self.data.trn_ds.conts.shape[1], )])\n\n\nclass StructuredModel(BasicModel):\n    def get_layer_groups(self):\n        m=self.model\n        return [m.embs, children(m.lins)+children(m.bns), m.outp]\n\n\nclass CollabFilterDataset(Dataset):\n    def __init__(self, path, user_col, item_col, ratings):\n        self.ratings,self.path = ratings.values.astype(np.float32),path\n        self.n = len(ratings)\n        (self.users,self.user2idx,self.user_col,self.n_users) = self.proc_col(user_col)\n        (self.items,self.item2idx,self.item_col,self.n_items) = self.proc_col(item_col)\n        self.min_score,self.max_score = min(ratings),max(ratings)\n        self.cols = [self.user_col,self.item_col,self.ratings]\n\n    @classmethod\n    def from_data_frame(cls, path, df, user_name, item_name, rating_name):\n        return cls(path, df[user_name], df[item_name], df[rating_name])\n\n    @classmethod\n    def from_csv(cls, path, csv, user_name, item_name, rating_name):\n        df = pd.read_csv(os.path.join(path,csv))\n        return cls.from_data_frame(path, df, user_name, item_name, rating_name)\n\n    def proc_col(self,col):\n        uniq = col.unique()\n        name2idx = {o:i for i,o in enumerate(uniq)}\n        return (uniq, name2idx, np.array([name2idx[x] for x in col]), len(uniq))\n\n    def __len__(self): return self.n\n    def __getitem__(self, idx): return [o[idx] for o in self.cols]\n\n    def get_data(self, val_idxs, bs):\n        val, trn = zip(*split_by_idx(val_idxs, *self.cols))\n        return ColumnarModelData(self.path, PassthruDataset(*trn), PassthruDataset(*val), bs)\n\n    def get_model(self, n_factors):\n        model = EmbeddingDotBias(n_factors, self.n_users, self.n_items, self.min_score, self.max_score)\n        return CollabFilterModel(to_gpu(model))\n\n    def get_learner(self, n_factors, val_idxs, bs, **kwargs):\n        return CollabFilterLearner(self.get_data(val_idxs, bs), self.get_model(n_factors), **kwargs)\n\n\ndef get_emb(ni,nf):\n    e = nn.Embedding(ni, nf)\n    e.weight.data.uniform_(-0.05,0.05)\n    return e\n\n\nclass EmbeddingDotBias(nn.Module):\n    def __init__(self, n_factors, n_users, n_items, min_score, max_score):\n        super().__init__()\n        self.min_score,self.max_score = min_score,max_score\n        (self.u, self.i, self.ub, self.ib) = [get_emb(*o) for o in [\n            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n        ]]\n\n    def forward(self, users, items):\n        um = self.u(users)* self.i(items)\n        res = um.sum(1) + self.ub(users).squeeze() + self.ib(items).squeeze()\n        return F.sigmoid(res) * (self.max_score-self.min_score) + self.min_score\n\n\nclass CollabFilterLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n\nclass CollabFilterModel(BasicModel):\n    def get_layer_groups(self): return self.model\n\n'"
fastai/tutorials/fastai/conv_learner.py,0,"b'from .core import *\nfrom .layers import *\nfrom .learner import *\nfrom .initializers import *\n\nmodel_meta = {\n    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n    vgg16:[0,22], vgg19:[0,22],\n    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n}\nmodel_features = {inception_4: 3072, dn121: 2048, dn161: 4416,} # nasnetalarge: 4032*2}\n\nclass ConvnetBuilder():\n    """"""Class representing a convolutional network.\n\n    Arguments:\n        f: a model creation function (e.g. resnet34, vgg16, etc)\n        c (int): size of the last layer\n        is_multi (bool): is multilabel classification?\n            (def here http://scikit-learn.org/stable/modules/multiclass.html)\n        is_reg (bool): is a regression?\n        ps (float or array of float): dropout parameters\n        xtra_fc (list of ints): list of hidden layers with # hidden neurons\n        xtra_cut (int): # layers earlier than default to cut the model, default is 0\n        custom_head : add custom model classes that are inherited from nn.modules at the end of the model\n                      that is mentioned on Argument \'f\' \n    """"""\n\n    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, pretrained=True):\n        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n        if xtra_fc is None: xtra_fc = [512]\n        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n        self.ps,self.xtra_fc = ps,xtra_fc\n\n        if f in model_meta: cut,self.lr_cut = model_meta[f]\n        else: cut,self.lr_cut = 0,0\n        cut-=xtra_cut\n        layers = cut_model(f(pretrained), cut)\n        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n        self.top_model = nn.Sequential(*layers)\n\n        n_fc = len(self.xtra_fc)+1\n        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n\n        if custom_head: fc_layers = [custom_head]\n        else: fc_layers = self.get_fc_layers()\n        self.n_fc = len(fc_layers)\n        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n\n    @property\n    def name(self): return f\'{self.f.__name__}_{self.xtra_cut}\'\n\n    def create_fc_layer(self, ni, nf, p, actn=None):\n        res=[nn.BatchNorm1d(num_features=ni)]\n        if p: res.append(nn.Dropout(p=p))\n        res.append(nn.Linear(in_features=ni, out_features=nf))\n        if actn: res.append(actn)\n        return res\n\n    def get_fc_layers(self):\n        res=[]\n        ni=self.nf\n        for i,nf in enumerate(self.xtra_fc):\n            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n            ni=nf\n        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n        if self.is_reg: final_actn = None\n        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n        return res\n\n    def get_layer_groups(self, do_fc=False):\n        if do_fc:\n            return [self.fc_model]\n        idxs = [self.lr_cut]\n        c = children(self.top_model)\n        if len(c)==3: c = children(c[0])+c[1:]\n        lgs = list(split_by_idxs(c,idxs))\n        return lgs+[self.fc_model]\n\n\nclass ConvLearner(Learner):\n    """"""\n    Class used to train a chosen supported covnet model. Eg. ResNet-34, etc.\n    Arguments:\n        data: training data for model\n        models: model architectures to base learner\n        precompute: bool to reuse precomputed activations\n        **kwargs: parameters from Learner() class\n    """"""\n    def __init__(self, data, models, precompute=False, **kwargs):\n        self.precompute = False\n        super().__init__(data, models, **kwargs)\n        if hasattr(data, \'is_multi\') and not data.is_reg and self.metrics is None:\n            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n        if precompute: self.save_fc1()\n        self.freeze()\n        self.precompute = precompute\n\n    def _get_crit(self, data):\n        if not hasattr(data, \'is_multi\'): return super()._get_crit(data)\n\n        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    @classmethod\n    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                   pretrained=True, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n        return cls(data, models, precompute, **kwargs)\n\n    @classmethod\n    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n        convlearn=cls(data, models, precompute, **kwargs)\n        convlearn.lsuv_init()\n        return convlearn\n    \n    @property\n    def model(self): return self.models.fc_model if self.precompute else self.models.model\n\n    @property\n    def data(self): return self.fc_data if self.precompute else self.data_\n\n    def create_empty_bcolz(self, n, name):\n        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode=\'w\', rootdir=name)\n\n    def set_data(self, data, precompute=False):\n        super().set_data(data)\n        if precompute:\n            self.unfreeze()\n            self.save_fc1()\n            self.freeze()\n            self.precompute = True\n        else:\n            self.freeze()\n\n    def get_layer_groups(self):\n        return self.models.get_layer_groups(self.precompute)\n\n    def summary(self):\n        precompute = self.precompute\n        self.precompute = False\n        res = super().summary()\n        self.precompute = precompute\n        return res\n\n    def get_activations(self, force=False):\n        tmpl = f\'_{self.models.name}_{self.data.sz}.bc\'\n        # TODO: Somehow check that directory names haven\'t changed (e.g. added test set)\n        names = [os.path.join(self.tmp_path, p+tmpl) for p in (\'x_act\', \'x_act_val\', \'x_act_test\')]\n        if os.path.exists(names[0]) and not force:\n            self.activations = [bcolz.open(p) for p in names]\n        else:\n            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n\n    def save_fc1(self):\n        self.get_activations()\n        act, val_act, test_act = self.activations\n        m=self.models.top_model\n        if len(self.activations[0])!=len(self.data.trn_ds):\n            predict_to_bcolz(m, self.data.fix_dl, act)\n        if len(self.activations[1])!=len(self.data.val_ds):\n            predict_to_bcolz(m, self.data.val_dl, val_act)\n        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n\n        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n                test = test_act if self.data.test_dl else None, num_workers=8)\n\n    def freeze(self):\n        """""" Freeze all but the very last layer.\n\n        Make all layers untrainable (i.e. frozen) except for the last layer.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(-1)\n\n    def unfreeze(self):\n        """""" Unfreeze all layers.\n\n        Make all layers trainable by unfreezing. This will also set the `precompute` to `False` since we can\n        no longer pre-calculate the activation of frozen layers.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(0)\n        self.precompute = False\n'"
fastai/tutorials/fastai/core.py,11,"b'from .imports import *\nfrom .torch_imports import *\n\ndef sum_geom(a,r,n): return a*n if r==1 else math.ceil(a*(1-r**n)/(1-r))\n\ndef is_listy(x): return isinstance(x, (list,tuple))\ndef is_iter(x): return isinstance(x, collections.Iterable)\ndef map_over(x, f): return [f(o) for o in x] if is_listy(x) else f(x)\ndef map_none(x, f): return None if x is None else f(x)\n\nconv_dict = {np.dtype(\'int8\'): torch.LongTensor, np.dtype(\'int16\'): torch.LongTensor,\n    np.dtype(\'int32\'): torch.LongTensor, np.dtype(\'int64\'): torch.LongTensor,\n    np.dtype(\'float32\'): torch.FloatTensor, np.dtype(\'float64\'): torch.FloatTensor}\n\ndef A(*a):\n    """"""convert iterable object into numpy array""""""\n    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]\n\ndef T(a, half=False, cuda=True):\n    """"""\n    Convert numpy array into a pytorch tensor. \n    if Cuda is available and USE_GPU=ture, store resulting tensor in GPU.\n    """"""\n    if not torch.is_tensor(a):\n        a = np.array(np.ascontiguousarray(a))\n        if a.dtype in (np.int8, np.int16, np.int32, np.int64):\n            a = torch.LongTensor(a.astype(np.int64))\n        elif a.dtype in (np.float32, np.float64):\n            a = torch.cuda.HalfTensor(a) if half else torch.FloatTensor(a)\n        else: raise NotImplementedError(a.dtype)\n    if cuda: a = to_gpu(a, async=True)\n    return a\n\ndef create_variable(x, volatile, requires_grad=False):\n    if type (x) != Variable:\n        if IS_TORCH_04: x = Variable(T(x), requires_grad=requires_grad)\n        else:           x = Variable(T(x), requires_grad=requires_grad, volatile=volatile)\n    return x\n\ndef V_(x, requires_grad=False, volatile=False):\n    \'\'\'equivalent to create_variable, which creates a pytorch tensor\'\'\'\n    return create_variable(x, volatile=volatile, requires_grad=requires_grad)\ndef V(x, requires_grad=False, volatile=False):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, lambda o: V_(o, requires_grad, volatile))\n\ndef VV_(x): \n    \'\'\'creates a volatile tensor, which does not require gradients. \'\'\'\n    return create_variable(x, True)\n\ndef VV(x):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, VV_)\n\ndef to_np(v):\n    \'\'\'returns an np.array object given an input of np.array, list, tuple, torch variable or tensor.\'\'\'\n    if isinstance(v, (np.ndarray, np.generic)): return v\n    if isinstance(v, (list,tuple)): return [to_np(o) for o in v]\n    if isinstance(v, Variable): v=v.data\n    if isinstance(v, torch.cuda.HalfTensor): v=v.float()\n    return v.cpu().numpy()\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\nUSE_GPU = torch.cuda.is_available()\ndef to_gpu(x, *args, **kwargs):\n    \'\'\'puts pytorch variable to gpu, if cuda is avaialble and USE_GPU is set to true. \'\'\'\n    return x.cuda(*args, **kwargs) if USE_GPU else x\n\ndef noop(*args, **kwargs): return\n\ndef split_by_idxs(seq, idxs):\n    \'\'\'A generator that returns sequence pieces, seperated by indexes specified in idxs. \'\'\'\n    last = 0\n    for idx in idxs:\n        yield seq[last:idx]\n        last = idx\n    yield seq[last:]\n\ndef trainable_params_(m):\n    \'\'\'Returns a list of trainable parameters in the model m. (i.e., those that require gradients.)\'\'\'\n    return [p for p in m.parameters() if p.requires_grad]\n\ndef chain_params(p):\n    if is_listy(p):\n        return list(chain(*[trainable_params_(o) for o in p]))\n    return trainable_params_(p)\n\ndef set_trainable_attr(m,b):\n    m.trainable=b\n    for p in m.parameters(): p.requires_grad=b\n\ndef apply_leaf(m, f):\n    c = children(m)\n    if isinstance(m, nn.Module): f(m)\n    if len(c)>0:\n        for l in c: apply_leaf(l,f)\n\ndef set_trainable(l, b):\n    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n\ndef SGD_Momentum(momentum):\n    return lambda *args, **kwargs: optim.SGD(*args, momentum=momentum, **kwargs)\n\ndef one_hot(a,c): return np.eye(c)[a]\n\ndef partition(a, sz): \n    """"""splits iterables a in equal parts of size sz""""""\n    return [a[i:i+sz] for i in range(0, len(a), sz)]\n\ndef partition_by_cores(a):\n    return partition(a, len(a)//num_cpus() + 1)\n\ndef num_cpus():\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n\n\nclass BasicModel():\n    def __init__(self,model,name=\'unnamed\'): self.model,self.name = model,name\n    def get_layer_groups(self, do_fc=False): return children(self.model)\n\nclass SingleModel(BasicModel):\n    def get_layer_groups(self): return [self.model]\n\nclass SimpleNet(nn.Module):\n    def __init__(self, layers):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return F.log_softmax(l_x, dim=-1)\n\n\ndef save(fn, a): \n    """"""Utility function that savess model, function, etc as pickle""""""    \n    pickle.dump(a, open(fn,\'wb\'))\ndef load(fn): \n    """"""Utility function that loads model, function, etc as pickle""""""\n    return pickle.load(open(fn,\'rb\'))\ndef load2(fn):\n    """"""Utility funciton allowing model piclking across Python2 and Python3""""""\n    return pickle.load(open(fn,\'rb\'), encoding=\'iso-8859-1\')\n\ndef load_array(fname): \n    \'\'\'\n    Load array using bcolz, which is based on numpy, for fast array saving and loading operations. \n    https://github.com/Blosc/bcolz\n    \'\'\'\n    return bcolz.open(fname)[:]\n\n\ndef chunk_iter(iterable, chunk_size):\n    \'\'\'A generator that yields chunks of iterable, chunk_size at a time. \'\'\'\n    while True:\n        chunk = []\n        try:\n            for _ in range(chunk_size): chunk.append(next(iterable))\n            yield chunk\n        except StopIteration:\n            if chunk: yield chunk\n            break\n\ndef set_grad_enabled(mode): return torch.set_grad_enabled(mode) if IS_TORCH_04 else contextlib.suppress()\n\ndef no_grad_context(): return torch.no_grad() if IS_TORCH_04 else contextlib.suppress()\n'"
fastai/tutorials/fastai/dataloader.py,1,"b'import torch, queue\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler\nfrom .imports import *\nfrom .core import *\nimport collections,sys,traceback,threading\n\nstring_classes = (str, bytes)\n\n\ndef get_tensor(batch, pin, half=False):\n    if isinstance(batch, (np.ndarray, np.generic)):\n        batch = T(batch, half=half, cuda=False).contiguous()\n        if pin: batch = batch.pin_memory()\n        return to_gpu(batch)\n    elif isinstance(batch, string_classes):\n        return batch\n    elif isinstance(batch, collections.Mapping):\n        return {k: get_tensor(sample, pin, half) for k, sample in batch.items()}\n    elif isinstance(batch, collections.Sequence):\n        return [get_tensor(sample, pin, half) for sample in batch]\n    raise TypeError(f""batch must contain numbers, dicts or lists; found {type(batch)}"")\n\n\nclass DataLoader(object):\n    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, pad_idx=0,\n                 num_workers=None, pin_memory=False, drop_last=False, pre_pad=True, half=False,\n                 transpose=False, transpose_y=False):\n        self.dataset,self.batch_size,self.num_workers = dataset,batch_size,num_workers\n        self.pin_memory,self.drop_last,self.pre_pad = pin_memory,drop_last,pre_pad\n        self.transpose,self.transpose_y,self.pad_idx,self.half = transpose,transpose_y,pad_idx,half\n\n        if batch_sampler is not None:\n            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n                raise ValueError(\'batch_sampler is mutually exclusive with \'\n                                 \'batch_size, shuffle, sampler, and drop_last\')\n\n        if sampler is not None and shuffle:\n            raise ValueError(\'sampler is mutually exclusive with shuffle\')\n\n        if batch_sampler is None:\n            if sampler is None:\n                sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n\n        if num_workers is None:\n            self.num_workers = num_cpus()\n\n        self.sampler = sampler\n        self.batch_sampler = batch_sampler\n\n    def __len__(self): return len(self.batch_sampler)\n\n    def jag_stack(self, b):\n        if len(b[0].shape) not in (1,2): return np.stack(b)\n        ml = max(len(o) for o in b)\n        if min(len(o) for o in b)==ml: return np.stack(b)\n        res = np.zeros((len(b), ml), dtype=b[0].dtype) + self.pad_idx\n        for i,o in enumerate(b):\n            if self.pre_pad: res[i, -len(o):] = o\n            else:            res[i,  :len(o)] = o\n        return res\n\n    def np_collate(self, batch):\n        b = batch[0]\n        if isinstance(b, (np.ndarray, np.generic)): return self.jag_stack(batch)\n        elif isinstance(b, (int, float)): return np.array(batch)\n        elif isinstance(b, string_classes): return batch\n        elif isinstance(b, collections.Mapping):\n            return {key: self.np_collate([d[key] for d in batch]) for key in b}\n        elif isinstance(b, collections.Sequence):\n            return [self.np_collate(samples) for samples in zip(*batch)]\n        raise TypeError((""batch must contain numbers, dicts or lists; found {}"".format(type(b))))\n\n    def get_batch(self, indices):\n        res = self.np_collate([self.dataset[i] for i in indices])\n        if self.transpose:   res[0] = res[0].T\n        if self.transpose_y: res[1] = res[1].T\n        return res\n\n    def __iter__(self):\n        if self.num_workers==0:\n            for batch in map(self.get_batch, iter(self.batch_sampler)):\n                yield get_tensor(batch, self.pin_memory, self.half)\n        else:\n            with ThreadPoolExecutor(max_workers=self.num_workers) as e:\n                # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n                for c in chunk_iter(iter(self.batch_sampler), self.num_workers*10):\n                    for batch in e.map(self.get_batch, c):\n                        yield get_tensor(batch, self.pin_memory, self.half)\n\n'"
fastai/tutorials/fastai/dataset.py,1,"b'import csv\n\nfrom .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .layer_optimizer import *\nfrom .dataloader import DataLoader\n\ndef get_cv_idxs(n, cv_idx=0, val_pct=0.2, seed=42):\n    """""" Get a list of index values for Validation set from a dataset\n    \n    Arguments:\n        n : int, Total number of elements in the data set.\n        cv_idx : int, starting index [idx_start = cv_idx*int(val_pct*n)] \n        val_pct : (int, float), validation set percentage \n        seed : seed value for RandomState\n        \n    Returns:\n        list of indexes \n    """"""\n    np.random.seed(seed)\n    n_val = int(val_pct*n)\n    idx_start = cv_idx*n_val\n    idxs = np.random.permutation(n)\n    return idxs[idx_start:idx_start+n_val]\n\ndef resize_img(fname, targ, path, new_path):\n    """"""\n    Enlarge or shrink a single image to scale, such that the smaller of the height or width dimension is equal to targ.\n    """"""\n    dest = os.path.join(path,new_path,str(targ),fname)\n    if os.path.exists(dest): return\n    im = Image.open(os.path.join(path, fname)).convert(\'RGB\')\n    r,c = im.size\n    ratio = targ/min(r,c)\n    sz = (scale_to(r, ratio, targ), scale_to(c, ratio, targ))\n    os.makedirs(os.path.split(dest)[0], exist_ok=True)\n    im.resize(sz, Image.LINEAR).save(dest)\n\ndef resize_imgs(fnames, targ, path, new_path):\n    """"""\n    Enlarge or shrink a set of images in the same directory to scale, such that the smaller of the height or width dimension is equal to targ.\n    Note: \n    -- This function is multithreaded for efficiency. \n    -- When destination file or folder already exist, function exists without raising an error. \n    """"""\n    if not os.path.exists(os.path.join(path,new_path,str(targ),fnames[0])):\n        with ThreadPoolExecutor(8) as e:\n            ims = e.map(lambda x: resize_img(x, targ, path, new_path), fnames)\n            for x in tqdm(ims, total=len(fnames), leave=False): pass\n    return os.path.join(path,new_path,str(targ))\n\ndef read_dir(path, folder):\n    """""" Returns a list of relative file paths to `path` for all files within `folder` """"""\n    full_path = os.path.join(path, folder)\n    fnames = glob(f""{full_path}/*.*"")\n    if any(fnames):\n        return [os.path.relpath(f,path) for f in fnames]\n    else:\n        raise FileNotFoundError(""{} folder doesn\'t exist or is empty"".format(folder))\n\ndef read_dirs(path, folder):\n    \'\'\'\n    Fetches name of all files in path in long form, and labels associated by extrapolation of directory names. \n    \'\'\'\n    lbls, fnames, all_lbls = [], [], []\n    full_path = os.path.join(path, folder)\n    for lbl in sorted(os.listdir(full_path)):\n        if lbl not in (\'.ipynb_checkpoints\',\'.DS_Store\'):\n            all_lbls.append(lbl)\n            for fname in os.listdir(os.path.join(full_path, lbl)):\n                fnames.append(os.path.join(folder, lbl, fname))\n                lbls.append(lbl)\n    return fnames, lbls, all_lbls\n\ndef n_hot(ids, c):\n    \'\'\'\n    one hot encoding by index. Returns array of length c, where all entries are 0, except for the indecies in ids\n    \'\'\'\n    res = np.zeros((c,), dtype=np.float32)\n    res[ids] = 1\n    return res\n\ndef folder_source(path, folder):\n    """"""\n    Returns the filenames and labels for a folder within a path\n    \n    Returns:\n    -------\n    fnames: a list of the filenames within `folder`\n    all_lbls: a list of all of the labels in `folder`, where the # of labels is determined by the # of directories within `folder`\n    lbl_arr: a numpy array of the label indices in `all_lbls`\n    """"""\n    fnames, lbls, all_lbls = read_dirs(path, folder)\n    lbl2idx = {lbl:idx for idx,lbl in enumerate(all_lbls)}\n    idxs = [lbl2idx[lbl] for lbl in lbls]\n    lbl_arr = np.array(idxs, dtype=int)\n    return fnames, lbl_arr, all_lbls\n\ndef parse_csv_labels(fn, skip_header=True, cat_separator = \' \'):\n    """"""Parse filenames and label sets from a CSV file.\n\n    This method expects that the csv file at path :fn: has two columns. If it\n    has a header, :skip_header: should be set to True. The labels in the\n    label set are expected to be space separated.\n\n    Arguments:\n        fn: Path to a CSV file.\n        skip_header: A boolean flag indicating whether to skip the header.\n\n    Returns:\n        a four-tuple of (\n            sorted image filenames,\n            a dictionary of filenames and corresponding labels,\n            a sorted set of unique labels,\n            a dictionary of labels to their corresponding index, which will\n            be one-hot encoded.\n        )\n    .\n    :param cat_separator: the separator for the categories column\n    """"""\n    df = pd.read_csv(fn, index_col=0, header=0 if skip_header else None, dtype=str)\n    fnames = df.index.values\n    df.iloc[:,0] = df.iloc[:,0].str.split(cat_separator)\n    return sorted(fnames), list(df.to_dict().values())[0]\n\ndef nhot_labels(label2idx, csv_labels, fnames, c):\n    \n    all_idx = {k: n_hot([label2idx[o] for o in v], c)\n               for k,v in csv_labels.items()}\n    return np.stack([all_idx[o] for o in fnames])\n\ndef csv_source(folder, csv_file, skip_header=True, suffix=\'\', continuous=False):\n    fnames,csv_labels = parse_csv_labels(csv_file, skip_header)\n    return dict_source(folder, fnames, csv_labels, suffix, continuous)\n\ndef dict_source(folder, fnames, csv_labels, suffix=\'\', continuous=False):\n    all_labels = sorted(list(set(p for o in csv_labels.values() for p in o)))\n    full_names = [os.path.join(folder,str(fn)+suffix) for fn in fnames]\n    if continuous:\n        label_arr = np.array([np.array(csv_labels[i]).astype(np.float32)\n                for i in fnames])\n    else:\n        label2idx = {v:k for k,v in enumerate(all_labels)}\n        label_arr = nhot_labels(label2idx, csv_labels, fnames, len(all_labels))\n        is_single = np.all(label_arr.sum(axis=1)==1)\n        if is_single: label_arr = np.argmax(label_arr, axis=1)\n    return full_names, label_arr, all_labels\n\nclass BaseDataset(Dataset):\n    """"""An abstract class representing a fastai dataset, it extends torch.utils.data.Dataset.""""""\n    def __init__(self, transform=None):\n        self.transform = transform\n        self.n = self.get_n()\n        self.c = self.get_c()\n        self.sz = self.get_sz()\n\n    def get1item(self, idx):\n        x,y = self.get_x(idx),self.get_y(idx)\n        return self.get(self.transform, x, y)\n\n    def __getitem__(self, idx):\n        if isinstance(idx,slice):\n            xs,ys = zip(*[self.get1item(i) for i in range(*idx.indices(self.n))])\n            return np.stack(xs),ys\n        return self.get1item(idx)\n\n    def __len__(self): return self.n\n\n    def get(self, tfm, x, y):\n        return (x,y) if tfm is None else tfm(x,y)\n\n    @abstractmethod\n    def get_n(self):\n        """"""Return number of elements in the dataset == len(self).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_c(self):\n        """"""Return number of classes in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_sz(self):\n        """"""Return maximum size of an image in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_x(self, i):\n        """"""Return i-th example (image, wav, etc).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_y(self, i):\n        """"""Return i-th label.""""""\n        raise NotImplementedError\n\n    @property\n    def is_multi(self):\n        """"""Returns true if this data set contains multiple labels per sample.""""""\n        return False\n\n    @property\n    def is_reg(self):\n        """"""True if the data set is used to train regression models.""""""\n        return False\n\ndef open_image(fn):\n    """""" Opens an image using OpenCV given the file path.\n\n    Arguments:\n        fn: the file path of the image\n\n    Returns:\n        The image in RGB format as numpy array of floats normalized to range between 0.0 - 1.0\n    """"""\n    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n    if not os.path.exists(fn):\n        raise OSError(\'No such file or directory: {}\'.format(fn))\n    elif os.path.isdir(fn):\n        raise OSError(\'Is a directory: {}\'.format(fn))\n    else:\n        #res = np.array(Image.open(fn), dtype=np.float32)/255\n        #if len(res.shape)==2: res = np.repeat(res[...,None],3,2)\n        #return res\n        try:\n            im = cv2.imread(str(fn), flags).astype(np.float32)/255\n            if im is None: raise OSError(f\'File not recognized by opencv: {fn}\')\n            return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        except Exception as e:\n            raise OSError(\'Error handling image at: {}\'.format(fn)) from e\n\nclass FilesDataset(BaseDataset):\n    def __init__(self, fnames, transform, path):\n        self.path,self.fnames = path,fnames\n        super().__init__(transform)\n    def get_sz(self): return self.transform.sz\n    def get_x(self, i): return open_image(os.path.join(self.path, self.fnames[i]))\n    def get_n(self): return len(self.fnames)\n\n    def resize_imgs(self, targ, new_path):\n        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n        return self.__class__(self.fnames, self.y, self.transform, dest)\n\n    def denorm(self,arr):\n        """"""Reverse the normalization done to a batch of images.\n\n        Arguments:\n            arr: of shape/size (N,3,sz,sz)\n        """"""\n        if type(arr) is not np.ndarray: arr = to_np(arr)\n        if len(arr.shape)==3: arr = arr[None]\n        return self.transform.denorm(np.rollaxis(arr,1,4))\n\n\nclass FilesArrayDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    def get_y(self, i): return self.y[i]\n    def get_c(self):\n        return self.y.shape[1] if len(self.y.shape)>1 else 0\n\nclass FilesIndexArrayDataset(FilesArrayDataset):\n    def get_c(self): return int(self.y.max())+1\n\n\nclass FilesNhotArrayDataset(FilesArrayDataset):\n    @property\n    def is_multi(self): return True\n\n\nclass FilesIndexArrayRegressionDataset(FilesArrayDataset):\n    def is_reg(self): return True\n\nclass ArraysDataset(BaseDataset):\n    def __init__(self, x, y, transform):\n        self.x,self.y=x,y\n        assert(len(x)==len(y))\n        super().__init__(transform)\n    def get_x(self, i): return self.x[i]\n    def get_y(self, i): return self.y[i]\n    def get_n(self): return len(self.y)\n    def get_sz(self): return self.x.shape[1]\n\n\nclass ArraysIndexDataset(ArraysDataset):\n    def get_c(self): return int(self.y.max())+1\n    def get_y(self, i): return self.y[i]\n\n\nclass ArraysNhotDataset(ArraysDataset):\n    def get_c(self): return self.y.shape[1]\n    @property\n    def is_multi(self): return True\n\n\nclass ModelData():\n    def __init__(self, path, trn_dl, val_dl, test_dl=None):\n        self.path,self.trn_dl,self.val_dl,self.test_dl = path,trn_dl,val_dl,test_dl\n\n    @classmethod\n    def from_dls(cls, path,trn_dl,val_dl,test_dl=None):\n        #trn_dl,val_dl = DataLoader(trn_dl),DataLoader(val_dl)\n        #if test_dl: test_dl = DataLoader(test_dl)\n        return cls(path, trn_dl, val_dl, test_dl)\n\n    @property\n    def is_reg(self): return self.trn_ds.is_reg\n    @property\n    def is_multi(self): return self.trn_ds.is_multi\n    @property\n    def trn_ds(self): return self.trn_dl.dataset\n    @property\n    def val_ds(self): return self.val_dl.dataset\n    @property\n    def test_ds(self): return self.test_dl.dataset\n    @property\n    def trn_y(self): return self.trn_ds.y\n    @property\n    def val_y(self): return self.val_ds.y\n\n\nclass ImageData(ModelData):\n    def __init__(self, path, datasets, bs, num_workers, classes):\n        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n            self.get_dl(ds,shuf) for ds,shuf in [\n                (trn_ds,True),(val_ds,False),(fix_ds,False),(aug_ds,False),\n                (test_ds,False),(test_aug_ds,False)\n            ]\n        ]\n\n    def get_dl(self, ds, shuffle):\n        if ds is None: return None\n        return DataLoader(ds, batch_size=self.bs, shuffle=shuffle,\n            num_workers=self.num_workers, pin_memory=False)\n\n    @property\n    def sz(self): return self.trn_ds.sz\n    @property\n    def c(self): return self.trn_ds.c\n\n    def resized(self, dl, targ, new_path):\n        return dl.dataset.resize_imgs(targ,new_path) if dl else None\n\n    def resize(self, targ_sz, new_path=\'tmp\'):\n        new_ds = []\n        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n        else: dls += [None,None]\n        t = tqdm_notebook(dls)\n        for dl in t: new_ds.append(self.resized(dl, targ_sz, new_path))\n        t.close()\n        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)\n\n    @staticmethod\n    def get_ds(fn, trn, val, tfms, test=None, **kwargs):\n        res = [\n            fn(trn[0], trn[1], tfms[0], **kwargs), # train\n            fn(val[0], val[1], tfms[1], **kwargs), # val\n            fn(trn[0], trn[1], tfms[1], **kwargs), # fix\n            fn(val[0], val[1], tfms[0], **kwargs)  # aug\n        ]\n        if test is not None:\n            if isinstance(test, tuple):\n                test_lbls = test[1]\n                test = test[0]\n            else:\n                test_lbls = np.zeros((len(test),1))\n            res += [\n                fn(test, test_lbls, tfms[1], **kwargs), # test\n                fn(test, test_lbls, tfms[0], **kwargs)  # test_aug\n            ]\n        else: res += [None,None]\n        return res\n\n\nclass ImageClassifierData(ImageData):\n    @classmethod\n    def from_arrays(cls, path, trn, val, bs=64, tfms=(None,None), classes=None, num_workers=4, test=None):\n        """""" Read in images and their labels given as numpy arrays\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            trn: a tuple of training data matrix and target label/classification array (e.g. `trn=(x,y)` where `x` has the\n                shape of `(5000, 784)` and `y` has the shape of `(5000,)`)\n            val: a tuple of validation data matrix and target label/classification array.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            classes: a list of all labels/classifications\n            num_workers: a number of workers\n            test: a matrix of test data (the shape should match `trn[0]`)\n\n        Returns:\n            ImageClassifierData\n        """"""\n        datasets = cls.get_ds(ArraysIndexDataset, trn, val, tfms, test=test)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\n    @classmethod\n    def from_paths(cls, path, bs=64, tfms=(None,None), trn_name=\'train\', val_name=\'valid\', test_name=None, test_with_labels=False, num_workers=8):\n        """""" Read in images and their labels given as sub-folder names\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            trn_name: a name of the folder that contains training images.\n            val_name:  a name of the folder that contains validation images.\n            test_name:  a name of the folder that contains test images.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not(tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        trn,val = [folder_source(path, o) for o in (trn_name, val_name)]\n        if test_name:\n            test = folder_source(path, test_name) if test_with_labels else read_dir(path, test_name)\n        else: test = None\n        datasets = cls.get_ds(FilesIndexArrayDataset, trn, val, tfms, path=path, test=test)\n        return cls(path, datasets, bs, num_workers, classes=trn[2])\n\n    @classmethod\n    def from_csv(cls, path, folder, csv_fname, bs=64, tfms=(None,None),\n               val_idxs=None, suffix=\'\', test_name=None, continuous=False, skip_header=True, num_workers=8):\n        """""" Read in images and their labels given as a CSV file.\n\n        This method should be used when training image labels are given in an CSV file as opposed to\n        sub-directories with label names.\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            folder: a name of the folder in which training images are contained.\n            csv_fname: a name of the CSV file which contains target labels.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            val_idxs: index of images to be used for validation. e.g. output of `get_cv_idxs`.\n                If None, default arguments to get_cv_idxs are used.\n            suffix: suffix to add to image names in CSV file (sometimes CSV only contains the file name without file\n                    extension e.g. \'.jpg\' - in which case, you can set suffix as \'.jpg\')\n            test_name: a name of the folder which contains test images.\n            continuous: TODO\n            skip_header: skip the first row of the CSV file.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not (tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        assert not (os.path.isabs(folder)), ""folder needs to be a relative path""\n        fnames,y,classes = csv_source(folder, csv_fname, skip_header, suffix, continuous=continuous)\n        return cls.from_names_and_array(path, fnames, y, classes, val_idxs, test_name,\n                num_workers=num_workers, suffix=suffix, tfms=tfms, bs=bs, continuous=continuous)\n\n    @classmethod\n    def from_names_and_array(cls, path, fnames,y,classes, val_idxs=None, test_name=None,\n            num_workers=8, suffix=\'\', tfms=(None,None), bs=64, continuous=False):\n        val_idxs = get_cv_idxs(len(fnames)) if val_idxs is None else val_idxs\n        ((val_fnames,trn_fnames),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), y)\n\n        test_fnames = read_dir(path, test_name) if test_name else None\n        if continuous: f = FilesIndexArrayRegressionDataset\n        else:\n            f = FilesIndexArrayDataset if len(trn_y.shape)==1 else FilesNhotArrayDataset\n        datasets = cls.get_ds(f, (trn_fnames,trn_y), (val_fnames,val_y), tfms,\n                               path=path, test=test_fnames)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\ndef split_by_idx(idxs, *a):\n    """"""\n    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n    This can be used to split multiple arrays containing training data to validation and training set.\n\n    :param idxs [int]: list of indexes selected\n    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n    :return: list of tuples, each containing a split of corresponding array from *a.\n            First element of each tuple is an array composed from elements selected by idxs,\n            second element is an array of remaining elements.\n    """"""\n    mask = np.zeros(len(a[0]),dtype=bool)\n    mask[np.array(idxs)] = True\n    return [(o[mask],o[~mask]) for o in a]\n\n'"
fastai/tutorials/fastai/executors.py,0,"b'import collections\nimport itertools\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\nclass LazyThreadPoolExecutor(ThreadPoolExecutor):\n    def map(self, fn, *iterables, timeout=None, chunksize=1, prefetch=None):\n        """"""\n        Collects iterables lazily, rather than immediately.\n        Docstring same as parent: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor\n        Implmentation taken from this PR: https://github.com/python/cpython/pull/707\n        """"""\n        if timeout is not None: end_time = timeout + time.time()\n        if prefetch is None: prefetch = self._max_workers\n        if prefetch < 0: raise ValueError(""prefetch count may not be negative"")\n        argsiter = zip(*iterables)\n        fs = collections.deque(self.submit(fn, *args) for args in itertools.islice(argsiter, self._max_workers+prefetch))\n        # Yield must be hidden in closure so that the futures are submitted before the first iterator value is required.\n        def result_iterator():\n            nonlocal argsiter\n            try:\n                while fs:\n                    res = fs[0].result() if timeout is None else fs[0].result(end_time-time.time())\n                    # Got a result, future needn\'t be cancelled\n                    del fs[0]\n                    # Dispatch next task before yielding to keep pipeline full\n                    if argsiter:\n                        try:\n                            args = next(argsiter)\n                        except StopIteration:\n                            argsiter = None\n                        else:\n                            fs.append(self.submit(fn, *args))\n                    yield res\n            finally:\n                for future in fs: future.cancel()\n        return result_iterator()'"
fastai/tutorials/fastai/fp16.py,2,"b'import torch\nimport torch.nn as nn\n\n\nclass FP16(nn.Module):\n    def __init__(self, module): \n        super(FP16, self).__init__()\n        self.module = batchnorm_to_fp32(module.half())\n        \n    def forward(self, input): \n        return self.module(input.half())\n    \n    def load_state_dict(self, *inputs, **kwargs):\n        self.module.load_state_dict(*inputs, **kwargs)\n\n    def state_dict(self, *inputs, **kwargs):\n        return self.module.state_dict(*inputs, **kwargs)\n\ndef batchnorm_to_fp32(module):\n    \'\'\'\n    BatchNorm layers to have parameters in single precision.\n    Find all layers and convert them back to float. This can\'t\n    be done with built in .apply as that function will apply\n    fn to all modules, parameters, and buffers. Thus we wouldn\'t\n    be able to guard the float conversion based on the module type.\n    \'\'\'\n    if isinstance(module, nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        batchnorm_to_fp32(child)\n    return module\n\ndef copy_model_to_fp32(m, optim):\n    """"""  Creates a fp32 copy of model parameters and sets optimizer parameters\n    """"""\n    fp32_params = [m_param.clone().type(torch.cuda.FloatTensor).detach() for m_param in m.parameters()]\n    optim_groups = [group[\'params\'] for group in optim.param_groups]\n    iter_fp32_params = iter(fp32_params)\n    for group_params in optim_groups:\n        for i in range(len(group_params)):\n            fp32_param = next(iter_fp32_params)\n            fp32_param.requires_grad = group_params[i].requires_grad\n            group_params[i] = fp32_param\n    return fp32_params\n\ndef copy_fp32_to_model(m, fp32_params):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        m_param.data.copy_(fp32_param.data)\n\ndef update_fp32_grads(fp32_params, m):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        if fp32_param.grad is None:\n            fp32_param.grad = nn.Parameter(fp32_param.data.new().resize_(*fp32_param.data.size()))\n        fp32_param.grad.data.copy_(m_param.grad.data)\n\n'"
fastai/tutorials/fastai/imports.py,0,"b""from IPython.lib.deepreload import reload as dreload\nimport PIL, os, numpy as np, math, collections, threading, json, bcolz, random, scipy, cv2\nimport pandas as pd, pickle, sys, itertools, string, sys, re, datetime, time, shutil, copy\nimport seaborn as sns, matplotlib\nimport IPython, graphviz, sklearn_pandas, sklearn, warnings, pdb\nimport contextlib\nfrom abc import abstractmethod\nfrom glob import glob, iglob\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom itertools import chain\nfrom functools import partial\nfrom collections import Iterable, Counter, OrderedDict\nfrom isoweek import Week\nfrom pandas_summary import DataFrameSummary\nfrom IPython.lib.display import FileLink\nfrom PIL import Image, ImageEnhance, ImageOps\nfrom sklearn import metrics, ensemble, preprocessing\nfrom operator import itemgetter, attrgetter\nfrom pathlib import Path\nfrom distutils.version import LooseVersion\n\nfrom matplotlib import pyplot as plt, rcParams, animation\nfrom ipywidgets import interact, interactive, fixed, widgets\nmatplotlib.rc('animation', html='html5')\nnp.set_printoptions(precision=5, linewidth=110, suppress=True)\n\nfrom ipykernel.kernelapp import IPKernelApp\ndef in_notebook(): return IPKernelApp.initialized()\n\ndef in_ipynb():\n    try:\n        cls = get_ipython().__class__.__name__\n        return cls == 'ZMQInteractiveShell'\n    except NameError:\n        return False\n\nimport tqdm as tq\nfrom tqdm import tqdm_notebook, tnrange\n\ndef clear_tqdm():\n    inst = getattr(tq.tqdm, '_instances', None)\n    if not inst: return\n    try:\n        for i in range(len(inst)): inst.pop().close()\n    except Exception:\n        pass\n\nif in_notebook():\n    def tqdm(*args, **kwargs):\n        clear_tqdm()\n        return tq.tqdm(*args, file=sys.stdout, **kwargs)\n    def trange(*args, **kwargs):\n        clear_tqdm()\n        return tq.trange(*args, file=sys.stdout, **kwargs)\nelse:\n    from tqdm import tqdm, trange\n    tnrange=trange\n    tqdm_notebook=tqdm\n\n"""
fastai/tutorials/fastai/initializers.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\ndef cond_init(m, init_fn):\n    if not isinstance(m, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):\n        if hasattr(m, 'weight'): init_fn(m.weight)\n        if hasattr(m, 'bias'): m.bias.data.fill_(0.)\n\ndef apply_init(m, init_fn):\n    m.apply(lambda x: cond_init(x, init_fn))\n\n\n"""
fastai/tutorials/fastai/io.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\nimport gzip\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\n\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None: self.total = tsize\n        self.update(b * bsize - self.n)\n\ndef get_data(url, filename):\n    if not os.path.exists(filename):\n\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n\n"""
fastai/tutorials/fastai/layer_optimizer.py,0,"b""from .imports import *\nfrom .torch_imports import *\nfrom .core import *\n\ndef opt_params(parm, lr, wd):\n    return {'params': chain_params(parm), 'lr':lr, 'weight_decay':wd}\n\nclass LayerOptimizer():\n    def __init__(self, opt_fn, layer_groups, lrs, wds=None):\n        if not isinstance(layer_groups, (list,tuple)): layer_groups=[layer_groups]\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(layer_groups)\n        if wds is None: wds=0.\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(layer_groups)\n        self.layer_groups,self.lrs,self.wds = layer_groups,lrs,wds\n        self.opt = opt_fn(self.opt_params())\n\n    def opt_params(self):\n        assert(len(self.layer_groups) == len(self.lrs))\n        assert(len(self.layer_groups) == len(self.wds))\n        params = list(zip(self.layer_groups,self.lrs,self.wds))\n        return [opt_params(*p) for p in params]\n\n    @property\n    def lr(self): return self.lrs[-1]\n\n    @property\n    def mom(self):\n        if 'betas' in self.opt.param_groups[0]:\n            return self.opt.param_groups[0]['betas'][0]\n        else:\n            return self.opt.param_groups[0]['momentum']\n\n    def set_lrs(self, lrs):\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(self.layer_groups)\n        set_lrs(self.opt, lrs)\n        self.lrs=lrs\n\n    def set_wds(self, wds):\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(self.layer_groups)\n        set_wds(self.opt, wds)\n        self.wds=wds\n    \n    def set_mom(self,momentum):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (momentum, pg['betas'][1])\n        else:\n            for pg in self.opt.param_groups: pg['momentum'] = momentum\n    \n    def set_beta(self,beta):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (pg['betas'][0],beta)\n        elif 'alpha' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['alpha'] = beta\n\n    def set_opt_fn(self, opt_fn):\n        if type(self.opt) != type(opt_fn(self.opt_params())):\n            self.opt = opt_fn(self.opt_params())\n\ndef zip_strict_(l, r):\n    assert(len(l) == len(r))\n    return zip(l, r)\n\ndef set_lrs(opt, lrs):\n    if not isinstance(lrs, Iterable): lrs=[lrs]\n    if len(lrs)==1: lrs=lrs*len(opt.param_groups)\n    for pg,lr in zip_strict_(opt.param_groups,lrs): pg['lr'] = lr\n\ndef set_wds(opt, wds):\n    if not isinstance(wds, Iterable): wds=[wds]\n    if len(wds)==1: wds=wds*len(opt.param_groups)\n    assert(len(opt.param_groups) == len(wds))\n    for pg,wd in zip_strict_(opt.param_groups,wds): pg['weight_decay'] = wd\n\n"""
fastai/tutorials/fastai/layers.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1,1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n\nclass Lambda(nn.Module):\n    def __init__(self, f): super().__init__(); self.f=f\n    def forward(self, x): return self.f(x)\n\nclass Flatten(nn.Module):\n    def __init__(self): super().__init__()\n    def forward(self, x): return x.view(x.size(0), -1)\n\n'"
fastai/tutorials/fastai/learner.py,1,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .model import *\nfrom .dataset import *\nfrom .sgdr import *\nfrom .layer_optimizer import *\nfrom .layers import *\nfrom .metrics import *\nfrom .losses import *\nfrom .swa import *\nfrom .fp16 import *\nfrom .lsuv_initializer import apply_lsuv_init\nimport time\n\n\nclass Learner():\n    def __init__(self, data, models, opt_fn=None, tmp_name=\'tmp\', models_name=\'models\', metrics=None, clip=None, crit=None):\n        """"""\n        Combines a ModelData object with a nn.Module object, such that you can train that\n        module.\n        data (ModelData): An instance of ModelData.\n        models(module): chosen neural architecture for solving a supported problem.\n        opt_fn(function): optimizer function, uses SGD with Momentum of .9 if none.\n        tmp_name(str): output name of the directory containing temporary files from training process\n        models_name(str): output name of the directory containing the trained model\n        metrics(list): array of functions for evaluating a desired metric. Eg. accuracy.\n        clip(float): gradient clip chosen to limit the change in the gradient to prevent exploding gradients Eg. .3\n        """"""\n        self.data_,self.models,self.metrics = data,models,metrics\n        self.sched=None\n        self.wd_sched = None\n        self.clip = None\n        self.opt_fn = opt_fn or SGD_Momentum(0.9)\n        self.tmp_path = tmp_name if os.path.isabs(tmp_name) else os.path.join(self.data.path, tmp_name)\n        self.models_path = models_name if os.path.isabs(models_name) else os.path.join(self.data.path, models_name)\n        os.makedirs(self.tmp_path, exist_ok=True)\n        os.makedirs(self.models_path, exist_ok=True)\n        self.crit = crit if crit else self._get_crit(data)\n        self.reg_fn = None\n        self.fp16 = False\n\n    @classmethod\n    def from_model_data(cls, m, data, **kwargs):\n        self = cls(data, BasicModel(to_gpu(m)), **kwargs)\n        self.unfreeze()\n        return self\n\n    def __getitem__(self,i): return self.children[i]\n\n    @property\n    def children(self): return children(self.model)\n\n    @property\n    def model(self): return self.models.model\n\n    @property\n    def data(self): return self.data_\n\n    def summary(self): return model_summary(self.model, [3,self.data.sz,self.data.sz])\n\n    def __repr__(self): return self.model.__repr__()\n    \n    def lsuv_init(self, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False):         \n        x = V(next(iter(self.data.trn_dl))[0])\n        self.models.model=apply_lsuv_init(self.model, x, needed_std=needed_std, std_tol=std_tol,\n                            max_attempts=max_attempts, do_orthonorm=do_orthonorm, \n                            cuda=USE_GPU and torch.cuda.is_available())\n\n    def set_bn_freeze(self, m, do_freeze):\n        if hasattr(m, \'running_mean\'): m.bn_freeze = do_freeze\n\n    def bn_freeze(self, do_freeze):\n        apply_leaf(self.model, lambda m: self.set_bn_freeze(m, do_freeze))\n\n    def freeze_to(self, n):\n        c=self.get_layer_groups()\n        for l in c:     set_trainable(l, False)\n        for l in c[n:]: set_trainable(l, True)\n\n    def freeze_all_but(self, n):\n        c=self.get_layer_groups()\n        for l in c: set_trainable(l, False)\n        set_trainable(c[n], True)\n\n    def unfreeze(self): self.freeze_to(0)\n\n    def get_model_path(self, name): return os.path.join(self.models_path,name)+\'.h5\'\n    \n    def save(self, name): \n        save_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): save_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n                       \n    def load(self, name): \n        load_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): load_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n\n    def set_data(self, data): self.data_ = data\n\n    def get_cycle_end(self, name):\n        if name is None: return None\n        return lambda sched, cycle: self.save_cycle(name, cycle)\n\n    def save_cycle(self, name, cycle): self.save(f\'{name}_cyc_{cycle}\')\n    def load_cycle(self, name, cycle): self.load(f\'{name}_cyc_{cycle}\')\n\n    def half(self):\n        if self.fp16: return\n        self.fp16 = True\n        if type(self.model) != FP16: self.models.model = FP16(self.model)\n    def float(self):\n        if not self.fp16: return\n        self.fp16 = False\n        if type(self.model) == FP16: self.models.model = self.model.module\n        self.model.float()\n\n    def fit_gen(self, model, data, layer_opt, n_cycle, cycle_len=None, cycle_mult=1, cycle_save_name=None, best_save_name=None,\n                use_clr=None, use_clr_beta=None, metrics=None, callbacks=None, use_wd_sched=False, norm_wds=False,             \n                wds_sched_mult=None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n\n        """"""Method does some preparation before finally delegating to the \'fit\' method for\n        fitting the model. Namely, if cycle_len is defined, it adds a \'Cosine Annealing\'\n        scheduler for varying the learning rate across iterations.\n\n        Method also computes the total number of epochs to fit based on provided \'cycle_len\',\n        \'cycle_mult\', and \'n_cycle\' parameters.\n\n        Args:\n            model (Learner):  Any neural architecture for solving a supported problem.\n                Eg. ResNet-34, RNN_Learner etc.\n\n            data (ModelData): An instance of ModelData.\n\n            layer_opt (LayerOptimizer): An instance of the LayerOptimizer class\n\n            n_cycle (int): number of cycles\n\n            cycle_len (int):  number of cycles before lr is reset to the initial value.\n                E.g if cycle_len = 3, then the lr is varied between a maximum\n                and minimum value over 3 epochs.\n\n            cycle_mult (int): additional parameter for influencing how the lr resets over\n                the cycles. For an intuitive explanation, please see\n                https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb\n\n            cycle_save_name (str): use to save the weights at end of each cycle\n\n            best_save_name (str): use to save weights of best model during training.\n\n            metrics (function): some function for evaluating a desired metric. Eg. accuracy.\n\n            callbacks (list(Callback)): callbacks to apply during the training.\n\n            use_wd_sched (bool, optional): set to True to enable weight regularization using\n                the technique mentioned in https://arxiv.org/abs/1711.05101. When this is True\n                alone (see below), the regularization is detached from gradient update and\n                applied directly to the weights.\n\n            norm_wds (bool, optional): when this is set to True along with use_wd_sched, the\n                regularization factor is normalized with each training cycle.\n\n            wds_sched_mult (function, optional): when this is provided along with use_wd_sched\n                as True, the value computed by this function is multiplied with the regularization\n                strength. This function is passed the WeightDecaySchedule object. And example\n                function that can be passed is:\n                            f = lambda x: np.array(x.layer_opt.lrs) / x.init_lrs\n                            \n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work.\n                \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n                \n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n\n        Returns:\n            None\n        """"""\n\n        if callbacks is None: callbacks=[]\n        if metrics is None: metrics=self.metrics\n\n        if use_wd_sched:\n            # This needs to come before CosAnneal() because we need to read the initial learning rate from\n            # layer_opt.lrs - but CosAnneal() alters the layer_opt.lrs value initially (divides by 100)\n            if np.sum(layer_opt.wds) == 0:\n                print(\'fit() warning: use_wd_sched is set to True, but weight decay(s) passed are 0. Use wds to \'\n                      \'pass weight decay values.\')\n            batch_per_epoch = len(data.trn_dl)\n            cl = cycle_len if cycle_len else 1\n            self.wd_sched = WeightDecaySchedule(layer_opt, batch_per_epoch, cl, cycle_mult, n_cycle,\n                                                norm_wds, wds_sched_mult)\n            callbacks += [self.wd_sched]\n\n        if use_clr is not None:\n            clr_div,cut_div = use_clr[:2]\n            moms = use_clr[2:] if len(use_clr) > 2 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=clr_div, cut_div=cut_div,\n                                    momentums=moms)\n        elif use_clr_beta is not None:\n            div,pct = use_clr_beta[:2]\n            moms = use_clr_beta[2:] if len(use_clr_beta) > 3 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR_beta(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=div,\n                                    pct=pct, momentums=moms)\n        elif cycle_len:\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            cycle_batches = len(data.trn_dl)*cycle_len\n            self.sched = CosAnneal(layer_opt, cycle_batches, on_cycle_end=cycle_end, cycle_mult=cycle_mult)\n        elif not self.sched: self.sched=LossRecorder(layer_opt)\n        callbacks+=[self.sched]\n\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(model)\n            callbacks+=[SWA(model, self.swa_model, swa_start)]\n\n        n_epoch = int(sum_geom(cycle_len if cycle_len else 1, cycle_mult, n_cycle))\n        return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def get_layer_groups(self): return self.models.get_layer_groups()\n\n    def get_layer_opt(self, lrs, wds):\n\n        """"""Method returns an instance of the LayerOptimizer class, which\n        allows for setting differential learning rates for different\n        parts of the model.\n\n        An example of how a model maybe differentiated into different parts\n        for application of differential learning rates and weight decays is\n        seen in ../.../courses/dl1/fastai/conv_learner.py, using the dict\n        \'model_meta\'. Currently, this seems supported only for convolutional\n        networks such as VGG-19, ResNet-XX etc.\n\n        Args:\n            lrs (float or list(float)): learning rate(s) for the model\n\n            wds (float or list(float)): weight decay parameter(s).\n\n        Returns:\n            An instance of a LayerOptimizer\n        """"""\n        return LayerOptimizer(self.opt_fn, self.get_layer_groups(), lrs, wds)\n\n    def fit(self, lrs, n_cycle, wds=None, **kwargs):\n\n        """"""Method gets an instance of LayerOptimizer and delegates to self.fit_gen(..)\n\n        Note that one can specify a list of learning rates which, when appropriately\n        defined, will be applied to different segments of an architecture. This seems\n        mostly relevant to ImageNet-trained models, where we want to alter the layers\n        closest to the images by much smaller amounts.\n\n        Likewise, a single or list of weight decay parameters can be specified, which\n        if appropriate for a model, will apply variable weight decay parameters to\n        different segments of the model.\n\n        Args:\n            lrs (float or list(float)): learning rate for the model\n\n            n_cycle (int): number of cycles (or iterations) to fit the model for\n\n            wds (float or list(float)): weight decay parameter(s).\n\n            kwargs: other arguments\n\n        Returns:\n            None\n        """"""\n        self.sched = None\n        layer_opt = self.get_layer_opt(lrs, wds)\n        return self.fit_gen(self.model, self.data, layer_opt, n_cycle, **kwargs)\n\n    def warm_up(self, lr, wds=None):\n        layer_opt = self.get_layer_opt(lr/4, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), lr, linear=True)\n        return self.fit_gen(self.model, self.data, layer_opt, 1)\n\n    def lr_find(self, start_lr=1e-5, end_lr=10, wds=None, linear=False, **kwargs):\n        """"""Helps you find an optimal learning rate for a model.\n\n         It uses the technique developed in the 2015 paper\n         `Cyclical Learning Rates for Training Neural Networks`, where\n         we simply keep increasing the learning rate from a very small value,\n         until the loss starts decreasing.\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            wds (iterable/float)\n\n        Examples:\n            As training moves us closer to the optimal weights for a model,\n            the optimal learning rate will be smaller. We can take advantage of\n            that knowledge and provide lr_find() with a starting learning rate\n            1000x smaller than the model\'s current learning rate as such:\n\n            >> learn.lr_find(lr/1000)\n\n            >> lrs = np.array([ 1e-4, 1e-3, 1e-2 ])\n            >> learn.lr_find(lrs / 1000)\n\n        Notes:\n            lr_find() may finish before going through each batch of examples if\n            the loss decreases enough.\n\n        .. _Cyclical Learning Rates for Training Neural Networks:\n            http://arxiv.org/abs/1506.01186\n\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), end_lr, linear=linear)\n        self.fit_gen(self.model, self.data, layer_opt, 1, **kwargs)\n        self.load(\'tmp\')\n\n    def lr_find2(self, start_lr=1e-5, end_lr=10, num_it = 100, wds=None, linear=False, stop_dv=True, **kwargs):\n        """"""A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n        At each step, it computes the validation loss and the metrics on the next\n        batch of the validation data, so it\'s slower than lr_find().\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            num_it : the number of iterations you want it to run\n            wds (iterable/float)\n            stop_dv : stops (or not) when the losses starts to explode.\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder2(layer_opt, num_it, end_lr, linear=linear, metrics=self.metrics, stop_dv=stop_dv)\n        self.fit_gen(self.model, self.data, layer_opt, num_it//len(self.data.trn_dl) + 1, all_val=True, **kwargs)\n        self.load(\'tmp\')\n\n    def predict(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict(m, dl)\n\n    def predict_with_targs(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict_with_targs(m, dl)\n\n    def predict_dl(self, dl): return predict_with_targs(self.model, dl)[0]\n\n    def predict_array(self, arr):\n        self.model.eval()\n        return to_np(self.model(to_gpu(V(T(arr)))))\n\n    def TTA(self, n_aug=4, is_test=False):\n        """""" Predict with Test Time Augmentation (TTA)\n\n        Additional to the original test/validation images, apply image augmentation to them\n        (just like for training images) and calculate the mean of predictions. The intent\n        is to increase the accuracy of predictions by examining the images using multiple\n        perspectives.\n\n        Args:\n            n_aug: a number of augmentation images to use per original image\n            is_test: indicate to use test images; otherwise use validation images\n\n        Returns:\n            (tuple): a tuple containing:\n\n                log predictions (numpy.ndarray): log predictions (i.e. `np.exp(log_preds)` will return probabilities)\n                targs (numpy.ndarray): target values when `is_test==False`; zeros otherwise.\n        """"""\n        dl1 = self.data.test_dl     if is_test else self.data.val_dl\n        dl2 = self.data.test_aug_dl if is_test else self.data.aug_dl\n        preds1,targs = predict_with_targs(self.model, dl1)\n        preds1 = [preds1]*math.ceil(n_aug/4)\n        preds2 = [predict_with_targs(self.model, dl2)[0] for i in tqdm(range(n_aug), leave=False)]\n        return np.stack(preds1+preds2), targs\n\n    def fit_opt_sched(self, phases, cycle_save_name=None, best_save_name=None, stop_div=False, data_list=None, callbacks=None, \n                      cut = None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n        """"""Wraps us the content of phases to send them to model.fit(..)\n\n        This will split the training in several parts, each with their own learning rates/\n        wds/momentums/optimizer detailed in phases.\n\n        Additionaly we can add a list of different data objets in data_list to train\n        on different datasets (to change the size for instance) for each of these groups.\n\n        Args:\n            phases: a list of TrainingPhase objects\n            stop_div: when True, stops the training if the loss goes too high\n            data_list: a list of different Data objects.\n            kwargs: other arguments\n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work. \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n        Returns:\n            None\n        """"""\n        if data_list is None: data_list=[]\n        if callbacks is None: callbacks=[]\n        layer_opt = LayerOptimizer(phases[0].opt_fn, self.get_layer_groups(), 1e-2, phases[0].wds)\n        self.sched = OptimScheduler(layer_opt, phases, len(self.data.trn_dl), stop_div)\n        callbacks.append(self.sched)\n        metrics = self.metrics\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(self.model)\n            callbacks+=[SWA(self.model, self.swa_model, swa_start)]\n        n_epochs = [phase.epochs for phase in phases] if cut is None else cut\n        if len(data_list)==0: data_list = [self.data]\n        return fit(self.model, data_list, n_epochs,layer_opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n'"
fastai/tutorials/fastai/lm_rnn.py,5,"b'import warnings\nfrom .imports import *\nfrom .torch_imports import *\nfrom .rnn_reg import LockedDropout,WeightDrop,EmbeddingDropout\nfrom .model import Stepper\nfrom .core import set_grad_enabled\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef seq2seq_reg(output, xtra, loss, alpha=0, beta=0):\n    hs,dropped_hs = xtra\n    if alpha:  # Activation Regularization\n        loss = loss + sum(alpha * dropped_hs[-1].pow(2).mean())\n    if beta:   # Temporal Activation Regularization (slowness)\n        h = hs[-1]\n        if len(h)>1: loss = loss + sum(beta * (h[1:] - h[:-1]).pow(2).mean())\n    return loss\n\n\ndef repackage_var(h):\n    """"""Wraps h in new Variables, to detach them from their history.""""""\n    if IS_TORCH_04: return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)\n    else: return Variable(h.data) if type(h) == Variable else tuple(repackage_var(v) for v in h)\n\n\nclass RNN_Encoder(nn.Module):\n\n    """"""A custom RNN encoder network that uses\n        - an embedding matrix to encode input,\n        - a stack of LSTM layers to drive the network, and\n        - variational dropouts in the embedding and LSTM layers\n\n        The architecture for this network was inspired by the work done in\n        ""Regularizing and Optimizing LSTM Language Models"".\n        (https://arxiv.org/pdf/1708.02182.pdf)\n    """"""\n\n    initrange=0.1\n\n    def __init__(self, ntoken, emb_sz, nhid, nlayers, pad_token, bidir=False,\n                 dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5):\n        """""" Default constructor for the RNN_Encoder class\n\n            Args:\n                bs (int): batch size of input data\n                ntoken (int): number of vocabulary (or tokens) in the source dataset\n                emb_sz (int): the embedding size to use to encode each token\n                nhid (int): number of hidden activation per LSTM layer\n                nlayers (int): number of LSTM layers to use in the architecture\n                pad_token (int): the int value used for padding text.\n                dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n                dropouti (float): dropout to apply to the input layer.\n                dropoute (float): dropout to apply to the embedding layer.\n                wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n\n            Returns:\n                None\n          """"""\n\n        super().__init__()\n        self.ndir = 2 if bidir else 1\n        self.bs = 1\n        self.encoder = nn.Embedding(ntoken, emb_sz, padding_idx=pad_token)\n        self.encoder_with_dropout = EmbeddingDropout(self.encoder)\n        self.rnns = [nn.LSTM(emb_sz if l == 0 else nhid, (nhid if l != nlayers - 1 else emb_sz)//self.ndir,\n             1, bidirectional=bidir) for l in range(nlayers)]\n        if wdrop: self.rnns = [WeightDrop(rnn, wdrop) for rnn in self.rnns]\n        self.rnns = torch.nn.ModuleList(self.rnns)\n        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n\n        self.emb_sz,self.nhid,self.nlayers,self.dropoute = emb_sz,nhid,nlayers,dropoute\n        self.dropouti = LockedDropout(dropouti)\n        self.dropouths = nn.ModuleList([LockedDropout(dropouth) for l in range(nlayers)])\n\n    def forward(self, input):\n        """""" Invoked during the forward propagation of the RNN_Encoder module.\n        Args:\n            input (Tensor): input of shape (sentence length x batch_size)\n\n        Returns:\n            raw_outputs (tuple(list (Tensor), list(Tensor)): list of tensors evaluated from each RNN layer without using\n            dropouth, list of tensors evaluated from each RNN layer using dropouth,\n        """"""\n        sl,bs = input.size()\n        if bs!=self.bs:\n            self.bs=bs\n            self.reset()\n        with set_grad_enabled(self.training):\n            emb = self.encoder_with_dropout(input, dropout=self.dropoute if self.training else 0)\n            emb = self.dropouti(emb)\n            raw_output = emb\n            new_hidden,raw_outputs,outputs = [],[],[]\n            for l, (rnn,drop) in enumerate(zip(self.rnns, self.dropouths)):\n                current_input = raw_output\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    raw_output, new_h = rnn(raw_output, self.hidden[l])\n                new_hidden.append(new_h)\n                raw_outputs.append(raw_output)\n                if l != self.nlayers - 1: raw_output = drop(raw_output)\n                outputs.append(raw_output)\n\n            self.hidden = repackage_var(new_hidden)\n        return raw_outputs, outputs\n\n    def one_hidden(self, l):\n        nh = (self.nhid if l != self.nlayers - 1 else self.emb_sz)//self.ndir\n        if IS_TORCH_04: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_())\n        else: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_(), volatile=not self.training)\n\n    def reset(self):\n        self.weights = next(self.parameters()).data\n        self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.nlayers)]\n\n\nclass MultiBatchRNN(RNN_Encoder):\n    def __init__(self, bptt, max_seq, *args, **kwargs):\n        self.max_seq,self.bptt = max_seq,bptt\n        super().__init__(*args, **kwargs)\n\n    def concat(self, arrs):\n        return [torch.cat([l[si] for l in arrs]) for si in range(len(arrs[0]))]\n\n    def forward(self, input):\n        sl,bs = input.size()\n        for l in self.hidden:\n            for h in l: h.data.zero_()\n        raw_outputs, outputs = [],[]\n        for i in range(0, sl, self.bptt):\n            r, o = super().forward(input[i: min(i+self.bptt, sl)])\n            if i>(sl-self.max_seq):\n                raw_outputs.append(r)\n                outputs.append(o)\n        return self.concat(raw_outputs), self.concat(outputs)\n\nclass LinearDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, n_out, nhid, dropout, tie_encoder=None):\n        super().__init__()\n        self.decoder = nn.Linear(nhid, n_out, bias=False)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.dropout = LockedDropout(dropout)\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = self.dropout(outputs[-1])\n        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n        result = decoded.view(-1, decoded.size(1))\n        return result, raw_outputs, outputs\n\n\nclass LinearBlock(nn.Module):\n    def __init__(self, ni, nf, drop):\n        super().__init__()\n        self.lin = nn.Linear(ni, nf)\n        self.drop = nn.Dropout(drop)\n        self.bn = nn.BatchNorm1d(ni)\n\n    def forward(self, x): return self.lin(self.drop(self.bn(x)))\n\n\nclass PoolingLinearClassifier(nn.Module):\n    def __init__(self, layers, drops):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            LinearBlock(layers[i], layers[i + 1], drops[i]) for i in range(len(layers) - 1)])\n\n    def pool(self, x, bs, is_max):\n        f = F.adaptive_max_pool1d if is_max else F.adaptive_avg_pool1d\n        return f(x.permute(1,2,0), (1,)).view(bs,-1)\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = outputs[-1]\n        sl,bs,_ = output.size()\n        avgpool = self.pool(output, bs, False)\n        mxpool = self.pool(output, bs, True)\n        x = torch.cat([output[-1], mxpool, avgpool], 1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return l_x, raw_outputs, outputs\n\n\nclass SequentialRNN(nn.Sequential):\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \'reset\'): c.reset()\n\n\ndef get_language_model(n_tok, emb_sz, nhid, nlayers, pad_token,\n                 dropout=0.4, dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5, tie_weights=True):\n    """"""Returns a SequentialRNN model.\n\n    A RNN_Encoder layer is instantiated using the parameters provided.\n\n    This is followed by the creation of a LinearDecoder layer.\n\n    Also by default (i.e. tie_weights = True), the embedding matrix used in the RNN_Encoder\n    is used to  instantiate the weights for the LinearDecoder layer.\n\n    The SequentialRNN layer is the native torch\'s Sequential wrapper that puts the RNN_Encoder and\n    LinearDecoder layers sequentially in the model.\n\n    Args:\n        n_tok (int): number of unique vocabulary words (or tokens) in the source dataset\n        emb_sz (int): the embedding size to use to encode each token\n        nhid (int): number of hidden activation per LSTM layer\n        nlayers (int): number of LSTM layers to use in the architecture\n        pad_token (int): the int value used for padding text.\n        dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n        dropouti (float): dropout to apply to the input layer.\n        dropoute (float): dropout to apply to the embedding layer.\n        wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n        tie_weights (bool): decide if the weights of the embedding matrix in the RNN encoder should be tied to the\n            weights of the LinearDecoder layer.\n    Returns:\n        A SequentialRNN model\n    """"""\n\n    rnn_enc = RNN_Encoder(n_tok, emb_sz, nhid=nhid, nlayers=nlayers, pad_token=pad_token,\n                 dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    enc = rnn_enc.encoder if tie_weights else None\n    return SequentialRNN(rnn_enc, LinearDecoder(n_tok, emb_sz, dropout, tie_encoder=enc))\n\n\ndef get_rnn_classifer(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n                      dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n    rnn_enc = MultiBatchRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir,\n                      dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    return SequentialRNN(rnn_enc, PoolingLinearClassifier(layers, drops))\n\n'"
fastai/tutorials/fastai/losses.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\ndef fbeta_torch(y_true, y_pred, beta, threshold, eps=1e-9):\n    y_pred = (y_pred.float() > threshold).float()\n    y_true = y_true.float()\n    tp = (y_pred * y_true).sum(dim=1)\n    precision = tp / (y_pred.sum(dim=1)+eps)\n    recall = tp / (y_true.sum(dim=1)+eps)\n    return torch.mean(\n        precision*recall / (precision*(beta**2)+recall+eps) * (1+beta**2))\n\n'"
fastai/tutorials/fastai/lsuv_initializer.py,4,"b'""""""\nFrom https://github.com/ducha-aiki/LSUV-pytorch\n\nCopyright (C) 2017, Dmytro Mishkin\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the\n   distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\nimport numpy as np\nimport torch\nimport torch.nn.init\nimport torch.nn as nn\n\ngg = {}\ngg[\'hook_position\'] = 0\ngg[\'total_fc_conv_layers\'] = 0\ngg[\'done_counter\'] = -1\ngg[\'hook\'] = None\ngg[\'act_dict\'] = {}\ngg[\'counter_to_apply_correction\'] = 0\ngg[\'correction_needed\'] = False\ngg[\'current_coef\'] = 1.0\n\n# Orthonorm init code is taked from Lasagne\n# https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\ndef svd_orthonormal(w):\n    shape = w.shape\n    if len(shape) < 2:\n        raise RuntimeError(""Only shapes of length 2 or more are supported."")\n    flat_shape = (shape[0], np.prod(shape[1:]))\n    a = np.random.normal(0.0, 1.0, flat_shape)#w;\n    u, _, v = np.linalg.svd(a, full_matrices=False)\n    q = u if u.shape == flat_shape else v\n    q = q.reshape(shape)\n    return q.astype(np.float32)\n\ndef store_activations(self, input, output):\n    gg[\'act_dict\'] = output.data.cpu().numpy();\n    return\n\ndef add_current_hook(m):\n    if gg[\'hook\'] is not None:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'hook_position\'] > gg[\'done_counter\']:\n            gg[\'hook\'] = m.register_forward_hook(store_activations)\n        else:\n            gg[\'hook_position\'] += 1\n    return\n\ndef count_conv_fc_layers(m):\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        gg[\'total_fc_conv_layers\'] +=1\n    return\n\ndef remove_hooks(hooks):\n    for h in hooks:\n        h.remove()\n    return\n\ndef orthogonal_weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        if hasattr(m, \'weight_v\'):\n            w_ortho = svd_orthonormal(m.weight_v.data.cpu().numpy())\n            m.weight_v.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n        else:\n            w_ortho = svd_orthonormal(m.weight.data.cpu().numpy())\n            m.weight.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n    return\n\ndef apply_weights_correction(m):\n    if gg[\'hook\'] is None:\n        return\n    if not gg[\'correction_needed\']:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'counter_to_apply_correction\'] < gg[\'hook_position\']:\n            gg[\'counter_to_apply_correction\'] += 1\n        else:\n            if hasattr(m, \'weight_g\'):\n                m.weight_g.data *= float(gg[\'current_coef\'])\n                gg[\'correction_needed\'] = False\n            else:\n                m.weight.data *= gg[\'current_coef\']\n                gg[\'correction_needed\'] = False\n            return\n    return\n\ndef apply_lsuv_init(model, data, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=True, cuda=True):\n    model.eval();\n    if cuda:\n        model=model.cuda()\n        data=data.cuda()\n    else:\n        model=model.cpu()\n        data=data.cpu()        \n        \n    model.apply(count_conv_fc_layers)\n    if do_orthonorm:\n        model.apply(orthogonal_weights_init)\n        if cuda:\n            model=model.cuda()\n    for layer_idx in range(gg[\'total_fc_conv_layers\']):\n        model.apply(add_current_hook)\n        out = model(data)\n        current_std = gg[\'act_dict\'].std()\n        attempts = 0\n        while (np.abs(current_std - needed_std) > std_tol):\n            gg[\'current_coef\'] =  needed_std / (current_std  + 1e-8);\n            gg[\'correction_needed\'] = True\n            model.apply(apply_weights_correction)\n            if cuda:\n                model=model.cuda()\n            out = model(data)\n            current_std = gg[\'act_dict\'].std()\n            attempts+=1\n            if attempts > max_attempts:\n                print(f\'Cannot converge in {max_attempts} iterations\')\n                break\n        if gg[\'hook\'] is not None:\n           gg[\'hook\'].remove()\n        gg[\'done_counter\']+=1\n        gg[\'counter_to_apply_correction\'] = 0\n        gg[\'hook_position\'] = 0\n        gg[\'hook\']  = None\n    if not cuda:\n        model=model.cpu()\n    return model\n'"
fastai/tutorials/fastai/metrics.py,3,"b'from .imports import *\nfrom .torch_imports import *\n\ndef accuracy_np(preds, targs):\n    preds = np.argmax(preds, 1)\n    return (preds==targs).mean()\n\ndef accuracy(preds, targs):\n    preds = torch.max(preds, dim=1)[1]\n    return (preds==targs).float().mean()\n\ndef accuracy_thresh(thresh):\n    return lambda preds,targs: accuracy_multi(preds, targs, thresh)\n\ndef accuracy_multi(preds, targs, thresh):\n    return ((preds>thresh).float()==targs).float().mean()\n\ndef accuracy_multi_np(preds, targs, thresh):\n    return ((preds>thresh)==targs).mean()\n\ndef recall(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/targs.sum()\n\ndef precision(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/pred_pos.sum()\n\ndef fbeta(preds, targs, beta, thresh=0.5):\n    """"""Calculates the F-beta score (the weighted harmonic mean of precision and recall).\n    This is the micro averaged version where the true positives, false negatives and\n    false positives are calculated globally (as opposed to on a per label basis).\n\n    beta == 1 places equal weight on precision and recall, b < 1 emphasizes precision and\n    beta > 1 favors recall.\n    """"""\n    assert beta > 0, \'beta needs to be greater than 0\'\n    beta2 = beta ** 2\n    rec = recall(preds, targs, thresh)\n    prec = precision(preds, targs, thresh)\n    return (1 + beta2) * prec * rec / (beta2 * prec + rec)\n\ndef f1(preds, targs, thresh=0.5): return fbeta(preds, targs, 1, thresh)\n'"
fastai/tutorials/fastai/model.py,8,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .layer_optimizer import *\nfrom .swa import *\nfrom .fp16 import *\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef cut_model(m, cut):\n    return list(m.children())[:cut] if cut else [m]\n\ndef predict_to_bcolz(m, gen, arr, workers=4):\n    arr.trim(len(arr))\n    lock=threading.Lock()\n    m.eval()\n    for x,*_ in tqdm(gen):\n        y = to_np(m(VV(x)).data)\n        with lock:\n            arr.append(y)\n            arr.flush()\n\ndef num_features(m):\n    c=children(m)\n    if len(c)==0: return None\n    for l in reversed(c):\n        if hasattr(l, \'num_features\'): return l.num_features\n        res = num_features(l)\n        if res is not None: return res\n\ndef torch_item(x): return x.item() if hasattr(x,\'item\') else x[0]\n\nclass Stepper():\n    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n        self.fp16 = fp16\n        self.reset(True)\n        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n        self.loss_scale = loss_scale\n\n    def reset(self, train=True):\n        if train: apply_leaf(self.m, set_train_mode)\n        else: self.m.eval()\n        if hasattr(self.m, \'reset\'):\n            self.m.reset()\n            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n\n    def step(self, xs, y, epoch):\n        xtra = []\n        output = self.m(*xs)\n        if isinstance(output,tuple): output,*xtra = output\n        if self.fp16: self.m.zero_grad()\n        else: self.opt.zero_grad() \n        loss = raw_loss = self.crit(output, y)\n        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n        loss.backward()\n        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n        if self.loss_scale != 1:\n            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n        if self.clip:   # Gradient clipping\n            if IS_TORCH_04: nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n            else: nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n        self.opt.step()\n        if self.fp16: \n            copy_fp32_to_model(self.m, self.fp32_params)\n            torch.cuda.synchronize()\n        return torch_item(raw_loss.data)\n\n    def evaluate(self, xs, y):\n        preds = self.m(*xs)\n        if isinstance(preds,tuple): preds=preds[0]\n        return preds, self.crit(preds, y)\n\ndef set_train_mode(m):\n    if (hasattr(m, \'running_mean\') and (getattr(m,\'bn_freeze\',False)\n              or not getattr(m,\'trainable\',False))): m.eval()\n    elif (getattr(m,\'drop_freeze\',False) and hasattr(m, \'p\')\n          and (\'drop\' in type(m).__name__.lower())): m.eval()\n    else: m.train()\n\ndef fit(model, data, n_epochs, opt, crit, metrics=None, callbacks=None, stepper=Stepper,\n        swa_model=None, swa_start=None, swa_eval_freq=None, **kwargs):\n    """""" Fits a model\n\n    Arguments:\n       model (model): any pytorch module\n           net = to_gpu(net)\n       data (ModelData): see ModelData class and subclasses (can be a list)\n       opts: an optimizer. Example: optim.Adam. \n       If n_epochs is a list, it needs to be the layer_optimizer to get the optimizer as it changes.\n       n_epochs(int or list): number of epochs (or list of number of epochs)\n       crit: loss function to optimize. Example: F.cross_entropy\n    """"""\n\n    all_val = kwargs.pop(\'all_val\') if \'all_val\' in kwargs else False\n    get_ep_vals = kwargs.pop(\'get_ep_vals\') if \'get_ep_vals\' in kwargs else False\n    metrics = metrics or []\n    callbacks = callbacks or []\n    avg_mom=0.98\n    batch_num,avg_loss=0,0.\n    for cb in callbacks: cb.on_train_begin()\n    names = [""epoch"", ""trn_loss"", ""val_loss""] + [f.__name__ for f in metrics]\n    if swa_model is not None:\n        swa_names = [\'swa_loss\'] + [f\'swa_{f.__name__}\' for f in metrics]\n        names += swa_names\n        # will use this to call evaluate later\n        swa_stepper = stepper(swa_model, None, crit, **kwargs)\n\n    layout = ""{!s:10} "" * len(names)\n    if not isinstance(n_epochs, Iterable): n_epochs=[n_epochs]\n    if not isinstance(data, Iterable): data = [data]\n    if len(data) == 1: data = data * len(n_epochs)\n    for cb in callbacks: cb.on_phase_begin()\n    model_stepper = stepper(model, opt.opt if hasattr(opt,\'opt\') else opt, crit, **kwargs)\n    ep_vals = collections.OrderedDict()\n    tot_epochs = int(np.ceil(np.array(n_epochs).sum()))\n    cnt_phases = np.array([ep * len(dat.trn_dl) for (ep,dat) in zip(n_epochs,data)]).cumsum()\n    phase = 0\n    for epoch in tnrange(tot_epochs, desc=\'Epoch\'):\n        model_stepper.reset(True)\n        cur_data = data[phase]\n        if hasattr(cur_data, \'trn_sampler\'): cur_data.trn_sampler.set_epoch(epoch)\n        if hasattr(cur_data, \'val_sampler\'): cur_data.val_sampler.set_epoch(epoch)\n        num_batch = len(cur_data.trn_dl)\n        t = tqdm(iter(cur_data.trn_dl), leave=False, total=num_batch)\n        if all_val: val_iter = IterBatch(cur_data.val_dl)\n\n        for (*x,y) in t:\n            batch_num += 1\n            for cb in callbacks: cb.on_batch_begin()\n            loss = model_stepper.step(V(x),V(y), epoch)\n            avg_loss = avg_loss * avg_mom + loss * (1-avg_mom)\n            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n            t.set_postfix(loss=debias_loss)\n            stop=False\n            los = debias_loss if not all_val else [debias_loss] + validate_next(model_stepper,metrics, val_iter)\n            for cb in callbacks: stop = stop or cb.on_batch_end(los)\n            if stop: return\n            if batch_num >= cnt_phases[phase]:\n                for cb in callbacks: cb.on_phase_end()\n                phase += 1\n                if phase >= len(n_epochs):\n                    t.close()\n                    break\n                for cb in callbacks: cb.on_phase_begin()\n                if isinstance(opt, LayerOptimizer): model_stepper.opt = opt.opt\n                if cur_data != data[phase]:\n                    t.close()\n                    break\n\n        if not all_val:\n            vals = validate(model_stepper, cur_data.val_dl, metrics)\n            stop=False\n            for cb in callbacks: stop = stop or cb.on_epoch_end(vals)\n            if swa_model is not None:\n                if (epoch + 1) >= swa_start and ((epoch + 1 - swa_start) % swa_eval_freq == 0 or epoch == tot_epochs - 1):\n                    fix_batchnorm(swa_model, cur_data.trn_dl)\n                    swa_vals = validate(swa_stepper, cur_data.val_dl, metrics)\n                    vals += swa_vals\n\n            if epoch == 0: print(layout.format(*names))\n            print_stats(epoch, [debias_loss] + vals)\n            ep_vals = append_stats(ep_vals, epoch, [debias_loss] + vals)\n        if stop: break\n    for cb in callbacks: cb.on_train_end()\n    if get_ep_vals: return vals, ep_vals\n    else: return vals\n\ndef append_stats(ep_vals, epoch, values, decimals=6):\n    ep_vals[epoch]=list(np.round(values, decimals))\n    return ep_vals\n\ndef print_stats(epoch, values, decimals=6):\n    layout = ""{!s:^10}"" + "" {!s:10}"" * len(values)\n    values = [epoch] + list(np.round(values, decimals))\n    print(layout.format(*values))\n\nclass IterBatch():\n    def __init__(self, dl):\n        self.idx = 0\n        self.dl = dl\n        self.iter = iter(dl)\n\n    def __iter__(self): return self\n\n    def next(self):\n        res = next(self.iter)\n        self.idx += 1\n        if self.idx == len(self.dl):\n            self.iter = iter(self.dl)\n            self.idx=0\n        return res\n\ndef validate_next(stepper, metrics, val_iter):\n    """"""Computes the loss on the next minibatch of the validation set.""""""\n    stepper.reset(False)\n    with no_grad_context():\n        (*x,y) = val_iter.next()\n        preds,l = stepper.evaluate(VV(x), VV(y))\n        res = [to_np(l)[0]]\n        res += [f(preds.data,y) for f in metrics]\n    stepper.reset(True)\n    return res\n\ndef validate(stepper, dl, metrics):\n    batch_cnts,loss,res = [],[],[]\n    stepper.reset(False)\n    with no_grad_context():\n        for (*x,y) in iter(dl):\n            preds, l = stepper.evaluate(VV(x), VV(y))\n            if isinstance(x,list): batch_cnts.append(len(x[0]))\n            else: batch_cnts.append(len(x))\n            loss.append(to_np(l))\n            res.append([f(preds.data, y) for f in metrics])\n    return [np.average(loss, 0, weights=batch_cnts)] + list(np.average(np.stack(res), 0, weights=batch_cnts))\n\ndef get_prediction(x):\n    if is_listy(x): x=x[0]\n    return x.data\n\ndef predict(m, dl):\n    preda,_ = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda))\n\ndef predict_batch(m, x):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    return m(VV(x))\n\ndef predict_with_targs_(m, dl):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    res = []\n    for *x,y in iter(dl): res.append([get_prediction(m(*VV(x))),y])\n    return zip(*res)\n\ndef predict_with_targs(m, dl):\n    preda,targa = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda)), to_np(torch.cat(targa))\n\n# From https://github.com/ncullen93/torchsample\ndef model_summary(m, input_size):\n    def register_hook(module):\n        def hook(module, input, output):\n            class_name = str(module.__class__).split(\'.\')[-1].split(""\'"")[0]\n            module_idx = len(summary)\n\n            m_key = \'%s-%i\' % (class_name, module_idx+1)\n            summary[m_key] = OrderedDict()\n            summary[m_key][\'input_shape\'] = list(input[0].size())\n            summary[m_key][\'input_shape\'][0] = -1\n            if is_listy(output):\n                summary[m_key][\'output_shape\'] = [[-1] + list(o.size())[1:] for o in output]\n            else:\n                summary[m_key][\'output_shape\'] = list(output.size())\n                summary[m_key][\'output_shape\'][0] = -1\n\n            params = 0\n            if hasattr(module, \'weight\'):\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n                summary[m_key][\'trainable\'] = module.weight.requires_grad\n            if hasattr(module, \'bias\') and module.bias is not None:\n                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n            summary[m_key][\'nb_params\'] = params\n\n        if (not isinstance(module, nn.Sequential) and\n           not isinstance(module, nn.ModuleList) and\n           not (module == m)):\n            hooks.append(module.register_forward_hook(hook))\n\n    summary = OrderedDict()\n    hooks = []\n    m.apply(register_hook)\n\n    if is_listy(input_size[0]):\n        x = [to_gpu(Variable(torch.rand(3,*in_size))) for in_size in input_size]\n    else: x = [to_gpu(Variable(torch.rand(3,*input_size)))]\n    m(*x)\n\n    for h in hooks: h.remove()\n    return summary\n\n'"
fastai/tutorials/fastai/nlp.py,4,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .model import *\nfrom .dataset import *\nfrom .learner import *\nfrom .text import *\nfrom .lm_rnn import *\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.datasets import language_modeling\n\nclass DotProdNB(nn.Module):\n    def __init__(self, nf, ny, w_adj=0.4, r_adj=10):\n        super().__init__()\n        self.w_adj,self.r_adj = w_adj,r_adj\n        self.w = nn.Embedding(nf+1, 1, padding_idx=0)\n        self.w.weight.data.uniform_(-0.1,0.1)\n        self.r = nn.Embedding(nf+1, ny)\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        w = self.w(feat_idx)\n        r = self.r(feat_idx)\n        x = ((w+self.w_adj)*r/self.r_adj).sum(1)\n        return F.softmax(x)\n\nclass SimpleNB(nn.Module):\n    def __init__(self, nf, ny):\n        super().__init__()\n        self.r = nn.Embedding(nf+1, ny, padding_idx=0)\n        self.b = nn.Parameter(torch.zeros(ny,))\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        r = self.r(feat_idx)\n        x = r.sum(1)+self.b\n        return F.softmax(x)\n\nclass BOW_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.l1_loss\n\ndef calc_pr(y_i, x, y, b):\n    idx = np.argwhere((y==y_i)==b)\n    p = x[idx[:,0]].sum(0)+1\n    return p/((y==y_i)==b).sum()\n\ndef calc_r(y_i, x, y):\n    return np.log(calc_pr(y_i, x, y, True) / calc_pr(y_i, x, y, False))\n\nclass BOW_Dataset(Dataset):\n    def __init__(self, bow, y, max_len):\n        self.bow,self.max_len = bow,max_len\n        self.c = int(y.max())+1\n        self.n,self.vocab_size = bow.shape\n        self.y = one_hot(y,self.c).astype(np.float32)\n        x = self.bow.sign()\n        self.r = np.stack([calc_r(i, x, y).A1 for i in range(self.c)]).T\n\n    def __getitem__(self, i):\n        row = self.bow.getrow(i)\n\n        num_row_entries = row.indices.shape[0]\n        indices = (row.indices + 1).astype(np.int64)\n        data = (row.data).astype(np.int64)\n\n        if num_row_entries < self.max_len:\n            # If short, pad\n            indices = np.pad(indices, (self.max_len - num_row_entries, 0), mode=\'constant\')\n            data = np.pad(data, (self.max_len - num_row_entries, 0), mode=\'constant\')\n        else:\n            # If long, truncate\n            indices, data = indices[-self.max_len:], data[-self.max_len:]\n\n        return indices, data, min(self.max_len, num_row_entries), self.y[i]\n\n    def __len__(self): return len(self.bow.indptr)-1\n\n\nclass TextClassifierData(ModelData):\n    @property\n    def c(self): return self.trn_ds.c\n\n    @property\n    def r(self):\n        return torch.Tensor(np.concatenate([np.zeros((1,self.c)), self.trn_ds.r]))\n\n    def get_model(self, f, **kwargs):\n        m = to_gpu(f(self.trn_ds.vocab_size, self.c, **kwargs))\n        m.r.weight.data = to_gpu(self.r)\n        m.r.weight.requires_grad = False\n        model = BasicModel(m)\n        return BOW_Learner(self, model, metrics=[accuracy_thresh(0.5)], opt_fn=optim.Adam)\n\n    def dotprod_nb_learner(self, **kwargs): return self.get_model(DotProdNB, **kwargs)\n    def nb_learner(self, **kwargs): return self.get_model(SimpleNB, **kwargs)\n\n    @classmethod\n    def from_bow(cls, trn_bow, trn_y, val_bow, val_y, sl):\n        trn_ds = BOW_Dataset(trn_bow, trn_y, sl)\n        val_ds = BOW_Dataset(val_bow, val_y, sl)\n        trn_dl = DataLoader(trn_ds, 64, True)\n        val_dl = DataLoader(val_ds, 64, False)\n        return cls(\'.\', trn_dl, val_dl)\n\n\ndef flip_tensor(x, dim):\n    xsize = x.size()\n    dim = x.dim() + dim if dim < 0 else dim\n    x = x.view(-1, *xsize[dim:])\n    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1,\n                      -1, -1), (\'cpu\',\'cuda\')[x.is_cuda])().long(), :]\n    return x.view(xsize)\n\n\nclass LanguageModelLoader():\n\n    def __init__(self, ds, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        text = sum([o.text for o in ds], [])\n        fld = ds.fields[\'text\']\n        nums = fld.numericalize([text],device=None if torch.cuda.is_available() else -1)\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        return self\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def __next__(self):\n        if self.i >= self.n-1 or self.iter>=len(self): raise StopIteration\n        bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n        seq_len = max(5, int(np.random.normal(bptt, 5)))\n        res = self.get_batch(self.i, seq_len)\n        self.i += seq_len\n        self.iter += 1\n        return res\n\n    def batchify(self, data):\n        nb = data.size(0) // self.bs\n        data = data[:nb*self.bs]\n        data = data.view(self.bs, -1).t().contiguous()\n        if self.backwards: data=flip_tensor(data, 0)\n        return to_gpu(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass ConcatTextDataset(torchtext.data.Dataset):\n    def __init__(self, path, text_field, newline_eos=True, encoding=\'utf-8\', **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n        if os.path.isdir(path): paths=glob(f\'{path}/*.*\')\n        else: paths=[path]\n        for p in paths:\n            for line in open(p, encoding=encoding): text += text_field.preprocess(line)\n            if newline_eos: text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n        super().__init__(examples, fields, **kwargs)\n\n\nclass ConcatTextDatasetFromDataFrames(torchtext.data.Dataset):\n    def __init__(self, df, text_field, col, newline_eos=True, **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n\n        text += text_field.preprocess(df[col].str.cat(sep=\' <eos> \'))\n        if (newline_eos): text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n\n        super().__init__(examples, fields, **kwargs)\n\n    @classmethod\n    def splits(cls, train_df=None, val_df=None, test_df=None, keep_nones=False, **kwargs):\n        res = (\n            cls(train_df, **kwargs),\n            cls(val_df, **kwargs),\n            map_none(test_df, partial(cls, **kwargs)))  # not required\n        return res if keep_nones else tuple(d for d in res if d is not None)\n\n\nclass LanguageModelData():\n    """"""\n    This class provides the entry point for dealing with supported NLP tasks.\n    Usage:\n    1.  Use one of the factory constructors (from_dataframes, from_text_files) to\n        obtain an instance of the class.\n    2.  Use the get_model method to return a RNN_Learner instance (a network suited\n        for NLP tasks), then proceed with training.\n\n        Example:\n            >> TEXT = data.Field(lower=True, tokenize=spacy_tok)\n            >> FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n            >> md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=64, bptt=70, min_freq=10)\n\n            >> em_sz = 200  # size of each embedding vector\n            >> nh = 500     # number of hidden activations per layer\n            >> nl = 3       # number of layers\n\n            >> opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n            >> learner = md.get_model(opt_fn, em_sz, nh, nl,\n                           dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n            >> learner.reg_fn = seq2seq_reg\n            >> learner.clip=0.3\n\n            >> learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n\n    """"""\n    def __init__(self, path, field, trn_ds, val_ds, test_ds, bs, bptt, backwards=False, **kwargs):\n        """""" Constructor for the class. An important thing that happens here is\n            that the field\'s ""build_vocab"" method is invoked, which builds the vocabulary\n            for this NLP model.\n\n            Also, three instances of the LanguageModelLoader are constructed; one each\n            for training data (self.trn_dl), validation data (self.val_dl), and the\n            testing data (self.test_dl)\n\n            Args:\n                path (str): testing path\n                field (Field): torchtext field object\n                trn_ds (Dataset): training dataset\n                val_ds (Dataset): validation dataset\n                test_ds (Dataset): testing dataset\n                bs (int): batch size\n                bptt (int): back propagation through time\n                kwargs: other arguments\n        """"""\n        self.bs = bs\n        self.path = path\n        self.trn_ds = trn_ds; self.val_ds = val_ds; self.test_ds = test_ds\n        if not hasattr(field, \'vocab\'): field.build_vocab(self.trn_ds, **kwargs)\n\n        self.pad_idx = field.vocab.stoi[field.pad_token]\n        self.nt = len(field.vocab)\n\n        factory = lambda ds: LanguageModelLoader(ds, bs, bptt, backwards=backwards)\n        self.trn_dl = factory(self.trn_ds)\n        self.val_dl = factory(self.val_ds)\n        self.test_dl = map_none(self.test_ds, factory)  # not required\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        """""" Method returns a RNN_Learner object, that wraps an instance of the RNN_Encoder module.\n\n        Args:\n            opt_fn (Optimizer): the torch optimizer function to use\n            emb_sz (int): embedding size\n            n_hid (int): number of hidden inputs\n            n_layers (int): number of hidden layers\n            kwargs: other arguments\n\n        Returns:\n            An instance of the RNN_Learner class.\n\n        """"""\n        m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = SingleModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    @classmethod\n    def from_dataframes(cls, path, field, col, train_df, val_df, test_df=None, bs=64, bptt=70, **kwargs):\n        trn_ds, val_ds, test_ds = ConcatTextDatasetFromDataFrames.splits(\n            text_field=field, col=col, train_df=train_df, val_df=val_df, test_df=test_df, keep_nones=True)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n    @classmethod\n    def from_text_files(cls, path, field, train, validation, test=None, bs=64, bptt=70, **kwargs):\n        """""" Method used to instantiate a LanguageModelData object that can be used for a\n            supported nlp task.\n\n        Args:\n            path (str): the absolute path in which temporary model data will be saved\n            field (Field): torchtext field\n            train (str): file location of the training data\n            validation (str): file location of the validation data\n            test (str): file location of the testing data\n            bs (int): batch size to use\n            bptt (int): back propagation through time hyper-parameter\n            kwargs: other arguments\n\n        Returns:\n            a LanguageModelData instance, which most importantly, provides us the datasets for training,\n                validation, and testing\n\n        Note:\n            The train, validation, and test path can be pointed to any file (or folder) that contains a valid\n                text corpus.\n\n        """"""\n        trn_ds, val_ds, test_ds = ConcatTextDataset.splits(\n            path, text_field=field, train=train, validation=validation, test=test)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n\nclass TextDataLoader():\n    def __init__(self, src, x_fld, y_fld):\n        self.src,self.x_fld,self.y_fld = src,x_fld,y_fld\n\n    def __len__(self): return len(self.src)\n\n    def __iter__(self):\n        it = iter(self.src)\n        for i in range(len(self)):\n            b = next(it)\n            yield getattr(b, self.x_fld).data, getattr(b, self.y_fld).data\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n\nclass TextData(ModelData):\n    def create_td(self, it): return TextDataLoader(it, self.text_fld, self.label_fld)\n\n    @classmethod\n    def from_splits(cls, path, splits, bs, text_name=\'text\', label_name=\'label\'):\n        text_fld = splits[0].fields[text_name]\n        label_fld = splits[0].fields[label_name]\n        if hasattr(label_fld, \'build_vocab\'): label_fld.build_vocab(splits[0])\n        iters = torchtext.data.BucketIterator.splits(splits, batch_size=bs)\n        trn_iter,val_iter,test_iter = iters[0],iters[1],None\n        test_dl = None\n        if len(iters) == 3:\n            test_iter = iters[2]\n            test_dl = TextDataLoader(test_iter, text_name, label_name)\n        trn_dl = TextDataLoader(trn_iter, text_name, label_name)\n        val_dl = TextDataLoader(val_iter, text_name, label_name)\n        obj = cls.from_dls(path, trn_dl, val_dl, test_dl)\n        obj.bs = bs\n        obj.pad_idx = text_fld.vocab.stoi[text_fld.pad_token]\n        obj.nt = len(text_fld.vocab)\n        obj.c = (len(label_fld.vocab) if hasattr(label_fld, \'vocab\')\n                 else len(getattr(splits[0][0], label_name)))\n        return obj\n\n    def to_model(self, m, opt_fn):\n        model = TextModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    def get_model(self, opt_fn, max_sl, bptt, emb_sz, n_hid, n_layers, dropout, **kwargs):\n        m = get_rnn_classifer(bptt, max_sl, self.c, self.nt,\n              layers=[emb_sz*3, self.c], drops=[dropout],\n              emb_sz=emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=self.pad_idx, **kwargs)\n        return self.to_model(m, opt_fn)\n\n'"
fastai/tutorials/fastai/plots.py,0,"b'from .imports import *\nfrom .torch_imports import *\nfrom sklearn.metrics import confusion_matrix\n\ndef ceildiv(a, b):\n    return -(-a // b)\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None, maintitle=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None:\n        plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else \'none\')\n\n\ndef plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n    """"""Plots images given image files.\n\n    Arguments:\n        im_paths (list): list of paths\n        figsize (tuple): figure size\n        rows (int): number of rows\n        titles (list): list of titles\n        maintitle (string): main title\n    """"""\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(imspaths)):\n        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        img = plt.imread(imspaths[i])\n        plt.imshow(img)\n\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title=\'Confusion matrix\', cmap=plt.cm.Blues, figsize=None):\n    """"""\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    (This function is copied from the scikit docs.)\n    """"""\n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize: cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=""center"", color=""white"" if cm[i, j] > thresh else ""black"")\n\n    plt.tight_layout()\n    plt.ylabel(\'True label\')\n    plt.xlabel(\'Predicted label\')\n\ndef plots_raw(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])\n\ndef load_img_id(ds, idx, path): return np.array(PIL.Image.open(os.path.join(path, ds.fnames[idx])))\n\n\nclass ImageModelResults():\n    """""" Visualize the results of an image model\n\n    Arguments:\n        ds (dataset): a dataset which contains the images\n        log_preds (numpy.ndarray): predictions for the dataset in log scale\n\n    Returns:\n        ImageModelResults\n    """"""\n    def __init__(self, ds, log_preds):\n        """"""Initialize an ImageModelResults class instance""""""\n        self.ds = ds\n        # returns the indices of the maximum value of predictions along axis 1, representing the predicted class\n        # log_preds.shape = (number_of_samples, number_of_classes);\n        # preds.shape = (number_of_samples,)\n        self.preds = np.argmax(log_preds, axis=1)\n        # computes the probabilities\n        self.probs = np.exp(log_preds)\n        # extracts the number of classes\n        self.num_classes = log_preds.shape[1]\n\n    def plot_val_with_title(self, idxs, y):\n        """""" Displays the images and their probabilities of belonging to a certain class\n\n            Arguments:\n                idxs (numpy.ndarray): indexes of the image samples from the dataset\n                y (int): the selected class\n\n            Returns:\n                Plots the images in n rows [rows = n]\n        """"""\n        # if there are any samples to be displayed\n        if len(idxs) > 0:\n            imgs = np.stack([self.ds[x][0] for x in idxs])\n            title_probs = [self.probs[x,y] for x in idxs]\n\n            return plots(self.ds.denorm(imgs), rows=1, titles=title_probs)\n        # if idxs is empty return false\n        else:\n            return False;\n\n    def most_by_mask(self, mask, y, mult):\n        """""" Extracts the first 4 most correct/incorrect indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n                mult (int): sets the ordering; -1 descending, 1 ascending\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        cnt = min(4, len(idxs))\n        return idxs[np.argsort(mult * self.probs[idxs,y])[:cnt]]\n\n    def most_uncertain_by_mask(self, mask, y):\n        """""" Extracts the first 4 most uncertain indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        # the most uncertain samples will have abs(probs-1/num_classes) close to 0;\n        return idxs[np.argsort(np.abs(self.probs[idxs,y]-(1/self.num_classes)))[:4]]\n\n    def most_by_correct(self, y, is_correct):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        # mult=-1 when the is_correct flag is true -> when we want to display the most correct classes we will make a descending sorting (argsort) because we want that the biggest probabilities to be displayed first.\n        # When is_correct is false, we want to display the most incorrect classes, so we want an ascending sorting since our interest is in the smallest probabilities.\n        mult = -1 if is_correct==True else 1\n        return self.most_by_mask(((self.preds == self.ds.y)==is_correct)\n                                 & (self.ds.y == y), y, mult)\n\n    def plot_by_correct(self, y, is_correct):\n        """""" Plots the images which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n        """"""\n        return self.plot_val_with_title(self.most_by_correct(y, is_correct), y)\n\n    def most_by_uncertain(self, y):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and have probabilities nearest to 1/number_of_classes (eg. 0.5 for 2 classes, 0.33 for 3 classes) for the selected class.\n\n            Arguments:\n                y (int): the selected class\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        return self.most_uncertain_by_mask((self.ds.y == y), y)\n\n    def plot_most_correct(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most correct.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, True)\n    def plot_most_incorrect(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most incorrect.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, False)\n    def plot_most_uncertain(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most uncertain i.e have probabilities nearest to 1/number_of_classes.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_val_with_title(self.most_by_uncertain(y), y)\n'"
fastai/tutorials/fastai/rnn_reg.py,16,"b'from .torch_imports import *\nfrom .core import *\nfrom functools import wraps\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef dropout_mask(x, sz, dropout):\n    """""" Applies a dropout mask whose size is determined by passed argument \'sz\'.\n    Args:\n        x (nn.Variable): A torch Variable object\n        sz (tuple(int, int, int)): The expected size of the new tensor\n        dropout (float): The dropout fraction to apply\n\n    This method uses the bernoulli distribution to decide which activations to keep.\n    Additionally, the sampled activations is rescaled is using the factor 1/(1 - dropout).\n\n    In the example given below, one can see that approximately .8 fraction of the\n    returned tensors are zero. Rescaling with the factor 1/(1 - 0.8) returns a tensor\n    with 5\'s in the unit places.\n\n    The official link to the pytorch bernoulli function is here:\n        http://pytorch.org/docs/master/torch.html#torch.bernoulli\n\n    Examples:\n        >>> a_Var = torch.autograd.Variable(torch.Tensor(2, 3, 4).uniform_(0, 1), requires_grad=False)\n        >>> a_Var\n            Variable containing:\n            (0 ,.,.) =\n              0.6890  0.5412  0.4303  0.8918\n              0.3871  0.7944  0.0791  0.5979\n              0.4575  0.7036  0.6186  0.7217\n            (1 ,.,.) =\n              0.8354  0.1690  0.1734  0.8099\n              0.6002  0.2602  0.7907  0.4446\n              0.5877  0.7464  0.4257  0.3386\n            [torch.FloatTensor of size 2x3x4]\n        >>> a_mask = dropout_mask(a_Var.data, (1,a_Var.size(1),a_Var.size(2)), dropout=0.8)\n        >>> a_mask\n            (0 ,.,.) =\n              0  5  0  0\n              0  0  0  5\n              5  0  5  0\n            [torch.FloatTensor of size 1x3x4]\n    """"""\n    return x.new(*sz).bernoulli_(1-dropout)/(1-dropout)\n\n\nclass LockedDropout(nn.Module):\n    def __init__(self, p=0.5):\n        super().__init__()\n        self.p=p\n\n    def forward(self, x):\n        if not self.training or not self.p: return x\n        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n        return Variable(m, requires_grad=False) * x\n\n\nclass WeightDrop(torch.nn.Module):\n    """"""A custom torch layer that serves as a wrapper on another torch layer.\n    Primarily responsible for updating the weights in the wrapped module based\n    on a specified dropout.\n    """"""\n    def __init__(self, module, dropout, weights=[\'weight_hh_l0\']):\n        """""" Default constructor for the WeightDrop module\n\n        Args:\n            module (torch.nn.Module): A pytorch layer being wrapped\n            dropout (float): a dropout value to apply\n            weights (list(str)): the parameters of the wrapped **module**\n                which should be fractionally dropped.\n        """"""\n        super().__init__()\n        self.module,self.weights,self.dropout = module,weights,dropout\n        self._setup()\n\n    def _setup(self):\n        """""" for each string defined in self.weights, the corresponding\n        attribute in the wrapped module is referenced, then deleted, and subsequently\n        registered as a new parameter with a slightly modified name.\n\n        Args:\n            None\n\n         Returns:\n             None\n        """"""\n        if isinstance(self.module, torch.nn.RNNBase): self.module.flatten_parameters = noop\n        for name_w in self.weights:\n            w = getattr(self.module, name_w)\n            del self.module._parameters[name_w]\n            self.module.register_parameter(name_w + \'_raw\', nn.Parameter(w.data))\n\n\n    def _setweights(self):\n        """""" Uses pytorch\'s built-in dropout function to apply dropout to the parameters of\n        the wrapped module.\n\n        Args:\n            None\n        Returns:\n            None\n        """"""\n        for name_w in self.weights:\n            raw_w = getattr(self.module, name_w + \'_raw\')\n            w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n            setattr(self.module, name_w, w)\n\n    def forward(self, *args):\n        """""" updates weights and delegates the propagation of the tensor to the wrapped module\'s\n        forward method\n\n        Args:\n            *args: supplied arguments\n\n        Returns:\n            tensor obtained by running the forward method on the wrapped module.\n        """"""\n        self._setweights()\n        return self.module.forward(*args)\n\nclass EmbeddingDropout(nn.Module):\n\n    """""" Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\n    Uses the dropout_mask custom layer to achieve this.\n\n    Args:\n        embed (torch.nn.Embedding): An embedding torch layer\n        words (torch.nn.Variable): A torch variable\n        dropout (float): dropout fraction to apply to the embedding weights\n        scale (float): additional scaling to apply to the modified embedding weights\n\n    Returns:\n        tensor of size: (batch_size x seq_length x embedding_size)\n\n    Example:\n\n    >> embed = torch.nn.Embedding(10,3)\n    >> words = Variable(torch.LongTensor([[1,2,4,5] ,[4,3,2,9]]))\n    >> words.size()\n        (2,4)\n    >> embed_dropout_layer = EmbeddingDropout(embed)\n    >> dropout_out_ = embed_dropout_layer(embed, words, dropout=0.40)\n    >> dropout_out_\n        Variable containing:\n        (0 ,.,.) =\n          1.2549  1.8230  1.9367\n          0.0000 -0.0000  0.0000\n          2.2540 -0.1299  1.5448\n          0.0000 -0.0000 -0.0000\n\n        (1 ,.,.) =\n          2.2540 -0.1299  1.5448\n         -4.0457  2.4815 -0.2897\n          0.0000 -0.0000  0.0000\n          1.8796 -0.4022  3.8773\n        [torch.FloatTensor of size 2x4x3]\n    """"""\n\n    def __init__(self, embed):\n        super().__init__()\n        self.embed = embed\n\n    def forward(self, words, dropout=0.1, scale=None):\n        if dropout:\n            size = (self.embed.weight.size(0),1)\n            mask = Variable(dropout_mask(self.embed.weight.data, size, dropout))\n            masked_embed_weight = mask * self.embed.weight\n        else: masked_embed_weight = self.embed.weight\n\n        if scale: masked_embed_weight = scale * masked_embed_weight\n\n        padding_idx = self.embed.padding_idx\n        if padding_idx is None: padding_idx = -1\n\n        \n        if IS_TORCH_04:\n            X = F.embedding(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n        else:\n            X = self.embed._backend.Embedding.apply(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n\n        return X\n'"
fastai/tutorials/fastai/rnn_train.py,2,b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom .core import *\n\n'
fastai/tutorials/fastai/set_spawn.py,0,"b""from multiprocessing import set_start_method\nset_start_method('spawn')\n\n"""
fastai/tutorials/fastai/sgdr.py,1,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\nimport copy\n\n\nclass Callback:\n    \'\'\'\n    An abstract class that all callback(e.g., LossRecorder) classes extends from. \n    Must be extended before usage.\n    \'\'\'\n    def on_train_begin(self): pass\n    def on_batch_begin(self): pass\n    def on_phase_begin(self): pass\n    def on_epoch_end(self, metrics): pass\n    def on_phase_end(self): pass\n    def on_batch_end(self, metrics): pass\n    def on_train_end(self): pass\n\n# Useful for maintaining status of a long-running job.\n# \n# Usage:\n# learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\nclass LoggingCallback(Callback):\n    \'\'\'\n    A class useful for maintaining status of a long-running job.\n    e.g.: learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\n    \'\'\'\n    def __init__(self, save_path):\n        super().__init__()\n        self.save_path=save_path\n    def on_train_begin(self):\n        self.batch = 0\n        self.epoch = 0\n        self.phase = 0\n        self.f = open(self.save_path, ""a"", 1)\n        self.log(""\\ton_train_begin"")\n    def on_batch_begin(self):\n        self.log(str(self.batch)+""\\ton_batch_begin"")\n    def on_phase_begin(self):\n        self.log(str(self.phase)+""\\ton_phase_begin"")\n    def on_epoch_end(self, metrics):\n        self.log(str(self.epoch)+""\\ton_epoch_end: ""+str(metrics))\n        self.epoch += 1\n    def on_phase_end(self):\n        self.log(str(self.phase)+""\\ton_phase_end"")\n        self.phase+=1\n    def on_batch_end(self, metrics):\n        self.log(str(self.batch)+""\\ton_batch_end: ""+str(metrics))\n        self.batch += 1\n    def on_train_end(self):\n        self.log(""\\ton_train_end"")\n        self.f.close()\n    def log(self, string):\n        self.f.write(time.strftime(""%Y-%m-%dT%H:%M:%S"")+""\\t""+string+""\\n"")\n        \nclass LossRecorder(Callback):\n    \'\'\'\n    Saves and displays loss functions and other metrics. \n    Default sched when none is specified in a learner. \n    \'\'\'\n    def __init__(self, layer_opt, save_path=\'\', record_mom=False, metrics=[]):\n        super().__init__()\n        self.layer_opt=layer_opt\n        self.init_lrs=np.array(layer_opt.lrs)\n        self.save_path, self.record_mom, self.metrics = save_path, record_mom, metrics\n\n    def on_train_begin(self):\n        self.losses,self.lrs,self.iterations = [],[],[]\n        self.val_losses, self.rec_metrics = [], []\n        if self.record_mom:\n            self.momentums = []\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n        self.save_metrics(metrics)\n\n    def on_batch_end(self, loss):\n        self.iteration += 1\n        self.lrs.append(self.layer_opt.lr)\n        self.iterations.append(self.iteration)\n        if isinstance(loss, list):\n            self.losses.append(loss[0])\n            self.save_metrics(loss[1:])\n        else: self.losses.append(loss)\n        if self.record_mom: self.momentums.append(self.layer_opt.mom)\n\n    def save_metrics(self,vals):\n        self.val_losses.append(vals[0][0] if isinstance(vals[0], Iterable) else vals[0])\n        if len(vals) > 2: self.rec_metrics.append(vals[1:])\n        elif len(vals) == 2: self.rec_metrics.append(vals[1])\n\n    def plot_loss(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        plots loss function as function of iterations. \n        When used in Jupyternotebook, plot will be displayed in notebook. Else, plot will be displayed in console and both plot and loss are saved in save_path. \n        \'\'\'\n        if not in_ipynb(): plt.switch_backend(\'agg\')\n        plt.plot(self.iterations[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'loss_plot.png\'))\n            np.save(os.path.join(self.save_path, \'losses.npy\'), self.losses[10:])\n\n    def plot_lr(self):\n        \'\'\'Plots learning rate in jupyter notebook or console, depending on the enviroment of the learner.\'\'\'\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        if self.record_mom:\n            fig, axs = plt.subplots(1,2,figsize=(12,4))\n            for i in range(0,2): axs[i].set_xlabel(\'iterations\')\n            axs[0].set_ylabel(\'learning rate\')\n            axs[1].set_ylabel(\'momentum\')\n            axs[0].plot(self.iterations,self.lrs)\n            axs[1].plot(self.iterations,self.momentums)   \n        else:\n            plt.xlabel(""iterations"")\n            plt.ylabel(""learning rate"")\n            plt.plot(self.iterations, self.lrs)\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n\n\nclass LR_Updater(LossRecorder):\n    \'\'\'\n    Abstract class where all Learning Rate updaters inherit from. (e.g., CirularLR)\n    Calculates and updates new learning rate and momentum at the end of each batch. \n    Have to be extended. \n    \'\'\'\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n\n    def on_batch_end(self, loss):\n        res = super().on_batch_end(loss)\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n        return res\n\n    def update_lr(self):\n        new_lrs = self.calc_lr(self.init_lrs)\n        self.layer_opt.set_lrs(new_lrs)\n    \n    def update_mom(self):\n        new_mom = self.calc_mom()\n        self.layer_opt.set_mom(new_mom)\n\n    @abstractmethod\n    def calc_lr(self, init_lrs): raise NotImplementedError\n    \n    @abstractmethod\n    def calc_mom(self): raise NotImplementedError\n\n\nclass LR_Finder(LR_Updater):\n    \'\'\'\n    Helps you find an optimal learning rate for a model, as per suggetion of 2015 CLR paper. \n    Learning rate is increased in linear or log scale, depending on user input, and the result of the loss funciton is retained and can be plotted later. \n    \'\'\'\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics = []):\n        self.linear, self.stop_dv = linear, True\n        ratio = end_lr/layer_opt.lr\n        self.lr_mult = (ratio/nb) if linear else ratio**(1/nb)\n        super().__init__(layer_opt,metrics=metrics)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.best=1e9\n\n    def calc_lr(self, init_lrs):\n        mult = self.lr_mult*self.iteration if self.linear else self.lr_mult**self.iteration\n        return init_lrs * mult\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_dv and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        return super().on_batch_end(metrics)\n\n    def plot(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        Plots the loss function with respect to learning rate, in log scale. \n        \'\'\'\n        plt.ylabel(""loss"")\n        plt.xlabel(""learning rate (log scale)"")\n        plt.plot(self.lrs[n_skip:-(n_skip_end+1)], self.losses[n_skip:-(n_skip_end+1)])\n        plt.xscale(\'log\')\n\nclass LR_Finder2(LR_Finder):\n    """"""\n        A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n    """"""\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics=[], stop_dv=True):\n        self.nb, self.metrics = nb, metrics\n        super().__init__(layer_opt, nb, end_lr, linear, metrics)\n        self.stop_dv = stop_dv\n\n    def on_batch_end(self, loss):\n        if self.iteration == self.nb:\n            return True\n        return super().on_batch_end(loss)\n\n    def plot(self, n_skip=10, n_skip_end=5, smoothed=True):\n        if self.metrics is None: self.metrics = []\n        n_plots = len(self.metrics)+2\n        fig, axs = plt.subplots(n_plots,figsize=(6,4*n_plots))\n        for i in range(0,n_plots): axs[i].set_xlabel(\'learning rate\')\n        axs[0].set_ylabel(\'training loss\')\n        axs[1].set_ylabel(\'validation loss\')\n        for i,m in enumerate(self.metrics): \n            axs[i+2].set_ylabel(m.__name__)\n            if len(self.metrics) == 1:\n                values = self.rec_metrics\n            else:\n                values = [rec[i] for rec in self.rec_metrics]\n            if smoothed: values = smooth_curve(values,0.98)\n            axs[i+2].plot(self.lrs[n_skip:-n_skip_end], values[n_skip:-n_skip_end])\n        plt_val_l = smooth_curve(self.val_losses, 0.98) if smoothed else self.val_losses\n        axs[0].plot(self.lrs[n_skip:-n_skip_end],self.losses[n_skip:-n_skip_end])\n        axs[1].plot(self.lrs[n_skip:-n_skip_end],plt_val_l[n_skip:-n_skip_end])\n\nclass CosAnneal(LR_Updater):\n    \'\'\' Learning rate scheduler that inpelements a cosine annealation schedule. \'\'\'\n    def __init__(self, layer_opt, nb, on_cycle_end=None, cycle_mult=1):\n        self.nb,self.on_cycle_end,self.cycle_mult = nb,on_cycle_end,cycle_mult\n        super().__init__(layer_opt)\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.iteration<self.nb/20:\n            self.cycle_iter += 1\n            return init_lrs/100.\n\n        cos_out = np.cos(np.pi*(self.cycle_iter)/self.nb) + 1\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            self.nb *= self.cycle_mult\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return init_lrs / 2 * cos_out\n\n\nclass CircularLR(LR_Updater):\n    \'\'\'\n    An learning rate updater that implements the CirularLearningRate (CLR) scheme. \n    Learning rate is increased then decreased linearly. \n    \'\'\'\n    def __init__(self, layer_opt, nb, div=4, cut_div=8, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.cut_div,self.on_cycle_end = nb,div,cut_div,on_cycle_end\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = 1 - (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = self.cycle_iter/cut_pt\n        res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n    \n    def calc_mom(self):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = 1 - self.cycle_iter/cut_pt\n        res = self.moms[1] + pct * (self.moms[0] - self.moms[1])\n        return res\n\nclass CircularLR_beta(LR_Updater):\n    def __init__(self, layer_opt, nb, div=10, pct=10, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.pct,self.on_cycle_end = nb,div,pct,on_cycle_end\n        self.cycle_nb = int(nb * (1-pct/100) / 2)\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.cycle_iter>2 * self.cycle_nb:\n            pct = (self.cycle_iter - 2*self.cycle_nb)/(self.nb - 2*self.cycle_nb)\n            res = init_lrs * (1 + (pct * (1-100)/100)) / self.div\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n\n    def calc_mom(self):\n        if self.cycle_iter>2*self.cycle_nb:\n            res = self.moms[0]\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        return res\n\n\nclass SaveBestModel(LossRecorder):\n    \n    """""" Save weights of the best model based during training.\n        If metrics are provided, the first metric in the list is used to\n        find the best model. \n        If no metrics are provided, the loss is used.\n        \n        Args:\n            model: the fastai model\n            lr: indicate to use test images; otherwise use validation images\n            name: the name of filename of the weights without \'.h5\'\n        \n        Usage:\n            Briefly, you have your model \'learn\' variable and call fit.\n            >>> learn.fit(lr, 2, cycle_len=2, cycle_mult=1, best_save_name=\'mybestmodel\')\n            ....\n            >>> learn.load(\'mybestmodel\')\n            \n            For more details see http://forums.fast.ai/t/a-code-snippet-to-save-the-best-model-during-training/12066\n \n    """"""\n    def __init__(self, model, layer_opt, metrics, name=\'best_model\'):\n        super().__init__(layer_opt)\n        self.name = name\n        self.model = model\n        self.best_loss = None\n        self.best_acc = None\n        self.save_method = self.save_when_only_loss if metrics==None else self.save_when_acc\n        \n    def save_when_only_loss(self, metrics):\n        loss = metrics[0]\n        if self.best_loss == None or loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n    \n    def save_when_acc(self, metrics):\n        loss, acc = metrics[0], metrics[1]\n        if self.best_acc == None or acc > self.best_acc:\n            self.best_acc = acc\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        elif acc == self.best_acc and  loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        \n    def on_epoch_end(self, metrics):\n        super().on_epoch_end(metrics)\n        self.save_method(metrics)\n\n\nclass WeightDecaySchedule(Callback):\n    def __init__(self, layer_opt, batch_per_epoch, cycle_len, cycle_mult, n_cycles, norm_wds=False, wds_sched_mult=None):\n        """"""\n        Implements the weight decay schedule as mentioned in https://arxiv.org/abs/1711.05101\n\n        :param layer_opt: The LayerOptimizer\n        :param batch_per_epoch: Num batches in 1 epoch\n        :param cycle_len: Num epochs in initial cycle. Subsequent cycle_len = previous cycle_len * cycle_mult\n        :param cycle_mult: Cycle multiplier\n        :param n_cycles: Number of cycles to be executed\n        """"""\n        super().__init__()\n\n        self.layer_opt = layer_opt\n        self.batch_per_epoch = batch_per_epoch\n        self.init_wds = np.array(layer_opt.wds)  # Weights as set by user\n        self.init_lrs = np.array(layer_opt.lrs)  # Learning rates as set by user\n        self.new_wds = None                      # Holds the new weight decay factors, calculated in on_batch_begin()\n        self.param_groups_old = None             # Caches the old parameter values in on_batch_begin()\n        self.iteration = 0\n        self.epoch = 0\n        self.wds_sched_mult = wds_sched_mult\n        self.norm_wds = norm_wds\n        self.wds_history = list()\n\n        # Pre calculating the number of epochs in the cycle of current running epoch\n        self.epoch_to_num_cycles, i = dict(), 0\n        for cycle in range(n_cycles):\n            for _ in range(cycle_len):\n                self.epoch_to_num_cycles[i] = cycle_len\n                i += 1\n            cycle_len *= cycle_mult\n\n    def on_train_begin(self):\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_batch_begin(self):\n        # Prepare for decay of weights\n\n        # Default weight decay (as provided by user)\n        wdn = self.init_wds\n\n        # Weight decay multiplier (The \'eta\' in the paper). Optional.\n        wdm = 1.0\n        if self.wds_sched_mult is not None:\n            wdm = self.wds_sched_mult(self)\n\n        # Weight decay normalized. Optional.\n        if self.norm_wds:\n            wdn = wdn / np.sqrt(self.batch_per_epoch * self.epoch_to_num_cycles[self.epoch])\n\n        # Final wds\n        self.new_wds = wdm * wdn\n\n        # Record the wds\n        self.wds_history.append(self.new_wds)\n\n        # Set weight_decay with zeros so that it is not applied in Adam, we will apply it outside in on_batch_end()\n        self.layer_opt.set_wds(torch.zeros(self.new_wds.size))\n        # We have to save the existing weights before the optimizer changes the values\n        self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n        self.iteration += 1\n\n    def on_batch_end(self, loss):\n        # Decay the weights\n        for group, group_old, wds in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.new_wds):\n            for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                if p.grad is None:\n                    continue\n                p.data = p.data.add(-wds, p_old.data)\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n\nclass DecayType(IntEnum):\n    \'\'\' Data class, each decay type is assigned a number. \'\'\'\n    NO = 1\n    LINEAR = 2\n    COSINE = 3\n    EXPONENTIAL = 4\n    POLYNOMIAL = 5\n\nclass DecayScheduler():\n    \'\'\'Given initial and endvalue, this class generates the next value depending on decay type and number of iterations. (by calling next_val().) \'\'\'\n\n    def __init__(self, dec_type, num_it, start_val, end_val=None, extra=None):\n        self.dec_type, self.nb, self.start_val, self.end_val, self.extra = dec_type, num_it, start_val, end_val, extra\n        self.it = 0\n        if self.end_val is None and not (self.dec_type in [1,4]): self.end_val = 0\n    \n    def next_val(self):\n        self.it += 1\n        if self.dec_type == DecayType.NO:\n            return self.start_val\n        elif self.dec_type == DecayType.LINEAR:\n            pct = self.it/self.nb\n            return self.start_val + pct * (self.end_val-self.start_val)\n        elif self.dec_type == DecayType.COSINE:\n            cos_out = np.cos(np.pi*(self.it)/self.nb) + 1\n            return self.end_val + (self.start_val-self.end_val) / 2 * cos_out\n        elif self.dec_type == DecayType.EXPONENTIAL:\n            ratio = self.end_val / self.start_val\n            return self.start_val * (ratio **  (self.it/self.nb))\n        elif self.dec_type == DecayType.POLYNOMIAL:\n            return self.end_val + (self.start_val-self.end_val) * (1 - self.it/self.nb)**self.extra\n        \n\nclass TrainingPhase():\n    \'\'\'\n    Object with training information for each phase, when multiple phases are involved during training.  \n    Used in fit_opt_sched in learner.py\n    \'\'\'\n    def __init__(self, epochs=1, opt_fn=optim.SGD, lr=1e-2, lr_decay=DecayType.NO, momentum=0.9,\n                momentum_decay=DecayType.NO, beta=None, wds=None, wd_loss=True):\n        """"""\n        Creates an object containing all the relevant informations for one part of a model training.\n\n        Args\n        epochs: number of epochs to train like this\n        opt_fn: an optimizer (example optim.Adam)\n        lr: one learning rate or a tuple of the form (start_lr,end_lr)\n          each of those can be a list/numpy array for differential learning rates\n        lr_decay: a DecayType object specifying how the learning rate should change\n        momentum: one momentum (or beta1 in case of Adam), or a tuple of the form (start_mom,end_mom)\n        momentum_decay: a DecayType object specifying how the momentum should change\n        beta: beta2 parameter of Adam or alpha parameter of RMSProp\n        wds: weight decay (can be an array for differential wds)\n        """"""\n        self.epochs, self.opt_fn, self.lr, self.momentum, self.beta, self.wds = epochs, opt_fn, lr, momentum, beta, wds\n        if isinstance(lr_decay,tuple): self.lr_decay, self.extra_lr = lr_decay\n        else: self.lr_decay, self.extra_lr = lr_decay, None\n        if isinstance(momentum_decay,tuple): self.mom_decay, self.extra_mom = momentum_decay\n        else: self.mom_decay, self.extra_mom = momentum_decay, None\n        self.wd_loss = wd_loss\n\n    def phase_begin(self, layer_opt, nb_batches):\n        self.layer_opt = layer_opt\n        if isinstance(self.lr, tuple): start_lr,end_lr = self.lr\n        else: start_lr, end_lr = self.lr, None\n        self.lr_sched = DecayScheduler(self.lr_decay, nb_batches * self.epochs, start_lr, end_lr, extra=self.extra_lr)\n        if isinstance(self.momentum, tuple): start_mom,end_mom = self.momentum\n        else: start_mom, end_mom = self.momentum, None\n        self.mom_sched = DecayScheduler(self.mom_decay, nb_batches * self.epochs, start_mom, end_mom, extra=self.extra_mom)\n        self.layer_opt.set_opt_fn(self.opt_fn)\n        self.layer_opt.set_lrs(start_lr)\n        self.layer_opt.set_mom(start_mom)\n        if self.beta is not None: self.layer_opt.set_beta(self.beta)\n        if self.wds is not None:\n            if not isinstance(self.wds, Iterable): self.wds=[self.wds]\n            if len(self.wds)==1: self.wds=self.wds*len(self.layer_opt.layer_groups) \n            if self.wd_loss: self.layer_opt.set_wds(self.wds)\n            else: self.layer_opt.set_wds([0] * len(self.wds))\n    \n    def on_batch_begin(self):\n        if not self.wd_loss: self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n\n    def update(self):\n        new_lr, new_mom = self.lr_sched.next_val(), self.mom_sched.next_val()\n        self.layer_opt.set_lrs(new_lr)\n        self.layer_opt.set_mom(new_mom)\n        if not self.wd_loss: # Decay the weights outside of the loss\n            if not isinstance(new_lr, Iterable): new_lr=[new_lr]\n            if len(new_lr)==1: new_lr=new_lr*len(self.layer_opt.layer_groups)\n            for group, group_old, wds, lr in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.wds, new_lr):\n                for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                    if p.grad is None: continue\n                    p.data = p.data.add(-wds*lr, p_old.data)\n    \n\nclass OptimScheduler(LossRecorder):\n    \'\'\'Learning rate Scheduler for training involving multiple phases.\'\'\'\n\n    def __init__(self, layer_opt, phases, nb_batches, stop_div = False):\n        self.phases, self.nb_batches, self.stop_div = phases, nb_batches, stop_div\n        super().__init__(layer_opt, record_mom=True)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.phase,self.best=0,1e9\n    \n    def on_batch_begin(self):\n        self.phases[self.phase].on_batch_begin()\n        super().on_batch_begin()\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_div and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        super().on_batch_end(metrics)\n        self.phases[self.phase].update()\n    \n    def on_phase_begin(self):\n        self.phases[self.phase].phase_begin(self.layer_opt, self.nb_batches)\n\n    def on_phase_end(self):\n        self.phase += 1\n\n    def plot_lr(self, show_text=True, show_moms=True):\n        """"""Plots the lr rate/momentum schedule""""""\n        phase_limits = [0]\n        for phase in self.phases:\n            phase_limits.append(phase_limits[-1] + self.nb_batches * phase.epochs)\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        np_plts = 2 if show_moms else 1\n        fig, axs = plt.subplots(1,np_plts,figsize=(6*np_plts,4))\n        if not show_moms: axs = [axs]\n        for i in range(np_plts): axs[i].set_xlabel(\'iterations\')\n        axs[0].set_ylabel(\'learning rate\')\n        axs[0].plot(self.iterations,self.lrs)\n        if show_moms:\n            axs[1].set_ylabel(\'momentum\')\n            axs[1].plot(self.iterations,self.momentums)\n        if show_text:   \n            for i, phase in enumerate(self.phases):\n                text = phase.opt_fn.__name__\n                if phase.wds is not None: text+=\'\\nwds=\'+str(phase.wds)\n                if phase.beta is not None: text+=\'\\nbeta=\'+str(phase.beta)\n                for k in range(np_plts):\n                    if i < len(self.phases)-1:\n                        draw_line(axs[k], phase_limits[i+1])\n                    draw_text(axs[k], (phase_limits[i]+phase_limits[i+1])/2, text) \n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n    \n    def plot(self, n_skip=10, n_skip_end=5, linear=None):\n        if linear is None: linear = self.phases[-1].lr_decay == DecayType.LINEAR\n        plt.ylabel(""loss"")\n        plt.plot(self.lrs[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if linear: plt.xlabel(""learning rate"")\n        else:\n            plt.xlabel(""learning rate (log scale)"")\n            plt.xscale(\'log\')\n\ndef draw_line(ax,x):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.plot([x,x],[ymin,ymax], color=\'red\', linestyle=\'dashed\')\n\ndef draw_text(ax,x, text):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.text(x,(ymin+ymax)/2,text, horizontalalignment=\'center\', verticalalignment=\'center\', fontsize=14, alpha=0.5)\n\ndef smooth_curve(vals, beta):\n    avg_val = 0\n    smoothed = []\n    for (i,v) in enumerate(vals):\n        avg_val = beta * avg_val + (1-beta) * v\n        smoothed.append(avg_val/(1-beta**(i+1)))\n    return smoothed\n'"
fastai/tutorials/fastai/structured.py,0,"b'from .imports import *\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\n\ndef set_plot_sizes(sml, med, big):\n    plt.rc(\'font\', size=sml)          # controls default text sizes\n    plt.rc(\'axes\', titlesize=sml)     # fontsize of the axes title\n    plt.rc(\'axes\', labelsize=med)    # fontsize of the x and y labels\n    plt.rc(\'xtick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'ytick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'legend\', fontsize=sml)    # legend fontsize\n    plt.rc(\'figure\', titlesize=big)  # fontsize of the figure title\n\ndef parallel_trees(m, fn, n_jobs=8):\n        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    """""" Draws a representation of a random forest in IPython.\n\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    """"""\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub(\'Tree {\',\n       f\'Tree {{ size={size}; ratio={ratio}\', s)))\n\ndef combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = (\'<M8[Y]\', \'<m8[M]\', \'<m8[D]\', \'<m8[W]\', \'<m8[h]\',\n             \'<m8[m]\', \'<m8[s]\', \'<m8[ms]\', \'<m8[us]\', \'<m8[ns]\')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\ndef get_sample(df,n):\n    """""" Gets a random sample of n rows from df, without replacement.\n\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    >>> get_sample(df, 2)\n       col1 col2\n    1     2    b\n    2     3    a\n    """"""\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef add_datepart(df, fldname, drop=True, time=False):\n    """"""add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({ \'A\' : pd.to_datetime([\'3/11/2000\', \'3/12/2000\', \'3/13/2000\'], infer_datetime_format=False) })\n    >>> df\n\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n\n    >>> add_datepart(df, \'A\')\n    >>> df\n\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    """"""\n    fld = df[fldname]\n    if not np.issubdtype(fld.dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub(\'[Dd]ate$\', \'\', fldname)\n    attr = [\'Year\', \'Month\', \'Week\', \'Day\', \'Dayofweek\', \'Dayofyear\',\n            \'Is_month_end\', \'Is_month_start\', \'Is_quarter_end\', \'Is_quarter_start\', \'Is_year_end\', \'Is_year_start\']\n    if time: attr = attr + [\'Hour\', \'Minute\', \'Second\']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + \'Elapsed\'] = fld.astype(np.int64) // 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n\ndef is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n\ndef train_cats(df):\n    """"""Change any columns of strings in a panda\'s dataframe to a column of\n    catagorical values. This applies the changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category\n    """"""\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype(\'category\').cat.as_ordered()\n\ndef apply_cats(df, trn):\n    """"""Changes any columns of strings in df into categorical variables using trn as\n    a template for the category codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values. The category codes are determined by trn.\n\n    trn: A pandas dataframe. When creating a category for df, it looks up the\n        what the category\'s code were in trn and makes those the category codes\n        for df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category {a : 1, b : 2}\n\n    >>> df2 = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'b\', \'a\', \'a\']})\n    >>> apply_cats(df2, df)\n\n           col1 col2\n        0     1    b\n        1     2    a\n        2     3    a\n\n    now the type of col is category {a : 1, b : 2}\n    """"""\n    for n,c in df.items():\n        if (n in trn.columns) and (trn[n].dtype.name==\'category\'):\n            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n\ndef fix_missing(df, col, name, na_dict):\n    """""" Fill missing data in a column of df with the median, and add a {name}_na column\n    which specifies if the data was missing.\n\n    Parameters:\n    -----------\n    df: The data frame that will be changed.\n\n    col: The column of data to fix by filling in missing data.\n\n    name: The name of the new filled column in df.\n\n    na_dict: A dictionary of values to create na\'s of and the value to insert. If\n        name is not a key of na_dict the median will fill any missing data. Also\n        if name is not a key of na_dict and there is no missing data in col, then\n        no {name}_na column is not created.\n\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1     2    2    True\n    2     3    2   False\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col2\'], \'col2\', {})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {\'col1\' : 500})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1   500    2    True\n    2     3    2   False\n    """"""\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+\'_na\'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    """""" Changes the column col from a categorical type to it\'s integer codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. df[name] will be filled with the integer codes from\n        col.\n\n    col: The column you wish to change into the categories.\n    name: The column name you wish to insert into df. This column will hold the\n        integer codes.\n\n    max_n_cat: If col has more categories than max_n_cat it will not change the\n        it to its integer codes. If max_n_cat is None, then col will always be\n        converted.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> numericalize(df, df[\'col2\'], \'col3\', None)\n\n       col1 col2 col3\n    0     1    a    1\n    1     2    b    2\n    2     3    a    1\n    """"""\n    if not is_numeric_dtype(col) and ( max_n_cat is None or col.nunique()>max_n_cat):\n        df[name] = col.cat.codes+1\n\ndef scale_vars(df, mapper):\n    warnings.filterwarnings(\'ignore\', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper\n\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    """""" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n\n    y_fld: The name of the response variable\n\n    skip_flds: A list of fields that dropped from df.\n\n    ignore_flds: A list of fields that are ignored during processing.\n\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n\n    preproc_fn: A function that gets applied to df.\n\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n\n    subset: Takes a random subset of size subset from df.\n\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n\n        y: y is the response variable\n\n        nas: returns a dictionary of which nas it created, and the associated median.\n\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> x, y, nas = proc_df(df, \'col1\')\n    >>> x\n\n       col2\n    0     1\n    1     2\n    2     1\n\n    >>> data = DataFrame(pet=[""cat"", ""dog"", ""dog"", ""fish"", ""cat"", ""dog"", ""cat"", ""fish""],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    """"""\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    df = df.copy()\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({\'cols\':df.columns, \'imp\':m.feature_importances_}\n                       ).sort_values(\'imp\', ascending=False)\n\ndef set_rf_samples(n):\n    """""" Changes Scikit learn\'s random forests to give each tree a random sample of\n    n random rows.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    """""" Undoes the changes produced by set_rf_samples.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\ndef get_nn_mappers(df, cat_vars, contin_vars):\n    # Replace nulls with 0 for continuous, """" for categorical.\n    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n    for v in cat_vars: df[v].fillna(\'#NA#\', inplace=True)\n\n    # list of tuples, containing variable and instance of a transformer for that variable\n    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n    return DataFrameMapper(cat_maps).fit(df), DataFrameMapper(contin_maps).fit(df)\n'"
fastai/tutorials/fastai/swa.py,3,"b'""""""\n    From the paper:\n        Averaging Weights Leads to Wider Optima and Better Generalization\n        Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, Andrew Gordon Wilson\n        https://arxiv.org/abs/1803.05407\n        2018\n        \n    Author\'s implementation: https://github.com/timgaripov/swa\n""""""\n\nimport torch\nfrom .sgdr import *\nfrom .core import *\n\n\nclass SWA(Callback):\n    def __init__(self, model, swa_model, swa_start):\n        super().__init__()\n        self.model,self.swa_model,self.swa_start=model,swa_model,swa_start\n        \n    def on_train_begin(self):\n        self.epoch = 0\n        self.swa_n = 0\n\n    def on_epoch_end(self, metrics):\n        if (self.epoch + 1) >= self.swa_start:\n            self.update_average_model()\n            self.swa_n += 1\n            \n        self.epoch += 1\n            \n    def update_average_model(self):\n        # update running average of parameters\n        model_params = self.model.parameters()\n        swa_params = self.swa_model.parameters()\n        for model_param, swa_param in zip(model_params, swa_params):\n            swa_param.data *= self.swa_n\n            swa_param.data += model_param.data\n            swa_param.data /= (self.swa_n + 1)            \n    \ndef collect_bn_modules(module, bn_modules):\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        bn_modules.append(module)\n\ndef fix_batchnorm(swa_model, train_dl):\n    """"""\n    During training, batch norm layers keep track of a running mean and\n    variance of the previous layer\'s activations. Because the parameters\n    of the SWA model are computed as the average of other models\' parameters,\n    the SWA model never sees the training data itself, and therefore has no\n    opportunity to compute the correct batch norm statistics. Before performing \n    inference with the SWA model, we perform a single pass over the training data\n    to calculate an accurate running mean and variance for each batch norm layer.\n    """"""\n    bn_modules = []\n    swa_model.apply(lambda module: collect_bn_modules(module, bn_modules))\n    \n    if not bn_modules: return\n\n    swa_model.train()\n\n    for module in bn_modules:\n        module.running_mean = torch.zeros_like(module.running_mean)\n        module.running_var = torch.ones_like(module.running_var)\n    \n    momenta = [m.momentum for m in bn_modules]\n\n    inputs_seen = 0\n\n    for (*x,y) in iter(train_dl):        \n        xs = V(x)\n        batch_size = xs[0].size(0)\n\n        momentum = batch_size / (inputs_seen + batch_size)\n        for module in bn_modules:\n            module.momentum = momentum\n                            \n        res = swa_model(*xs)        \n        \n        inputs_seen += batch_size\n                \n    for module, momentum in zip(bn_modules, momenta):\n        module.momentum = momentum    '"
fastai/tutorials/fastai/text.py,1,"b'from .core import *\nfrom .learner import *\nfrom .lm_rnn import *\nfrom torch.utils.data.sampler import Sampler\nimport spacy\nfrom spacy.symbols import ORTH\n\nre_tok = re.compile(f\'([{string.punctuation}\xe2\x80\x9c\xe2\x80\x9d\xc2\xa8\xc2\xab\xc2\xbb\xc2\xae\xc2\xb4\xc2\xb7\xc2\xba\xc2\xbd\xc2\xbe\xc2\xbf\xc2\xa1\xc2\xa7\xc2\xa3\xe2\x82\xa4\xe2\x80\x98\xe2\x80\x99])\')\ndef tokenize(s): return re_tok.sub(r\' \\1 \', s).split()\n\ndef texts_labels_from_folders(path, folders):\n    texts,labels = [],[]\n    for idx,label in enumerate(folders):\n        for fname in glob(os.path.join(path, label, \'*.*\')):\n            texts.append(open(fname, \'r\').read())\n            labels.append(idx)\n    return texts, np.array(labels).astype(np.int64)\n\ndef numericalize_tok(tokens, max_vocab=50000, min_freq=0, unk_tok=""_unk_"", pad_tok=""_pad_"", bos_tok=""_bos_"", eos_tok=""_eos_""):\n    """"""Takes in text tokens and returns int2tok and tok2int converters\n\n        Arguments:\n        tokens(list): List of tokens. Can be a list of strings, or a list of lists of strings.\n        max_vocab(int): Number of tokens to return in the vocab (sorted by frequency)\n        min_freq(int): Minimum number of instances a token must be present in order to be preserved.\n        unk_tok(str): Token to use when unknown tokens are encountered in the source text.\n        pad_tok(str): Token to use when padding sequences.\n    """"""\n    if isinstance(tokens, str):\n        raise ValueError(""Expected to receive a list of tokens. Received a string instead"")\n    if isinstance(tokens[0], list):\n        tokens = [p for o in tokens for p in o]\n    freq = Counter(tokens)\n    int2tok = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n    unk_id = 3\n    int2tok.insert(0, bos_tok)\n    int2tok.insert(1, pad_tok)\n    int2tok.insert(2, eos_tok)\n    int2tok.insert(unk_id, unk_tok)\n    tok2int = collections.defaultdict(lambda:unk_id, {v:k for k,v in enumerate(int2tok)})\n    return int2tok, tok2int\n\nclass Tokenizer():\n    def __init__(self, lang=\'en\'):\n        self.re_br = re.compile(r\'<\\s*br\\s*/?>\', re.IGNORECASE)\n        self.tok = spacy.load(lang)\n        for w in (\'<eos>\',\'<bos>\',\'<unk>\'):\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\n\n    def sub_br(self,x): return self.re_br.sub(""\\n"", x)\n\n    def spacy_tok(self,x):\n        return [t.text for t in self.tok.tokenizer(self.sub_br(x))]\n\n    re_rep = re.compile(r\'(\\S)(\\1{3,})\')\n    re_word_rep = re.compile(r\'(\\b\\w+\\W+)(\\1{3,})\')\n\n    @staticmethod\n    def replace_rep(m):\n        TK_REP = \'tk_rep\'\n        c,cc = m.groups()\n        return f\' {TK_REP} {len(cc)+1} {c} \'\n\n    @staticmethod\n    def replace_wrep(m):\n        TK_WREP = \'tk_wrep\'\n        c,cc = m.groups()\n        return f\' {TK_WREP} {len(cc.split())+1} {c} \'\n\n    @staticmethod\n    def do_caps(ss):\n        TOK_UP,TOK_SENT,TOK_MIX = \' t_up \',\' t_st \',\' t_mx \'\n        res = []\n        prev=\'.\'\n        re_word = re.compile(\'\\w\')\n        re_nonsp = re.compile(\'\\S\')\n        for s in re.findall(r\'\\w+|\\W+\', ss):\n            res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n    #                 else [TOK_SENT,s.lower()] if (s.istitle() and re_word.search(prev))\n                    else [s.lower()])\n    #         if re_nonsp.search(s): prev = s\n        return \'\'.join(res)\n\n    def proc_text(self, s):\n        s = self.re_rep.sub(Tokenizer.replace_rep, s)\n        s = self.re_word_rep.sub(Tokenizer.replace_wrep, s)\n        s = Tokenizer.do_caps(s)\n        s = re.sub(r\'([/#])\', r\' \\1 \', s)\n        s = re.sub(\' {2,}\', \' \', s)\n        return self.spacy_tok(s)\n\n    @staticmethod\n    def proc_all(ss, lang):\n        tok = Tokenizer(lang)\n        return [tok.proc_text(s) for s in ss]\n\n    @staticmethod\n    def proc_all_mp(ss, lang=\'en\'):\n        ncpus = num_cpus()//2\n        with ProcessPoolExecutor(ncpus) as e:\n            return sum(e.map(Tokenizer.proc_all, ss, [lang]*len(ss)), [])\n\n\nclass TextDataset(Dataset):\n    def __init__(self, x, y, backwards=False, sos=None, eos=None):\n        self.x,self.y,self.backwards,self.sos,self.eos = x,y,backwards,sos,eos\n\n    def __getitem__(self, idx):\n        x = self.x[idx]\n        if self.backwards: x = list(reversed(x))\n        if self.eos is not None: x = x + [self.eos]\n        if self.sos is not None: x = [self.sos]+x\n        return np.array(x),self.y[idx]\n\n    def __len__(self): return len(self.x)\n\n\nclass SortSampler(Sampler):\n    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n    def __len__(self): return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range(len(self.data_source)), key=self.key, reverse=True))\n\n\nclass SortishSampler(Sampler):\n    """"""Returns an iterator that traverses the the data in randomly ordered batches that are approximately the same size.\n    The max key size batch is always returned in the first call because of pytorch cuda memory allocation sequencing.\n    Without that max key returned first multiple buffers may be allocated when the first created isn\'t large enough\n    to hold the next in the sequence.\n    """"""\n    def __init__(self, data_source, key, bs):\n        self.data_source,self.key,self.bs = data_source,key,bs\n\n    def __len__(self): return len(self.data_source)\n\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs*50\n        ck_idx = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n        sort_idx = np.concatenate([sorted(s, key=self.key, reverse=True) for s in ck_idx])\n        sz = self.bs\n        ck_idx = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n        max_ck = np.argmax([ck[0] for ck in ck_idx])  # find the chunk with the largest key,\n        ck_idx[0],ck_idx[max_ck] = ck_idx[max_ck],ck_idx[0]  # then make sure it goes first.\n        sort_idx = np.concatenate(np.random.permutation(ck_idx[1:]))\n        sort_idx = np.concatenate((ck_idx[0], sort_idx))\n        return iter(sort_idx)\n\n\nclass LanguageModelLoader():\n    """""" Returns a language model iterator that iterates through batches that are of length N(bptt,5)\n    The first batch returned is always bptt+25; the max possible width.  This is done because of they way that pytorch\n    allocates cuda memory in order to prevent multiple buffers from being created as the batch width grows.\n    """"""\n    def __init__(self, nums, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        while self.i < self.n-1 and self.iter<len(self):\n            if self.i == 0:\n                seq_len = self.bptt + 5 * 5\n            else:\n                bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n                seq_len = max(5, int(np.random.normal(bptt, 5)))\n            res = self.get_batch(self.i, seq_len)\n            self.i += seq_len\n            self.iter += 1\n            yield res\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def batchify(self, data):\n        nb = data.shape[0] // self.bs\n        data = np.array(data[:nb*self.bs])\n        data = data.reshape(self.bs, -1).T\n        if self.backwards: data=data[::-1]\n        return T(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass LanguageModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [*zip(m.rnns, m.dropouths), (self.model[1], m.dropouti)]\n\n\nclass LanguageModelData():\n    def __init__(self, path, pad_idx, n_tok, trn_dl, val_dl, test_dl=None, **kwargs):\n        self.path,self.pad_idx,self.n_tok = path,pad_idx,n_tok\n        self.trn_dl,self.val_dl,self.test_dl = trn_dl,val_dl,test_dl\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        m = get_language_model(self.n_tok, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = LanguageModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n'"
fastai/tutorials/fastai/torch_imports.py,6,"b'import os\nimport torch, torchvision, torchtext\nfrom torch import nn, cuda, backends, FloatTensor, LongTensor, optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.nn.init import kaiming_uniform, kaiming_normal\nfrom torchvision.transforms import Compose\nfrom torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\nfrom torchvision.models import vgg16_bn, vgg19_bn\nfrom torchvision.models import densenet121, densenet161, densenet169, densenet201\n\nfrom .models.resnext_50_32x4d import resnext_50_32x4d\nfrom .models.resnext_101_32x4d import resnext_101_32x4d\nfrom .models.resnext_101_64x4d import resnext_101_64x4d\nfrom .models.wrn_50_2f import wrn_50_2f\nfrom .models.inceptionresnetv2 import InceptionResnetV2\nfrom .models.inceptionv4 import inceptionv4\nfrom .models.nasnet import nasnetalarge\nfrom .models.fa_resnet import *\n\nimport warnings\nwarnings.filterwarnings(\'ignore\', message=\'Implicit dimension choice\', category=UserWarning)\n\ndef children(m): return m if isinstance(m, (list, tuple)) else list(m.children())\ndef save_model(m, p): torch.save(m.state_dict(), p)\ndef load_model(m, p): m.load_state_dict(torch.load(p, map_location=lambda storage, loc: storage))\n\ndef load_pre(pre, f, fn):\n    m = f()\n    path = os.path.dirname(__file__)\n    if pre: load_model(m, f\'{path}/weights/{fn}.pth\')\n    return m\n\ndef _fastai_model(name, paper_title, paper_href):\n    def add_docs_wrapper(f):\n        f.__doc__ = f""""""{name} model from\n        `""{paper_title}"" <{paper_href}>`_\n\n        Args:\n           pre (bool): If True, returns a model pre-trained on ImageNet\n        """"""\n        return f\n    return add_docs_wrapper\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inception_4(pre): return children(inceptionv4(pretrained=pre))[0]\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inceptionresnet_2(pre): return load_pre(pre, InceptionResnetV2, \'inceptionresnetv2-d579a627\')\n\n@_fastai_model(\'ResNeXt 50\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext50(pre): return load_pre(pre, resnext_50_32x4d, \'resnext_50_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_32\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101(pre): return load_pre(pre, resnext_101_32x4d, \'resnext_101_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_64\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101_64(pre): return load_pre(pre, resnext_101_64x4d, \'resnext_101_64x4d\')\n\n@_fastai_model(\'Wide Residual Networks\', \'Wide Residual Networks\',\n               \'https://arxiv.org/pdf/1605.07146.pdf\')\ndef wrn(pre): return load_pre(pre, wrn_50_2f, \'wrn_50_2f\')\n\n@_fastai_model(\'Densenet-121\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn121(pre): return children(densenet121(pre))[0]\n\n@_fastai_model(\'Densenet-169\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn161(pre): return children(densenet161(pre))[0]\n\n@_fastai_model(\'Densenet-161\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn169(pre): return children(densenet169(pre))[0]\n\n@_fastai_model(\'Densenet-201\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn201(pre): return children(densenet201(pre))[0]\n\n@_fastai_model(\'Vgg-16 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg16(pre): return children(vgg16_bn(pre))[0]\n\n@_fastai_model(\'Vgg-19 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg19(pre): return children(vgg19_bn(pre))[0]\n\n'"
fastai/tutorials/fastai/transforms.py,0,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\n\ndef scale_min(im, targ, interpolation=cv2.INTER_AREA):\n    """""" Scales the image so that the smallest axis is of size targ.\n\n    Arguments:\n        im (array): image\n        targ (int): target size\n    """"""\n    r,c,*_ = im.shape\n    ratio = targ/min(r,c)\n    sz = (scale_to(c, ratio, targ), scale_to(r, ratio, targ))\n    return cv2.resize(im, sz, interpolation=interpolation)\n\ndef zoom_cv(x,z):\n    \'\'\'zooms the center of image x, by a factor of z+1 while retaining the origal image size and proportion. \'\'\'\n    if z==0: return x\n    r,c,*_ = x.shape\n    M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)\n    return cv2.warpAffine(x,M,(c,r))\n\ndef stretch_cv(x,sr,sc,interpolation=cv2.INTER_AREA):\n    \'\'\'stretches image x horizontally by sr+1, and vertically by sc+1 while retaining the origal image size and proportion.\'\'\'\n    if sr==0 and sc==0: return x\n    r,c,*_ = x.shape\n    x = cv2.resize(x, None, fx=sr+1, fy=sc+1, interpolation=interpolation)\n    nr,nc,*_ = x.shape\n    cr = (nr-r)//2; cc = (nc-c)//2\n    return x[cr:r+cr, cc:c+cc]\n\ndef dihedral(x, dih):\n    \'\'\'performs any of 8 90 rotations or flips for image x.\n    \'\'\'\n    x = np.rot90(x, dih%4)\n    return x if dih<4 else np.fliplr(x)\n\ndef lighting(im, b, c):\n    \'\'\' adjusts image\'s balance and contrast\'\'\'\n    if b==0 and c==1: return im\n    mu = np.average(im)\n    return np.clip((im-mu)*c+mu+b,0.,1.).astype(np.float32)\n\ndef rotate_cv(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n    """""" Rotates an image by deg degrees\n\n    Arguments:\n        deg (float): degree to rotate.\n    """"""\n    r,c,*_ = im.shape\n    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n\ndef no_crop(im, min_sz=None, interpolation=cv2.INTER_AREA):\n    """""" Returns a squared resized image """"""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    return cv2.resize(im, (min_sz, min_sz), interpolation=interpolation)\n\ndef center_crop(im, min_sz=None):\n    """""" Returns a center crop of an image""""""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    start_r = math.ceil((r-min_sz)/2)\n    start_c = math.ceil((c-min_sz)/2)\n    return crop(im, start_r, start_c, min_sz)\n\ndef googlenet_resize(im, targ, min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p, interpolation=cv2.INTER_AREA):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ\n    \n    References:\n    1. https://arxiv.org/pdf/1409.4842.pdf\n    2. https://arxiv.org/pdf/1802.07888.pdf\n    """"""\n    h,w,*_ = im.shape\n    area = h*w\n    for _ in range(10):\n        targetArea = random.uniform(min_area_frac, 1.0) * area\n        aspectR = random.uniform(min_aspect_ratio, max_aspect_ratio)\n        ww = int(np.sqrt(targetArea * aspectR) + 0.5)\n        hh = int(np.sqrt(targetArea / aspectR) + 0.5)\n        if flip_hw_p:\n            ww, hh = hh, ww\n        if hh <= h and ww <= w:\n            x1 = 0 if w == ww else random.randint(0, w - ww)\n            y1 = 0 if h == hh else random.randint(0, h - hh)\n            out = im[y1:y1 + hh, x1:x1 + ww]\n            out = cv2.resize(out, (targ, targ), interpolation=interpolation)\n            return out\n    out = scale_min(im, targ, interpolation=interpolation)\n    out = center_crop(out)\n    return out\n\ndef cutout(im, n_holes, length):\n    \'\'\' cuts out n_holes number of square holes of size length in image at random locations. holes may be overlapping. \'\'\'\n    r,c,*_ = im.shape\n    mask = np.ones((r, c), np.int32)\n    for n in range(n_holes):\n        y = np.random.randint(length / 2, r - length / 2)\n        x = np.random.randint(length / 2, c - length / 2)\n\n        y1 = int(np.clip(y - length / 2, 0, r))\n        y2 = int(np.clip(y + length / 2, 0, r))\n        x1 = int(np.clip(x - length / 2, 0, c))\n        x2 = int(np.clip(x + length / 2, 0, c))\n        mask[y1: y2, x1: x2] = 0.\n    \n    mask = mask[:,:,None]\n    im = im * mask\n    return im\n\ndef scale_to(x, ratio, targ): \n    \'\'\'Calculate dimension of an image during scaling with aspect ratio\'\'\'\n    return max(math.floor(x*ratio), targ)\n\ndef crop(im, r, c, sz): \n    \'\'\'\n    crop image into a square of size sz, \n    \'\'\'\n    return im[r:r+sz, c:c+sz]\n\ndef det_dihedral(dih): return lambda x: dihedral(x, dih)\ndef det_stretch(sr, sc): return lambda x: stretch_cv(x, sr, sc)\ndef det_lighting(b, c): return lambda x: lighting(x, b, c)\ndef det_rotate(deg): return lambda x: rotate_cv(x, deg)\ndef det_zoom(zoom): return lambda x: zoom_cv(x, zoom)\n\ndef rand0(s): return random.random()*(s*2)-s\n\n\nclass TfmType(IntEnum):\n    """""" Type of transformation.\n    Parameters\n        IntEnum: predefined types of transformations\n            NO:    the default, y does not get transformed when x is transformed.\n            PIXEL: x and y are images and should be transformed in the same way.\n                   Example: image segmentation.\n            COORD: y are coordinates (i.e bounding boxes)\n            CLASS: y are class labels (same behaviour as PIXEL, except no normalization)\n    """"""\n    NO = 1\n    PIXEL = 2\n    COORD = 3\n    CLASS = 4\n\n\nclass Denormalize():\n    """""" De-normalizes an image, returning it to original format.\n    """"""\n    def __init__(self, m, s):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n    def __call__(self, x): return x*self.s+self.m\n\n\nclass Normalize():\n    """""" Normalizes an image to zero mean and unit standard deviation, given the mean m and std s of the original image """"""\n    def __init__(self, m, s, tfm_y=TfmType.NO):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n        self.tfm_y=tfm_y\n\n    def __call__(self, x, y=None):\n        x = (x-self.m)/self.s\n        if self.tfm_y==TfmType.PIXEL and y is not None: y = (y-self.m)/self.s\n        return x,y\n\nclass ChannelOrder():\n    \'\'\'\n    changes image array shape from (h, w, 3) to (3, h, w). \n    tfm_y decides the transformation done to the y element. \n    \'\'\'\n    def __init__(self, tfm_y=TfmType.NO): self.tfm_y=tfm_y\n\n    def __call__(self, x, y):\n        x = np.rollaxis(x, 2)\n        #if isinstance(y,np.ndarray) and (len(y.shape)==3):\n        if self.tfm_y==TfmType.PIXEL: y = np.rollaxis(y, 2)\n        elif self.tfm_y==TfmType.CLASS: y = y[...,0]\n        return x,y\n\n\ndef to_bb(YY, y=""deprecated""):\n    """"""Convert mask YY to a bounding box, assumes 0 as background nonzero object""""""\n    cols,rows = np.nonzero(YY)\n    if len(cols)==0: return np.zeros(4, dtype=np.float32)\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n\ndef coords2px(y, x):\n    """""" Transforming coordinates to pixels.\n\n    Arguments:\n        y : np array\n            vector in which (y[0], y[1]) and (y[2], y[3]) are the\n            the corners of a bounding box.\n        x : image\n            an image\n    Returns:\n        Y : image\n            of shape x.shape\n    """"""\n    rows = np.rint([y[0], y[0], y[2], y[2]]).astype(int)\n    cols = np.rint([y[1], y[3], y[1], y[3]]).astype(int)\n    r,c,*_ = x.shape\n    Y = np.zeros((r, c))\n    Y[rows, cols] = 1\n    return Y\n\n\nclass Transform():\n    """""" A class that represents a transform.\n\n    All other transforms should subclass it. All subclasses should override\n    do_transform.\n\n    Arguments\n    ---------\n        tfm_y : TfmType\n            type of transform\n    """"""\n    def __init__(self, tfm_y=TfmType.NO):\n        self.tfm_y=tfm_y\n        self.store = threading.local()\n\n    def set_state(self): pass\n    def __call__(self, x, y):\n        self.set_state()\n        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n                else self.transform_coord(x,y))\n        return x, y\n\n    def transform_coord(self, x, y): return self.transform(x),y\n\n    def transform(self, x, y=None):\n        x = self.do_transform(x,False)\n        return (x, self.do_transform(y,True)) if y is not None else x\n\n    @abstractmethod\n    def do_transform(self, x, is_y): raise NotImplementedError\n\n\nclass CoordTransform(Transform):\n    """""" A coordinate transform.  """"""\n\n    @staticmethod\n    def make_square(y, x):\n        r,c,*_ = x.shape\n        y1 = np.zeros((r, c))\n        y = y.astype(np.int)\n        y1[y[0]:y[2], y[1]:y[3]] = 1.\n        return y1\n\n    def map_y(self, y0, x):\n        y = CoordTransform.make_square(y0, x)\n        y_tr = self.do_transform(y, True)\n        return to_bb(y_tr)\n\n    def transform_coord(self, x, ys):\n        yp = partition(ys, 4)\n        y2 = [self.map_y(y,x) for y in yp]\n        x = self.do_transform(x, False)\n        return x, np.concatenate(y2)\n\n\nclass AddPadding(CoordTransform):\n    """""" A class that represents adding paddings to an image.\n\n    The default padding is border_reflect\n    Arguments\n    ---------\n        pad : int\n            size of padding on top, bottom, left and right\n        mode:\n            type of cv2 padding modes. (e.g., constant, reflect, wrap, replicate. etc. )\n    """"""\n    def __init__(self, pad, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.pad,self.mode = pad,mode\n\n    def do_transform(self, im, is_y):\n        return cv2.copyMakeBorder(im, self.pad, self.pad, self.pad, self.pad, self.mode)\n\nclass CenterCrop(CoordTransform):\n    """""" A class that represents a Center Crop.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        sz: int\n            size of the crop.\n        tfm_y : TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.min_sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        return center_crop(x, self.sz_y if is_y else self.min_sz)\n\n\nclass RandomCrop(CoordTransform):\n    """""" A class that represents a Random Crop transformation.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        targ: int\n            target size of the crop.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, targ_sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz,self.sz_y = targ_sz,sz_y\n\n    def set_state(self):\n        self.store.rand_r = random.uniform(0, 1)\n        self.store.rand_c = random.uniform(0, 1)\n\n    def do_transform(self, x, is_y):\n        r,c,*_ = x.shape\n        sz = self.sz_y if is_y else self.targ_sz\n        start_r = np.floor(self.store.rand_r*(r-sz)).astype(int)\n        start_c = np.floor(self.store.rand_c*(c-sz)).astype(int)\n        return crop(x, start_r, start_c, sz)\n\n\nclass NoCrop(CoordTransform):\n    """"""  A transformation that resize to a square image without cropping.\n\n    This transforms (optionally) resizes x,y at with the same parameters.\n    Arguments:\n        targ: int\n            target size of the crop.\n        tfm_y (TfmType): type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return no_crop(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return no_crop(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass Scale(CoordTransform):\n    """""" A transformation that scales the min size to sz.\n\n    Arguments:\n        sz: int\n            target size to scale minimum size.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass RandomScale(CoordTransform):\n    """""" Scales an image so that the min size is a random number between [sz, sz*max_zoom]\n\n    This transforms (optionally) scales x,y at with the same parameters.\n    Arguments:\n        sz: int\n            target size\n        max_zoom: float\n            float >= 1.0\n        p : float\n            a probability for doing the random sizing\n        tfm_y: TfmType\n            type of y transform\n    """"""\n    def __init__(self, sz, max_zoom, p=0.75, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.max_zoom,self.p,self.sz_y = sz,max_zoom,p,sz_y\n\n    def set_state(self):\n        min_z = 1.\n        max_z = self.max_zoom\n        if isinstance(self.max_zoom, collections.Iterable):\n            min_z, max_z = self.max_zoom\n        self.store.mult = random.uniform(min_z, max_z) if random.random()<self.p else 1\n        self.store.new_sz = int(self.store.mult*self.sz)\n        if self.sz_y is not None: self.store.new_sz_y = int(self.store.mult*self.sz_y)\n\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.store.new_sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.store.new_sz,   cv2.INTER_AREA   )\n\n\nclass RandomRotate(CoordTransform):\n    """""" Rotates images and (optionally) target y.\n\n    Rotating coordinates is treated differently for x and y on this\n    transform.\n     Arguments:\n        deg (float): degree to rotate.\n        p (float): probability of rotation\n        mode: type of border\n        tfm_y (TfmType): type of y transform\n    """"""\n    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.deg,self.p = deg,p\n        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n            self.modes = (mode,cv2.BORDER_CONSTANT)\n        else:\n            self.modes = (mode,mode)\n\n    def set_state(self):\n        self.store.rdeg = rand0(self.deg)\n        self.store.rp = random.random()<self.p\n\n    def do_transform(self, x, is_y):\n        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n                mode= self.modes[1] if is_y else self.modes[0],\n                interpolation=cv2.INTER_NEAREST if is_y else cv2.INTER_AREA)\n        return x\n\n\nclass RandomDihedral(CoordTransform):\n    """"""\n    Rotates images by random multiples of 90 degrees and/or reflection.\n    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n    """"""\n    def set_state(self):\n        self.store.rot_times = random.randint(0,3)\n        self.store.do_flip = random.random()<0.5\n\n    def do_transform(self, x, is_y):\n        x = np.rot90(x, self.store.rot_times)\n        return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomFlip(CoordTransform):\n    def __init__(self, tfm_y=TfmType.NO, p=0.5):\n        super().__init__(tfm_y=tfm_y)\n        self.p=p\n\n    def set_state(self): self.store.do_flip = random.random()<self.p\n    def do_transform(self, x, is_y): return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomLighting(Transform):\n    def __init__(self, b, c, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.b,self.c = b,c\n\n    def set_state(self):\n        self.store.b_rand = rand0(self.b)\n        self.store.c_rand = rand0(self.c)\n\n    def do_transform(self, x, is_y):\n        if is_y and self.tfm_y != TfmType.PIXEL: return x\n        b = self.store.b_rand\n        c = self.store.c_rand\n        c = -1/(c-1) if c<0 else c+1\n        x = lighting(x, b, c)\n        return x\n\nclass RandomRotateZoom(CoordTransform):\n    """""" \n        Selects between a rotate, zoom, stretch, or no transform.\n        Arguments:\n            deg - maximum degrees of rotation.\n            zoom - maximum fraction of zoom.\n            stretch - maximum fraction of stretch.\n            ps - probabilities for each transform. List of length 4. The order for these probabilities is as listed respectively (4th probability is \'no transform\'.\n    """"""\n    def __init__(self, deg, zoom, stretch, ps=None, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        if ps is None: ps = [0.25,0.25,0.25,0.25]\n        assert len(ps) == 4, \'does not have 4 probabilities for p, it has %d\' % len(ps)\n        self.transforms = RandomRotate(deg, p=1, mode=mode, tfm_y=tfm_y), RandomZoom(zoom, tfm_y=tfm_y), RandomStretch(stretch,tfm_y=tfm_y)\n        self.pass_t = PassThru()\n        self.cum_ps = np.cumsum(ps)\n        assert self.cum_ps[3]==1, \'probabilites do not sum to 1; they sum to %d\' % self.cum_ps[3]\n\n    def set_state(self):\n        self.store.trans = self.pass_t\n        self.store.choice = self.cum_ps[3]*random.random()\n        for i in range(len(self.transforms)):\n            if self.store.choice < self.cum_ps[i]:\n                self.store.trans = self.transforms[i]\n                break\n        self.store.trans.set_state()\n\n    def do_transform(self, x, is_y): return self.store.trans.do_transform(x, is_y)\n\nclass RandomZoom(CoordTransform):\n    def __init__(self, zoom_max, zoom_min=0, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.zoom_max, self.zoom_min = zoom_max, zoom_min\n\n    def set_state(self):\n        self.store.zoom = self.zoom_min+(self.zoom_max-self.zoom_min)*random.random()\n\n    def do_transform(self, x, is_y):\n        return zoom_cv(x, self.store.zoom)\n\nclass RandomStretch(CoordTransform):\n    def __init__(self, max_stretch, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.max_stretch = max_stretch\n\n    def set_state(self):\n        self.store.stretch = self.max_stretch*random.random()\n        self.store.stretch_dir = random.randint(0,1)\n\n    def do_transform(self, x, is_y):\n        if self.store.stretch_dir==0: x = stretch_cv(x, self.store.stretch, 0)\n        else:                         x = stretch_cv(x, 0, self.store.stretch)\n        return x\n\nclass PassThru(CoordTransform):\n    def do_transform(self, x, is_y):\n        return x\n\nclass RandomBlur(Transform):\n    """"""\n    Adds a gaussian blur to the image at chance.\n    Multiple blur strengths can be configured, one of them is used by random chance.\n    """"""\n\n    def __init__(self, blur_strengths=5, probability=0.5, tfm_y=TfmType.NO):\n        # Blur strength must be an odd number, because it is used as a kernel size.\n        super().__init__(tfm_y)\n        self.blur_strengths = (np.array(blur_strengths, ndmin=1) * 2) - 1\n        if np.any(self.blur_strengths < 0):\n            raise ValueError(""all blur_strengths must be > 0"")\n        self.probability = probability\n        self.apply_transform = False\n\n    def set_state(self):\n        self.store.apply_transform = random.random() < self.probability\n        kernel_size = np.random.choice(self.blur_strengths)\n        self.store.kernel = (kernel_size, kernel_size)\n\n    def do_transform(self, x, is_y):\n        return cv2.GaussianBlur(src=x, ksize=self.store.kernel, sigmaX=0) if self.apply_transform else x\n\nclass Cutout(Transform):\n    def __init__(self, n_holes, length, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.n_holes,self.length = n_holes,length\n\n    def do_transform(self, img, is_y):\n        return cutout(img, self.n_holes, self.length)\n\nclass GoogleNetResize(CoordTransform):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ \n    \n    Arguments:\n        targ_sz: int\n            target size\n        min_area_frac: float < 1.0\n            minimum area of the original image for cropping\n        min_aspect_ratio : float\n            minimum aspect ratio\n        max_aspect_ratio : float\n            maximum aspect ratio\n        flip_hw_p : float\n            probability for flipping magnitudes of height and width\n        tfm_y: TfmType\n            type of y transform\n    """"""\n\n    def __init__(self, targ_sz,\n                 min_area_frac=0.08, min_aspect_ratio=0.75, max_aspect_ratio=1.333, flip_hw_p=0.5,\n                 tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz, self.tfm_y, self.sz_y = targ_sz, tfm_y, sz_y\n        self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.flip_hw_p = min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p\n\n    def set_state(self):\n        # if self.random_state: random.seed(self.random_state)\n        self.store.fp = random.random()<self.flip_hw_p\n\n    def do_transform(self, x, is_y):\n        sz = self.sz_y if is_y else self.targ_sz\n        if is_y:\n            interpolation = cv2.INTER_NEAREST if self.tfm_y in (TfmType.COORD, TfmType.CLASS) else cv2.INTER_AREA\n        else:\n            interpolation = cv2.INTER_AREA\n        return googlenet_resize(x, sz, self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.store.fp, interpolation=interpolation)\n\n\ndef compose(im, y, fns):\n    """""" apply a collection of transformation functions fns to images\n    """"""\n    for fn in fns:\n        #pdb.set_trace()\n        im, y =fn(im, y)\n    return im if y is None else (im, y)\n\n\nclass CropType(IntEnum):\n    """""" Type of image cropping.\n    """"""\n    RANDOM = 1\n    CENTER = 2\n    NO = 3\n    GOOGLENET = 4\n\ncrop_fn_lu = {CropType.RANDOM: RandomCrop, CropType.CENTER: CenterCrop, CropType.NO: NoCrop, CropType.GOOGLENET: GoogleNetResize}\n\nclass Transforms():\n    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n                 tfm_y=TfmType.NO, sz_y=None):\n        if sz_y is None: sz_y = sz\n        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n        self.tfms = tfms\n        self.tfms.append(crop_tfm)\n        if normalizer is not None: self.tfms.append(normalizer)\n        self.tfms.append(ChannelOrder(tfm_y))\n\n    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n    def __repr__(self): return str(self.tfms)\n\n\ndef image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n    """"""\n    Generate a standard set of transformations\n\n    Arguments\n    ---------\n     normalizer :\n         image normalizing function\n     denorm :\n         image denormalizing function\n     sz :\n         size, sz_y = sz if not specified.\n     tfms :\n         iterable collection of transformation functions\n     max_zoom : float,\n         maximum zoom\n     pad : int,\n         padding on top, left, right and bottom\n     crop_type :\n         crop type\n     tfm_y :\n         y axis specific transformations\n     sz_y :\n         y size, height\n     pad_mode :\n         cv2 padding style: repeat, reflect, etc.\n\n    Returns\n    -------\n     type : ``Transforms``\n         transformer for specified image operations.\n\n    See Also\n    --------\n     Transforms: the transformer object returned by this function\n    """"""\n    if tfm_y is None: tfm_y=TfmType.NO\n    if tfms is None: tfms=[]\n    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n    if sz_y is None: sz_y = sz\n    if scale is None:\n        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n                 else Scale(sz, tfm_y, sz_y=sz_y)]\n    elif not is_listy(scale): scale = [scale]\n    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n                      tfm_y=tfm_y, sz_y=sz_y)\n\ndef noop(x):\n    """"""dummy function for do-nothing.\n    equivalent to: lambda x: x""""""\n    return x\n\ntransforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)]\ntransforms_side_on  = transforms_basic + [RandomFlip()]\ntransforms_top_down = transforms_basic + [RandomDihedral()]\n\nimagenet_stats = A([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n""""""Statistics pertaining to image data from image net. mean and std of the images of each color channel""""""\ninception_stats = A([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\ninception_models = (inception_4, inceptionresnet_2)\n\ndef tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Given the statistics of the training image sets, returns separate training and validation transform functions\n    """"""\n    if aug_tfms is None: aug_tfms=[]\n    tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n    tfm_denorm = Denormalize(*stats) if stats is not None else None\n    val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n    val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n            tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n    trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n            tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n    return trn_tfm, val_tfm\n\n\ndef tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Returns separate transformers of images for training and validation.\n    Transformers are constructed according to the image statistics given b y the model. (See tfms_from_stats)\n\n    Arguments:\n        f_model: model, pretrained or not pretrained\n    """"""\n    stats = inception_stats if f_model in inception_models else imagenet_stats\n    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)\n\n'"
fastai/tutorials/fastai/transforms_pil.py,1,"b'import torch\nimport numpy as np\n\n\nclass Cutout(object):\n    """"""Randomly mask out one or more patches from an image.\n\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    """"""\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (Tensor): Tensor image of size (C, H, W).\n        Returns:\n            Tensor: Image with n_holes of dimension length x length cut out of it.\n        """"""\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length / 2, 0, h)\n            y2 = np.clip(y + self.length / 2, 0, h)\n            x1 = np.clip(x - self.length / 2, 0, w)\n            x2 = np.clip(x + self.length / 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n'"
fastai/tutorials/fastai/utils.py,0,"b""import math, os, json, sys, re, numpy as np, pickle, PIL, scipy\nfrom PIL import Image\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom operator import itemgetter, attrgetter, methodcaller\nfrom collections import OrderedDict\nimport itertools\nfrom itertools import chain\n\nimport pandas as pd\nfrom numpy.random import random, permutation, randn, normal, uniform, choice\nfrom numpy import newaxis\nfrom scipy import misc, ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.manifold import TSNE\nimport bcolz\n\nfrom IPython.lib.display import FileLink\n\nimport keras\nfrom keras import backend as K\nfrom keras.utils.data_utils import get_file\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\nfrom keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\nfrom keras.layers import Flatten, Dense, Dropout, Lambda\nfrom keras.regularizers import l2, l1\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.layers import deserialize as layer_from_config\nfrom keras.metrics import categorical_crossentropy, categorical_accuracy\nfrom keras.layers.convolutional import *\nfrom keras.preprocessing import image, sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom vgg16 import Vgg16\nnp.set_printoptions(precision=4, linewidth=100)\n\n\nto_bw = np.array([0.299, 0.587, 0.114])\n\ndef gray(img): return np.rollaxis(img, 0, 1).dot(to_bw)\ndef to_plot(img): return np.rollaxis(img, 0, 1).astype(np.uint8)\ndef plot(img): plt.imshow(to_plot(img))\n\ndef floor(x): return int(math.floor(x))\ndef ceil(x): return int(math.ceil(x))\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    \n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n\n\ndef do_clip(arr, mx):\n    clipped = np.clip(arr, (1-mx)/1, mx)\n    return clipped/clipped.sum(axis=1)[:, np.newaxis]\n\n\ndef wrap_config(layer):\n    return {'class_name': layer.__class__.__name__, 'config': layer.get_config()}\n\ndef copy_layer(layer): return layer_from_config(wrap_config(layer))\n\ndef copy_layers(layers): return [copy_layer(layer) for layer in layers]\n\ndef copy_weights(from_layers, to_layers):\n    for from_layer,to_layer in zip(from_layers, to_layers):\n        to_layer.set_weights(from_layer.get_weights())\n\ndef save_array(fname, arr):\n    c=bcolz.carray(arr, rootdir=fname, mode='w')\n    c.flush()\n\ndef load_array(fname): return bcolz.open(fname)[:]\n\ndef get_classes(path):\n    batches = get_batches(path+'train', shuffle=False, batch_size=1)\n    val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n    test_batches = get_batches(path+'test', shuffle=False, batch_size=1)\n    return (val_batches.classes, batches.classes, onehot(val_batches.classes), onehot(batches.classes),\n        val_batches.filenames, batches.filenames, test_batches.filenames)\n\ndef limit_mem():\n    K.get_session().close()\n    cfg = K.tf.ConfigProto()\n    cfg.gpu_options.allow_growth = True\n    K.set_session(K.tf.Session(config=cfg))\n\nclass MixIterator(object):\n    def __init__(self, iters):\n        self.iters = iters\n        self.multi = type(iters) is list\n        if self.multi:\n            self.N = sum([it[0].N for it in self.iters])\n        else:\n            self.N = sum([it.N for it in self.iters])\n\n    def reset(self):\n        for it in self.iters: it.reset()\n\n    def __iter__(self):\n        return self\n\n    def next(self, *args, **kwargs):\n        if self.multi:\n            nexts = [[next(it) for it in o] for o in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n        else:\n            nexts = [next(it) for it in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n"""
fastai/courses/dl1/fastai/__init__.py,0,b''
fastai/courses/dl1/fastai/adaptive_softmax.py,1,"b'from .lm_rnn import *\n\nclass AdaptiveSoftmax(nn.Module):\n    def __init__(self, input_size, cutoff):\n        super().__init__()\n        self.input_size,self.cutoff = input_size,cutoff\n        self.output_size = cutoff[0] + len(cutoff) - 1\n        self.head = nn.Linear(input_size, self.output_size)\n        self.tail = nn.ModuleList()\n        for i in range(len(cutoff) - 1):\n            seq = nn.Sequential(nn.Linear(input_size, input_size // 4 ** i, False),\n                nn.Linear(input_size // 4 ** i, cutoff[i + 1] - cutoff[i], False))\n            self.tail.append(seq)\n\n    def reset(self):\n        nn.init.xavier_normal(self.head.weight)\n        for tail in self.tail:\n            nn.init.xavier_normal(tail[0].weight)\n            nn.init.xavier_normal(tail[1].weight)\n\n    def set_target(self, target):\n        self.id = []\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            if mask.sum() > 0:\n                self.id.append(Variable(mask.float().nonzero().squeeze(1)))\n            else: self.id.append(None)\n\n    def forward(self, input):\n        output = [self.head(input)]\n        for i in range(len(self.id)):\n            if self.id[i] is not None:\n                output.append(self.tail[i](input.index_select(0, self.id[i])))\n            else: output.append(None)\n        return output\n\n    def log_prob(self, input):\n        lsm = nn.LogSoftmax().cuda()\n        head_out = self.head(input)\n        batch_size = head_out.size(0)\n        prob = torch.zeros(batch_size, self.cutoff[-1]).cuda()\n        lsm_head = lsm(head_out)\n        prob.narrow(1, 0, self.output_size).add_(lsm_head.narrow(1, 0, self.output_size).data)\n        for i in range(len(self.tail)):\n            pos = self.cutoff[i]\n            i_size = self.cutoff[i + 1] - pos\n            buffer = lsm_head.narrow(1, self.cutoff[0] + i, 1)\n            buffer = buffer.expand(batch_size, i_size)\n            lsm_tail = lsm(self.tail[i](input))\n            prob.narrow(1, pos, i_size).copy_(buffer.data).add_(lsm_tail.data)\n        return prob\n\n\nclass AdaptiveLoss(nn.Module):\n    def __init__(self, cutoff):\n        super().__init__()\n        self.cutoff = cutoff\n        self.criterions = nn.ModuleList([nn.CrossEntropyLoss(size_average=False) for i in self.cutoff])\n\n    def remap_target(self, target):\n        new_target = [target.clone()]\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            new_target[0][mask] = self.cutoff[0] + i\n            if mask.sum() > 0: new_target.append(target[mask].add(-self.cutoff[i]))\n            else: new_target.append(None)\n        return new_target\n\n    def forward(self, input, target):\n        batch_size = input[0].size(0)\n        target = self.remap_target(target.data)\n        output = 0.0\n        for i in range(len(input)):\n            if input[i] is not None:\n                assert(target[i].min() >= 0 and target[i].max() <= input[i].size(1))\n                criterion = self.criterions[i]\n                output += criterion(input[i], Variable(target[i]))\n        output /= batch_size\n        return output\n\n'"
fastai/courses/dl1/fastai/column_data.py,2,"b'from .imports import *\nfrom .torch_imports import *\nfrom .dataset import *\nfrom .learner import *\n\n\nclass PassthruDataset(Dataset):\n    def __init__(self,*args, is_reg=True, is_multi=False):\n        *xs,y=args\n        self.xs,self.y = xs,y\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n    def __getitem__(self, idx): return [o[idx] for o in self.xs] + [self.y[idx]]\n\n    @classmethod\n    def from_data_frame(cls, df, cols_x, col_y, is_reg=True, is_multi=False):\n        cols = [df[o] for o in cols_x+[col_y]]\n        return cls(*cols, is_reg=is_reg, is_multi=is_multi)\n\n\nclass ColumnarDataset(Dataset):\n    def __init__(self, cats, conts, y, is_reg, is_multi):\n        n = len(cats[0]) if cats else len(conts[0])\n        self.cats = np.stack(cats, 1).astype(np.int64) if cats else np.zeros((n,1))\n        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n        self.y = np.zeros((n,1)) if y is None else y\n        if is_reg:\n            self.y =  self.y[:,None]\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n\n    def __getitem__(self, idx):\n        return [self.cats[idx], self.conts[idx], self.y[idx]]\n\n    @classmethod\n    def from_data_frames(cls, df_cat, df_cont, y=None, is_reg=True, is_multi=False):\n        cat_cols = [c.values for n,c in df_cat.items()]\n        cont_cols = [c.values for n,c in df_cont.items()]\n        return cls(cat_cols, cont_cols, y, is_reg, is_multi)\n\n    @classmethod\n    def from_data_frame(cls, df, cat_flds, y=None, is_reg=True, is_multi=False):\n        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y, is_reg, is_multi)\n\n\nclass ColumnarModelData(ModelData):\n    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n            DataLoader(val_ds, bs*2, shuffle=False, num_workers=1), test_dl)\n\n    @classmethod\n    def from_arrays(cls, path, val_idxs, xs, y, is_reg=True, is_multi=False, bs=64, test_xs=None, shuffle=True):\n        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs), is_reg=is_reg, is_multi=is_multi) if test_xs is not None else None\n        return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n                   PassthruDataset(*(val_xs.T), val_y, is_reg=is_reg, is_multi=is_multi),\n                   bs=bs, shuffle=shuffle, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=None):\n        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, None, is_reg, is_multi) if test_df is not None else None\n        return cls(path, ColumnarDataset.from_data_frame(trn_df, cat_flds, trn_y, is_reg, is_multi),\n                    ColumnarDataset.from_data_frame(val_df, cat_flds, val_y, is_reg, is_multi), bs, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, is_reg=True, is_multi=False, test_df=None):\n        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=test_df)\n\n    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                    y_range=None, use_bn=False, **kwargs):\n        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn, self.is_reg, self.is_multi)\n        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n\n\ndef emb_init(x):\n    x = x.weight.data\n    sc = 2/(x.size(1)+1)\n    x.uniform_(-sc,sc)\n\n\nclass MixedInputModel(nn.Module):\n    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                 y_range=None, use_bn=False, is_reg=True, is_multi=False):\n        super().__init__()\n        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n        for emb in self.embs: emb_init(emb)\n        n_emb = sum(e.embedding_dim for e in self.embs)\n        self.n_emb, self.n_cont=n_emb, n_cont\n        \n        szs = [n_emb+n_cont] + szs\n        self.lins = nn.ModuleList([\n            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n        self.bns = nn.ModuleList([\n            nn.BatchNorm1d(sz) for sz in szs[1:]])\n        for o in self.lins: kaiming_normal(o.weight.data)\n        self.outp = nn.Linear(szs[-1], out_sz)\n        kaiming_normal(self.outp.weight.data)\n\n        self.emb_drop = nn.Dropout(emb_drop)\n        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n        self.bn = nn.BatchNorm1d(n_cont)\n        self.use_bn,self.y_range = use_bn,y_range\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def forward(self, x_cat, x_cont):\n        if self.n_emb != 0:\n            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n            x = torch.cat(x, 1)\n            x = self.emb_drop(x)\n        if self.n_cont != 0:\n            x2 = self.bn(x_cont)\n            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n        for l,d,b in zip(self.lins, self.drops, self.bns):\n            x = F.relu(l(x))\n            if self.use_bn: x = b(x)\n            x = d(x)\n        x = self.outp(x)\n        if not self.is_reg:\n            if self.is_multi:\n                x = F.sigmoid(x)\n            else:\n                x = F.log_softmax(x)\n        elif self.y_range:\n            x = F.sigmoid(x)\n            x = x*(self.y_range[1] - self.y_range[0])\n            x = x+self.y_range[0]\n        return x\n\n\nclass StructuredLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    def summary(self): return model_summary(self.model, [(self.data.trn_ds.cats.shape[1], ), (self.data.trn_ds.conts.shape[1], )])\n\n\nclass StructuredModel(BasicModel):\n    def get_layer_groups(self):\n        m=self.model\n        return [m.embs, children(m.lins)+children(m.bns), m.outp]\n\n\nclass CollabFilterDataset(Dataset):\n    def __init__(self, path, user_col, item_col, ratings):\n        self.ratings,self.path = ratings.values.astype(np.float32),path\n        self.n = len(ratings)\n        (self.users,self.user2idx,self.user_col,self.n_users) = self.proc_col(user_col)\n        (self.items,self.item2idx,self.item_col,self.n_items) = self.proc_col(item_col)\n        self.min_score,self.max_score = min(ratings),max(ratings)\n        self.cols = [self.user_col,self.item_col,self.ratings]\n\n    @classmethod\n    def from_data_frame(cls, path, df, user_name, item_name, rating_name):\n        return cls(path, df[user_name], df[item_name], df[rating_name])\n\n    @classmethod\n    def from_csv(cls, path, csv, user_name, item_name, rating_name):\n        df = pd.read_csv(os.path.join(path,csv))\n        return cls.from_data_frame(path, df, user_name, item_name, rating_name)\n\n    def proc_col(self,col):\n        uniq = col.unique()\n        name2idx = {o:i for i,o in enumerate(uniq)}\n        return (uniq, name2idx, np.array([name2idx[x] for x in col]), len(uniq))\n\n    def __len__(self): return self.n\n    def __getitem__(self, idx): return [o[idx] for o in self.cols]\n\n    def get_data(self, val_idxs, bs):\n        val, trn = zip(*split_by_idx(val_idxs, *self.cols))\n        return ColumnarModelData(self.path, PassthruDataset(*trn), PassthruDataset(*val), bs)\n\n    def get_model(self, n_factors):\n        model = EmbeddingDotBias(n_factors, self.n_users, self.n_items, self.min_score, self.max_score)\n        return CollabFilterModel(to_gpu(model))\n\n    def get_learner(self, n_factors, val_idxs, bs, **kwargs):\n        return CollabFilterLearner(self.get_data(val_idxs, bs), self.get_model(n_factors), **kwargs)\n\n\ndef get_emb(ni,nf):\n    e = nn.Embedding(ni, nf)\n    e.weight.data.uniform_(-0.05,0.05)\n    return e\n\n\nclass EmbeddingDotBias(nn.Module):\n    def __init__(self, n_factors, n_users, n_items, min_score, max_score):\n        super().__init__()\n        self.min_score,self.max_score = min_score,max_score\n        (self.u, self.i, self.ub, self.ib) = [get_emb(*o) for o in [\n            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n        ]]\n\n    def forward(self, users, items):\n        um = self.u(users)* self.i(items)\n        res = um.sum(1) + self.ub(users).squeeze() + self.ib(items).squeeze()\n        return F.sigmoid(res) * (self.max_score-self.min_score) + self.min_score\n\n\nclass CollabFilterLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n\nclass CollabFilterModel(BasicModel):\n    def get_layer_groups(self): return self.model\n\n'"
fastai/courses/dl1/fastai/conv_learner.py,0,"b'from .core import *\nfrom .layers import *\nfrom .learner import *\nfrom .initializers import *\n\nmodel_meta = {\n    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n    vgg16:[0,22], vgg19:[0,22],\n    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n}\nmodel_features = {inception_4: 3072, dn121: 2048, dn161: 4416,} # nasnetalarge: 4032*2}\n\nclass ConvnetBuilder():\n    """"""Class representing a convolutional network.\n\n    Arguments:\n        f: a model creation function (e.g. resnet34, vgg16, etc)\n        c (int): size of the last layer\n        is_multi (bool): is multilabel classification?\n            (def here http://scikit-learn.org/stable/modules/multiclass.html)\n        is_reg (bool): is a regression?\n        ps (float or array of float): dropout parameters\n        xtra_fc (list of ints): list of hidden layers with # hidden neurons\n        xtra_cut (int): # layers earlier than default to cut the model, default is 0\n        custom_head : add custom model classes that are inherited from nn.modules at the end of the model\n                      that is mentioned on Argument \'f\' \n    """"""\n\n    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, pretrained=True):\n        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n        if xtra_fc is None: xtra_fc = [512]\n        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n        self.ps,self.xtra_fc = ps,xtra_fc\n\n        if f in model_meta: cut,self.lr_cut = model_meta[f]\n        else: cut,self.lr_cut = 0,0\n        cut-=xtra_cut\n        layers = cut_model(f(pretrained), cut)\n        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n        self.top_model = nn.Sequential(*layers)\n\n        n_fc = len(self.xtra_fc)+1\n        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n\n        if custom_head: fc_layers = [custom_head]\n        else: fc_layers = self.get_fc_layers()\n        self.n_fc = len(fc_layers)\n        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n\n    @property\n    def name(self): return f\'{self.f.__name__}_{self.xtra_cut}\'\n\n    def create_fc_layer(self, ni, nf, p, actn=None):\n        res=[nn.BatchNorm1d(num_features=ni)]\n        if p: res.append(nn.Dropout(p=p))\n        res.append(nn.Linear(in_features=ni, out_features=nf))\n        if actn: res.append(actn)\n        return res\n\n    def get_fc_layers(self):\n        res=[]\n        ni=self.nf\n        for i,nf in enumerate(self.xtra_fc):\n            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n            ni=nf\n        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n        if self.is_reg: final_actn = None\n        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n        return res\n\n    def get_layer_groups(self, do_fc=False):\n        if do_fc:\n            return [self.fc_model]\n        idxs = [self.lr_cut]\n        c = children(self.top_model)\n        if len(c)==3: c = children(c[0])+c[1:]\n        lgs = list(split_by_idxs(c,idxs))\n        return lgs+[self.fc_model]\n\n\nclass ConvLearner(Learner):\n    """"""\n    Class used to train a chosen supported covnet model. Eg. ResNet-34, etc.\n    Arguments:\n        data: training data for model\n        models: model architectures to base learner\n        precompute: bool to reuse precomputed activations\n        **kwargs: parameters from Learner() class\n    """"""\n    def __init__(self, data, models, precompute=False, **kwargs):\n        self.precompute = False\n        super().__init__(data, models, **kwargs)\n        if hasattr(data, \'is_multi\') and not data.is_reg and self.metrics is None:\n            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n        if precompute: self.save_fc1()\n        self.freeze()\n        self.precompute = precompute\n\n    def _get_crit(self, data):\n        if not hasattr(data, \'is_multi\'): return super()._get_crit(data)\n\n        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    @classmethod\n    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                   pretrained=True, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n        return cls(data, models, precompute, **kwargs)\n\n    @classmethod\n    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n        convlearn=cls(data, models, precompute, **kwargs)\n        convlearn.lsuv_init()\n        return convlearn\n    \n    @property\n    def model(self): return self.models.fc_model if self.precompute else self.models.model\n\n    @property\n    def data(self): return self.fc_data if self.precompute else self.data_\n\n    def create_empty_bcolz(self, n, name):\n        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode=\'w\', rootdir=name)\n\n    def set_data(self, data, precompute=False):\n        super().set_data(data)\n        if precompute:\n            self.unfreeze()\n            self.save_fc1()\n            self.freeze()\n            self.precompute = True\n        else:\n            self.freeze()\n\n    def get_layer_groups(self):\n        return self.models.get_layer_groups(self.precompute)\n\n    def summary(self):\n        precompute = self.precompute\n        self.precompute = False\n        res = super().summary()\n        self.precompute = precompute\n        return res\n\n    def get_activations(self, force=False):\n        tmpl = f\'_{self.models.name}_{self.data.sz}.bc\'\n        # TODO: Somehow check that directory names haven\'t changed (e.g. added test set)\n        names = [os.path.join(self.tmp_path, p+tmpl) for p in (\'x_act\', \'x_act_val\', \'x_act_test\')]\n        if os.path.exists(names[0]) and not force:\n            self.activations = [bcolz.open(p) for p in names]\n        else:\n            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n\n    def save_fc1(self):\n        self.get_activations()\n        act, val_act, test_act = self.activations\n        m=self.models.top_model\n        if len(self.activations[0])!=len(self.data.trn_ds):\n            predict_to_bcolz(m, self.data.fix_dl, act)\n        if len(self.activations[1])!=len(self.data.val_ds):\n            predict_to_bcolz(m, self.data.val_dl, val_act)\n        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n\n        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n                test = test_act if self.data.test_dl else None, num_workers=8)\n\n    def freeze(self):\n        """""" Freeze all but the very last layer.\n\n        Make all layers untrainable (i.e. frozen) except for the last layer.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(-1)\n\n    def unfreeze(self):\n        """""" Unfreeze all layers.\n\n        Make all layers trainable by unfreezing. This will also set the `precompute` to `False` since we can\n        no longer pre-calculate the activation of frozen layers.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(0)\n        self.precompute = False\n'"
fastai/courses/dl1/fastai/core.py,11,"b'from .imports import *\nfrom .torch_imports import *\n\ndef sum_geom(a,r,n): return a*n if r==1 else math.ceil(a*(1-r**n)/(1-r))\n\ndef is_listy(x): return isinstance(x, (list,tuple))\ndef is_iter(x): return isinstance(x, collections.Iterable)\ndef map_over(x, f): return [f(o) for o in x] if is_listy(x) else f(x)\ndef map_none(x, f): return None if x is None else f(x)\n\nconv_dict = {np.dtype(\'int8\'): torch.LongTensor, np.dtype(\'int16\'): torch.LongTensor,\n    np.dtype(\'int32\'): torch.LongTensor, np.dtype(\'int64\'): torch.LongTensor,\n    np.dtype(\'float32\'): torch.FloatTensor, np.dtype(\'float64\'): torch.FloatTensor}\n\ndef A(*a):\n    """"""convert iterable object into numpy array""""""\n    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]\n\ndef T(a, half=False, cuda=True):\n    """"""\n    Convert numpy array into a pytorch tensor. \n    if Cuda is available and USE_GPU=ture, store resulting tensor in GPU.\n    """"""\n    if not torch.is_tensor(a):\n        a = np.array(np.ascontiguousarray(a))\n        if a.dtype in (np.int8, np.int16, np.int32, np.int64):\n            a = torch.LongTensor(a.astype(np.int64))\n        elif a.dtype in (np.float32, np.float64):\n            a = torch.cuda.HalfTensor(a) if half else torch.FloatTensor(a)\n        else: raise NotImplementedError(a.dtype)\n    if cuda: a = to_gpu(a, async=True)\n    return a\n\ndef create_variable(x, volatile, requires_grad=False):\n    if type (x) != Variable:\n        if IS_TORCH_04: x = Variable(T(x), requires_grad=requires_grad)\n        else:           x = Variable(T(x), requires_grad=requires_grad, volatile=volatile)\n    return x\n\ndef V_(x, requires_grad=False, volatile=False):\n    \'\'\'equivalent to create_variable, which creates a pytorch tensor\'\'\'\n    return create_variable(x, volatile=volatile, requires_grad=requires_grad)\ndef V(x, requires_grad=False, volatile=False):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, lambda o: V_(o, requires_grad, volatile))\n\ndef VV_(x): \n    \'\'\'creates a volatile tensor, which does not require gradients. \'\'\'\n    return create_variable(x, True)\n\ndef VV(x):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, VV_)\n\ndef to_np(v):\n    \'\'\'returns an np.array object given an input of np.array, list, tuple, torch variable or tensor.\'\'\'\n    if isinstance(v, (np.ndarray, np.generic)): return v\n    if isinstance(v, (list,tuple)): return [to_np(o) for o in v]\n    if isinstance(v, Variable): v=v.data\n    if isinstance(v, torch.cuda.HalfTensor): v=v.float()\n    return v.cpu().numpy()\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\nUSE_GPU = torch.cuda.is_available()\ndef to_gpu(x, *args, **kwargs):\n    \'\'\'puts pytorch variable to gpu, if cuda is avaialble and USE_GPU is set to true. \'\'\'\n    return x.cuda(*args, **kwargs) if USE_GPU else x\n\ndef noop(*args, **kwargs): return\n\ndef split_by_idxs(seq, idxs):\n    \'\'\'A generator that returns sequence pieces, seperated by indexes specified in idxs. \'\'\'\n    last = 0\n    for idx in idxs:\n        yield seq[last:idx]\n        last = idx\n    yield seq[last:]\n\ndef trainable_params_(m):\n    \'\'\'Returns a list of trainable parameters in the model m. (i.e., those that require gradients.)\'\'\'\n    return [p for p in m.parameters() if p.requires_grad]\n\ndef chain_params(p):\n    if is_listy(p):\n        return list(chain(*[trainable_params_(o) for o in p]))\n    return trainable_params_(p)\n\ndef set_trainable_attr(m,b):\n    m.trainable=b\n    for p in m.parameters(): p.requires_grad=b\n\ndef apply_leaf(m, f):\n    c = children(m)\n    if isinstance(m, nn.Module): f(m)\n    if len(c)>0:\n        for l in c: apply_leaf(l,f)\n\ndef set_trainable(l, b):\n    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n\ndef SGD_Momentum(momentum):\n    return lambda *args, **kwargs: optim.SGD(*args, momentum=momentum, **kwargs)\n\ndef one_hot(a,c): return np.eye(c)[a]\n\ndef partition(a, sz): \n    """"""splits iterables a in equal parts of size sz""""""\n    return [a[i:i+sz] for i in range(0, len(a), sz)]\n\ndef partition_by_cores(a):\n    return partition(a, len(a)//num_cpus() + 1)\n\ndef num_cpus():\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n\n\nclass BasicModel():\n    def __init__(self,model,name=\'unnamed\'): self.model,self.name = model,name\n    def get_layer_groups(self, do_fc=False): return children(self.model)\n\nclass SingleModel(BasicModel):\n    def get_layer_groups(self): return [self.model]\n\nclass SimpleNet(nn.Module):\n    def __init__(self, layers):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return F.log_softmax(l_x, dim=-1)\n\n\ndef save(fn, a): \n    """"""Utility function that savess model, function, etc as pickle""""""    \n    pickle.dump(a, open(fn,\'wb\'))\ndef load(fn): \n    """"""Utility function that loads model, function, etc as pickle""""""\n    return pickle.load(open(fn,\'rb\'))\ndef load2(fn):\n    """"""Utility funciton allowing model piclking across Python2 and Python3""""""\n    return pickle.load(open(fn,\'rb\'), encoding=\'iso-8859-1\')\n\ndef load_array(fname): \n    \'\'\'\n    Load array using bcolz, which is based on numpy, for fast array saving and loading operations. \n    https://github.com/Blosc/bcolz\n    \'\'\'\n    return bcolz.open(fname)[:]\n\n\ndef chunk_iter(iterable, chunk_size):\n    \'\'\'A generator that yields chunks of iterable, chunk_size at a time. \'\'\'\n    while True:\n        chunk = []\n        try:\n            for _ in range(chunk_size): chunk.append(next(iterable))\n            yield chunk\n        except StopIteration:\n            if chunk: yield chunk\n            break\n\ndef set_grad_enabled(mode): return torch.set_grad_enabled(mode) if IS_TORCH_04 else contextlib.suppress()\n\ndef no_grad_context(): return torch.no_grad() if IS_TORCH_04 else contextlib.suppress()\n'"
fastai/courses/dl1/fastai/dataloader.py,1,"b'import torch, queue\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler\nfrom .imports import *\nfrom .core import *\nimport collections,sys,traceback,threading\n\nstring_classes = (str, bytes)\n\n\ndef get_tensor(batch, pin, half=False):\n    if isinstance(batch, (np.ndarray, np.generic)):\n        batch = T(batch, half=half, cuda=False).contiguous()\n        if pin: batch = batch.pin_memory()\n        return to_gpu(batch)\n    elif isinstance(batch, string_classes):\n        return batch\n    elif isinstance(batch, collections.Mapping):\n        return {k: get_tensor(sample, pin, half) for k, sample in batch.items()}\n    elif isinstance(batch, collections.Sequence):\n        return [get_tensor(sample, pin, half) for sample in batch]\n    raise TypeError(f""batch must contain numbers, dicts or lists; found {type(batch)}"")\n\n\nclass DataLoader(object):\n    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, pad_idx=0,\n                 num_workers=None, pin_memory=False, drop_last=False, pre_pad=True, half=False,\n                 transpose=False, transpose_y=False):\n        self.dataset,self.batch_size,self.num_workers = dataset,batch_size,num_workers\n        self.pin_memory,self.drop_last,self.pre_pad = pin_memory,drop_last,pre_pad\n        self.transpose,self.transpose_y,self.pad_idx,self.half = transpose,transpose_y,pad_idx,half\n\n        if batch_sampler is not None:\n            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n                raise ValueError(\'batch_sampler is mutually exclusive with \'\n                                 \'batch_size, shuffle, sampler, and drop_last\')\n\n        if sampler is not None and shuffle:\n            raise ValueError(\'sampler is mutually exclusive with shuffle\')\n\n        if batch_sampler is None:\n            if sampler is None:\n                sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n\n        if num_workers is None:\n            self.num_workers = num_cpus()\n\n        self.sampler = sampler\n        self.batch_sampler = batch_sampler\n\n    def __len__(self): return len(self.batch_sampler)\n\n    def jag_stack(self, b):\n        if len(b[0].shape) not in (1,2): return np.stack(b)\n        ml = max(len(o) for o in b)\n        if min(len(o) for o in b)==ml: return np.stack(b)\n        res = np.zeros((len(b), ml), dtype=b[0].dtype) + self.pad_idx\n        for i,o in enumerate(b):\n            if self.pre_pad: res[i, -len(o):] = o\n            else:            res[i,  :len(o)] = o\n        return res\n\n    def np_collate(self, batch):\n        b = batch[0]\n        if isinstance(b, (np.ndarray, np.generic)): return self.jag_stack(batch)\n        elif isinstance(b, (int, float)): return np.array(batch)\n        elif isinstance(b, string_classes): return batch\n        elif isinstance(b, collections.Mapping):\n            return {key: self.np_collate([d[key] for d in batch]) for key in b}\n        elif isinstance(b, collections.Sequence):\n            return [self.np_collate(samples) for samples in zip(*batch)]\n        raise TypeError((""batch must contain numbers, dicts or lists; found {}"".format(type(b))))\n\n    def get_batch(self, indices):\n        res = self.np_collate([self.dataset[i] for i in indices])\n        if self.transpose:   res[0] = res[0].T\n        if self.transpose_y: res[1] = res[1].T\n        return res\n\n    def __iter__(self):\n        if self.num_workers==0:\n            for batch in map(self.get_batch, iter(self.batch_sampler)):\n                yield get_tensor(batch, self.pin_memory, self.half)\n        else:\n            with ThreadPoolExecutor(max_workers=self.num_workers) as e:\n                # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n                for c in chunk_iter(iter(self.batch_sampler), self.num_workers*10):\n                    for batch in e.map(self.get_batch, c):\n                        yield get_tensor(batch, self.pin_memory, self.half)\n\n'"
fastai/courses/dl1/fastai/dataset.py,1,"b'import csv\n\nfrom .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .layer_optimizer import *\nfrom .dataloader import DataLoader\n\ndef get_cv_idxs(n, cv_idx=0, val_pct=0.2, seed=42):\n    """""" Get a list of index values for Validation set from a dataset\n    \n    Arguments:\n        n : int, Total number of elements in the data set.\n        cv_idx : int, starting index [idx_start = cv_idx*int(val_pct*n)] \n        val_pct : (int, float), validation set percentage \n        seed : seed value for RandomState\n        \n    Returns:\n        list of indexes \n    """"""\n    np.random.seed(seed)\n    n_val = int(val_pct*n)\n    idx_start = cv_idx*n_val\n    idxs = np.random.permutation(n)\n    return idxs[idx_start:idx_start+n_val]\n\ndef resize_img(fname, targ, path, new_path):\n    """"""\n    Enlarge or shrink a single image to scale, such that the smaller of the height or width dimension is equal to targ.\n    """"""\n    dest = os.path.join(path,new_path,str(targ),fname)\n    if os.path.exists(dest): return\n    im = Image.open(os.path.join(path, fname)).convert(\'RGB\')\n    r,c = im.size\n    ratio = targ/min(r,c)\n    sz = (scale_to(r, ratio, targ), scale_to(c, ratio, targ))\n    os.makedirs(os.path.split(dest)[0], exist_ok=True)\n    im.resize(sz, Image.LINEAR).save(dest)\n\ndef resize_imgs(fnames, targ, path, new_path):\n    """"""\n    Enlarge or shrink a set of images in the same directory to scale, such that the smaller of the height or width dimension is equal to targ.\n    Note: \n    -- This function is multithreaded for efficiency. \n    -- When destination file or folder already exist, function exists without raising an error. \n    """"""\n    if not os.path.exists(os.path.join(path,new_path,str(targ),fnames[0])):\n        with ThreadPoolExecutor(8) as e:\n            ims = e.map(lambda x: resize_img(x, targ, path, new_path), fnames)\n            for x in tqdm(ims, total=len(fnames), leave=False): pass\n    return os.path.join(path,new_path,str(targ))\n\ndef read_dir(path, folder):\n    """""" Returns a list of relative file paths to `path` for all files within `folder` """"""\n    full_path = os.path.join(path, folder)\n    fnames = glob(f""{full_path}/*.*"")\n    if any(fnames):\n        return [os.path.relpath(f,path) for f in fnames]\n    else:\n        raise FileNotFoundError(""{} folder doesn\'t exist or is empty"".format(folder))\n\ndef read_dirs(path, folder):\n    \'\'\'\n    Fetches name of all files in path in long form, and labels associated by extrapolation of directory names. \n    \'\'\'\n    lbls, fnames, all_lbls = [], [], []\n    full_path = os.path.join(path, folder)\n    for lbl in sorted(os.listdir(full_path)):\n        if lbl not in (\'.ipynb_checkpoints\',\'.DS_Store\'):\n            all_lbls.append(lbl)\n            for fname in os.listdir(os.path.join(full_path, lbl)):\n                fnames.append(os.path.join(folder, lbl, fname))\n                lbls.append(lbl)\n    return fnames, lbls, all_lbls\n\ndef n_hot(ids, c):\n    \'\'\'\n    one hot encoding by index. Returns array of length c, where all entries are 0, except for the indecies in ids\n    \'\'\'\n    res = np.zeros((c,), dtype=np.float32)\n    res[ids] = 1\n    return res\n\ndef folder_source(path, folder):\n    """"""\n    Returns the filenames and labels for a folder within a path\n    \n    Returns:\n    -------\n    fnames: a list of the filenames within `folder`\n    all_lbls: a list of all of the labels in `folder`, where the # of labels is determined by the # of directories within `folder`\n    lbl_arr: a numpy array of the label indices in `all_lbls`\n    """"""\n    fnames, lbls, all_lbls = read_dirs(path, folder)\n    lbl2idx = {lbl:idx for idx,lbl in enumerate(all_lbls)}\n    idxs = [lbl2idx[lbl] for lbl in lbls]\n    lbl_arr = np.array(idxs, dtype=int)\n    return fnames, lbl_arr, all_lbls\n\ndef parse_csv_labels(fn, skip_header=True, cat_separator = \' \'):\n    """"""Parse filenames and label sets from a CSV file.\n\n    This method expects that the csv file at path :fn: has two columns. If it\n    has a header, :skip_header: should be set to True. The labels in the\n    label set are expected to be space separated.\n\n    Arguments:\n        fn: Path to a CSV file.\n        skip_header: A boolean flag indicating whether to skip the header.\n\n    Returns:\n        a four-tuple of (\n            sorted image filenames,\n            a dictionary of filenames and corresponding labels,\n            a sorted set of unique labels,\n            a dictionary of labels to their corresponding index, which will\n            be one-hot encoded.\n        )\n    .\n    :param cat_separator: the separator for the categories column\n    """"""\n    df = pd.read_csv(fn, index_col=0, header=0 if skip_header else None, dtype=str)\n    fnames = df.index.values\n    df.iloc[:,0] = df.iloc[:,0].str.split(cat_separator)\n    return sorted(fnames), list(df.to_dict().values())[0]\n\ndef nhot_labels(label2idx, csv_labels, fnames, c):\n    \n    all_idx = {k: n_hot([label2idx[o] for o in v], c)\n               for k,v in csv_labels.items()}\n    return np.stack([all_idx[o] for o in fnames])\n\ndef csv_source(folder, csv_file, skip_header=True, suffix=\'\', continuous=False):\n    fnames,csv_labels = parse_csv_labels(csv_file, skip_header)\n    return dict_source(folder, fnames, csv_labels, suffix, continuous)\n\ndef dict_source(folder, fnames, csv_labels, suffix=\'\', continuous=False):\n    all_labels = sorted(list(set(p for o in csv_labels.values() for p in o)))\n    full_names = [os.path.join(folder,str(fn)+suffix) for fn in fnames]\n    if continuous:\n        label_arr = np.array([np.array(csv_labels[i]).astype(np.float32)\n                for i in fnames])\n    else:\n        label2idx = {v:k for k,v in enumerate(all_labels)}\n        label_arr = nhot_labels(label2idx, csv_labels, fnames, len(all_labels))\n        is_single = np.all(label_arr.sum(axis=1)==1)\n        if is_single: label_arr = np.argmax(label_arr, axis=1)\n    return full_names, label_arr, all_labels\n\nclass BaseDataset(Dataset):\n    """"""An abstract class representing a fastai dataset, it extends torch.utils.data.Dataset.""""""\n    def __init__(self, transform=None):\n        self.transform = transform\n        self.n = self.get_n()\n        self.c = self.get_c()\n        self.sz = self.get_sz()\n\n    def get1item(self, idx):\n        x,y = self.get_x(idx),self.get_y(idx)\n        return self.get(self.transform, x, y)\n\n    def __getitem__(self, idx):\n        if isinstance(idx,slice):\n            xs,ys = zip(*[self.get1item(i) for i in range(*idx.indices(self.n))])\n            return np.stack(xs),ys\n        return self.get1item(idx)\n\n    def __len__(self): return self.n\n\n    def get(self, tfm, x, y):\n        return (x,y) if tfm is None else tfm(x,y)\n\n    @abstractmethod\n    def get_n(self):\n        """"""Return number of elements in the dataset == len(self).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_c(self):\n        """"""Return number of classes in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_sz(self):\n        """"""Return maximum size of an image in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_x(self, i):\n        """"""Return i-th example (image, wav, etc).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_y(self, i):\n        """"""Return i-th label.""""""\n        raise NotImplementedError\n\n    @property\n    def is_multi(self):\n        """"""Returns true if this data set contains multiple labels per sample.""""""\n        return False\n\n    @property\n    def is_reg(self):\n        """"""True if the data set is used to train regression models.""""""\n        return False\n\ndef open_image(fn):\n    """""" Opens an image using OpenCV given the file path.\n\n    Arguments:\n        fn: the file path of the image\n\n    Returns:\n        The image in RGB format as numpy array of floats normalized to range between 0.0 - 1.0\n    """"""\n    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n    if not os.path.exists(fn):\n        raise OSError(\'No such file or directory: {}\'.format(fn))\n    elif os.path.isdir(fn):\n        raise OSError(\'Is a directory: {}\'.format(fn))\n    else:\n        #res = np.array(Image.open(fn), dtype=np.float32)/255\n        #if len(res.shape)==2: res = np.repeat(res[...,None],3,2)\n        #return res\n        try:\n            im = cv2.imread(str(fn), flags).astype(np.float32)/255\n            if im is None: raise OSError(f\'File not recognized by opencv: {fn}\')\n            return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        except Exception as e:\n            raise OSError(\'Error handling image at: {}\'.format(fn)) from e\n\nclass FilesDataset(BaseDataset):\n    def __init__(self, fnames, transform, path):\n        self.path,self.fnames = path,fnames\n        super().__init__(transform)\n    def get_sz(self): return self.transform.sz\n    def get_x(self, i): return open_image(os.path.join(self.path, self.fnames[i]))\n    def get_n(self): return len(self.fnames)\n\n    def resize_imgs(self, targ, new_path):\n        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n        return self.__class__(self.fnames, self.y, self.transform, dest)\n\n    def denorm(self,arr):\n        """"""Reverse the normalization done to a batch of images.\n\n        Arguments:\n            arr: of shape/size (N,3,sz,sz)\n        """"""\n        if type(arr) is not np.ndarray: arr = to_np(arr)\n        if len(arr.shape)==3: arr = arr[None]\n        return self.transform.denorm(np.rollaxis(arr,1,4))\n\n\nclass FilesArrayDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    def get_y(self, i): return self.y[i]\n    def get_c(self):\n        return self.y.shape[1] if len(self.y.shape)>1 else 0\n\nclass FilesIndexArrayDataset(FilesArrayDataset):\n    def get_c(self): return int(self.y.max())+1\n\n\nclass FilesNhotArrayDataset(FilesArrayDataset):\n    @property\n    def is_multi(self): return True\n\n\nclass FilesIndexArrayRegressionDataset(FilesArrayDataset):\n    def is_reg(self): return True\n\nclass ArraysDataset(BaseDataset):\n    def __init__(self, x, y, transform):\n        self.x,self.y=x,y\n        assert(len(x)==len(y))\n        super().__init__(transform)\n    def get_x(self, i): return self.x[i]\n    def get_y(self, i): return self.y[i]\n    def get_n(self): return len(self.y)\n    def get_sz(self): return self.x.shape[1]\n\n\nclass ArraysIndexDataset(ArraysDataset):\n    def get_c(self): return int(self.y.max())+1\n    def get_y(self, i): return self.y[i]\n\n\nclass ArraysNhotDataset(ArraysDataset):\n    def get_c(self): return self.y.shape[1]\n    @property\n    def is_multi(self): return True\n\n\nclass ModelData():\n    def __init__(self, path, trn_dl, val_dl, test_dl=None):\n        self.path,self.trn_dl,self.val_dl,self.test_dl = path,trn_dl,val_dl,test_dl\n\n    @classmethod\n    def from_dls(cls, path,trn_dl,val_dl,test_dl=None):\n        #trn_dl,val_dl = DataLoader(trn_dl),DataLoader(val_dl)\n        #if test_dl: test_dl = DataLoader(test_dl)\n        return cls(path, trn_dl, val_dl, test_dl)\n\n    @property\n    def is_reg(self): return self.trn_ds.is_reg\n    @property\n    def is_multi(self): return self.trn_ds.is_multi\n    @property\n    def trn_ds(self): return self.trn_dl.dataset\n    @property\n    def val_ds(self): return self.val_dl.dataset\n    @property\n    def test_ds(self): return self.test_dl.dataset\n    @property\n    def trn_y(self): return self.trn_ds.y\n    @property\n    def val_y(self): return self.val_ds.y\n\n\nclass ImageData(ModelData):\n    def __init__(self, path, datasets, bs, num_workers, classes):\n        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n            self.get_dl(ds,shuf) for ds,shuf in [\n                (trn_ds,True),(val_ds,False),(fix_ds,False),(aug_ds,False),\n                (test_ds,False),(test_aug_ds,False)\n            ]\n        ]\n\n    def get_dl(self, ds, shuffle):\n        if ds is None: return None\n        return DataLoader(ds, batch_size=self.bs, shuffle=shuffle,\n            num_workers=self.num_workers, pin_memory=False)\n\n    @property\n    def sz(self): return self.trn_ds.sz\n    @property\n    def c(self): return self.trn_ds.c\n\n    def resized(self, dl, targ, new_path):\n        return dl.dataset.resize_imgs(targ,new_path) if dl else None\n\n    def resize(self, targ_sz, new_path=\'tmp\'):\n        new_ds = []\n        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n        else: dls += [None,None]\n        t = tqdm_notebook(dls)\n        for dl in t: new_ds.append(self.resized(dl, targ_sz, new_path))\n        t.close()\n        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)\n\n    @staticmethod\n    def get_ds(fn, trn, val, tfms, test=None, **kwargs):\n        res = [\n            fn(trn[0], trn[1], tfms[0], **kwargs), # train\n            fn(val[0], val[1], tfms[1], **kwargs), # val\n            fn(trn[0], trn[1], tfms[1], **kwargs), # fix\n            fn(val[0], val[1], tfms[0], **kwargs)  # aug\n        ]\n        if test is not None:\n            if isinstance(test, tuple):\n                test_lbls = test[1]\n                test = test[0]\n            else:\n                test_lbls = np.zeros((len(test),1))\n            res += [\n                fn(test, test_lbls, tfms[1], **kwargs), # test\n                fn(test, test_lbls, tfms[0], **kwargs)  # test_aug\n            ]\n        else: res += [None,None]\n        return res\n\n\nclass ImageClassifierData(ImageData):\n    @classmethod\n    def from_arrays(cls, path, trn, val, bs=64, tfms=(None,None), classes=None, num_workers=4, test=None):\n        """""" Read in images and their labels given as numpy arrays\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            trn: a tuple of training data matrix and target label/classification array (e.g. `trn=(x,y)` where `x` has the\n                shape of `(5000, 784)` and `y` has the shape of `(5000,)`)\n            val: a tuple of validation data matrix and target label/classification array.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            classes: a list of all labels/classifications\n            num_workers: a number of workers\n            test: a matrix of test data (the shape should match `trn[0]`)\n\n        Returns:\n            ImageClassifierData\n        """"""\n        datasets = cls.get_ds(ArraysIndexDataset, trn, val, tfms, test=test)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\n    @classmethod\n    def from_paths(cls, path, bs=64, tfms=(None,None), trn_name=\'train\', val_name=\'valid\', test_name=None, test_with_labels=False, num_workers=8):\n        """""" Read in images and their labels given as sub-folder names\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            trn_name: a name of the folder that contains training images.\n            val_name:  a name of the folder that contains validation images.\n            test_name:  a name of the folder that contains test images.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not(tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        trn,val = [folder_source(path, o) for o in (trn_name, val_name)]\n        if test_name:\n            test = folder_source(path, test_name) if test_with_labels else read_dir(path, test_name)\n        else: test = None\n        datasets = cls.get_ds(FilesIndexArrayDataset, trn, val, tfms, path=path, test=test)\n        return cls(path, datasets, bs, num_workers, classes=trn[2])\n\n    @classmethod\n    def from_csv(cls, path, folder, csv_fname, bs=64, tfms=(None,None),\n               val_idxs=None, suffix=\'\', test_name=None, continuous=False, skip_header=True, num_workers=8):\n        """""" Read in images and their labels given as a CSV file.\n\n        This method should be used when training image labels are given in an CSV file as opposed to\n        sub-directories with label names.\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            folder: a name of the folder in which training images are contained.\n            csv_fname: a name of the CSV file which contains target labels.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            val_idxs: index of images to be used for validation. e.g. output of `get_cv_idxs`.\n                If None, default arguments to get_cv_idxs are used.\n            suffix: suffix to add to image names in CSV file (sometimes CSV only contains the file name without file\n                    extension e.g. \'.jpg\' - in which case, you can set suffix as \'.jpg\')\n            test_name: a name of the folder which contains test images.\n            continuous: TODO\n            skip_header: skip the first row of the CSV file.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not (tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        assert not (os.path.isabs(folder)), ""folder needs to be a relative path""\n        fnames,y,classes = csv_source(folder, csv_fname, skip_header, suffix, continuous=continuous)\n        return cls.from_names_and_array(path, fnames, y, classes, val_idxs, test_name,\n                num_workers=num_workers, suffix=suffix, tfms=tfms, bs=bs, continuous=continuous)\n\n    @classmethod\n    def from_names_and_array(cls, path, fnames,y,classes, val_idxs=None, test_name=None,\n            num_workers=8, suffix=\'\', tfms=(None,None), bs=64, continuous=False):\n        val_idxs = get_cv_idxs(len(fnames)) if val_idxs is None else val_idxs\n        ((val_fnames,trn_fnames),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), y)\n\n        test_fnames = read_dir(path, test_name) if test_name else None\n        if continuous: f = FilesIndexArrayRegressionDataset\n        else:\n            f = FilesIndexArrayDataset if len(trn_y.shape)==1 else FilesNhotArrayDataset\n        datasets = cls.get_ds(f, (trn_fnames,trn_y), (val_fnames,val_y), tfms,\n                               path=path, test=test_fnames)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\ndef split_by_idx(idxs, *a):\n    """"""\n    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n    This can be used to split multiple arrays containing training data to validation and training set.\n\n    :param idxs [int]: list of indexes selected\n    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n    :return: list of tuples, each containing a split of corresponding array from *a.\n            First element of each tuple is an array composed from elements selected by idxs,\n            second element is an array of remaining elements.\n    """"""\n    mask = np.zeros(len(a[0]),dtype=bool)\n    mask[np.array(idxs)] = True\n    return [(o[mask],o[~mask]) for o in a]\n\n'"
fastai/courses/dl1/fastai/executors.py,0,"b'import collections\nimport itertools\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\nclass LazyThreadPoolExecutor(ThreadPoolExecutor):\n    def map(self, fn, *iterables, timeout=None, chunksize=1, prefetch=None):\n        """"""\n        Collects iterables lazily, rather than immediately.\n        Docstring same as parent: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor\n        Implmentation taken from this PR: https://github.com/python/cpython/pull/707\n        """"""\n        if timeout is not None: end_time = timeout + time.time()\n        if prefetch is None: prefetch = self._max_workers\n        if prefetch < 0: raise ValueError(""prefetch count may not be negative"")\n        argsiter = zip(*iterables)\n        fs = collections.deque(self.submit(fn, *args) for args in itertools.islice(argsiter, self._max_workers+prefetch))\n        # Yield must be hidden in closure so that the futures are submitted before the first iterator value is required.\n        def result_iterator():\n            nonlocal argsiter\n            try:\n                while fs:\n                    res = fs[0].result() if timeout is None else fs[0].result(end_time-time.time())\n                    # Got a result, future needn\'t be cancelled\n                    del fs[0]\n                    # Dispatch next task before yielding to keep pipeline full\n                    if argsiter:\n                        try:\n                            args = next(argsiter)\n                        except StopIteration:\n                            argsiter = None\n                        else:\n                            fs.append(self.submit(fn, *args))\n                    yield res\n            finally:\n                for future in fs: future.cancel()\n        return result_iterator()'"
fastai/courses/dl1/fastai/fp16.py,2,"b'import torch\nimport torch.nn as nn\n\n\nclass FP16(nn.Module):\n    def __init__(self, module): \n        super(FP16, self).__init__()\n        self.module = batchnorm_to_fp32(module.half())\n        \n    def forward(self, input): \n        return self.module(input.half())\n    \n    def load_state_dict(self, *inputs, **kwargs):\n        self.module.load_state_dict(*inputs, **kwargs)\n\n    def state_dict(self, *inputs, **kwargs):\n        return self.module.state_dict(*inputs, **kwargs)\n\ndef batchnorm_to_fp32(module):\n    \'\'\'\n    BatchNorm layers to have parameters in single precision.\n    Find all layers and convert them back to float. This can\'t\n    be done with built in .apply as that function will apply\n    fn to all modules, parameters, and buffers. Thus we wouldn\'t\n    be able to guard the float conversion based on the module type.\n    \'\'\'\n    if isinstance(module, nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        batchnorm_to_fp32(child)\n    return module\n\ndef copy_model_to_fp32(m, optim):\n    """"""  Creates a fp32 copy of model parameters and sets optimizer parameters\n    """"""\n    fp32_params = [m_param.clone().type(torch.cuda.FloatTensor).detach() for m_param in m.parameters()]\n    optim_groups = [group[\'params\'] for group in optim.param_groups]\n    iter_fp32_params = iter(fp32_params)\n    for group_params in optim_groups:\n        for i in range(len(group_params)):\n            fp32_param = next(iter_fp32_params)\n            fp32_param.requires_grad = group_params[i].requires_grad\n            group_params[i] = fp32_param\n    return fp32_params\n\ndef copy_fp32_to_model(m, fp32_params):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        m_param.data.copy_(fp32_param.data)\n\ndef update_fp32_grads(fp32_params, m):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        if fp32_param.grad is None:\n            fp32_param.grad = nn.Parameter(fp32_param.data.new().resize_(*fp32_param.data.size()))\n        fp32_param.grad.data.copy_(m_param.grad.data)\n\n'"
fastai/courses/dl1/fastai/imports.py,0,"b""from IPython.lib.deepreload import reload as dreload\nimport PIL, os, numpy as np, math, collections, threading, json, bcolz, random, scipy, cv2\nimport pandas as pd, pickle, sys, itertools, string, sys, re, datetime, time, shutil, copy\nimport seaborn as sns, matplotlib\nimport IPython, graphviz, sklearn_pandas, sklearn, warnings, pdb\nimport contextlib\nfrom abc import abstractmethod\nfrom glob import glob, iglob\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom itertools import chain\nfrom functools import partial\nfrom collections import Iterable, Counter, OrderedDict\nfrom isoweek import Week\nfrom pandas_summary import DataFrameSummary\nfrom IPython.lib.display import FileLink\nfrom PIL import Image, ImageEnhance, ImageOps\nfrom sklearn import metrics, ensemble, preprocessing\nfrom operator import itemgetter, attrgetter\nfrom pathlib import Path\nfrom distutils.version import LooseVersion\n\nfrom matplotlib import pyplot as plt, rcParams, animation\nfrom ipywidgets import interact, interactive, fixed, widgets\nmatplotlib.rc('animation', html='html5')\nnp.set_printoptions(precision=5, linewidth=110, suppress=True)\n\nfrom ipykernel.kernelapp import IPKernelApp\ndef in_notebook(): return IPKernelApp.initialized()\n\ndef in_ipynb():\n    try:\n        cls = get_ipython().__class__.__name__\n        return cls == 'ZMQInteractiveShell'\n    except NameError:\n        return False\n\nimport tqdm as tq\nfrom tqdm import tqdm_notebook, tnrange\n\ndef clear_tqdm():\n    inst = getattr(tq.tqdm, '_instances', None)\n    if not inst: return\n    try:\n        for i in range(len(inst)): inst.pop().close()\n    except Exception:\n        pass\n\nif in_notebook():\n    def tqdm(*args, **kwargs):\n        clear_tqdm()\n        return tq.tqdm(*args, file=sys.stdout, **kwargs)\n    def trange(*args, **kwargs):\n        clear_tqdm()\n        return tq.trange(*args, file=sys.stdout, **kwargs)\nelse:\n    from tqdm import tqdm, trange\n    tnrange=trange\n    tqdm_notebook=tqdm\n\n"""
fastai/courses/dl1/fastai/initializers.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\ndef cond_init(m, init_fn):\n    if not isinstance(m, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):\n        if hasattr(m, 'weight'): init_fn(m.weight)\n        if hasattr(m, 'bias'): m.bias.data.fill_(0.)\n\ndef apply_init(m, init_fn):\n    m.apply(lambda x: cond_init(x, init_fn))\n\n\n"""
fastai/courses/dl1/fastai/io.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\nimport gzip\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\n\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None: self.total = tsize\n        self.update(b * bsize - self.n)\n\ndef get_data(url, filename):\n    if not os.path.exists(filename):\n\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n\n"""
fastai/courses/dl1/fastai/layer_optimizer.py,0,"b""from .imports import *\nfrom .torch_imports import *\nfrom .core import *\n\ndef opt_params(parm, lr, wd):\n    return {'params': chain_params(parm), 'lr':lr, 'weight_decay':wd}\n\nclass LayerOptimizer():\n    def __init__(self, opt_fn, layer_groups, lrs, wds=None):\n        if not isinstance(layer_groups, (list,tuple)): layer_groups=[layer_groups]\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(layer_groups)\n        if wds is None: wds=0.\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(layer_groups)\n        self.layer_groups,self.lrs,self.wds = layer_groups,lrs,wds\n        self.opt = opt_fn(self.opt_params())\n\n    def opt_params(self):\n        assert(len(self.layer_groups) == len(self.lrs))\n        assert(len(self.layer_groups) == len(self.wds))\n        params = list(zip(self.layer_groups,self.lrs,self.wds))\n        return [opt_params(*p) for p in params]\n\n    @property\n    def lr(self): return self.lrs[-1]\n\n    @property\n    def mom(self):\n        if 'betas' in self.opt.param_groups[0]:\n            return self.opt.param_groups[0]['betas'][0]\n        else:\n            return self.opt.param_groups[0]['momentum']\n\n    def set_lrs(self, lrs):\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(self.layer_groups)\n        set_lrs(self.opt, lrs)\n        self.lrs=lrs\n\n    def set_wds(self, wds):\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(self.layer_groups)\n        set_wds(self.opt, wds)\n        self.wds=wds\n    \n    def set_mom(self,momentum):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (momentum, pg['betas'][1])\n        else:\n            for pg in self.opt.param_groups: pg['momentum'] = momentum\n    \n    def set_beta(self,beta):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (pg['betas'][0],beta)\n        elif 'alpha' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['alpha'] = beta\n\n    def set_opt_fn(self, opt_fn):\n        if type(self.opt) != type(opt_fn(self.opt_params())):\n            self.opt = opt_fn(self.opt_params())\n\ndef zip_strict_(l, r):\n    assert(len(l) == len(r))\n    return zip(l, r)\n\ndef set_lrs(opt, lrs):\n    if not isinstance(lrs, Iterable): lrs=[lrs]\n    if len(lrs)==1: lrs=lrs*len(opt.param_groups)\n    for pg,lr in zip_strict_(opt.param_groups,lrs): pg['lr'] = lr\n\ndef set_wds(opt, wds):\n    if not isinstance(wds, Iterable): wds=[wds]\n    if len(wds)==1: wds=wds*len(opt.param_groups)\n    assert(len(opt.param_groups) == len(wds))\n    for pg,wd in zip_strict_(opt.param_groups,wds): pg['weight_decay'] = wd\n\n"""
fastai/courses/dl1/fastai/layers.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1,1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n\nclass Lambda(nn.Module):\n    def __init__(self, f): super().__init__(); self.f=f\n    def forward(self, x): return self.f(x)\n\nclass Flatten(nn.Module):\n    def __init__(self): super().__init__()\n    def forward(self, x): return x.view(x.size(0), -1)\n\n'"
fastai/courses/dl1/fastai/learner.py,1,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .model import *\nfrom .dataset import *\nfrom .sgdr import *\nfrom .layer_optimizer import *\nfrom .layers import *\nfrom .metrics import *\nfrom .losses import *\nfrom .swa import *\nfrom .fp16 import *\nfrom .lsuv_initializer import apply_lsuv_init\nimport time\n\n\nclass Learner():\n    def __init__(self, data, models, opt_fn=None, tmp_name=\'tmp\', models_name=\'models\', metrics=None, clip=None, crit=None):\n        """"""\n        Combines a ModelData object with a nn.Module object, such that you can train that\n        module.\n        data (ModelData): An instance of ModelData.\n        models(module): chosen neural architecture for solving a supported problem.\n        opt_fn(function): optimizer function, uses SGD with Momentum of .9 if none.\n        tmp_name(str): output name of the directory containing temporary files from training process\n        models_name(str): output name of the directory containing the trained model\n        metrics(list): array of functions for evaluating a desired metric. Eg. accuracy.\n        clip(float): gradient clip chosen to limit the change in the gradient to prevent exploding gradients Eg. .3\n        """"""\n        self.data_,self.models,self.metrics = data,models,metrics\n        self.sched=None\n        self.wd_sched = None\n        self.clip = None\n        self.opt_fn = opt_fn or SGD_Momentum(0.9)\n        self.tmp_path = tmp_name if os.path.isabs(tmp_name) else os.path.join(self.data.path, tmp_name)\n        self.models_path = models_name if os.path.isabs(models_name) else os.path.join(self.data.path, models_name)\n        os.makedirs(self.tmp_path, exist_ok=True)\n        os.makedirs(self.models_path, exist_ok=True)\n        self.crit = crit if crit else self._get_crit(data)\n        self.reg_fn = None\n        self.fp16 = False\n\n    @classmethod\n    def from_model_data(cls, m, data, **kwargs):\n        self = cls(data, BasicModel(to_gpu(m)), **kwargs)\n        self.unfreeze()\n        return self\n\n    def __getitem__(self,i): return self.children[i]\n\n    @property\n    def children(self): return children(self.model)\n\n    @property\n    def model(self): return self.models.model\n\n    @property\n    def data(self): return self.data_\n\n    def summary(self): return model_summary(self.model, [3,self.data.sz,self.data.sz])\n\n    def __repr__(self): return self.model.__repr__()\n    \n    def lsuv_init(self, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False):         \n        x = V(next(iter(self.data.trn_dl))[0])\n        self.models.model=apply_lsuv_init(self.model, x, needed_std=needed_std, std_tol=std_tol,\n                            max_attempts=max_attempts, do_orthonorm=do_orthonorm, \n                            cuda=USE_GPU and torch.cuda.is_available())\n\n    def set_bn_freeze(self, m, do_freeze):\n        if hasattr(m, \'running_mean\'): m.bn_freeze = do_freeze\n\n    def bn_freeze(self, do_freeze):\n        apply_leaf(self.model, lambda m: self.set_bn_freeze(m, do_freeze))\n\n    def freeze_to(self, n):\n        c=self.get_layer_groups()\n        for l in c:     set_trainable(l, False)\n        for l in c[n:]: set_trainable(l, True)\n\n    def freeze_all_but(self, n):\n        c=self.get_layer_groups()\n        for l in c: set_trainable(l, False)\n        set_trainable(c[n], True)\n\n    def unfreeze(self): self.freeze_to(0)\n\n    def get_model_path(self, name): return os.path.join(self.models_path,name)+\'.h5\'\n    \n    def save(self, name): \n        save_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): save_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n                       \n    def load(self, name): \n        load_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): load_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n\n    def set_data(self, data): self.data_ = data\n\n    def get_cycle_end(self, name):\n        if name is None: return None\n        return lambda sched, cycle: self.save_cycle(name, cycle)\n\n    def save_cycle(self, name, cycle): self.save(f\'{name}_cyc_{cycle}\')\n    def load_cycle(self, name, cycle): self.load(f\'{name}_cyc_{cycle}\')\n\n    def half(self):\n        if self.fp16: return\n        self.fp16 = True\n        if type(self.model) != FP16: self.models.model = FP16(self.model)\n    def float(self):\n        if not self.fp16: return\n        self.fp16 = False\n        if type(self.model) == FP16: self.models.model = self.model.module\n        self.model.float()\n\n    def fit_gen(self, model, data, layer_opt, n_cycle, cycle_len=None, cycle_mult=1, cycle_save_name=None, best_save_name=None,\n                use_clr=None, use_clr_beta=None, metrics=None, callbacks=None, use_wd_sched=False, norm_wds=False,             \n                wds_sched_mult=None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n\n        """"""Method does some preparation before finally delegating to the \'fit\' method for\n        fitting the model. Namely, if cycle_len is defined, it adds a \'Cosine Annealing\'\n        scheduler for varying the learning rate across iterations.\n\n        Method also computes the total number of epochs to fit based on provided \'cycle_len\',\n        \'cycle_mult\', and \'n_cycle\' parameters.\n\n        Args:\n            model (Learner):  Any neural architecture for solving a supported problem.\n                Eg. ResNet-34, RNN_Learner etc.\n\n            data (ModelData): An instance of ModelData.\n\n            layer_opt (LayerOptimizer): An instance of the LayerOptimizer class\n\n            n_cycle (int): number of cycles\n\n            cycle_len (int):  number of cycles before lr is reset to the initial value.\n                E.g if cycle_len = 3, then the lr is varied between a maximum\n                and minimum value over 3 epochs.\n\n            cycle_mult (int): additional parameter for influencing how the lr resets over\n                the cycles. For an intuitive explanation, please see\n                https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb\n\n            cycle_save_name (str): use to save the weights at end of each cycle\n\n            best_save_name (str): use to save weights of best model during training.\n\n            metrics (function): some function for evaluating a desired metric. Eg. accuracy.\n\n            callbacks (list(Callback)): callbacks to apply during the training.\n\n            use_wd_sched (bool, optional): set to True to enable weight regularization using\n                the technique mentioned in https://arxiv.org/abs/1711.05101. When this is True\n                alone (see below), the regularization is detached from gradient update and\n                applied directly to the weights.\n\n            norm_wds (bool, optional): when this is set to True along with use_wd_sched, the\n                regularization factor is normalized with each training cycle.\n\n            wds_sched_mult (function, optional): when this is provided along with use_wd_sched\n                as True, the value computed by this function is multiplied with the regularization\n                strength. This function is passed the WeightDecaySchedule object. And example\n                function that can be passed is:\n                            f = lambda x: np.array(x.layer_opt.lrs) / x.init_lrs\n                            \n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work.\n                \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n                \n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n\n        Returns:\n            None\n        """"""\n\n        if callbacks is None: callbacks=[]\n        if metrics is None: metrics=self.metrics\n\n        if use_wd_sched:\n            # This needs to come before CosAnneal() because we need to read the initial learning rate from\n            # layer_opt.lrs - but CosAnneal() alters the layer_opt.lrs value initially (divides by 100)\n            if np.sum(layer_opt.wds) == 0:\n                print(\'fit() warning: use_wd_sched is set to True, but weight decay(s) passed are 0. Use wds to \'\n                      \'pass weight decay values.\')\n            batch_per_epoch = len(data.trn_dl)\n            cl = cycle_len if cycle_len else 1\n            self.wd_sched = WeightDecaySchedule(layer_opt, batch_per_epoch, cl, cycle_mult, n_cycle,\n                                                norm_wds, wds_sched_mult)\n            callbacks += [self.wd_sched]\n\n        if use_clr is not None:\n            clr_div,cut_div = use_clr[:2]\n            moms = use_clr[2:] if len(use_clr) > 2 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=clr_div, cut_div=cut_div,\n                                    momentums=moms)\n        elif use_clr_beta is not None:\n            div,pct = use_clr_beta[:2]\n            moms = use_clr_beta[2:] if len(use_clr_beta) > 3 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR_beta(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=div,\n                                    pct=pct, momentums=moms)\n        elif cycle_len:\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            cycle_batches = len(data.trn_dl)*cycle_len\n            self.sched = CosAnneal(layer_opt, cycle_batches, on_cycle_end=cycle_end, cycle_mult=cycle_mult)\n        elif not self.sched: self.sched=LossRecorder(layer_opt)\n        callbacks+=[self.sched]\n\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(model)\n            callbacks+=[SWA(model, self.swa_model, swa_start)]\n\n        n_epoch = int(sum_geom(cycle_len if cycle_len else 1, cycle_mult, n_cycle))\n        return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def get_layer_groups(self): return self.models.get_layer_groups()\n\n    def get_layer_opt(self, lrs, wds):\n\n        """"""Method returns an instance of the LayerOptimizer class, which\n        allows for setting differential learning rates for different\n        parts of the model.\n\n        An example of how a model maybe differentiated into different parts\n        for application of differential learning rates and weight decays is\n        seen in ../.../courses/dl1/fastai/conv_learner.py, using the dict\n        \'model_meta\'. Currently, this seems supported only for convolutional\n        networks such as VGG-19, ResNet-XX etc.\n\n        Args:\n            lrs (float or list(float)): learning rate(s) for the model\n\n            wds (float or list(float)): weight decay parameter(s).\n\n        Returns:\n            An instance of a LayerOptimizer\n        """"""\n        return LayerOptimizer(self.opt_fn, self.get_layer_groups(), lrs, wds)\n\n    def fit(self, lrs, n_cycle, wds=None, **kwargs):\n\n        """"""Method gets an instance of LayerOptimizer and delegates to self.fit_gen(..)\n\n        Note that one can specify a list of learning rates which, when appropriately\n        defined, will be applied to different segments of an architecture. This seems\n        mostly relevant to ImageNet-trained models, where we want to alter the layers\n        closest to the images by much smaller amounts.\n\n        Likewise, a single or list of weight decay parameters can be specified, which\n        if appropriate for a model, will apply variable weight decay parameters to\n        different segments of the model.\n\n        Args:\n            lrs (float or list(float)): learning rate for the model\n\n            n_cycle (int): number of cycles (or iterations) to fit the model for\n\n            wds (float or list(float)): weight decay parameter(s).\n\n            kwargs: other arguments\n\n        Returns:\n            None\n        """"""\n        self.sched = None\n        layer_opt = self.get_layer_opt(lrs, wds)\n        return self.fit_gen(self.model, self.data, layer_opt, n_cycle, **kwargs)\n\n    def warm_up(self, lr, wds=None):\n        layer_opt = self.get_layer_opt(lr/4, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), lr, linear=True)\n        return self.fit_gen(self.model, self.data, layer_opt, 1)\n\n    def lr_find(self, start_lr=1e-5, end_lr=10, wds=None, linear=False, **kwargs):\n        """"""Helps you find an optimal learning rate for a model.\n\n         It uses the technique developed in the 2015 paper\n         `Cyclical Learning Rates for Training Neural Networks`, where\n         we simply keep increasing the learning rate from a very small value,\n         until the loss starts decreasing.\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            wds (iterable/float)\n\n        Examples:\n            As training moves us closer to the optimal weights for a model,\n            the optimal learning rate will be smaller. We can take advantage of\n            that knowledge and provide lr_find() with a starting learning rate\n            1000x smaller than the model\'s current learning rate as such:\n\n            >> learn.lr_find(lr/1000)\n\n            >> lrs = np.array([ 1e-4, 1e-3, 1e-2 ])\n            >> learn.lr_find(lrs / 1000)\n\n        Notes:\n            lr_find() may finish before going through each batch of examples if\n            the loss decreases enough.\n\n        .. _Cyclical Learning Rates for Training Neural Networks:\n            http://arxiv.org/abs/1506.01186\n\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), end_lr, linear=linear)\n        self.fit_gen(self.model, self.data, layer_opt, 1, **kwargs)\n        self.load(\'tmp\')\n\n    def lr_find2(self, start_lr=1e-5, end_lr=10, num_it = 100, wds=None, linear=False, stop_dv=True, **kwargs):\n        """"""A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n        At each step, it computes the validation loss and the metrics on the next\n        batch of the validation data, so it\'s slower than lr_find().\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            num_it : the number of iterations you want it to run\n            wds (iterable/float)\n            stop_dv : stops (or not) when the losses starts to explode.\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder2(layer_opt, num_it, end_lr, linear=linear, metrics=self.metrics, stop_dv=stop_dv)\n        self.fit_gen(self.model, self.data, layer_opt, num_it//len(self.data.trn_dl) + 1, all_val=True, **kwargs)\n        self.load(\'tmp\')\n\n    def predict(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict(m, dl)\n\n    def predict_with_targs(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict_with_targs(m, dl)\n\n    def predict_dl(self, dl): return predict_with_targs(self.model, dl)[0]\n\n    def predict_array(self, arr):\n        self.model.eval()\n        return to_np(self.model(to_gpu(V(T(arr)))))\n\n    def TTA(self, n_aug=4, is_test=False):\n        """""" Predict with Test Time Augmentation (TTA)\n\n        Additional to the original test/validation images, apply image augmentation to them\n        (just like for training images) and calculate the mean of predictions. The intent\n        is to increase the accuracy of predictions by examining the images using multiple\n        perspectives.\n\n        Args:\n            n_aug: a number of augmentation images to use per original image\n            is_test: indicate to use test images; otherwise use validation images\n\n        Returns:\n            (tuple): a tuple containing:\n\n                log predictions (numpy.ndarray): log predictions (i.e. `np.exp(log_preds)` will return probabilities)\n                targs (numpy.ndarray): target values when `is_test==False`; zeros otherwise.\n        """"""\n        dl1 = self.data.test_dl     if is_test else self.data.val_dl\n        dl2 = self.data.test_aug_dl if is_test else self.data.aug_dl\n        preds1,targs = predict_with_targs(self.model, dl1)\n        preds1 = [preds1]*math.ceil(n_aug/4)\n        preds2 = [predict_with_targs(self.model, dl2)[0] for i in tqdm(range(n_aug), leave=False)]\n        return np.stack(preds1+preds2), targs\n\n    def fit_opt_sched(self, phases, cycle_save_name=None, best_save_name=None, stop_div=False, data_list=None, callbacks=None, \n                      cut = None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n        """"""Wraps us the content of phases to send them to model.fit(..)\n\n        This will split the training in several parts, each with their own learning rates/\n        wds/momentums/optimizer detailed in phases.\n\n        Additionaly we can add a list of different data objets in data_list to train\n        on different datasets (to change the size for instance) for each of these groups.\n\n        Args:\n            phases: a list of TrainingPhase objects\n            stop_div: when True, stops the training if the loss goes too high\n            data_list: a list of different Data objects.\n            kwargs: other arguments\n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work. \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n        Returns:\n            None\n        """"""\n        if data_list is None: data_list=[]\n        if callbacks is None: callbacks=[]\n        layer_opt = LayerOptimizer(phases[0].opt_fn, self.get_layer_groups(), 1e-2, phases[0].wds)\n        self.sched = OptimScheduler(layer_opt, phases, len(self.data.trn_dl), stop_div)\n        callbacks.append(self.sched)\n        metrics = self.metrics\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(self.model)\n            callbacks+=[SWA(self.model, self.swa_model, swa_start)]\n        n_epochs = [phase.epochs for phase in phases] if cut is None else cut\n        if len(data_list)==0: data_list = [self.data]\n        return fit(self.model, data_list, n_epochs,layer_opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n'"
fastai/courses/dl1/fastai/lm_rnn.py,5,"b'import warnings\nfrom .imports import *\nfrom .torch_imports import *\nfrom .rnn_reg import LockedDropout,WeightDrop,EmbeddingDropout\nfrom .model import Stepper\nfrom .core import set_grad_enabled\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef seq2seq_reg(output, xtra, loss, alpha=0, beta=0):\n    hs,dropped_hs = xtra\n    if alpha:  # Activation Regularization\n        loss = loss + sum(alpha * dropped_hs[-1].pow(2).mean())\n    if beta:   # Temporal Activation Regularization (slowness)\n        h = hs[-1]\n        if len(h)>1: loss = loss + sum(beta * (h[1:] - h[:-1]).pow(2).mean())\n    return loss\n\n\ndef repackage_var(h):\n    """"""Wraps h in new Variables, to detach them from their history.""""""\n    if IS_TORCH_04: return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)\n    else: return Variable(h.data) if type(h) == Variable else tuple(repackage_var(v) for v in h)\n\n\nclass RNN_Encoder(nn.Module):\n\n    """"""A custom RNN encoder network that uses\n        - an embedding matrix to encode input,\n        - a stack of LSTM layers to drive the network, and\n        - variational dropouts in the embedding and LSTM layers\n\n        The architecture for this network was inspired by the work done in\n        ""Regularizing and Optimizing LSTM Language Models"".\n        (https://arxiv.org/pdf/1708.02182.pdf)\n    """"""\n\n    initrange=0.1\n\n    def __init__(self, ntoken, emb_sz, nhid, nlayers, pad_token, bidir=False,\n                 dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5):\n        """""" Default constructor for the RNN_Encoder class\n\n            Args:\n                bs (int): batch size of input data\n                ntoken (int): number of vocabulary (or tokens) in the source dataset\n                emb_sz (int): the embedding size to use to encode each token\n                nhid (int): number of hidden activation per LSTM layer\n                nlayers (int): number of LSTM layers to use in the architecture\n                pad_token (int): the int value used for padding text.\n                dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n                dropouti (float): dropout to apply to the input layer.\n                dropoute (float): dropout to apply to the embedding layer.\n                wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n\n            Returns:\n                None\n          """"""\n\n        super().__init__()\n        self.ndir = 2 if bidir else 1\n        self.bs = 1\n        self.encoder = nn.Embedding(ntoken, emb_sz, padding_idx=pad_token)\n        self.encoder_with_dropout = EmbeddingDropout(self.encoder)\n        self.rnns = [nn.LSTM(emb_sz if l == 0 else nhid, (nhid if l != nlayers - 1 else emb_sz)//self.ndir,\n             1, bidirectional=bidir) for l in range(nlayers)]\n        if wdrop: self.rnns = [WeightDrop(rnn, wdrop) for rnn in self.rnns]\n        self.rnns = torch.nn.ModuleList(self.rnns)\n        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n\n        self.emb_sz,self.nhid,self.nlayers,self.dropoute = emb_sz,nhid,nlayers,dropoute\n        self.dropouti = LockedDropout(dropouti)\n        self.dropouths = nn.ModuleList([LockedDropout(dropouth) for l in range(nlayers)])\n\n    def forward(self, input):\n        """""" Invoked during the forward propagation of the RNN_Encoder module.\n        Args:\n            input (Tensor): input of shape (sentence length x batch_size)\n\n        Returns:\n            raw_outputs (tuple(list (Tensor), list(Tensor)): list of tensors evaluated from each RNN layer without using\n            dropouth, list of tensors evaluated from each RNN layer using dropouth,\n        """"""\n        sl,bs = input.size()\n        if bs!=self.bs:\n            self.bs=bs\n            self.reset()\n        with set_grad_enabled(self.training):\n            emb = self.encoder_with_dropout(input, dropout=self.dropoute if self.training else 0)\n            emb = self.dropouti(emb)\n            raw_output = emb\n            new_hidden,raw_outputs,outputs = [],[],[]\n            for l, (rnn,drop) in enumerate(zip(self.rnns, self.dropouths)):\n                current_input = raw_output\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    raw_output, new_h = rnn(raw_output, self.hidden[l])\n                new_hidden.append(new_h)\n                raw_outputs.append(raw_output)\n                if l != self.nlayers - 1: raw_output = drop(raw_output)\n                outputs.append(raw_output)\n\n            self.hidden = repackage_var(new_hidden)\n        return raw_outputs, outputs\n\n    def one_hidden(self, l):\n        nh = (self.nhid if l != self.nlayers - 1 else self.emb_sz)//self.ndir\n        if IS_TORCH_04: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_())\n        else: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_(), volatile=not self.training)\n\n    def reset(self):\n        self.weights = next(self.parameters()).data\n        self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.nlayers)]\n\n\nclass MultiBatchRNN(RNN_Encoder):\n    def __init__(self, bptt, max_seq, *args, **kwargs):\n        self.max_seq,self.bptt = max_seq,bptt\n        super().__init__(*args, **kwargs)\n\n    def concat(self, arrs):\n        return [torch.cat([l[si] for l in arrs]) for si in range(len(arrs[0]))]\n\n    def forward(self, input):\n        sl,bs = input.size()\n        for l in self.hidden:\n            for h in l: h.data.zero_()\n        raw_outputs, outputs = [],[]\n        for i in range(0, sl, self.bptt):\n            r, o = super().forward(input[i: min(i+self.bptt, sl)])\n            if i>(sl-self.max_seq):\n                raw_outputs.append(r)\n                outputs.append(o)\n        return self.concat(raw_outputs), self.concat(outputs)\n\nclass LinearDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, n_out, nhid, dropout, tie_encoder=None):\n        super().__init__()\n        self.decoder = nn.Linear(nhid, n_out, bias=False)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.dropout = LockedDropout(dropout)\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = self.dropout(outputs[-1])\n        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n        result = decoded.view(-1, decoded.size(1))\n        return result, raw_outputs, outputs\n\n\nclass LinearBlock(nn.Module):\n    def __init__(self, ni, nf, drop):\n        super().__init__()\n        self.lin = nn.Linear(ni, nf)\n        self.drop = nn.Dropout(drop)\n        self.bn = nn.BatchNorm1d(ni)\n\n    def forward(self, x): return self.lin(self.drop(self.bn(x)))\n\n\nclass PoolingLinearClassifier(nn.Module):\n    def __init__(self, layers, drops):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            LinearBlock(layers[i], layers[i + 1], drops[i]) for i in range(len(layers) - 1)])\n\n    def pool(self, x, bs, is_max):\n        f = F.adaptive_max_pool1d if is_max else F.adaptive_avg_pool1d\n        return f(x.permute(1,2,0), (1,)).view(bs,-1)\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = outputs[-1]\n        sl,bs,_ = output.size()\n        avgpool = self.pool(output, bs, False)\n        mxpool = self.pool(output, bs, True)\n        x = torch.cat([output[-1], mxpool, avgpool], 1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return l_x, raw_outputs, outputs\n\n\nclass SequentialRNN(nn.Sequential):\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \'reset\'): c.reset()\n\n\ndef get_language_model(n_tok, emb_sz, nhid, nlayers, pad_token,\n                 dropout=0.4, dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5, tie_weights=True):\n    """"""Returns a SequentialRNN model.\n\n    A RNN_Encoder layer is instantiated using the parameters provided.\n\n    This is followed by the creation of a LinearDecoder layer.\n\n    Also by default (i.e. tie_weights = True), the embedding matrix used in the RNN_Encoder\n    is used to  instantiate the weights for the LinearDecoder layer.\n\n    The SequentialRNN layer is the native torch\'s Sequential wrapper that puts the RNN_Encoder and\n    LinearDecoder layers sequentially in the model.\n\n    Args:\n        n_tok (int): number of unique vocabulary words (or tokens) in the source dataset\n        emb_sz (int): the embedding size to use to encode each token\n        nhid (int): number of hidden activation per LSTM layer\n        nlayers (int): number of LSTM layers to use in the architecture\n        pad_token (int): the int value used for padding text.\n        dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n        dropouti (float): dropout to apply to the input layer.\n        dropoute (float): dropout to apply to the embedding layer.\n        wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n        tie_weights (bool): decide if the weights of the embedding matrix in the RNN encoder should be tied to the\n            weights of the LinearDecoder layer.\n    Returns:\n        A SequentialRNN model\n    """"""\n\n    rnn_enc = RNN_Encoder(n_tok, emb_sz, nhid=nhid, nlayers=nlayers, pad_token=pad_token,\n                 dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    enc = rnn_enc.encoder if tie_weights else None\n    return SequentialRNN(rnn_enc, LinearDecoder(n_tok, emb_sz, dropout, tie_encoder=enc))\n\n\ndef get_rnn_classifer(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n                      dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n    rnn_enc = MultiBatchRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir,\n                      dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    return SequentialRNN(rnn_enc, PoolingLinearClassifier(layers, drops))\n\n'"
fastai/courses/dl1/fastai/losses.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\ndef fbeta_torch(y_true, y_pred, beta, threshold, eps=1e-9):\n    y_pred = (y_pred.float() > threshold).float()\n    y_true = y_true.float()\n    tp = (y_pred * y_true).sum(dim=1)\n    precision = tp / (y_pred.sum(dim=1)+eps)\n    recall = tp / (y_true.sum(dim=1)+eps)\n    return torch.mean(\n        precision*recall / (precision*(beta**2)+recall+eps) * (1+beta**2))\n\n'"
fastai/courses/dl1/fastai/lsuv_initializer.py,4,"b'""""""\nFrom https://github.com/ducha-aiki/LSUV-pytorch\n\nCopyright (C) 2017, Dmytro Mishkin\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the\n   distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\nimport numpy as np\nimport torch\nimport torch.nn.init\nimport torch.nn as nn\n\ngg = {}\ngg[\'hook_position\'] = 0\ngg[\'total_fc_conv_layers\'] = 0\ngg[\'done_counter\'] = -1\ngg[\'hook\'] = None\ngg[\'act_dict\'] = {}\ngg[\'counter_to_apply_correction\'] = 0\ngg[\'correction_needed\'] = False\ngg[\'current_coef\'] = 1.0\n\n# Orthonorm init code is taked from Lasagne\n# https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\ndef svd_orthonormal(w):\n    shape = w.shape\n    if len(shape) < 2:\n        raise RuntimeError(""Only shapes of length 2 or more are supported."")\n    flat_shape = (shape[0], np.prod(shape[1:]))\n    a = np.random.normal(0.0, 1.0, flat_shape)#w;\n    u, _, v = np.linalg.svd(a, full_matrices=False)\n    q = u if u.shape == flat_shape else v\n    q = q.reshape(shape)\n    return q.astype(np.float32)\n\ndef store_activations(self, input, output):\n    gg[\'act_dict\'] = output.data.cpu().numpy();\n    return\n\ndef add_current_hook(m):\n    if gg[\'hook\'] is not None:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'hook_position\'] > gg[\'done_counter\']:\n            gg[\'hook\'] = m.register_forward_hook(store_activations)\n        else:\n            gg[\'hook_position\'] += 1\n    return\n\ndef count_conv_fc_layers(m):\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        gg[\'total_fc_conv_layers\'] +=1\n    return\n\ndef remove_hooks(hooks):\n    for h in hooks:\n        h.remove()\n    return\n\ndef orthogonal_weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        if hasattr(m, \'weight_v\'):\n            w_ortho = svd_orthonormal(m.weight_v.data.cpu().numpy())\n            m.weight_v.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n        else:\n            w_ortho = svd_orthonormal(m.weight.data.cpu().numpy())\n            m.weight.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n    return\n\ndef apply_weights_correction(m):\n    if gg[\'hook\'] is None:\n        return\n    if not gg[\'correction_needed\']:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'counter_to_apply_correction\'] < gg[\'hook_position\']:\n            gg[\'counter_to_apply_correction\'] += 1\n        else:\n            if hasattr(m, \'weight_g\'):\n                m.weight_g.data *= float(gg[\'current_coef\'])\n                gg[\'correction_needed\'] = False\n            else:\n                m.weight.data *= gg[\'current_coef\']\n                gg[\'correction_needed\'] = False\n            return\n    return\n\ndef apply_lsuv_init(model, data, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=True, cuda=True):\n    model.eval();\n    if cuda:\n        model=model.cuda()\n        data=data.cuda()\n    else:\n        model=model.cpu()\n        data=data.cpu()        \n        \n    model.apply(count_conv_fc_layers)\n    if do_orthonorm:\n        model.apply(orthogonal_weights_init)\n        if cuda:\n            model=model.cuda()\n    for layer_idx in range(gg[\'total_fc_conv_layers\']):\n        model.apply(add_current_hook)\n        out = model(data)\n        current_std = gg[\'act_dict\'].std()\n        attempts = 0\n        while (np.abs(current_std - needed_std) > std_tol):\n            gg[\'current_coef\'] =  needed_std / (current_std  + 1e-8);\n            gg[\'correction_needed\'] = True\n            model.apply(apply_weights_correction)\n            if cuda:\n                model=model.cuda()\n            out = model(data)\n            current_std = gg[\'act_dict\'].std()\n            attempts+=1\n            if attempts > max_attempts:\n                print(f\'Cannot converge in {max_attempts} iterations\')\n                break\n        if gg[\'hook\'] is not None:\n           gg[\'hook\'].remove()\n        gg[\'done_counter\']+=1\n        gg[\'counter_to_apply_correction\'] = 0\n        gg[\'hook_position\'] = 0\n        gg[\'hook\']  = None\n    if not cuda:\n        model=model.cpu()\n    return model\n'"
fastai/courses/dl1/fastai/metrics.py,3,"b'from .imports import *\nfrom .torch_imports import *\n\ndef accuracy_np(preds, targs):\n    preds = np.argmax(preds, 1)\n    return (preds==targs).mean()\n\ndef accuracy(preds, targs):\n    preds = torch.max(preds, dim=1)[1]\n    return (preds==targs).float().mean()\n\ndef accuracy_thresh(thresh):\n    return lambda preds,targs: accuracy_multi(preds, targs, thresh)\n\ndef accuracy_multi(preds, targs, thresh):\n    return ((preds>thresh).float()==targs).float().mean()\n\ndef accuracy_multi_np(preds, targs, thresh):\n    return ((preds>thresh)==targs).mean()\n\ndef recall(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/targs.sum()\n\ndef precision(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/pred_pos.sum()\n\ndef fbeta(preds, targs, beta, thresh=0.5):\n    """"""Calculates the F-beta score (the weighted harmonic mean of precision and recall).\n    This is the micro averaged version where the true positives, false negatives and\n    false positives are calculated globally (as opposed to on a per label basis).\n\n    beta == 1 places equal weight on precision and recall, b < 1 emphasizes precision and\n    beta > 1 favors recall.\n    """"""\n    assert beta > 0, \'beta needs to be greater than 0\'\n    beta2 = beta ** 2\n    rec = recall(preds, targs, thresh)\n    prec = precision(preds, targs, thresh)\n    return (1 + beta2) * prec * rec / (beta2 * prec + rec)\n\ndef f1(preds, targs, thresh=0.5): return fbeta(preds, targs, 1, thresh)\n'"
fastai/courses/dl1/fastai/model.py,8,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .layer_optimizer import *\nfrom .swa import *\nfrom .fp16 import *\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef cut_model(m, cut):\n    return list(m.children())[:cut] if cut else [m]\n\ndef predict_to_bcolz(m, gen, arr, workers=4):\n    arr.trim(len(arr))\n    lock=threading.Lock()\n    m.eval()\n    for x,*_ in tqdm(gen):\n        y = to_np(m(VV(x)).data)\n        with lock:\n            arr.append(y)\n            arr.flush()\n\ndef num_features(m):\n    c=children(m)\n    if len(c)==0: return None\n    for l in reversed(c):\n        if hasattr(l, \'num_features\'): return l.num_features\n        res = num_features(l)\n        if res is not None: return res\n\ndef torch_item(x): return x.item() if hasattr(x,\'item\') else x[0]\n\nclass Stepper():\n    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n        self.fp16 = fp16\n        self.reset(True)\n        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n        self.loss_scale = loss_scale\n\n    def reset(self, train=True):\n        if train: apply_leaf(self.m, set_train_mode)\n        else: self.m.eval()\n        if hasattr(self.m, \'reset\'):\n            self.m.reset()\n            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n\n    def step(self, xs, y, epoch):\n        xtra = []\n        output = self.m(*xs)\n        if isinstance(output,tuple): output,*xtra = output\n        if self.fp16: self.m.zero_grad()\n        else: self.opt.zero_grad() \n        loss = raw_loss = self.crit(output, y)\n        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n        loss.backward()\n        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n        if self.loss_scale != 1:\n            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n        if self.clip:   # Gradient clipping\n            if IS_TORCH_04: nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n            else: nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n        self.opt.step()\n        if self.fp16: \n            copy_fp32_to_model(self.m, self.fp32_params)\n            torch.cuda.synchronize()\n        return torch_item(raw_loss.data)\n\n    def evaluate(self, xs, y):\n        preds = self.m(*xs)\n        if isinstance(preds,tuple): preds=preds[0]\n        return preds, self.crit(preds, y)\n\ndef set_train_mode(m):\n    if (hasattr(m, \'running_mean\') and (getattr(m,\'bn_freeze\',False)\n              or not getattr(m,\'trainable\',False))): m.eval()\n    elif (getattr(m,\'drop_freeze\',False) and hasattr(m, \'p\')\n          and (\'drop\' in type(m).__name__.lower())): m.eval()\n    else: m.train()\n\ndef fit(model, data, n_epochs, opt, crit, metrics=None, callbacks=None, stepper=Stepper,\n        swa_model=None, swa_start=None, swa_eval_freq=None, **kwargs):\n    """""" Fits a model\n\n    Arguments:\n       model (model): any pytorch module\n           net = to_gpu(net)\n       data (ModelData): see ModelData class and subclasses (can be a list)\n       opts: an optimizer. Example: optim.Adam. \n       If n_epochs is a list, it needs to be the layer_optimizer to get the optimizer as it changes.\n       n_epochs(int or list): number of epochs (or list of number of epochs)\n       crit: loss function to optimize. Example: F.cross_entropy\n    """"""\n\n    all_val = kwargs.pop(\'all_val\') if \'all_val\' in kwargs else False\n    get_ep_vals = kwargs.pop(\'get_ep_vals\') if \'get_ep_vals\' in kwargs else False\n    metrics = metrics or []\n    callbacks = callbacks or []\n    avg_mom=0.98\n    batch_num,avg_loss=0,0.\n    for cb in callbacks: cb.on_train_begin()\n    names = [""epoch"", ""trn_loss"", ""val_loss""] + [f.__name__ for f in metrics]\n    if swa_model is not None:\n        swa_names = [\'swa_loss\'] + [f\'swa_{f.__name__}\' for f in metrics]\n        names += swa_names\n        # will use this to call evaluate later\n        swa_stepper = stepper(swa_model, None, crit, **kwargs)\n\n    layout = ""{!s:10} "" * len(names)\n    if not isinstance(n_epochs, Iterable): n_epochs=[n_epochs]\n    if not isinstance(data, Iterable): data = [data]\n    if len(data) == 1: data = data * len(n_epochs)\n    for cb in callbacks: cb.on_phase_begin()\n    model_stepper = stepper(model, opt.opt if hasattr(opt,\'opt\') else opt, crit, **kwargs)\n    ep_vals = collections.OrderedDict()\n    tot_epochs = int(np.ceil(np.array(n_epochs).sum()))\n    cnt_phases = np.array([ep * len(dat.trn_dl) for (ep,dat) in zip(n_epochs,data)]).cumsum()\n    phase = 0\n    for epoch in tnrange(tot_epochs, desc=\'Epoch\'):\n        model_stepper.reset(True)\n        cur_data = data[phase]\n        if hasattr(cur_data, \'trn_sampler\'): cur_data.trn_sampler.set_epoch(epoch)\n        if hasattr(cur_data, \'val_sampler\'): cur_data.val_sampler.set_epoch(epoch)\n        num_batch = len(cur_data.trn_dl)\n        t = tqdm(iter(cur_data.trn_dl), leave=False, total=num_batch)\n        if all_val: val_iter = IterBatch(cur_data.val_dl)\n\n        for (*x,y) in t:\n            batch_num += 1\n            for cb in callbacks: cb.on_batch_begin()\n            loss = model_stepper.step(V(x),V(y), epoch)\n            avg_loss = avg_loss * avg_mom + loss * (1-avg_mom)\n            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n            t.set_postfix(loss=debias_loss)\n            stop=False\n            los = debias_loss if not all_val else [debias_loss] + validate_next(model_stepper,metrics, val_iter)\n            for cb in callbacks: stop = stop or cb.on_batch_end(los)\n            if stop: return\n            if batch_num >= cnt_phases[phase]:\n                for cb in callbacks: cb.on_phase_end()\n                phase += 1\n                if phase >= len(n_epochs):\n                    t.close()\n                    break\n                for cb in callbacks: cb.on_phase_begin()\n                if isinstance(opt, LayerOptimizer): model_stepper.opt = opt.opt\n                if cur_data != data[phase]:\n                    t.close()\n                    break\n\n        if not all_val:\n            vals = validate(model_stepper, cur_data.val_dl, metrics)\n            stop=False\n            for cb in callbacks: stop = stop or cb.on_epoch_end(vals)\n            if swa_model is not None:\n                if (epoch + 1) >= swa_start and ((epoch + 1 - swa_start) % swa_eval_freq == 0 or epoch == tot_epochs - 1):\n                    fix_batchnorm(swa_model, cur_data.trn_dl)\n                    swa_vals = validate(swa_stepper, cur_data.val_dl, metrics)\n                    vals += swa_vals\n\n            if epoch == 0: print(layout.format(*names))\n            print_stats(epoch, [debias_loss] + vals)\n            ep_vals = append_stats(ep_vals, epoch, [debias_loss] + vals)\n        if stop: break\n    for cb in callbacks: cb.on_train_end()\n    if get_ep_vals: return vals, ep_vals\n    else: return vals\n\ndef append_stats(ep_vals, epoch, values, decimals=6):\n    ep_vals[epoch]=list(np.round(values, decimals))\n    return ep_vals\n\ndef print_stats(epoch, values, decimals=6):\n    layout = ""{!s:^10}"" + "" {!s:10}"" * len(values)\n    values = [epoch] + list(np.round(values, decimals))\n    print(layout.format(*values))\n\nclass IterBatch():\n    def __init__(self, dl):\n        self.idx = 0\n        self.dl = dl\n        self.iter = iter(dl)\n\n    def __iter__(self): return self\n\n    def next(self):\n        res = next(self.iter)\n        self.idx += 1\n        if self.idx == len(self.dl):\n            self.iter = iter(self.dl)\n            self.idx=0\n        return res\n\ndef validate_next(stepper, metrics, val_iter):\n    """"""Computes the loss on the next minibatch of the validation set.""""""\n    stepper.reset(False)\n    with no_grad_context():\n        (*x,y) = val_iter.next()\n        preds,l = stepper.evaluate(VV(x), VV(y))\n        res = [to_np(l)[0]]\n        res += [f(preds.data,y) for f in metrics]\n    stepper.reset(True)\n    return res\n\ndef validate(stepper, dl, metrics):\n    batch_cnts,loss,res = [],[],[]\n    stepper.reset(False)\n    with no_grad_context():\n        for (*x,y) in iter(dl):\n            preds, l = stepper.evaluate(VV(x), VV(y))\n            if isinstance(x,list): batch_cnts.append(len(x[0]))\n            else: batch_cnts.append(len(x))\n            loss.append(to_np(l))\n            res.append([f(preds.data, y) for f in metrics])\n    return [np.average(loss, 0, weights=batch_cnts)] + list(np.average(np.stack(res), 0, weights=batch_cnts))\n\ndef get_prediction(x):\n    if is_listy(x): x=x[0]\n    return x.data\n\ndef predict(m, dl):\n    preda,_ = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda))\n\ndef predict_batch(m, x):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    return m(VV(x))\n\ndef predict_with_targs_(m, dl):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    res = []\n    for *x,y in iter(dl): res.append([get_prediction(m(*VV(x))),y])\n    return zip(*res)\n\ndef predict_with_targs(m, dl):\n    preda,targa = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda)), to_np(torch.cat(targa))\n\n# From https://github.com/ncullen93/torchsample\ndef model_summary(m, input_size):\n    def register_hook(module):\n        def hook(module, input, output):\n            class_name = str(module.__class__).split(\'.\')[-1].split(""\'"")[0]\n            module_idx = len(summary)\n\n            m_key = \'%s-%i\' % (class_name, module_idx+1)\n            summary[m_key] = OrderedDict()\n            summary[m_key][\'input_shape\'] = list(input[0].size())\n            summary[m_key][\'input_shape\'][0] = -1\n            if is_listy(output):\n                summary[m_key][\'output_shape\'] = [[-1] + list(o.size())[1:] for o in output]\n            else:\n                summary[m_key][\'output_shape\'] = list(output.size())\n                summary[m_key][\'output_shape\'][0] = -1\n\n            params = 0\n            if hasattr(module, \'weight\'):\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n                summary[m_key][\'trainable\'] = module.weight.requires_grad\n            if hasattr(module, \'bias\') and module.bias is not None:\n                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n            summary[m_key][\'nb_params\'] = params\n\n        if (not isinstance(module, nn.Sequential) and\n           not isinstance(module, nn.ModuleList) and\n           not (module == m)):\n            hooks.append(module.register_forward_hook(hook))\n\n    summary = OrderedDict()\n    hooks = []\n    m.apply(register_hook)\n\n    if is_listy(input_size[0]):\n        x = [to_gpu(Variable(torch.rand(3,*in_size))) for in_size in input_size]\n    else: x = [to_gpu(Variable(torch.rand(3,*input_size)))]\n    m(*x)\n\n    for h in hooks: h.remove()\n    return summary\n\n'"
fastai/courses/dl1/fastai/nlp.py,4,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .model import *\nfrom .dataset import *\nfrom .learner import *\nfrom .text import *\nfrom .lm_rnn import *\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.datasets import language_modeling\n\nclass DotProdNB(nn.Module):\n    def __init__(self, nf, ny, w_adj=0.4, r_adj=10):\n        super().__init__()\n        self.w_adj,self.r_adj = w_adj,r_adj\n        self.w = nn.Embedding(nf+1, 1, padding_idx=0)\n        self.w.weight.data.uniform_(-0.1,0.1)\n        self.r = nn.Embedding(nf+1, ny)\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        w = self.w(feat_idx)\n        r = self.r(feat_idx)\n        x = ((w+self.w_adj)*r/self.r_adj).sum(1)\n        return F.softmax(x)\n\nclass SimpleNB(nn.Module):\n    def __init__(self, nf, ny):\n        super().__init__()\n        self.r = nn.Embedding(nf+1, ny, padding_idx=0)\n        self.b = nn.Parameter(torch.zeros(ny,))\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        r = self.r(feat_idx)\n        x = r.sum(1)+self.b\n        return F.softmax(x)\n\nclass BOW_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.l1_loss\n\ndef calc_pr(y_i, x, y, b):\n    idx = np.argwhere((y==y_i)==b)\n    p = x[idx[:,0]].sum(0)+1\n    return p/((y==y_i)==b).sum()\n\ndef calc_r(y_i, x, y):\n    return np.log(calc_pr(y_i, x, y, True) / calc_pr(y_i, x, y, False))\n\nclass BOW_Dataset(Dataset):\n    def __init__(self, bow, y, max_len):\n        self.bow,self.max_len = bow,max_len\n        self.c = int(y.max())+1\n        self.n,self.vocab_size = bow.shape\n        self.y = one_hot(y,self.c).astype(np.float32)\n        x = self.bow.sign()\n        self.r = np.stack([calc_r(i, x, y).A1 for i in range(self.c)]).T\n\n    def __getitem__(self, i):\n        row = self.bow.getrow(i)\n\n        num_row_entries = row.indices.shape[0]\n        indices = (row.indices + 1).astype(np.int64)\n        data = (row.data).astype(np.int64)\n\n        if num_row_entries < self.max_len:\n            # If short, pad\n            indices = np.pad(indices, (self.max_len - num_row_entries, 0), mode=\'constant\')\n            data = np.pad(data, (self.max_len - num_row_entries, 0), mode=\'constant\')\n        else:\n            # If long, truncate\n            indices, data = indices[-self.max_len:], data[-self.max_len:]\n\n        return indices, data, min(self.max_len, num_row_entries), self.y[i]\n\n    def __len__(self): return len(self.bow.indptr)-1\n\n\nclass TextClassifierData(ModelData):\n    @property\n    def c(self): return self.trn_ds.c\n\n    @property\n    def r(self):\n        return torch.Tensor(np.concatenate([np.zeros((1,self.c)), self.trn_ds.r]))\n\n    def get_model(self, f, **kwargs):\n        m = to_gpu(f(self.trn_ds.vocab_size, self.c, **kwargs))\n        m.r.weight.data = to_gpu(self.r)\n        m.r.weight.requires_grad = False\n        model = BasicModel(m)\n        return BOW_Learner(self, model, metrics=[accuracy_thresh(0.5)], opt_fn=optim.Adam)\n\n    def dotprod_nb_learner(self, **kwargs): return self.get_model(DotProdNB, **kwargs)\n    def nb_learner(self, **kwargs): return self.get_model(SimpleNB, **kwargs)\n\n    @classmethod\n    def from_bow(cls, trn_bow, trn_y, val_bow, val_y, sl):\n        trn_ds = BOW_Dataset(trn_bow, trn_y, sl)\n        val_ds = BOW_Dataset(val_bow, val_y, sl)\n        trn_dl = DataLoader(trn_ds, 64, True)\n        val_dl = DataLoader(val_ds, 64, False)\n        return cls(\'.\', trn_dl, val_dl)\n\n\ndef flip_tensor(x, dim):\n    xsize = x.size()\n    dim = x.dim() + dim if dim < 0 else dim\n    x = x.view(-1, *xsize[dim:])\n    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1,\n                      -1, -1), (\'cpu\',\'cuda\')[x.is_cuda])().long(), :]\n    return x.view(xsize)\n\n\nclass LanguageModelLoader():\n\n    def __init__(self, ds, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        text = sum([o.text for o in ds], [])\n        fld = ds.fields[\'text\']\n        nums = fld.numericalize([text],device=None if torch.cuda.is_available() else -1)\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        return self\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def __next__(self):\n        if self.i >= self.n-1 or self.iter>=len(self): raise StopIteration\n        bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n        seq_len = max(5, int(np.random.normal(bptt, 5)))\n        res = self.get_batch(self.i, seq_len)\n        self.i += seq_len\n        self.iter += 1\n        return res\n\n    def batchify(self, data):\n        nb = data.size(0) // self.bs\n        data = data[:nb*self.bs]\n        data = data.view(self.bs, -1).t().contiguous()\n        if self.backwards: data=flip_tensor(data, 0)\n        return to_gpu(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass ConcatTextDataset(torchtext.data.Dataset):\n    def __init__(self, path, text_field, newline_eos=True, encoding=\'utf-8\', **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n        if os.path.isdir(path): paths=glob(f\'{path}/*.*\')\n        else: paths=[path]\n        for p in paths:\n            for line in open(p, encoding=encoding): text += text_field.preprocess(line)\n            if newline_eos: text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n        super().__init__(examples, fields, **kwargs)\n\n\nclass ConcatTextDatasetFromDataFrames(torchtext.data.Dataset):\n    def __init__(self, df, text_field, col, newline_eos=True, **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n\n        text += text_field.preprocess(df[col].str.cat(sep=\' <eos> \'))\n        if (newline_eos): text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n\n        super().__init__(examples, fields, **kwargs)\n\n    @classmethod\n    def splits(cls, train_df=None, val_df=None, test_df=None, keep_nones=False, **kwargs):\n        res = (\n            cls(train_df, **kwargs),\n            cls(val_df, **kwargs),\n            map_none(test_df, partial(cls, **kwargs)))  # not required\n        return res if keep_nones else tuple(d for d in res if d is not None)\n\n\nclass LanguageModelData():\n    """"""\n    This class provides the entry point for dealing with supported NLP tasks.\n    Usage:\n    1.  Use one of the factory constructors (from_dataframes, from_text_files) to\n        obtain an instance of the class.\n    2.  Use the get_model method to return a RNN_Learner instance (a network suited\n        for NLP tasks), then proceed with training.\n\n        Example:\n            >> TEXT = data.Field(lower=True, tokenize=spacy_tok)\n            >> FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n            >> md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=64, bptt=70, min_freq=10)\n\n            >> em_sz = 200  # size of each embedding vector\n            >> nh = 500     # number of hidden activations per layer\n            >> nl = 3       # number of layers\n\n            >> opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n            >> learner = md.get_model(opt_fn, em_sz, nh, nl,\n                           dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n            >> learner.reg_fn = seq2seq_reg\n            >> learner.clip=0.3\n\n            >> learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n\n    """"""\n    def __init__(self, path, field, trn_ds, val_ds, test_ds, bs, bptt, backwards=False, **kwargs):\n        """""" Constructor for the class. An important thing that happens here is\n            that the field\'s ""build_vocab"" method is invoked, which builds the vocabulary\n            for this NLP model.\n\n            Also, three instances of the LanguageModelLoader are constructed; one each\n            for training data (self.trn_dl), validation data (self.val_dl), and the\n            testing data (self.test_dl)\n\n            Args:\n                path (str): testing path\n                field (Field): torchtext field object\n                trn_ds (Dataset): training dataset\n                val_ds (Dataset): validation dataset\n                test_ds (Dataset): testing dataset\n                bs (int): batch size\n                bptt (int): back propagation through time\n                kwargs: other arguments\n        """"""\n        self.bs = bs\n        self.path = path\n        self.trn_ds = trn_ds; self.val_ds = val_ds; self.test_ds = test_ds\n        if not hasattr(field, \'vocab\'): field.build_vocab(self.trn_ds, **kwargs)\n\n        self.pad_idx = field.vocab.stoi[field.pad_token]\n        self.nt = len(field.vocab)\n\n        factory = lambda ds: LanguageModelLoader(ds, bs, bptt, backwards=backwards)\n        self.trn_dl = factory(self.trn_ds)\n        self.val_dl = factory(self.val_ds)\n        self.test_dl = map_none(self.test_ds, factory)  # not required\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        """""" Method returns a RNN_Learner object, that wraps an instance of the RNN_Encoder module.\n\n        Args:\n            opt_fn (Optimizer): the torch optimizer function to use\n            emb_sz (int): embedding size\n            n_hid (int): number of hidden inputs\n            n_layers (int): number of hidden layers\n            kwargs: other arguments\n\n        Returns:\n            An instance of the RNN_Learner class.\n\n        """"""\n        m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = SingleModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    @classmethod\n    def from_dataframes(cls, path, field, col, train_df, val_df, test_df=None, bs=64, bptt=70, **kwargs):\n        trn_ds, val_ds, test_ds = ConcatTextDatasetFromDataFrames.splits(\n            text_field=field, col=col, train_df=train_df, val_df=val_df, test_df=test_df, keep_nones=True)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n    @classmethod\n    def from_text_files(cls, path, field, train, validation, test=None, bs=64, bptt=70, **kwargs):\n        """""" Method used to instantiate a LanguageModelData object that can be used for a\n            supported nlp task.\n\n        Args:\n            path (str): the absolute path in which temporary model data will be saved\n            field (Field): torchtext field\n            train (str): file location of the training data\n            validation (str): file location of the validation data\n            test (str): file location of the testing data\n            bs (int): batch size to use\n            bptt (int): back propagation through time hyper-parameter\n            kwargs: other arguments\n\n        Returns:\n            a LanguageModelData instance, which most importantly, provides us the datasets for training,\n                validation, and testing\n\n        Note:\n            The train, validation, and test path can be pointed to any file (or folder) that contains a valid\n                text corpus.\n\n        """"""\n        trn_ds, val_ds, test_ds = ConcatTextDataset.splits(\n            path, text_field=field, train=train, validation=validation, test=test)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n\nclass TextDataLoader():\n    def __init__(self, src, x_fld, y_fld):\n        self.src,self.x_fld,self.y_fld = src,x_fld,y_fld\n\n    def __len__(self): return len(self.src)\n\n    def __iter__(self):\n        it = iter(self.src)\n        for i in range(len(self)):\n            b = next(it)\n            yield getattr(b, self.x_fld).data, getattr(b, self.y_fld).data\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n\nclass TextData(ModelData):\n    def create_td(self, it): return TextDataLoader(it, self.text_fld, self.label_fld)\n\n    @classmethod\n    def from_splits(cls, path, splits, bs, text_name=\'text\', label_name=\'label\'):\n        text_fld = splits[0].fields[text_name]\n        label_fld = splits[0].fields[label_name]\n        if hasattr(label_fld, \'build_vocab\'): label_fld.build_vocab(splits[0])\n        iters = torchtext.data.BucketIterator.splits(splits, batch_size=bs)\n        trn_iter,val_iter,test_iter = iters[0],iters[1],None\n        test_dl = None\n        if len(iters) == 3:\n            test_iter = iters[2]\n            test_dl = TextDataLoader(test_iter, text_name, label_name)\n        trn_dl = TextDataLoader(trn_iter, text_name, label_name)\n        val_dl = TextDataLoader(val_iter, text_name, label_name)\n        obj = cls.from_dls(path, trn_dl, val_dl, test_dl)\n        obj.bs = bs\n        obj.pad_idx = text_fld.vocab.stoi[text_fld.pad_token]\n        obj.nt = len(text_fld.vocab)\n        obj.c = (len(label_fld.vocab) if hasattr(label_fld, \'vocab\')\n                 else len(getattr(splits[0][0], label_name)))\n        return obj\n\n    def to_model(self, m, opt_fn):\n        model = TextModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    def get_model(self, opt_fn, max_sl, bptt, emb_sz, n_hid, n_layers, dropout, **kwargs):\n        m = get_rnn_classifer(bptt, max_sl, self.c, self.nt,\n              layers=[emb_sz*3, self.c], drops=[dropout],\n              emb_sz=emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=self.pad_idx, **kwargs)\n        return self.to_model(m, opt_fn)\n\n'"
fastai/courses/dl1/fastai/plots.py,0,"b'from .imports import *\nfrom .torch_imports import *\nfrom sklearn.metrics import confusion_matrix\n\ndef ceildiv(a, b):\n    return -(-a // b)\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None, maintitle=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None:\n        plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else \'none\')\n\n\ndef plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n    """"""Plots images given image files.\n\n    Arguments:\n        im_paths (list): list of paths\n        figsize (tuple): figure size\n        rows (int): number of rows\n        titles (list): list of titles\n        maintitle (string): main title\n    """"""\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(imspaths)):\n        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        img = plt.imread(imspaths[i])\n        plt.imshow(img)\n\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title=\'Confusion matrix\', cmap=plt.cm.Blues, figsize=None):\n    """"""\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    (This function is copied from the scikit docs.)\n    """"""\n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize: cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=""center"", color=""white"" if cm[i, j] > thresh else ""black"")\n\n    plt.tight_layout()\n    plt.ylabel(\'True label\')\n    plt.xlabel(\'Predicted label\')\n\ndef plots_raw(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])\n\ndef load_img_id(ds, idx, path): return np.array(PIL.Image.open(os.path.join(path, ds.fnames[idx])))\n\n\nclass ImageModelResults():\n    """""" Visualize the results of an image model\n\n    Arguments:\n        ds (dataset): a dataset which contains the images\n        log_preds (numpy.ndarray): predictions for the dataset in log scale\n\n    Returns:\n        ImageModelResults\n    """"""\n    def __init__(self, ds, log_preds):\n        """"""Initialize an ImageModelResults class instance""""""\n        self.ds = ds\n        # returns the indices of the maximum value of predictions along axis 1, representing the predicted class\n        # log_preds.shape = (number_of_samples, number_of_classes);\n        # preds.shape = (number_of_samples,)\n        self.preds = np.argmax(log_preds, axis=1)\n        # computes the probabilities\n        self.probs = np.exp(log_preds)\n        # extracts the number of classes\n        self.num_classes = log_preds.shape[1]\n\n    def plot_val_with_title(self, idxs, y):\n        """""" Displays the images and their probabilities of belonging to a certain class\n\n            Arguments:\n                idxs (numpy.ndarray): indexes of the image samples from the dataset\n                y (int): the selected class\n\n            Returns:\n                Plots the images in n rows [rows = n]\n        """"""\n        # if there are any samples to be displayed\n        if len(idxs) > 0:\n            imgs = np.stack([self.ds[x][0] for x in idxs])\n            title_probs = [self.probs[x,y] for x in idxs]\n\n            return plots(self.ds.denorm(imgs), rows=1, titles=title_probs)\n        # if idxs is empty return false\n        else:\n            return False;\n\n    def most_by_mask(self, mask, y, mult):\n        """""" Extracts the first 4 most correct/incorrect indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n                mult (int): sets the ordering; -1 descending, 1 ascending\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        cnt = min(4, len(idxs))\n        return idxs[np.argsort(mult * self.probs[idxs,y])[:cnt]]\n\n    def most_uncertain_by_mask(self, mask, y):\n        """""" Extracts the first 4 most uncertain indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        # the most uncertain samples will have abs(probs-1/num_classes) close to 0;\n        return idxs[np.argsort(np.abs(self.probs[idxs,y]-(1/self.num_classes)))[:4]]\n\n    def most_by_correct(self, y, is_correct):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        # mult=-1 when the is_correct flag is true -> when we want to display the most correct classes we will make a descending sorting (argsort) because we want that the biggest probabilities to be displayed first.\n        # When is_correct is false, we want to display the most incorrect classes, so we want an ascending sorting since our interest is in the smallest probabilities.\n        mult = -1 if is_correct==True else 1\n        return self.most_by_mask(((self.preds == self.ds.y)==is_correct)\n                                 & (self.ds.y == y), y, mult)\n\n    def plot_by_correct(self, y, is_correct):\n        """""" Plots the images which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n        """"""\n        return self.plot_val_with_title(self.most_by_correct(y, is_correct), y)\n\n    def most_by_uncertain(self, y):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and have probabilities nearest to 1/number_of_classes (eg. 0.5 for 2 classes, 0.33 for 3 classes) for the selected class.\n\n            Arguments:\n                y (int): the selected class\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        return self.most_uncertain_by_mask((self.ds.y == y), y)\n\n    def plot_most_correct(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most correct.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, True)\n    def plot_most_incorrect(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most incorrect.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, False)\n    def plot_most_uncertain(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most uncertain i.e have probabilities nearest to 1/number_of_classes.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_val_with_title(self.most_by_uncertain(y), y)\n'"
fastai/courses/dl1/fastai/rnn_reg.py,16,"b'from .torch_imports import *\nfrom .core import *\nfrom functools import wraps\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef dropout_mask(x, sz, dropout):\n    """""" Applies a dropout mask whose size is determined by passed argument \'sz\'.\n    Args:\n        x (nn.Variable): A torch Variable object\n        sz (tuple(int, int, int)): The expected size of the new tensor\n        dropout (float): The dropout fraction to apply\n\n    This method uses the bernoulli distribution to decide which activations to keep.\n    Additionally, the sampled activations is rescaled is using the factor 1/(1 - dropout).\n\n    In the example given below, one can see that approximately .8 fraction of the\n    returned tensors are zero. Rescaling with the factor 1/(1 - 0.8) returns a tensor\n    with 5\'s in the unit places.\n\n    The official link to the pytorch bernoulli function is here:\n        http://pytorch.org/docs/master/torch.html#torch.bernoulli\n\n    Examples:\n        >>> a_Var = torch.autograd.Variable(torch.Tensor(2, 3, 4).uniform_(0, 1), requires_grad=False)\n        >>> a_Var\n            Variable containing:\n            (0 ,.,.) =\n              0.6890  0.5412  0.4303  0.8918\n              0.3871  0.7944  0.0791  0.5979\n              0.4575  0.7036  0.6186  0.7217\n            (1 ,.,.) =\n              0.8354  0.1690  0.1734  0.8099\n              0.6002  0.2602  0.7907  0.4446\n              0.5877  0.7464  0.4257  0.3386\n            [torch.FloatTensor of size 2x3x4]\n        >>> a_mask = dropout_mask(a_Var.data, (1,a_Var.size(1),a_Var.size(2)), dropout=0.8)\n        >>> a_mask\n            (0 ,.,.) =\n              0  5  0  0\n              0  0  0  5\n              5  0  5  0\n            [torch.FloatTensor of size 1x3x4]\n    """"""\n    return x.new(*sz).bernoulli_(1-dropout)/(1-dropout)\n\n\nclass LockedDropout(nn.Module):\n    def __init__(self, p=0.5):\n        super().__init__()\n        self.p=p\n\n    def forward(self, x):\n        if not self.training or not self.p: return x\n        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n        return Variable(m, requires_grad=False) * x\n\n\nclass WeightDrop(torch.nn.Module):\n    """"""A custom torch layer that serves as a wrapper on another torch layer.\n    Primarily responsible for updating the weights in the wrapped module based\n    on a specified dropout.\n    """"""\n    def __init__(self, module, dropout, weights=[\'weight_hh_l0\']):\n        """""" Default constructor for the WeightDrop module\n\n        Args:\n            module (torch.nn.Module): A pytorch layer being wrapped\n            dropout (float): a dropout value to apply\n            weights (list(str)): the parameters of the wrapped **module**\n                which should be fractionally dropped.\n        """"""\n        super().__init__()\n        self.module,self.weights,self.dropout = module,weights,dropout\n        self._setup()\n\n    def _setup(self):\n        """""" for each string defined in self.weights, the corresponding\n        attribute in the wrapped module is referenced, then deleted, and subsequently\n        registered as a new parameter with a slightly modified name.\n\n        Args:\n            None\n\n         Returns:\n             None\n        """"""\n        if isinstance(self.module, torch.nn.RNNBase): self.module.flatten_parameters = noop\n        for name_w in self.weights:\n            w = getattr(self.module, name_w)\n            del self.module._parameters[name_w]\n            self.module.register_parameter(name_w + \'_raw\', nn.Parameter(w.data))\n\n\n    def _setweights(self):\n        """""" Uses pytorch\'s built-in dropout function to apply dropout to the parameters of\n        the wrapped module.\n\n        Args:\n            None\n        Returns:\n            None\n        """"""\n        for name_w in self.weights:\n            raw_w = getattr(self.module, name_w + \'_raw\')\n            w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n            setattr(self.module, name_w, w)\n\n    def forward(self, *args):\n        """""" updates weights and delegates the propagation of the tensor to the wrapped module\'s\n        forward method\n\n        Args:\n            *args: supplied arguments\n\n        Returns:\n            tensor obtained by running the forward method on the wrapped module.\n        """"""\n        self._setweights()\n        return self.module.forward(*args)\n\nclass EmbeddingDropout(nn.Module):\n\n    """""" Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\n    Uses the dropout_mask custom layer to achieve this.\n\n    Args:\n        embed (torch.nn.Embedding): An embedding torch layer\n        words (torch.nn.Variable): A torch variable\n        dropout (float): dropout fraction to apply to the embedding weights\n        scale (float): additional scaling to apply to the modified embedding weights\n\n    Returns:\n        tensor of size: (batch_size x seq_length x embedding_size)\n\n    Example:\n\n    >> embed = torch.nn.Embedding(10,3)\n    >> words = Variable(torch.LongTensor([[1,2,4,5] ,[4,3,2,9]]))\n    >> words.size()\n        (2,4)\n    >> embed_dropout_layer = EmbeddingDropout(embed)\n    >> dropout_out_ = embed_dropout_layer(embed, words, dropout=0.40)\n    >> dropout_out_\n        Variable containing:\n        (0 ,.,.) =\n          1.2549  1.8230  1.9367\n          0.0000 -0.0000  0.0000\n          2.2540 -0.1299  1.5448\n          0.0000 -0.0000 -0.0000\n\n        (1 ,.,.) =\n          2.2540 -0.1299  1.5448\n         -4.0457  2.4815 -0.2897\n          0.0000 -0.0000  0.0000\n          1.8796 -0.4022  3.8773\n        [torch.FloatTensor of size 2x4x3]\n    """"""\n\n    def __init__(self, embed):\n        super().__init__()\n        self.embed = embed\n\n    def forward(self, words, dropout=0.1, scale=None):\n        if dropout:\n            size = (self.embed.weight.size(0),1)\n            mask = Variable(dropout_mask(self.embed.weight.data, size, dropout))\n            masked_embed_weight = mask * self.embed.weight\n        else: masked_embed_weight = self.embed.weight\n\n        if scale: masked_embed_weight = scale * masked_embed_weight\n\n        padding_idx = self.embed.padding_idx\n        if padding_idx is None: padding_idx = -1\n\n        \n        if IS_TORCH_04:\n            X = F.embedding(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n        else:\n            X = self.embed._backend.Embedding.apply(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n\n        return X\n'"
fastai/courses/dl1/fastai/rnn_train.py,2,b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom .core import *\n\n'
fastai/courses/dl1/fastai/set_spawn.py,0,"b""from multiprocessing import set_start_method\nset_start_method('spawn')\n\n"""
fastai/courses/dl1/fastai/sgdr.py,1,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\nimport copy\n\n\nclass Callback:\n    \'\'\'\n    An abstract class that all callback(e.g., LossRecorder) classes extends from. \n    Must be extended before usage.\n    \'\'\'\n    def on_train_begin(self): pass\n    def on_batch_begin(self): pass\n    def on_phase_begin(self): pass\n    def on_epoch_end(self, metrics): pass\n    def on_phase_end(self): pass\n    def on_batch_end(self, metrics): pass\n    def on_train_end(self): pass\n\n# Useful for maintaining status of a long-running job.\n# \n# Usage:\n# learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\nclass LoggingCallback(Callback):\n    \'\'\'\n    A class useful for maintaining status of a long-running job.\n    e.g.: learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\n    \'\'\'\n    def __init__(self, save_path):\n        super().__init__()\n        self.save_path=save_path\n    def on_train_begin(self):\n        self.batch = 0\n        self.epoch = 0\n        self.phase = 0\n        self.f = open(self.save_path, ""a"", 1)\n        self.log(""\\ton_train_begin"")\n    def on_batch_begin(self):\n        self.log(str(self.batch)+""\\ton_batch_begin"")\n    def on_phase_begin(self):\n        self.log(str(self.phase)+""\\ton_phase_begin"")\n    def on_epoch_end(self, metrics):\n        self.log(str(self.epoch)+""\\ton_epoch_end: ""+str(metrics))\n        self.epoch += 1\n    def on_phase_end(self):\n        self.log(str(self.phase)+""\\ton_phase_end"")\n        self.phase+=1\n    def on_batch_end(self, metrics):\n        self.log(str(self.batch)+""\\ton_batch_end: ""+str(metrics))\n        self.batch += 1\n    def on_train_end(self):\n        self.log(""\\ton_train_end"")\n        self.f.close()\n    def log(self, string):\n        self.f.write(time.strftime(""%Y-%m-%dT%H:%M:%S"")+""\\t""+string+""\\n"")\n        \nclass LossRecorder(Callback):\n    \'\'\'\n    Saves and displays loss functions and other metrics. \n    Default sched when none is specified in a learner. \n    \'\'\'\n    def __init__(self, layer_opt, save_path=\'\', record_mom=False, metrics=[]):\n        super().__init__()\n        self.layer_opt=layer_opt\n        self.init_lrs=np.array(layer_opt.lrs)\n        self.save_path, self.record_mom, self.metrics = save_path, record_mom, metrics\n\n    def on_train_begin(self):\n        self.losses,self.lrs,self.iterations = [],[],[]\n        self.val_losses, self.rec_metrics = [], []\n        if self.record_mom:\n            self.momentums = []\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n        self.save_metrics(metrics)\n\n    def on_batch_end(self, loss):\n        self.iteration += 1\n        self.lrs.append(self.layer_opt.lr)\n        self.iterations.append(self.iteration)\n        if isinstance(loss, list):\n            self.losses.append(loss[0])\n            self.save_metrics(loss[1:])\n        else: self.losses.append(loss)\n        if self.record_mom: self.momentums.append(self.layer_opt.mom)\n\n    def save_metrics(self,vals):\n        self.val_losses.append(vals[0][0] if isinstance(vals[0], Iterable) else vals[0])\n        if len(vals) > 2: self.rec_metrics.append(vals[1:])\n        elif len(vals) == 2: self.rec_metrics.append(vals[1])\n\n    def plot_loss(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        plots loss function as function of iterations. \n        When used in Jupyternotebook, plot will be displayed in notebook. Else, plot will be displayed in console and both plot and loss are saved in save_path. \n        \'\'\'\n        if not in_ipynb(): plt.switch_backend(\'agg\')\n        plt.plot(self.iterations[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'loss_plot.png\'))\n            np.save(os.path.join(self.save_path, \'losses.npy\'), self.losses[10:])\n\n    def plot_lr(self):\n        \'\'\'Plots learning rate in jupyter notebook or console, depending on the enviroment of the learner.\'\'\'\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        if self.record_mom:\n            fig, axs = plt.subplots(1,2,figsize=(12,4))\n            for i in range(0,2): axs[i].set_xlabel(\'iterations\')\n            axs[0].set_ylabel(\'learning rate\')\n            axs[1].set_ylabel(\'momentum\')\n            axs[0].plot(self.iterations,self.lrs)\n            axs[1].plot(self.iterations,self.momentums)   \n        else:\n            plt.xlabel(""iterations"")\n            plt.ylabel(""learning rate"")\n            plt.plot(self.iterations, self.lrs)\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n\n\nclass LR_Updater(LossRecorder):\n    \'\'\'\n    Abstract class where all Learning Rate updaters inherit from. (e.g., CirularLR)\n    Calculates and updates new learning rate and momentum at the end of each batch. \n    Have to be extended. \n    \'\'\'\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n\n    def on_batch_end(self, loss):\n        res = super().on_batch_end(loss)\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n        return res\n\n    def update_lr(self):\n        new_lrs = self.calc_lr(self.init_lrs)\n        self.layer_opt.set_lrs(new_lrs)\n    \n    def update_mom(self):\n        new_mom = self.calc_mom()\n        self.layer_opt.set_mom(new_mom)\n\n    @abstractmethod\n    def calc_lr(self, init_lrs): raise NotImplementedError\n    \n    @abstractmethod\n    def calc_mom(self): raise NotImplementedError\n\n\nclass LR_Finder(LR_Updater):\n    \'\'\'\n    Helps you find an optimal learning rate for a model, as per suggetion of 2015 CLR paper. \n    Learning rate is increased in linear or log scale, depending on user input, and the result of the loss funciton is retained and can be plotted later. \n    \'\'\'\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics = []):\n        self.linear, self.stop_dv = linear, True\n        ratio = end_lr/layer_opt.lr\n        self.lr_mult = (ratio/nb) if linear else ratio**(1/nb)\n        super().__init__(layer_opt,metrics=metrics)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.best=1e9\n\n    def calc_lr(self, init_lrs):\n        mult = self.lr_mult*self.iteration if self.linear else self.lr_mult**self.iteration\n        return init_lrs * mult\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_dv and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        return super().on_batch_end(metrics)\n\n    def plot(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        Plots the loss function with respect to learning rate, in log scale. \n        \'\'\'\n        plt.ylabel(""loss"")\n        plt.xlabel(""learning rate (log scale)"")\n        plt.plot(self.lrs[n_skip:-(n_skip_end+1)], self.losses[n_skip:-(n_skip_end+1)])\n        plt.xscale(\'log\')\n\nclass LR_Finder2(LR_Finder):\n    """"""\n        A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n    """"""\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics=[], stop_dv=True):\n        self.nb, self.metrics = nb, metrics\n        super().__init__(layer_opt, nb, end_lr, linear, metrics)\n        self.stop_dv = stop_dv\n\n    def on_batch_end(self, loss):\n        if self.iteration == self.nb:\n            return True\n        return super().on_batch_end(loss)\n\n    def plot(self, n_skip=10, n_skip_end=5, smoothed=True):\n        if self.metrics is None: self.metrics = []\n        n_plots = len(self.metrics)+2\n        fig, axs = plt.subplots(n_plots,figsize=(6,4*n_plots))\n        for i in range(0,n_plots): axs[i].set_xlabel(\'learning rate\')\n        axs[0].set_ylabel(\'training loss\')\n        axs[1].set_ylabel(\'validation loss\')\n        for i,m in enumerate(self.metrics): \n            axs[i+2].set_ylabel(m.__name__)\n            if len(self.metrics) == 1:\n                values = self.rec_metrics\n            else:\n                values = [rec[i] for rec in self.rec_metrics]\n            if smoothed: values = smooth_curve(values,0.98)\n            axs[i+2].plot(self.lrs[n_skip:-n_skip_end], values[n_skip:-n_skip_end])\n        plt_val_l = smooth_curve(self.val_losses, 0.98) if smoothed else self.val_losses\n        axs[0].plot(self.lrs[n_skip:-n_skip_end],self.losses[n_skip:-n_skip_end])\n        axs[1].plot(self.lrs[n_skip:-n_skip_end],plt_val_l[n_skip:-n_skip_end])\n\nclass CosAnneal(LR_Updater):\n    \'\'\' Learning rate scheduler that inpelements a cosine annealation schedule. \'\'\'\n    def __init__(self, layer_opt, nb, on_cycle_end=None, cycle_mult=1):\n        self.nb,self.on_cycle_end,self.cycle_mult = nb,on_cycle_end,cycle_mult\n        super().__init__(layer_opt)\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.iteration<self.nb/20:\n            self.cycle_iter += 1\n            return init_lrs/100.\n\n        cos_out = np.cos(np.pi*(self.cycle_iter)/self.nb) + 1\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            self.nb *= self.cycle_mult\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return init_lrs / 2 * cos_out\n\n\nclass CircularLR(LR_Updater):\n    \'\'\'\n    An learning rate updater that implements the CirularLearningRate (CLR) scheme. \n    Learning rate is increased then decreased linearly. \n    \'\'\'\n    def __init__(self, layer_opt, nb, div=4, cut_div=8, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.cut_div,self.on_cycle_end = nb,div,cut_div,on_cycle_end\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = 1 - (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = self.cycle_iter/cut_pt\n        res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n    \n    def calc_mom(self):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = 1 - self.cycle_iter/cut_pt\n        res = self.moms[1] + pct * (self.moms[0] - self.moms[1])\n        return res\n\nclass CircularLR_beta(LR_Updater):\n    def __init__(self, layer_opt, nb, div=10, pct=10, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.pct,self.on_cycle_end = nb,div,pct,on_cycle_end\n        self.cycle_nb = int(nb * (1-pct/100) / 2)\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.cycle_iter>2 * self.cycle_nb:\n            pct = (self.cycle_iter - 2*self.cycle_nb)/(self.nb - 2*self.cycle_nb)\n            res = init_lrs * (1 + (pct * (1-100)/100)) / self.div\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n\n    def calc_mom(self):\n        if self.cycle_iter>2*self.cycle_nb:\n            res = self.moms[0]\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        return res\n\n\nclass SaveBestModel(LossRecorder):\n    \n    """""" Save weights of the best model based during training.\n        If metrics are provided, the first metric in the list is used to\n        find the best model. \n        If no metrics are provided, the loss is used.\n        \n        Args:\n            model: the fastai model\n            lr: indicate to use test images; otherwise use validation images\n            name: the name of filename of the weights without \'.h5\'\n        \n        Usage:\n            Briefly, you have your model \'learn\' variable and call fit.\n            >>> learn.fit(lr, 2, cycle_len=2, cycle_mult=1, best_save_name=\'mybestmodel\')\n            ....\n            >>> learn.load(\'mybestmodel\')\n            \n            For more details see http://forums.fast.ai/t/a-code-snippet-to-save-the-best-model-during-training/12066\n \n    """"""\n    def __init__(self, model, layer_opt, metrics, name=\'best_model\'):\n        super().__init__(layer_opt)\n        self.name = name\n        self.model = model\n        self.best_loss = None\n        self.best_acc = None\n        self.save_method = self.save_when_only_loss if metrics==None else self.save_when_acc\n        \n    def save_when_only_loss(self, metrics):\n        loss = metrics[0]\n        if self.best_loss == None or loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n    \n    def save_when_acc(self, metrics):\n        loss, acc = metrics[0], metrics[1]\n        if self.best_acc == None or acc > self.best_acc:\n            self.best_acc = acc\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        elif acc == self.best_acc and  loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        \n    def on_epoch_end(self, metrics):\n        super().on_epoch_end(metrics)\n        self.save_method(metrics)\n\n\nclass WeightDecaySchedule(Callback):\n    def __init__(self, layer_opt, batch_per_epoch, cycle_len, cycle_mult, n_cycles, norm_wds=False, wds_sched_mult=None):\n        """"""\n        Implements the weight decay schedule as mentioned in https://arxiv.org/abs/1711.05101\n\n        :param layer_opt: The LayerOptimizer\n        :param batch_per_epoch: Num batches in 1 epoch\n        :param cycle_len: Num epochs in initial cycle. Subsequent cycle_len = previous cycle_len * cycle_mult\n        :param cycle_mult: Cycle multiplier\n        :param n_cycles: Number of cycles to be executed\n        """"""\n        super().__init__()\n\n        self.layer_opt = layer_opt\n        self.batch_per_epoch = batch_per_epoch\n        self.init_wds = np.array(layer_opt.wds)  # Weights as set by user\n        self.init_lrs = np.array(layer_opt.lrs)  # Learning rates as set by user\n        self.new_wds = None                      # Holds the new weight decay factors, calculated in on_batch_begin()\n        self.param_groups_old = None             # Caches the old parameter values in on_batch_begin()\n        self.iteration = 0\n        self.epoch = 0\n        self.wds_sched_mult = wds_sched_mult\n        self.norm_wds = norm_wds\n        self.wds_history = list()\n\n        # Pre calculating the number of epochs in the cycle of current running epoch\n        self.epoch_to_num_cycles, i = dict(), 0\n        for cycle in range(n_cycles):\n            for _ in range(cycle_len):\n                self.epoch_to_num_cycles[i] = cycle_len\n                i += 1\n            cycle_len *= cycle_mult\n\n    def on_train_begin(self):\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_batch_begin(self):\n        # Prepare for decay of weights\n\n        # Default weight decay (as provided by user)\n        wdn = self.init_wds\n\n        # Weight decay multiplier (The \'eta\' in the paper). Optional.\n        wdm = 1.0\n        if self.wds_sched_mult is not None:\n            wdm = self.wds_sched_mult(self)\n\n        # Weight decay normalized. Optional.\n        if self.norm_wds:\n            wdn = wdn / np.sqrt(self.batch_per_epoch * self.epoch_to_num_cycles[self.epoch])\n\n        # Final wds\n        self.new_wds = wdm * wdn\n\n        # Record the wds\n        self.wds_history.append(self.new_wds)\n\n        # Set weight_decay with zeros so that it is not applied in Adam, we will apply it outside in on_batch_end()\n        self.layer_opt.set_wds(torch.zeros(self.new_wds.size))\n        # We have to save the existing weights before the optimizer changes the values\n        self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n        self.iteration += 1\n\n    def on_batch_end(self, loss):\n        # Decay the weights\n        for group, group_old, wds in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.new_wds):\n            for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                if p.grad is None:\n                    continue\n                p.data = p.data.add(-wds, p_old.data)\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n\nclass DecayType(IntEnum):\n    \'\'\' Data class, each decay type is assigned a number. \'\'\'\n    NO = 1\n    LINEAR = 2\n    COSINE = 3\n    EXPONENTIAL = 4\n    POLYNOMIAL = 5\n\nclass DecayScheduler():\n    \'\'\'Given initial and endvalue, this class generates the next value depending on decay type and number of iterations. (by calling next_val().) \'\'\'\n\n    def __init__(self, dec_type, num_it, start_val, end_val=None, extra=None):\n        self.dec_type, self.nb, self.start_val, self.end_val, self.extra = dec_type, num_it, start_val, end_val, extra\n        self.it = 0\n        if self.end_val is None and not (self.dec_type in [1,4]): self.end_val = 0\n    \n    def next_val(self):\n        self.it += 1\n        if self.dec_type == DecayType.NO:\n            return self.start_val\n        elif self.dec_type == DecayType.LINEAR:\n            pct = self.it/self.nb\n            return self.start_val + pct * (self.end_val-self.start_val)\n        elif self.dec_type == DecayType.COSINE:\n            cos_out = np.cos(np.pi*(self.it)/self.nb) + 1\n            return self.end_val + (self.start_val-self.end_val) / 2 * cos_out\n        elif self.dec_type == DecayType.EXPONENTIAL:\n            ratio = self.end_val / self.start_val\n            return self.start_val * (ratio **  (self.it/self.nb))\n        elif self.dec_type == DecayType.POLYNOMIAL:\n            return self.end_val + (self.start_val-self.end_val) * (1 - self.it/self.nb)**self.extra\n        \n\nclass TrainingPhase():\n    \'\'\'\n    Object with training information for each phase, when multiple phases are involved during training.  \n    Used in fit_opt_sched in learner.py\n    \'\'\'\n    def __init__(self, epochs=1, opt_fn=optim.SGD, lr=1e-2, lr_decay=DecayType.NO, momentum=0.9,\n                momentum_decay=DecayType.NO, beta=None, wds=None, wd_loss=True):\n        """"""\n        Creates an object containing all the relevant informations for one part of a model training.\n\n        Args\n        epochs: number of epochs to train like this\n        opt_fn: an optimizer (example optim.Adam)\n        lr: one learning rate or a tuple of the form (start_lr,end_lr)\n          each of those can be a list/numpy array for differential learning rates\n        lr_decay: a DecayType object specifying how the learning rate should change\n        momentum: one momentum (or beta1 in case of Adam), or a tuple of the form (start_mom,end_mom)\n        momentum_decay: a DecayType object specifying how the momentum should change\n        beta: beta2 parameter of Adam or alpha parameter of RMSProp\n        wds: weight decay (can be an array for differential wds)\n        """"""\n        self.epochs, self.opt_fn, self.lr, self.momentum, self.beta, self.wds = epochs, opt_fn, lr, momentum, beta, wds\n        if isinstance(lr_decay,tuple): self.lr_decay, self.extra_lr = lr_decay\n        else: self.lr_decay, self.extra_lr = lr_decay, None\n        if isinstance(momentum_decay,tuple): self.mom_decay, self.extra_mom = momentum_decay\n        else: self.mom_decay, self.extra_mom = momentum_decay, None\n        self.wd_loss = wd_loss\n\n    def phase_begin(self, layer_opt, nb_batches):\n        self.layer_opt = layer_opt\n        if isinstance(self.lr, tuple): start_lr,end_lr = self.lr\n        else: start_lr, end_lr = self.lr, None\n        self.lr_sched = DecayScheduler(self.lr_decay, nb_batches * self.epochs, start_lr, end_lr, extra=self.extra_lr)\n        if isinstance(self.momentum, tuple): start_mom,end_mom = self.momentum\n        else: start_mom, end_mom = self.momentum, None\n        self.mom_sched = DecayScheduler(self.mom_decay, nb_batches * self.epochs, start_mom, end_mom, extra=self.extra_mom)\n        self.layer_opt.set_opt_fn(self.opt_fn)\n        self.layer_opt.set_lrs(start_lr)\n        self.layer_opt.set_mom(start_mom)\n        if self.beta is not None: self.layer_opt.set_beta(self.beta)\n        if self.wds is not None:\n            if not isinstance(self.wds, Iterable): self.wds=[self.wds]\n            if len(self.wds)==1: self.wds=self.wds*len(self.layer_opt.layer_groups) \n            if self.wd_loss: self.layer_opt.set_wds(self.wds)\n            else: self.layer_opt.set_wds([0] * len(self.wds))\n    \n    def on_batch_begin(self):\n        if not self.wd_loss: self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n\n    def update(self):\n        new_lr, new_mom = self.lr_sched.next_val(), self.mom_sched.next_val()\n        self.layer_opt.set_lrs(new_lr)\n        self.layer_opt.set_mom(new_mom)\n        if not self.wd_loss: # Decay the weights outside of the loss\n            if not isinstance(new_lr, Iterable): new_lr=[new_lr]\n            if len(new_lr)==1: new_lr=new_lr*len(self.layer_opt.layer_groups)\n            for group, group_old, wds, lr in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.wds, new_lr):\n                for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                    if p.grad is None: continue\n                    p.data = p.data.add(-wds*lr, p_old.data)\n    \n\nclass OptimScheduler(LossRecorder):\n    \'\'\'Learning rate Scheduler for training involving multiple phases.\'\'\'\n\n    def __init__(self, layer_opt, phases, nb_batches, stop_div = False):\n        self.phases, self.nb_batches, self.stop_div = phases, nb_batches, stop_div\n        super().__init__(layer_opt, record_mom=True)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.phase,self.best=0,1e9\n    \n    def on_batch_begin(self):\n        self.phases[self.phase].on_batch_begin()\n        super().on_batch_begin()\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_div and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        super().on_batch_end(metrics)\n        self.phases[self.phase].update()\n    \n    def on_phase_begin(self):\n        self.phases[self.phase].phase_begin(self.layer_opt, self.nb_batches)\n\n    def on_phase_end(self):\n        self.phase += 1\n\n    def plot_lr(self, show_text=True, show_moms=True):\n        """"""Plots the lr rate/momentum schedule""""""\n        phase_limits = [0]\n        for phase in self.phases:\n            phase_limits.append(phase_limits[-1] + self.nb_batches * phase.epochs)\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        np_plts = 2 if show_moms else 1\n        fig, axs = plt.subplots(1,np_plts,figsize=(6*np_plts,4))\n        if not show_moms: axs = [axs]\n        for i in range(np_plts): axs[i].set_xlabel(\'iterations\')\n        axs[0].set_ylabel(\'learning rate\')\n        axs[0].plot(self.iterations,self.lrs)\n        if show_moms:\n            axs[1].set_ylabel(\'momentum\')\n            axs[1].plot(self.iterations,self.momentums)\n        if show_text:   \n            for i, phase in enumerate(self.phases):\n                text = phase.opt_fn.__name__\n                if phase.wds is not None: text+=\'\\nwds=\'+str(phase.wds)\n                if phase.beta is not None: text+=\'\\nbeta=\'+str(phase.beta)\n                for k in range(np_plts):\n                    if i < len(self.phases)-1:\n                        draw_line(axs[k], phase_limits[i+1])\n                    draw_text(axs[k], (phase_limits[i]+phase_limits[i+1])/2, text) \n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n    \n    def plot(self, n_skip=10, n_skip_end=5, linear=None):\n        if linear is None: linear = self.phases[-1].lr_decay == DecayType.LINEAR\n        plt.ylabel(""loss"")\n        plt.plot(self.lrs[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if linear: plt.xlabel(""learning rate"")\n        else:\n            plt.xlabel(""learning rate (log scale)"")\n            plt.xscale(\'log\')\n\ndef draw_line(ax,x):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.plot([x,x],[ymin,ymax], color=\'red\', linestyle=\'dashed\')\n\ndef draw_text(ax,x, text):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.text(x,(ymin+ymax)/2,text, horizontalalignment=\'center\', verticalalignment=\'center\', fontsize=14, alpha=0.5)\n\ndef smooth_curve(vals, beta):\n    avg_val = 0\n    smoothed = []\n    for (i,v) in enumerate(vals):\n        avg_val = beta * avg_val + (1-beta) * v\n        smoothed.append(avg_val/(1-beta**(i+1)))\n    return smoothed\n'"
fastai/courses/dl1/fastai/structured.py,0,"b'from .imports import *\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\n\ndef set_plot_sizes(sml, med, big):\n    plt.rc(\'font\', size=sml)          # controls default text sizes\n    plt.rc(\'axes\', titlesize=sml)     # fontsize of the axes title\n    plt.rc(\'axes\', labelsize=med)    # fontsize of the x and y labels\n    plt.rc(\'xtick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'ytick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'legend\', fontsize=sml)    # legend fontsize\n    plt.rc(\'figure\', titlesize=big)  # fontsize of the figure title\n\ndef parallel_trees(m, fn, n_jobs=8):\n        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    """""" Draws a representation of a random forest in IPython.\n\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    """"""\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub(\'Tree {\',\n       f\'Tree {{ size={size}; ratio={ratio}\', s)))\n\ndef combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = (\'<M8[Y]\', \'<m8[M]\', \'<m8[D]\', \'<m8[W]\', \'<m8[h]\',\n             \'<m8[m]\', \'<m8[s]\', \'<m8[ms]\', \'<m8[us]\', \'<m8[ns]\')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\ndef get_sample(df,n):\n    """""" Gets a random sample of n rows from df, without replacement.\n\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    >>> get_sample(df, 2)\n       col1 col2\n    1     2    b\n    2     3    a\n    """"""\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef add_datepart(df, fldname, drop=True, time=False):\n    """"""add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({ \'A\' : pd.to_datetime([\'3/11/2000\', \'3/12/2000\', \'3/13/2000\'], infer_datetime_format=False) })\n    >>> df\n\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n\n    >>> add_datepart(df, \'A\')\n    >>> df\n\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    """"""\n    fld = df[fldname]\n    if not np.issubdtype(fld.dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub(\'[Dd]ate$\', \'\', fldname)\n    attr = [\'Year\', \'Month\', \'Week\', \'Day\', \'Dayofweek\', \'Dayofyear\',\n            \'Is_month_end\', \'Is_month_start\', \'Is_quarter_end\', \'Is_quarter_start\', \'Is_year_end\', \'Is_year_start\']\n    if time: attr = attr + [\'Hour\', \'Minute\', \'Second\']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + \'Elapsed\'] = fld.astype(np.int64) // 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n\ndef is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n\ndef train_cats(df):\n    """"""Change any columns of strings in a panda\'s dataframe to a column of\n    catagorical values. This applies the changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category\n    """"""\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype(\'category\').cat.as_ordered()\n\ndef apply_cats(df, trn):\n    """"""Changes any columns of strings in df into categorical variables using trn as\n    a template for the category codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values. The category codes are determined by trn.\n\n    trn: A pandas dataframe. When creating a category for df, it looks up the\n        what the category\'s code were in trn and makes those the category codes\n        for df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category {a : 1, b : 2}\n\n    >>> df2 = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'b\', \'a\', \'a\']})\n    >>> apply_cats(df2, df)\n\n           col1 col2\n        0     1    b\n        1     2    a\n        2     3    a\n\n    now the type of col is category {a : 1, b : 2}\n    """"""\n    for n,c in df.items():\n        if (n in trn.columns) and (trn[n].dtype.name==\'category\'):\n            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n\ndef fix_missing(df, col, name, na_dict):\n    """""" Fill missing data in a column of df with the median, and add a {name}_na column\n    which specifies if the data was missing.\n\n    Parameters:\n    -----------\n    df: The data frame that will be changed.\n\n    col: The column of data to fix by filling in missing data.\n\n    name: The name of the new filled column in df.\n\n    na_dict: A dictionary of values to create na\'s of and the value to insert. If\n        name is not a key of na_dict the median will fill any missing data. Also\n        if name is not a key of na_dict and there is no missing data in col, then\n        no {name}_na column is not created.\n\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1     2    2    True\n    2     3    2   False\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col2\'], \'col2\', {})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {\'col1\' : 500})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1   500    2    True\n    2     3    2   False\n    """"""\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+\'_na\'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    """""" Changes the column col from a categorical type to it\'s integer codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. df[name] will be filled with the integer codes from\n        col.\n\n    col: The column you wish to change into the categories.\n    name: The column name you wish to insert into df. This column will hold the\n        integer codes.\n\n    max_n_cat: If col has more categories than max_n_cat it will not change the\n        it to its integer codes. If max_n_cat is None, then col will always be\n        converted.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> numericalize(df, df[\'col2\'], \'col3\', None)\n\n       col1 col2 col3\n    0     1    a    1\n    1     2    b    2\n    2     3    a    1\n    """"""\n    if not is_numeric_dtype(col) and ( max_n_cat is None or col.nunique()>max_n_cat):\n        df[name] = col.cat.codes+1\n\ndef scale_vars(df, mapper):\n    warnings.filterwarnings(\'ignore\', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper\n\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    """""" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n\n    y_fld: The name of the response variable\n\n    skip_flds: A list of fields that dropped from df.\n\n    ignore_flds: A list of fields that are ignored during processing.\n\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n\n    preproc_fn: A function that gets applied to df.\n\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n\n    subset: Takes a random subset of size subset from df.\n\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n\n        y: y is the response variable\n\n        nas: returns a dictionary of which nas it created, and the associated median.\n\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> x, y, nas = proc_df(df, \'col1\')\n    >>> x\n\n       col2\n    0     1\n    1     2\n    2     1\n\n    >>> data = DataFrame(pet=[""cat"", ""dog"", ""dog"", ""fish"", ""cat"", ""dog"", ""cat"", ""fish""],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    """"""\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    df = df.copy()\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({\'cols\':df.columns, \'imp\':m.feature_importances_}\n                       ).sort_values(\'imp\', ascending=False)\n\ndef set_rf_samples(n):\n    """""" Changes Scikit learn\'s random forests to give each tree a random sample of\n    n random rows.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    """""" Undoes the changes produced by set_rf_samples.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\ndef get_nn_mappers(df, cat_vars, contin_vars):\n    # Replace nulls with 0 for continuous, """" for categorical.\n    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n    for v in cat_vars: df[v].fillna(\'#NA#\', inplace=True)\n\n    # list of tuples, containing variable and instance of a transformer for that variable\n    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n    return DataFrameMapper(cat_maps).fit(df), DataFrameMapper(contin_maps).fit(df)\n'"
fastai/courses/dl1/fastai/swa.py,3,"b'""""""\n    From the paper:\n        Averaging Weights Leads to Wider Optima and Better Generalization\n        Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, Andrew Gordon Wilson\n        https://arxiv.org/abs/1803.05407\n        2018\n        \n    Author\'s implementation: https://github.com/timgaripov/swa\n""""""\n\nimport torch\nfrom .sgdr import *\nfrom .core import *\n\n\nclass SWA(Callback):\n    def __init__(self, model, swa_model, swa_start):\n        super().__init__()\n        self.model,self.swa_model,self.swa_start=model,swa_model,swa_start\n        \n    def on_train_begin(self):\n        self.epoch = 0\n        self.swa_n = 0\n\n    def on_epoch_end(self, metrics):\n        if (self.epoch + 1) >= self.swa_start:\n            self.update_average_model()\n            self.swa_n += 1\n            \n        self.epoch += 1\n            \n    def update_average_model(self):\n        # update running average of parameters\n        model_params = self.model.parameters()\n        swa_params = self.swa_model.parameters()\n        for model_param, swa_param in zip(model_params, swa_params):\n            swa_param.data *= self.swa_n\n            swa_param.data += model_param.data\n            swa_param.data /= (self.swa_n + 1)            \n    \ndef collect_bn_modules(module, bn_modules):\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        bn_modules.append(module)\n\ndef fix_batchnorm(swa_model, train_dl):\n    """"""\n    During training, batch norm layers keep track of a running mean and\n    variance of the previous layer\'s activations. Because the parameters\n    of the SWA model are computed as the average of other models\' parameters,\n    the SWA model never sees the training data itself, and therefore has no\n    opportunity to compute the correct batch norm statistics. Before performing \n    inference with the SWA model, we perform a single pass over the training data\n    to calculate an accurate running mean and variance for each batch norm layer.\n    """"""\n    bn_modules = []\n    swa_model.apply(lambda module: collect_bn_modules(module, bn_modules))\n    \n    if not bn_modules: return\n\n    swa_model.train()\n\n    for module in bn_modules:\n        module.running_mean = torch.zeros_like(module.running_mean)\n        module.running_var = torch.ones_like(module.running_var)\n    \n    momenta = [m.momentum for m in bn_modules]\n\n    inputs_seen = 0\n\n    for (*x,y) in iter(train_dl):        \n        xs = V(x)\n        batch_size = xs[0].size(0)\n\n        momentum = batch_size / (inputs_seen + batch_size)\n        for module in bn_modules:\n            module.momentum = momentum\n                            \n        res = swa_model(*xs)        \n        \n        inputs_seen += batch_size\n                \n    for module, momentum in zip(bn_modules, momenta):\n        module.momentum = momentum    '"
fastai/courses/dl1/fastai/text.py,1,"b'from .core import *\nfrom .learner import *\nfrom .lm_rnn import *\nfrom torch.utils.data.sampler import Sampler\nimport spacy\nfrom spacy.symbols import ORTH\n\nre_tok = re.compile(f\'([{string.punctuation}\xe2\x80\x9c\xe2\x80\x9d\xc2\xa8\xc2\xab\xc2\xbb\xc2\xae\xc2\xb4\xc2\xb7\xc2\xba\xc2\xbd\xc2\xbe\xc2\xbf\xc2\xa1\xc2\xa7\xc2\xa3\xe2\x82\xa4\xe2\x80\x98\xe2\x80\x99])\')\ndef tokenize(s): return re_tok.sub(r\' \\1 \', s).split()\n\ndef texts_labels_from_folders(path, folders):\n    texts,labels = [],[]\n    for idx,label in enumerate(folders):\n        for fname in glob(os.path.join(path, label, \'*.*\')):\n            texts.append(open(fname, \'r\').read())\n            labels.append(idx)\n    return texts, np.array(labels).astype(np.int64)\n\ndef numericalize_tok(tokens, max_vocab=50000, min_freq=0, unk_tok=""_unk_"", pad_tok=""_pad_"", bos_tok=""_bos_"", eos_tok=""_eos_""):\n    """"""Takes in text tokens and returns int2tok and tok2int converters\n\n        Arguments:\n        tokens(list): List of tokens. Can be a list of strings, or a list of lists of strings.\n        max_vocab(int): Number of tokens to return in the vocab (sorted by frequency)\n        min_freq(int): Minimum number of instances a token must be present in order to be preserved.\n        unk_tok(str): Token to use when unknown tokens are encountered in the source text.\n        pad_tok(str): Token to use when padding sequences.\n    """"""\n    if isinstance(tokens, str):\n        raise ValueError(""Expected to receive a list of tokens. Received a string instead"")\n    if isinstance(tokens[0], list):\n        tokens = [p for o in tokens for p in o]\n    freq = Counter(tokens)\n    int2tok = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n    unk_id = 3\n    int2tok.insert(0, bos_tok)\n    int2tok.insert(1, pad_tok)\n    int2tok.insert(2, eos_tok)\n    int2tok.insert(unk_id, unk_tok)\n    tok2int = collections.defaultdict(lambda:unk_id, {v:k for k,v in enumerate(int2tok)})\n    return int2tok, tok2int\n\nclass Tokenizer():\n    def __init__(self, lang=\'en\'):\n        self.re_br = re.compile(r\'<\\s*br\\s*/?>\', re.IGNORECASE)\n        self.tok = spacy.load(lang)\n        for w in (\'<eos>\',\'<bos>\',\'<unk>\'):\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\n\n    def sub_br(self,x): return self.re_br.sub(""\\n"", x)\n\n    def spacy_tok(self,x):\n        return [t.text for t in self.tok.tokenizer(self.sub_br(x))]\n\n    re_rep = re.compile(r\'(\\S)(\\1{3,})\')\n    re_word_rep = re.compile(r\'(\\b\\w+\\W+)(\\1{3,})\')\n\n    @staticmethod\n    def replace_rep(m):\n        TK_REP = \'tk_rep\'\n        c,cc = m.groups()\n        return f\' {TK_REP} {len(cc)+1} {c} \'\n\n    @staticmethod\n    def replace_wrep(m):\n        TK_WREP = \'tk_wrep\'\n        c,cc = m.groups()\n        return f\' {TK_WREP} {len(cc.split())+1} {c} \'\n\n    @staticmethod\n    def do_caps(ss):\n        TOK_UP,TOK_SENT,TOK_MIX = \' t_up \',\' t_st \',\' t_mx \'\n        res = []\n        prev=\'.\'\n        re_word = re.compile(\'\\w\')\n        re_nonsp = re.compile(\'\\S\')\n        for s in re.findall(r\'\\w+|\\W+\', ss):\n            res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n    #                 else [TOK_SENT,s.lower()] if (s.istitle() and re_word.search(prev))\n                    else [s.lower()])\n    #         if re_nonsp.search(s): prev = s\n        return \'\'.join(res)\n\n    def proc_text(self, s):\n        s = self.re_rep.sub(Tokenizer.replace_rep, s)\n        s = self.re_word_rep.sub(Tokenizer.replace_wrep, s)\n        s = Tokenizer.do_caps(s)\n        s = re.sub(r\'([/#])\', r\' \\1 \', s)\n        s = re.sub(\' {2,}\', \' \', s)\n        return self.spacy_tok(s)\n\n    @staticmethod\n    def proc_all(ss, lang):\n        tok = Tokenizer(lang)\n        return [tok.proc_text(s) for s in ss]\n\n    @staticmethod\n    def proc_all_mp(ss, lang=\'en\'):\n        ncpus = num_cpus()//2\n        with ProcessPoolExecutor(ncpus) as e:\n            return sum(e.map(Tokenizer.proc_all, ss, [lang]*len(ss)), [])\n\n\nclass TextDataset(Dataset):\n    def __init__(self, x, y, backwards=False, sos=None, eos=None):\n        self.x,self.y,self.backwards,self.sos,self.eos = x,y,backwards,sos,eos\n\n    def __getitem__(self, idx):\n        x = self.x[idx]\n        if self.backwards: x = list(reversed(x))\n        if self.eos is not None: x = x + [self.eos]\n        if self.sos is not None: x = [self.sos]+x\n        return np.array(x),self.y[idx]\n\n    def __len__(self): return len(self.x)\n\n\nclass SortSampler(Sampler):\n    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n    def __len__(self): return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range(len(self.data_source)), key=self.key, reverse=True))\n\n\nclass SortishSampler(Sampler):\n    """"""Returns an iterator that traverses the the data in randomly ordered batches that are approximately the same size.\n    The max key size batch is always returned in the first call because of pytorch cuda memory allocation sequencing.\n    Without that max key returned first multiple buffers may be allocated when the first created isn\'t large enough\n    to hold the next in the sequence.\n    """"""\n    def __init__(self, data_source, key, bs):\n        self.data_source,self.key,self.bs = data_source,key,bs\n\n    def __len__(self): return len(self.data_source)\n\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs*50\n        ck_idx = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n        sort_idx = np.concatenate([sorted(s, key=self.key, reverse=True) for s in ck_idx])\n        sz = self.bs\n        ck_idx = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n        max_ck = np.argmax([ck[0] for ck in ck_idx])  # find the chunk with the largest key,\n        ck_idx[0],ck_idx[max_ck] = ck_idx[max_ck],ck_idx[0]  # then make sure it goes first.\n        sort_idx = np.concatenate(np.random.permutation(ck_idx[1:]))\n        sort_idx = np.concatenate((ck_idx[0], sort_idx))\n        return iter(sort_idx)\n\n\nclass LanguageModelLoader():\n    """""" Returns a language model iterator that iterates through batches that are of length N(bptt,5)\n    The first batch returned is always bptt+25; the max possible width.  This is done because of they way that pytorch\n    allocates cuda memory in order to prevent multiple buffers from being created as the batch width grows.\n    """"""\n    def __init__(self, nums, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        while self.i < self.n-1 and self.iter<len(self):\n            if self.i == 0:\n                seq_len = self.bptt + 5 * 5\n            else:\n                bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n                seq_len = max(5, int(np.random.normal(bptt, 5)))\n            res = self.get_batch(self.i, seq_len)\n            self.i += seq_len\n            self.iter += 1\n            yield res\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def batchify(self, data):\n        nb = data.shape[0] // self.bs\n        data = np.array(data[:nb*self.bs])\n        data = data.reshape(self.bs, -1).T\n        if self.backwards: data=data[::-1]\n        return T(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass LanguageModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [*zip(m.rnns, m.dropouths), (self.model[1], m.dropouti)]\n\n\nclass LanguageModelData():\n    def __init__(self, path, pad_idx, n_tok, trn_dl, val_dl, test_dl=None, **kwargs):\n        self.path,self.pad_idx,self.n_tok = path,pad_idx,n_tok\n        self.trn_dl,self.val_dl,self.test_dl = trn_dl,val_dl,test_dl\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        m = get_language_model(self.n_tok, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = LanguageModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n'"
fastai/courses/dl1/fastai/torch_imports.py,6,"b'import os\nimport torch, torchvision, torchtext\nfrom torch import nn, cuda, backends, FloatTensor, LongTensor, optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.nn.init import kaiming_uniform, kaiming_normal\nfrom torchvision.transforms import Compose\nfrom torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\nfrom torchvision.models import vgg16_bn, vgg19_bn\nfrom torchvision.models import densenet121, densenet161, densenet169, densenet201\n\nfrom .models.resnext_50_32x4d import resnext_50_32x4d\nfrom .models.resnext_101_32x4d import resnext_101_32x4d\nfrom .models.resnext_101_64x4d import resnext_101_64x4d\nfrom .models.wrn_50_2f import wrn_50_2f\nfrom .models.inceptionresnetv2 import InceptionResnetV2\nfrom .models.inceptionv4 import inceptionv4\nfrom .models.nasnet import nasnetalarge\nfrom .models.fa_resnet import *\n\nimport warnings\nwarnings.filterwarnings(\'ignore\', message=\'Implicit dimension choice\', category=UserWarning)\n\ndef children(m): return m if isinstance(m, (list, tuple)) else list(m.children())\ndef save_model(m, p): torch.save(m.state_dict(), p)\ndef load_model(m, p): m.load_state_dict(torch.load(p, map_location=lambda storage, loc: storage))\n\ndef load_pre(pre, f, fn):\n    m = f()\n    path = os.path.dirname(__file__)\n    if pre: load_model(m, f\'{path}/weights/{fn}.pth\')\n    return m\n\ndef _fastai_model(name, paper_title, paper_href):\n    def add_docs_wrapper(f):\n        f.__doc__ = f""""""{name} model from\n        `""{paper_title}"" <{paper_href}>`_\n\n        Args:\n           pre (bool): If True, returns a model pre-trained on ImageNet\n        """"""\n        return f\n    return add_docs_wrapper\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inception_4(pre): return children(inceptionv4(pretrained=pre))[0]\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inceptionresnet_2(pre): return load_pre(pre, InceptionResnetV2, \'inceptionresnetv2-d579a627\')\n\n@_fastai_model(\'ResNeXt 50\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext50(pre): return load_pre(pre, resnext_50_32x4d, \'resnext_50_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_32\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101(pre): return load_pre(pre, resnext_101_32x4d, \'resnext_101_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_64\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101_64(pre): return load_pre(pre, resnext_101_64x4d, \'resnext_101_64x4d\')\n\n@_fastai_model(\'Wide Residual Networks\', \'Wide Residual Networks\',\n               \'https://arxiv.org/pdf/1605.07146.pdf\')\ndef wrn(pre): return load_pre(pre, wrn_50_2f, \'wrn_50_2f\')\n\n@_fastai_model(\'Densenet-121\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn121(pre): return children(densenet121(pre))[0]\n\n@_fastai_model(\'Densenet-169\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn161(pre): return children(densenet161(pre))[0]\n\n@_fastai_model(\'Densenet-161\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn169(pre): return children(densenet169(pre))[0]\n\n@_fastai_model(\'Densenet-201\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn201(pre): return children(densenet201(pre))[0]\n\n@_fastai_model(\'Vgg-16 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg16(pre): return children(vgg16_bn(pre))[0]\n\n@_fastai_model(\'Vgg-19 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg19(pre): return children(vgg19_bn(pre))[0]\n\n'"
fastai/courses/dl1/fastai/transforms.py,0,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\n\ndef scale_min(im, targ, interpolation=cv2.INTER_AREA):\n    """""" Scales the image so that the smallest axis is of size targ.\n\n    Arguments:\n        im (array): image\n        targ (int): target size\n    """"""\n    r,c,*_ = im.shape\n    ratio = targ/min(r,c)\n    sz = (scale_to(c, ratio, targ), scale_to(r, ratio, targ))\n    return cv2.resize(im, sz, interpolation=interpolation)\n\ndef zoom_cv(x,z):\n    \'\'\'zooms the center of image x, by a factor of z+1 while retaining the origal image size and proportion. \'\'\'\n    if z==0: return x\n    r,c,*_ = x.shape\n    M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)\n    return cv2.warpAffine(x,M,(c,r))\n\ndef stretch_cv(x,sr,sc,interpolation=cv2.INTER_AREA):\n    \'\'\'stretches image x horizontally by sr+1, and vertically by sc+1 while retaining the origal image size and proportion.\'\'\'\n    if sr==0 and sc==0: return x\n    r,c,*_ = x.shape\n    x = cv2.resize(x, None, fx=sr+1, fy=sc+1, interpolation=interpolation)\n    nr,nc,*_ = x.shape\n    cr = (nr-r)//2; cc = (nc-c)//2\n    return x[cr:r+cr, cc:c+cc]\n\ndef dihedral(x, dih):\n    \'\'\'performs any of 8 90 rotations or flips for image x.\n    \'\'\'\n    x = np.rot90(x, dih%4)\n    return x if dih<4 else np.fliplr(x)\n\ndef lighting(im, b, c):\n    \'\'\' adjusts image\'s balance and contrast\'\'\'\n    if b==0 and c==1: return im\n    mu = np.average(im)\n    return np.clip((im-mu)*c+mu+b,0.,1.).astype(np.float32)\n\ndef rotate_cv(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n    """""" Rotates an image by deg degrees\n\n    Arguments:\n        deg (float): degree to rotate.\n    """"""\n    r,c,*_ = im.shape\n    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n\ndef no_crop(im, min_sz=None, interpolation=cv2.INTER_AREA):\n    """""" Returns a squared resized image """"""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    return cv2.resize(im, (min_sz, min_sz), interpolation=interpolation)\n\ndef center_crop(im, min_sz=None):\n    """""" Returns a center crop of an image""""""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    start_r = math.ceil((r-min_sz)/2)\n    start_c = math.ceil((c-min_sz)/2)\n    return crop(im, start_r, start_c, min_sz)\n\ndef googlenet_resize(im, targ, min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p, interpolation=cv2.INTER_AREA):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ\n    \n    References:\n    1. https://arxiv.org/pdf/1409.4842.pdf\n    2. https://arxiv.org/pdf/1802.07888.pdf\n    """"""\n    h,w,*_ = im.shape\n    area = h*w\n    for _ in range(10):\n        targetArea = random.uniform(min_area_frac, 1.0) * area\n        aspectR = random.uniform(min_aspect_ratio, max_aspect_ratio)\n        ww = int(np.sqrt(targetArea * aspectR) + 0.5)\n        hh = int(np.sqrt(targetArea / aspectR) + 0.5)\n        if flip_hw_p:\n            ww, hh = hh, ww\n        if hh <= h and ww <= w:\n            x1 = 0 if w == ww else random.randint(0, w - ww)\n            y1 = 0 if h == hh else random.randint(0, h - hh)\n            out = im[y1:y1 + hh, x1:x1 + ww]\n            out = cv2.resize(out, (targ, targ), interpolation=interpolation)\n            return out\n    out = scale_min(im, targ, interpolation=interpolation)\n    out = center_crop(out)\n    return out\n\ndef cutout(im, n_holes, length):\n    \'\'\' cuts out n_holes number of square holes of size length in image at random locations. holes may be overlapping. \'\'\'\n    r,c,*_ = im.shape\n    mask = np.ones((r, c), np.int32)\n    for n in range(n_holes):\n        y = np.random.randint(length / 2, r - length / 2)\n        x = np.random.randint(length / 2, c - length / 2)\n\n        y1 = int(np.clip(y - length / 2, 0, r))\n        y2 = int(np.clip(y + length / 2, 0, r))\n        x1 = int(np.clip(x - length / 2, 0, c))\n        x2 = int(np.clip(x + length / 2, 0, c))\n        mask[y1: y2, x1: x2] = 0.\n    \n    mask = mask[:,:,None]\n    im = im * mask\n    return im\n\ndef scale_to(x, ratio, targ): \n    \'\'\'Calculate dimension of an image during scaling with aspect ratio\'\'\'\n    return max(math.floor(x*ratio), targ)\n\ndef crop(im, r, c, sz): \n    \'\'\'\n    crop image into a square of size sz, \n    \'\'\'\n    return im[r:r+sz, c:c+sz]\n\ndef det_dihedral(dih): return lambda x: dihedral(x, dih)\ndef det_stretch(sr, sc): return lambda x: stretch_cv(x, sr, sc)\ndef det_lighting(b, c): return lambda x: lighting(x, b, c)\ndef det_rotate(deg): return lambda x: rotate_cv(x, deg)\ndef det_zoom(zoom): return lambda x: zoom_cv(x, zoom)\n\ndef rand0(s): return random.random()*(s*2)-s\n\n\nclass TfmType(IntEnum):\n    """""" Type of transformation.\n    Parameters\n        IntEnum: predefined types of transformations\n            NO:    the default, y does not get transformed when x is transformed.\n            PIXEL: x and y are images and should be transformed in the same way.\n                   Example: image segmentation.\n            COORD: y are coordinates (i.e bounding boxes)\n            CLASS: y are class labels (same behaviour as PIXEL, except no normalization)\n    """"""\n    NO = 1\n    PIXEL = 2\n    COORD = 3\n    CLASS = 4\n\n\nclass Denormalize():\n    """""" De-normalizes an image, returning it to original format.\n    """"""\n    def __init__(self, m, s):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n    def __call__(self, x): return x*self.s+self.m\n\n\nclass Normalize():\n    """""" Normalizes an image to zero mean and unit standard deviation, given the mean m and std s of the original image """"""\n    def __init__(self, m, s, tfm_y=TfmType.NO):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n        self.tfm_y=tfm_y\n\n    def __call__(self, x, y=None):\n        x = (x-self.m)/self.s\n        if self.tfm_y==TfmType.PIXEL and y is not None: y = (y-self.m)/self.s\n        return x,y\n\nclass ChannelOrder():\n    \'\'\'\n    changes image array shape from (h, w, 3) to (3, h, w). \n    tfm_y decides the transformation done to the y element. \n    \'\'\'\n    def __init__(self, tfm_y=TfmType.NO): self.tfm_y=tfm_y\n\n    def __call__(self, x, y):\n        x = np.rollaxis(x, 2)\n        #if isinstance(y,np.ndarray) and (len(y.shape)==3):\n        if self.tfm_y==TfmType.PIXEL: y = np.rollaxis(y, 2)\n        elif self.tfm_y==TfmType.CLASS: y = y[...,0]\n        return x,y\n\n\ndef to_bb(YY, y=""deprecated""):\n    """"""Convert mask YY to a bounding box, assumes 0 as background nonzero object""""""\n    cols,rows = np.nonzero(YY)\n    if len(cols)==0: return np.zeros(4, dtype=np.float32)\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n\ndef coords2px(y, x):\n    """""" Transforming coordinates to pixels.\n\n    Arguments:\n        y : np array\n            vector in which (y[0], y[1]) and (y[2], y[3]) are the\n            the corners of a bounding box.\n        x : image\n            an image\n    Returns:\n        Y : image\n            of shape x.shape\n    """"""\n    rows = np.rint([y[0], y[0], y[2], y[2]]).astype(int)\n    cols = np.rint([y[1], y[3], y[1], y[3]]).astype(int)\n    r,c,*_ = x.shape\n    Y = np.zeros((r, c))\n    Y[rows, cols] = 1\n    return Y\n\n\nclass Transform():\n    """""" A class that represents a transform.\n\n    All other transforms should subclass it. All subclasses should override\n    do_transform.\n\n    Arguments\n    ---------\n        tfm_y : TfmType\n            type of transform\n    """"""\n    def __init__(self, tfm_y=TfmType.NO):\n        self.tfm_y=tfm_y\n        self.store = threading.local()\n\n    def set_state(self): pass\n    def __call__(self, x, y):\n        self.set_state()\n        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n                else self.transform_coord(x,y))\n        return x, y\n\n    def transform_coord(self, x, y): return self.transform(x),y\n\n    def transform(self, x, y=None):\n        x = self.do_transform(x,False)\n        return (x, self.do_transform(y,True)) if y is not None else x\n\n    @abstractmethod\n    def do_transform(self, x, is_y): raise NotImplementedError\n\n\nclass CoordTransform(Transform):\n    """""" A coordinate transform.  """"""\n\n    @staticmethod\n    def make_square(y, x):\n        r,c,*_ = x.shape\n        y1 = np.zeros((r, c))\n        y = y.astype(np.int)\n        y1[y[0]:y[2], y[1]:y[3]] = 1.\n        return y1\n\n    def map_y(self, y0, x):\n        y = CoordTransform.make_square(y0, x)\n        y_tr = self.do_transform(y, True)\n        return to_bb(y_tr)\n\n    def transform_coord(self, x, ys):\n        yp = partition(ys, 4)\n        y2 = [self.map_y(y,x) for y in yp]\n        x = self.do_transform(x, False)\n        return x, np.concatenate(y2)\n\n\nclass AddPadding(CoordTransform):\n    """""" A class that represents adding paddings to an image.\n\n    The default padding is border_reflect\n    Arguments\n    ---------\n        pad : int\n            size of padding on top, bottom, left and right\n        mode:\n            type of cv2 padding modes. (e.g., constant, reflect, wrap, replicate. etc. )\n    """"""\n    def __init__(self, pad, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.pad,self.mode = pad,mode\n\n    def do_transform(self, im, is_y):\n        return cv2.copyMakeBorder(im, self.pad, self.pad, self.pad, self.pad, self.mode)\n\nclass CenterCrop(CoordTransform):\n    """""" A class that represents a Center Crop.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        sz: int\n            size of the crop.\n        tfm_y : TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.min_sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        return center_crop(x, self.sz_y if is_y else self.min_sz)\n\n\nclass RandomCrop(CoordTransform):\n    """""" A class that represents a Random Crop transformation.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        targ: int\n            target size of the crop.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, targ_sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz,self.sz_y = targ_sz,sz_y\n\n    def set_state(self):\n        self.store.rand_r = random.uniform(0, 1)\n        self.store.rand_c = random.uniform(0, 1)\n\n    def do_transform(self, x, is_y):\n        r,c,*_ = x.shape\n        sz = self.sz_y if is_y else self.targ_sz\n        start_r = np.floor(self.store.rand_r*(r-sz)).astype(int)\n        start_c = np.floor(self.store.rand_c*(c-sz)).astype(int)\n        return crop(x, start_r, start_c, sz)\n\n\nclass NoCrop(CoordTransform):\n    """"""  A transformation that resize to a square image without cropping.\n\n    This transforms (optionally) resizes x,y at with the same parameters.\n    Arguments:\n        targ: int\n            target size of the crop.\n        tfm_y (TfmType): type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return no_crop(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return no_crop(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass Scale(CoordTransform):\n    """""" A transformation that scales the min size to sz.\n\n    Arguments:\n        sz: int\n            target size to scale minimum size.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass RandomScale(CoordTransform):\n    """""" Scales an image so that the min size is a random number between [sz, sz*max_zoom]\n\n    This transforms (optionally) scales x,y at with the same parameters.\n    Arguments:\n        sz: int\n            target size\n        max_zoom: float\n            float >= 1.0\n        p : float\n            a probability for doing the random sizing\n        tfm_y: TfmType\n            type of y transform\n    """"""\n    def __init__(self, sz, max_zoom, p=0.75, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.max_zoom,self.p,self.sz_y = sz,max_zoom,p,sz_y\n\n    def set_state(self):\n        min_z = 1.\n        max_z = self.max_zoom\n        if isinstance(self.max_zoom, collections.Iterable):\n            min_z, max_z = self.max_zoom\n        self.store.mult = random.uniform(min_z, max_z) if random.random()<self.p else 1\n        self.store.new_sz = int(self.store.mult*self.sz)\n        if self.sz_y is not None: self.store.new_sz_y = int(self.store.mult*self.sz_y)\n\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.store.new_sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.store.new_sz,   cv2.INTER_AREA   )\n\n\nclass RandomRotate(CoordTransform):\n    """""" Rotates images and (optionally) target y.\n\n    Rotating coordinates is treated differently for x and y on this\n    transform.\n     Arguments:\n        deg (float): degree to rotate.\n        p (float): probability of rotation\n        mode: type of border\n        tfm_y (TfmType): type of y transform\n    """"""\n    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.deg,self.p = deg,p\n        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n            self.modes = (mode,cv2.BORDER_CONSTANT)\n        else:\n            self.modes = (mode,mode)\n\n    def set_state(self):\n        self.store.rdeg = rand0(self.deg)\n        self.store.rp = random.random()<self.p\n\n    def do_transform(self, x, is_y):\n        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n                mode= self.modes[1] if is_y else self.modes[0],\n                interpolation=cv2.INTER_NEAREST if is_y else cv2.INTER_AREA)\n        return x\n\n\nclass RandomDihedral(CoordTransform):\n    """"""\n    Rotates images by random multiples of 90 degrees and/or reflection.\n    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n    """"""\n    def set_state(self):\n        self.store.rot_times = random.randint(0,3)\n        self.store.do_flip = random.random()<0.5\n\n    def do_transform(self, x, is_y):\n        x = np.rot90(x, self.store.rot_times)\n        return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomFlip(CoordTransform):\n    def __init__(self, tfm_y=TfmType.NO, p=0.5):\n        super().__init__(tfm_y=tfm_y)\n        self.p=p\n\n    def set_state(self): self.store.do_flip = random.random()<self.p\n    def do_transform(self, x, is_y): return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomLighting(Transform):\n    def __init__(self, b, c, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.b,self.c = b,c\n\n    def set_state(self):\n        self.store.b_rand = rand0(self.b)\n        self.store.c_rand = rand0(self.c)\n\n    def do_transform(self, x, is_y):\n        if is_y and self.tfm_y != TfmType.PIXEL: return x\n        b = self.store.b_rand\n        c = self.store.c_rand\n        c = -1/(c-1) if c<0 else c+1\n        x = lighting(x, b, c)\n        return x\n\nclass RandomRotateZoom(CoordTransform):\n    """""" \n        Selects between a rotate, zoom, stretch, or no transform.\n        Arguments:\n            deg - maximum degrees of rotation.\n            zoom - maximum fraction of zoom.\n            stretch - maximum fraction of stretch.\n            ps - probabilities for each transform. List of length 4. The order for these probabilities is as listed respectively (4th probability is \'no transform\'.\n    """"""\n    def __init__(self, deg, zoom, stretch, ps=None, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        if ps is None: ps = [0.25,0.25,0.25,0.25]\n        assert len(ps) == 4, \'does not have 4 probabilities for p, it has %d\' % len(ps)\n        self.transforms = RandomRotate(deg, p=1, mode=mode, tfm_y=tfm_y), RandomZoom(zoom, tfm_y=tfm_y), RandomStretch(stretch,tfm_y=tfm_y)\n        self.pass_t = PassThru()\n        self.cum_ps = np.cumsum(ps)\n        assert self.cum_ps[3]==1, \'probabilites do not sum to 1; they sum to %d\' % self.cum_ps[3]\n\n    def set_state(self):\n        self.store.trans = self.pass_t\n        self.store.choice = self.cum_ps[3]*random.random()\n        for i in range(len(self.transforms)):\n            if self.store.choice < self.cum_ps[i]:\n                self.store.trans = self.transforms[i]\n                break\n        self.store.trans.set_state()\n\n    def do_transform(self, x, is_y): return self.store.trans.do_transform(x, is_y)\n\nclass RandomZoom(CoordTransform):\n    def __init__(self, zoom_max, zoom_min=0, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.zoom_max, self.zoom_min = zoom_max, zoom_min\n\n    def set_state(self):\n        self.store.zoom = self.zoom_min+(self.zoom_max-self.zoom_min)*random.random()\n\n    def do_transform(self, x, is_y):\n        return zoom_cv(x, self.store.zoom)\n\nclass RandomStretch(CoordTransform):\n    def __init__(self, max_stretch, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.max_stretch = max_stretch\n\n    def set_state(self):\n        self.store.stretch = self.max_stretch*random.random()\n        self.store.stretch_dir = random.randint(0,1)\n\n    def do_transform(self, x, is_y):\n        if self.store.stretch_dir==0: x = stretch_cv(x, self.store.stretch, 0)\n        else:                         x = stretch_cv(x, 0, self.store.stretch)\n        return x\n\nclass PassThru(CoordTransform):\n    def do_transform(self, x, is_y):\n        return x\n\nclass RandomBlur(Transform):\n    """"""\n    Adds a gaussian blur to the image at chance.\n    Multiple blur strengths can be configured, one of them is used by random chance.\n    """"""\n\n    def __init__(self, blur_strengths=5, probability=0.5, tfm_y=TfmType.NO):\n        # Blur strength must be an odd number, because it is used as a kernel size.\n        super().__init__(tfm_y)\n        self.blur_strengths = (np.array(blur_strengths, ndmin=1) * 2) - 1\n        if np.any(self.blur_strengths < 0):\n            raise ValueError(""all blur_strengths must be > 0"")\n        self.probability = probability\n        self.apply_transform = False\n\n    def set_state(self):\n        self.store.apply_transform = random.random() < self.probability\n        kernel_size = np.random.choice(self.blur_strengths)\n        self.store.kernel = (kernel_size, kernel_size)\n\n    def do_transform(self, x, is_y):\n        return cv2.GaussianBlur(src=x, ksize=self.store.kernel, sigmaX=0) if self.apply_transform else x\n\nclass Cutout(Transform):\n    def __init__(self, n_holes, length, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.n_holes,self.length = n_holes,length\n\n    def do_transform(self, img, is_y):\n        return cutout(img, self.n_holes, self.length)\n\nclass GoogleNetResize(CoordTransform):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ \n    \n    Arguments:\n        targ_sz: int\n            target size\n        min_area_frac: float < 1.0\n            minimum area of the original image for cropping\n        min_aspect_ratio : float\n            minimum aspect ratio\n        max_aspect_ratio : float\n            maximum aspect ratio\n        flip_hw_p : float\n            probability for flipping magnitudes of height and width\n        tfm_y: TfmType\n            type of y transform\n    """"""\n\n    def __init__(self, targ_sz,\n                 min_area_frac=0.08, min_aspect_ratio=0.75, max_aspect_ratio=1.333, flip_hw_p=0.5,\n                 tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz, self.tfm_y, self.sz_y = targ_sz, tfm_y, sz_y\n        self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.flip_hw_p = min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p\n\n    def set_state(self):\n        # if self.random_state: random.seed(self.random_state)\n        self.store.fp = random.random()<self.flip_hw_p\n\n    def do_transform(self, x, is_y):\n        sz = self.sz_y if is_y else self.targ_sz\n        if is_y:\n            interpolation = cv2.INTER_NEAREST if self.tfm_y in (TfmType.COORD, TfmType.CLASS) else cv2.INTER_AREA\n        else:\n            interpolation = cv2.INTER_AREA\n        return googlenet_resize(x, sz, self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.store.fp, interpolation=interpolation)\n\n\ndef compose(im, y, fns):\n    """""" apply a collection of transformation functions fns to images\n    """"""\n    for fn in fns:\n        #pdb.set_trace()\n        im, y =fn(im, y)\n    return im if y is None else (im, y)\n\n\nclass CropType(IntEnum):\n    """""" Type of image cropping.\n    """"""\n    RANDOM = 1\n    CENTER = 2\n    NO = 3\n    GOOGLENET = 4\n\ncrop_fn_lu = {CropType.RANDOM: RandomCrop, CropType.CENTER: CenterCrop, CropType.NO: NoCrop, CropType.GOOGLENET: GoogleNetResize}\n\nclass Transforms():\n    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n                 tfm_y=TfmType.NO, sz_y=None):\n        if sz_y is None: sz_y = sz\n        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n        self.tfms = tfms\n        self.tfms.append(crop_tfm)\n        if normalizer is not None: self.tfms.append(normalizer)\n        self.tfms.append(ChannelOrder(tfm_y))\n\n    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n    def __repr__(self): return str(self.tfms)\n\n\ndef image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n    """"""\n    Generate a standard set of transformations\n\n    Arguments\n    ---------\n     normalizer :\n         image normalizing function\n     denorm :\n         image denormalizing function\n     sz :\n         size, sz_y = sz if not specified.\n     tfms :\n         iterable collection of transformation functions\n     max_zoom : float,\n         maximum zoom\n     pad : int,\n         padding on top, left, right and bottom\n     crop_type :\n         crop type\n     tfm_y :\n         y axis specific transformations\n     sz_y :\n         y size, height\n     pad_mode :\n         cv2 padding style: repeat, reflect, etc.\n\n    Returns\n    -------\n     type : ``Transforms``\n         transformer for specified image operations.\n\n    See Also\n    --------\n     Transforms: the transformer object returned by this function\n    """"""\n    if tfm_y is None: tfm_y=TfmType.NO\n    if tfms is None: tfms=[]\n    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n    if sz_y is None: sz_y = sz\n    if scale is None:\n        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n                 else Scale(sz, tfm_y, sz_y=sz_y)]\n    elif not is_listy(scale): scale = [scale]\n    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n                      tfm_y=tfm_y, sz_y=sz_y)\n\ndef noop(x):\n    """"""dummy function for do-nothing.\n    equivalent to: lambda x: x""""""\n    return x\n\ntransforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)]\ntransforms_side_on  = transforms_basic + [RandomFlip()]\ntransforms_top_down = transforms_basic + [RandomDihedral()]\n\nimagenet_stats = A([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n""""""Statistics pertaining to image data from image net. mean and std of the images of each color channel""""""\ninception_stats = A([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\ninception_models = (inception_4, inceptionresnet_2)\n\ndef tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Given the statistics of the training image sets, returns separate training and validation transform functions\n    """"""\n    if aug_tfms is None: aug_tfms=[]\n    tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n    tfm_denorm = Denormalize(*stats) if stats is not None else None\n    val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n    val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n            tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n    trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n            tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n    return trn_tfm, val_tfm\n\n\ndef tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Returns separate transformers of images for training and validation.\n    Transformers are constructed according to the image statistics given b y the model. (See tfms_from_stats)\n\n    Arguments:\n        f_model: model, pretrained or not pretrained\n    """"""\n    stats = inception_stats if f_model in inception_models else imagenet_stats\n    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)\n\n'"
fastai/courses/dl1/fastai/transforms_pil.py,1,"b'import torch\nimport numpy as np\n\n\nclass Cutout(object):\n    """"""Randomly mask out one or more patches from an image.\n\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    """"""\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (Tensor): Tensor image of size (C, H, W).\n        Returns:\n            Tensor: Image with n_holes of dimension length x length cut out of it.\n        """"""\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length / 2, 0, h)\n            y2 = np.clip(y + self.length / 2, 0, h)\n            x1 = np.clip(x - self.length / 2, 0, w)\n            x2 = np.clip(x + self.length / 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n'"
fastai/courses/dl1/fastai/utils.py,0,"b""import math, os, json, sys, re, numpy as np, pickle, PIL, scipy\nfrom PIL import Image\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom operator import itemgetter, attrgetter, methodcaller\nfrom collections import OrderedDict\nimport itertools\nfrom itertools import chain\n\nimport pandas as pd\nfrom numpy.random import random, permutation, randn, normal, uniform, choice\nfrom numpy import newaxis\nfrom scipy import misc, ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.manifold import TSNE\nimport bcolz\n\nfrom IPython.lib.display import FileLink\n\nimport keras\nfrom keras import backend as K\nfrom keras.utils.data_utils import get_file\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\nfrom keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\nfrom keras.layers import Flatten, Dense, Dropout, Lambda\nfrom keras.regularizers import l2, l1\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.layers import deserialize as layer_from_config\nfrom keras.metrics import categorical_crossentropy, categorical_accuracy\nfrom keras.layers.convolutional import *\nfrom keras.preprocessing import image, sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom vgg16 import Vgg16\nnp.set_printoptions(precision=4, linewidth=100)\n\n\nto_bw = np.array([0.299, 0.587, 0.114])\n\ndef gray(img): return np.rollaxis(img, 0, 1).dot(to_bw)\ndef to_plot(img): return np.rollaxis(img, 0, 1).astype(np.uint8)\ndef plot(img): plt.imshow(to_plot(img))\n\ndef floor(x): return int(math.floor(x))\ndef ceil(x): return int(math.ceil(x))\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    \n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n\n\ndef do_clip(arr, mx):\n    clipped = np.clip(arr, (1-mx)/1, mx)\n    return clipped/clipped.sum(axis=1)[:, np.newaxis]\n\n\ndef wrap_config(layer):\n    return {'class_name': layer.__class__.__name__, 'config': layer.get_config()}\n\ndef copy_layer(layer): return layer_from_config(wrap_config(layer))\n\ndef copy_layers(layers): return [copy_layer(layer) for layer in layers]\n\ndef copy_weights(from_layers, to_layers):\n    for from_layer,to_layer in zip(from_layers, to_layers):\n        to_layer.set_weights(from_layer.get_weights())\n\ndef save_array(fname, arr):\n    c=bcolz.carray(arr, rootdir=fname, mode='w')\n    c.flush()\n\ndef load_array(fname): return bcolz.open(fname)[:]\n\ndef get_classes(path):\n    batches = get_batches(path+'train', shuffle=False, batch_size=1)\n    val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n    test_batches = get_batches(path+'test', shuffle=False, batch_size=1)\n    return (val_batches.classes, batches.classes, onehot(val_batches.classes), onehot(batches.classes),\n        val_batches.filenames, batches.filenames, test_batches.filenames)\n\ndef limit_mem():\n    K.get_session().close()\n    cfg = K.tf.ConfigProto()\n    cfg.gpu_options.allow_growth = True\n    K.set_session(K.tf.Session(config=cfg))\n\nclass MixIterator(object):\n    def __init__(self, iters):\n        self.iters = iters\n        self.multi = type(iters) is list\n        if self.multi:\n            self.N = sum([it[0].N for it in self.iters])\n        else:\n            self.N = sum([it.N for it in self.iters])\n\n    def reset(self):\n        for it in self.iters: it.reset()\n\n    def __iter__(self):\n        return self\n\n    def next(self, *args, **kwargs):\n        if self.multi:\n            nexts = [[next(it) for it in o] for o in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n        else:\n            nexts = [next(it) for it in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n"""
fastai/courses/dl1/scripts/train_planet.py,2,"b'from fast_gen import *\nfrom learner import *\nfrom pt_models import *\nfrom dataset_pt import *\nfrom sgdr_pt import *\nfrom planet import *\n\nbs=64; f_model = resnet34\npath = ""/data/jhoward/fast/planet/""\ncv_idx = int(sys.argv[1])\ntorch.cuda.set_device(cv_idx % 4)\nif cv_idx==1: torch.cuda.set_device(2)\nn=len(list(open(f\'{path}train_v2.csv\')))-1\n\ndef train_sz(sz, load=None, save_name=None, suf=None):\n    print(f\'\\n***** {sz} *****\')\n    #data=get_data_pad(f_model, path, sz, bs, n, cv_idx)\n    data=get_data_zoom(f_model, path, sz, bs, n, cv_idx)\n    learn = Learner.pretrained_convnet(f_model, data, metrics=[f2])\n    if load: learn.load(f\'{load}_{cv_idx}{suf}\')\n    print(\'--- FC\')\n    learn.fit(0.3, 2, cycle_len=1)\n    print(\'--- Gradual\')\n    for i in range(6,3,-1):\n        learn.freeze_to(i)\n        learn.fit(0.1*(i-3), 1, cycle_len=1)\n    learn.unfreeze()\n    print(\'--- All\')\n    learn.fit(0.2, 15, cycle_len=3, cycle_save_name=f\'{save_name}{suf}\')\n    learn.save(f\'{sz}_{cv_idx}{suf}\')\n\nsuf=\'_zoom\'\ntrain_sz(64, suf=suf)\ntrain_sz(128, load=64, suf=suf)\ntrain_sz(244, load=128, save_name=f\'170809_{cv_idx}\', suf=suf)\n\n'"
fastai/courses/dl2/cgan/__init__.py,0,b''
fastai/courses/dl2/cgan/test.py,0,"b""import os\nfrom options.test_options import TestOptions\nfrom data.data_loader import CreateDataLoader\nfrom models.models import create_model\nfrom util.visualizer import Visualizer\nfrom util import html\n\nopt = TestOptions().parse()\nopt.nThreads = 1   # test code only supports nThreads = 1\nopt.batchSize = 1  # test code only supports batchSize = 1\nopt.serial_batches = True  # no shuffle\nopt.no_flip = True  # no flip\n\ndata_loader = CreateDataLoader(opt)\ndataset = data_loader.load_data()\nmodel = create_model(opt)\nvisualizer = Visualizer(opt)\n# create website\nweb_dir = os.path.join(opt.results_dir, opt.name, '%s_%s' % (opt.phase, opt.which_epoch))\nwebpage = html.HTML(web_dir, 'Experiment = %s, Phase = %s, Epoch = %s' % (opt.name, opt.phase, opt.which_epoch))\n# test\nfor i, data in enumerate(dataset):\n    if i >= opt.how_many: break\n    model.set_input(data)\n    model.test()\n    visuals = model.get_current_visuals()\n    img_path = model.get_image_paths()\n    print('%04d: process image... %s' % (i, img_path))\n    visualizer.save_images(webpage, visuals, img_path, aspect_ratio=opt.aspect_ratio)\n\nwebpage.save()\n"""
fastai/courses/dl2/cgan/train.py,0,"b""import time\nfrom options.train_options import TrainOptions\nfrom data.data_loader import CreateDataLoader\nfrom models.models import create_model\nfrom util.visualizer import Visualizer\n\nopt = TrainOptions().parse()\ndata_loader = CreateDataLoader(opt)\ndataset = data_loader.load_data()\ndataset_size = len(data_loader)\nprint('#training images = %d' % dataset_size)\n\nmodel = create_model(opt)\nvisualizer = Visualizer(opt)\ntotal_steps = 0\n\nfor epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n    epoch_start_time = time.time()\n    iter_data_time = time.time()\n    epoch_iter = 0\n\n    for i, data in enumerate(dataset):\n        iter_start_time = time.time()\n        if total_steps % opt.print_freq == 0:\n            t_data = iter_start_time - iter_data_time\n        visualizer.reset()\n        total_steps += opt.batchSize\n        epoch_iter += opt.batchSize\n        model.set_input(data)\n        model.optimize_parameters()\n\n        if total_steps % opt.display_freq == 0:\n            save_result = total_steps % opt.update_html_freq == 0\n            visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)\n\n        if total_steps % opt.print_freq == 0:\n            errors = model.get_current_errors()\n            t = (time.time() - iter_start_time) / opt.batchSize\n            visualizer.print_current_errors(epoch, epoch_iter, errors, t, t_data)\n            if opt.display_id > 0:\n                visualizer.plot_current_errors(epoch, float(epoch_iter) / dataset_size, opt, errors)\n\n        if total_steps % opt.save_latest_freq == 0:\n            print('saving the latest model (epoch %d, total_steps %d)' %\n                  (epoch, total_steps))\n            model.save('latest')\n\n        iter_data_time = time.time()\n    if epoch % opt.save_epoch_freq == 0:\n        print('saving the model at the end of epoch %d, iters %d' %\n              (epoch, total_steps))\n        model.save('latest')\n        model.save(epoch)\n\n    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n    model.update_learning_rate()\n"""
fastai/courses/dl2/fastai/__init__.py,0,b''
fastai/courses/dl2/fastai/adaptive_softmax.py,1,"b'from .lm_rnn import *\n\nclass AdaptiveSoftmax(nn.Module):\n    def __init__(self, input_size, cutoff):\n        super().__init__()\n        self.input_size,self.cutoff = input_size,cutoff\n        self.output_size = cutoff[0] + len(cutoff) - 1\n        self.head = nn.Linear(input_size, self.output_size)\n        self.tail = nn.ModuleList()\n        for i in range(len(cutoff) - 1):\n            seq = nn.Sequential(nn.Linear(input_size, input_size // 4 ** i, False),\n                nn.Linear(input_size // 4 ** i, cutoff[i + 1] - cutoff[i], False))\n            self.tail.append(seq)\n\n    def reset(self):\n        nn.init.xavier_normal(self.head.weight)\n        for tail in self.tail:\n            nn.init.xavier_normal(tail[0].weight)\n            nn.init.xavier_normal(tail[1].weight)\n\n    def set_target(self, target):\n        self.id = []\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            if mask.sum() > 0:\n                self.id.append(Variable(mask.float().nonzero().squeeze(1)))\n            else: self.id.append(None)\n\n    def forward(self, input):\n        output = [self.head(input)]\n        for i in range(len(self.id)):\n            if self.id[i] is not None:\n                output.append(self.tail[i](input.index_select(0, self.id[i])))\n            else: output.append(None)\n        return output\n\n    def log_prob(self, input):\n        lsm = nn.LogSoftmax().cuda()\n        head_out = self.head(input)\n        batch_size = head_out.size(0)\n        prob = torch.zeros(batch_size, self.cutoff[-1]).cuda()\n        lsm_head = lsm(head_out)\n        prob.narrow(1, 0, self.output_size).add_(lsm_head.narrow(1, 0, self.output_size).data)\n        for i in range(len(self.tail)):\n            pos = self.cutoff[i]\n            i_size = self.cutoff[i + 1] - pos\n            buffer = lsm_head.narrow(1, self.cutoff[0] + i, 1)\n            buffer = buffer.expand(batch_size, i_size)\n            lsm_tail = lsm(self.tail[i](input))\n            prob.narrow(1, pos, i_size).copy_(buffer.data).add_(lsm_tail.data)\n        return prob\n\n\nclass AdaptiveLoss(nn.Module):\n    def __init__(self, cutoff):\n        super().__init__()\n        self.cutoff = cutoff\n        self.criterions = nn.ModuleList([nn.CrossEntropyLoss(size_average=False) for i in self.cutoff])\n\n    def remap_target(self, target):\n        new_target = [target.clone()]\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            new_target[0][mask] = self.cutoff[0] + i\n            if mask.sum() > 0: new_target.append(target[mask].add(-self.cutoff[i]))\n            else: new_target.append(None)\n        return new_target\n\n    def forward(self, input, target):\n        batch_size = input[0].size(0)\n        target = self.remap_target(target.data)\n        output = 0.0\n        for i in range(len(input)):\n            if input[i] is not None:\n                assert(target[i].min() >= 0 and target[i].max() <= input[i].size(1))\n                criterion = self.criterions[i]\n                output += criterion(input[i], Variable(target[i]))\n        output /= batch_size\n        return output\n\n'"
fastai/courses/dl2/fastai/column_data.py,2,"b'from .imports import *\nfrom .torch_imports import *\nfrom .dataset import *\nfrom .learner import *\n\n\nclass PassthruDataset(Dataset):\n    def __init__(self,*args, is_reg=True, is_multi=False):\n        *xs,y=args\n        self.xs,self.y = xs,y\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n    def __getitem__(self, idx): return [o[idx] for o in self.xs] + [self.y[idx]]\n\n    @classmethod\n    def from_data_frame(cls, df, cols_x, col_y, is_reg=True, is_multi=False):\n        cols = [df[o] for o in cols_x+[col_y]]\n        return cls(*cols, is_reg=is_reg, is_multi=is_multi)\n\n\nclass ColumnarDataset(Dataset):\n    def __init__(self, cats, conts, y, is_reg, is_multi):\n        n = len(cats[0]) if cats else len(conts[0])\n        self.cats = np.stack(cats, 1).astype(np.int64) if cats else np.zeros((n,1))\n        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n        self.y = np.zeros((n,1)) if y is None else y\n        if is_reg:\n            self.y =  self.y[:,None]\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n\n    def __getitem__(self, idx):\n        return [self.cats[idx], self.conts[idx], self.y[idx]]\n\n    @classmethod\n    def from_data_frames(cls, df_cat, df_cont, y=None, is_reg=True, is_multi=False):\n        cat_cols = [c.values for n,c in df_cat.items()]\n        cont_cols = [c.values for n,c in df_cont.items()]\n        return cls(cat_cols, cont_cols, y, is_reg, is_multi)\n\n    @classmethod\n    def from_data_frame(cls, df, cat_flds, y=None, is_reg=True, is_multi=False):\n        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y, is_reg, is_multi)\n\n\nclass ColumnarModelData(ModelData):\n    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n            DataLoader(val_ds, bs*2, shuffle=False, num_workers=1), test_dl)\n\n    @classmethod\n    def from_arrays(cls, path, val_idxs, xs, y, is_reg=True, is_multi=False, bs=64, test_xs=None, shuffle=True):\n        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs), is_reg=is_reg, is_multi=is_multi) if test_xs is not None else None\n        return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n                   PassthruDataset(*(val_xs.T), val_y, is_reg=is_reg, is_multi=is_multi),\n                   bs=bs, shuffle=shuffle, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=None):\n        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, None, is_reg, is_multi) if test_df is not None else None\n        return cls(path, ColumnarDataset.from_data_frame(trn_df, cat_flds, trn_y, is_reg, is_multi),\n                    ColumnarDataset.from_data_frame(val_df, cat_flds, val_y, is_reg, is_multi), bs, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, is_reg=True, is_multi=False, test_df=None):\n        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=test_df)\n\n    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                    y_range=None, use_bn=False, **kwargs):\n        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn, self.is_reg, self.is_multi)\n        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n\n\ndef emb_init(x):\n    x = x.weight.data\n    sc = 2/(x.size(1)+1)\n    x.uniform_(-sc,sc)\n\n\nclass MixedInputModel(nn.Module):\n    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                 y_range=None, use_bn=False, is_reg=True, is_multi=False):\n        super().__init__()\n        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n        for emb in self.embs: emb_init(emb)\n        n_emb = sum(e.embedding_dim for e in self.embs)\n        self.n_emb, self.n_cont=n_emb, n_cont\n        \n        szs = [n_emb+n_cont] + szs\n        self.lins = nn.ModuleList([\n            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n        self.bns = nn.ModuleList([\n            nn.BatchNorm1d(sz) for sz in szs[1:]])\n        for o in self.lins: kaiming_normal(o.weight.data)\n        self.outp = nn.Linear(szs[-1], out_sz)\n        kaiming_normal(self.outp.weight.data)\n\n        self.emb_drop = nn.Dropout(emb_drop)\n        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n        self.bn = nn.BatchNorm1d(n_cont)\n        self.use_bn,self.y_range = use_bn,y_range\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def forward(self, x_cat, x_cont):\n        if self.n_emb != 0:\n            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n            x = torch.cat(x, 1)\n            x = self.emb_drop(x)\n        if self.n_cont != 0:\n            x2 = self.bn(x_cont)\n            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n        for l,d,b in zip(self.lins, self.drops, self.bns):\n            x = F.relu(l(x))\n            if self.use_bn: x = b(x)\n            x = d(x)\n        x = self.outp(x)\n        if not self.is_reg:\n            if self.is_multi:\n                x = F.sigmoid(x)\n            else:\n                x = F.log_softmax(x)\n        elif self.y_range:\n            x = F.sigmoid(x)\n            x = x*(self.y_range[1] - self.y_range[0])\n            x = x+self.y_range[0]\n        return x\n\n\nclass StructuredLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    def summary(self): return model_summary(self.model, [(self.data.trn_ds.cats.shape[1], ), (self.data.trn_ds.conts.shape[1], )])\n\n\nclass StructuredModel(BasicModel):\n    def get_layer_groups(self):\n        m=self.model\n        return [m.embs, children(m.lins)+children(m.bns), m.outp]\n\n\nclass CollabFilterDataset(Dataset):\n    def __init__(self, path, user_col, item_col, ratings):\n        self.ratings,self.path = ratings.values.astype(np.float32),path\n        self.n = len(ratings)\n        (self.users,self.user2idx,self.user_col,self.n_users) = self.proc_col(user_col)\n        (self.items,self.item2idx,self.item_col,self.n_items) = self.proc_col(item_col)\n        self.min_score,self.max_score = min(ratings),max(ratings)\n        self.cols = [self.user_col,self.item_col,self.ratings]\n\n    @classmethod\n    def from_data_frame(cls, path, df, user_name, item_name, rating_name):\n        return cls(path, df[user_name], df[item_name], df[rating_name])\n\n    @classmethod\n    def from_csv(cls, path, csv, user_name, item_name, rating_name):\n        df = pd.read_csv(os.path.join(path,csv))\n        return cls.from_data_frame(path, df, user_name, item_name, rating_name)\n\n    def proc_col(self,col):\n        uniq = col.unique()\n        name2idx = {o:i for i,o in enumerate(uniq)}\n        return (uniq, name2idx, np.array([name2idx[x] for x in col]), len(uniq))\n\n    def __len__(self): return self.n\n    def __getitem__(self, idx): return [o[idx] for o in self.cols]\n\n    def get_data(self, val_idxs, bs):\n        val, trn = zip(*split_by_idx(val_idxs, *self.cols))\n        return ColumnarModelData(self.path, PassthruDataset(*trn), PassthruDataset(*val), bs)\n\n    def get_model(self, n_factors):\n        model = EmbeddingDotBias(n_factors, self.n_users, self.n_items, self.min_score, self.max_score)\n        return CollabFilterModel(to_gpu(model))\n\n    def get_learner(self, n_factors, val_idxs, bs, **kwargs):\n        return CollabFilterLearner(self.get_data(val_idxs, bs), self.get_model(n_factors), **kwargs)\n\n\ndef get_emb(ni,nf):\n    e = nn.Embedding(ni, nf)\n    e.weight.data.uniform_(-0.05,0.05)\n    return e\n\n\nclass EmbeddingDotBias(nn.Module):\n    def __init__(self, n_factors, n_users, n_items, min_score, max_score):\n        super().__init__()\n        self.min_score,self.max_score = min_score,max_score\n        (self.u, self.i, self.ub, self.ib) = [get_emb(*o) for o in [\n            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n        ]]\n\n    def forward(self, users, items):\n        um = self.u(users)* self.i(items)\n        res = um.sum(1) + self.ub(users).squeeze() + self.ib(items).squeeze()\n        return F.sigmoid(res) * (self.max_score-self.min_score) + self.min_score\n\n\nclass CollabFilterLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n\nclass CollabFilterModel(BasicModel):\n    def get_layer_groups(self): return self.model\n\n'"
fastai/courses/dl2/fastai/conv_learner.py,0,"b'from .core import *\nfrom .layers import *\nfrom .learner import *\nfrom .initializers import *\n\nmodel_meta = {\n    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n    vgg16:[0,22], vgg19:[0,22],\n    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n}\nmodel_features = {inception_4: 3072, dn121: 2048, dn161: 4416,} # nasnetalarge: 4032*2}\n\nclass ConvnetBuilder():\n    """"""Class representing a convolutional network.\n\n    Arguments:\n        f: a model creation function (e.g. resnet34, vgg16, etc)\n        c (int): size of the last layer\n        is_multi (bool): is multilabel classification?\n            (def here http://scikit-learn.org/stable/modules/multiclass.html)\n        is_reg (bool): is a regression?\n        ps (float or array of float): dropout parameters\n        xtra_fc (list of ints): list of hidden layers with # hidden neurons\n        xtra_cut (int): # layers earlier than default to cut the model, default is 0\n        custom_head : add custom model classes that are inherited from nn.modules at the end of the model\n                      that is mentioned on Argument \'f\' \n    """"""\n\n    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, pretrained=True):\n        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n        if xtra_fc is None: xtra_fc = [512]\n        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n        self.ps,self.xtra_fc = ps,xtra_fc\n\n        if f in model_meta: cut,self.lr_cut = model_meta[f]\n        else: cut,self.lr_cut = 0,0\n        cut-=xtra_cut\n        layers = cut_model(f(pretrained), cut)\n        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n        self.top_model = nn.Sequential(*layers)\n\n        n_fc = len(self.xtra_fc)+1\n        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n\n        if custom_head: fc_layers = [custom_head]\n        else: fc_layers = self.get_fc_layers()\n        self.n_fc = len(fc_layers)\n        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n\n    @property\n    def name(self): return f\'{self.f.__name__}_{self.xtra_cut}\'\n\n    def create_fc_layer(self, ni, nf, p, actn=None):\n        res=[nn.BatchNorm1d(num_features=ni)]\n        if p: res.append(nn.Dropout(p=p))\n        res.append(nn.Linear(in_features=ni, out_features=nf))\n        if actn: res.append(actn)\n        return res\n\n    def get_fc_layers(self):\n        res=[]\n        ni=self.nf\n        for i,nf in enumerate(self.xtra_fc):\n            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n            ni=nf\n        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n        if self.is_reg: final_actn = None\n        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n        return res\n\n    def get_layer_groups(self, do_fc=False):\n        if do_fc:\n            return [self.fc_model]\n        idxs = [self.lr_cut]\n        c = children(self.top_model)\n        if len(c)==3: c = children(c[0])+c[1:]\n        lgs = list(split_by_idxs(c,idxs))\n        return lgs+[self.fc_model]\n\n\nclass ConvLearner(Learner):\n    """"""\n    Class used to train a chosen supported covnet model. Eg. ResNet-34, etc.\n    Arguments:\n        data: training data for model\n        models: model architectures to base learner\n        precompute: bool to reuse precomputed activations\n        **kwargs: parameters from Learner() class\n    """"""\n    def __init__(self, data, models, precompute=False, **kwargs):\n        self.precompute = False\n        super().__init__(data, models, **kwargs)\n        if hasattr(data, \'is_multi\') and not data.is_reg and self.metrics is None:\n            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n        if precompute: self.save_fc1()\n        self.freeze()\n        self.precompute = precompute\n\n    def _get_crit(self, data):\n        if not hasattr(data, \'is_multi\'): return super()._get_crit(data)\n\n        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    @classmethod\n    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                   pretrained=True, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n        return cls(data, models, precompute, **kwargs)\n\n    @classmethod\n    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n        convlearn=cls(data, models, precompute, **kwargs)\n        convlearn.lsuv_init()\n        return convlearn\n    \n    @property\n    def model(self): return self.models.fc_model if self.precompute else self.models.model\n\n    @property\n    def data(self): return self.fc_data if self.precompute else self.data_\n\n    def create_empty_bcolz(self, n, name):\n        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode=\'w\', rootdir=name)\n\n    def set_data(self, data, precompute=False):\n        super().set_data(data)\n        if precompute:\n            self.unfreeze()\n            self.save_fc1()\n            self.freeze()\n            self.precompute = True\n        else:\n            self.freeze()\n\n    def get_layer_groups(self):\n        return self.models.get_layer_groups(self.precompute)\n\n    def summary(self):\n        precompute = self.precompute\n        self.precompute = False\n        res = super().summary()\n        self.precompute = precompute\n        return res\n\n    def get_activations(self, force=False):\n        tmpl = f\'_{self.models.name}_{self.data.sz}.bc\'\n        # TODO: Somehow check that directory names haven\'t changed (e.g. added test set)\n        names = [os.path.join(self.tmp_path, p+tmpl) for p in (\'x_act\', \'x_act_val\', \'x_act_test\')]\n        if os.path.exists(names[0]) and not force:\n            self.activations = [bcolz.open(p) for p in names]\n        else:\n            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n\n    def save_fc1(self):\n        self.get_activations()\n        act, val_act, test_act = self.activations\n        m=self.models.top_model\n        if len(self.activations[0])!=len(self.data.trn_ds):\n            predict_to_bcolz(m, self.data.fix_dl, act)\n        if len(self.activations[1])!=len(self.data.val_ds):\n            predict_to_bcolz(m, self.data.val_dl, val_act)\n        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n\n        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n                test = test_act if self.data.test_dl else None, num_workers=8)\n\n    def freeze(self):\n        """""" Freeze all but the very last layer.\n\n        Make all layers untrainable (i.e. frozen) except for the last layer.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(-1)\n\n    def unfreeze(self):\n        """""" Unfreeze all layers.\n\n        Make all layers trainable by unfreezing. This will also set the `precompute` to `False` since we can\n        no longer pre-calculate the activation of frozen layers.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(0)\n        self.precompute = False\n'"
fastai/courses/dl2/fastai/core.py,11,"b'from .imports import *\nfrom .torch_imports import *\n\ndef sum_geom(a,r,n): return a*n if r==1 else math.ceil(a*(1-r**n)/(1-r))\n\ndef is_listy(x): return isinstance(x, (list,tuple))\ndef is_iter(x): return isinstance(x, collections.Iterable)\ndef map_over(x, f): return [f(o) for o in x] if is_listy(x) else f(x)\ndef map_none(x, f): return None if x is None else f(x)\n\nconv_dict = {np.dtype(\'int8\'): torch.LongTensor, np.dtype(\'int16\'): torch.LongTensor,\n    np.dtype(\'int32\'): torch.LongTensor, np.dtype(\'int64\'): torch.LongTensor,\n    np.dtype(\'float32\'): torch.FloatTensor, np.dtype(\'float64\'): torch.FloatTensor}\n\ndef A(*a):\n    """"""convert iterable object into numpy array""""""\n    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]\n\ndef T(a, half=False, cuda=True):\n    """"""\n    Convert numpy array into a pytorch tensor. \n    if Cuda is available and USE_GPU=ture, store resulting tensor in GPU.\n    """"""\n    if not torch.is_tensor(a):\n        a = np.array(np.ascontiguousarray(a))\n        if a.dtype in (np.int8, np.int16, np.int32, np.int64):\n            a = torch.LongTensor(a.astype(np.int64))\n        elif a.dtype in (np.float32, np.float64):\n            a = torch.cuda.HalfTensor(a) if half else torch.FloatTensor(a)\n        else: raise NotImplementedError(a.dtype)\n    if cuda: a = to_gpu(a, async=True)\n    return a\n\ndef create_variable(x, volatile, requires_grad=False):\n    if type (x) != Variable:\n        if IS_TORCH_04: x = Variable(T(x), requires_grad=requires_grad)\n        else:           x = Variable(T(x), requires_grad=requires_grad, volatile=volatile)\n    return x\n\ndef V_(x, requires_grad=False, volatile=False):\n    \'\'\'equivalent to create_variable, which creates a pytorch tensor\'\'\'\n    return create_variable(x, volatile=volatile, requires_grad=requires_grad)\ndef V(x, requires_grad=False, volatile=False):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, lambda o: V_(o, requires_grad, volatile))\n\ndef VV_(x): \n    \'\'\'creates a volatile tensor, which does not require gradients. \'\'\'\n    return create_variable(x, True)\n\ndef VV(x):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, VV_)\n\ndef to_np(v):\n    \'\'\'returns an np.array object given an input of np.array, list, tuple, torch variable or tensor.\'\'\'\n    if isinstance(v, (np.ndarray, np.generic)): return v\n    if isinstance(v, (list,tuple)): return [to_np(o) for o in v]\n    if isinstance(v, Variable): v=v.data\n    if isinstance(v, torch.cuda.HalfTensor): v=v.float()\n    return v.cpu().numpy()\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\nUSE_GPU = torch.cuda.is_available()\ndef to_gpu(x, *args, **kwargs):\n    \'\'\'puts pytorch variable to gpu, if cuda is avaialble and USE_GPU is set to true. \'\'\'\n    return x.cuda(*args, **kwargs) if USE_GPU else x\n\ndef noop(*args, **kwargs): return\n\ndef split_by_idxs(seq, idxs):\n    \'\'\'A generator that returns sequence pieces, seperated by indexes specified in idxs. \'\'\'\n    last = 0\n    for idx in idxs:\n        yield seq[last:idx]\n        last = idx\n    yield seq[last:]\n\ndef trainable_params_(m):\n    \'\'\'Returns a list of trainable parameters in the model m. (i.e., those that require gradients.)\'\'\'\n    return [p for p in m.parameters() if p.requires_grad]\n\ndef chain_params(p):\n    if is_listy(p):\n        return list(chain(*[trainable_params_(o) for o in p]))\n    return trainable_params_(p)\n\ndef set_trainable_attr(m,b):\n    m.trainable=b\n    for p in m.parameters(): p.requires_grad=b\n\ndef apply_leaf(m, f):\n    c = children(m)\n    if isinstance(m, nn.Module): f(m)\n    if len(c)>0:\n        for l in c: apply_leaf(l,f)\n\ndef set_trainable(l, b):\n    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n\ndef SGD_Momentum(momentum):\n    return lambda *args, **kwargs: optim.SGD(*args, momentum=momentum, **kwargs)\n\ndef one_hot(a,c): return np.eye(c)[a]\n\ndef partition(a, sz): \n    """"""splits iterables a in equal parts of size sz""""""\n    return [a[i:i+sz] for i in range(0, len(a), sz)]\n\ndef partition_by_cores(a):\n    return partition(a, len(a)//num_cpus() + 1)\n\ndef num_cpus():\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n\n\nclass BasicModel():\n    def __init__(self,model,name=\'unnamed\'): self.model,self.name = model,name\n    def get_layer_groups(self, do_fc=False): return children(self.model)\n\nclass SingleModel(BasicModel):\n    def get_layer_groups(self): return [self.model]\n\nclass SimpleNet(nn.Module):\n    def __init__(self, layers):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return F.log_softmax(l_x, dim=-1)\n\n\ndef save(fn, a): \n    """"""Utility function that savess model, function, etc as pickle""""""    \n    pickle.dump(a, open(fn,\'wb\'))\ndef load(fn): \n    """"""Utility function that loads model, function, etc as pickle""""""\n    return pickle.load(open(fn,\'rb\'))\ndef load2(fn):\n    """"""Utility funciton allowing model piclking across Python2 and Python3""""""\n    return pickle.load(open(fn,\'rb\'), encoding=\'iso-8859-1\')\n\ndef load_array(fname): \n    \'\'\'\n    Load array using bcolz, which is based on numpy, for fast array saving and loading operations. \n    https://github.com/Blosc/bcolz\n    \'\'\'\n    return bcolz.open(fname)[:]\n\n\ndef chunk_iter(iterable, chunk_size):\n    \'\'\'A generator that yields chunks of iterable, chunk_size at a time. \'\'\'\n    while True:\n        chunk = []\n        try:\n            for _ in range(chunk_size): chunk.append(next(iterable))\n            yield chunk\n        except StopIteration:\n            if chunk: yield chunk\n            break\n\ndef set_grad_enabled(mode): return torch.set_grad_enabled(mode) if IS_TORCH_04 else contextlib.suppress()\n\ndef no_grad_context(): return torch.no_grad() if IS_TORCH_04 else contextlib.suppress()\n'"
fastai/courses/dl2/fastai/dataloader.py,1,"b'import torch, queue\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler\nfrom .imports import *\nfrom .core import *\nimport collections,sys,traceback,threading\n\nstring_classes = (str, bytes)\n\n\ndef get_tensor(batch, pin, half=False):\n    if isinstance(batch, (np.ndarray, np.generic)):\n        batch = T(batch, half=half, cuda=False).contiguous()\n        if pin: batch = batch.pin_memory()\n        return to_gpu(batch)\n    elif isinstance(batch, string_classes):\n        return batch\n    elif isinstance(batch, collections.Mapping):\n        return {k: get_tensor(sample, pin, half) for k, sample in batch.items()}\n    elif isinstance(batch, collections.Sequence):\n        return [get_tensor(sample, pin, half) for sample in batch]\n    raise TypeError(f""batch must contain numbers, dicts or lists; found {type(batch)}"")\n\n\nclass DataLoader(object):\n    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, pad_idx=0,\n                 num_workers=None, pin_memory=False, drop_last=False, pre_pad=True, half=False,\n                 transpose=False, transpose_y=False):\n        self.dataset,self.batch_size,self.num_workers = dataset,batch_size,num_workers\n        self.pin_memory,self.drop_last,self.pre_pad = pin_memory,drop_last,pre_pad\n        self.transpose,self.transpose_y,self.pad_idx,self.half = transpose,transpose_y,pad_idx,half\n\n        if batch_sampler is not None:\n            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n                raise ValueError(\'batch_sampler is mutually exclusive with \'\n                                 \'batch_size, shuffle, sampler, and drop_last\')\n\n        if sampler is not None and shuffle:\n            raise ValueError(\'sampler is mutually exclusive with shuffle\')\n\n        if batch_sampler is None:\n            if sampler is None:\n                sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n\n        if num_workers is None:\n            self.num_workers = num_cpus()\n\n        self.sampler = sampler\n        self.batch_sampler = batch_sampler\n\n    def __len__(self): return len(self.batch_sampler)\n\n    def jag_stack(self, b):\n        if len(b[0].shape) not in (1,2): return np.stack(b)\n        ml = max(len(o) for o in b)\n        if min(len(o) for o in b)==ml: return np.stack(b)\n        res = np.zeros((len(b), ml), dtype=b[0].dtype) + self.pad_idx\n        for i,o in enumerate(b):\n            if self.pre_pad: res[i, -len(o):] = o\n            else:            res[i,  :len(o)] = o\n        return res\n\n    def np_collate(self, batch):\n        b = batch[0]\n        if isinstance(b, (np.ndarray, np.generic)): return self.jag_stack(batch)\n        elif isinstance(b, (int, float)): return np.array(batch)\n        elif isinstance(b, string_classes): return batch\n        elif isinstance(b, collections.Mapping):\n            return {key: self.np_collate([d[key] for d in batch]) for key in b}\n        elif isinstance(b, collections.Sequence):\n            return [self.np_collate(samples) for samples in zip(*batch)]\n        raise TypeError((""batch must contain numbers, dicts or lists; found {}"".format(type(b))))\n\n    def get_batch(self, indices):\n        res = self.np_collate([self.dataset[i] for i in indices])\n        if self.transpose:   res[0] = res[0].T\n        if self.transpose_y: res[1] = res[1].T\n        return res\n\n    def __iter__(self):\n        if self.num_workers==0:\n            for batch in map(self.get_batch, iter(self.batch_sampler)):\n                yield get_tensor(batch, self.pin_memory, self.half)\n        else:\n            with ThreadPoolExecutor(max_workers=self.num_workers) as e:\n                # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n                for c in chunk_iter(iter(self.batch_sampler), self.num_workers*10):\n                    for batch in e.map(self.get_batch, c):\n                        yield get_tensor(batch, self.pin_memory, self.half)\n\n'"
fastai/courses/dl2/fastai/dataset.py,1,"b'import csv\n\nfrom .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .layer_optimizer import *\nfrom .dataloader import DataLoader\n\ndef get_cv_idxs(n, cv_idx=0, val_pct=0.2, seed=42):\n    """""" Get a list of index values for Validation set from a dataset\n    \n    Arguments:\n        n : int, Total number of elements in the data set.\n        cv_idx : int, starting index [idx_start = cv_idx*int(val_pct*n)] \n        val_pct : (int, float), validation set percentage \n        seed : seed value for RandomState\n        \n    Returns:\n        list of indexes \n    """"""\n    np.random.seed(seed)\n    n_val = int(val_pct*n)\n    idx_start = cv_idx*n_val\n    idxs = np.random.permutation(n)\n    return idxs[idx_start:idx_start+n_val]\n\ndef resize_img(fname, targ, path, new_path):\n    """"""\n    Enlarge or shrink a single image to scale, such that the smaller of the height or width dimension is equal to targ.\n    """"""\n    dest = os.path.join(path,new_path,str(targ),fname)\n    if os.path.exists(dest): return\n    im = Image.open(os.path.join(path, fname)).convert(\'RGB\')\n    r,c = im.size\n    ratio = targ/min(r,c)\n    sz = (scale_to(r, ratio, targ), scale_to(c, ratio, targ))\n    os.makedirs(os.path.split(dest)[0], exist_ok=True)\n    im.resize(sz, Image.LINEAR).save(dest)\n\ndef resize_imgs(fnames, targ, path, new_path):\n    """"""\n    Enlarge or shrink a set of images in the same directory to scale, such that the smaller of the height or width dimension is equal to targ.\n    Note: \n    -- This function is multithreaded for efficiency. \n    -- When destination file or folder already exist, function exists without raising an error. \n    """"""\n    if not os.path.exists(os.path.join(path,new_path,str(targ),fnames[0])):\n        with ThreadPoolExecutor(8) as e:\n            ims = e.map(lambda x: resize_img(x, targ, path, new_path), fnames)\n            for x in tqdm(ims, total=len(fnames), leave=False): pass\n    return os.path.join(path,new_path,str(targ))\n\ndef read_dir(path, folder):\n    """""" Returns a list of relative file paths to `path` for all files within `folder` """"""\n    full_path = os.path.join(path, folder)\n    fnames = glob(f""{full_path}/*.*"")\n    if any(fnames):\n        return [os.path.relpath(f,path) for f in fnames]\n    else:\n        raise FileNotFoundError(""{} folder doesn\'t exist or is empty"".format(folder))\n\ndef read_dirs(path, folder):\n    \'\'\'\n    Fetches name of all files in path in long form, and labels associated by extrapolation of directory names. \n    \'\'\'\n    lbls, fnames, all_lbls = [], [], []\n    full_path = os.path.join(path, folder)\n    for lbl in sorted(os.listdir(full_path)):\n        if lbl not in (\'.ipynb_checkpoints\',\'.DS_Store\'):\n            all_lbls.append(lbl)\n            for fname in os.listdir(os.path.join(full_path, lbl)):\n                fnames.append(os.path.join(folder, lbl, fname))\n                lbls.append(lbl)\n    return fnames, lbls, all_lbls\n\ndef n_hot(ids, c):\n    \'\'\'\n    one hot encoding by index. Returns array of length c, where all entries are 0, except for the indecies in ids\n    \'\'\'\n    res = np.zeros((c,), dtype=np.float32)\n    res[ids] = 1\n    return res\n\ndef folder_source(path, folder):\n    """"""\n    Returns the filenames and labels for a folder within a path\n    \n    Returns:\n    -------\n    fnames: a list of the filenames within `folder`\n    all_lbls: a list of all of the labels in `folder`, where the # of labels is determined by the # of directories within `folder`\n    lbl_arr: a numpy array of the label indices in `all_lbls`\n    """"""\n    fnames, lbls, all_lbls = read_dirs(path, folder)\n    lbl2idx = {lbl:idx for idx,lbl in enumerate(all_lbls)}\n    idxs = [lbl2idx[lbl] for lbl in lbls]\n    lbl_arr = np.array(idxs, dtype=int)\n    return fnames, lbl_arr, all_lbls\n\ndef parse_csv_labels(fn, skip_header=True, cat_separator = \' \'):\n    """"""Parse filenames and label sets from a CSV file.\n\n    This method expects that the csv file at path :fn: has two columns. If it\n    has a header, :skip_header: should be set to True. The labels in the\n    label set are expected to be space separated.\n\n    Arguments:\n        fn: Path to a CSV file.\n        skip_header: A boolean flag indicating whether to skip the header.\n\n    Returns:\n        a four-tuple of (\n            sorted image filenames,\n            a dictionary of filenames and corresponding labels,\n            a sorted set of unique labels,\n            a dictionary of labels to their corresponding index, which will\n            be one-hot encoded.\n        )\n    .\n    :param cat_separator: the separator for the categories column\n    """"""\n    df = pd.read_csv(fn, index_col=0, header=0 if skip_header else None, dtype=str)\n    fnames = df.index.values\n    df.iloc[:,0] = df.iloc[:,0].str.split(cat_separator)\n    return sorted(fnames), list(df.to_dict().values())[0]\n\ndef nhot_labels(label2idx, csv_labels, fnames, c):\n    \n    all_idx = {k: n_hot([label2idx[o] for o in v], c)\n               for k,v in csv_labels.items()}\n    return np.stack([all_idx[o] for o in fnames])\n\ndef csv_source(folder, csv_file, skip_header=True, suffix=\'\', continuous=False):\n    fnames,csv_labels = parse_csv_labels(csv_file, skip_header)\n    return dict_source(folder, fnames, csv_labels, suffix, continuous)\n\ndef dict_source(folder, fnames, csv_labels, suffix=\'\', continuous=False):\n    all_labels = sorted(list(set(p for o in csv_labels.values() for p in o)))\n    full_names = [os.path.join(folder,str(fn)+suffix) for fn in fnames]\n    if continuous:\n        label_arr = np.array([np.array(csv_labels[i]).astype(np.float32)\n                for i in fnames])\n    else:\n        label2idx = {v:k for k,v in enumerate(all_labels)}\n        label_arr = nhot_labels(label2idx, csv_labels, fnames, len(all_labels))\n        is_single = np.all(label_arr.sum(axis=1)==1)\n        if is_single: label_arr = np.argmax(label_arr, axis=1)\n    return full_names, label_arr, all_labels\n\nclass BaseDataset(Dataset):\n    """"""An abstract class representing a fastai dataset, it extends torch.utils.data.Dataset.""""""\n    def __init__(self, transform=None):\n        self.transform = transform\n        self.n = self.get_n()\n        self.c = self.get_c()\n        self.sz = self.get_sz()\n\n    def get1item(self, idx):\n        x,y = self.get_x(idx),self.get_y(idx)\n        return self.get(self.transform, x, y)\n\n    def __getitem__(self, idx):\n        if isinstance(idx,slice):\n            xs,ys = zip(*[self.get1item(i) for i in range(*idx.indices(self.n))])\n            return np.stack(xs),ys\n        return self.get1item(idx)\n\n    def __len__(self): return self.n\n\n    def get(self, tfm, x, y):\n        return (x,y) if tfm is None else tfm(x,y)\n\n    @abstractmethod\n    def get_n(self):\n        """"""Return number of elements in the dataset == len(self).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_c(self):\n        """"""Return number of classes in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_sz(self):\n        """"""Return maximum size of an image in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_x(self, i):\n        """"""Return i-th example (image, wav, etc).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_y(self, i):\n        """"""Return i-th label.""""""\n        raise NotImplementedError\n\n    @property\n    def is_multi(self):\n        """"""Returns true if this data set contains multiple labels per sample.""""""\n        return False\n\n    @property\n    def is_reg(self):\n        """"""True if the data set is used to train regression models.""""""\n        return False\n\ndef open_image(fn):\n    """""" Opens an image using OpenCV given the file path.\n\n    Arguments:\n        fn: the file path of the image\n\n    Returns:\n        The image in RGB format as numpy array of floats normalized to range between 0.0 - 1.0\n    """"""\n    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n    if not os.path.exists(fn):\n        raise OSError(\'No such file or directory: {}\'.format(fn))\n    elif os.path.isdir(fn):\n        raise OSError(\'Is a directory: {}\'.format(fn))\n    else:\n        #res = np.array(Image.open(fn), dtype=np.float32)/255\n        #if len(res.shape)==2: res = np.repeat(res[...,None],3,2)\n        #return res\n        try:\n            im = cv2.imread(str(fn), flags).astype(np.float32)/255\n            if im is None: raise OSError(f\'File not recognized by opencv: {fn}\')\n            return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        except Exception as e:\n            raise OSError(\'Error handling image at: {}\'.format(fn)) from e\n\nclass FilesDataset(BaseDataset):\n    def __init__(self, fnames, transform, path):\n        self.path,self.fnames = path,fnames\n        super().__init__(transform)\n    def get_sz(self): return self.transform.sz\n    def get_x(self, i): return open_image(os.path.join(self.path, self.fnames[i]))\n    def get_n(self): return len(self.fnames)\n\n    def resize_imgs(self, targ, new_path):\n        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n        return self.__class__(self.fnames, self.y, self.transform, dest)\n\n    def denorm(self,arr):\n        """"""Reverse the normalization done to a batch of images.\n\n        Arguments:\n            arr: of shape/size (N,3,sz,sz)\n        """"""\n        if type(arr) is not np.ndarray: arr = to_np(arr)\n        if len(arr.shape)==3: arr = arr[None]\n        return self.transform.denorm(np.rollaxis(arr,1,4))\n\n\nclass FilesArrayDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    def get_y(self, i): return self.y[i]\n    def get_c(self):\n        return self.y.shape[1] if len(self.y.shape)>1 else 0\n\nclass FilesIndexArrayDataset(FilesArrayDataset):\n    def get_c(self): return int(self.y.max())+1\n\n\nclass FilesNhotArrayDataset(FilesArrayDataset):\n    @property\n    def is_multi(self): return True\n\n\nclass FilesIndexArrayRegressionDataset(FilesArrayDataset):\n    def is_reg(self): return True\n\nclass ArraysDataset(BaseDataset):\n    def __init__(self, x, y, transform):\n        self.x,self.y=x,y\n        assert(len(x)==len(y))\n        super().__init__(transform)\n    def get_x(self, i): return self.x[i]\n    def get_y(self, i): return self.y[i]\n    def get_n(self): return len(self.y)\n    def get_sz(self): return self.x.shape[1]\n\n\nclass ArraysIndexDataset(ArraysDataset):\n    def get_c(self): return int(self.y.max())+1\n    def get_y(self, i): return self.y[i]\n\n\nclass ArraysNhotDataset(ArraysDataset):\n    def get_c(self): return self.y.shape[1]\n    @property\n    def is_multi(self): return True\n\n\nclass ModelData():\n    def __init__(self, path, trn_dl, val_dl, test_dl=None):\n        self.path,self.trn_dl,self.val_dl,self.test_dl = path,trn_dl,val_dl,test_dl\n\n    @classmethod\n    def from_dls(cls, path,trn_dl,val_dl,test_dl=None):\n        #trn_dl,val_dl = DataLoader(trn_dl),DataLoader(val_dl)\n        #if test_dl: test_dl = DataLoader(test_dl)\n        return cls(path, trn_dl, val_dl, test_dl)\n\n    @property\n    def is_reg(self): return self.trn_ds.is_reg\n    @property\n    def is_multi(self): return self.trn_ds.is_multi\n    @property\n    def trn_ds(self): return self.trn_dl.dataset\n    @property\n    def val_ds(self): return self.val_dl.dataset\n    @property\n    def test_ds(self): return self.test_dl.dataset\n    @property\n    def trn_y(self): return self.trn_ds.y\n    @property\n    def val_y(self): return self.val_ds.y\n\n\nclass ImageData(ModelData):\n    def __init__(self, path, datasets, bs, num_workers, classes):\n        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n            self.get_dl(ds,shuf) for ds,shuf in [\n                (trn_ds,True),(val_ds,False),(fix_ds,False),(aug_ds,False),\n                (test_ds,False),(test_aug_ds,False)\n            ]\n        ]\n\n    def get_dl(self, ds, shuffle):\n        if ds is None: return None\n        return DataLoader(ds, batch_size=self.bs, shuffle=shuffle,\n            num_workers=self.num_workers, pin_memory=False)\n\n    @property\n    def sz(self): return self.trn_ds.sz\n    @property\n    def c(self): return self.trn_ds.c\n\n    def resized(self, dl, targ, new_path):\n        return dl.dataset.resize_imgs(targ,new_path) if dl else None\n\n    def resize(self, targ_sz, new_path=\'tmp\'):\n        new_ds = []\n        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n        else: dls += [None,None]\n        t = tqdm_notebook(dls)\n        for dl in t: new_ds.append(self.resized(dl, targ_sz, new_path))\n        t.close()\n        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)\n\n    @staticmethod\n    def get_ds(fn, trn, val, tfms, test=None, **kwargs):\n        res = [\n            fn(trn[0], trn[1], tfms[0], **kwargs), # train\n            fn(val[0], val[1], tfms[1], **kwargs), # val\n            fn(trn[0], trn[1], tfms[1], **kwargs), # fix\n            fn(val[0], val[1], tfms[0], **kwargs)  # aug\n        ]\n        if test is not None:\n            if isinstance(test, tuple):\n                test_lbls = test[1]\n                test = test[0]\n            else:\n                test_lbls = np.zeros((len(test),1))\n            res += [\n                fn(test, test_lbls, tfms[1], **kwargs), # test\n                fn(test, test_lbls, tfms[0], **kwargs)  # test_aug\n            ]\n        else: res += [None,None]\n        return res\n\n\nclass ImageClassifierData(ImageData):\n    @classmethod\n    def from_arrays(cls, path, trn, val, bs=64, tfms=(None,None), classes=None, num_workers=4, test=None):\n        """""" Read in images and their labels given as numpy arrays\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            trn: a tuple of training data matrix and target label/classification array (e.g. `trn=(x,y)` where `x` has the\n                shape of `(5000, 784)` and `y` has the shape of `(5000,)`)\n            val: a tuple of validation data matrix and target label/classification array.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            classes: a list of all labels/classifications\n            num_workers: a number of workers\n            test: a matrix of test data (the shape should match `trn[0]`)\n\n        Returns:\n            ImageClassifierData\n        """"""\n        datasets = cls.get_ds(ArraysIndexDataset, trn, val, tfms, test=test)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\n    @classmethod\n    def from_paths(cls, path, bs=64, tfms=(None,None), trn_name=\'train\', val_name=\'valid\', test_name=None, test_with_labels=False, num_workers=8):\n        """""" Read in images and their labels given as sub-folder names\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            trn_name: a name of the folder that contains training images.\n            val_name:  a name of the folder that contains validation images.\n            test_name:  a name of the folder that contains test images.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not(tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        trn,val = [folder_source(path, o) for o in (trn_name, val_name)]\n        if test_name:\n            test = folder_source(path, test_name) if test_with_labels else read_dir(path, test_name)\n        else: test = None\n        datasets = cls.get_ds(FilesIndexArrayDataset, trn, val, tfms, path=path, test=test)\n        return cls(path, datasets, bs, num_workers, classes=trn[2])\n\n    @classmethod\n    def from_csv(cls, path, folder, csv_fname, bs=64, tfms=(None,None),\n               val_idxs=None, suffix=\'\', test_name=None, continuous=False, skip_header=True, num_workers=8):\n        """""" Read in images and their labels given as a CSV file.\n\n        This method should be used when training image labels are given in an CSV file as opposed to\n        sub-directories with label names.\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            folder: a name of the folder in which training images are contained.\n            csv_fname: a name of the CSV file which contains target labels.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            val_idxs: index of images to be used for validation. e.g. output of `get_cv_idxs`.\n                If None, default arguments to get_cv_idxs are used.\n            suffix: suffix to add to image names in CSV file (sometimes CSV only contains the file name without file\n                    extension e.g. \'.jpg\' - in which case, you can set suffix as \'.jpg\')\n            test_name: a name of the folder which contains test images.\n            continuous: TODO\n            skip_header: skip the first row of the CSV file.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not (tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        assert not (os.path.isabs(folder)), ""folder needs to be a relative path""\n        fnames,y,classes = csv_source(folder, csv_fname, skip_header, suffix, continuous=continuous)\n        return cls.from_names_and_array(path, fnames, y, classes, val_idxs, test_name,\n                num_workers=num_workers, suffix=suffix, tfms=tfms, bs=bs, continuous=continuous)\n\n    @classmethod\n    def from_names_and_array(cls, path, fnames,y,classes, val_idxs=None, test_name=None,\n            num_workers=8, suffix=\'\', tfms=(None,None), bs=64, continuous=False):\n        val_idxs = get_cv_idxs(len(fnames)) if val_idxs is None else val_idxs\n        ((val_fnames,trn_fnames),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), y)\n\n        test_fnames = read_dir(path, test_name) if test_name else None\n        if continuous: f = FilesIndexArrayRegressionDataset\n        else:\n            f = FilesIndexArrayDataset if len(trn_y.shape)==1 else FilesNhotArrayDataset\n        datasets = cls.get_ds(f, (trn_fnames,trn_y), (val_fnames,val_y), tfms,\n                               path=path, test=test_fnames)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\ndef split_by_idx(idxs, *a):\n    """"""\n    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n    This can be used to split multiple arrays containing training data to validation and training set.\n\n    :param idxs [int]: list of indexes selected\n    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n    :return: list of tuples, each containing a split of corresponding array from *a.\n            First element of each tuple is an array composed from elements selected by idxs,\n            second element is an array of remaining elements.\n    """"""\n    mask = np.zeros(len(a[0]),dtype=bool)\n    mask[np.array(idxs)] = True\n    return [(o[mask],o[~mask]) for o in a]\n\n'"
fastai/courses/dl2/fastai/executors.py,0,"b'import collections\nimport itertools\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\nclass LazyThreadPoolExecutor(ThreadPoolExecutor):\n    def map(self, fn, *iterables, timeout=None, chunksize=1, prefetch=None):\n        """"""\n        Collects iterables lazily, rather than immediately.\n        Docstring same as parent: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor\n        Implmentation taken from this PR: https://github.com/python/cpython/pull/707\n        """"""\n        if timeout is not None: end_time = timeout + time.time()\n        if prefetch is None: prefetch = self._max_workers\n        if prefetch < 0: raise ValueError(""prefetch count may not be negative"")\n        argsiter = zip(*iterables)\n        fs = collections.deque(self.submit(fn, *args) for args in itertools.islice(argsiter, self._max_workers+prefetch))\n        # Yield must be hidden in closure so that the futures are submitted before the first iterator value is required.\n        def result_iterator():\n            nonlocal argsiter\n            try:\n                while fs:\n                    res = fs[0].result() if timeout is None else fs[0].result(end_time-time.time())\n                    # Got a result, future needn\'t be cancelled\n                    del fs[0]\n                    # Dispatch next task before yielding to keep pipeline full\n                    if argsiter:\n                        try:\n                            args = next(argsiter)\n                        except StopIteration:\n                            argsiter = None\n                        else:\n                            fs.append(self.submit(fn, *args))\n                    yield res\n            finally:\n                for future in fs: future.cancel()\n        return result_iterator()'"
fastai/courses/dl2/fastai/fp16.py,2,"b'import torch\nimport torch.nn as nn\n\n\nclass FP16(nn.Module):\n    def __init__(self, module): \n        super(FP16, self).__init__()\n        self.module = batchnorm_to_fp32(module.half())\n        \n    def forward(self, input): \n        return self.module(input.half())\n    \n    def load_state_dict(self, *inputs, **kwargs):\n        self.module.load_state_dict(*inputs, **kwargs)\n\n    def state_dict(self, *inputs, **kwargs):\n        return self.module.state_dict(*inputs, **kwargs)\n\ndef batchnorm_to_fp32(module):\n    \'\'\'\n    BatchNorm layers to have parameters in single precision.\n    Find all layers and convert them back to float. This can\'t\n    be done with built in .apply as that function will apply\n    fn to all modules, parameters, and buffers. Thus we wouldn\'t\n    be able to guard the float conversion based on the module type.\n    \'\'\'\n    if isinstance(module, nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        batchnorm_to_fp32(child)\n    return module\n\ndef copy_model_to_fp32(m, optim):\n    """"""  Creates a fp32 copy of model parameters and sets optimizer parameters\n    """"""\n    fp32_params = [m_param.clone().type(torch.cuda.FloatTensor).detach() for m_param in m.parameters()]\n    optim_groups = [group[\'params\'] for group in optim.param_groups]\n    iter_fp32_params = iter(fp32_params)\n    for group_params in optim_groups:\n        for i in range(len(group_params)):\n            fp32_param = next(iter_fp32_params)\n            fp32_param.requires_grad = group_params[i].requires_grad\n            group_params[i] = fp32_param\n    return fp32_params\n\ndef copy_fp32_to_model(m, fp32_params):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        m_param.data.copy_(fp32_param.data)\n\ndef update_fp32_grads(fp32_params, m):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        if fp32_param.grad is None:\n            fp32_param.grad = nn.Parameter(fp32_param.data.new().resize_(*fp32_param.data.size()))\n        fp32_param.grad.data.copy_(m_param.grad.data)\n\n'"
fastai/courses/dl2/fastai/imports.py,0,"b""from IPython.lib.deepreload import reload as dreload\nimport PIL, os, numpy as np, math, collections, threading, json, bcolz, random, scipy, cv2\nimport pandas as pd, pickle, sys, itertools, string, sys, re, datetime, time, shutil, copy\nimport seaborn as sns, matplotlib\nimport IPython, graphviz, sklearn_pandas, sklearn, warnings, pdb\nimport contextlib\nfrom abc import abstractmethod\nfrom glob import glob, iglob\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom itertools import chain\nfrom functools import partial\nfrom collections import Iterable, Counter, OrderedDict\nfrom isoweek import Week\nfrom pandas_summary import DataFrameSummary\nfrom IPython.lib.display import FileLink\nfrom PIL import Image, ImageEnhance, ImageOps\nfrom sklearn import metrics, ensemble, preprocessing\nfrom operator import itemgetter, attrgetter\nfrom pathlib import Path\nfrom distutils.version import LooseVersion\n\nfrom matplotlib import pyplot as plt, rcParams, animation\nfrom ipywidgets import interact, interactive, fixed, widgets\nmatplotlib.rc('animation', html='html5')\nnp.set_printoptions(precision=5, linewidth=110, suppress=True)\n\nfrom ipykernel.kernelapp import IPKernelApp\ndef in_notebook(): return IPKernelApp.initialized()\n\ndef in_ipynb():\n    try:\n        cls = get_ipython().__class__.__name__\n        return cls == 'ZMQInteractiveShell'\n    except NameError:\n        return False\n\nimport tqdm as tq\nfrom tqdm import tqdm_notebook, tnrange\n\ndef clear_tqdm():\n    inst = getattr(tq.tqdm, '_instances', None)\n    if not inst: return\n    try:\n        for i in range(len(inst)): inst.pop().close()\n    except Exception:\n        pass\n\nif in_notebook():\n    def tqdm(*args, **kwargs):\n        clear_tqdm()\n        return tq.tqdm(*args, file=sys.stdout, **kwargs)\n    def trange(*args, **kwargs):\n        clear_tqdm()\n        return tq.trange(*args, file=sys.stdout, **kwargs)\nelse:\n    from tqdm import tqdm, trange\n    tnrange=trange\n    tqdm_notebook=tqdm\n\n"""
fastai/courses/dl2/fastai/initializers.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\ndef cond_init(m, init_fn):\n    if not isinstance(m, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):\n        if hasattr(m, 'weight'): init_fn(m.weight)\n        if hasattr(m, 'bias'): m.bias.data.fill_(0.)\n\ndef apply_init(m, init_fn):\n    m.apply(lambda x: cond_init(x, init_fn))\n\n\n"""
fastai/courses/dl2/fastai/io.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\nimport gzip\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\n\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None: self.total = tsize\n        self.update(b * bsize - self.n)\n\ndef get_data(url, filename):\n    if not os.path.exists(filename):\n\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n\n"""
fastai/courses/dl2/fastai/layer_optimizer.py,0,"b""from .imports import *\nfrom .torch_imports import *\nfrom .core import *\n\ndef opt_params(parm, lr, wd):\n    return {'params': chain_params(parm), 'lr':lr, 'weight_decay':wd}\n\nclass LayerOptimizer():\n    def __init__(self, opt_fn, layer_groups, lrs, wds=None):\n        if not isinstance(layer_groups, (list,tuple)): layer_groups=[layer_groups]\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(layer_groups)\n        if wds is None: wds=0.\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(layer_groups)\n        self.layer_groups,self.lrs,self.wds = layer_groups,lrs,wds\n        self.opt = opt_fn(self.opt_params())\n\n    def opt_params(self):\n        assert(len(self.layer_groups) == len(self.lrs))\n        assert(len(self.layer_groups) == len(self.wds))\n        params = list(zip(self.layer_groups,self.lrs,self.wds))\n        return [opt_params(*p) for p in params]\n\n    @property\n    def lr(self): return self.lrs[-1]\n\n    @property\n    def mom(self):\n        if 'betas' in self.opt.param_groups[0]:\n            return self.opt.param_groups[0]['betas'][0]\n        else:\n            return self.opt.param_groups[0]['momentum']\n\n    def set_lrs(self, lrs):\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(self.layer_groups)\n        set_lrs(self.opt, lrs)\n        self.lrs=lrs\n\n    def set_wds(self, wds):\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(self.layer_groups)\n        set_wds(self.opt, wds)\n        self.wds=wds\n    \n    def set_mom(self,momentum):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (momentum, pg['betas'][1])\n        else:\n            for pg in self.opt.param_groups: pg['momentum'] = momentum\n    \n    def set_beta(self,beta):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (pg['betas'][0],beta)\n        elif 'alpha' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['alpha'] = beta\n\n    def set_opt_fn(self, opt_fn):\n        if type(self.opt) != type(opt_fn(self.opt_params())):\n            self.opt = opt_fn(self.opt_params())\n\ndef zip_strict_(l, r):\n    assert(len(l) == len(r))\n    return zip(l, r)\n\ndef set_lrs(opt, lrs):\n    if not isinstance(lrs, Iterable): lrs=[lrs]\n    if len(lrs)==1: lrs=lrs*len(opt.param_groups)\n    for pg,lr in zip_strict_(opt.param_groups,lrs): pg['lr'] = lr\n\ndef set_wds(opt, wds):\n    if not isinstance(wds, Iterable): wds=[wds]\n    if len(wds)==1: wds=wds*len(opt.param_groups)\n    assert(len(opt.param_groups) == len(wds))\n    for pg,wd in zip_strict_(opt.param_groups,wds): pg['weight_decay'] = wd\n\n"""
fastai/courses/dl2/fastai/layers.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1,1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n\nclass Lambda(nn.Module):\n    def __init__(self, f): super().__init__(); self.f=f\n    def forward(self, x): return self.f(x)\n\nclass Flatten(nn.Module):\n    def __init__(self): super().__init__()\n    def forward(self, x): return x.view(x.size(0), -1)\n\n'"
fastai/courses/dl2/fastai/learner.py,1,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .model import *\nfrom .dataset import *\nfrom .sgdr import *\nfrom .layer_optimizer import *\nfrom .layers import *\nfrom .metrics import *\nfrom .losses import *\nfrom .swa import *\nfrom .fp16 import *\nfrom .lsuv_initializer import apply_lsuv_init\nimport time\n\n\nclass Learner():\n    def __init__(self, data, models, opt_fn=None, tmp_name=\'tmp\', models_name=\'models\', metrics=None, clip=None, crit=None):\n        """"""\n        Combines a ModelData object with a nn.Module object, such that you can train that\n        module.\n        data (ModelData): An instance of ModelData.\n        models(module): chosen neural architecture for solving a supported problem.\n        opt_fn(function): optimizer function, uses SGD with Momentum of .9 if none.\n        tmp_name(str): output name of the directory containing temporary files from training process\n        models_name(str): output name of the directory containing the trained model\n        metrics(list): array of functions for evaluating a desired metric. Eg. accuracy.\n        clip(float): gradient clip chosen to limit the change in the gradient to prevent exploding gradients Eg. .3\n        """"""\n        self.data_,self.models,self.metrics = data,models,metrics\n        self.sched=None\n        self.wd_sched = None\n        self.clip = None\n        self.opt_fn = opt_fn or SGD_Momentum(0.9)\n        self.tmp_path = tmp_name if os.path.isabs(tmp_name) else os.path.join(self.data.path, tmp_name)\n        self.models_path = models_name if os.path.isabs(models_name) else os.path.join(self.data.path, models_name)\n        os.makedirs(self.tmp_path, exist_ok=True)\n        os.makedirs(self.models_path, exist_ok=True)\n        self.crit = crit if crit else self._get_crit(data)\n        self.reg_fn = None\n        self.fp16 = False\n\n    @classmethod\n    def from_model_data(cls, m, data, **kwargs):\n        self = cls(data, BasicModel(to_gpu(m)), **kwargs)\n        self.unfreeze()\n        return self\n\n    def __getitem__(self,i): return self.children[i]\n\n    @property\n    def children(self): return children(self.model)\n\n    @property\n    def model(self): return self.models.model\n\n    @property\n    def data(self): return self.data_\n\n    def summary(self): return model_summary(self.model, [3,self.data.sz,self.data.sz])\n\n    def __repr__(self): return self.model.__repr__()\n    \n    def lsuv_init(self, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False):         \n        x = V(next(iter(self.data.trn_dl))[0])\n        self.models.model=apply_lsuv_init(self.model, x, needed_std=needed_std, std_tol=std_tol,\n                            max_attempts=max_attempts, do_orthonorm=do_orthonorm, \n                            cuda=USE_GPU and torch.cuda.is_available())\n\n    def set_bn_freeze(self, m, do_freeze):\n        if hasattr(m, \'running_mean\'): m.bn_freeze = do_freeze\n\n    def bn_freeze(self, do_freeze):\n        apply_leaf(self.model, lambda m: self.set_bn_freeze(m, do_freeze))\n\n    def freeze_to(self, n):\n        c=self.get_layer_groups()\n        for l in c:     set_trainable(l, False)\n        for l in c[n:]: set_trainable(l, True)\n\n    def freeze_all_but(self, n):\n        c=self.get_layer_groups()\n        for l in c: set_trainable(l, False)\n        set_trainable(c[n], True)\n\n    def unfreeze(self): self.freeze_to(0)\n\n    def get_model_path(self, name): return os.path.join(self.models_path,name)+\'.h5\'\n    \n    def save(self, name): \n        save_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): save_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n                       \n    def load(self, name): \n        load_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): load_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n\n    def set_data(self, data): self.data_ = data\n\n    def get_cycle_end(self, name):\n        if name is None: return None\n        return lambda sched, cycle: self.save_cycle(name, cycle)\n\n    def save_cycle(self, name, cycle): self.save(f\'{name}_cyc_{cycle}\')\n    def load_cycle(self, name, cycle): self.load(f\'{name}_cyc_{cycle}\')\n\n    def half(self):\n        if self.fp16: return\n        self.fp16 = True\n        if type(self.model) != FP16: self.models.model = FP16(self.model)\n    def float(self):\n        if not self.fp16: return\n        self.fp16 = False\n        if type(self.model) == FP16: self.models.model = self.model.module\n        self.model.float()\n\n    def fit_gen(self, model, data, layer_opt, n_cycle, cycle_len=None, cycle_mult=1, cycle_save_name=None, best_save_name=None,\n                use_clr=None, use_clr_beta=None, metrics=None, callbacks=None, use_wd_sched=False, norm_wds=False,             \n                wds_sched_mult=None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n\n        """"""Method does some preparation before finally delegating to the \'fit\' method for\n        fitting the model. Namely, if cycle_len is defined, it adds a \'Cosine Annealing\'\n        scheduler for varying the learning rate across iterations.\n\n        Method also computes the total number of epochs to fit based on provided \'cycle_len\',\n        \'cycle_mult\', and \'n_cycle\' parameters.\n\n        Args:\n            model (Learner):  Any neural architecture for solving a supported problem.\n                Eg. ResNet-34, RNN_Learner etc.\n\n            data (ModelData): An instance of ModelData.\n\n            layer_opt (LayerOptimizer): An instance of the LayerOptimizer class\n\n            n_cycle (int): number of cycles\n\n            cycle_len (int):  number of cycles before lr is reset to the initial value.\n                E.g if cycle_len = 3, then the lr is varied between a maximum\n                and minimum value over 3 epochs.\n\n            cycle_mult (int): additional parameter for influencing how the lr resets over\n                the cycles. For an intuitive explanation, please see\n                https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb\n\n            cycle_save_name (str): use to save the weights at end of each cycle\n\n            best_save_name (str): use to save weights of best model during training.\n\n            metrics (function): some function for evaluating a desired metric. Eg. accuracy.\n\n            callbacks (list(Callback)): callbacks to apply during the training.\n\n            use_wd_sched (bool, optional): set to True to enable weight regularization using\n                the technique mentioned in https://arxiv.org/abs/1711.05101. When this is True\n                alone (see below), the regularization is detached from gradient update and\n                applied directly to the weights.\n\n            norm_wds (bool, optional): when this is set to True along with use_wd_sched, the\n                regularization factor is normalized with each training cycle.\n\n            wds_sched_mult (function, optional): when this is provided along with use_wd_sched\n                as True, the value computed by this function is multiplied with the regularization\n                strength. This function is passed the WeightDecaySchedule object. And example\n                function that can be passed is:\n                            f = lambda x: np.array(x.layer_opt.lrs) / x.init_lrs\n                            \n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work.\n                \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n                \n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n\n        Returns:\n            None\n        """"""\n\n        if callbacks is None: callbacks=[]\n        if metrics is None: metrics=self.metrics\n\n        if use_wd_sched:\n            # This needs to come before CosAnneal() because we need to read the initial learning rate from\n            # layer_opt.lrs - but CosAnneal() alters the layer_opt.lrs value initially (divides by 100)\n            if np.sum(layer_opt.wds) == 0:\n                print(\'fit() warning: use_wd_sched is set to True, but weight decay(s) passed are 0. Use wds to \'\n                      \'pass weight decay values.\')\n            batch_per_epoch = len(data.trn_dl)\n            cl = cycle_len if cycle_len else 1\n            self.wd_sched = WeightDecaySchedule(layer_opt, batch_per_epoch, cl, cycle_mult, n_cycle,\n                                                norm_wds, wds_sched_mult)\n            callbacks += [self.wd_sched]\n\n        if use_clr is not None:\n            clr_div,cut_div = use_clr[:2]\n            moms = use_clr[2:] if len(use_clr) > 2 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=clr_div, cut_div=cut_div,\n                                    momentums=moms)\n        elif use_clr_beta is not None:\n            div,pct = use_clr_beta[:2]\n            moms = use_clr_beta[2:] if len(use_clr_beta) > 3 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR_beta(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=div,\n                                    pct=pct, momentums=moms)\n        elif cycle_len:\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            cycle_batches = len(data.trn_dl)*cycle_len\n            self.sched = CosAnneal(layer_opt, cycle_batches, on_cycle_end=cycle_end, cycle_mult=cycle_mult)\n        elif not self.sched: self.sched=LossRecorder(layer_opt)\n        callbacks+=[self.sched]\n\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(model)\n            callbacks+=[SWA(model, self.swa_model, swa_start)]\n\n        n_epoch = int(sum_geom(cycle_len if cycle_len else 1, cycle_mult, n_cycle))\n        return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def get_layer_groups(self): return self.models.get_layer_groups()\n\n    def get_layer_opt(self, lrs, wds):\n\n        """"""Method returns an instance of the LayerOptimizer class, which\n        allows for setting differential learning rates for different\n        parts of the model.\n\n        An example of how a model maybe differentiated into different parts\n        for application of differential learning rates and weight decays is\n        seen in ../.../courses/dl1/fastai/conv_learner.py, using the dict\n        \'model_meta\'. Currently, this seems supported only for convolutional\n        networks such as VGG-19, ResNet-XX etc.\n\n        Args:\n            lrs (float or list(float)): learning rate(s) for the model\n\n            wds (float or list(float)): weight decay parameter(s).\n\n        Returns:\n            An instance of a LayerOptimizer\n        """"""\n        return LayerOptimizer(self.opt_fn, self.get_layer_groups(), lrs, wds)\n\n    def fit(self, lrs, n_cycle, wds=None, **kwargs):\n\n        """"""Method gets an instance of LayerOptimizer and delegates to self.fit_gen(..)\n\n        Note that one can specify a list of learning rates which, when appropriately\n        defined, will be applied to different segments of an architecture. This seems\n        mostly relevant to ImageNet-trained models, where we want to alter the layers\n        closest to the images by much smaller amounts.\n\n        Likewise, a single or list of weight decay parameters can be specified, which\n        if appropriate for a model, will apply variable weight decay parameters to\n        different segments of the model.\n\n        Args:\n            lrs (float or list(float)): learning rate for the model\n\n            n_cycle (int): number of cycles (or iterations) to fit the model for\n\n            wds (float or list(float)): weight decay parameter(s).\n\n            kwargs: other arguments\n\n        Returns:\n            None\n        """"""\n        self.sched = None\n        layer_opt = self.get_layer_opt(lrs, wds)\n        return self.fit_gen(self.model, self.data, layer_opt, n_cycle, **kwargs)\n\n    def warm_up(self, lr, wds=None):\n        layer_opt = self.get_layer_opt(lr/4, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), lr, linear=True)\n        return self.fit_gen(self.model, self.data, layer_opt, 1)\n\n    def lr_find(self, start_lr=1e-5, end_lr=10, wds=None, linear=False, **kwargs):\n        """"""Helps you find an optimal learning rate for a model.\n\n         It uses the technique developed in the 2015 paper\n         `Cyclical Learning Rates for Training Neural Networks`, where\n         we simply keep increasing the learning rate from a very small value,\n         until the loss starts decreasing.\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            wds (iterable/float)\n\n        Examples:\n            As training moves us closer to the optimal weights for a model,\n            the optimal learning rate will be smaller. We can take advantage of\n            that knowledge and provide lr_find() with a starting learning rate\n            1000x smaller than the model\'s current learning rate as such:\n\n            >> learn.lr_find(lr/1000)\n\n            >> lrs = np.array([ 1e-4, 1e-3, 1e-2 ])\n            >> learn.lr_find(lrs / 1000)\n\n        Notes:\n            lr_find() may finish before going through each batch of examples if\n            the loss decreases enough.\n\n        .. _Cyclical Learning Rates for Training Neural Networks:\n            http://arxiv.org/abs/1506.01186\n\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), end_lr, linear=linear)\n        self.fit_gen(self.model, self.data, layer_opt, 1, **kwargs)\n        self.load(\'tmp\')\n\n    def lr_find2(self, start_lr=1e-5, end_lr=10, num_it = 100, wds=None, linear=False, stop_dv=True, **kwargs):\n        """"""A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n        At each step, it computes the validation loss and the metrics on the next\n        batch of the validation data, so it\'s slower than lr_find().\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            num_it : the number of iterations you want it to run\n            wds (iterable/float)\n            stop_dv : stops (or not) when the losses starts to explode.\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder2(layer_opt, num_it, end_lr, linear=linear, metrics=self.metrics, stop_dv=stop_dv)\n        self.fit_gen(self.model, self.data, layer_opt, num_it//len(self.data.trn_dl) + 1, all_val=True, **kwargs)\n        self.load(\'tmp\')\n\n    def predict(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict(m, dl)\n\n    def predict_with_targs(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict_with_targs(m, dl)\n\n    def predict_dl(self, dl): return predict_with_targs(self.model, dl)[0]\n\n    def predict_array(self, arr):\n        self.model.eval()\n        return to_np(self.model(to_gpu(V(T(arr)))))\n\n    def TTA(self, n_aug=4, is_test=False):\n        """""" Predict with Test Time Augmentation (TTA)\n\n        Additional to the original test/validation images, apply image augmentation to them\n        (just like for training images) and calculate the mean of predictions. The intent\n        is to increase the accuracy of predictions by examining the images using multiple\n        perspectives.\n\n        Args:\n            n_aug: a number of augmentation images to use per original image\n            is_test: indicate to use test images; otherwise use validation images\n\n        Returns:\n            (tuple): a tuple containing:\n\n                log predictions (numpy.ndarray): log predictions (i.e. `np.exp(log_preds)` will return probabilities)\n                targs (numpy.ndarray): target values when `is_test==False`; zeros otherwise.\n        """"""\n        dl1 = self.data.test_dl     if is_test else self.data.val_dl\n        dl2 = self.data.test_aug_dl if is_test else self.data.aug_dl\n        preds1,targs = predict_with_targs(self.model, dl1)\n        preds1 = [preds1]*math.ceil(n_aug/4)\n        preds2 = [predict_with_targs(self.model, dl2)[0] for i in tqdm(range(n_aug), leave=False)]\n        return np.stack(preds1+preds2), targs\n\n    def fit_opt_sched(self, phases, cycle_save_name=None, best_save_name=None, stop_div=False, data_list=None, callbacks=None, \n                      cut = None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n        """"""Wraps us the content of phases to send them to model.fit(..)\n\n        This will split the training in several parts, each with their own learning rates/\n        wds/momentums/optimizer detailed in phases.\n\n        Additionaly we can add a list of different data objets in data_list to train\n        on different datasets (to change the size for instance) for each of these groups.\n\n        Args:\n            phases: a list of TrainingPhase objects\n            stop_div: when True, stops the training if the loss goes too high\n            data_list: a list of different Data objects.\n            kwargs: other arguments\n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work. \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n        Returns:\n            None\n        """"""\n        if data_list is None: data_list=[]\n        if callbacks is None: callbacks=[]\n        layer_opt = LayerOptimizer(phases[0].opt_fn, self.get_layer_groups(), 1e-2, phases[0].wds)\n        self.sched = OptimScheduler(layer_opt, phases, len(self.data.trn_dl), stop_div)\n        callbacks.append(self.sched)\n        metrics = self.metrics\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(self.model)\n            callbacks+=[SWA(self.model, self.swa_model, swa_start)]\n        n_epochs = [phase.epochs for phase in phases] if cut is None else cut\n        if len(data_list)==0: data_list = [self.data]\n        return fit(self.model, data_list, n_epochs,layer_opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n'"
fastai/courses/dl2/fastai/lm_rnn.py,5,"b'import warnings\nfrom .imports import *\nfrom .torch_imports import *\nfrom .rnn_reg import LockedDropout,WeightDrop,EmbeddingDropout\nfrom .model import Stepper\nfrom .core import set_grad_enabled\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef seq2seq_reg(output, xtra, loss, alpha=0, beta=0):\n    hs,dropped_hs = xtra\n    if alpha:  # Activation Regularization\n        loss = loss + sum(alpha * dropped_hs[-1].pow(2).mean())\n    if beta:   # Temporal Activation Regularization (slowness)\n        h = hs[-1]\n        if len(h)>1: loss = loss + sum(beta * (h[1:] - h[:-1]).pow(2).mean())\n    return loss\n\n\ndef repackage_var(h):\n    """"""Wraps h in new Variables, to detach them from their history.""""""\n    if IS_TORCH_04: return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)\n    else: return Variable(h.data) if type(h) == Variable else tuple(repackage_var(v) for v in h)\n\n\nclass RNN_Encoder(nn.Module):\n\n    """"""A custom RNN encoder network that uses\n        - an embedding matrix to encode input,\n        - a stack of LSTM layers to drive the network, and\n        - variational dropouts in the embedding and LSTM layers\n\n        The architecture for this network was inspired by the work done in\n        ""Regularizing and Optimizing LSTM Language Models"".\n        (https://arxiv.org/pdf/1708.02182.pdf)\n    """"""\n\n    initrange=0.1\n\n    def __init__(self, ntoken, emb_sz, nhid, nlayers, pad_token, bidir=False,\n                 dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5):\n        """""" Default constructor for the RNN_Encoder class\n\n            Args:\n                bs (int): batch size of input data\n                ntoken (int): number of vocabulary (or tokens) in the source dataset\n                emb_sz (int): the embedding size to use to encode each token\n                nhid (int): number of hidden activation per LSTM layer\n                nlayers (int): number of LSTM layers to use in the architecture\n                pad_token (int): the int value used for padding text.\n                dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n                dropouti (float): dropout to apply to the input layer.\n                dropoute (float): dropout to apply to the embedding layer.\n                wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n\n            Returns:\n                None\n          """"""\n\n        super().__init__()\n        self.ndir = 2 if bidir else 1\n        self.bs = 1\n        self.encoder = nn.Embedding(ntoken, emb_sz, padding_idx=pad_token)\n        self.encoder_with_dropout = EmbeddingDropout(self.encoder)\n        self.rnns = [nn.LSTM(emb_sz if l == 0 else nhid, (nhid if l != nlayers - 1 else emb_sz)//self.ndir,\n             1, bidirectional=bidir) for l in range(nlayers)]\n        if wdrop: self.rnns = [WeightDrop(rnn, wdrop) for rnn in self.rnns]\n        self.rnns = torch.nn.ModuleList(self.rnns)\n        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n\n        self.emb_sz,self.nhid,self.nlayers,self.dropoute = emb_sz,nhid,nlayers,dropoute\n        self.dropouti = LockedDropout(dropouti)\n        self.dropouths = nn.ModuleList([LockedDropout(dropouth) for l in range(nlayers)])\n\n    def forward(self, input):\n        """""" Invoked during the forward propagation of the RNN_Encoder module.\n        Args:\n            input (Tensor): input of shape (sentence length x batch_size)\n\n        Returns:\n            raw_outputs (tuple(list (Tensor), list(Tensor)): list of tensors evaluated from each RNN layer without using\n            dropouth, list of tensors evaluated from each RNN layer using dropouth,\n        """"""\n        sl,bs = input.size()\n        if bs!=self.bs:\n            self.bs=bs\n            self.reset()\n        with set_grad_enabled(self.training):\n            emb = self.encoder_with_dropout(input, dropout=self.dropoute if self.training else 0)\n            emb = self.dropouti(emb)\n            raw_output = emb\n            new_hidden,raw_outputs,outputs = [],[],[]\n            for l, (rnn,drop) in enumerate(zip(self.rnns, self.dropouths)):\n                current_input = raw_output\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    raw_output, new_h = rnn(raw_output, self.hidden[l])\n                new_hidden.append(new_h)\n                raw_outputs.append(raw_output)\n                if l != self.nlayers - 1: raw_output = drop(raw_output)\n                outputs.append(raw_output)\n\n            self.hidden = repackage_var(new_hidden)\n        return raw_outputs, outputs\n\n    def one_hidden(self, l):\n        nh = (self.nhid if l != self.nlayers - 1 else self.emb_sz)//self.ndir\n        if IS_TORCH_04: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_())\n        else: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_(), volatile=not self.training)\n\n    def reset(self):\n        self.weights = next(self.parameters()).data\n        self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.nlayers)]\n\n\nclass MultiBatchRNN(RNN_Encoder):\n    def __init__(self, bptt, max_seq, *args, **kwargs):\n        self.max_seq,self.bptt = max_seq,bptt\n        super().__init__(*args, **kwargs)\n\n    def concat(self, arrs):\n        return [torch.cat([l[si] for l in arrs]) for si in range(len(arrs[0]))]\n\n    def forward(self, input):\n        sl,bs = input.size()\n        for l in self.hidden:\n            for h in l: h.data.zero_()\n        raw_outputs, outputs = [],[]\n        for i in range(0, sl, self.bptt):\n            r, o = super().forward(input[i: min(i+self.bptt, sl)])\n            if i>(sl-self.max_seq):\n                raw_outputs.append(r)\n                outputs.append(o)\n        return self.concat(raw_outputs), self.concat(outputs)\n\nclass LinearDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, n_out, nhid, dropout, tie_encoder=None):\n        super().__init__()\n        self.decoder = nn.Linear(nhid, n_out, bias=False)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.dropout = LockedDropout(dropout)\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = self.dropout(outputs[-1])\n        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n        result = decoded.view(-1, decoded.size(1))\n        return result, raw_outputs, outputs\n\n\nclass LinearBlock(nn.Module):\n    def __init__(self, ni, nf, drop):\n        super().__init__()\n        self.lin = nn.Linear(ni, nf)\n        self.drop = nn.Dropout(drop)\n        self.bn = nn.BatchNorm1d(ni)\n\n    def forward(self, x): return self.lin(self.drop(self.bn(x)))\n\n\nclass PoolingLinearClassifier(nn.Module):\n    def __init__(self, layers, drops):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            LinearBlock(layers[i], layers[i + 1], drops[i]) for i in range(len(layers) - 1)])\n\n    def pool(self, x, bs, is_max):\n        f = F.adaptive_max_pool1d if is_max else F.adaptive_avg_pool1d\n        return f(x.permute(1,2,0), (1,)).view(bs,-1)\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = outputs[-1]\n        sl,bs,_ = output.size()\n        avgpool = self.pool(output, bs, False)\n        mxpool = self.pool(output, bs, True)\n        x = torch.cat([output[-1], mxpool, avgpool], 1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return l_x, raw_outputs, outputs\n\n\nclass SequentialRNN(nn.Sequential):\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \'reset\'): c.reset()\n\n\ndef get_language_model(n_tok, emb_sz, nhid, nlayers, pad_token,\n                 dropout=0.4, dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5, tie_weights=True):\n    """"""Returns a SequentialRNN model.\n\n    A RNN_Encoder layer is instantiated using the parameters provided.\n\n    This is followed by the creation of a LinearDecoder layer.\n\n    Also by default (i.e. tie_weights = True), the embedding matrix used in the RNN_Encoder\n    is used to  instantiate the weights for the LinearDecoder layer.\n\n    The SequentialRNN layer is the native torch\'s Sequential wrapper that puts the RNN_Encoder and\n    LinearDecoder layers sequentially in the model.\n\n    Args:\n        n_tok (int): number of unique vocabulary words (or tokens) in the source dataset\n        emb_sz (int): the embedding size to use to encode each token\n        nhid (int): number of hidden activation per LSTM layer\n        nlayers (int): number of LSTM layers to use in the architecture\n        pad_token (int): the int value used for padding text.\n        dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n        dropouti (float): dropout to apply to the input layer.\n        dropoute (float): dropout to apply to the embedding layer.\n        wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n        tie_weights (bool): decide if the weights of the embedding matrix in the RNN encoder should be tied to the\n            weights of the LinearDecoder layer.\n    Returns:\n        A SequentialRNN model\n    """"""\n\n    rnn_enc = RNN_Encoder(n_tok, emb_sz, nhid=nhid, nlayers=nlayers, pad_token=pad_token,\n                 dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    enc = rnn_enc.encoder if tie_weights else None\n    return SequentialRNN(rnn_enc, LinearDecoder(n_tok, emb_sz, dropout, tie_encoder=enc))\n\n\ndef get_rnn_classifer(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n                      dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n    rnn_enc = MultiBatchRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir,\n                      dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    return SequentialRNN(rnn_enc, PoolingLinearClassifier(layers, drops))\n\n'"
fastai/courses/dl2/fastai/losses.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\ndef fbeta_torch(y_true, y_pred, beta, threshold, eps=1e-9):\n    y_pred = (y_pred.float() > threshold).float()\n    y_true = y_true.float()\n    tp = (y_pred * y_true).sum(dim=1)\n    precision = tp / (y_pred.sum(dim=1)+eps)\n    recall = tp / (y_true.sum(dim=1)+eps)\n    return torch.mean(\n        precision*recall / (precision*(beta**2)+recall+eps) * (1+beta**2))\n\n'"
fastai/courses/dl2/fastai/lsuv_initializer.py,4,"b'""""""\nFrom https://github.com/ducha-aiki/LSUV-pytorch\n\nCopyright (C) 2017, Dmytro Mishkin\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the\n   distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\nimport numpy as np\nimport torch\nimport torch.nn.init\nimport torch.nn as nn\n\ngg = {}\ngg[\'hook_position\'] = 0\ngg[\'total_fc_conv_layers\'] = 0\ngg[\'done_counter\'] = -1\ngg[\'hook\'] = None\ngg[\'act_dict\'] = {}\ngg[\'counter_to_apply_correction\'] = 0\ngg[\'correction_needed\'] = False\ngg[\'current_coef\'] = 1.0\n\n# Orthonorm init code is taked from Lasagne\n# https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\ndef svd_orthonormal(w):\n    shape = w.shape\n    if len(shape) < 2:\n        raise RuntimeError(""Only shapes of length 2 or more are supported."")\n    flat_shape = (shape[0], np.prod(shape[1:]))\n    a = np.random.normal(0.0, 1.0, flat_shape)#w;\n    u, _, v = np.linalg.svd(a, full_matrices=False)\n    q = u if u.shape == flat_shape else v\n    q = q.reshape(shape)\n    return q.astype(np.float32)\n\ndef store_activations(self, input, output):\n    gg[\'act_dict\'] = output.data.cpu().numpy();\n    return\n\ndef add_current_hook(m):\n    if gg[\'hook\'] is not None:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'hook_position\'] > gg[\'done_counter\']:\n            gg[\'hook\'] = m.register_forward_hook(store_activations)\n        else:\n            gg[\'hook_position\'] += 1\n    return\n\ndef count_conv_fc_layers(m):\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        gg[\'total_fc_conv_layers\'] +=1\n    return\n\ndef remove_hooks(hooks):\n    for h in hooks:\n        h.remove()\n    return\n\ndef orthogonal_weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        if hasattr(m, \'weight_v\'):\n            w_ortho = svd_orthonormal(m.weight_v.data.cpu().numpy())\n            m.weight_v.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n        else:\n            w_ortho = svd_orthonormal(m.weight.data.cpu().numpy())\n            m.weight.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n    return\n\ndef apply_weights_correction(m):\n    if gg[\'hook\'] is None:\n        return\n    if not gg[\'correction_needed\']:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'counter_to_apply_correction\'] < gg[\'hook_position\']:\n            gg[\'counter_to_apply_correction\'] += 1\n        else:\n            if hasattr(m, \'weight_g\'):\n                m.weight_g.data *= float(gg[\'current_coef\'])\n                gg[\'correction_needed\'] = False\n            else:\n                m.weight.data *= gg[\'current_coef\']\n                gg[\'correction_needed\'] = False\n            return\n    return\n\ndef apply_lsuv_init(model, data, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=True, cuda=True):\n    model.eval();\n    if cuda:\n        model=model.cuda()\n        data=data.cuda()\n    else:\n        model=model.cpu()\n        data=data.cpu()        \n        \n    model.apply(count_conv_fc_layers)\n    if do_orthonorm:\n        model.apply(orthogonal_weights_init)\n        if cuda:\n            model=model.cuda()\n    for layer_idx in range(gg[\'total_fc_conv_layers\']):\n        model.apply(add_current_hook)\n        out = model(data)\n        current_std = gg[\'act_dict\'].std()\n        attempts = 0\n        while (np.abs(current_std - needed_std) > std_tol):\n            gg[\'current_coef\'] =  needed_std / (current_std  + 1e-8);\n            gg[\'correction_needed\'] = True\n            model.apply(apply_weights_correction)\n            if cuda:\n                model=model.cuda()\n            out = model(data)\n            current_std = gg[\'act_dict\'].std()\n            attempts+=1\n            if attempts > max_attempts:\n                print(f\'Cannot converge in {max_attempts} iterations\')\n                break\n        if gg[\'hook\'] is not None:\n           gg[\'hook\'].remove()\n        gg[\'done_counter\']+=1\n        gg[\'counter_to_apply_correction\'] = 0\n        gg[\'hook_position\'] = 0\n        gg[\'hook\']  = None\n    if not cuda:\n        model=model.cpu()\n    return model\n'"
fastai/courses/dl2/fastai/metrics.py,3,"b'from .imports import *\nfrom .torch_imports import *\n\ndef accuracy_np(preds, targs):\n    preds = np.argmax(preds, 1)\n    return (preds==targs).mean()\n\ndef accuracy(preds, targs):\n    preds = torch.max(preds, dim=1)[1]\n    return (preds==targs).float().mean()\n\ndef accuracy_thresh(thresh):\n    return lambda preds,targs: accuracy_multi(preds, targs, thresh)\n\ndef accuracy_multi(preds, targs, thresh):\n    return ((preds>thresh).float()==targs).float().mean()\n\ndef accuracy_multi_np(preds, targs, thresh):\n    return ((preds>thresh)==targs).mean()\n\ndef recall(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/targs.sum()\n\ndef precision(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/pred_pos.sum()\n\ndef fbeta(preds, targs, beta, thresh=0.5):\n    """"""Calculates the F-beta score (the weighted harmonic mean of precision and recall).\n    This is the micro averaged version where the true positives, false negatives and\n    false positives are calculated globally (as opposed to on a per label basis).\n\n    beta == 1 places equal weight on precision and recall, b < 1 emphasizes precision and\n    beta > 1 favors recall.\n    """"""\n    assert beta > 0, \'beta needs to be greater than 0\'\n    beta2 = beta ** 2\n    rec = recall(preds, targs, thresh)\n    prec = precision(preds, targs, thresh)\n    return (1 + beta2) * prec * rec / (beta2 * prec + rec)\n\ndef f1(preds, targs, thresh=0.5): return fbeta(preds, targs, 1, thresh)\n'"
fastai/courses/dl2/fastai/model.py,8,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .layer_optimizer import *\nfrom .swa import *\nfrom .fp16 import *\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef cut_model(m, cut):\n    return list(m.children())[:cut] if cut else [m]\n\ndef predict_to_bcolz(m, gen, arr, workers=4):\n    arr.trim(len(arr))\n    lock=threading.Lock()\n    m.eval()\n    for x,*_ in tqdm(gen):\n        y = to_np(m(VV(x)).data)\n        with lock:\n            arr.append(y)\n            arr.flush()\n\ndef num_features(m):\n    c=children(m)\n    if len(c)==0: return None\n    for l in reversed(c):\n        if hasattr(l, \'num_features\'): return l.num_features\n        res = num_features(l)\n        if res is not None: return res\n\ndef torch_item(x): return x.item() if hasattr(x,\'item\') else x[0]\n\nclass Stepper():\n    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n        self.fp16 = fp16\n        self.reset(True)\n        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n        self.loss_scale = loss_scale\n\n    def reset(self, train=True):\n        if train: apply_leaf(self.m, set_train_mode)\n        else: self.m.eval()\n        if hasattr(self.m, \'reset\'):\n            self.m.reset()\n            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n\n    def step(self, xs, y, epoch):\n        xtra = []\n        output = self.m(*xs)\n        if isinstance(output,tuple): output,*xtra = output\n        if self.fp16: self.m.zero_grad()\n        else: self.opt.zero_grad() \n        loss = raw_loss = self.crit(output, y)\n        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n        loss.backward()\n        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n        if self.loss_scale != 1:\n            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n        if self.clip:   # Gradient clipping\n            if IS_TORCH_04: nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n            else: nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n        self.opt.step()\n        if self.fp16: \n            copy_fp32_to_model(self.m, self.fp32_params)\n            torch.cuda.synchronize()\n        return torch_item(raw_loss.data)\n\n    def evaluate(self, xs, y):\n        preds = self.m(*xs)\n        if isinstance(preds,tuple): preds=preds[0]\n        return preds, self.crit(preds, y)\n\ndef set_train_mode(m):\n    if (hasattr(m, \'running_mean\') and (getattr(m,\'bn_freeze\',False)\n              or not getattr(m,\'trainable\',False))): m.eval()\n    elif (getattr(m,\'drop_freeze\',False) and hasattr(m, \'p\')\n          and (\'drop\' in type(m).__name__.lower())): m.eval()\n    else: m.train()\n\ndef fit(model, data, n_epochs, opt, crit, metrics=None, callbacks=None, stepper=Stepper,\n        swa_model=None, swa_start=None, swa_eval_freq=None, **kwargs):\n    """""" Fits a model\n\n    Arguments:\n       model (model): any pytorch module\n           net = to_gpu(net)\n       data (ModelData): see ModelData class and subclasses (can be a list)\n       opts: an optimizer. Example: optim.Adam. \n       If n_epochs is a list, it needs to be the layer_optimizer to get the optimizer as it changes.\n       n_epochs(int or list): number of epochs (or list of number of epochs)\n       crit: loss function to optimize. Example: F.cross_entropy\n    """"""\n\n    all_val = kwargs.pop(\'all_val\') if \'all_val\' in kwargs else False\n    get_ep_vals = kwargs.pop(\'get_ep_vals\') if \'get_ep_vals\' in kwargs else False\n    metrics = metrics or []\n    callbacks = callbacks or []\n    avg_mom=0.98\n    batch_num,avg_loss=0,0.\n    for cb in callbacks: cb.on_train_begin()\n    names = [""epoch"", ""trn_loss"", ""val_loss""] + [f.__name__ for f in metrics]\n    if swa_model is not None:\n        swa_names = [\'swa_loss\'] + [f\'swa_{f.__name__}\' for f in metrics]\n        names += swa_names\n        # will use this to call evaluate later\n        swa_stepper = stepper(swa_model, None, crit, **kwargs)\n\n    layout = ""{!s:10} "" * len(names)\n    if not isinstance(n_epochs, Iterable): n_epochs=[n_epochs]\n    if not isinstance(data, Iterable): data = [data]\n    if len(data) == 1: data = data * len(n_epochs)\n    for cb in callbacks: cb.on_phase_begin()\n    model_stepper = stepper(model, opt.opt if hasattr(opt,\'opt\') else opt, crit, **kwargs)\n    ep_vals = collections.OrderedDict()\n    tot_epochs = int(np.ceil(np.array(n_epochs).sum()))\n    cnt_phases = np.array([ep * len(dat.trn_dl) for (ep,dat) in zip(n_epochs,data)]).cumsum()\n    phase = 0\n    for epoch in tnrange(tot_epochs, desc=\'Epoch\'):\n        model_stepper.reset(True)\n        cur_data = data[phase]\n        if hasattr(cur_data, \'trn_sampler\'): cur_data.trn_sampler.set_epoch(epoch)\n        if hasattr(cur_data, \'val_sampler\'): cur_data.val_sampler.set_epoch(epoch)\n        num_batch = len(cur_data.trn_dl)\n        t = tqdm(iter(cur_data.trn_dl), leave=False, total=num_batch)\n        if all_val: val_iter = IterBatch(cur_data.val_dl)\n\n        for (*x,y) in t:\n            batch_num += 1\n            for cb in callbacks: cb.on_batch_begin()\n            loss = model_stepper.step(V(x),V(y), epoch)\n            avg_loss = avg_loss * avg_mom + loss * (1-avg_mom)\n            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n            t.set_postfix(loss=debias_loss)\n            stop=False\n            los = debias_loss if not all_val else [debias_loss] + validate_next(model_stepper,metrics, val_iter)\n            for cb in callbacks: stop = stop or cb.on_batch_end(los)\n            if stop: return\n            if batch_num >= cnt_phases[phase]:\n                for cb in callbacks: cb.on_phase_end()\n                phase += 1\n                if phase >= len(n_epochs):\n                    t.close()\n                    break\n                for cb in callbacks: cb.on_phase_begin()\n                if isinstance(opt, LayerOptimizer): model_stepper.opt = opt.opt\n                if cur_data != data[phase]:\n                    t.close()\n                    break\n\n        if not all_val:\n            vals = validate(model_stepper, cur_data.val_dl, metrics)\n            stop=False\n            for cb in callbacks: stop = stop or cb.on_epoch_end(vals)\n            if swa_model is not None:\n                if (epoch + 1) >= swa_start and ((epoch + 1 - swa_start) % swa_eval_freq == 0 or epoch == tot_epochs - 1):\n                    fix_batchnorm(swa_model, cur_data.trn_dl)\n                    swa_vals = validate(swa_stepper, cur_data.val_dl, metrics)\n                    vals += swa_vals\n\n            if epoch == 0: print(layout.format(*names))\n            print_stats(epoch, [debias_loss] + vals)\n            ep_vals = append_stats(ep_vals, epoch, [debias_loss] + vals)\n        if stop: break\n    for cb in callbacks: cb.on_train_end()\n    if get_ep_vals: return vals, ep_vals\n    else: return vals\n\ndef append_stats(ep_vals, epoch, values, decimals=6):\n    ep_vals[epoch]=list(np.round(values, decimals))\n    return ep_vals\n\ndef print_stats(epoch, values, decimals=6):\n    layout = ""{!s:^10}"" + "" {!s:10}"" * len(values)\n    values = [epoch] + list(np.round(values, decimals))\n    print(layout.format(*values))\n\nclass IterBatch():\n    def __init__(self, dl):\n        self.idx = 0\n        self.dl = dl\n        self.iter = iter(dl)\n\n    def __iter__(self): return self\n\n    def next(self):\n        res = next(self.iter)\n        self.idx += 1\n        if self.idx == len(self.dl):\n            self.iter = iter(self.dl)\n            self.idx=0\n        return res\n\ndef validate_next(stepper, metrics, val_iter):\n    """"""Computes the loss on the next minibatch of the validation set.""""""\n    stepper.reset(False)\n    with no_grad_context():\n        (*x,y) = val_iter.next()\n        preds,l = stepper.evaluate(VV(x), VV(y))\n        res = [to_np(l)[0]]\n        res += [f(preds.data,y) for f in metrics]\n    stepper.reset(True)\n    return res\n\ndef validate(stepper, dl, metrics):\n    batch_cnts,loss,res = [],[],[]\n    stepper.reset(False)\n    with no_grad_context():\n        for (*x,y) in iter(dl):\n            preds, l = stepper.evaluate(VV(x), VV(y))\n            if isinstance(x,list): batch_cnts.append(len(x[0]))\n            else: batch_cnts.append(len(x))\n            loss.append(to_np(l))\n            res.append([f(preds.data, y) for f in metrics])\n    return [np.average(loss, 0, weights=batch_cnts)] + list(np.average(np.stack(res), 0, weights=batch_cnts))\n\ndef get_prediction(x):\n    if is_listy(x): x=x[0]\n    return x.data\n\ndef predict(m, dl):\n    preda,_ = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda))\n\ndef predict_batch(m, x):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    return m(VV(x))\n\ndef predict_with_targs_(m, dl):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    res = []\n    for *x,y in iter(dl): res.append([get_prediction(m(*VV(x))),y])\n    return zip(*res)\n\ndef predict_with_targs(m, dl):\n    preda,targa = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda)), to_np(torch.cat(targa))\n\n# From https://github.com/ncullen93/torchsample\ndef model_summary(m, input_size):\n    def register_hook(module):\n        def hook(module, input, output):\n            class_name = str(module.__class__).split(\'.\')[-1].split(""\'"")[0]\n            module_idx = len(summary)\n\n            m_key = \'%s-%i\' % (class_name, module_idx+1)\n            summary[m_key] = OrderedDict()\n            summary[m_key][\'input_shape\'] = list(input[0].size())\n            summary[m_key][\'input_shape\'][0] = -1\n            if is_listy(output):\n                summary[m_key][\'output_shape\'] = [[-1] + list(o.size())[1:] for o in output]\n            else:\n                summary[m_key][\'output_shape\'] = list(output.size())\n                summary[m_key][\'output_shape\'][0] = -1\n\n            params = 0\n            if hasattr(module, \'weight\'):\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n                summary[m_key][\'trainable\'] = module.weight.requires_grad\n            if hasattr(module, \'bias\') and module.bias is not None:\n                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n            summary[m_key][\'nb_params\'] = params\n\n        if (not isinstance(module, nn.Sequential) and\n           not isinstance(module, nn.ModuleList) and\n           not (module == m)):\n            hooks.append(module.register_forward_hook(hook))\n\n    summary = OrderedDict()\n    hooks = []\n    m.apply(register_hook)\n\n    if is_listy(input_size[0]):\n        x = [to_gpu(Variable(torch.rand(3,*in_size))) for in_size in input_size]\n    else: x = [to_gpu(Variable(torch.rand(3,*input_size)))]\n    m(*x)\n\n    for h in hooks: h.remove()\n    return summary\n\n'"
fastai/courses/dl2/fastai/nlp.py,4,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .model import *\nfrom .dataset import *\nfrom .learner import *\nfrom .text import *\nfrom .lm_rnn import *\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.datasets import language_modeling\n\nclass DotProdNB(nn.Module):\n    def __init__(self, nf, ny, w_adj=0.4, r_adj=10):\n        super().__init__()\n        self.w_adj,self.r_adj = w_adj,r_adj\n        self.w = nn.Embedding(nf+1, 1, padding_idx=0)\n        self.w.weight.data.uniform_(-0.1,0.1)\n        self.r = nn.Embedding(nf+1, ny)\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        w = self.w(feat_idx)\n        r = self.r(feat_idx)\n        x = ((w+self.w_adj)*r/self.r_adj).sum(1)\n        return F.softmax(x)\n\nclass SimpleNB(nn.Module):\n    def __init__(self, nf, ny):\n        super().__init__()\n        self.r = nn.Embedding(nf+1, ny, padding_idx=0)\n        self.b = nn.Parameter(torch.zeros(ny,))\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        r = self.r(feat_idx)\n        x = r.sum(1)+self.b\n        return F.softmax(x)\n\nclass BOW_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.l1_loss\n\ndef calc_pr(y_i, x, y, b):\n    idx = np.argwhere((y==y_i)==b)\n    p = x[idx[:,0]].sum(0)+1\n    return p/((y==y_i)==b).sum()\n\ndef calc_r(y_i, x, y):\n    return np.log(calc_pr(y_i, x, y, True) / calc_pr(y_i, x, y, False))\n\nclass BOW_Dataset(Dataset):\n    def __init__(self, bow, y, max_len):\n        self.bow,self.max_len = bow,max_len\n        self.c = int(y.max())+1\n        self.n,self.vocab_size = bow.shape\n        self.y = one_hot(y,self.c).astype(np.float32)\n        x = self.bow.sign()\n        self.r = np.stack([calc_r(i, x, y).A1 for i in range(self.c)]).T\n\n    def __getitem__(self, i):\n        row = self.bow.getrow(i)\n\n        num_row_entries = row.indices.shape[0]\n        indices = (row.indices + 1).astype(np.int64)\n        data = (row.data).astype(np.int64)\n\n        if num_row_entries < self.max_len:\n            # If short, pad\n            indices = np.pad(indices, (self.max_len - num_row_entries, 0), mode=\'constant\')\n            data = np.pad(data, (self.max_len - num_row_entries, 0), mode=\'constant\')\n        else:\n            # If long, truncate\n            indices, data = indices[-self.max_len:], data[-self.max_len:]\n\n        return indices, data, min(self.max_len, num_row_entries), self.y[i]\n\n    def __len__(self): return len(self.bow.indptr)-1\n\n\nclass TextClassifierData(ModelData):\n    @property\n    def c(self): return self.trn_ds.c\n\n    @property\n    def r(self):\n        return torch.Tensor(np.concatenate([np.zeros((1,self.c)), self.trn_ds.r]))\n\n    def get_model(self, f, **kwargs):\n        m = to_gpu(f(self.trn_ds.vocab_size, self.c, **kwargs))\n        m.r.weight.data = to_gpu(self.r)\n        m.r.weight.requires_grad = False\n        model = BasicModel(m)\n        return BOW_Learner(self, model, metrics=[accuracy_thresh(0.5)], opt_fn=optim.Adam)\n\n    def dotprod_nb_learner(self, **kwargs): return self.get_model(DotProdNB, **kwargs)\n    def nb_learner(self, **kwargs): return self.get_model(SimpleNB, **kwargs)\n\n    @classmethod\n    def from_bow(cls, trn_bow, trn_y, val_bow, val_y, sl):\n        trn_ds = BOW_Dataset(trn_bow, trn_y, sl)\n        val_ds = BOW_Dataset(val_bow, val_y, sl)\n        trn_dl = DataLoader(trn_ds, 64, True)\n        val_dl = DataLoader(val_ds, 64, False)\n        return cls(\'.\', trn_dl, val_dl)\n\n\ndef flip_tensor(x, dim):\n    xsize = x.size()\n    dim = x.dim() + dim if dim < 0 else dim\n    x = x.view(-1, *xsize[dim:])\n    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1,\n                      -1, -1), (\'cpu\',\'cuda\')[x.is_cuda])().long(), :]\n    return x.view(xsize)\n\n\nclass LanguageModelLoader():\n\n    def __init__(self, ds, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        text = sum([o.text for o in ds], [])\n        fld = ds.fields[\'text\']\n        nums = fld.numericalize([text],device=None if torch.cuda.is_available() else -1)\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        return self\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def __next__(self):\n        if self.i >= self.n-1 or self.iter>=len(self): raise StopIteration\n        bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n        seq_len = max(5, int(np.random.normal(bptt, 5)))\n        res = self.get_batch(self.i, seq_len)\n        self.i += seq_len\n        self.iter += 1\n        return res\n\n    def batchify(self, data):\n        nb = data.size(0) // self.bs\n        data = data[:nb*self.bs]\n        data = data.view(self.bs, -1).t().contiguous()\n        if self.backwards: data=flip_tensor(data, 0)\n        return to_gpu(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass ConcatTextDataset(torchtext.data.Dataset):\n    def __init__(self, path, text_field, newline_eos=True, encoding=\'utf-8\', **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n        if os.path.isdir(path): paths=glob(f\'{path}/*.*\')\n        else: paths=[path]\n        for p in paths:\n            for line in open(p, encoding=encoding): text += text_field.preprocess(line)\n            if newline_eos: text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n        super().__init__(examples, fields, **kwargs)\n\n\nclass ConcatTextDatasetFromDataFrames(torchtext.data.Dataset):\n    def __init__(self, df, text_field, col, newline_eos=True, **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n\n        text += text_field.preprocess(df[col].str.cat(sep=\' <eos> \'))\n        if (newline_eos): text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n\n        super().__init__(examples, fields, **kwargs)\n\n    @classmethod\n    def splits(cls, train_df=None, val_df=None, test_df=None, keep_nones=False, **kwargs):\n        res = (\n            cls(train_df, **kwargs),\n            cls(val_df, **kwargs),\n            map_none(test_df, partial(cls, **kwargs)))  # not required\n        return res if keep_nones else tuple(d for d in res if d is not None)\n\n\nclass LanguageModelData():\n    """"""\n    This class provides the entry point for dealing with supported NLP tasks.\n    Usage:\n    1.  Use one of the factory constructors (from_dataframes, from_text_files) to\n        obtain an instance of the class.\n    2.  Use the get_model method to return a RNN_Learner instance (a network suited\n        for NLP tasks), then proceed with training.\n\n        Example:\n            >> TEXT = data.Field(lower=True, tokenize=spacy_tok)\n            >> FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n            >> md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=64, bptt=70, min_freq=10)\n\n            >> em_sz = 200  # size of each embedding vector\n            >> nh = 500     # number of hidden activations per layer\n            >> nl = 3       # number of layers\n\n            >> opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n            >> learner = md.get_model(opt_fn, em_sz, nh, nl,\n                           dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n            >> learner.reg_fn = seq2seq_reg\n            >> learner.clip=0.3\n\n            >> learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n\n    """"""\n    def __init__(self, path, field, trn_ds, val_ds, test_ds, bs, bptt, backwards=False, **kwargs):\n        """""" Constructor for the class. An important thing that happens here is\n            that the field\'s ""build_vocab"" method is invoked, which builds the vocabulary\n            for this NLP model.\n\n            Also, three instances of the LanguageModelLoader are constructed; one each\n            for training data (self.trn_dl), validation data (self.val_dl), and the\n            testing data (self.test_dl)\n\n            Args:\n                path (str): testing path\n                field (Field): torchtext field object\n                trn_ds (Dataset): training dataset\n                val_ds (Dataset): validation dataset\n                test_ds (Dataset): testing dataset\n                bs (int): batch size\n                bptt (int): back propagation through time\n                kwargs: other arguments\n        """"""\n        self.bs = bs\n        self.path = path\n        self.trn_ds = trn_ds; self.val_ds = val_ds; self.test_ds = test_ds\n        if not hasattr(field, \'vocab\'): field.build_vocab(self.trn_ds, **kwargs)\n\n        self.pad_idx = field.vocab.stoi[field.pad_token]\n        self.nt = len(field.vocab)\n\n        factory = lambda ds: LanguageModelLoader(ds, bs, bptt, backwards=backwards)\n        self.trn_dl = factory(self.trn_ds)\n        self.val_dl = factory(self.val_ds)\n        self.test_dl = map_none(self.test_ds, factory)  # not required\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        """""" Method returns a RNN_Learner object, that wraps an instance of the RNN_Encoder module.\n\n        Args:\n            opt_fn (Optimizer): the torch optimizer function to use\n            emb_sz (int): embedding size\n            n_hid (int): number of hidden inputs\n            n_layers (int): number of hidden layers\n            kwargs: other arguments\n\n        Returns:\n            An instance of the RNN_Learner class.\n\n        """"""\n        m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = SingleModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    @classmethod\n    def from_dataframes(cls, path, field, col, train_df, val_df, test_df=None, bs=64, bptt=70, **kwargs):\n        trn_ds, val_ds, test_ds = ConcatTextDatasetFromDataFrames.splits(\n            text_field=field, col=col, train_df=train_df, val_df=val_df, test_df=test_df, keep_nones=True)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n    @classmethod\n    def from_text_files(cls, path, field, train, validation, test=None, bs=64, bptt=70, **kwargs):\n        """""" Method used to instantiate a LanguageModelData object that can be used for a\n            supported nlp task.\n\n        Args:\n            path (str): the absolute path in which temporary model data will be saved\n            field (Field): torchtext field\n            train (str): file location of the training data\n            validation (str): file location of the validation data\n            test (str): file location of the testing data\n            bs (int): batch size to use\n            bptt (int): back propagation through time hyper-parameter\n            kwargs: other arguments\n\n        Returns:\n            a LanguageModelData instance, which most importantly, provides us the datasets for training,\n                validation, and testing\n\n        Note:\n            The train, validation, and test path can be pointed to any file (or folder) that contains a valid\n                text corpus.\n\n        """"""\n        trn_ds, val_ds, test_ds = ConcatTextDataset.splits(\n            path, text_field=field, train=train, validation=validation, test=test)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n\nclass TextDataLoader():\n    def __init__(self, src, x_fld, y_fld):\n        self.src,self.x_fld,self.y_fld = src,x_fld,y_fld\n\n    def __len__(self): return len(self.src)\n\n    def __iter__(self):\n        it = iter(self.src)\n        for i in range(len(self)):\n            b = next(it)\n            yield getattr(b, self.x_fld).data, getattr(b, self.y_fld).data\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n\nclass TextData(ModelData):\n    def create_td(self, it): return TextDataLoader(it, self.text_fld, self.label_fld)\n\n    @classmethod\n    def from_splits(cls, path, splits, bs, text_name=\'text\', label_name=\'label\'):\n        text_fld = splits[0].fields[text_name]\n        label_fld = splits[0].fields[label_name]\n        if hasattr(label_fld, \'build_vocab\'): label_fld.build_vocab(splits[0])\n        iters = torchtext.data.BucketIterator.splits(splits, batch_size=bs)\n        trn_iter,val_iter,test_iter = iters[0],iters[1],None\n        test_dl = None\n        if len(iters) == 3:\n            test_iter = iters[2]\n            test_dl = TextDataLoader(test_iter, text_name, label_name)\n        trn_dl = TextDataLoader(trn_iter, text_name, label_name)\n        val_dl = TextDataLoader(val_iter, text_name, label_name)\n        obj = cls.from_dls(path, trn_dl, val_dl, test_dl)\n        obj.bs = bs\n        obj.pad_idx = text_fld.vocab.stoi[text_fld.pad_token]\n        obj.nt = len(text_fld.vocab)\n        obj.c = (len(label_fld.vocab) if hasattr(label_fld, \'vocab\')\n                 else len(getattr(splits[0][0], label_name)))\n        return obj\n\n    def to_model(self, m, opt_fn):\n        model = TextModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    def get_model(self, opt_fn, max_sl, bptt, emb_sz, n_hid, n_layers, dropout, **kwargs):\n        m = get_rnn_classifer(bptt, max_sl, self.c, self.nt,\n              layers=[emb_sz*3, self.c], drops=[dropout],\n              emb_sz=emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=self.pad_idx, **kwargs)\n        return self.to_model(m, opt_fn)\n\n'"
fastai/courses/dl2/fastai/plots.py,0,"b'from .imports import *\nfrom .torch_imports import *\nfrom sklearn.metrics import confusion_matrix\n\ndef ceildiv(a, b):\n    return -(-a // b)\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None, maintitle=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None:\n        plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else \'none\')\n\n\ndef plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n    """"""Plots images given image files.\n\n    Arguments:\n        im_paths (list): list of paths\n        figsize (tuple): figure size\n        rows (int): number of rows\n        titles (list): list of titles\n        maintitle (string): main title\n    """"""\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(imspaths)):\n        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        img = plt.imread(imspaths[i])\n        plt.imshow(img)\n\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title=\'Confusion matrix\', cmap=plt.cm.Blues, figsize=None):\n    """"""\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    (This function is copied from the scikit docs.)\n    """"""\n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize: cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=""center"", color=""white"" if cm[i, j] > thresh else ""black"")\n\n    plt.tight_layout()\n    plt.ylabel(\'True label\')\n    plt.xlabel(\'Predicted label\')\n\ndef plots_raw(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])\n\ndef load_img_id(ds, idx, path): return np.array(PIL.Image.open(os.path.join(path, ds.fnames[idx])))\n\n\nclass ImageModelResults():\n    """""" Visualize the results of an image model\n\n    Arguments:\n        ds (dataset): a dataset which contains the images\n        log_preds (numpy.ndarray): predictions for the dataset in log scale\n\n    Returns:\n        ImageModelResults\n    """"""\n    def __init__(self, ds, log_preds):\n        """"""Initialize an ImageModelResults class instance""""""\n        self.ds = ds\n        # returns the indices of the maximum value of predictions along axis 1, representing the predicted class\n        # log_preds.shape = (number_of_samples, number_of_classes);\n        # preds.shape = (number_of_samples,)\n        self.preds = np.argmax(log_preds, axis=1)\n        # computes the probabilities\n        self.probs = np.exp(log_preds)\n        # extracts the number of classes\n        self.num_classes = log_preds.shape[1]\n\n    def plot_val_with_title(self, idxs, y):\n        """""" Displays the images and their probabilities of belonging to a certain class\n\n            Arguments:\n                idxs (numpy.ndarray): indexes of the image samples from the dataset\n                y (int): the selected class\n\n            Returns:\n                Plots the images in n rows [rows = n]\n        """"""\n        # if there are any samples to be displayed\n        if len(idxs) > 0:\n            imgs = np.stack([self.ds[x][0] for x in idxs])\n            title_probs = [self.probs[x,y] for x in idxs]\n\n            return plots(self.ds.denorm(imgs), rows=1, titles=title_probs)\n        # if idxs is empty return false\n        else:\n            return False;\n\n    def most_by_mask(self, mask, y, mult):\n        """""" Extracts the first 4 most correct/incorrect indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n                mult (int): sets the ordering; -1 descending, 1 ascending\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        cnt = min(4, len(idxs))\n        return idxs[np.argsort(mult * self.probs[idxs,y])[:cnt]]\n\n    def most_uncertain_by_mask(self, mask, y):\n        """""" Extracts the first 4 most uncertain indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        # the most uncertain samples will have abs(probs-1/num_classes) close to 0;\n        return idxs[np.argsort(np.abs(self.probs[idxs,y]-(1/self.num_classes)))[:4]]\n\n    def most_by_correct(self, y, is_correct):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        # mult=-1 when the is_correct flag is true -> when we want to display the most correct classes we will make a descending sorting (argsort) because we want that the biggest probabilities to be displayed first.\n        # When is_correct is false, we want to display the most incorrect classes, so we want an ascending sorting since our interest is in the smallest probabilities.\n        mult = -1 if is_correct==True else 1\n        return self.most_by_mask(((self.preds == self.ds.y)==is_correct)\n                                 & (self.ds.y == y), y, mult)\n\n    def plot_by_correct(self, y, is_correct):\n        """""" Plots the images which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n        """"""\n        return self.plot_val_with_title(self.most_by_correct(y, is_correct), y)\n\n    def most_by_uncertain(self, y):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and have probabilities nearest to 1/number_of_classes (eg. 0.5 for 2 classes, 0.33 for 3 classes) for the selected class.\n\n            Arguments:\n                y (int): the selected class\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        return self.most_uncertain_by_mask((self.ds.y == y), y)\n\n    def plot_most_correct(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most correct.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, True)\n    def plot_most_incorrect(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most incorrect.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, False)\n    def plot_most_uncertain(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most uncertain i.e have probabilities nearest to 1/number_of_classes.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_val_with_title(self.most_by_uncertain(y), y)\n'"
fastai/courses/dl2/fastai/rnn_reg.py,16,"b'from .torch_imports import *\nfrom .core import *\nfrom functools import wraps\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef dropout_mask(x, sz, dropout):\n    """""" Applies a dropout mask whose size is determined by passed argument \'sz\'.\n    Args:\n        x (nn.Variable): A torch Variable object\n        sz (tuple(int, int, int)): The expected size of the new tensor\n        dropout (float): The dropout fraction to apply\n\n    This method uses the bernoulli distribution to decide which activations to keep.\n    Additionally, the sampled activations is rescaled is using the factor 1/(1 - dropout).\n\n    In the example given below, one can see that approximately .8 fraction of the\n    returned tensors are zero. Rescaling with the factor 1/(1 - 0.8) returns a tensor\n    with 5\'s in the unit places.\n\n    The official link to the pytorch bernoulli function is here:\n        http://pytorch.org/docs/master/torch.html#torch.bernoulli\n\n    Examples:\n        >>> a_Var = torch.autograd.Variable(torch.Tensor(2, 3, 4).uniform_(0, 1), requires_grad=False)\n        >>> a_Var\n            Variable containing:\n            (0 ,.,.) =\n              0.6890  0.5412  0.4303  0.8918\n              0.3871  0.7944  0.0791  0.5979\n              0.4575  0.7036  0.6186  0.7217\n            (1 ,.,.) =\n              0.8354  0.1690  0.1734  0.8099\n              0.6002  0.2602  0.7907  0.4446\n              0.5877  0.7464  0.4257  0.3386\n            [torch.FloatTensor of size 2x3x4]\n        >>> a_mask = dropout_mask(a_Var.data, (1,a_Var.size(1),a_Var.size(2)), dropout=0.8)\n        >>> a_mask\n            (0 ,.,.) =\n              0  5  0  0\n              0  0  0  5\n              5  0  5  0\n            [torch.FloatTensor of size 1x3x4]\n    """"""\n    return x.new(*sz).bernoulli_(1-dropout)/(1-dropout)\n\n\nclass LockedDropout(nn.Module):\n    def __init__(self, p=0.5):\n        super().__init__()\n        self.p=p\n\n    def forward(self, x):\n        if not self.training or not self.p: return x\n        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n        return Variable(m, requires_grad=False) * x\n\n\nclass WeightDrop(torch.nn.Module):\n    """"""A custom torch layer that serves as a wrapper on another torch layer.\n    Primarily responsible for updating the weights in the wrapped module based\n    on a specified dropout.\n    """"""\n    def __init__(self, module, dropout, weights=[\'weight_hh_l0\']):\n        """""" Default constructor for the WeightDrop module\n\n        Args:\n            module (torch.nn.Module): A pytorch layer being wrapped\n            dropout (float): a dropout value to apply\n            weights (list(str)): the parameters of the wrapped **module**\n                which should be fractionally dropped.\n        """"""\n        super().__init__()\n        self.module,self.weights,self.dropout = module,weights,dropout\n        self._setup()\n\n    def _setup(self):\n        """""" for each string defined in self.weights, the corresponding\n        attribute in the wrapped module is referenced, then deleted, and subsequently\n        registered as a new parameter with a slightly modified name.\n\n        Args:\n            None\n\n         Returns:\n             None\n        """"""\n        if isinstance(self.module, torch.nn.RNNBase): self.module.flatten_parameters = noop\n        for name_w in self.weights:\n            w = getattr(self.module, name_w)\n            del self.module._parameters[name_w]\n            self.module.register_parameter(name_w + \'_raw\', nn.Parameter(w.data))\n\n\n    def _setweights(self):\n        """""" Uses pytorch\'s built-in dropout function to apply dropout to the parameters of\n        the wrapped module.\n\n        Args:\n            None\n        Returns:\n            None\n        """"""\n        for name_w in self.weights:\n            raw_w = getattr(self.module, name_w + \'_raw\')\n            w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n            setattr(self.module, name_w, w)\n\n    def forward(self, *args):\n        """""" updates weights and delegates the propagation of the tensor to the wrapped module\'s\n        forward method\n\n        Args:\n            *args: supplied arguments\n\n        Returns:\n            tensor obtained by running the forward method on the wrapped module.\n        """"""\n        self._setweights()\n        return self.module.forward(*args)\n\nclass EmbeddingDropout(nn.Module):\n\n    """""" Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\n    Uses the dropout_mask custom layer to achieve this.\n\n    Args:\n        embed (torch.nn.Embedding): An embedding torch layer\n        words (torch.nn.Variable): A torch variable\n        dropout (float): dropout fraction to apply to the embedding weights\n        scale (float): additional scaling to apply to the modified embedding weights\n\n    Returns:\n        tensor of size: (batch_size x seq_length x embedding_size)\n\n    Example:\n\n    >> embed = torch.nn.Embedding(10,3)\n    >> words = Variable(torch.LongTensor([[1,2,4,5] ,[4,3,2,9]]))\n    >> words.size()\n        (2,4)\n    >> embed_dropout_layer = EmbeddingDropout(embed)\n    >> dropout_out_ = embed_dropout_layer(embed, words, dropout=0.40)\n    >> dropout_out_\n        Variable containing:\n        (0 ,.,.) =\n          1.2549  1.8230  1.9367\n          0.0000 -0.0000  0.0000\n          2.2540 -0.1299  1.5448\n          0.0000 -0.0000 -0.0000\n\n        (1 ,.,.) =\n          2.2540 -0.1299  1.5448\n         -4.0457  2.4815 -0.2897\n          0.0000 -0.0000  0.0000\n          1.8796 -0.4022  3.8773\n        [torch.FloatTensor of size 2x4x3]\n    """"""\n\n    def __init__(self, embed):\n        super().__init__()\n        self.embed = embed\n\n    def forward(self, words, dropout=0.1, scale=None):\n        if dropout:\n            size = (self.embed.weight.size(0),1)\n            mask = Variable(dropout_mask(self.embed.weight.data, size, dropout))\n            masked_embed_weight = mask * self.embed.weight\n        else: masked_embed_weight = self.embed.weight\n\n        if scale: masked_embed_weight = scale * masked_embed_weight\n\n        padding_idx = self.embed.padding_idx\n        if padding_idx is None: padding_idx = -1\n\n        \n        if IS_TORCH_04:\n            X = F.embedding(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n        else:\n            X = self.embed._backend.Embedding.apply(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n\n        return X\n'"
fastai/courses/dl2/fastai/rnn_train.py,2,b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom .core import *\n\n'
fastai/courses/dl2/fastai/set_spawn.py,0,"b""from multiprocessing import set_start_method\nset_start_method('spawn')\n\n"""
fastai/courses/dl2/fastai/sgdr.py,1,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\nimport copy\n\n\nclass Callback:\n    \'\'\'\n    An abstract class that all callback(e.g., LossRecorder) classes extends from. \n    Must be extended before usage.\n    \'\'\'\n    def on_train_begin(self): pass\n    def on_batch_begin(self): pass\n    def on_phase_begin(self): pass\n    def on_epoch_end(self, metrics): pass\n    def on_phase_end(self): pass\n    def on_batch_end(self, metrics): pass\n    def on_train_end(self): pass\n\n# Useful for maintaining status of a long-running job.\n# \n# Usage:\n# learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\nclass LoggingCallback(Callback):\n    \'\'\'\n    A class useful for maintaining status of a long-running job.\n    e.g.: learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\n    \'\'\'\n    def __init__(self, save_path):\n        super().__init__()\n        self.save_path=save_path\n    def on_train_begin(self):\n        self.batch = 0\n        self.epoch = 0\n        self.phase = 0\n        self.f = open(self.save_path, ""a"", 1)\n        self.log(""\\ton_train_begin"")\n    def on_batch_begin(self):\n        self.log(str(self.batch)+""\\ton_batch_begin"")\n    def on_phase_begin(self):\n        self.log(str(self.phase)+""\\ton_phase_begin"")\n    def on_epoch_end(self, metrics):\n        self.log(str(self.epoch)+""\\ton_epoch_end: ""+str(metrics))\n        self.epoch += 1\n    def on_phase_end(self):\n        self.log(str(self.phase)+""\\ton_phase_end"")\n        self.phase+=1\n    def on_batch_end(self, metrics):\n        self.log(str(self.batch)+""\\ton_batch_end: ""+str(metrics))\n        self.batch += 1\n    def on_train_end(self):\n        self.log(""\\ton_train_end"")\n        self.f.close()\n    def log(self, string):\n        self.f.write(time.strftime(""%Y-%m-%dT%H:%M:%S"")+""\\t""+string+""\\n"")\n        \nclass LossRecorder(Callback):\n    \'\'\'\n    Saves and displays loss functions and other metrics. \n    Default sched when none is specified in a learner. \n    \'\'\'\n    def __init__(self, layer_opt, save_path=\'\', record_mom=False, metrics=[]):\n        super().__init__()\n        self.layer_opt=layer_opt\n        self.init_lrs=np.array(layer_opt.lrs)\n        self.save_path, self.record_mom, self.metrics = save_path, record_mom, metrics\n\n    def on_train_begin(self):\n        self.losses,self.lrs,self.iterations = [],[],[]\n        self.val_losses, self.rec_metrics = [], []\n        if self.record_mom:\n            self.momentums = []\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n        self.save_metrics(metrics)\n\n    def on_batch_end(self, loss):\n        self.iteration += 1\n        self.lrs.append(self.layer_opt.lr)\n        self.iterations.append(self.iteration)\n        if isinstance(loss, list):\n            self.losses.append(loss[0])\n            self.save_metrics(loss[1:])\n        else: self.losses.append(loss)\n        if self.record_mom: self.momentums.append(self.layer_opt.mom)\n\n    def save_metrics(self,vals):\n        self.val_losses.append(vals[0][0] if isinstance(vals[0], Iterable) else vals[0])\n        if len(vals) > 2: self.rec_metrics.append(vals[1:])\n        elif len(vals) == 2: self.rec_metrics.append(vals[1])\n\n    def plot_loss(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        plots loss function as function of iterations. \n        When used in Jupyternotebook, plot will be displayed in notebook. Else, plot will be displayed in console and both plot and loss are saved in save_path. \n        \'\'\'\n        if not in_ipynb(): plt.switch_backend(\'agg\')\n        plt.plot(self.iterations[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'loss_plot.png\'))\n            np.save(os.path.join(self.save_path, \'losses.npy\'), self.losses[10:])\n\n    def plot_lr(self):\n        \'\'\'Plots learning rate in jupyter notebook or console, depending on the enviroment of the learner.\'\'\'\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        if self.record_mom:\n            fig, axs = plt.subplots(1,2,figsize=(12,4))\n            for i in range(0,2): axs[i].set_xlabel(\'iterations\')\n            axs[0].set_ylabel(\'learning rate\')\n            axs[1].set_ylabel(\'momentum\')\n            axs[0].plot(self.iterations,self.lrs)\n            axs[1].plot(self.iterations,self.momentums)   \n        else:\n            plt.xlabel(""iterations"")\n            plt.ylabel(""learning rate"")\n            plt.plot(self.iterations, self.lrs)\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n\n\nclass LR_Updater(LossRecorder):\n    \'\'\'\n    Abstract class where all Learning Rate updaters inherit from. (e.g., CirularLR)\n    Calculates and updates new learning rate and momentum at the end of each batch. \n    Have to be extended. \n    \'\'\'\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n\n    def on_batch_end(self, loss):\n        res = super().on_batch_end(loss)\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n        return res\n\n    def update_lr(self):\n        new_lrs = self.calc_lr(self.init_lrs)\n        self.layer_opt.set_lrs(new_lrs)\n    \n    def update_mom(self):\n        new_mom = self.calc_mom()\n        self.layer_opt.set_mom(new_mom)\n\n    @abstractmethod\n    def calc_lr(self, init_lrs): raise NotImplementedError\n    \n    @abstractmethod\n    def calc_mom(self): raise NotImplementedError\n\n\nclass LR_Finder(LR_Updater):\n    \'\'\'\n    Helps you find an optimal learning rate for a model, as per suggetion of 2015 CLR paper. \n    Learning rate is increased in linear or log scale, depending on user input, and the result of the loss funciton is retained and can be plotted later. \n    \'\'\'\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics = []):\n        self.linear, self.stop_dv = linear, True\n        ratio = end_lr/layer_opt.lr\n        self.lr_mult = (ratio/nb) if linear else ratio**(1/nb)\n        super().__init__(layer_opt,metrics=metrics)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.best=1e9\n\n    def calc_lr(self, init_lrs):\n        mult = self.lr_mult*self.iteration if self.linear else self.lr_mult**self.iteration\n        return init_lrs * mult\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_dv and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        return super().on_batch_end(metrics)\n\n    def plot(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        Plots the loss function with respect to learning rate, in log scale. \n        \'\'\'\n        plt.ylabel(""loss"")\n        plt.xlabel(""learning rate (log scale)"")\n        plt.plot(self.lrs[n_skip:-(n_skip_end+1)], self.losses[n_skip:-(n_skip_end+1)])\n        plt.xscale(\'log\')\n\nclass LR_Finder2(LR_Finder):\n    """"""\n        A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n    """"""\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics=[], stop_dv=True):\n        self.nb, self.metrics = nb, metrics\n        super().__init__(layer_opt, nb, end_lr, linear, metrics)\n        self.stop_dv = stop_dv\n\n    def on_batch_end(self, loss):\n        if self.iteration == self.nb:\n            return True\n        return super().on_batch_end(loss)\n\n    def plot(self, n_skip=10, n_skip_end=5, smoothed=True):\n        if self.metrics is None: self.metrics = []\n        n_plots = len(self.metrics)+2\n        fig, axs = plt.subplots(n_plots,figsize=(6,4*n_plots))\n        for i in range(0,n_plots): axs[i].set_xlabel(\'learning rate\')\n        axs[0].set_ylabel(\'training loss\')\n        axs[1].set_ylabel(\'validation loss\')\n        for i,m in enumerate(self.metrics): \n            axs[i+2].set_ylabel(m.__name__)\n            if len(self.metrics) == 1:\n                values = self.rec_metrics\n            else:\n                values = [rec[i] for rec in self.rec_metrics]\n            if smoothed: values = smooth_curve(values,0.98)\n            axs[i+2].plot(self.lrs[n_skip:-n_skip_end], values[n_skip:-n_skip_end])\n        plt_val_l = smooth_curve(self.val_losses, 0.98) if smoothed else self.val_losses\n        axs[0].plot(self.lrs[n_skip:-n_skip_end],self.losses[n_skip:-n_skip_end])\n        axs[1].plot(self.lrs[n_skip:-n_skip_end],plt_val_l[n_skip:-n_skip_end])\n\nclass CosAnneal(LR_Updater):\n    \'\'\' Learning rate scheduler that inpelements a cosine annealation schedule. \'\'\'\n    def __init__(self, layer_opt, nb, on_cycle_end=None, cycle_mult=1):\n        self.nb,self.on_cycle_end,self.cycle_mult = nb,on_cycle_end,cycle_mult\n        super().__init__(layer_opt)\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.iteration<self.nb/20:\n            self.cycle_iter += 1\n            return init_lrs/100.\n\n        cos_out = np.cos(np.pi*(self.cycle_iter)/self.nb) + 1\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            self.nb *= self.cycle_mult\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return init_lrs / 2 * cos_out\n\n\nclass CircularLR(LR_Updater):\n    \'\'\'\n    An learning rate updater that implements the CirularLearningRate (CLR) scheme. \n    Learning rate is increased then decreased linearly. \n    \'\'\'\n    def __init__(self, layer_opt, nb, div=4, cut_div=8, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.cut_div,self.on_cycle_end = nb,div,cut_div,on_cycle_end\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = 1 - (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = self.cycle_iter/cut_pt\n        res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n    \n    def calc_mom(self):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = 1 - self.cycle_iter/cut_pt\n        res = self.moms[1] + pct * (self.moms[0] - self.moms[1])\n        return res\n\nclass CircularLR_beta(LR_Updater):\n    def __init__(self, layer_opt, nb, div=10, pct=10, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.pct,self.on_cycle_end = nb,div,pct,on_cycle_end\n        self.cycle_nb = int(nb * (1-pct/100) / 2)\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.cycle_iter>2 * self.cycle_nb:\n            pct = (self.cycle_iter - 2*self.cycle_nb)/(self.nb - 2*self.cycle_nb)\n            res = init_lrs * (1 + (pct * (1-100)/100)) / self.div\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n\n    def calc_mom(self):\n        if self.cycle_iter>2*self.cycle_nb:\n            res = self.moms[0]\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        return res\n\n\nclass SaveBestModel(LossRecorder):\n    \n    """""" Save weights of the best model based during training.\n        If metrics are provided, the first metric in the list is used to\n        find the best model. \n        If no metrics are provided, the loss is used.\n        \n        Args:\n            model: the fastai model\n            lr: indicate to use test images; otherwise use validation images\n            name: the name of filename of the weights without \'.h5\'\n        \n        Usage:\n            Briefly, you have your model \'learn\' variable and call fit.\n            >>> learn.fit(lr, 2, cycle_len=2, cycle_mult=1, best_save_name=\'mybestmodel\')\n            ....\n            >>> learn.load(\'mybestmodel\')\n            \n            For more details see http://forums.fast.ai/t/a-code-snippet-to-save-the-best-model-during-training/12066\n \n    """"""\n    def __init__(self, model, layer_opt, metrics, name=\'best_model\'):\n        super().__init__(layer_opt)\n        self.name = name\n        self.model = model\n        self.best_loss = None\n        self.best_acc = None\n        self.save_method = self.save_when_only_loss if metrics==None else self.save_when_acc\n        \n    def save_when_only_loss(self, metrics):\n        loss = metrics[0]\n        if self.best_loss == None or loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n    \n    def save_when_acc(self, metrics):\n        loss, acc = metrics[0], metrics[1]\n        if self.best_acc == None or acc > self.best_acc:\n            self.best_acc = acc\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        elif acc == self.best_acc and  loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        \n    def on_epoch_end(self, metrics):\n        super().on_epoch_end(metrics)\n        self.save_method(metrics)\n\n\nclass WeightDecaySchedule(Callback):\n    def __init__(self, layer_opt, batch_per_epoch, cycle_len, cycle_mult, n_cycles, norm_wds=False, wds_sched_mult=None):\n        """"""\n        Implements the weight decay schedule as mentioned in https://arxiv.org/abs/1711.05101\n\n        :param layer_opt: The LayerOptimizer\n        :param batch_per_epoch: Num batches in 1 epoch\n        :param cycle_len: Num epochs in initial cycle. Subsequent cycle_len = previous cycle_len * cycle_mult\n        :param cycle_mult: Cycle multiplier\n        :param n_cycles: Number of cycles to be executed\n        """"""\n        super().__init__()\n\n        self.layer_opt = layer_opt\n        self.batch_per_epoch = batch_per_epoch\n        self.init_wds = np.array(layer_opt.wds)  # Weights as set by user\n        self.init_lrs = np.array(layer_opt.lrs)  # Learning rates as set by user\n        self.new_wds = None                      # Holds the new weight decay factors, calculated in on_batch_begin()\n        self.param_groups_old = None             # Caches the old parameter values in on_batch_begin()\n        self.iteration = 0\n        self.epoch = 0\n        self.wds_sched_mult = wds_sched_mult\n        self.norm_wds = norm_wds\n        self.wds_history = list()\n\n        # Pre calculating the number of epochs in the cycle of current running epoch\n        self.epoch_to_num_cycles, i = dict(), 0\n        for cycle in range(n_cycles):\n            for _ in range(cycle_len):\n                self.epoch_to_num_cycles[i] = cycle_len\n                i += 1\n            cycle_len *= cycle_mult\n\n    def on_train_begin(self):\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_batch_begin(self):\n        # Prepare for decay of weights\n\n        # Default weight decay (as provided by user)\n        wdn = self.init_wds\n\n        # Weight decay multiplier (The \'eta\' in the paper). Optional.\n        wdm = 1.0\n        if self.wds_sched_mult is not None:\n            wdm = self.wds_sched_mult(self)\n\n        # Weight decay normalized. Optional.\n        if self.norm_wds:\n            wdn = wdn / np.sqrt(self.batch_per_epoch * self.epoch_to_num_cycles[self.epoch])\n\n        # Final wds\n        self.new_wds = wdm * wdn\n\n        # Record the wds\n        self.wds_history.append(self.new_wds)\n\n        # Set weight_decay with zeros so that it is not applied in Adam, we will apply it outside in on_batch_end()\n        self.layer_opt.set_wds(torch.zeros(self.new_wds.size))\n        # We have to save the existing weights before the optimizer changes the values\n        self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n        self.iteration += 1\n\n    def on_batch_end(self, loss):\n        # Decay the weights\n        for group, group_old, wds in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.new_wds):\n            for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                if p.grad is None:\n                    continue\n                p.data = p.data.add(-wds, p_old.data)\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n\nclass DecayType(IntEnum):\n    \'\'\' Data class, each decay type is assigned a number. \'\'\'\n    NO = 1\n    LINEAR = 2\n    COSINE = 3\n    EXPONENTIAL = 4\n    POLYNOMIAL = 5\n\nclass DecayScheduler():\n    \'\'\'Given initial and endvalue, this class generates the next value depending on decay type and number of iterations. (by calling next_val().) \'\'\'\n\n    def __init__(self, dec_type, num_it, start_val, end_val=None, extra=None):\n        self.dec_type, self.nb, self.start_val, self.end_val, self.extra = dec_type, num_it, start_val, end_val, extra\n        self.it = 0\n        if self.end_val is None and not (self.dec_type in [1,4]): self.end_val = 0\n    \n    def next_val(self):\n        self.it += 1\n        if self.dec_type == DecayType.NO:\n            return self.start_val\n        elif self.dec_type == DecayType.LINEAR:\n            pct = self.it/self.nb\n            return self.start_val + pct * (self.end_val-self.start_val)\n        elif self.dec_type == DecayType.COSINE:\n            cos_out = np.cos(np.pi*(self.it)/self.nb) + 1\n            return self.end_val + (self.start_val-self.end_val) / 2 * cos_out\n        elif self.dec_type == DecayType.EXPONENTIAL:\n            ratio = self.end_val / self.start_val\n            return self.start_val * (ratio **  (self.it/self.nb))\n        elif self.dec_type == DecayType.POLYNOMIAL:\n            return self.end_val + (self.start_val-self.end_val) * (1 - self.it/self.nb)**self.extra\n        \n\nclass TrainingPhase():\n    \'\'\'\n    Object with training information for each phase, when multiple phases are involved during training.  \n    Used in fit_opt_sched in learner.py\n    \'\'\'\n    def __init__(self, epochs=1, opt_fn=optim.SGD, lr=1e-2, lr_decay=DecayType.NO, momentum=0.9,\n                momentum_decay=DecayType.NO, beta=None, wds=None, wd_loss=True):\n        """"""\n        Creates an object containing all the relevant informations for one part of a model training.\n\n        Args\n        epochs: number of epochs to train like this\n        opt_fn: an optimizer (example optim.Adam)\n        lr: one learning rate or a tuple of the form (start_lr,end_lr)\n          each of those can be a list/numpy array for differential learning rates\n        lr_decay: a DecayType object specifying how the learning rate should change\n        momentum: one momentum (or beta1 in case of Adam), or a tuple of the form (start_mom,end_mom)\n        momentum_decay: a DecayType object specifying how the momentum should change\n        beta: beta2 parameter of Adam or alpha parameter of RMSProp\n        wds: weight decay (can be an array for differential wds)\n        """"""\n        self.epochs, self.opt_fn, self.lr, self.momentum, self.beta, self.wds = epochs, opt_fn, lr, momentum, beta, wds\n        if isinstance(lr_decay,tuple): self.lr_decay, self.extra_lr = lr_decay\n        else: self.lr_decay, self.extra_lr = lr_decay, None\n        if isinstance(momentum_decay,tuple): self.mom_decay, self.extra_mom = momentum_decay\n        else: self.mom_decay, self.extra_mom = momentum_decay, None\n        self.wd_loss = wd_loss\n\n    def phase_begin(self, layer_opt, nb_batches):\n        self.layer_opt = layer_opt\n        if isinstance(self.lr, tuple): start_lr,end_lr = self.lr\n        else: start_lr, end_lr = self.lr, None\n        self.lr_sched = DecayScheduler(self.lr_decay, nb_batches * self.epochs, start_lr, end_lr, extra=self.extra_lr)\n        if isinstance(self.momentum, tuple): start_mom,end_mom = self.momentum\n        else: start_mom, end_mom = self.momentum, None\n        self.mom_sched = DecayScheduler(self.mom_decay, nb_batches * self.epochs, start_mom, end_mom, extra=self.extra_mom)\n        self.layer_opt.set_opt_fn(self.opt_fn)\n        self.layer_opt.set_lrs(start_lr)\n        self.layer_opt.set_mom(start_mom)\n        if self.beta is not None: self.layer_opt.set_beta(self.beta)\n        if self.wds is not None:\n            if not isinstance(self.wds, Iterable): self.wds=[self.wds]\n            if len(self.wds)==1: self.wds=self.wds*len(self.layer_opt.layer_groups) \n            if self.wd_loss: self.layer_opt.set_wds(self.wds)\n            else: self.layer_opt.set_wds([0] * len(self.wds))\n    \n    def on_batch_begin(self):\n        if not self.wd_loss: self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n\n    def update(self):\n        new_lr, new_mom = self.lr_sched.next_val(), self.mom_sched.next_val()\n        self.layer_opt.set_lrs(new_lr)\n        self.layer_opt.set_mom(new_mom)\n        if not self.wd_loss: # Decay the weights outside of the loss\n            if not isinstance(new_lr, Iterable): new_lr=[new_lr]\n            if len(new_lr)==1: new_lr=new_lr*len(self.layer_opt.layer_groups)\n            for group, group_old, wds, lr in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.wds, new_lr):\n                for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                    if p.grad is None: continue\n                    p.data = p.data.add(-wds*lr, p_old.data)\n    \n\nclass OptimScheduler(LossRecorder):\n    \'\'\'Learning rate Scheduler for training involving multiple phases.\'\'\'\n\n    def __init__(self, layer_opt, phases, nb_batches, stop_div = False):\n        self.phases, self.nb_batches, self.stop_div = phases, nb_batches, stop_div\n        super().__init__(layer_opt, record_mom=True)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.phase,self.best=0,1e9\n    \n    def on_batch_begin(self):\n        self.phases[self.phase].on_batch_begin()\n        super().on_batch_begin()\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_div and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        super().on_batch_end(metrics)\n        self.phases[self.phase].update()\n    \n    def on_phase_begin(self):\n        self.phases[self.phase].phase_begin(self.layer_opt, self.nb_batches)\n\n    def on_phase_end(self):\n        self.phase += 1\n\n    def plot_lr(self, show_text=True, show_moms=True):\n        """"""Plots the lr rate/momentum schedule""""""\n        phase_limits = [0]\n        for phase in self.phases:\n            phase_limits.append(phase_limits[-1] + self.nb_batches * phase.epochs)\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        np_plts = 2 if show_moms else 1\n        fig, axs = plt.subplots(1,np_plts,figsize=(6*np_plts,4))\n        if not show_moms: axs = [axs]\n        for i in range(np_plts): axs[i].set_xlabel(\'iterations\')\n        axs[0].set_ylabel(\'learning rate\')\n        axs[0].plot(self.iterations,self.lrs)\n        if show_moms:\n            axs[1].set_ylabel(\'momentum\')\n            axs[1].plot(self.iterations,self.momentums)\n        if show_text:   \n            for i, phase in enumerate(self.phases):\n                text = phase.opt_fn.__name__\n                if phase.wds is not None: text+=\'\\nwds=\'+str(phase.wds)\n                if phase.beta is not None: text+=\'\\nbeta=\'+str(phase.beta)\n                for k in range(np_plts):\n                    if i < len(self.phases)-1:\n                        draw_line(axs[k], phase_limits[i+1])\n                    draw_text(axs[k], (phase_limits[i]+phase_limits[i+1])/2, text) \n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n    \n    def plot(self, n_skip=10, n_skip_end=5, linear=None):\n        if linear is None: linear = self.phases[-1].lr_decay == DecayType.LINEAR\n        plt.ylabel(""loss"")\n        plt.plot(self.lrs[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if linear: plt.xlabel(""learning rate"")\n        else:\n            plt.xlabel(""learning rate (log scale)"")\n            plt.xscale(\'log\')\n\ndef draw_line(ax,x):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.plot([x,x],[ymin,ymax], color=\'red\', linestyle=\'dashed\')\n\ndef draw_text(ax,x, text):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.text(x,(ymin+ymax)/2,text, horizontalalignment=\'center\', verticalalignment=\'center\', fontsize=14, alpha=0.5)\n\ndef smooth_curve(vals, beta):\n    avg_val = 0\n    smoothed = []\n    for (i,v) in enumerate(vals):\n        avg_val = beta * avg_val + (1-beta) * v\n        smoothed.append(avg_val/(1-beta**(i+1)))\n    return smoothed\n'"
fastai/courses/dl2/fastai/structured.py,0,"b'from .imports import *\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\n\ndef set_plot_sizes(sml, med, big):\n    plt.rc(\'font\', size=sml)          # controls default text sizes\n    plt.rc(\'axes\', titlesize=sml)     # fontsize of the axes title\n    plt.rc(\'axes\', labelsize=med)    # fontsize of the x and y labels\n    plt.rc(\'xtick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'ytick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'legend\', fontsize=sml)    # legend fontsize\n    plt.rc(\'figure\', titlesize=big)  # fontsize of the figure title\n\ndef parallel_trees(m, fn, n_jobs=8):\n        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    """""" Draws a representation of a random forest in IPython.\n\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    """"""\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub(\'Tree {\',\n       f\'Tree {{ size={size}; ratio={ratio}\', s)))\n\ndef combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = (\'<M8[Y]\', \'<m8[M]\', \'<m8[D]\', \'<m8[W]\', \'<m8[h]\',\n             \'<m8[m]\', \'<m8[s]\', \'<m8[ms]\', \'<m8[us]\', \'<m8[ns]\')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\ndef get_sample(df,n):\n    """""" Gets a random sample of n rows from df, without replacement.\n\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    >>> get_sample(df, 2)\n       col1 col2\n    1     2    b\n    2     3    a\n    """"""\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef add_datepart(df, fldname, drop=True, time=False):\n    """"""add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({ \'A\' : pd.to_datetime([\'3/11/2000\', \'3/12/2000\', \'3/13/2000\'], infer_datetime_format=False) })\n    >>> df\n\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n\n    >>> add_datepart(df, \'A\')\n    >>> df\n\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    """"""\n    fld = df[fldname]\n    if not np.issubdtype(fld.dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub(\'[Dd]ate$\', \'\', fldname)\n    attr = [\'Year\', \'Month\', \'Week\', \'Day\', \'Dayofweek\', \'Dayofyear\',\n            \'Is_month_end\', \'Is_month_start\', \'Is_quarter_end\', \'Is_quarter_start\', \'Is_year_end\', \'Is_year_start\']\n    if time: attr = attr + [\'Hour\', \'Minute\', \'Second\']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + \'Elapsed\'] = fld.astype(np.int64) // 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n\ndef is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n\ndef train_cats(df):\n    """"""Change any columns of strings in a panda\'s dataframe to a column of\n    catagorical values. This applies the changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category\n    """"""\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype(\'category\').cat.as_ordered()\n\ndef apply_cats(df, trn):\n    """"""Changes any columns of strings in df into categorical variables using trn as\n    a template for the category codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values. The category codes are determined by trn.\n\n    trn: A pandas dataframe. When creating a category for df, it looks up the\n        what the category\'s code were in trn and makes those the category codes\n        for df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category {a : 1, b : 2}\n\n    >>> df2 = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'b\', \'a\', \'a\']})\n    >>> apply_cats(df2, df)\n\n           col1 col2\n        0     1    b\n        1     2    a\n        2     3    a\n\n    now the type of col is category {a : 1, b : 2}\n    """"""\n    for n,c in df.items():\n        if (n in trn.columns) and (trn[n].dtype.name==\'category\'):\n            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n\ndef fix_missing(df, col, name, na_dict):\n    """""" Fill missing data in a column of df with the median, and add a {name}_na column\n    which specifies if the data was missing.\n\n    Parameters:\n    -----------\n    df: The data frame that will be changed.\n\n    col: The column of data to fix by filling in missing data.\n\n    name: The name of the new filled column in df.\n\n    na_dict: A dictionary of values to create na\'s of and the value to insert. If\n        name is not a key of na_dict the median will fill any missing data. Also\n        if name is not a key of na_dict and there is no missing data in col, then\n        no {name}_na column is not created.\n\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1     2    2    True\n    2     3    2   False\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col2\'], \'col2\', {})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {\'col1\' : 500})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1   500    2    True\n    2     3    2   False\n    """"""\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+\'_na\'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    """""" Changes the column col from a categorical type to it\'s integer codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. df[name] will be filled with the integer codes from\n        col.\n\n    col: The column you wish to change into the categories.\n    name: The column name you wish to insert into df. This column will hold the\n        integer codes.\n\n    max_n_cat: If col has more categories than max_n_cat it will not change the\n        it to its integer codes. If max_n_cat is None, then col will always be\n        converted.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> numericalize(df, df[\'col2\'], \'col3\', None)\n\n       col1 col2 col3\n    0     1    a    1\n    1     2    b    2\n    2     3    a    1\n    """"""\n    if not is_numeric_dtype(col) and ( max_n_cat is None or col.nunique()>max_n_cat):\n        df[name] = col.cat.codes+1\n\ndef scale_vars(df, mapper):\n    warnings.filterwarnings(\'ignore\', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper\n\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    """""" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n\n    y_fld: The name of the response variable\n\n    skip_flds: A list of fields that dropped from df.\n\n    ignore_flds: A list of fields that are ignored during processing.\n\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n\n    preproc_fn: A function that gets applied to df.\n\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n\n    subset: Takes a random subset of size subset from df.\n\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n\n        y: y is the response variable\n\n        nas: returns a dictionary of which nas it created, and the associated median.\n\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> x, y, nas = proc_df(df, \'col1\')\n    >>> x\n\n       col2\n    0     1\n    1     2\n    2     1\n\n    >>> data = DataFrame(pet=[""cat"", ""dog"", ""dog"", ""fish"", ""cat"", ""dog"", ""cat"", ""fish""],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    """"""\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    df = df.copy()\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({\'cols\':df.columns, \'imp\':m.feature_importances_}\n                       ).sort_values(\'imp\', ascending=False)\n\ndef set_rf_samples(n):\n    """""" Changes Scikit learn\'s random forests to give each tree a random sample of\n    n random rows.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    """""" Undoes the changes produced by set_rf_samples.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\ndef get_nn_mappers(df, cat_vars, contin_vars):\n    # Replace nulls with 0 for continuous, """" for categorical.\n    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n    for v in cat_vars: df[v].fillna(\'#NA#\', inplace=True)\n\n    # list of tuples, containing variable and instance of a transformer for that variable\n    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n    return DataFrameMapper(cat_maps).fit(df), DataFrameMapper(contin_maps).fit(df)\n'"
fastai/courses/dl2/fastai/swa.py,3,"b'""""""\n    From the paper:\n        Averaging Weights Leads to Wider Optima and Better Generalization\n        Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, Andrew Gordon Wilson\n        https://arxiv.org/abs/1803.05407\n        2018\n        \n    Author\'s implementation: https://github.com/timgaripov/swa\n""""""\n\nimport torch\nfrom .sgdr import *\nfrom .core import *\n\n\nclass SWA(Callback):\n    def __init__(self, model, swa_model, swa_start):\n        super().__init__()\n        self.model,self.swa_model,self.swa_start=model,swa_model,swa_start\n        \n    def on_train_begin(self):\n        self.epoch = 0\n        self.swa_n = 0\n\n    def on_epoch_end(self, metrics):\n        if (self.epoch + 1) >= self.swa_start:\n            self.update_average_model()\n            self.swa_n += 1\n            \n        self.epoch += 1\n            \n    def update_average_model(self):\n        # update running average of parameters\n        model_params = self.model.parameters()\n        swa_params = self.swa_model.parameters()\n        for model_param, swa_param in zip(model_params, swa_params):\n            swa_param.data *= self.swa_n\n            swa_param.data += model_param.data\n            swa_param.data /= (self.swa_n + 1)            \n    \ndef collect_bn_modules(module, bn_modules):\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        bn_modules.append(module)\n\ndef fix_batchnorm(swa_model, train_dl):\n    """"""\n    During training, batch norm layers keep track of a running mean and\n    variance of the previous layer\'s activations. Because the parameters\n    of the SWA model are computed as the average of other models\' parameters,\n    the SWA model never sees the training data itself, and therefore has no\n    opportunity to compute the correct batch norm statistics. Before performing \n    inference with the SWA model, we perform a single pass over the training data\n    to calculate an accurate running mean and variance for each batch norm layer.\n    """"""\n    bn_modules = []\n    swa_model.apply(lambda module: collect_bn_modules(module, bn_modules))\n    \n    if not bn_modules: return\n\n    swa_model.train()\n\n    for module in bn_modules:\n        module.running_mean = torch.zeros_like(module.running_mean)\n        module.running_var = torch.ones_like(module.running_var)\n    \n    momenta = [m.momentum for m in bn_modules]\n\n    inputs_seen = 0\n\n    for (*x,y) in iter(train_dl):        \n        xs = V(x)\n        batch_size = xs[0].size(0)\n\n        momentum = batch_size / (inputs_seen + batch_size)\n        for module in bn_modules:\n            module.momentum = momentum\n                            \n        res = swa_model(*xs)        \n        \n        inputs_seen += batch_size\n                \n    for module, momentum in zip(bn_modules, momenta):\n        module.momentum = momentum    '"
fastai/courses/dl2/fastai/text.py,1,"b'from .core import *\nfrom .learner import *\nfrom .lm_rnn import *\nfrom torch.utils.data.sampler import Sampler\nimport spacy\nfrom spacy.symbols import ORTH\n\nre_tok = re.compile(f\'([{string.punctuation}\xe2\x80\x9c\xe2\x80\x9d\xc2\xa8\xc2\xab\xc2\xbb\xc2\xae\xc2\xb4\xc2\xb7\xc2\xba\xc2\xbd\xc2\xbe\xc2\xbf\xc2\xa1\xc2\xa7\xc2\xa3\xe2\x82\xa4\xe2\x80\x98\xe2\x80\x99])\')\ndef tokenize(s): return re_tok.sub(r\' \\1 \', s).split()\n\ndef texts_labels_from_folders(path, folders):\n    texts,labels = [],[]\n    for idx,label in enumerate(folders):\n        for fname in glob(os.path.join(path, label, \'*.*\')):\n            texts.append(open(fname, \'r\').read())\n            labels.append(idx)\n    return texts, np.array(labels).astype(np.int64)\n\ndef numericalize_tok(tokens, max_vocab=50000, min_freq=0, unk_tok=""_unk_"", pad_tok=""_pad_"", bos_tok=""_bos_"", eos_tok=""_eos_""):\n    """"""Takes in text tokens and returns int2tok and tok2int converters\n\n        Arguments:\n        tokens(list): List of tokens. Can be a list of strings, or a list of lists of strings.\n        max_vocab(int): Number of tokens to return in the vocab (sorted by frequency)\n        min_freq(int): Minimum number of instances a token must be present in order to be preserved.\n        unk_tok(str): Token to use when unknown tokens are encountered in the source text.\n        pad_tok(str): Token to use when padding sequences.\n    """"""\n    if isinstance(tokens, str):\n        raise ValueError(""Expected to receive a list of tokens. Received a string instead"")\n    if isinstance(tokens[0], list):\n        tokens = [p for o in tokens for p in o]\n    freq = Counter(tokens)\n    int2tok = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n    unk_id = 3\n    int2tok.insert(0, bos_tok)\n    int2tok.insert(1, pad_tok)\n    int2tok.insert(2, eos_tok)\n    int2tok.insert(unk_id, unk_tok)\n    tok2int = collections.defaultdict(lambda:unk_id, {v:k for k,v in enumerate(int2tok)})\n    return int2tok, tok2int\n\nclass Tokenizer():\n    def __init__(self, lang=\'en\'):\n        self.re_br = re.compile(r\'<\\s*br\\s*/?>\', re.IGNORECASE)\n        self.tok = spacy.load(lang)\n        for w in (\'<eos>\',\'<bos>\',\'<unk>\'):\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\n\n    def sub_br(self,x): return self.re_br.sub(""\\n"", x)\n\n    def spacy_tok(self,x):\n        return [t.text for t in self.tok.tokenizer(self.sub_br(x))]\n\n    re_rep = re.compile(r\'(\\S)(\\1{3,})\')\n    re_word_rep = re.compile(r\'(\\b\\w+\\W+)(\\1{3,})\')\n\n    @staticmethod\n    def replace_rep(m):\n        TK_REP = \'tk_rep\'\n        c,cc = m.groups()\n        return f\' {TK_REP} {len(cc)+1} {c} \'\n\n    @staticmethod\n    def replace_wrep(m):\n        TK_WREP = \'tk_wrep\'\n        c,cc = m.groups()\n        return f\' {TK_WREP} {len(cc.split())+1} {c} \'\n\n    @staticmethod\n    def do_caps(ss):\n        TOK_UP,TOK_SENT,TOK_MIX = \' t_up \',\' t_st \',\' t_mx \'\n        res = []\n        prev=\'.\'\n        re_word = re.compile(\'\\w\')\n        re_nonsp = re.compile(\'\\S\')\n        for s in re.findall(r\'\\w+|\\W+\', ss):\n            res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n    #                 else [TOK_SENT,s.lower()] if (s.istitle() and re_word.search(prev))\n                    else [s.lower()])\n    #         if re_nonsp.search(s): prev = s\n        return \'\'.join(res)\n\n    def proc_text(self, s):\n        s = self.re_rep.sub(Tokenizer.replace_rep, s)\n        s = self.re_word_rep.sub(Tokenizer.replace_wrep, s)\n        s = Tokenizer.do_caps(s)\n        s = re.sub(r\'([/#])\', r\' \\1 \', s)\n        s = re.sub(\' {2,}\', \' \', s)\n        return self.spacy_tok(s)\n\n    @staticmethod\n    def proc_all(ss, lang):\n        tok = Tokenizer(lang)\n        return [tok.proc_text(s) for s in ss]\n\n    @staticmethod\n    def proc_all_mp(ss, lang=\'en\'):\n        ncpus = num_cpus()//2\n        with ProcessPoolExecutor(ncpus) as e:\n            return sum(e.map(Tokenizer.proc_all, ss, [lang]*len(ss)), [])\n\n\nclass TextDataset(Dataset):\n    def __init__(self, x, y, backwards=False, sos=None, eos=None):\n        self.x,self.y,self.backwards,self.sos,self.eos = x,y,backwards,sos,eos\n\n    def __getitem__(self, idx):\n        x = self.x[idx]\n        if self.backwards: x = list(reversed(x))\n        if self.eos is not None: x = x + [self.eos]\n        if self.sos is not None: x = [self.sos]+x\n        return np.array(x),self.y[idx]\n\n    def __len__(self): return len(self.x)\n\n\nclass SortSampler(Sampler):\n    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n    def __len__(self): return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range(len(self.data_source)), key=self.key, reverse=True))\n\n\nclass SortishSampler(Sampler):\n    """"""Returns an iterator that traverses the the data in randomly ordered batches that are approximately the same size.\n    The max key size batch is always returned in the first call because of pytorch cuda memory allocation sequencing.\n    Without that max key returned first multiple buffers may be allocated when the first created isn\'t large enough\n    to hold the next in the sequence.\n    """"""\n    def __init__(self, data_source, key, bs):\n        self.data_source,self.key,self.bs = data_source,key,bs\n\n    def __len__(self): return len(self.data_source)\n\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs*50\n        ck_idx = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n        sort_idx = np.concatenate([sorted(s, key=self.key, reverse=True) for s in ck_idx])\n        sz = self.bs\n        ck_idx = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n        max_ck = np.argmax([ck[0] for ck in ck_idx])  # find the chunk with the largest key,\n        ck_idx[0],ck_idx[max_ck] = ck_idx[max_ck],ck_idx[0]  # then make sure it goes first.\n        sort_idx = np.concatenate(np.random.permutation(ck_idx[1:]))\n        sort_idx = np.concatenate((ck_idx[0], sort_idx))\n        return iter(sort_idx)\n\n\nclass LanguageModelLoader():\n    """""" Returns a language model iterator that iterates through batches that are of length N(bptt,5)\n    The first batch returned is always bptt+25; the max possible width.  This is done because of they way that pytorch\n    allocates cuda memory in order to prevent multiple buffers from being created as the batch width grows.\n    """"""\n    def __init__(self, nums, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        while self.i < self.n-1 and self.iter<len(self):\n            if self.i == 0:\n                seq_len = self.bptt + 5 * 5\n            else:\n                bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n                seq_len = max(5, int(np.random.normal(bptt, 5)))\n            res = self.get_batch(self.i, seq_len)\n            self.i += seq_len\n            self.iter += 1\n            yield res\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def batchify(self, data):\n        nb = data.shape[0] // self.bs\n        data = np.array(data[:nb*self.bs])\n        data = data.reshape(self.bs, -1).T\n        if self.backwards: data=data[::-1]\n        return T(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass LanguageModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [*zip(m.rnns, m.dropouths), (self.model[1], m.dropouti)]\n\n\nclass LanguageModelData():\n    def __init__(self, path, pad_idx, n_tok, trn_dl, val_dl, test_dl=None, **kwargs):\n        self.path,self.pad_idx,self.n_tok = path,pad_idx,n_tok\n        self.trn_dl,self.val_dl,self.test_dl = trn_dl,val_dl,test_dl\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        m = get_language_model(self.n_tok, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = LanguageModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n'"
fastai/courses/dl2/fastai/torch_imports.py,6,"b'import os\nimport torch, torchvision, torchtext\nfrom torch import nn, cuda, backends, FloatTensor, LongTensor, optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.nn.init import kaiming_uniform, kaiming_normal\nfrom torchvision.transforms import Compose\nfrom torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\nfrom torchvision.models import vgg16_bn, vgg19_bn\nfrom torchvision.models import densenet121, densenet161, densenet169, densenet201\n\nfrom .models.resnext_50_32x4d import resnext_50_32x4d\nfrom .models.resnext_101_32x4d import resnext_101_32x4d\nfrom .models.resnext_101_64x4d import resnext_101_64x4d\nfrom .models.wrn_50_2f import wrn_50_2f\nfrom .models.inceptionresnetv2 import InceptionResnetV2\nfrom .models.inceptionv4 import inceptionv4\nfrom .models.nasnet import nasnetalarge\nfrom .models.fa_resnet import *\n\nimport warnings\nwarnings.filterwarnings(\'ignore\', message=\'Implicit dimension choice\', category=UserWarning)\n\ndef children(m): return m if isinstance(m, (list, tuple)) else list(m.children())\ndef save_model(m, p): torch.save(m.state_dict(), p)\ndef load_model(m, p): m.load_state_dict(torch.load(p, map_location=lambda storage, loc: storage))\n\ndef load_pre(pre, f, fn):\n    m = f()\n    path = os.path.dirname(__file__)\n    if pre: load_model(m, f\'{path}/weights/{fn}.pth\')\n    return m\n\ndef _fastai_model(name, paper_title, paper_href):\n    def add_docs_wrapper(f):\n        f.__doc__ = f""""""{name} model from\n        `""{paper_title}"" <{paper_href}>`_\n\n        Args:\n           pre (bool): If True, returns a model pre-trained on ImageNet\n        """"""\n        return f\n    return add_docs_wrapper\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inception_4(pre): return children(inceptionv4(pretrained=pre))[0]\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inceptionresnet_2(pre): return load_pre(pre, InceptionResnetV2, \'inceptionresnetv2-d579a627\')\n\n@_fastai_model(\'ResNeXt 50\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext50(pre): return load_pre(pre, resnext_50_32x4d, \'resnext_50_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_32\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101(pre): return load_pre(pre, resnext_101_32x4d, \'resnext_101_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_64\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101_64(pre): return load_pre(pre, resnext_101_64x4d, \'resnext_101_64x4d\')\n\n@_fastai_model(\'Wide Residual Networks\', \'Wide Residual Networks\',\n               \'https://arxiv.org/pdf/1605.07146.pdf\')\ndef wrn(pre): return load_pre(pre, wrn_50_2f, \'wrn_50_2f\')\n\n@_fastai_model(\'Densenet-121\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn121(pre): return children(densenet121(pre))[0]\n\n@_fastai_model(\'Densenet-169\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn161(pre): return children(densenet161(pre))[0]\n\n@_fastai_model(\'Densenet-161\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn169(pre): return children(densenet169(pre))[0]\n\n@_fastai_model(\'Densenet-201\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn201(pre): return children(densenet201(pre))[0]\n\n@_fastai_model(\'Vgg-16 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg16(pre): return children(vgg16_bn(pre))[0]\n\n@_fastai_model(\'Vgg-19 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg19(pre): return children(vgg19_bn(pre))[0]\n\n'"
fastai/courses/dl2/fastai/transforms.py,0,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\n\ndef scale_min(im, targ, interpolation=cv2.INTER_AREA):\n    """""" Scales the image so that the smallest axis is of size targ.\n\n    Arguments:\n        im (array): image\n        targ (int): target size\n    """"""\n    r,c,*_ = im.shape\n    ratio = targ/min(r,c)\n    sz = (scale_to(c, ratio, targ), scale_to(r, ratio, targ))\n    return cv2.resize(im, sz, interpolation=interpolation)\n\ndef zoom_cv(x,z):\n    \'\'\'zooms the center of image x, by a factor of z+1 while retaining the origal image size and proportion. \'\'\'\n    if z==0: return x\n    r,c,*_ = x.shape\n    M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)\n    return cv2.warpAffine(x,M,(c,r))\n\ndef stretch_cv(x,sr,sc,interpolation=cv2.INTER_AREA):\n    \'\'\'stretches image x horizontally by sr+1, and vertically by sc+1 while retaining the origal image size and proportion.\'\'\'\n    if sr==0 and sc==0: return x\n    r,c,*_ = x.shape\n    x = cv2.resize(x, None, fx=sr+1, fy=sc+1, interpolation=interpolation)\n    nr,nc,*_ = x.shape\n    cr = (nr-r)//2; cc = (nc-c)//2\n    return x[cr:r+cr, cc:c+cc]\n\ndef dihedral(x, dih):\n    \'\'\'performs any of 8 90 rotations or flips for image x.\n    \'\'\'\n    x = np.rot90(x, dih%4)\n    return x if dih<4 else np.fliplr(x)\n\ndef lighting(im, b, c):\n    \'\'\' adjusts image\'s balance and contrast\'\'\'\n    if b==0 and c==1: return im\n    mu = np.average(im)\n    return np.clip((im-mu)*c+mu+b,0.,1.).astype(np.float32)\n\ndef rotate_cv(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n    """""" Rotates an image by deg degrees\n\n    Arguments:\n        deg (float): degree to rotate.\n    """"""\n    r,c,*_ = im.shape\n    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n\ndef no_crop(im, min_sz=None, interpolation=cv2.INTER_AREA):\n    """""" Returns a squared resized image """"""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    return cv2.resize(im, (min_sz, min_sz), interpolation=interpolation)\n\ndef center_crop(im, min_sz=None):\n    """""" Returns a center crop of an image""""""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    start_r = math.ceil((r-min_sz)/2)\n    start_c = math.ceil((c-min_sz)/2)\n    return crop(im, start_r, start_c, min_sz)\n\ndef googlenet_resize(im, targ, min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p, interpolation=cv2.INTER_AREA):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ\n    \n    References:\n    1. https://arxiv.org/pdf/1409.4842.pdf\n    2. https://arxiv.org/pdf/1802.07888.pdf\n    """"""\n    h,w,*_ = im.shape\n    area = h*w\n    for _ in range(10):\n        targetArea = random.uniform(min_area_frac, 1.0) * area\n        aspectR = random.uniform(min_aspect_ratio, max_aspect_ratio)\n        ww = int(np.sqrt(targetArea * aspectR) + 0.5)\n        hh = int(np.sqrt(targetArea / aspectR) + 0.5)\n        if flip_hw_p:\n            ww, hh = hh, ww\n        if hh <= h and ww <= w:\n            x1 = 0 if w == ww else random.randint(0, w - ww)\n            y1 = 0 if h == hh else random.randint(0, h - hh)\n            out = im[y1:y1 + hh, x1:x1 + ww]\n            out = cv2.resize(out, (targ, targ), interpolation=interpolation)\n            return out\n    out = scale_min(im, targ, interpolation=interpolation)\n    out = center_crop(out)\n    return out\n\ndef cutout(im, n_holes, length):\n    \'\'\' cuts out n_holes number of square holes of size length in image at random locations. holes may be overlapping. \'\'\'\n    r,c,*_ = im.shape\n    mask = np.ones((r, c), np.int32)\n    for n in range(n_holes):\n        y = np.random.randint(length / 2, r - length / 2)\n        x = np.random.randint(length / 2, c - length / 2)\n\n        y1 = int(np.clip(y - length / 2, 0, r))\n        y2 = int(np.clip(y + length / 2, 0, r))\n        x1 = int(np.clip(x - length / 2, 0, c))\n        x2 = int(np.clip(x + length / 2, 0, c))\n        mask[y1: y2, x1: x2] = 0.\n    \n    mask = mask[:,:,None]\n    im = im * mask\n    return im\n\ndef scale_to(x, ratio, targ): \n    \'\'\'Calculate dimension of an image during scaling with aspect ratio\'\'\'\n    return max(math.floor(x*ratio), targ)\n\ndef crop(im, r, c, sz): \n    \'\'\'\n    crop image into a square of size sz, \n    \'\'\'\n    return im[r:r+sz, c:c+sz]\n\ndef det_dihedral(dih): return lambda x: dihedral(x, dih)\ndef det_stretch(sr, sc): return lambda x: stretch_cv(x, sr, sc)\ndef det_lighting(b, c): return lambda x: lighting(x, b, c)\ndef det_rotate(deg): return lambda x: rotate_cv(x, deg)\ndef det_zoom(zoom): return lambda x: zoom_cv(x, zoom)\n\ndef rand0(s): return random.random()*(s*2)-s\n\n\nclass TfmType(IntEnum):\n    """""" Type of transformation.\n    Parameters\n        IntEnum: predefined types of transformations\n            NO:    the default, y does not get transformed when x is transformed.\n            PIXEL: x and y are images and should be transformed in the same way.\n                   Example: image segmentation.\n            COORD: y are coordinates (i.e bounding boxes)\n            CLASS: y are class labels (same behaviour as PIXEL, except no normalization)\n    """"""\n    NO = 1\n    PIXEL = 2\n    COORD = 3\n    CLASS = 4\n\n\nclass Denormalize():\n    """""" De-normalizes an image, returning it to original format.\n    """"""\n    def __init__(self, m, s):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n    def __call__(self, x): return x*self.s+self.m\n\n\nclass Normalize():\n    """""" Normalizes an image to zero mean and unit standard deviation, given the mean m and std s of the original image """"""\n    def __init__(self, m, s, tfm_y=TfmType.NO):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n        self.tfm_y=tfm_y\n\n    def __call__(self, x, y=None):\n        x = (x-self.m)/self.s\n        if self.tfm_y==TfmType.PIXEL and y is not None: y = (y-self.m)/self.s\n        return x,y\n\nclass ChannelOrder():\n    \'\'\'\n    changes image array shape from (h, w, 3) to (3, h, w). \n    tfm_y decides the transformation done to the y element. \n    \'\'\'\n    def __init__(self, tfm_y=TfmType.NO): self.tfm_y=tfm_y\n\n    def __call__(self, x, y):\n        x = np.rollaxis(x, 2)\n        #if isinstance(y,np.ndarray) and (len(y.shape)==3):\n        if self.tfm_y==TfmType.PIXEL: y = np.rollaxis(y, 2)\n        elif self.tfm_y==TfmType.CLASS: y = y[...,0]\n        return x,y\n\n\ndef to_bb(YY, y=""deprecated""):\n    """"""Convert mask YY to a bounding box, assumes 0 as background nonzero object""""""\n    cols,rows = np.nonzero(YY)\n    if len(cols)==0: return np.zeros(4, dtype=np.float32)\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n\ndef coords2px(y, x):\n    """""" Transforming coordinates to pixels.\n\n    Arguments:\n        y : np array\n            vector in which (y[0], y[1]) and (y[2], y[3]) are the\n            the corners of a bounding box.\n        x : image\n            an image\n    Returns:\n        Y : image\n            of shape x.shape\n    """"""\n    rows = np.rint([y[0], y[0], y[2], y[2]]).astype(int)\n    cols = np.rint([y[1], y[3], y[1], y[3]]).astype(int)\n    r,c,*_ = x.shape\n    Y = np.zeros((r, c))\n    Y[rows, cols] = 1\n    return Y\n\n\nclass Transform():\n    """""" A class that represents a transform.\n\n    All other transforms should subclass it. All subclasses should override\n    do_transform.\n\n    Arguments\n    ---------\n        tfm_y : TfmType\n            type of transform\n    """"""\n    def __init__(self, tfm_y=TfmType.NO):\n        self.tfm_y=tfm_y\n        self.store = threading.local()\n\n    def set_state(self): pass\n    def __call__(self, x, y):\n        self.set_state()\n        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n                else self.transform_coord(x,y))\n        return x, y\n\n    def transform_coord(self, x, y): return self.transform(x),y\n\n    def transform(self, x, y=None):\n        x = self.do_transform(x,False)\n        return (x, self.do_transform(y,True)) if y is not None else x\n\n    @abstractmethod\n    def do_transform(self, x, is_y): raise NotImplementedError\n\n\nclass CoordTransform(Transform):\n    """""" A coordinate transform.  """"""\n\n    @staticmethod\n    def make_square(y, x):\n        r,c,*_ = x.shape\n        y1 = np.zeros((r, c))\n        y = y.astype(np.int)\n        y1[y[0]:y[2], y[1]:y[3]] = 1.\n        return y1\n\n    def map_y(self, y0, x):\n        y = CoordTransform.make_square(y0, x)\n        y_tr = self.do_transform(y, True)\n        return to_bb(y_tr)\n\n    def transform_coord(self, x, ys):\n        yp = partition(ys, 4)\n        y2 = [self.map_y(y,x) for y in yp]\n        x = self.do_transform(x, False)\n        return x, np.concatenate(y2)\n\n\nclass AddPadding(CoordTransform):\n    """""" A class that represents adding paddings to an image.\n\n    The default padding is border_reflect\n    Arguments\n    ---------\n        pad : int\n            size of padding on top, bottom, left and right\n        mode:\n            type of cv2 padding modes. (e.g., constant, reflect, wrap, replicate. etc. )\n    """"""\n    def __init__(self, pad, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.pad,self.mode = pad,mode\n\n    def do_transform(self, im, is_y):\n        return cv2.copyMakeBorder(im, self.pad, self.pad, self.pad, self.pad, self.mode)\n\nclass CenterCrop(CoordTransform):\n    """""" A class that represents a Center Crop.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        sz: int\n            size of the crop.\n        tfm_y : TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.min_sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        return center_crop(x, self.sz_y if is_y else self.min_sz)\n\n\nclass RandomCrop(CoordTransform):\n    """""" A class that represents a Random Crop transformation.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        targ: int\n            target size of the crop.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, targ_sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz,self.sz_y = targ_sz,sz_y\n\n    def set_state(self):\n        self.store.rand_r = random.uniform(0, 1)\n        self.store.rand_c = random.uniform(0, 1)\n\n    def do_transform(self, x, is_y):\n        r,c,*_ = x.shape\n        sz = self.sz_y if is_y else self.targ_sz\n        start_r = np.floor(self.store.rand_r*(r-sz)).astype(int)\n        start_c = np.floor(self.store.rand_c*(c-sz)).astype(int)\n        return crop(x, start_r, start_c, sz)\n\n\nclass NoCrop(CoordTransform):\n    """"""  A transformation that resize to a square image without cropping.\n\n    This transforms (optionally) resizes x,y at with the same parameters.\n    Arguments:\n        targ: int\n            target size of the crop.\n        tfm_y (TfmType): type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return no_crop(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return no_crop(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass Scale(CoordTransform):\n    """""" A transformation that scales the min size to sz.\n\n    Arguments:\n        sz: int\n            target size to scale minimum size.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass RandomScale(CoordTransform):\n    """""" Scales an image so that the min size is a random number between [sz, sz*max_zoom]\n\n    This transforms (optionally) scales x,y at with the same parameters.\n    Arguments:\n        sz: int\n            target size\n        max_zoom: float\n            float >= 1.0\n        p : float\n            a probability for doing the random sizing\n        tfm_y: TfmType\n            type of y transform\n    """"""\n    def __init__(self, sz, max_zoom, p=0.75, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.max_zoom,self.p,self.sz_y = sz,max_zoom,p,sz_y\n\n    def set_state(self):\n        min_z = 1.\n        max_z = self.max_zoom\n        if isinstance(self.max_zoom, collections.Iterable):\n            min_z, max_z = self.max_zoom\n        self.store.mult = random.uniform(min_z, max_z) if random.random()<self.p else 1\n        self.store.new_sz = int(self.store.mult*self.sz)\n        if self.sz_y is not None: self.store.new_sz_y = int(self.store.mult*self.sz_y)\n\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.store.new_sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.store.new_sz,   cv2.INTER_AREA   )\n\n\nclass RandomRotate(CoordTransform):\n    """""" Rotates images and (optionally) target y.\n\n    Rotating coordinates is treated differently for x and y on this\n    transform.\n     Arguments:\n        deg (float): degree to rotate.\n        p (float): probability of rotation\n        mode: type of border\n        tfm_y (TfmType): type of y transform\n    """"""\n    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.deg,self.p = deg,p\n        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n            self.modes = (mode,cv2.BORDER_CONSTANT)\n        else:\n            self.modes = (mode,mode)\n\n    def set_state(self):\n        self.store.rdeg = rand0(self.deg)\n        self.store.rp = random.random()<self.p\n\n    def do_transform(self, x, is_y):\n        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n                mode= self.modes[1] if is_y else self.modes[0],\n                interpolation=cv2.INTER_NEAREST if is_y else cv2.INTER_AREA)\n        return x\n\n\nclass RandomDihedral(CoordTransform):\n    """"""\n    Rotates images by random multiples of 90 degrees and/or reflection.\n    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n    """"""\n    def set_state(self):\n        self.store.rot_times = random.randint(0,3)\n        self.store.do_flip = random.random()<0.5\n\n    def do_transform(self, x, is_y):\n        x = np.rot90(x, self.store.rot_times)\n        return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomFlip(CoordTransform):\n    def __init__(self, tfm_y=TfmType.NO, p=0.5):\n        super().__init__(tfm_y=tfm_y)\n        self.p=p\n\n    def set_state(self): self.store.do_flip = random.random()<self.p\n    def do_transform(self, x, is_y): return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomLighting(Transform):\n    def __init__(self, b, c, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.b,self.c = b,c\n\n    def set_state(self):\n        self.store.b_rand = rand0(self.b)\n        self.store.c_rand = rand0(self.c)\n\n    def do_transform(self, x, is_y):\n        if is_y and self.tfm_y != TfmType.PIXEL: return x\n        b = self.store.b_rand\n        c = self.store.c_rand\n        c = -1/(c-1) if c<0 else c+1\n        x = lighting(x, b, c)\n        return x\n\nclass RandomRotateZoom(CoordTransform):\n    """""" \n        Selects between a rotate, zoom, stretch, or no transform.\n        Arguments:\n            deg - maximum degrees of rotation.\n            zoom - maximum fraction of zoom.\n            stretch - maximum fraction of stretch.\n            ps - probabilities for each transform. List of length 4. The order for these probabilities is as listed respectively (4th probability is \'no transform\'.\n    """"""\n    def __init__(self, deg, zoom, stretch, ps=None, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        if ps is None: ps = [0.25,0.25,0.25,0.25]\n        assert len(ps) == 4, \'does not have 4 probabilities for p, it has %d\' % len(ps)\n        self.transforms = RandomRotate(deg, p=1, mode=mode, tfm_y=tfm_y), RandomZoom(zoom, tfm_y=tfm_y), RandomStretch(stretch,tfm_y=tfm_y)\n        self.pass_t = PassThru()\n        self.cum_ps = np.cumsum(ps)\n        assert self.cum_ps[3]==1, \'probabilites do not sum to 1; they sum to %d\' % self.cum_ps[3]\n\n    def set_state(self):\n        self.store.trans = self.pass_t\n        self.store.choice = self.cum_ps[3]*random.random()\n        for i in range(len(self.transforms)):\n            if self.store.choice < self.cum_ps[i]:\n                self.store.trans = self.transforms[i]\n                break\n        self.store.trans.set_state()\n\n    def do_transform(self, x, is_y): return self.store.trans.do_transform(x, is_y)\n\nclass RandomZoom(CoordTransform):\n    def __init__(self, zoom_max, zoom_min=0, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.zoom_max, self.zoom_min = zoom_max, zoom_min\n\n    def set_state(self):\n        self.store.zoom = self.zoom_min+(self.zoom_max-self.zoom_min)*random.random()\n\n    def do_transform(self, x, is_y):\n        return zoom_cv(x, self.store.zoom)\n\nclass RandomStretch(CoordTransform):\n    def __init__(self, max_stretch, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.max_stretch = max_stretch\n\n    def set_state(self):\n        self.store.stretch = self.max_stretch*random.random()\n        self.store.stretch_dir = random.randint(0,1)\n\n    def do_transform(self, x, is_y):\n        if self.store.stretch_dir==0: x = stretch_cv(x, self.store.stretch, 0)\n        else:                         x = stretch_cv(x, 0, self.store.stretch)\n        return x\n\nclass PassThru(CoordTransform):\n    def do_transform(self, x, is_y):\n        return x\n\nclass RandomBlur(Transform):\n    """"""\n    Adds a gaussian blur to the image at chance.\n    Multiple blur strengths can be configured, one of them is used by random chance.\n    """"""\n\n    def __init__(self, blur_strengths=5, probability=0.5, tfm_y=TfmType.NO):\n        # Blur strength must be an odd number, because it is used as a kernel size.\n        super().__init__(tfm_y)\n        self.blur_strengths = (np.array(blur_strengths, ndmin=1) * 2) - 1\n        if np.any(self.blur_strengths < 0):\n            raise ValueError(""all blur_strengths must be > 0"")\n        self.probability = probability\n        self.apply_transform = False\n\n    def set_state(self):\n        self.store.apply_transform = random.random() < self.probability\n        kernel_size = np.random.choice(self.blur_strengths)\n        self.store.kernel = (kernel_size, kernel_size)\n\n    def do_transform(self, x, is_y):\n        return cv2.GaussianBlur(src=x, ksize=self.store.kernel, sigmaX=0) if self.apply_transform else x\n\nclass Cutout(Transform):\n    def __init__(self, n_holes, length, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.n_holes,self.length = n_holes,length\n\n    def do_transform(self, img, is_y):\n        return cutout(img, self.n_holes, self.length)\n\nclass GoogleNetResize(CoordTransform):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ \n    \n    Arguments:\n        targ_sz: int\n            target size\n        min_area_frac: float < 1.0\n            minimum area of the original image for cropping\n        min_aspect_ratio : float\n            minimum aspect ratio\n        max_aspect_ratio : float\n            maximum aspect ratio\n        flip_hw_p : float\n            probability for flipping magnitudes of height and width\n        tfm_y: TfmType\n            type of y transform\n    """"""\n\n    def __init__(self, targ_sz,\n                 min_area_frac=0.08, min_aspect_ratio=0.75, max_aspect_ratio=1.333, flip_hw_p=0.5,\n                 tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz, self.tfm_y, self.sz_y = targ_sz, tfm_y, sz_y\n        self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.flip_hw_p = min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p\n\n    def set_state(self):\n        # if self.random_state: random.seed(self.random_state)\n        self.store.fp = random.random()<self.flip_hw_p\n\n    def do_transform(self, x, is_y):\n        sz = self.sz_y if is_y else self.targ_sz\n        if is_y:\n            interpolation = cv2.INTER_NEAREST if self.tfm_y in (TfmType.COORD, TfmType.CLASS) else cv2.INTER_AREA\n        else:\n            interpolation = cv2.INTER_AREA\n        return googlenet_resize(x, sz, self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.store.fp, interpolation=interpolation)\n\n\ndef compose(im, y, fns):\n    """""" apply a collection of transformation functions fns to images\n    """"""\n    for fn in fns:\n        #pdb.set_trace()\n        im, y =fn(im, y)\n    return im if y is None else (im, y)\n\n\nclass CropType(IntEnum):\n    """""" Type of image cropping.\n    """"""\n    RANDOM = 1\n    CENTER = 2\n    NO = 3\n    GOOGLENET = 4\n\ncrop_fn_lu = {CropType.RANDOM: RandomCrop, CropType.CENTER: CenterCrop, CropType.NO: NoCrop, CropType.GOOGLENET: GoogleNetResize}\n\nclass Transforms():\n    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n                 tfm_y=TfmType.NO, sz_y=None):\n        if sz_y is None: sz_y = sz\n        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n        self.tfms = tfms\n        self.tfms.append(crop_tfm)\n        if normalizer is not None: self.tfms.append(normalizer)\n        self.tfms.append(ChannelOrder(tfm_y))\n\n    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n    def __repr__(self): return str(self.tfms)\n\n\ndef image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n    """"""\n    Generate a standard set of transformations\n\n    Arguments\n    ---------\n     normalizer :\n         image normalizing function\n     denorm :\n         image denormalizing function\n     sz :\n         size, sz_y = sz if not specified.\n     tfms :\n         iterable collection of transformation functions\n     max_zoom : float,\n         maximum zoom\n     pad : int,\n         padding on top, left, right and bottom\n     crop_type :\n         crop type\n     tfm_y :\n         y axis specific transformations\n     sz_y :\n         y size, height\n     pad_mode :\n         cv2 padding style: repeat, reflect, etc.\n\n    Returns\n    -------\n     type : ``Transforms``\n         transformer for specified image operations.\n\n    See Also\n    --------\n     Transforms: the transformer object returned by this function\n    """"""\n    if tfm_y is None: tfm_y=TfmType.NO\n    if tfms is None: tfms=[]\n    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n    if sz_y is None: sz_y = sz\n    if scale is None:\n        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n                 else Scale(sz, tfm_y, sz_y=sz_y)]\n    elif not is_listy(scale): scale = [scale]\n    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n                      tfm_y=tfm_y, sz_y=sz_y)\n\ndef noop(x):\n    """"""dummy function for do-nothing.\n    equivalent to: lambda x: x""""""\n    return x\n\ntransforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)]\ntransforms_side_on  = transforms_basic + [RandomFlip()]\ntransforms_top_down = transforms_basic + [RandomDihedral()]\n\nimagenet_stats = A([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n""""""Statistics pertaining to image data from image net. mean and std of the images of each color channel""""""\ninception_stats = A([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\ninception_models = (inception_4, inceptionresnet_2)\n\ndef tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Given the statistics of the training image sets, returns separate training and validation transform functions\n    """"""\n    if aug_tfms is None: aug_tfms=[]\n    tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n    tfm_denorm = Denormalize(*stats) if stats is not None else None\n    val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n    val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n            tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n    trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n            tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n    return trn_tfm, val_tfm\n\n\ndef tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Returns separate transformers of images for training and validation.\n    Transformers are constructed according to the image statistics given b y the model. (See tfms_from_stats)\n\n    Arguments:\n        f_model: model, pretrained or not pretrained\n    """"""\n    stats = inception_stats if f_model in inception_models else imagenet_stats\n    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)\n\n'"
fastai/courses/dl2/fastai/transforms_pil.py,1,"b'import torch\nimport numpy as np\n\n\nclass Cutout(object):\n    """"""Randomly mask out one or more patches from an image.\n\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    """"""\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (Tensor): Tensor image of size (C, H, W).\n        Returns:\n            Tensor: Image with n_holes of dimension length x length cut out of it.\n        """"""\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length / 2, 0, h)\n            y2 = np.clip(y + self.length / 2, 0, h)\n            x1 = np.clip(x - self.length / 2, 0, w)\n            x2 = np.clip(x + self.length / 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n'"
fastai/courses/dl2/fastai/utils.py,0,"b""import math, os, json, sys, re, numpy as np, pickle, PIL, scipy\nfrom PIL import Image\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom operator import itemgetter, attrgetter, methodcaller\nfrom collections import OrderedDict\nimport itertools\nfrom itertools import chain\n\nimport pandas as pd\nfrom numpy.random import random, permutation, randn, normal, uniform, choice\nfrom numpy import newaxis\nfrom scipy import misc, ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.manifold import TSNE\nimport bcolz\n\nfrom IPython.lib.display import FileLink\n\nimport keras\nfrom keras import backend as K\nfrom keras.utils.data_utils import get_file\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\nfrom keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\nfrom keras.layers import Flatten, Dense, Dropout, Lambda\nfrom keras.regularizers import l2, l1\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.layers import deserialize as layer_from_config\nfrom keras.metrics import categorical_crossentropy, categorical_accuracy\nfrom keras.layers.convolutional import *\nfrom keras.preprocessing import image, sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom vgg16 import Vgg16\nnp.set_printoptions(precision=4, linewidth=100)\n\n\nto_bw = np.array([0.299, 0.587, 0.114])\n\ndef gray(img): return np.rollaxis(img, 0, 1).dot(to_bw)\ndef to_plot(img): return np.rollaxis(img, 0, 1).astype(np.uint8)\ndef plot(img): plt.imshow(to_plot(img))\n\ndef floor(x): return int(math.floor(x))\ndef ceil(x): return int(math.ceil(x))\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    \n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n\n\ndef do_clip(arr, mx):\n    clipped = np.clip(arr, (1-mx)/1, mx)\n    return clipped/clipped.sum(axis=1)[:, np.newaxis]\n\n\ndef wrap_config(layer):\n    return {'class_name': layer.__class__.__name__, 'config': layer.get_config()}\n\ndef copy_layer(layer): return layer_from_config(wrap_config(layer))\n\ndef copy_layers(layers): return [copy_layer(layer) for layer in layers]\n\ndef copy_weights(from_layers, to_layers):\n    for from_layer,to_layer in zip(from_layers, to_layers):\n        to_layer.set_weights(from_layer.get_weights())\n\ndef save_array(fname, arr):\n    c=bcolz.carray(arr, rootdir=fname, mode='w')\n    c.flush()\n\ndef load_array(fname): return bcolz.open(fname)[:]\n\ndef get_classes(path):\n    batches = get_batches(path+'train', shuffle=False, batch_size=1)\n    val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n    test_batches = get_batches(path+'test', shuffle=False, batch_size=1)\n    return (val_batches.classes, batches.classes, onehot(val_batches.classes), onehot(batches.classes),\n        val_batches.filenames, batches.filenames, test_batches.filenames)\n\ndef limit_mem():\n    K.get_session().close()\n    cfg = K.tf.ConfigProto()\n    cfg.gpu_options.allow_growth = True\n    K.set_session(K.tf.Session(config=cfg))\n\nclass MixIterator(object):\n    def __init__(self, iters):\n        self.iters = iters\n        self.multi = type(iters) is list\n        if self.multi:\n            self.N = sum([it[0].N for it in self.iters])\n        else:\n            self.N = sum([it.N for it in self.iters])\n\n    def reset(self):\n        for it in self.iters: it.reset()\n\n    def __iter__(self):\n        return self\n\n    def next(self, *args, **kwargs):\n        if self.multi:\n            nexts = [[next(it) for it in o] for o in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n        else:\n            nexts = [next(it) for it in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n"""
fastai/courses/dl2/imdb_scripts/create_toks.py,0,"b'from fastai.text import *\nimport html\nimport fire\n\nBOS = \'xbos\'  # beginning-of-sentence tag\nFLD = \'xfld\'  # data field tag\n\nre1 = re.compile(r\'  +\')\n\n\ndef fixup(x):\n    x = x.replace(\'#39;\', ""\'"").replace(\'amp;\', \'&\').replace(\'#146;\', ""\'"").replace(\n        \'nbsp;\', \' \').replace(\'#36;\', \'$\').replace(\'\\\\n\', ""\\n"").replace(\'quot;\', ""\'"").replace(\n        \'<br />\', ""\\n"").replace(\'\\\\""\', \'""\').replace(\'<unk>\',\'u_n\').replace(\' @.@ \',\'.\').replace(\n        \' @-@ \',\'-\').replace(\'\\\\\', \' \\\\ \')\n    return re1.sub(\' \', html.unescape(x))\n\n\ndef get_texts(df, n_lbls):\n    if len(df.columns) == 1:\n        labels = []\n        texts = f\'\\n{BOS} {FLD} 1 \' + df[0].astype(str)\n        texts = texts.apply(fixup).values.astype(str)\n    else:\n        labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n        texts = f\'\\n{BOS} {FLD} 1 \' + df[n_lbls].astype(str)\n        for i in range(n_lbls+1, len(df.columns)): texts += f\' {FLD} {i-n_lbls} \' + df[i].astype(str)\n        texts = texts.apply(fixup).values.astype(str)\n\n    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n    return tok, list(labels)\n\n\ndef get_all(df, n_lbls):\n    tok, labels = [], []\n    for i, r in enumerate(df):\n        print(i)\n        tok_, labels_ = get_texts(r, n_lbls)\n        tok += tok_;\n        labels += labels_\n    return tok, labels\n\n\ndef create_toks(prefix, pr_abbr, chunksize=24000, n_lbls=1):\n    PATH = f\'data/nlp_clas/{prefix}/\'\n\n    df_trn = pd.read_csv(f\'{PATH}train.csv\', header=None, chunksize=chunksize)\n    df_val = pd.read_csv(f\'{PATH}test.csv\', header=None, chunksize=chunksize)\n    print(prefix)\n\n    os.makedirs(f\'{PATH}tmp\', exist_ok=True)\n    tok_trn, trn_labels = get_all(df_trn, n_lbls)\n    tok_val, val_labels = get_all(df_val, n_lbls)\n\n    np.save(f\'{PATH}tmp/tok_trn.npy\', tok_trn)\n    np.save(f\'{PATH}tmp/tok_val.npy\', tok_val)\n    np.save(f\'{PATH}tmp/lbl_trn.npy\', trn_labels)\n    np.save(f\'{PATH}tmp/lbl_val.npy\', val_labels)\n\n    trn_joined = [\' \'.join(o) for o in tok_trn]\n    mdl_fn = f\'{PATH}tmp/{pr_abbr}_joined.txt\'\n    open(mdl_fn, \'w\', encoding=\'utf-8\').writelines(trn_joined)\n\n\nif __name__ == \'__main__\': fire.Fire(create_toks)\n'"
fastai/courses/dl2/imdb_scripts/tok2id.py,0,"b""from fastai.text import *\nimport html\nimport fire\n\ndef tok2id(prefix, max_vocab=60000, min_freq=1):\n    print(f'prefix {prefix} max_vocab {max_vocab} min_freq {min_freq}')\n    PATH=f'data/nlp_clas/{prefix}/'\n    trn_tok = np.load(f'{PATH}tmp/tok_trn.npy')\n    val_tok = np.load(f'{PATH}tmp/tok_val.npy')\n\n    freq = Counter(p for o in trn_tok for p in o)\n    print(freq.most_common(25))\n    itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n    itos.insert(0, '_pad_')\n    itos.insert(0, '_unk_')\n    stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n    print(len(itos))\n\n    trn_lm = np.array([[stoi[o] for o in p] for p in trn_tok])\n    val_lm = np.array([[stoi[o] for o in p] for p in val_tok])\n\n    np.save(f'{PATH}tmp/trn_ids.npy', trn_lm)\n    np.save(f'{PATH}tmp/val_ids.npy', val_lm)\n    pickle.dump(itos, open(f'{PATH}tmp/itos.pkl', 'wb'))\n\nif __name__ == '__main__': fire.Fire(tok2id)\n\n"""
fastai/courses/dl2/imdb_scripts/train_clas.py,1,"b""import fire\nfrom fastai.text import *\nfrom fastai.lm_rnn import *\n\n\ndef freeze_all_but(learner, n):\n    c=learner.get_layer_groups()\n    for l in c: set_trainable(l, False)\n    set_trainable(c[n], True)\n\n\ndef train_clas(prefix, cuda_id, lm_id='', clas_id=None, bs=64, cl=1, backwards=False, startat=0, unfreeze=True,\n               lr=0.01, dropmult=1.0, pretrain=True, bpe=False, use_clr=True,\n               use_regular_schedule=False, use_discriminative=True, last=False, chain_thaw=False,\n               from_scratch=False, train_file_id=''):\n    if clas_id is None: clas_id = lm_id\n    print(f'prefix {prefix}; cuda_id {cuda_id}; lm_id {lm_id}; clas_id {clas_id}; bs {bs}; cl {cl}; backwards {backwards}; '\n          f'dropmult {dropmult} unfreeze {unfreeze} startat {startat}; pretrain {pretrain}; bpe {bpe}; use_clr {use_clr};'\n          f'use_regular_schedule {use_regular_schedule}; use_discriminative {use_discriminative}; last {last};'\n          f'chain_thaw {chain_thaw}; from_scratch {from_scratch}; train_file_id {train_file_id}')\n    torch.cuda.set_device(cuda_id)\n    PRE = 'bwd_' if backwards else 'fwd_'\n    if bpe: PRE = 'bpe_' + PRE\n    IDS = 'bpe' if bpe else 'ids'\n    if train_file_id != '': train_file_id = f'_{train_file_id}'\n    PATH=f'data/nlp_clas/{prefix}/'\n    if lm_id != '': lm_id += '_'\n    if clas_id != '': clas_id += '_'\n    lm_path=f'{PRE}{lm_id}lm_enc'\n    assert os.path.exists(os.path.join(PATH, 'models', lm_path + '.h5')),\\\n        'Error: %s does not exist.' % os.path.join(PATH, 'models', lm_path + '.h5')\n    bptt,em_sz,nh,nl = 70,400,1150,3\n    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n\n    if backwards:\n        trn_sent = np.load(f'{PATH}tmp/trn_{IDS}{train_file_id}_bwd.npy')\n        val_sent = np.load(f'{PATH}tmp/val_{IDS}_bwd.npy')\n    else:\n        trn_sent = np.load(f'{PATH}tmp/trn_{IDS}{train_file_id}.npy')\n        val_sent = np.load(f'{PATH}tmp/val_{IDS}.npy')\n\n    trn_lbls = np.load(f'{PATH}tmp/lbl_trn{train_file_id}.npy')\n    val_lbls = np.load(f'{PATH}tmp/lbl_val.npy')\n    trn_lbls -= trn_lbls.min()\n    val_lbls -= val_lbls.min()\n    c=int(trn_lbls.max())+1\n\n    if bpe: vs=30002\n    else:\n        itos = pickle.load(open(f'{PATH}tmp/itos.pkl', 'rb'))\n        vs = len(itos)\n\n    trn_ds = TextDataset(trn_sent, trn_lbls)\n    val_ds = TextDataset(val_sent, val_lbls)\n    trn_samp = SortishSampler(trn_sent, key=lambda x: len(trn_sent[x]), bs=bs//2)\n    val_samp = SortSampler(val_sent, key=lambda x: len(val_sent[x]))\n    trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n    val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n    md = ModelData(PATH, trn_dl, val_dl)\n\n    dps = np.array([0.4,0.5,0.05,0.3,0.4])*dropmult\n    #dps = np.array([0.5, 0.4, 0.04, 0.3, 0.6])*dropmult\n    #dps = np.array([0.65,0.48,0.039,0.335,0.34])*dropmult\n    #dps = np.array([0.6,0.5,0.04,0.3,0.4])*dropmult\n\n    m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n              layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n              dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n\n    learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n    learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n    learn.clip=25.\n    learn.metrics = [accuracy]\n\n    lrm = 2.6\n    if use_discriminative:\n        lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n    else:\n        lrs = lr\n    wd = 1e-6\n    if not from_scratch:\n        learn.load_encoder(lm_path)\n    else:\n        print('Training classifier from scratch. LM encoder is not loaded.')\n        use_regular_schedule = True\n\n    if (startat<1) and pretrain and not last and not chain_thaw and not from_scratch:\n        learn.freeze_to(-1)\n        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n                  use_clr=None if use_regular_schedule or not use_clr else (8,3))\n        learn.freeze_to(-2)\n        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n                  use_clr=None if use_regular_schedule or not use_clr else (8, 3))\n        learn.save(f'{PRE}{clas_id}clas_0')\n    elif startat==1:\n        learn.load(f'{PRE}{clas_id}clas_0')\n\n    if chain_thaw:\n        lrs = np.array([0.0001, 0.0001, 0.0001, 0.0001, 0.001])\n        print('Using chain-thaw. Unfreezing all layers one at a time...')\n        n_layers = len(learn.get_layer_groups())\n        print('#\xc2\xa0of layers:', n_layers)\n        # fine-tune last layer\n        learn.freeze_to(-1)\n        print('Fine-tuning last layer...')\n        learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n                  use_clr=None if use_regular_schedule or not use_clr else (8,3))\n        n = 0\n        # fine-tune all layers up to the second-last one\n        while n < n_layers-1:\n            print('Fine-tuning layer #%d.' % n)\n            freeze_all_but(learn, n)\n            learn.fit(lrs, 1, wds=wd, cycle_len=None if use_regular_schedule else 1,\n                      use_clr=None if use_regular_schedule or not use_clr else (8,3))\n            n += 1\n\n    if unfreeze:\n        learn.unfreeze()\n    else:\n        learn.freeze_to(-3)\n\n    if last:\n        print('Fine-tuning only the last layer...')\n        learn.freeze_to(-1)\n\n    if use_regular_schedule:\n        print('Using regular schedule. Setting use_clr=None, n_cycles=cl, cycle_len=None.')\n        use_clr = None\n        n_cycles = cl\n        cl = None\n    else:\n        n_cycles = 1\n    learn.fit(lrs, n_cycles, wds=wd, cycle_len=cl, use_clr=(8,8) if use_clr else None)\n    print('Plotting lrs...')\n    learn.sched.plot_lr()\n    learn.save(f'{PRE}{clas_id}clas_1')\n\nif __name__ == '__main__': fire.Fire(train_clas)\n\n"""
fastai/courses/dl2/imdb_scripts/train_tri_lm.py,2,"b""import fire\nfrom fastai.text import *\nfrom fastai.lm_rnn import *\n\n\nclass EarlyStopping(Callback):\n    def __init__(self, learner, save_path, enc_path=None, patience=5):\n        super().__init__()\n        self.learner=learner\n        self.save_path=save_path\n        self.enc_path=enc_path\n        self.patience=patience\n    def on_train_begin(self):\n        self.best_val_loss=100\n        self.num_epochs_no_improvement=0\n    def on_epoch_end(self, metrics):\n        val_loss = metrics[0]\n        if val_loss < self.best_val_loss:\n            self.best_val_loss = val_loss\n            self.num_epochs_no_improvement = 0\n            self.learner.save(self.save_path)\n            if self.enc_path is not None:\n                self.learner.save_encoder(self.enc_path)\n        else:\n            self.num_epochs_no_improvement += 1\n        if self.num_epochs_no_improvement > self.patience:\n            print(f'Stopping - no improvement after {self.patience+1} epochs')\n            return True\n    def on_train_end(self):\n        print(f'Loading best model from {self.save_path}')\n        self.learner.load(self.save_path)\n\n\ndef train_lm(prefix, cuda_id=0, cl=1, pretrain='wikitext-103-nopl', lm_id='', bs=64,\n             dropmult=1.0, backwards=False, lr=0.4e-3, preload=True, bpe=False, startat=0,\n             use_clr=True, use_regular_schedule=False, use_discriminative=True, notrain=False, joined=False,\n             train_file_id='', early_stopping=False, figshare=False):\n    print(f'prefix {prefix}; cuda_id {cuda_id}; cl {cl}; bs {bs}; backwards {backwards} '\n          f'dropmult {dropmult}; lr {lr}; preload {preload}; bpe {bpe}; startat {startat} '\n          f'pretrain {pretrain}; use_clr {use_clr}; notrain {notrain}; joined {joined} '\n          f'early stopping {early_stopping}, figshare {figshare}')\n\n    assert not (figshare and joined), 'Use either figshare or joined.'\n    torch.cuda.set_device(cuda_id)\n    PRE  = 'bwd_' if backwards else 'fwd_'\n    if bpe: PRE = 'bpe_' + PRE\n    IDS = 'bpe' if bpe else 'ids'\n    if train_file_id != '': train_file_id = f'_{train_file_id}'\n\n    def get_joined_id(): return 'lm_' if joined else ''\n    joined_id = 'fig_' if figshare else get_joined_id()\n    PATH=f'data/nlp_clas/{prefix}/'\n    PRETRAIN_PATH=f'data/nlp_clas/{pretrain}'\n    assert os.path.exists(PRETRAIN_PATH), 'Error: %s does not exist.' % PRETRAIN_PATH\n    PRE_LM_PATH=f'{PRETRAIN_PATH}/models/{PRE}lm_3.h5'\n    assert os.path.exists(PRE_LM_PATH), 'Error: %s does not exist.' % PRE_LM_PATH\n    if lm_id != '': lm_id += '_'\n    lm_path=f'{PRE}{lm_id}lm'\n    enc_path=f'{PRE}{lm_id}lm_enc'\n    bptt=70\n    em_sz,nh,nl = 400,1150,3\n    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n\n    if backwards:\n        trn_lm_path = f'{PATH}tmp/trn_{joined_id}{IDS}{train_file_id}_bwd.npy'\n        val_lm_path = f'{PATH}tmp/val_{joined_id}{IDS}_bwd.npy'\n    else:\n        trn_lm_path = f'{PATH}tmp/trn_{joined_id}{IDS}{train_file_id}.npy'\n        val_lm_path = f'{PATH}tmp/val_{joined_id}{IDS}.npy'\n\n    print(f'Loading {trn_lm_path} and {val_lm_path}')\n    trn_lm = np.load(trn_lm_path)\n    print('Train data shape before concatentation:', trn_lm.shape)\n    if figshare:\n        print('Restricting train data to 15M documents...')\n        trn_lm = trn_lm[:15000000]\n\n    trn_lm = np.concatenate(trn_lm)\n    print('Train data shape after concatentation:', trn_lm.shape)\n    val_lm = np.load(val_lm_path)\n    val_lm = np.concatenate(val_lm)\n\n    if bpe: vs=30002\n    else:\n        itos = pickle.load(open(f'{PATH}tmp/itos.pkl', 'rb'))\n        vs = len(itos)\n\n    trn_dl = LanguageModelLoader(trn_lm, bs, bptt)\n    val_dl = LanguageModelLoader(val_lm, bs, bptt)\n    md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)\n\n    drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*dropmult\n\n    learner = md.get_model(opt_fn, em_sz, nh, nl,\n        dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n    learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n    learner.clip=0.3\n    learner.metrics = [accuracy]\n    wd=1e-7\n\n    lrs = np.array([lr/6,lr/3,lr,lr/2]) if use_discriminative else lr\n    if preload and (startat==0):\n        wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)\n        if bpe: learner.model.load_state_dict(wgts)\n        else:\n            print(f'Using {pretrain} weights...')\n            ew = to_np(wgts['0.encoder.weight'])\n            row_m = ew.mean(0)\n\n            itos2 = pickle.load(open(f'{PRETRAIN_PATH}/tmp/itos.pkl', 'rb'))\n            stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})\n            nw = np.zeros((vs, em_sz), dtype=np.float32)\n            nb = np.zeros((vs,), dtype=np.float32)\n            for i,w in enumerate(itos):\n                r = stoi2[w]\n                if r>=0: nw[i] = ew[r]\n                else:    nw[i] = row_m\n\n            wgts['0.encoder.weight'] = T(nw)\n            wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(nw))\n            wgts['1.decoder.weight'] = T(np.copy(nw))\n            learner.model.load_state_dict(wgts)\n            #learner.freeze_to(-1)\n            #learner.fit(lrs, 1, wds=wd, use_clr=(6,4), cycle_len=1)\n    elif preload:\n        print('Loading LM that was already fine-tuned on the target data...')\n        learner.load(lm_path)\n\n    if not notrain:\n        learner.unfreeze()\n        if use_regular_schedule:\n            print('Using regular schedule. Setting use_clr=None, n_cycles=cl, cycle_len=None.')\n            use_clr = None\n            n_cycles=cl\n            cl=None\n        else:\n            n_cycles=1\n        callbacks = []\n        if early_stopping:\n            callbacks.append(EarlyStopping(learner, lm_path, enc_path, patience=5))\n            print('Using early stopping...')\n        learner.fit(lrs, n_cycles, wds=wd, use_clr=(32,10) if use_clr else None, cycle_len=cl,\n                    callbacks=callbacks)\n        learner.save(lm_path)\n        learner.save_encoder(enc_path)\n    else:\n        print('No more fine-tuning used. Saving original LM...')\n        learner.save(lm_path)\n        learner.save_encoder(enc_path)\n\nif __name__ == '__main__': fire.Fire(train_lm)\n\n"""
fastai/courses/dl2/imdb_scripts/train_tri_wt.py,2,"b""import fire\nfrom fastai.learner import *\nfrom fastai.rnn_reg import *\nfrom fastai.rnn_train import *\nfrom fastai.text import *\nfrom fastai.lm_rnn import *\n\nfrom sampled_sm import *\n\n\ndef train_lm(prefix, cuda_id, cl=1, bs=64, backwards=False, lr=3e-4, startat=0, sampled=True, preload=True):\n    print(f'prefix {prefix}; cuda_id {cuda_id}; cl {cl}; bs {bs}; backwards {backwards} sampled {sampled} '\n          f'lr {lr} startat {startat}')\n    torch.cuda.set_device(cuda_id)\n    PRE  = 'bwd_' if backwards else 'fwd_'\n    PRE2 = PRE\n    PRE2 = 'bwd_'\n    IDS = 'ids'\n    NLPPATH=Path('data/nlp_clas')\n    PATH=NLPPATH / prefix\n    PATH2=NLPPATH / 'wikitext-103_2'\n    bptt=70\n    em_sz,nh,nl = 400,1150,3\n    opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n\n    if backwards:\n        trn_lm = np.load(PATH / f'tmp/trn_{IDS}_bwd.npy')\n        val_lm = np.load(PATH / f'tmp/val_{IDS}_bwd.npy')\n    else:\n        trn_lm = np.load(PATH / f'tmp/trn_{IDS}.npy')\n        val_lm = np.load(PATH / f'tmp/val_{IDS}.npy')\n    trn_lm = np.concatenate(trn_lm)\n    val_lm = np.concatenate(val_lm)\n\n    itos = pickle.load(open(PATH / 'tmp/itos.pkl', 'rb'))\n    vs = len(itos)\n\n    trn_dl = LanguageModelLoader(trn_lm, bs, bptt)\n    val_dl = LanguageModelLoader(val_lm, bs//5 if sampled else bs, bptt)\n    md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)\n\n    tprs = get_prs(trn_lm, vs)\n    drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.5\n    learner,crit = get_learner(drops, 15000, sampled, md, em_sz, nh, nl, opt_fn, tprs)\n    wd=1e-7\n    learner.metrics = [accuracy]\n\n    if (startat<1) and preload:\n        wgts = torch.load(PATH2 / f'models/{PRE2}lm_3.h5', map_location=lambda storage, loc: storage)\n        ew = to_np(wgts['0.encoder.weight'])\n        row_m = ew.mean(0)\n\n        itos2 = pickle.load(open(PATH2 / 'tmp/itos.pkl', 'rb'))\n        stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})\n        nw = np.zeros((vs, em_sz), dtype=np.float32)\n        for i,w in enumerate(itos):\n            r = stoi2[w]\n            nw[i] = ew[r] if r>=0 else row_m\n\n        wgts['0.encoder.weight'] = T(nw)\n        wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(nw))\n        wgts['1.decoder.weight'] = T(np.copy(nw))\n        learner.model.load_state_dict(wgts)\n    elif startat==1: learner.load(f'{PRE}lm_4')\n    learner.metrics = [accuracy]\n\n    lrs = np.array([lr/6,lr/3,lr,lr])\n    #lrs=lr\n\n    learner.unfreeze()\n    learner.fit(lrs, 1, wds=wd, use_clr=(32,10), cycle_len=cl)\n    learner.save(f'{PRE}lm_4')\n    learner.save_encoder(f'{PRE}lm_4_enc')\n\nif __name__ == '__main__': fire.Fire(train_lm)\n\n"""
fastai/courses/dl2/lsun_scripts/lsun-data.py,0,"b""from __future__ import print_function\nfrom tqdm import tqdm\nimport argparse, cv2, lmdb, numpy, os\nfrom os.path import exists, join\n\n__author__ = 'Fisher Yu'\n__email__ = 'fy@cs.princeton.edu'\n__license__ = 'MIT'\n# (Minor edits by Jeremy Howard)\n\n\ndef export_images(db_path, out_dir, flat=False):\n    print('Exporting', db_path, 'to', out_dir)\n    env = lmdb.open(db_path, map_size=1099511627776,\n                    max_readers=100, readonly=True)\n    with env.begin(write=False) as txn:\n        cursor = txn.cursor()\n        for key, val in tqdm(cursor):\n            key = key.decode()\n            if not flat: image_out_dir = join(out_dir, '/'.join(key[:3]))\n            else: image_out_dir = out_dir\n            if not exists(image_out_dir): os.makedirs(image_out_dir)\n            image_out_path = join(image_out_dir, key + '.jpg')\n            with open(image_out_path, 'wb') as fp: fp.write(val)\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('lmdb_path', nargs='+', type=str,\n                        help='The path to the lmdb database folder. '\n                             'Support multiple database paths.')\n    parser.add_argument('--out_dir', type=str, default='')\n    parser.add_argument('--flat', action='store_true',\n                        help='If enabled, the images are imported into output '\n                             'directory directly instead of hierarchical '\n                             'directories.')\n    args = parser.parse_args()\n    lmdb_paths = args.lmdb_path\n    for lmdb_path in lmdb_paths: export_images(lmdb_path, args.out_dir, args.flat)\n\n\nif __name__ == '__main__': main()\n"""
fastai/courses/dl2/lsun_scripts/lsun-download.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nfrom __future__ import print_function, division\nimport argparse\nimport json\nfrom os.path import join\n\nimport subprocess\nfrom six.moves.urllib.request import urlopen\n\n__author__ = \'Fisher Yu\'\n__email__ = \'fy@cs.princeton.edu\'\n__license__ = \'MIT\'\n\n\ndef list_categories(tag):\n    url = \'http://lsun.cs.princeton.edu/htbin/list.cgi?tag=\' + tag\n    f = urlopen(url)\n    return json.loads(f.read())\n\n\ndef download(out_dir, category, set_name, tag):\n    url = \'http://lsun.cs.princeton.edu/htbin/download.cgi?tag={tag}\' \\\n          \'&category={category}&set={set_name}\'.format(**locals())\n    if set_name == \'test\':\n        out_name = \'test_lmdb.zip\'\n    else:\n        out_name = \'{category}_{set_name}_lmdb.zip\'.format(**locals())\n    out_path = join(out_dir, out_name)\n    cmd = [\'curl\', url, \'-o\', out_path]\n    print(\'Downloading\', category, set_name, \'set\')\n    subprocess.call(cmd)\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--tag\', type=str, default=\'latest\')\n    parser.add_argument(\'-o\', \'--out_dir\', default=\'\')\n    parser.add_argument(\'-c\', \'--category\', default=None)\n    args = parser.parse_args()\n\n    categories = list_categories(args.tag)\n    if args.category is None:\n        print(\'Downloading\', len(categories), \'categories\')\n        for category in categories:\n            download(args.out_dir, category, \'train\', args.tag)\n            download(args.out_dir, category, \'val\', args.tag)\n        download(args.out_dir, \'\', \'test\', args.tag)\n    else:\n        if args.category == \'test\':\n            download(args.out_dir, \'\', \'test\', args.tag)\n        elif args.category not in categories:\n            print(\'Error:\', args.category, ""doesn\'t exist in"",\n                  args.tag, \'LSUN release\')\n        else:\n            download(args.out_dir, args.category, \'train\', args.tag)\n            download(args.out_dir, args.category, \'val\', args.tag)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
fastai/courses/ml1/fastai/__init__.py,0,b''
fastai/courses/ml1/fastai/adaptive_softmax.py,1,"b'from .lm_rnn import *\n\nclass AdaptiveSoftmax(nn.Module):\n    def __init__(self, input_size, cutoff):\n        super().__init__()\n        self.input_size,self.cutoff = input_size,cutoff\n        self.output_size = cutoff[0] + len(cutoff) - 1\n        self.head = nn.Linear(input_size, self.output_size)\n        self.tail = nn.ModuleList()\n        for i in range(len(cutoff) - 1):\n            seq = nn.Sequential(nn.Linear(input_size, input_size // 4 ** i, False),\n                nn.Linear(input_size // 4 ** i, cutoff[i + 1] - cutoff[i], False))\n            self.tail.append(seq)\n\n    def reset(self):\n        nn.init.xavier_normal(self.head.weight)\n        for tail in self.tail:\n            nn.init.xavier_normal(tail[0].weight)\n            nn.init.xavier_normal(tail[1].weight)\n\n    def set_target(self, target):\n        self.id = []\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            if mask.sum() > 0:\n                self.id.append(Variable(mask.float().nonzero().squeeze(1)))\n            else: self.id.append(None)\n\n    def forward(self, input):\n        output = [self.head(input)]\n        for i in range(len(self.id)):\n            if self.id[i] is not None:\n                output.append(self.tail[i](input.index_select(0, self.id[i])))\n            else: output.append(None)\n        return output\n\n    def log_prob(self, input):\n        lsm = nn.LogSoftmax().cuda()\n        head_out = self.head(input)\n        batch_size = head_out.size(0)\n        prob = torch.zeros(batch_size, self.cutoff[-1]).cuda()\n        lsm_head = lsm(head_out)\n        prob.narrow(1, 0, self.output_size).add_(lsm_head.narrow(1, 0, self.output_size).data)\n        for i in range(len(self.tail)):\n            pos = self.cutoff[i]\n            i_size = self.cutoff[i + 1] - pos\n            buffer = lsm_head.narrow(1, self.cutoff[0] + i, 1)\n            buffer = buffer.expand(batch_size, i_size)\n            lsm_tail = lsm(self.tail[i](input))\n            prob.narrow(1, pos, i_size).copy_(buffer.data).add_(lsm_tail.data)\n        return prob\n\n\nclass AdaptiveLoss(nn.Module):\n    def __init__(self, cutoff):\n        super().__init__()\n        self.cutoff = cutoff\n        self.criterions = nn.ModuleList([nn.CrossEntropyLoss(size_average=False) for i in self.cutoff])\n\n    def remap_target(self, target):\n        new_target = [target.clone()]\n        for i in range(len(self.cutoff) - 1):\n            mask = target.ge(self.cutoff[i]).mul(target.lt(self.cutoff[i + 1]))\n            new_target[0][mask] = self.cutoff[0] + i\n            if mask.sum() > 0: new_target.append(target[mask].add(-self.cutoff[i]))\n            else: new_target.append(None)\n        return new_target\n\n    def forward(self, input, target):\n        batch_size = input[0].size(0)\n        target = self.remap_target(target.data)\n        output = 0.0\n        for i in range(len(input)):\n            if input[i] is not None:\n                assert(target[i].min() >= 0 and target[i].max() <= input[i].size(1))\n                criterion = self.criterions[i]\n                output += criterion(input[i], Variable(target[i]))\n        output /= batch_size\n        return output\n\n'"
fastai/courses/ml1/fastai/column_data.py,2,"b'from .imports import *\nfrom .torch_imports import *\nfrom .dataset import *\nfrom .learner import *\n\n\nclass PassthruDataset(Dataset):\n    def __init__(self,*args, is_reg=True, is_multi=False):\n        *xs,y=args\n        self.xs,self.y = xs,y\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n    def __getitem__(self, idx): return [o[idx] for o in self.xs] + [self.y[idx]]\n\n    @classmethod\n    def from_data_frame(cls, df, cols_x, col_y, is_reg=True, is_multi=False):\n        cols = [df[o] for o in cols_x+[col_y]]\n        return cls(*cols, is_reg=is_reg, is_multi=is_multi)\n\n\nclass ColumnarDataset(Dataset):\n    def __init__(self, cats, conts, y, is_reg, is_multi):\n        n = len(cats[0]) if cats else len(conts[0])\n        self.cats = np.stack(cats, 1).astype(np.int64) if cats else np.zeros((n,1))\n        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n        self.y = np.zeros((n,1)) if y is None else y\n        if is_reg:\n            self.y =  self.y[:,None]\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n\n    def __getitem__(self, idx):\n        return [self.cats[idx], self.conts[idx], self.y[idx]]\n\n    @classmethod\n    def from_data_frames(cls, df_cat, df_cont, y=None, is_reg=True, is_multi=False):\n        cat_cols = [c.values for n,c in df_cat.items()]\n        cont_cols = [c.values for n,c in df_cont.items()]\n        return cls(cat_cols, cont_cols, y, is_reg, is_multi)\n\n    @classmethod\n    def from_data_frame(cls, df, cat_flds, y=None, is_reg=True, is_multi=False):\n        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y, is_reg, is_multi)\n\n\nclass ColumnarModelData(ModelData):\n    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n            DataLoader(val_ds, bs*2, shuffle=False, num_workers=1), test_dl)\n\n    @classmethod\n    def from_arrays(cls, path, val_idxs, xs, y, is_reg=True, is_multi=False, bs=64, test_xs=None, shuffle=True):\n        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs), is_reg=is_reg, is_multi=is_multi) if test_xs is not None else None\n        return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n                   PassthruDataset(*(val_xs.T), val_y, is_reg=is_reg, is_multi=is_multi),\n                   bs=bs, shuffle=shuffle, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=None):\n        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, None, is_reg, is_multi) if test_df is not None else None\n        return cls(path, ColumnarDataset.from_data_frame(trn_df, cat_flds, trn_y, is_reg, is_multi),\n                    ColumnarDataset.from_data_frame(val_df, cat_flds, val_y, is_reg, is_multi), bs, test_ds=test_ds)\n\n    @classmethod\n    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, is_reg=True, is_multi=False, test_df=None):\n        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=test_df)\n\n    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                    y_range=None, use_bn=False, **kwargs):\n        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn, self.is_reg, self.is_multi)\n        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n\n\ndef emb_init(x):\n    x = x.weight.data\n    sc = 2/(x.size(1)+1)\n    x.uniform_(-sc,sc)\n\n\nclass MixedInputModel(nn.Module):\n    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                 y_range=None, use_bn=False, is_reg=True, is_multi=False):\n        super().__init__()\n        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n        for emb in self.embs: emb_init(emb)\n        n_emb = sum(e.embedding_dim for e in self.embs)\n        self.n_emb, self.n_cont=n_emb, n_cont\n        \n        szs = [n_emb+n_cont] + szs\n        self.lins = nn.ModuleList([\n            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n        self.bns = nn.ModuleList([\n            nn.BatchNorm1d(sz) for sz in szs[1:]])\n        for o in self.lins: kaiming_normal(o.weight.data)\n        self.outp = nn.Linear(szs[-1], out_sz)\n        kaiming_normal(self.outp.weight.data)\n\n        self.emb_drop = nn.Dropout(emb_drop)\n        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n        self.bn = nn.BatchNorm1d(n_cont)\n        self.use_bn,self.y_range = use_bn,y_range\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def forward(self, x_cat, x_cont):\n        if self.n_emb != 0:\n            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n            x = torch.cat(x, 1)\n            x = self.emb_drop(x)\n        if self.n_cont != 0:\n            x2 = self.bn(x_cont)\n            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n        for l,d,b in zip(self.lins, self.drops, self.bns):\n            x = F.relu(l(x))\n            if self.use_bn: x = b(x)\n            x = d(x)\n        x = self.outp(x)\n        if not self.is_reg:\n            if self.is_multi:\n                x = F.sigmoid(x)\n            else:\n                x = F.log_softmax(x)\n        elif self.y_range:\n            x = F.sigmoid(x)\n            x = x*(self.y_range[1] - self.y_range[0])\n            x = x+self.y_range[0]\n        return x\n\n\nclass StructuredLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    def summary(self): return model_summary(self.model, [(self.data.trn_ds.cats.shape[1], ), (self.data.trn_ds.conts.shape[1], )])\n\n\nclass StructuredModel(BasicModel):\n    def get_layer_groups(self):\n        m=self.model\n        return [m.embs, children(m.lins)+children(m.bns), m.outp]\n\n\nclass CollabFilterDataset(Dataset):\n    def __init__(self, path, user_col, item_col, ratings):\n        self.ratings,self.path = ratings.values.astype(np.float32),path\n        self.n = len(ratings)\n        (self.users,self.user2idx,self.user_col,self.n_users) = self.proc_col(user_col)\n        (self.items,self.item2idx,self.item_col,self.n_items) = self.proc_col(item_col)\n        self.min_score,self.max_score = min(ratings),max(ratings)\n        self.cols = [self.user_col,self.item_col,self.ratings]\n\n    @classmethod\n    def from_data_frame(cls, path, df, user_name, item_name, rating_name):\n        return cls(path, df[user_name], df[item_name], df[rating_name])\n\n    @classmethod\n    def from_csv(cls, path, csv, user_name, item_name, rating_name):\n        df = pd.read_csv(os.path.join(path,csv))\n        return cls.from_data_frame(path, df, user_name, item_name, rating_name)\n\n    def proc_col(self,col):\n        uniq = col.unique()\n        name2idx = {o:i for i,o in enumerate(uniq)}\n        return (uniq, name2idx, np.array([name2idx[x] for x in col]), len(uniq))\n\n    def __len__(self): return self.n\n    def __getitem__(self, idx): return [o[idx] for o in self.cols]\n\n    def get_data(self, val_idxs, bs):\n        val, trn = zip(*split_by_idx(val_idxs, *self.cols))\n        return ColumnarModelData(self.path, PassthruDataset(*trn), PassthruDataset(*val), bs)\n\n    def get_model(self, n_factors):\n        model = EmbeddingDotBias(n_factors, self.n_users, self.n_items, self.min_score, self.max_score)\n        return CollabFilterModel(to_gpu(model))\n\n    def get_learner(self, n_factors, val_idxs, bs, **kwargs):\n        return CollabFilterLearner(self.get_data(val_idxs, bs), self.get_model(n_factors), **kwargs)\n\n\ndef get_emb(ni,nf):\n    e = nn.Embedding(ni, nf)\n    e.weight.data.uniform_(-0.05,0.05)\n    return e\n\n\nclass EmbeddingDotBias(nn.Module):\n    def __init__(self, n_factors, n_users, n_items, min_score, max_score):\n        super().__init__()\n        self.min_score,self.max_score = min_score,max_score\n        (self.u, self.i, self.ub, self.ib) = [get_emb(*o) for o in [\n            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n        ]]\n\n    def forward(self, users, items):\n        um = self.u(users)* self.i(items)\n        res = um.sum(1) + self.ub(users).squeeze() + self.ib(items).squeeze()\n        return F.sigmoid(res) * (self.max_score-self.min_score) + self.min_score\n\n\nclass CollabFilterLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n\nclass CollabFilterModel(BasicModel):\n    def get_layer_groups(self): return self.model\n\n'"
fastai/courses/ml1/fastai/conv_learner.py,0,"b'from .core import *\nfrom .layers import *\nfrom .learner import *\nfrom .initializers import *\n\nmodel_meta = {\n    resnet18:[8,6], resnet34:[8,6], resnet50:[8,6], resnet101:[8,6], resnet152:[8,6],\n    vgg16:[0,22], vgg19:[0,22],\n    resnext50:[8,6], resnext101:[8,6], resnext101_64:[8,6],\n    wrn:[8,6], inceptionresnet_2:[-2,9], inception_4:[-1,9],\n    dn121:[0,7], dn161:[0,7], dn169:[0,7], dn201:[0,7],\n}\nmodel_features = {inception_4: 3072, dn121: 2048, dn161: 4416,} # nasnetalarge: 4032*2}\n\nclass ConvnetBuilder():\n    """"""Class representing a convolutional network.\n\n    Arguments:\n        f: a model creation function (e.g. resnet34, vgg16, etc)\n        c (int): size of the last layer\n        is_multi (bool): is multilabel classification?\n            (def here http://scikit-learn.org/stable/modules/multiclass.html)\n        is_reg (bool): is a regression?\n        ps (float or array of float): dropout parameters\n        xtra_fc (list of ints): list of hidden layers with # hidden neurons\n        xtra_cut (int): # layers earlier than default to cut the model, default is 0\n        custom_head : add custom model classes that are inherited from nn.modules at the end of the model\n                      that is mentioned on Argument \'f\' \n    """"""\n\n    def __init__(self, f, c, is_multi, is_reg, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, pretrained=True):\n        self.f,self.c,self.is_multi,self.is_reg,self.xtra_cut = f,c,is_multi,is_reg,xtra_cut\n        if xtra_fc is None: xtra_fc = [512]\n        if ps is None: ps = [0.25]*len(xtra_fc) + [0.5]\n        self.ps,self.xtra_fc = ps,xtra_fc\n\n        if f in model_meta: cut,self.lr_cut = model_meta[f]\n        else: cut,self.lr_cut = 0,0\n        cut-=xtra_cut\n        layers = cut_model(f(pretrained), cut)\n        self.nf = model_features[f] if f in model_features else (num_features(layers)*2)\n        if not custom_head: layers += [AdaptiveConcatPool2d(), Flatten()]\n        self.top_model = nn.Sequential(*layers)\n\n        n_fc = len(self.xtra_fc)+1\n        if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc\n\n        if custom_head: fc_layers = [custom_head]\n        else: fc_layers = self.get_fc_layers()\n        self.n_fc = len(fc_layers)\n        self.fc_model = to_gpu(nn.Sequential(*fc_layers))\n        if not custom_head: apply_init(self.fc_model, kaiming_normal)\n        self.model = to_gpu(nn.Sequential(*(layers+fc_layers)))\n\n    @property\n    def name(self): return f\'{self.f.__name__}_{self.xtra_cut}\'\n\n    def create_fc_layer(self, ni, nf, p, actn=None):\n        res=[nn.BatchNorm1d(num_features=ni)]\n        if p: res.append(nn.Dropout(p=p))\n        res.append(nn.Linear(in_features=ni, out_features=nf))\n        if actn: res.append(actn)\n        return res\n\n    def get_fc_layers(self):\n        res=[]\n        ni=self.nf\n        for i,nf in enumerate(self.xtra_fc):\n            res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())\n            ni=nf\n        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()\n        if self.is_reg: final_actn = None\n        res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)\n        return res\n\n    def get_layer_groups(self, do_fc=False):\n        if do_fc:\n            return [self.fc_model]\n        idxs = [self.lr_cut]\n        c = children(self.top_model)\n        if len(c)==3: c = children(c[0])+c[1:]\n        lgs = list(split_by_idxs(c,idxs))\n        return lgs+[self.fc_model]\n\n\nclass ConvLearner(Learner):\n    """"""\n    Class used to train a chosen supported covnet model. Eg. ResNet-34, etc.\n    Arguments:\n        data: training data for model\n        models: model architectures to base learner\n        precompute: bool to reuse precomputed activations\n        **kwargs: parameters from Learner() class\n    """"""\n    def __init__(self, data, models, precompute=False, **kwargs):\n        self.precompute = False\n        super().__init__(data, models, **kwargs)\n        if hasattr(data, \'is_multi\') and not data.is_reg and self.metrics is None:\n            self.metrics = [accuracy_thresh(0.5)] if self.data.is_multi else [accuracy]\n        if precompute: self.save_fc1()\n        self.freeze()\n        self.precompute = precompute\n\n    def _get_crit(self, data):\n        if not hasattr(data, \'is_multi\'): return super()._get_crit(data)\n\n        return F.l1_loss if data.is_reg else F.binary_cross_entropy if data.is_multi else F.nll_loss\n\n    @classmethod\n    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                   pretrained=True, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=pretrained)\n        return cls(data, models, precompute, **kwargs)\n\n    @classmethod\n    def lsuv_learner(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False,\n                  needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False, **kwargs):\n        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,\n            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head, pretrained=False)\n        convlearn=cls(data, models, precompute, **kwargs)\n        convlearn.lsuv_init()\n        return convlearn\n    \n    @property\n    def model(self): return self.models.fc_model if self.precompute else self.models.model\n\n    @property\n    def data(self): return self.fc_data if self.precompute else self.data_\n\n    def create_empty_bcolz(self, n, name):\n        return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode=\'w\', rootdir=name)\n\n    def set_data(self, data, precompute=False):\n        super().set_data(data)\n        if precompute:\n            self.unfreeze()\n            self.save_fc1()\n            self.freeze()\n            self.precompute = True\n        else:\n            self.freeze()\n\n    def get_layer_groups(self):\n        return self.models.get_layer_groups(self.precompute)\n\n    def summary(self):\n        precompute = self.precompute\n        self.precompute = False\n        res = super().summary()\n        self.precompute = precompute\n        return res\n\n    def get_activations(self, force=False):\n        tmpl = f\'_{self.models.name}_{self.data.sz}.bc\'\n        # TODO: Somehow check that directory names haven\'t changed (e.g. added test set)\n        names = [os.path.join(self.tmp_path, p+tmpl) for p in (\'x_act\', \'x_act_val\', \'x_act_test\')]\n        if os.path.exists(names[0]) and not force:\n            self.activations = [bcolz.open(p) for p in names]\n        else:\n            self.activations = [self.create_empty_bcolz(self.models.nf,n) for n in names]\n\n    def save_fc1(self):\n        self.get_activations()\n        act, val_act, test_act = self.activations\n        m=self.models.top_model\n        if len(self.activations[0])!=len(self.data.trn_ds):\n            predict_to_bcolz(m, self.data.fix_dl, act)\n        if len(self.activations[1])!=len(self.data.val_ds):\n            predict_to_bcolz(m, self.data.val_dl, val_act)\n        if self.data.test_dl and (len(self.activations[2])!=len(self.data.test_ds)):\n            if self.data.test_dl: predict_to_bcolz(m, self.data.test_dl, test_act)\n\n        self.fc_data = ImageClassifierData.from_arrays(self.data.path,\n                (act, self.data.trn_y), (val_act, self.data.val_y), self.data.bs, classes=self.data.classes,\n                test = test_act if self.data.test_dl else None, num_workers=8)\n\n    def freeze(self):\n        """""" Freeze all but the very last layer.\n\n        Make all layers untrainable (i.e. frozen) except for the last layer.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(-1)\n\n    def unfreeze(self):\n        """""" Unfreeze all layers.\n\n        Make all layers trainable by unfreezing. This will also set the `precompute` to `False` since we can\n        no longer pre-calculate the activation of frozen layers.\n\n        Returns:\n            None\n        """"""\n        self.freeze_to(0)\n        self.precompute = False\n'"
fastai/courses/ml1/fastai/core.py,11,"b'from .imports import *\nfrom .torch_imports import *\n\ndef sum_geom(a,r,n): return a*n if r==1 else math.ceil(a*(1-r**n)/(1-r))\n\ndef is_listy(x): return isinstance(x, (list,tuple))\ndef is_iter(x): return isinstance(x, collections.Iterable)\ndef map_over(x, f): return [f(o) for o in x] if is_listy(x) else f(x)\ndef map_none(x, f): return None if x is None else f(x)\n\nconv_dict = {np.dtype(\'int8\'): torch.LongTensor, np.dtype(\'int16\'): torch.LongTensor,\n    np.dtype(\'int32\'): torch.LongTensor, np.dtype(\'int64\'): torch.LongTensor,\n    np.dtype(\'float32\'): torch.FloatTensor, np.dtype(\'float64\'): torch.FloatTensor}\n\ndef A(*a):\n    """"""convert iterable object into numpy array""""""\n    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]\n\ndef T(a, half=False, cuda=True):\n    """"""\n    Convert numpy array into a pytorch tensor. \n    if Cuda is available and USE_GPU=ture, store resulting tensor in GPU.\n    """"""\n    if not torch.is_tensor(a):\n        a = np.array(np.ascontiguousarray(a))\n        if a.dtype in (np.int8, np.int16, np.int32, np.int64):\n            a = torch.LongTensor(a.astype(np.int64))\n        elif a.dtype in (np.float32, np.float64):\n            a = torch.cuda.HalfTensor(a) if half else torch.FloatTensor(a)\n        else: raise NotImplementedError(a.dtype)\n    if cuda: a = to_gpu(a, async=True)\n    return a\n\ndef create_variable(x, volatile, requires_grad=False):\n    if type (x) != Variable:\n        if IS_TORCH_04: x = Variable(T(x), requires_grad=requires_grad)\n        else:           x = Variable(T(x), requires_grad=requires_grad, volatile=volatile)\n    return x\n\ndef V_(x, requires_grad=False, volatile=False):\n    \'\'\'equivalent to create_variable, which creates a pytorch tensor\'\'\'\n    return create_variable(x, volatile=volatile, requires_grad=requires_grad)\ndef V(x, requires_grad=False, volatile=False):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, lambda o: V_(o, requires_grad, volatile))\n\ndef VV_(x): \n    \'\'\'creates a volatile tensor, which does not require gradients. \'\'\'\n    return create_variable(x, True)\n\ndef VV(x):\n    \'\'\'creates a single or a list of pytorch tensors, depending on input x. \'\'\'\n    return map_over(x, VV_)\n\ndef to_np(v):\n    \'\'\'returns an np.array object given an input of np.array, list, tuple, torch variable or tensor.\'\'\'\n    if isinstance(v, (np.ndarray, np.generic)): return v\n    if isinstance(v, (list,tuple)): return [to_np(o) for o in v]\n    if isinstance(v, Variable): v=v.data\n    if isinstance(v, torch.cuda.HalfTensor): v=v.float()\n    return v.cpu().numpy()\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\nUSE_GPU = torch.cuda.is_available()\ndef to_gpu(x, *args, **kwargs):\n    \'\'\'puts pytorch variable to gpu, if cuda is avaialble and USE_GPU is set to true. \'\'\'\n    return x.cuda(*args, **kwargs) if USE_GPU else x\n\ndef noop(*args, **kwargs): return\n\ndef split_by_idxs(seq, idxs):\n    \'\'\'A generator that returns sequence pieces, seperated by indexes specified in idxs. \'\'\'\n    last = 0\n    for idx in idxs:\n        yield seq[last:idx]\n        last = idx\n    yield seq[last:]\n\ndef trainable_params_(m):\n    \'\'\'Returns a list of trainable parameters in the model m. (i.e., those that require gradients.)\'\'\'\n    return [p for p in m.parameters() if p.requires_grad]\n\ndef chain_params(p):\n    if is_listy(p):\n        return list(chain(*[trainable_params_(o) for o in p]))\n    return trainable_params_(p)\n\ndef set_trainable_attr(m,b):\n    m.trainable=b\n    for p in m.parameters(): p.requires_grad=b\n\ndef apply_leaf(m, f):\n    c = children(m)\n    if isinstance(m, nn.Module): f(m)\n    if len(c)>0:\n        for l in c: apply_leaf(l,f)\n\ndef set_trainable(l, b):\n    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n\ndef SGD_Momentum(momentum):\n    return lambda *args, **kwargs: optim.SGD(*args, momentum=momentum, **kwargs)\n\ndef one_hot(a,c): return np.eye(c)[a]\n\ndef partition(a, sz): \n    """"""splits iterables a in equal parts of size sz""""""\n    return [a[i:i+sz] for i in range(0, len(a), sz)]\n\ndef partition_by_cores(a):\n    return partition(a, len(a)//num_cpus() + 1)\n\ndef num_cpus():\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n\n\nclass BasicModel():\n    def __init__(self,model,name=\'unnamed\'): self.model,self.name = model,name\n    def get_layer_groups(self, do_fc=False): return children(self.model)\n\nclass SingleModel(BasicModel):\n    def get_layer_groups(self): return [self.model]\n\nclass SimpleNet(nn.Module):\n    def __init__(self, layers):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return F.log_softmax(l_x, dim=-1)\n\n\ndef save(fn, a): \n    """"""Utility function that savess model, function, etc as pickle""""""    \n    pickle.dump(a, open(fn,\'wb\'))\ndef load(fn): \n    """"""Utility function that loads model, function, etc as pickle""""""\n    return pickle.load(open(fn,\'rb\'))\ndef load2(fn):\n    """"""Utility funciton allowing model piclking across Python2 and Python3""""""\n    return pickle.load(open(fn,\'rb\'), encoding=\'iso-8859-1\')\n\ndef load_array(fname): \n    \'\'\'\n    Load array using bcolz, which is based on numpy, for fast array saving and loading operations. \n    https://github.com/Blosc/bcolz\n    \'\'\'\n    return bcolz.open(fname)[:]\n\n\ndef chunk_iter(iterable, chunk_size):\n    \'\'\'A generator that yields chunks of iterable, chunk_size at a time. \'\'\'\n    while True:\n        chunk = []\n        try:\n            for _ in range(chunk_size): chunk.append(next(iterable))\n            yield chunk\n        except StopIteration:\n            if chunk: yield chunk\n            break\n\ndef set_grad_enabled(mode): return torch.set_grad_enabled(mode) if IS_TORCH_04 else contextlib.suppress()\n\ndef no_grad_context(): return torch.no_grad() if IS_TORCH_04 else contextlib.suppress()\n'"
fastai/courses/ml1/fastai/dataloader.py,1,"b'import torch, queue\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler, BatchSampler\nfrom .imports import *\nfrom .core import *\nimport collections,sys,traceback,threading\n\nstring_classes = (str, bytes)\n\n\ndef get_tensor(batch, pin, half=False):\n    if isinstance(batch, (np.ndarray, np.generic)):\n        batch = T(batch, half=half, cuda=False).contiguous()\n        if pin: batch = batch.pin_memory()\n        return to_gpu(batch)\n    elif isinstance(batch, string_classes):\n        return batch\n    elif isinstance(batch, collections.Mapping):\n        return {k: get_tensor(sample, pin, half) for k, sample in batch.items()}\n    elif isinstance(batch, collections.Sequence):\n        return [get_tensor(sample, pin, half) for sample in batch]\n    raise TypeError(f""batch must contain numbers, dicts or lists; found {type(batch)}"")\n\n\nclass DataLoader(object):\n    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, pad_idx=0,\n                 num_workers=None, pin_memory=False, drop_last=False, pre_pad=True, half=False,\n                 transpose=False, transpose_y=False):\n        self.dataset,self.batch_size,self.num_workers = dataset,batch_size,num_workers\n        self.pin_memory,self.drop_last,self.pre_pad = pin_memory,drop_last,pre_pad\n        self.transpose,self.transpose_y,self.pad_idx,self.half = transpose,transpose_y,pad_idx,half\n\n        if batch_sampler is not None:\n            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n                raise ValueError(\'batch_sampler is mutually exclusive with \'\n                                 \'batch_size, shuffle, sampler, and drop_last\')\n\n        if sampler is not None and shuffle:\n            raise ValueError(\'sampler is mutually exclusive with shuffle\')\n\n        if batch_sampler is None:\n            if sampler is None:\n                sampler = RandomSampler(dataset) if shuffle else SequentialSampler(dataset)\n            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n\n        if num_workers is None:\n            self.num_workers = num_cpus()\n\n        self.sampler = sampler\n        self.batch_sampler = batch_sampler\n\n    def __len__(self): return len(self.batch_sampler)\n\n    def jag_stack(self, b):\n        if len(b[0].shape) not in (1,2): return np.stack(b)\n        ml = max(len(o) for o in b)\n        if min(len(o) for o in b)==ml: return np.stack(b)\n        res = np.zeros((len(b), ml), dtype=b[0].dtype) + self.pad_idx\n        for i,o in enumerate(b):\n            if self.pre_pad: res[i, -len(o):] = o\n            else:            res[i,  :len(o)] = o\n        return res\n\n    def np_collate(self, batch):\n        b = batch[0]\n        if isinstance(b, (np.ndarray, np.generic)): return self.jag_stack(batch)\n        elif isinstance(b, (int, float)): return np.array(batch)\n        elif isinstance(b, string_classes): return batch\n        elif isinstance(b, collections.Mapping):\n            return {key: self.np_collate([d[key] for d in batch]) for key in b}\n        elif isinstance(b, collections.Sequence):\n            return [self.np_collate(samples) for samples in zip(*batch)]\n        raise TypeError((""batch must contain numbers, dicts or lists; found {}"".format(type(b))))\n\n    def get_batch(self, indices):\n        res = self.np_collate([self.dataset[i] for i in indices])\n        if self.transpose:   res[0] = res[0].T\n        if self.transpose_y: res[1] = res[1].T\n        return res\n\n    def __iter__(self):\n        if self.num_workers==0:\n            for batch in map(self.get_batch, iter(self.batch_sampler)):\n                yield get_tensor(batch, self.pin_memory, self.half)\n        else:\n            with ThreadPoolExecutor(max_workers=self.num_workers) as e:\n                # avoid py3.6 issue where queue is infinite and can result in memory exhaustion\n                for c in chunk_iter(iter(self.batch_sampler), self.num_workers*10):\n                    for batch in e.map(self.get_batch, c):\n                        yield get_tensor(batch, self.pin_memory, self.half)\n\n'"
fastai/courses/ml1/fastai/dataset.py,1,"b'import csv\n\nfrom .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .layer_optimizer import *\nfrom .dataloader import DataLoader\n\ndef get_cv_idxs(n, cv_idx=0, val_pct=0.2, seed=42):\n    """""" Get a list of index values for Validation set from a dataset\n    \n    Arguments:\n        n : int, Total number of elements in the data set.\n        cv_idx : int, starting index [idx_start = cv_idx*int(val_pct*n)] \n        val_pct : (int, float), validation set percentage \n        seed : seed value for RandomState\n        \n    Returns:\n        list of indexes \n    """"""\n    np.random.seed(seed)\n    n_val = int(val_pct*n)\n    idx_start = cv_idx*n_val\n    idxs = np.random.permutation(n)\n    return idxs[idx_start:idx_start+n_val]\n\ndef resize_img(fname, targ, path, new_path):\n    """"""\n    Enlarge or shrink a single image to scale, such that the smaller of the height or width dimension is equal to targ.\n    """"""\n    dest = os.path.join(path,new_path,str(targ),fname)\n    if os.path.exists(dest): return\n    im = Image.open(os.path.join(path, fname)).convert(\'RGB\')\n    r,c = im.size\n    ratio = targ/min(r,c)\n    sz = (scale_to(r, ratio, targ), scale_to(c, ratio, targ))\n    os.makedirs(os.path.split(dest)[0], exist_ok=True)\n    im.resize(sz, Image.LINEAR).save(dest)\n\ndef resize_imgs(fnames, targ, path, new_path):\n    """"""\n    Enlarge or shrink a set of images in the same directory to scale, such that the smaller of the height or width dimension is equal to targ.\n    Note: \n    -- This function is multithreaded for efficiency. \n    -- When destination file or folder already exist, function exists without raising an error. \n    """"""\n    if not os.path.exists(os.path.join(path,new_path,str(targ),fnames[0])):\n        with ThreadPoolExecutor(8) as e:\n            ims = e.map(lambda x: resize_img(x, targ, path, new_path), fnames)\n            for x in tqdm(ims, total=len(fnames), leave=False): pass\n    return os.path.join(path,new_path,str(targ))\n\ndef read_dir(path, folder):\n    """""" Returns a list of relative file paths to `path` for all files within `folder` """"""\n    full_path = os.path.join(path, folder)\n    fnames = glob(f""{full_path}/*.*"")\n    if any(fnames):\n        return [os.path.relpath(f,path) for f in fnames]\n    else:\n        raise FileNotFoundError(""{} folder doesn\'t exist or is empty"".format(folder))\n\ndef read_dirs(path, folder):\n    \'\'\'\n    Fetches name of all files in path in long form, and labels associated by extrapolation of directory names. \n    \'\'\'\n    lbls, fnames, all_lbls = [], [], []\n    full_path = os.path.join(path, folder)\n    for lbl in sorted(os.listdir(full_path)):\n        if lbl not in (\'.ipynb_checkpoints\',\'.DS_Store\'):\n            all_lbls.append(lbl)\n            for fname in os.listdir(os.path.join(full_path, lbl)):\n                fnames.append(os.path.join(folder, lbl, fname))\n                lbls.append(lbl)\n    return fnames, lbls, all_lbls\n\ndef n_hot(ids, c):\n    \'\'\'\n    one hot encoding by index. Returns array of length c, where all entries are 0, except for the indecies in ids\n    \'\'\'\n    res = np.zeros((c,), dtype=np.float32)\n    res[ids] = 1\n    return res\n\ndef folder_source(path, folder):\n    """"""\n    Returns the filenames and labels for a folder within a path\n    \n    Returns:\n    -------\n    fnames: a list of the filenames within `folder`\n    all_lbls: a list of all of the labels in `folder`, where the # of labels is determined by the # of directories within `folder`\n    lbl_arr: a numpy array of the label indices in `all_lbls`\n    """"""\n    fnames, lbls, all_lbls = read_dirs(path, folder)\n    lbl2idx = {lbl:idx for idx,lbl in enumerate(all_lbls)}\n    idxs = [lbl2idx[lbl] for lbl in lbls]\n    lbl_arr = np.array(idxs, dtype=int)\n    return fnames, lbl_arr, all_lbls\n\ndef parse_csv_labels(fn, skip_header=True, cat_separator = \' \'):\n    """"""Parse filenames and label sets from a CSV file.\n\n    This method expects that the csv file at path :fn: has two columns. If it\n    has a header, :skip_header: should be set to True. The labels in the\n    label set are expected to be space separated.\n\n    Arguments:\n        fn: Path to a CSV file.\n        skip_header: A boolean flag indicating whether to skip the header.\n\n    Returns:\n        a four-tuple of (\n            sorted image filenames,\n            a dictionary of filenames and corresponding labels,\n            a sorted set of unique labels,\n            a dictionary of labels to their corresponding index, which will\n            be one-hot encoded.\n        )\n    .\n    :param cat_separator: the separator for the categories column\n    """"""\n    df = pd.read_csv(fn, index_col=0, header=0 if skip_header else None, dtype=str)\n    fnames = df.index.values\n    df.iloc[:,0] = df.iloc[:,0].str.split(cat_separator)\n    return sorted(fnames), list(df.to_dict().values())[0]\n\ndef nhot_labels(label2idx, csv_labels, fnames, c):\n    \n    all_idx = {k: n_hot([label2idx[o] for o in v], c)\n               for k,v in csv_labels.items()}\n    return np.stack([all_idx[o] for o in fnames])\n\ndef csv_source(folder, csv_file, skip_header=True, suffix=\'\', continuous=False):\n    fnames,csv_labels = parse_csv_labels(csv_file, skip_header)\n    return dict_source(folder, fnames, csv_labels, suffix, continuous)\n\ndef dict_source(folder, fnames, csv_labels, suffix=\'\', continuous=False):\n    all_labels = sorted(list(set(p for o in csv_labels.values() for p in o)))\n    full_names = [os.path.join(folder,str(fn)+suffix) for fn in fnames]\n    if continuous:\n        label_arr = np.array([np.array(csv_labels[i]).astype(np.float32)\n                for i in fnames])\n    else:\n        label2idx = {v:k for k,v in enumerate(all_labels)}\n        label_arr = nhot_labels(label2idx, csv_labels, fnames, len(all_labels))\n        is_single = np.all(label_arr.sum(axis=1)==1)\n        if is_single: label_arr = np.argmax(label_arr, axis=1)\n    return full_names, label_arr, all_labels\n\nclass BaseDataset(Dataset):\n    """"""An abstract class representing a fastai dataset, it extends torch.utils.data.Dataset.""""""\n    def __init__(self, transform=None):\n        self.transform = transform\n        self.n = self.get_n()\n        self.c = self.get_c()\n        self.sz = self.get_sz()\n\n    def get1item(self, idx):\n        x,y = self.get_x(idx),self.get_y(idx)\n        return self.get(self.transform, x, y)\n\n    def __getitem__(self, idx):\n        if isinstance(idx,slice):\n            xs,ys = zip(*[self.get1item(i) for i in range(*idx.indices(self.n))])\n            return np.stack(xs),ys\n        return self.get1item(idx)\n\n    def __len__(self): return self.n\n\n    def get(self, tfm, x, y):\n        return (x,y) if tfm is None else tfm(x,y)\n\n    @abstractmethod\n    def get_n(self):\n        """"""Return number of elements in the dataset == len(self).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_c(self):\n        """"""Return number of classes in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_sz(self):\n        """"""Return maximum size of an image in a dataset.""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_x(self, i):\n        """"""Return i-th example (image, wav, etc).""""""\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_y(self, i):\n        """"""Return i-th label.""""""\n        raise NotImplementedError\n\n    @property\n    def is_multi(self):\n        """"""Returns true if this data set contains multiple labels per sample.""""""\n        return False\n\n    @property\n    def is_reg(self):\n        """"""True if the data set is used to train regression models.""""""\n        return False\n\ndef open_image(fn):\n    """""" Opens an image using OpenCV given the file path.\n\n    Arguments:\n        fn: the file path of the image\n\n    Returns:\n        The image in RGB format as numpy array of floats normalized to range between 0.0 - 1.0\n    """"""\n    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n    if not os.path.exists(fn):\n        raise OSError(\'No such file or directory: {}\'.format(fn))\n    elif os.path.isdir(fn):\n        raise OSError(\'Is a directory: {}\'.format(fn))\n    else:\n        #res = np.array(Image.open(fn), dtype=np.float32)/255\n        #if len(res.shape)==2: res = np.repeat(res[...,None],3,2)\n        #return res\n        try:\n            im = cv2.imread(str(fn), flags).astype(np.float32)/255\n            if im is None: raise OSError(f\'File not recognized by opencv: {fn}\')\n            return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n        except Exception as e:\n            raise OSError(\'Error handling image at: {}\'.format(fn)) from e\n\nclass FilesDataset(BaseDataset):\n    def __init__(self, fnames, transform, path):\n        self.path,self.fnames = path,fnames\n        super().__init__(transform)\n    def get_sz(self): return self.transform.sz\n    def get_x(self, i): return open_image(os.path.join(self.path, self.fnames[i]))\n    def get_n(self): return len(self.fnames)\n\n    def resize_imgs(self, targ, new_path):\n        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n        return self.__class__(self.fnames, self.y, self.transform, dest)\n\n    def denorm(self,arr):\n        """"""Reverse the normalization done to a batch of images.\n\n        Arguments:\n            arr: of shape/size (N,3,sz,sz)\n        """"""\n        if type(arr) is not np.ndarray: arr = to_np(arr)\n        if len(arr.shape)==3: arr = arr[None]\n        return self.transform.denorm(np.rollaxis(arr,1,4))\n\n\nclass FilesArrayDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n    def get_y(self, i): return self.y[i]\n    def get_c(self):\n        return self.y.shape[1] if len(self.y.shape)>1 else 0\n\nclass FilesIndexArrayDataset(FilesArrayDataset):\n    def get_c(self): return int(self.y.max())+1\n\n\nclass FilesNhotArrayDataset(FilesArrayDataset):\n    @property\n    def is_multi(self): return True\n\n\nclass FilesIndexArrayRegressionDataset(FilesArrayDataset):\n    def is_reg(self): return True\n\nclass ArraysDataset(BaseDataset):\n    def __init__(self, x, y, transform):\n        self.x,self.y=x,y\n        assert(len(x)==len(y))\n        super().__init__(transform)\n    def get_x(self, i): return self.x[i]\n    def get_y(self, i): return self.y[i]\n    def get_n(self): return len(self.y)\n    def get_sz(self): return self.x.shape[1]\n\n\nclass ArraysIndexDataset(ArraysDataset):\n    def get_c(self): return int(self.y.max())+1\n    def get_y(self, i): return self.y[i]\n\n\nclass ArraysNhotDataset(ArraysDataset):\n    def get_c(self): return self.y.shape[1]\n    @property\n    def is_multi(self): return True\n\n\nclass ModelData():\n    def __init__(self, path, trn_dl, val_dl, test_dl=None):\n        self.path,self.trn_dl,self.val_dl,self.test_dl = path,trn_dl,val_dl,test_dl\n\n    @classmethod\n    def from_dls(cls, path,trn_dl,val_dl,test_dl=None):\n        #trn_dl,val_dl = DataLoader(trn_dl),DataLoader(val_dl)\n        #if test_dl: test_dl = DataLoader(test_dl)\n        return cls(path, trn_dl, val_dl, test_dl)\n\n    @property\n    def is_reg(self): return self.trn_ds.is_reg\n    @property\n    def is_multi(self): return self.trn_ds.is_multi\n    @property\n    def trn_ds(self): return self.trn_dl.dataset\n    @property\n    def val_ds(self): return self.val_dl.dataset\n    @property\n    def test_ds(self): return self.test_dl.dataset\n    @property\n    def trn_y(self): return self.trn_ds.y\n    @property\n    def val_y(self): return self.val_ds.y\n\n\nclass ImageData(ModelData):\n    def __init__(self, path, datasets, bs, num_workers, classes):\n        trn_ds,val_ds,fix_ds,aug_ds,test_ds,test_aug_ds = datasets\n        self.path,self.bs,self.num_workers,self.classes = path,bs,num_workers,classes\n        self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl,self.test_dl,self.test_aug_dl = [\n            self.get_dl(ds,shuf) for ds,shuf in [\n                (trn_ds,True),(val_ds,False),(fix_ds,False),(aug_ds,False),\n                (test_ds,False),(test_aug_ds,False)\n            ]\n        ]\n\n    def get_dl(self, ds, shuffle):\n        if ds is None: return None\n        return DataLoader(ds, batch_size=self.bs, shuffle=shuffle,\n            num_workers=self.num_workers, pin_memory=False)\n\n    @property\n    def sz(self): return self.trn_ds.sz\n    @property\n    def c(self): return self.trn_ds.c\n\n    def resized(self, dl, targ, new_path):\n        return dl.dataset.resize_imgs(targ,new_path) if dl else None\n\n    def resize(self, targ_sz, new_path=\'tmp\'):\n        new_ds = []\n        dls = [self.trn_dl,self.val_dl,self.fix_dl,self.aug_dl]\n        if self.test_dl: dls += [self.test_dl, self.test_aug_dl]\n        else: dls += [None,None]\n        t = tqdm_notebook(dls)\n        for dl in t: new_ds.append(self.resized(dl, targ_sz, new_path))\n        t.close()\n        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)\n\n    @staticmethod\n    def get_ds(fn, trn, val, tfms, test=None, **kwargs):\n        res = [\n            fn(trn[0], trn[1], tfms[0], **kwargs), # train\n            fn(val[0], val[1], tfms[1], **kwargs), # val\n            fn(trn[0], trn[1], tfms[1], **kwargs), # fix\n            fn(val[0], val[1], tfms[0], **kwargs)  # aug\n        ]\n        if test is not None:\n            if isinstance(test, tuple):\n                test_lbls = test[1]\n                test = test[0]\n            else:\n                test_lbls = np.zeros((len(test),1))\n            res += [\n                fn(test, test_lbls, tfms[1], **kwargs), # test\n                fn(test, test_lbls, tfms[0], **kwargs)  # test_aug\n            ]\n        else: res += [None,None]\n        return res\n\n\nclass ImageClassifierData(ImageData):\n    @classmethod\n    def from_arrays(cls, path, trn, val, bs=64, tfms=(None,None), classes=None, num_workers=4, test=None):\n        """""" Read in images and their labels given as numpy arrays\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            trn: a tuple of training data matrix and target label/classification array (e.g. `trn=(x,y)` where `x` has the\n                shape of `(5000, 784)` and `y` has the shape of `(5000,)`)\n            val: a tuple of validation data matrix and target label/classification array.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            classes: a list of all labels/classifications\n            num_workers: a number of workers\n            test: a matrix of test data (the shape should match `trn[0]`)\n\n        Returns:\n            ImageClassifierData\n        """"""\n        datasets = cls.get_ds(ArraysIndexDataset, trn, val, tfms, test=test)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\n    @classmethod\n    def from_paths(cls, path, bs=64, tfms=(None,None), trn_name=\'train\', val_name=\'valid\', test_name=None, test_with_labels=False, num_workers=8):\n        """""" Read in images and their labels given as sub-folder names\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            trn_name: a name of the folder that contains training images.\n            val_name:  a name of the folder that contains validation images.\n            test_name:  a name of the folder that contains test images.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not(tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        trn,val = [folder_source(path, o) for o in (trn_name, val_name)]\n        if test_name:\n            test = folder_source(path, test_name) if test_with_labels else read_dir(path, test_name)\n        else: test = None\n        datasets = cls.get_ds(FilesIndexArrayDataset, trn, val, tfms, path=path, test=test)\n        return cls(path, datasets, bs, num_workers, classes=trn[2])\n\n    @classmethod\n    def from_csv(cls, path, folder, csv_fname, bs=64, tfms=(None,None),\n               val_idxs=None, suffix=\'\', test_name=None, continuous=False, skip_header=True, num_workers=8):\n        """""" Read in images and their labels given as a CSV file.\n\n        This method should be used when training image labels are given in an CSV file as opposed to\n        sub-directories with label names.\n\n        Arguments:\n            path: a root path of the data (used for storing trained models, precomputed values, etc)\n            folder: a name of the folder in which training images are contained.\n            csv_fname: a name of the CSV file which contains target labels.\n            bs: batch size\n            tfms: transformations (for data augmentations). e.g. output of `tfms_from_model`\n            val_idxs: index of images to be used for validation. e.g. output of `get_cv_idxs`.\n                If None, default arguments to get_cv_idxs are used.\n            suffix: suffix to add to image names in CSV file (sometimes CSV only contains the file name without file\n                    extension e.g. \'.jpg\' - in which case, you can set suffix as \'.jpg\')\n            test_name: a name of the folder which contains test images.\n            continuous: TODO\n            skip_header: skip the first row of the CSV file.\n            num_workers: number of workers\n\n        Returns:\n            ImageClassifierData\n        """"""\n        assert not (tfms[0] is None or tfms[1] is None), ""please provide transformations for your train and validation sets""\n        assert not (os.path.isabs(folder)), ""folder needs to be a relative path""\n        fnames,y,classes = csv_source(folder, csv_fname, skip_header, suffix, continuous=continuous)\n        return cls.from_names_and_array(path, fnames, y, classes, val_idxs, test_name,\n                num_workers=num_workers, suffix=suffix, tfms=tfms, bs=bs, continuous=continuous)\n\n    @classmethod\n    def from_names_and_array(cls, path, fnames,y,classes, val_idxs=None, test_name=None,\n            num_workers=8, suffix=\'\', tfms=(None,None), bs=64, continuous=False):\n        val_idxs = get_cv_idxs(len(fnames)) if val_idxs is None else val_idxs\n        ((val_fnames,trn_fnames),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames), y)\n\n        test_fnames = read_dir(path, test_name) if test_name else None\n        if continuous: f = FilesIndexArrayRegressionDataset\n        else:\n            f = FilesIndexArrayDataset if len(trn_y.shape)==1 else FilesNhotArrayDataset\n        datasets = cls.get_ds(f, (trn_fnames,trn_y), (val_fnames,val_y), tfms,\n                               path=path, test=test_fnames)\n        return cls(path, datasets, bs, num_workers, classes=classes)\n\ndef split_by_idx(idxs, *a):\n    """"""\n    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n    This can be used to split multiple arrays containing training data to validation and training set.\n\n    :param idxs [int]: list of indexes selected\n    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n    :return: list of tuples, each containing a split of corresponding array from *a.\n            First element of each tuple is an array composed from elements selected by idxs,\n            second element is an array of remaining elements.\n    """"""\n    mask = np.zeros(len(a[0]),dtype=bool)\n    mask[np.array(idxs)] = True\n    return [(o[mask],o[~mask]) for o in a]\n\n'"
fastai/courses/ml1/fastai/executors.py,0,"b'import collections\nimport itertools\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\nclass LazyThreadPoolExecutor(ThreadPoolExecutor):\n    def map(self, fn, *iterables, timeout=None, chunksize=1, prefetch=None):\n        """"""\n        Collects iterables lazily, rather than immediately.\n        Docstring same as parent: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor\n        Implmentation taken from this PR: https://github.com/python/cpython/pull/707\n        """"""\n        if timeout is not None: end_time = timeout + time.time()\n        if prefetch is None: prefetch = self._max_workers\n        if prefetch < 0: raise ValueError(""prefetch count may not be negative"")\n        argsiter = zip(*iterables)\n        fs = collections.deque(self.submit(fn, *args) for args in itertools.islice(argsiter, self._max_workers+prefetch))\n        # Yield must be hidden in closure so that the futures are submitted before the first iterator value is required.\n        def result_iterator():\n            nonlocal argsiter\n            try:\n                while fs:\n                    res = fs[0].result() if timeout is None else fs[0].result(end_time-time.time())\n                    # Got a result, future needn\'t be cancelled\n                    del fs[0]\n                    # Dispatch next task before yielding to keep pipeline full\n                    if argsiter:\n                        try:\n                            args = next(argsiter)\n                        except StopIteration:\n                            argsiter = None\n                        else:\n                            fs.append(self.submit(fn, *args))\n                    yield res\n            finally:\n                for future in fs: future.cancel()\n        return result_iterator()'"
fastai/courses/ml1/fastai/fp16.py,2,"b'import torch\nimport torch.nn as nn\n\n\nclass FP16(nn.Module):\n    def __init__(self, module): \n        super(FP16, self).__init__()\n        self.module = batchnorm_to_fp32(module.half())\n        \n    def forward(self, input): \n        return self.module(input.half())\n    \n    def load_state_dict(self, *inputs, **kwargs):\n        self.module.load_state_dict(*inputs, **kwargs)\n\n    def state_dict(self, *inputs, **kwargs):\n        return self.module.state_dict(*inputs, **kwargs)\n\ndef batchnorm_to_fp32(module):\n    \'\'\'\n    BatchNorm layers to have parameters in single precision.\n    Find all layers and convert them back to float. This can\'t\n    be done with built in .apply as that function will apply\n    fn to all modules, parameters, and buffers. Thus we wouldn\'t\n    be able to guard the float conversion based on the module type.\n    \'\'\'\n    if isinstance(module, nn.modules.batchnorm._BatchNorm):\n        module.float()\n    for child in module.children():\n        batchnorm_to_fp32(child)\n    return module\n\ndef copy_model_to_fp32(m, optim):\n    """"""  Creates a fp32 copy of model parameters and sets optimizer parameters\n    """"""\n    fp32_params = [m_param.clone().type(torch.cuda.FloatTensor).detach() for m_param in m.parameters()]\n    optim_groups = [group[\'params\'] for group in optim.param_groups]\n    iter_fp32_params = iter(fp32_params)\n    for group_params in optim_groups:\n        for i in range(len(group_params)):\n            fp32_param = next(iter_fp32_params)\n            fp32_param.requires_grad = group_params[i].requires_grad\n            group_params[i] = fp32_param\n    return fp32_params\n\ndef copy_fp32_to_model(m, fp32_params):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        m_param.data.copy_(fp32_param.data)\n\ndef update_fp32_grads(fp32_params, m):\n    m_params = list(m.parameters())\n    for fp32_param, m_param in zip(fp32_params, m_params):\n        if fp32_param.grad is None:\n            fp32_param.grad = nn.Parameter(fp32_param.data.new().resize_(*fp32_param.data.size()))\n        fp32_param.grad.data.copy_(m_param.grad.data)\n\n'"
fastai/courses/ml1/fastai/imports.py,0,"b""from IPython.lib.deepreload import reload as dreload\nimport PIL, os, numpy as np, math, collections, threading, json, bcolz, random, scipy, cv2\nimport pandas as pd, pickle, sys, itertools, string, sys, re, datetime, time, shutil, copy\nimport seaborn as sns, matplotlib\nimport IPython, graphviz, sklearn_pandas, sklearn, warnings, pdb\nimport contextlib\nfrom abc import abstractmethod\nfrom glob import glob, iglob\nfrom concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\nfrom itertools import chain\nfrom functools import partial\nfrom collections import Iterable, Counter, OrderedDict\nfrom isoweek import Week\nfrom pandas_summary import DataFrameSummary\nfrom IPython.lib.display import FileLink\nfrom PIL import Image, ImageEnhance, ImageOps\nfrom sklearn import metrics, ensemble, preprocessing\nfrom operator import itemgetter, attrgetter\nfrom pathlib import Path\nfrom distutils.version import LooseVersion\n\nfrom matplotlib import pyplot as plt, rcParams, animation\nfrom ipywidgets import interact, interactive, fixed, widgets\nmatplotlib.rc('animation', html='html5')\nnp.set_printoptions(precision=5, linewidth=110, suppress=True)\n\nfrom ipykernel.kernelapp import IPKernelApp\ndef in_notebook(): return IPKernelApp.initialized()\n\ndef in_ipynb():\n    try:\n        cls = get_ipython().__class__.__name__\n        return cls == 'ZMQInteractiveShell'\n    except NameError:\n        return False\n\nimport tqdm as tq\nfrom tqdm import tqdm_notebook, tnrange\n\ndef clear_tqdm():\n    inst = getattr(tq.tqdm, '_instances', None)\n    if not inst: return\n    try:\n        for i in range(len(inst)): inst.pop().close()\n    except Exception:\n        pass\n\nif in_notebook():\n    def tqdm(*args, **kwargs):\n        clear_tqdm()\n        return tq.tqdm(*args, file=sys.stdout, **kwargs)\n    def trange(*args, **kwargs):\n        clear_tqdm()\n        return tq.trange(*args, file=sys.stdout, **kwargs)\nelse:\n    from tqdm import tqdm, trange\n    tnrange=trange\n    tqdm_notebook=tqdm\n\n"""
fastai/courses/ml1/fastai/initializers.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\ndef cond_init(m, init_fn):\n    if not isinstance(m, (nn.BatchNorm1d,nn.BatchNorm2d,nn.BatchNorm3d)):\n        if hasattr(m, 'weight'): init_fn(m.weight)\n        if hasattr(m, 'bias'): m.bias.data.fill_(0.)\n\ndef apply_init(m, init_fn):\n    m.apply(lambda x: cond_init(x, init_fn))\n\n\n"""
fastai/courses/ml1/fastai/io.py,0,"b""from .imports import *\nfrom .torch_imports import *\n\nimport gzip\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\n\nclass TqdmUpTo(tqdm):\n    def update_to(self, b=1, bsize=1, tsize=None):\n        if tsize is not None: self.total = tsize\n        self.update(b * bsize - self.n)\n\ndef get_data(url, filename):\n    if not os.path.exists(filename):\n\n        dirname = os.path.dirname(filename)\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        with TqdmUpTo(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n            urlretrieve(url, filename, reporthook=t.update_to)\n\n"""
fastai/courses/ml1/fastai/layer_optimizer.py,0,"b""from .imports import *\nfrom .torch_imports import *\nfrom .core import *\n\ndef opt_params(parm, lr, wd):\n    return {'params': chain_params(parm), 'lr':lr, 'weight_decay':wd}\n\nclass LayerOptimizer():\n    def __init__(self, opt_fn, layer_groups, lrs, wds=None):\n        if not isinstance(layer_groups, (list,tuple)): layer_groups=[layer_groups]\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(layer_groups)\n        if wds is None: wds=0.\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(layer_groups)\n        self.layer_groups,self.lrs,self.wds = layer_groups,lrs,wds\n        self.opt = opt_fn(self.opt_params())\n\n    def opt_params(self):\n        assert(len(self.layer_groups) == len(self.lrs))\n        assert(len(self.layer_groups) == len(self.wds))\n        params = list(zip(self.layer_groups,self.lrs,self.wds))\n        return [opt_params(*p) for p in params]\n\n    @property\n    def lr(self): return self.lrs[-1]\n\n    @property\n    def mom(self):\n        if 'betas' in self.opt.param_groups[0]:\n            return self.opt.param_groups[0]['betas'][0]\n        else:\n            return self.opt.param_groups[0]['momentum']\n\n    def set_lrs(self, lrs):\n        if not isinstance(lrs, Iterable): lrs=[lrs]\n        if len(lrs)==1: lrs=lrs*len(self.layer_groups)\n        set_lrs(self.opt, lrs)\n        self.lrs=lrs\n\n    def set_wds(self, wds):\n        if not isinstance(wds, Iterable): wds=[wds]\n        if len(wds)==1: wds=wds*len(self.layer_groups)\n        set_wds(self.opt, wds)\n        self.wds=wds\n    \n    def set_mom(self,momentum):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (momentum, pg['betas'][1])\n        else:\n            for pg in self.opt.param_groups: pg['momentum'] = momentum\n    \n    def set_beta(self,beta):\n        if 'betas' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['betas'] = (pg['betas'][0],beta)\n        elif 'alpha' in self.opt.param_groups[0]:\n            for pg in self.opt.param_groups: pg['alpha'] = beta\n\n    def set_opt_fn(self, opt_fn):\n        if type(self.opt) != type(opt_fn(self.opt_params())):\n            self.opt = opt_fn(self.opt_params())\n\ndef zip_strict_(l, r):\n    assert(len(l) == len(r))\n    return zip(l, r)\n\ndef set_lrs(opt, lrs):\n    if not isinstance(lrs, Iterable): lrs=[lrs]\n    if len(lrs)==1: lrs=lrs*len(opt.param_groups)\n    for pg,lr in zip_strict_(opt.param_groups,lrs): pg['lr'] = lr\n\ndef set_wds(opt, wds):\n    if not isinstance(wds, Iterable): wds=[wds]\n    if len(wds)==1: wds=wds*len(opt.param_groups)\n    assert(len(opt.param_groups) == len(wds))\n    for pg,wd in zip_strict_(opt.param_groups,wds): pg['weight_decay'] = wd\n\n"""
fastai/courses/ml1/fastai/layers.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\nclass AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1,1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n\nclass Lambda(nn.Module):\n    def __init__(self, f): super().__init__(); self.f=f\n    def forward(self, x): return self.f(x)\n\nclass Flatten(nn.Module):\n    def __init__(self): super().__init__()\n    def forward(self, x): return x.view(x.size(0), -1)\n\n'"
fastai/courses/ml1/fastai/learner.py,1,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .transforms import *\nfrom .model import *\nfrom .dataset import *\nfrom .sgdr import *\nfrom .layer_optimizer import *\nfrom .layers import *\nfrom .metrics import *\nfrom .losses import *\nfrom .swa import *\nfrom .fp16 import *\nfrom .lsuv_initializer import apply_lsuv_init\nimport time\n\n\nclass Learner():\n    def __init__(self, data, models, opt_fn=None, tmp_name=\'tmp\', models_name=\'models\', metrics=None, clip=None, crit=None):\n        """"""\n        Combines a ModelData object with a nn.Module object, such that you can train that\n        module.\n        data (ModelData): An instance of ModelData.\n        models(module): chosen neural architecture for solving a supported problem.\n        opt_fn(function): optimizer function, uses SGD with Momentum of .9 if none.\n        tmp_name(str): output name of the directory containing temporary files from training process\n        models_name(str): output name of the directory containing the trained model\n        metrics(list): array of functions for evaluating a desired metric. Eg. accuracy.\n        clip(float): gradient clip chosen to limit the change in the gradient to prevent exploding gradients Eg. .3\n        """"""\n        self.data_,self.models,self.metrics = data,models,metrics\n        self.sched=None\n        self.wd_sched = None\n        self.clip = None\n        self.opt_fn = opt_fn or SGD_Momentum(0.9)\n        self.tmp_path = tmp_name if os.path.isabs(tmp_name) else os.path.join(self.data.path, tmp_name)\n        self.models_path = models_name if os.path.isabs(models_name) else os.path.join(self.data.path, models_name)\n        os.makedirs(self.tmp_path, exist_ok=True)\n        os.makedirs(self.models_path, exist_ok=True)\n        self.crit = crit if crit else self._get_crit(data)\n        self.reg_fn = None\n        self.fp16 = False\n\n    @classmethod\n    def from_model_data(cls, m, data, **kwargs):\n        self = cls(data, BasicModel(to_gpu(m)), **kwargs)\n        self.unfreeze()\n        return self\n\n    def __getitem__(self,i): return self.children[i]\n\n    @property\n    def children(self): return children(self.model)\n\n    @property\n    def model(self): return self.models.model\n\n    @property\n    def data(self): return self.data_\n\n    def summary(self): return model_summary(self.model, [3,self.data.sz,self.data.sz])\n\n    def __repr__(self): return self.model.__repr__()\n    \n    def lsuv_init(self, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=False):         \n        x = V(next(iter(self.data.trn_dl))[0])\n        self.models.model=apply_lsuv_init(self.model, x, needed_std=needed_std, std_tol=std_tol,\n                            max_attempts=max_attempts, do_orthonorm=do_orthonorm, \n                            cuda=USE_GPU and torch.cuda.is_available())\n\n    def set_bn_freeze(self, m, do_freeze):\n        if hasattr(m, \'running_mean\'): m.bn_freeze = do_freeze\n\n    def bn_freeze(self, do_freeze):\n        apply_leaf(self.model, lambda m: self.set_bn_freeze(m, do_freeze))\n\n    def freeze_to(self, n):\n        c=self.get_layer_groups()\n        for l in c:     set_trainable(l, False)\n        for l in c[n:]: set_trainable(l, True)\n\n    def freeze_all_but(self, n):\n        c=self.get_layer_groups()\n        for l in c: set_trainable(l, False)\n        set_trainable(c[n], True)\n\n    def unfreeze(self): self.freeze_to(0)\n\n    def get_model_path(self, name): return os.path.join(self.models_path,name)+\'.h5\'\n    \n    def save(self, name): \n        save_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): save_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n                       \n    def load(self, name): \n        load_model(self.model, self.get_model_path(name))\n        if hasattr(self, \'swa_model\'): load_model(self.swa_model, self.get_model_path(name)[:-3]+\'-swa.h5\')\n\n    def set_data(self, data): self.data_ = data\n\n    def get_cycle_end(self, name):\n        if name is None: return None\n        return lambda sched, cycle: self.save_cycle(name, cycle)\n\n    def save_cycle(self, name, cycle): self.save(f\'{name}_cyc_{cycle}\')\n    def load_cycle(self, name, cycle): self.load(f\'{name}_cyc_{cycle}\')\n\n    def half(self):\n        if self.fp16: return\n        self.fp16 = True\n        if type(self.model) != FP16: self.models.model = FP16(self.model)\n    def float(self):\n        if not self.fp16: return\n        self.fp16 = False\n        if type(self.model) == FP16: self.models.model = self.model.module\n        self.model.float()\n\n    def fit_gen(self, model, data, layer_opt, n_cycle, cycle_len=None, cycle_mult=1, cycle_save_name=None, best_save_name=None,\n                use_clr=None, use_clr_beta=None, metrics=None, callbacks=None, use_wd_sched=False, norm_wds=False,             \n                wds_sched_mult=None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n\n        """"""Method does some preparation before finally delegating to the \'fit\' method for\n        fitting the model. Namely, if cycle_len is defined, it adds a \'Cosine Annealing\'\n        scheduler for varying the learning rate across iterations.\n\n        Method also computes the total number of epochs to fit based on provided \'cycle_len\',\n        \'cycle_mult\', and \'n_cycle\' parameters.\n\n        Args:\n            model (Learner):  Any neural architecture for solving a supported problem.\n                Eg. ResNet-34, RNN_Learner etc.\n\n            data (ModelData): An instance of ModelData.\n\n            layer_opt (LayerOptimizer): An instance of the LayerOptimizer class\n\n            n_cycle (int): number of cycles\n\n            cycle_len (int):  number of cycles before lr is reset to the initial value.\n                E.g if cycle_len = 3, then the lr is varied between a maximum\n                and minimum value over 3 epochs.\n\n            cycle_mult (int): additional parameter for influencing how the lr resets over\n                the cycles. For an intuitive explanation, please see\n                https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb\n\n            cycle_save_name (str): use to save the weights at end of each cycle\n\n            best_save_name (str): use to save weights of best model during training.\n\n            metrics (function): some function for evaluating a desired metric. Eg. accuracy.\n\n            callbacks (list(Callback)): callbacks to apply during the training.\n\n            use_wd_sched (bool, optional): set to True to enable weight regularization using\n                the technique mentioned in https://arxiv.org/abs/1711.05101. When this is True\n                alone (see below), the regularization is detached from gradient update and\n                applied directly to the weights.\n\n            norm_wds (bool, optional): when this is set to True along with use_wd_sched, the\n                regularization factor is normalized with each training cycle.\n\n            wds_sched_mult (function, optional): when this is provided along with use_wd_sched\n                as True, the value computed by this function is multiplied with the regularization\n                strength. This function is passed the WeightDecaySchedule object. And example\n                function that can be passed is:\n                            f = lambda x: np.array(x.layer_opt.lrs) / x.init_lrs\n                            \n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work.\n                \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n                \n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n\n        Returns:\n            None\n        """"""\n\n        if callbacks is None: callbacks=[]\n        if metrics is None: metrics=self.metrics\n\n        if use_wd_sched:\n            # This needs to come before CosAnneal() because we need to read the initial learning rate from\n            # layer_opt.lrs - but CosAnneal() alters the layer_opt.lrs value initially (divides by 100)\n            if np.sum(layer_opt.wds) == 0:\n                print(\'fit() warning: use_wd_sched is set to True, but weight decay(s) passed are 0. Use wds to \'\n                      \'pass weight decay values.\')\n            batch_per_epoch = len(data.trn_dl)\n            cl = cycle_len if cycle_len else 1\n            self.wd_sched = WeightDecaySchedule(layer_opt, batch_per_epoch, cl, cycle_mult, n_cycle,\n                                                norm_wds, wds_sched_mult)\n            callbacks += [self.wd_sched]\n\n        if use_clr is not None:\n            clr_div,cut_div = use_clr[:2]\n            moms = use_clr[2:] if len(use_clr) > 2 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=clr_div, cut_div=cut_div,\n                                    momentums=moms)\n        elif use_clr_beta is not None:\n            div,pct = use_clr_beta[:2]\n            moms = use_clr_beta[2:] if len(use_clr_beta) > 3 else None\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            self.sched = CircularLR_beta(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=div,\n                                    pct=pct, momentums=moms)\n        elif cycle_len:\n            cycle_end = self.get_cycle_end(cycle_save_name)\n            cycle_batches = len(data.trn_dl)*cycle_len\n            self.sched = CosAnneal(layer_opt, cycle_batches, on_cycle_end=cycle_end, cycle_mult=cycle_mult)\n        elif not self.sched: self.sched=LossRecorder(layer_opt)\n        callbacks+=[self.sched]\n\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(model)\n            callbacks+=[SWA(model, self.swa_model, swa_start)]\n\n        n_epoch = int(sum_geom(cycle_len if cycle_len else 1, cycle_mult, n_cycle))\n        return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def get_layer_groups(self): return self.models.get_layer_groups()\n\n    def get_layer_opt(self, lrs, wds):\n\n        """"""Method returns an instance of the LayerOptimizer class, which\n        allows for setting differential learning rates for different\n        parts of the model.\n\n        An example of how a model maybe differentiated into different parts\n        for application of differential learning rates and weight decays is\n        seen in ../.../courses/dl1/fastai/conv_learner.py, using the dict\n        \'model_meta\'. Currently, this seems supported only for convolutional\n        networks such as VGG-19, ResNet-XX etc.\n\n        Args:\n            lrs (float or list(float)): learning rate(s) for the model\n\n            wds (float or list(float)): weight decay parameter(s).\n\n        Returns:\n            An instance of a LayerOptimizer\n        """"""\n        return LayerOptimizer(self.opt_fn, self.get_layer_groups(), lrs, wds)\n\n    def fit(self, lrs, n_cycle, wds=None, **kwargs):\n\n        """"""Method gets an instance of LayerOptimizer and delegates to self.fit_gen(..)\n\n        Note that one can specify a list of learning rates which, when appropriately\n        defined, will be applied to different segments of an architecture. This seems\n        mostly relevant to ImageNet-trained models, where we want to alter the layers\n        closest to the images by much smaller amounts.\n\n        Likewise, a single or list of weight decay parameters can be specified, which\n        if appropriate for a model, will apply variable weight decay parameters to\n        different segments of the model.\n\n        Args:\n            lrs (float or list(float)): learning rate for the model\n\n            n_cycle (int): number of cycles (or iterations) to fit the model for\n\n            wds (float or list(float)): weight decay parameter(s).\n\n            kwargs: other arguments\n\n        Returns:\n            None\n        """"""\n        self.sched = None\n        layer_opt = self.get_layer_opt(lrs, wds)\n        return self.fit_gen(self.model, self.data, layer_opt, n_cycle, **kwargs)\n\n    def warm_up(self, lr, wds=None):\n        layer_opt = self.get_layer_opt(lr/4, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), lr, linear=True)\n        return self.fit_gen(self.model, self.data, layer_opt, 1)\n\n    def lr_find(self, start_lr=1e-5, end_lr=10, wds=None, linear=False, **kwargs):\n        """"""Helps you find an optimal learning rate for a model.\n\n         It uses the technique developed in the 2015 paper\n         `Cyclical Learning Rates for Training Neural Networks`, where\n         we simply keep increasing the learning rate from a very small value,\n         until the loss starts decreasing.\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            wds (iterable/float)\n\n        Examples:\n            As training moves us closer to the optimal weights for a model,\n            the optimal learning rate will be smaller. We can take advantage of\n            that knowledge and provide lr_find() with a starting learning rate\n            1000x smaller than the model\'s current learning rate as such:\n\n            >> learn.lr_find(lr/1000)\n\n            >> lrs = np.array([ 1e-4, 1e-3, 1e-2 ])\n            >> learn.lr_find(lrs / 1000)\n\n        Notes:\n            lr_find() may finish before going through each batch of examples if\n            the loss decreases enough.\n\n        .. _Cyclical Learning Rates for Training Neural Networks:\n            http://arxiv.org/abs/1506.01186\n\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder(layer_opt, len(self.data.trn_dl), end_lr, linear=linear)\n        self.fit_gen(self.model, self.data, layer_opt, 1, **kwargs)\n        self.load(\'tmp\')\n\n    def lr_find2(self, start_lr=1e-5, end_lr=10, num_it = 100, wds=None, linear=False, stop_dv=True, **kwargs):\n        """"""A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n        At each step, it computes the validation loss and the metrics on the next\n        batch of the validation data, so it\'s slower than lr_find().\n\n        Args:\n            start_lr (float/numpy array) : Passing in a numpy array allows you\n                to specify learning rates for a learner\'s layer_groups\n            end_lr (float) : The maximum learning rate to try.\n            num_it : the number of iterations you want it to run\n            wds (iterable/float)\n            stop_dv : stops (or not) when the losses starts to explode.\n        """"""\n        self.save(\'tmp\')\n        layer_opt = self.get_layer_opt(start_lr, wds)\n        self.sched = LR_Finder2(layer_opt, num_it, end_lr, linear=linear, metrics=self.metrics, stop_dv=stop_dv)\n        self.fit_gen(self.model, self.data, layer_opt, num_it//len(self.data.trn_dl) + 1, all_val=True, **kwargs)\n        self.load(\'tmp\')\n\n    def predict(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict(m, dl)\n\n    def predict_with_targs(self, is_test=False, use_swa=False):\n        dl = self.data.test_dl if is_test else self.data.val_dl\n        m = self.swa_model if use_swa else self.model\n        return predict_with_targs(m, dl)\n\n    def predict_dl(self, dl): return predict_with_targs(self.model, dl)[0]\n\n    def predict_array(self, arr):\n        self.model.eval()\n        return to_np(self.model(to_gpu(V(T(arr)))))\n\n    def TTA(self, n_aug=4, is_test=False):\n        """""" Predict with Test Time Augmentation (TTA)\n\n        Additional to the original test/validation images, apply image augmentation to them\n        (just like for training images) and calculate the mean of predictions. The intent\n        is to increase the accuracy of predictions by examining the images using multiple\n        perspectives.\n\n        Args:\n            n_aug: a number of augmentation images to use per original image\n            is_test: indicate to use test images; otherwise use validation images\n\n        Returns:\n            (tuple): a tuple containing:\n\n                log predictions (numpy.ndarray): log predictions (i.e. `np.exp(log_preds)` will return probabilities)\n                targs (numpy.ndarray): target values when `is_test==False`; zeros otherwise.\n        """"""\n        dl1 = self.data.test_dl     if is_test else self.data.val_dl\n        dl2 = self.data.test_aug_dl if is_test else self.data.aug_dl\n        preds1,targs = predict_with_targs(self.model, dl1)\n        preds1 = [preds1]*math.ceil(n_aug/4)\n        preds2 = [predict_with_targs(self.model, dl2)[0] for i in tqdm(range(n_aug), leave=False)]\n        return np.stack(preds1+preds2), targs\n\n    def fit_opt_sched(self, phases, cycle_save_name=None, best_save_name=None, stop_div=False, data_list=None, callbacks=None, \n                      cut = None, use_swa=False, swa_start=1, swa_eval_freq=5, **kwargs):\n        """"""Wraps us the content of phases to send them to model.fit(..)\n\n        This will split the training in several parts, each with their own learning rates/\n        wds/momentums/optimizer detailed in phases.\n\n        Additionaly we can add a list of different data objets in data_list to train\n        on different datasets (to change the size for instance) for each of these groups.\n\n        Args:\n            phases: a list of TrainingPhase objects\n            stop_div: when True, stops the training if the loss goes too high\n            data_list: a list of different Data objects.\n            kwargs: other arguments\n            use_swa (bool, optional): when this is set to True, it will enable the use of\n                Stochastic Weight Averaging (https://arxiv.org/abs/1803.05407). The learner will\n                include an additional model (in the swa_model attribute) for keeping track of the \n                average weights as described in the paper. All testing of this technique so far has\n                been in image classification, so use in other contexts is not guaranteed to work. \n            swa_start (int, optional): if use_swa is set to True, then this determines the epoch\n                to start keeping track of the average weights. It is 1-indexed per the paper\'s\n                conventions.\n            swa_eval_freq (int, optional): if use_swa is set to True, this determines the frequency\n                at which to evaluate the performance of the swa_model. This evaluation can be costly\n                for models using BatchNorm (requiring a full pass through the data), which is why the\n                default is not to evaluate after each epoch.\n        Returns:\n            None\n        """"""\n        if data_list is None: data_list=[]\n        if callbacks is None: callbacks=[]\n        layer_opt = LayerOptimizer(phases[0].opt_fn, self.get_layer_groups(), 1e-2, phases[0].wds)\n        self.sched = OptimScheduler(layer_opt, phases, len(self.data.trn_dl), stop_div)\n        callbacks.append(self.sched)\n        metrics = self.metrics\n        if best_save_name is not None:\n            callbacks+=[SaveBestModel(self, layer_opt, metrics, best_save_name)]\n        if use_swa:\n            # make a copy of the model to track average weights\n            self.swa_model = copy.deepcopy(self.model)\n            callbacks+=[SWA(self.model, self.swa_model, swa_start)]\n        n_epochs = [phase.epochs for phase in phases] if cut is None else cut\n        if len(data_list)==0: data_list = [self.data]\n        return fit(self.model, data_list, n_epochs,layer_opt, self.crit,\n            metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, fp16=self.fp16,\n            swa_model=self.swa_model if use_swa else None, swa_start=swa_start, \n            swa_eval_freq=swa_eval_freq, **kwargs)\n\n    def _get_crit(self, data): return F.mse_loss\n\n'"
fastai/courses/ml1/fastai/lm_rnn.py,5,"b'import warnings\nfrom .imports import *\nfrom .torch_imports import *\nfrom .rnn_reg import LockedDropout,WeightDrop,EmbeddingDropout\nfrom .model import Stepper\nfrom .core import set_grad_enabled\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef seq2seq_reg(output, xtra, loss, alpha=0, beta=0):\n    hs,dropped_hs = xtra\n    if alpha:  # Activation Regularization\n        loss = loss + sum(alpha * dropped_hs[-1].pow(2).mean())\n    if beta:   # Temporal Activation Regularization (slowness)\n        h = hs[-1]\n        if len(h)>1: loss = loss + sum(beta * (h[1:] - h[:-1]).pow(2).mean())\n    return loss\n\n\ndef repackage_var(h):\n    """"""Wraps h in new Variables, to detach them from their history.""""""\n    if IS_TORCH_04: return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)\n    else: return Variable(h.data) if type(h) == Variable else tuple(repackage_var(v) for v in h)\n\n\nclass RNN_Encoder(nn.Module):\n\n    """"""A custom RNN encoder network that uses\n        - an embedding matrix to encode input,\n        - a stack of LSTM layers to drive the network, and\n        - variational dropouts in the embedding and LSTM layers\n\n        The architecture for this network was inspired by the work done in\n        ""Regularizing and Optimizing LSTM Language Models"".\n        (https://arxiv.org/pdf/1708.02182.pdf)\n    """"""\n\n    initrange=0.1\n\n    def __init__(self, ntoken, emb_sz, nhid, nlayers, pad_token, bidir=False,\n                 dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5):\n        """""" Default constructor for the RNN_Encoder class\n\n            Args:\n                bs (int): batch size of input data\n                ntoken (int): number of vocabulary (or tokens) in the source dataset\n                emb_sz (int): the embedding size to use to encode each token\n                nhid (int): number of hidden activation per LSTM layer\n                nlayers (int): number of LSTM layers to use in the architecture\n                pad_token (int): the int value used for padding text.\n                dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n                dropouti (float): dropout to apply to the input layer.\n                dropoute (float): dropout to apply to the embedding layer.\n                wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n\n            Returns:\n                None\n          """"""\n\n        super().__init__()\n        self.ndir = 2 if bidir else 1\n        self.bs = 1\n        self.encoder = nn.Embedding(ntoken, emb_sz, padding_idx=pad_token)\n        self.encoder_with_dropout = EmbeddingDropout(self.encoder)\n        self.rnns = [nn.LSTM(emb_sz if l == 0 else nhid, (nhid if l != nlayers - 1 else emb_sz)//self.ndir,\n             1, bidirectional=bidir) for l in range(nlayers)]\n        if wdrop: self.rnns = [WeightDrop(rnn, wdrop) for rnn in self.rnns]\n        self.rnns = torch.nn.ModuleList(self.rnns)\n        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n\n        self.emb_sz,self.nhid,self.nlayers,self.dropoute = emb_sz,nhid,nlayers,dropoute\n        self.dropouti = LockedDropout(dropouti)\n        self.dropouths = nn.ModuleList([LockedDropout(dropouth) for l in range(nlayers)])\n\n    def forward(self, input):\n        """""" Invoked during the forward propagation of the RNN_Encoder module.\n        Args:\n            input (Tensor): input of shape (sentence length x batch_size)\n\n        Returns:\n            raw_outputs (tuple(list (Tensor), list(Tensor)): list of tensors evaluated from each RNN layer without using\n            dropouth, list of tensors evaluated from each RNN layer using dropouth,\n        """"""\n        sl,bs = input.size()\n        if bs!=self.bs:\n            self.bs=bs\n            self.reset()\n        with set_grad_enabled(self.training):\n            emb = self.encoder_with_dropout(input, dropout=self.dropoute if self.training else 0)\n            emb = self.dropouti(emb)\n            raw_output = emb\n            new_hidden,raw_outputs,outputs = [],[],[]\n            for l, (rnn,drop) in enumerate(zip(self.rnns, self.dropouths)):\n                current_input = raw_output\n                with warnings.catch_warnings():\n                    warnings.simplefilter(""ignore"")\n                    raw_output, new_h = rnn(raw_output, self.hidden[l])\n                new_hidden.append(new_h)\n                raw_outputs.append(raw_output)\n                if l != self.nlayers - 1: raw_output = drop(raw_output)\n                outputs.append(raw_output)\n\n            self.hidden = repackage_var(new_hidden)\n        return raw_outputs, outputs\n\n    def one_hidden(self, l):\n        nh = (self.nhid if l != self.nlayers - 1 else self.emb_sz)//self.ndir\n        if IS_TORCH_04: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_())\n        else: return Variable(self.weights.new(self.ndir, self.bs, nh).zero_(), volatile=not self.training)\n\n    def reset(self):\n        self.weights = next(self.parameters()).data\n        self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.nlayers)]\n\n\nclass MultiBatchRNN(RNN_Encoder):\n    def __init__(self, bptt, max_seq, *args, **kwargs):\n        self.max_seq,self.bptt = max_seq,bptt\n        super().__init__(*args, **kwargs)\n\n    def concat(self, arrs):\n        return [torch.cat([l[si] for l in arrs]) for si in range(len(arrs[0]))]\n\n    def forward(self, input):\n        sl,bs = input.size()\n        for l in self.hidden:\n            for h in l: h.data.zero_()\n        raw_outputs, outputs = [],[]\n        for i in range(0, sl, self.bptt):\n            r, o = super().forward(input[i: min(i+self.bptt, sl)])\n            if i>(sl-self.max_seq):\n                raw_outputs.append(r)\n                outputs.append(o)\n        return self.concat(raw_outputs), self.concat(outputs)\n\nclass LinearDecoder(nn.Module):\n    initrange=0.1\n    def __init__(self, n_out, nhid, dropout, tie_encoder=None):\n        super().__init__()\n        self.decoder = nn.Linear(nhid, n_out, bias=False)\n        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n        self.dropout = LockedDropout(dropout)\n        if tie_encoder: self.decoder.weight = tie_encoder.weight\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = self.dropout(outputs[-1])\n        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n        result = decoded.view(-1, decoded.size(1))\n        return result, raw_outputs, outputs\n\n\nclass LinearBlock(nn.Module):\n    def __init__(self, ni, nf, drop):\n        super().__init__()\n        self.lin = nn.Linear(ni, nf)\n        self.drop = nn.Dropout(drop)\n        self.bn = nn.BatchNorm1d(ni)\n\n    def forward(self, x): return self.lin(self.drop(self.bn(x)))\n\n\nclass PoolingLinearClassifier(nn.Module):\n    def __init__(self, layers, drops):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            LinearBlock(layers[i], layers[i + 1], drops[i]) for i in range(len(layers) - 1)])\n\n    def pool(self, x, bs, is_max):\n        f = F.adaptive_max_pool1d if is_max else F.adaptive_avg_pool1d\n        return f(x.permute(1,2,0), (1,)).view(bs,-1)\n\n    def forward(self, input):\n        raw_outputs, outputs = input\n        output = outputs[-1]\n        sl,bs,_ = output.size()\n        avgpool = self.pool(output, bs, False)\n        mxpool = self.pool(output, bs, True)\n        x = torch.cat([output[-1], mxpool, avgpool], 1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return l_x, raw_outputs, outputs\n\n\nclass SequentialRNN(nn.Sequential):\n    def reset(self):\n        for c in self.children():\n            if hasattr(c, \'reset\'): c.reset()\n\n\ndef get_language_model(n_tok, emb_sz, nhid, nlayers, pad_token,\n                 dropout=0.4, dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5, tie_weights=True):\n    """"""Returns a SequentialRNN model.\n\n    A RNN_Encoder layer is instantiated using the parameters provided.\n\n    This is followed by the creation of a LinearDecoder layer.\n\n    Also by default (i.e. tie_weights = True), the embedding matrix used in the RNN_Encoder\n    is used to  instantiate the weights for the LinearDecoder layer.\n\n    The SequentialRNN layer is the native torch\'s Sequential wrapper that puts the RNN_Encoder and\n    LinearDecoder layers sequentially in the model.\n\n    Args:\n        n_tok (int): number of unique vocabulary words (or tokens) in the source dataset\n        emb_sz (int): the embedding size to use to encode each token\n        nhid (int): number of hidden activation per LSTM layer\n        nlayers (int): number of LSTM layers to use in the architecture\n        pad_token (int): the int value used for padding text.\n        dropouth (float): dropout to apply to the activations going from one LSTM layer to another\n        dropouti (float): dropout to apply to the input layer.\n        dropoute (float): dropout to apply to the embedding layer.\n        wdrop (float): dropout used for a LSTM\'s internal (or hidden) recurrent weights.\n        tie_weights (bool): decide if the weights of the embedding matrix in the RNN encoder should be tied to the\n            weights of the LinearDecoder layer.\n    Returns:\n        A SequentialRNN model\n    """"""\n\n    rnn_enc = RNN_Encoder(n_tok, emb_sz, nhid=nhid, nlayers=nlayers, pad_token=pad_token,\n                 dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    enc = rnn_enc.encoder if tie_weights else None\n    return SequentialRNN(rnn_enc, LinearDecoder(n_tok, emb_sz, dropout, tie_encoder=enc))\n\n\ndef get_rnn_classifer(bptt, max_seq, n_class, n_tok, emb_sz, n_hid, n_layers, pad_token, layers, drops, bidir=False,\n                      dropouth=0.3, dropouti=0.5, dropoute=0.1, wdrop=0.5):\n    rnn_enc = MultiBatchRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir,\n                      dropouth=dropouth, dropouti=dropouti, dropoute=dropoute, wdrop=wdrop)\n    return SequentialRNN(rnn_enc, PoolingLinearClassifier(layers, drops))\n\n'"
fastai/courses/ml1/fastai/losses.py,1,"b'from .imports import *\nfrom .torch_imports import *\n\ndef fbeta_torch(y_true, y_pred, beta, threshold, eps=1e-9):\n    y_pred = (y_pred.float() > threshold).float()\n    y_true = y_true.float()\n    tp = (y_pred * y_true).sum(dim=1)\n    precision = tp / (y_pred.sum(dim=1)+eps)\n    recall = tp / (y_true.sum(dim=1)+eps)\n    return torch.mean(\n        precision*recall / (precision*(beta**2)+recall+eps) * (1+beta**2))\n\n'"
fastai/courses/ml1/fastai/lsuv_initializer.py,4,"b'""""""\nFrom https://github.com/ducha-aiki/LSUV-pytorch\n\nCopyright (C) 2017, Dmytro Mishkin\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the\n   distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n""""""\n\nimport numpy as np\nimport torch\nimport torch.nn.init\nimport torch.nn as nn\n\ngg = {}\ngg[\'hook_position\'] = 0\ngg[\'total_fc_conv_layers\'] = 0\ngg[\'done_counter\'] = -1\ngg[\'hook\'] = None\ngg[\'act_dict\'] = {}\ngg[\'counter_to_apply_correction\'] = 0\ngg[\'correction_needed\'] = False\ngg[\'current_coef\'] = 1.0\n\n# Orthonorm init code is taked from Lasagne\n# https://github.com/Lasagne/Lasagne/blob/master/lasagne/init.py\ndef svd_orthonormal(w):\n    shape = w.shape\n    if len(shape) < 2:\n        raise RuntimeError(""Only shapes of length 2 or more are supported."")\n    flat_shape = (shape[0], np.prod(shape[1:]))\n    a = np.random.normal(0.0, 1.0, flat_shape)#w;\n    u, _, v = np.linalg.svd(a, full_matrices=False)\n    q = u if u.shape == flat_shape else v\n    q = q.reshape(shape)\n    return q.astype(np.float32)\n\ndef store_activations(self, input, output):\n    gg[\'act_dict\'] = output.data.cpu().numpy();\n    return\n\ndef add_current_hook(m):\n    if gg[\'hook\'] is not None:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'hook_position\'] > gg[\'done_counter\']:\n            gg[\'hook\'] = m.register_forward_hook(store_activations)\n        else:\n            gg[\'hook_position\'] += 1\n    return\n\ndef count_conv_fc_layers(m):\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        gg[\'total_fc_conv_layers\'] +=1\n    return\n\ndef remove_hooks(hooks):\n    for h in hooks:\n        h.remove()\n    return\n\ndef orthogonal_weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n        if hasattr(m, \'weight_v\'):\n            w_ortho = svd_orthonormal(m.weight_v.data.cpu().numpy())\n            m.weight_v.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n        else:\n            w_ortho = svd_orthonormal(m.weight.data.cpu().numpy())\n            m.weight.data = torch.from_numpy(w_ortho)\n            try:\n                nn.init.constant(m.bias, 0)\n            except:\n                pass\n    return\n\ndef apply_weights_correction(m):\n    if gg[\'hook\'] is None:\n        return\n    if not gg[\'correction_needed\']:\n        return\n    if (isinstance(m, nn.Conv2d)) or (isinstance(m, nn.Linear)):\n        if gg[\'counter_to_apply_correction\'] < gg[\'hook_position\']:\n            gg[\'counter_to_apply_correction\'] += 1\n        else:\n            if hasattr(m, \'weight_g\'):\n                m.weight_g.data *= float(gg[\'current_coef\'])\n                gg[\'correction_needed\'] = False\n            else:\n                m.weight.data *= gg[\'current_coef\']\n                gg[\'correction_needed\'] = False\n            return\n    return\n\ndef apply_lsuv_init(model, data, needed_std=1.0, std_tol=0.1, max_attempts=10, do_orthonorm=True, cuda=True):\n    model.eval();\n    if cuda:\n        model=model.cuda()\n        data=data.cuda()\n    else:\n        model=model.cpu()\n        data=data.cpu()        \n        \n    model.apply(count_conv_fc_layers)\n    if do_orthonorm:\n        model.apply(orthogonal_weights_init)\n        if cuda:\n            model=model.cuda()\n    for layer_idx in range(gg[\'total_fc_conv_layers\']):\n        model.apply(add_current_hook)\n        out = model(data)\n        current_std = gg[\'act_dict\'].std()\n        attempts = 0\n        while (np.abs(current_std - needed_std) > std_tol):\n            gg[\'current_coef\'] =  needed_std / (current_std  + 1e-8);\n            gg[\'correction_needed\'] = True\n            model.apply(apply_weights_correction)\n            if cuda:\n                model=model.cuda()\n            out = model(data)\n            current_std = gg[\'act_dict\'].std()\n            attempts+=1\n            if attempts > max_attempts:\n                print(f\'Cannot converge in {max_attempts} iterations\')\n                break\n        if gg[\'hook\'] is not None:\n           gg[\'hook\'].remove()\n        gg[\'done_counter\']+=1\n        gg[\'counter_to_apply_correction\'] = 0\n        gg[\'hook_position\'] = 0\n        gg[\'hook\']  = None\n    if not cuda:\n        model=model.cpu()\n    return model\n'"
fastai/courses/ml1/fastai/metrics.py,3,"b'from .imports import *\nfrom .torch_imports import *\n\ndef accuracy_np(preds, targs):\n    preds = np.argmax(preds, 1)\n    return (preds==targs).mean()\n\ndef accuracy(preds, targs):\n    preds = torch.max(preds, dim=1)[1]\n    return (preds==targs).float().mean()\n\ndef accuracy_thresh(thresh):\n    return lambda preds,targs: accuracy_multi(preds, targs, thresh)\n\ndef accuracy_multi(preds, targs, thresh):\n    return ((preds>thresh).float()==targs).float().mean()\n\ndef accuracy_multi_np(preds, targs, thresh):\n    return ((preds>thresh)==targs).mean()\n\ndef recall(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/targs.sum()\n\ndef precision(preds, targs, thresh=0.5):\n    pred_pos = preds > thresh\n    tpos = torch.mul((targs.byte() == pred_pos), targs.byte())\n    return tpos.sum()/pred_pos.sum()\n\ndef fbeta(preds, targs, beta, thresh=0.5):\n    """"""Calculates the F-beta score (the weighted harmonic mean of precision and recall).\n    This is the micro averaged version where the true positives, false negatives and\n    false positives are calculated globally (as opposed to on a per label basis).\n\n    beta == 1 places equal weight on precision and recall, b < 1 emphasizes precision and\n    beta > 1 favors recall.\n    """"""\n    assert beta > 0, \'beta needs to be greater than 0\'\n    beta2 = beta ** 2\n    rec = recall(preds, targs, thresh)\n    prec = precision(preds, targs, thresh)\n    return (1 + beta2) * prec * rec / (beta2 * prec + rec)\n\ndef f1(preds, targs, thresh=0.5): return fbeta(preds, targs, 1, thresh)\n'"
fastai/courses/ml1/fastai/model.py,8,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .layer_optimizer import *\nfrom .swa import *\nfrom .fp16 import *\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef cut_model(m, cut):\n    return list(m.children())[:cut] if cut else [m]\n\ndef predict_to_bcolz(m, gen, arr, workers=4):\n    arr.trim(len(arr))\n    lock=threading.Lock()\n    m.eval()\n    for x,*_ in tqdm(gen):\n        y = to_np(m(VV(x)).data)\n        with lock:\n            arr.append(y)\n            arr.flush()\n\ndef num_features(m):\n    c=children(m)\n    if len(c)==0: return None\n    for l in reversed(c):\n        if hasattr(l, \'num_features\'): return l.num_features\n        res = num_features(l)\n        if res is not None: return res\n\ndef torch_item(x): return x.item() if hasattr(x,\'item\') else x[0]\n\nclass Stepper():\n    def __init__(self, m, opt, crit, clip=0, reg_fn=None, fp16=False, loss_scale=1):\n        self.m,self.opt,self.crit,self.clip,self.reg_fn = m,opt,crit,clip,reg_fn\n        self.fp16 = fp16\n        self.reset(True)\n        if self.fp16: self.fp32_params = copy_model_to_fp32(m, opt)\n        self.loss_scale = loss_scale\n\n    def reset(self, train=True):\n        if train: apply_leaf(self.m, set_train_mode)\n        else: self.m.eval()\n        if hasattr(self.m, \'reset\'):\n            self.m.reset()\n            if self.fp16: self.fp32_params = copy_model_to_fp32(self.m, self.opt)\n\n    def step(self, xs, y, epoch):\n        xtra = []\n        output = self.m(*xs)\n        if isinstance(output,tuple): output,*xtra = output\n        if self.fp16: self.m.zero_grad()\n        else: self.opt.zero_grad() \n        loss = raw_loss = self.crit(output, y)\n        if self.loss_scale != 1: assert(self.fp16); loss = loss*self.loss_scale\n        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n        loss.backward()\n        if self.fp16: update_fp32_grads(self.fp32_params, self.m)\n        if self.loss_scale != 1:\n            for param in self.fp32_params: param.grad.data.div_(self.loss_scale)\n        if self.clip:   # Gradient clipping\n            if IS_TORCH_04: nn.utils.clip_grad_norm_(trainable_params_(self.m), self.clip)\n            else: nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n        self.opt.step()\n        if self.fp16: \n            copy_fp32_to_model(self.m, self.fp32_params)\n            torch.cuda.synchronize()\n        return torch_item(raw_loss.data)\n\n    def evaluate(self, xs, y):\n        preds = self.m(*xs)\n        if isinstance(preds,tuple): preds=preds[0]\n        return preds, self.crit(preds, y)\n\ndef set_train_mode(m):\n    if (hasattr(m, \'running_mean\') and (getattr(m,\'bn_freeze\',False)\n              or not getattr(m,\'trainable\',False))): m.eval()\n    elif (getattr(m,\'drop_freeze\',False) and hasattr(m, \'p\')\n          and (\'drop\' in type(m).__name__.lower())): m.eval()\n    else: m.train()\n\ndef fit(model, data, n_epochs, opt, crit, metrics=None, callbacks=None, stepper=Stepper,\n        swa_model=None, swa_start=None, swa_eval_freq=None, **kwargs):\n    """""" Fits a model\n\n    Arguments:\n       model (model): any pytorch module\n           net = to_gpu(net)\n       data (ModelData): see ModelData class and subclasses (can be a list)\n       opts: an optimizer. Example: optim.Adam. \n       If n_epochs is a list, it needs to be the layer_optimizer to get the optimizer as it changes.\n       n_epochs(int or list): number of epochs (or list of number of epochs)\n       crit: loss function to optimize. Example: F.cross_entropy\n    """"""\n\n    all_val = kwargs.pop(\'all_val\') if \'all_val\' in kwargs else False\n    get_ep_vals = kwargs.pop(\'get_ep_vals\') if \'get_ep_vals\' in kwargs else False\n    metrics = metrics or []\n    callbacks = callbacks or []\n    avg_mom=0.98\n    batch_num,avg_loss=0,0.\n    for cb in callbacks: cb.on_train_begin()\n    names = [""epoch"", ""trn_loss"", ""val_loss""] + [f.__name__ for f in metrics]\n    if swa_model is not None:\n        swa_names = [\'swa_loss\'] + [f\'swa_{f.__name__}\' for f in metrics]\n        names += swa_names\n        # will use this to call evaluate later\n        swa_stepper = stepper(swa_model, None, crit, **kwargs)\n\n    layout = ""{!s:10} "" * len(names)\n    if not isinstance(n_epochs, Iterable): n_epochs=[n_epochs]\n    if not isinstance(data, Iterable): data = [data]\n    if len(data) == 1: data = data * len(n_epochs)\n    for cb in callbacks: cb.on_phase_begin()\n    model_stepper = stepper(model, opt.opt if hasattr(opt,\'opt\') else opt, crit, **kwargs)\n    ep_vals = collections.OrderedDict()\n    tot_epochs = int(np.ceil(np.array(n_epochs).sum()))\n    cnt_phases = np.array([ep * len(dat.trn_dl) for (ep,dat) in zip(n_epochs,data)]).cumsum()\n    phase = 0\n    for epoch in tnrange(tot_epochs, desc=\'Epoch\'):\n        model_stepper.reset(True)\n        cur_data = data[phase]\n        if hasattr(cur_data, \'trn_sampler\'): cur_data.trn_sampler.set_epoch(epoch)\n        if hasattr(cur_data, \'val_sampler\'): cur_data.val_sampler.set_epoch(epoch)\n        num_batch = len(cur_data.trn_dl)\n        t = tqdm(iter(cur_data.trn_dl), leave=False, total=num_batch)\n        if all_val: val_iter = IterBatch(cur_data.val_dl)\n\n        for (*x,y) in t:\n            batch_num += 1\n            for cb in callbacks: cb.on_batch_begin()\n            loss = model_stepper.step(V(x),V(y), epoch)\n            avg_loss = avg_loss * avg_mom + loss * (1-avg_mom)\n            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n            t.set_postfix(loss=debias_loss)\n            stop=False\n            los = debias_loss if not all_val else [debias_loss] + validate_next(model_stepper,metrics, val_iter)\n            for cb in callbacks: stop = stop or cb.on_batch_end(los)\n            if stop: return\n            if batch_num >= cnt_phases[phase]:\n                for cb in callbacks: cb.on_phase_end()\n                phase += 1\n                if phase >= len(n_epochs):\n                    t.close()\n                    break\n                for cb in callbacks: cb.on_phase_begin()\n                if isinstance(opt, LayerOptimizer): model_stepper.opt = opt.opt\n                if cur_data != data[phase]:\n                    t.close()\n                    break\n\n        if not all_val:\n            vals = validate(model_stepper, cur_data.val_dl, metrics)\n            stop=False\n            for cb in callbacks: stop = stop or cb.on_epoch_end(vals)\n            if swa_model is not None:\n                if (epoch + 1) >= swa_start and ((epoch + 1 - swa_start) % swa_eval_freq == 0 or epoch == tot_epochs - 1):\n                    fix_batchnorm(swa_model, cur_data.trn_dl)\n                    swa_vals = validate(swa_stepper, cur_data.val_dl, metrics)\n                    vals += swa_vals\n\n            if epoch == 0: print(layout.format(*names))\n            print_stats(epoch, [debias_loss] + vals)\n            ep_vals = append_stats(ep_vals, epoch, [debias_loss] + vals)\n        if stop: break\n    for cb in callbacks: cb.on_train_end()\n    if get_ep_vals: return vals, ep_vals\n    else: return vals\n\ndef append_stats(ep_vals, epoch, values, decimals=6):\n    ep_vals[epoch]=list(np.round(values, decimals))\n    return ep_vals\n\ndef print_stats(epoch, values, decimals=6):\n    layout = ""{!s:^10}"" + "" {!s:10}"" * len(values)\n    values = [epoch] + list(np.round(values, decimals))\n    print(layout.format(*values))\n\nclass IterBatch():\n    def __init__(self, dl):\n        self.idx = 0\n        self.dl = dl\n        self.iter = iter(dl)\n\n    def __iter__(self): return self\n\n    def next(self):\n        res = next(self.iter)\n        self.idx += 1\n        if self.idx == len(self.dl):\n            self.iter = iter(self.dl)\n            self.idx=0\n        return res\n\ndef validate_next(stepper, metrics, val_iter):\n    """"""Computes the loss on the next minibatch of the validation set.""""""\n    stepper.reset(False)\n    with no_grad_context():\n        (*x,y) = val_iter.next()\n        preds,l = stepper.evaluate(VV(x), VV(y))\n        res = [to_np(l)[0]]\n        res += [f(preds.data,y) for f in metrics]\n    stepper.reset(True)\n    return res\n\ndef validate(stepper, dl, metrics):\n    batch_cnts,loss,res = [],[],[]\n    stepper.reset(False)\n    with no_grad_context():\n        for (*x,y) in iter(dl):\n            preds, l = stepper.evaluate(VV(x), VV(y))\n            if isinstance(x,list): batch_cnts.append(len(x[0]))\n            else: batch_cnts.append(len(x))\n            loss.append(to_np(l))\n            res.append([f(preds.data, y) for f in metrics])\n    return [np.average(loss, 0, weights=batch_cnts)] + list(np.average(np.stack(res), 0, weights=batch_cnts))\n\ndef get_prediction(x):\n    if is_listy(x): x=x[0]\n    return x.data\n\ndef predict(m, dl):\n    preda,_ = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda))\n\ndef predict_batch(m, x):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    return m(VV(x))\n\ndef predict_with_targs_(m, dl):\n    m.eval()\n    if hasattr(m, \'reset\'): m.reset()\n    res = []\n    for *x,y in iter(dl): res.append([get_prediction(m(*VV(x))),y])\n    return zip(*res)\n\ndef predict_with_targs(m, dl):\n    preda,targa = predict_with_targs_(m, dl)\n    return to_np(torch.cat(preda)), to_np(torch.cat(targa))\n\n# From https://github.com/ncullen93/torchsample\ndef model_summary(m, input_size):\n    def register_hook(module):\n        def hook(module, input, output):\n            class_name = str(module.__class__).split(\'.\')[-1].split(""\'"")[0]\n            module_idx = len(summary)\n\n            m_key = \'%s-%i\' % (class_name, module_idx+1)\n            summary[m_key] = OrderedDict()\n            summary[m_key][\'input_shape\'] = list(input[0].size())\n            summary[m_key][\'input_shape\'][0] = -1\n            if is_listy(output):\n                summary[m_key][\'output_shape\'] = [[-1] + list(o.size())[1:] for o in output]\n            else:\n                summary[m_key][\'output_shape\'] = list(output.size())\n                summary[m_key][\'output_shape\'][0] = -1\n\n            params = 0\n            if hasattr(module, \'weight\'):\n                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n                summary[m_key][\'trainable\'] = module.weight.requires_grad\n            if hasattr(module, \'bias\') and module.bias is not None:\n                params +=  torch.prod(torch.LongTensor(list(module.bias.size())))\n            summary[m_key][\'nb_params\'] = params\n\n        if (not isinstance(module, nn.Sequential) and\n           not isinstance(module, nn.ModuleList) and\n           not (module == m)):\n            hooks.append(module.register_forward_hook(hook))\n\n    summary = OrderedDict()\n    hooks = []\n    m.apply(register_hook)\n\n    if is_listy(input_size[0]):\n        x = [to_gpu(Variable(torch.rand(3,*in_size))) for in_size in input_size]\n    else: x = [to_gpu(Variable(torch.rand(3,*input_size)))]\n    m(*x)\n\n    for h in hooks: h.remove()\n    return summary\n\n'"
fastai/courses/ml1/fastai/nlp.py,4,"b'from .imports import *\nfrom .torch_imports import *\nfrom .core import *\nfrom .model import *\nfrom .dataset import *\nfrom .learner import *\nfrom .text import *\nfrom .lm_rnn import *\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.datasets import language_modeling\n\nclass DotProdNB(nn.Module):\n    def __init__(self, nf, ny, w_adj=0.4, r_adj=10):\n        super().__init__()\n        self.w_adj,self.r_adj = w_adj,r_adj\n        self.w = nn.Embedding(nf+1, 1, padding_idx=0)\n        self.w.weight.data.uniform_(-0.1,0.1)\n        self.r = nn.Embedding(nf+1, ny)\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        w = self.w(feat_idx)\n        r = self.r(feat_idx)\n        x = ((w+self.w_adj)*r/self.r_adj).sum(1)\n        return F.softmax(x)\n\nclass SimpleNB(nn.Module):\n    def __init__(self, nf, ny):\n        super().__init__()\n        self.r = nn.Embedding(nf+1, ny, padding_idx=0)\n        self.b = nn.Parameter(torch.zeros(ny,))\n\n    def forward(self, feat_idx, feat_cnt, sz):\n        r = self.r(feat_idx)\n        x = r.sum(1)+self.b\n        return F.softmax(x)\n\nclass BOW_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.l1_loss\n\ndef calc_pr(y_i, x, y, b):\n    idx = np.argwhere((y==y_i)==b)\n    p = x[idx[:,0]].sum(0)+1\n    return p/((y==y_i)==b).sum()\n\ndef calc_r(y_i, x, y):\n    return np.log(calc_pr(y_i, x, y, True) / calc_pr(y_i, x, y, False))\n\nclass BOW_Dataset(Dataset):\n    def __init__(self, bow, y, max_len):\n        self.bow,self.max_len = bow,max_len\n        self.c = int(y.max())+1\n        self.n,self.vocab_size = bow.shape\n        self.y = one_hot(y,self.c).astype(np.float32)\n        x = self.bow.sign()\n        self.r = np.stack([calc_r(i, x, y).A1 for i in range(self.c)]).T\n\n    def __getitem__(self, i):\n        row = self.bow.getrow(i)\n\n        num_row_entries = row.indices.shape[0]\n        indices = (row.indices + 1).astype(np.int64)\n        data = (row.data).astype(np.int64)\n\n        if num_row_entries < self.max_len:\n            # If short, pad\n            indices = np.pad(indices, (self.max_len - num_row_entries, 0), mode=\'constant\')\n            data = np.pad(data, (self.max_len - num_row_entries, 0), mode=\'constant\')\n        else:\n            # If long, truncate\n            indices, data = indices[-self.max_len:], data[-self.max_len:]\n\n        return indices, data, min(self.max_len, num_row_entries), self.y[i]\n\n    def __len__(self): return len(self.bow.indptr)-1\n\n\nclass TextClassifierData(ModelData):\n    @property\n    def c(self): return self.trn_ds.c\n\n    @property\n    def r(self):\n        return torch.Tensor(np.concatenate([np.zeros((1,self.c)), self.trn_ds.r]))\n\n    def get_model(self, f, **kwargs):\n        m = to_gpu(f(self.trn_ds.vocab_size, self.c, **kwargs))\n        m.r.weight.data = to_gpu(self.r)\n        m.r.weight.requires_grad = False\n        model = BasicModel(m)\n        return BOW_Learner(self, model, metrics=[accuracy_thresh(0.5)], opt_fn=optim.Adam)\n\n    def dotprod_nb_learner(self, **kwargs): return self.get_model(DotProdNB, **kwargs)\n    def nb_learner(self, **kwargs): return self.get_model(SimpleNB, **kwargs)\n\n    @classmethod\n    def from_bow(cls, trn_bow, trn_y, val_bow, val_y, sl):\n        trn_ds = BOW_Dataset(trn_bow, trn_y, sl)\n        val_ds = BOW_Dataset(val_bow, val_y, sl)\n        trn_dl = DataLoader(trn_ds, 64, True)\n        val_dl = DataLoader(val_ds, 64, False)\n        return cls(\'.\', trn_dl, val_dl)\n\n\ndef flip_tensor(x, dim):\n    xsize = x.size()\n    dim = x.dim() + dim if dim < 0 else dim\n    x = x.view(-1, *xsize[dim:])\n    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1,\n                      -1, -1), (\'cpu\',\'cuda\')[x.is_cuda])().long(), :]\n    return x.view(xsize)\n\n\nclass LanguageModelLoader():\n\n    def __init__(self, ds, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        text = sum([o.text for o in ds], [])\n        fld = ds.fields[\'text\']\n        nums = fld.numericalize([text],device=None if torch.cuda.is_available() else -1)\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        return self\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def __next__(self):\n        if self.i >= self.n-1 or self.iter>=len(self): raise StopIteration\n        bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n        seq_len = max(5, int(np.random.normal(bptt, 5)))\n        res = self.get_batch(self.i, seq_len)\n        self.i += seq_len\n        self.iter += 1\n        return res\n\n    def batchify(self, data):\n        nb = data.size(0) // self.bs\n        data = data[:nb*self.bs]\n        data = data.view(self.bs, -1).t().contiguous()\n        if self.backwards: data=flip_tensor(data, 0)\n        return to_gpu(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass ConcatTextDataset(torchtext.data.Dataset):\n    def __init__(self, path, text_field, newline_eos=True, encoding=\'utf-8\', **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n        if os.path.isdir(path): paths=glob(f\'{path}/*.*\')\n        else: paths=[path]\n        for p in paths:\n            for line in open(p, encoding=encoding): text += text_field.preprocess(line)\n            if newline_eos: text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n        super().__init__(examples, fields, **kwargs)\n\n\nclass ConcatTextDatasetFromDataFrames(torchtext.data.Dataset):\n    def __init__(self, df, text_field, col, newline_eos=True, **kwargs):\n        fields = [(\'text\', text_field)]\n        text = []\n\n        text += text_field.preprocess(df[col].str.cat(sep=\' <eos> \'))\n        if (newline_eos): text.append(\'<eos>\')\n\n        examples = [torchtext.data.Example.fromlist([text], fields)]\n\n        super().__init__(examples, fields, **kwargs)\n\n    @classmethod\n    def splits(cls, train_df=None, val_df=None, test_df=None, keep_nones=False, **kwargs):\n        res = (\n            cls(train_df, **kwargs),\n            cls(val_df, **kwargs),\n            map_none(test_df, partial(cls, **kwargs)))  # not required\n        return res if keep_nones else tuple(d for d in res if d is not None)\n\n\nclass LanguageModelData():\n    """"""\n    This class provides the entry point for dealing with supported NLP tasks.\n    Usage:\n    1.  Use one of the factory constructors (from_dataframes, from_text_files) to\n        obtain an instance of the class.\n    2.  Use the get_model method to return a RNN_Learner instance (a network suited\n        for NLP tasks), then proceed with training.\n\n        Example:\n            >> TEXT = data.Field(lower=True, tokenize=spacy_tok)\n            >> FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n            >> md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=64, bptt=70, min_freq=10)\n\n            >> em_sz = 200  # size of each embedding vector\n            >> nh = 500     # number of hidden activations per layer\n            >> nl = 3       # number of layers\n\n            >> opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n            >> learner = md.get_model(opt_fn, em_sz, nh, nl,\n                           dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n            >> learner.reg_fn = seq2seq_reg\n            >> learner.clip=0.3\n\n            >> learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n\n    """"""\n    def __init__(self, path, field, trn_ds, val_ds, test_ds, bs, bptt, backwards=False, **kwargs):\n        """""" Constructor for the class. An important thing that happens here is\n            that the field\'s ""build_vocab"" method is invoked, which builds the vocabulary\n            for this NLP model.\n\n            Also, three instances of the LanguageModelLoader are constructed; one each\n            for training data (self.trn_dl), validation data (self.val_dl), and the\n            testing data (self.test_dl)\n\n            Args:\n                path (str): testing path\n                field (Field): torchtext field object\n                trn_ds (Dataset): training dataset\n                val_ds (Dataset): validation dataset\n                test_ds (Dataset): testing dataset\n                bs (int): batch size\n                bptt (int): back propagation through time\n                kwargs: other arguments\n        """"""\n        self.bs = bs\n        self.path = path\n        self.trn_ds = trn_ds; self.val_ds = val_ds; self.test_ds = test_ds\n        if not hasattr(field, \'vocab\'): field.build_vocab(self.trn_ds, **kwargs)\n\n        self.pad_idx = field.vocab.stoi[field.pad_token]\n        self.nt = len(field.vocab)\n\n        factory = lambda ds: LanguageModelLoader(ds, bs, bptt, backwards=backwards)\n        self.trn_dl = factory(self.trn_ds)\n        self.val_dl = factory(self.val_ds)\n        self.test_dl = map_none(self.test_ds, factory)  # not required\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        """""" Method returns a RNN_Learner object, that wraps an instance of the RNN_Encoder module.\n\n        Args:\n            opt_fn (Optimizer): the torch optimizer function to use\n            emb_sz (int): embedding size\n            n_hid (int): number of hidden inputs\n            n_layers (int): number of hidden layers\n            kwargs: other arguments\n\n        Returns:\n            An instance of the RNN_Learner class.\n\n        """"""\n        m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = SingleModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    @classmethod\n    def from_dataframes(cls, path, field, col, train_df, val_df, test_df=None, bs=64, bptt=70, **kwargs):\n        trn_ds, val_ds, test_ds = ConcatTextDatasetFromDataFrames.splits(\n            text_field=field, col=col, train_df=train_df, val_df=val_df, test_df=test_df, keep_nones=True)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n    @classmethod\n    def from_text_files(cls, path, field, train, validation, test=None, bs=64, bptt=70, **kwargs):\n        """""" Method used to instantiate a LanguageModelData object that can be used for a\n            supported nlp task.\n\n        Args:\n            path (str): the absolute path in which temporary model data will be saved\n            field (Field): torchtext field\n            train (str): file location of the training data\n            validation (str): file location of the validation data\n            test (str): file location of the testing data\n            bs (int): batch size to use\n            bptt (int): back propagation through time hyper-parameter\n            kwargs: other arguments\n\n        Returns:\n            a LanguageModelData instance, which most importantly, provides us the datasets for training,\n                validation, and testing\n\n        Note:\n            The train, validation, and test path can be pointed to any file (or folder) that contains a valid\n                text corpus.\n\n        """"""\n        trn_ds, val_ds, test_ds = ConcatTextDataset.splits(\n            path, text_field=field, train=train, validation=validation, test=test)\n        return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)\n\n\nclass TextDataLoader():\n    def __init__(self, src, x_fld, y_fld):\n        self.src,self.x_fld,self.y_fld = src,x_fld,y_fld\n\n    def __len__(self): return len(self.src)\n\n    def __iter__(self):\n        it = iter(self.src)\n        for i in range(len(self)):\n            b = next(it)\n            yield getattr(b, self.x_fld).data, getattr(b, self.y_fld).data\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n\nclass TextData(ModelData):\n    def create_td(self, it): return TextDataLoader(it, self.text_fld, self.label_fld)\n\n    @classmethod\n    def from_splits(cls, path, splits, bs, text_name=\'text\', label_name=\'label\'):\n        text_fld = splits[0].fields[text_name]\n        label_fld = splits[0].fields[label_name]\n        if hasattr(label_fld, \'build_vocab\'): label_fld.build_vocab(splits[0])\n        iters = torchtext.data.BucketIterator.splits(splits, batch_size=bs)\n        trn_iter,val_iter,test_iter = iters[0],iters[1],None\n        test_dl = None\n        if len(iters) == 3:\n            test_iter = iters[2]\n            test_dl = TextDataLoader(test_iter, text_name, label_name)\n        trn_dl = TextDataLoader(trn_iter, text_name, label_name)\n        val_dl = TextDataLoader(val_iter, text_name, label_name)\n        obj = cls.from_dls(path, trn_dl, val_dl, test_dl)\n        obj.bs = bs\n        obj.pad_idx = text_fld.vocab.stoi[text_fld.pad_token]\n        obj.nt = len(text_fld.vocab)\n        obj.c = (len(label_fld.vocab) if hasattr(label_fld, \'vocab\')\n                 else len(getattr(splits[0][0], label_name)))\n        return obj\n\n    def to_model(self, m, opt_fn):\n        model = TextModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n    def get_model(self, opt_fn, max_sl, bptt, emb_sz, n_hid, n_layers, dropout, **kwargs):\n        m = get_rnn_classifer(bptt, max_sl, self.c, self.nt,\n              layers=[emb_sz*3, self.c], drops=[dropout],\n              emb_sz=emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=self.pad_idx, **kwargs)\n        return self.to_model(m, opt_fn)\n\n'"
fastai/courses/ml1/fastai/plots.py,0,"b'from .imports import *\nfrom .torch_imports import *\nfrom sklearn.metrics import confusion_matrix\n\ndef ceildiv(a, b):\n    return -(-a // b)\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None, maintitle=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None:\n        plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else \'none\')\n\n\ndef plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n    """"""Plots images given image files.\n\n    Arguments:\n        im_paths (list): list of paths\n        figsize (tuple): figure size\n        rows (int): number of rows\n        titles (list): list of titles\n        maintitle (string): main title\n    """"""\n    f = plt.figure(figsize=figsize)\n    if maintitle is not None: plt.suptitle(maintitle, fontsize=16)\n    for i in range(len(imspaths)):\n        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        img = plt.imread(imspaths[i])\n        plt.imshow(img)\n\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title=\'Confusion matrix\', cmap=plt.cm.Blues, figsize=None):\n    """"""\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    (This function is copied from the scikit docs.)\n    """"""\n    plt.figure(figsize=figsize)\n    plt.imshow(cm, interpolation=\'nearest\', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize: cm = cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis]\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=""center"", color=""white"" if cm[i, j] > thresh else ""black"")\n\n    plt.tight_layout()\n    plt.ylabel(\'True label\')\n    plt.xlabel(\'Predicted label\')\n\ndef plots_raw(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, ceildiv(len(ims), rows), i+1)\n        sp.axis(\'Off\')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])\n\ndef load_img_id(ds, idx, path): return np.array(PIL.Image.open(os.path.join(path, ds.fnames[idx])))\n\n\nclass ImageModelResults():\n    """""" Visualize the results of an image model\n\n    Arguments:\n        ds (dataset): a dataset which contains the images\n        log_preds (numpy.ndarray): predictions for the dataset in log scale\n\n    Returns:\n        ImageModelResults\n    """"""\n    def __init__(self, ds, log_preds):\n        """"""Initialize an ImageModelResults class instance""""""\n        self.ds = ds\n        # returns the indices of the maximum value of predictions along axis 1, representing the predicted class\n        # log_preds.shape = (number_of_samples, number_of_classes);\n        # preds.shape = (number_of_samples,)\n        self.preds = np.argmax(log_preds, axis=1)\n        # computes the probabilities\n        self.probs = np.exp(log_preds)\n        # extracts the number of classes\n        self.num_classes = log_preds.shape[1]\n\n    def plot_val_with_title(self, idxs, y):\n        """""" Displays the images and their probabilities of belonging to a certain class\n\n            Arguments:\n                idxs (numpy.ndarray): indexes of the image samples from the dataset\n                y (int): the selected class\n\n            Returns:\n                Plots the images in n rows [rows = n]\n        """"""\n        # if there are any samples to be displayed\n        if len(idxs) > 0:\n            imgs = np.stack([self.ds[x][0] for x in idxs])\n            title_probs = [self.probs[x,y] for x in idxs]\n\n            return plots(self.ds.denorm(imgs), rows=1, titles=title_probs)\n        # if idxs is empty return false\n        else:\n            return False;\n\n    def most_by_mask(self, mask, y, mult):\n        """""" Extracts the first 4 most correct/incorrect indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n                mult (int): sets the ordering; -1 descending, 1 ascending\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        cnt = min(4, len(idxs))\n        return idxs[np.argsort(mult * self.probs[idxs,y])[:cnt]]\n\n    def most_uncertain_by_mask(self, mask, y):\n        """""" Extracts the first 4 most uncertain indexes from the ordered list of probabilities\n\n            Arguments:\n                mask (numpy.ndarray): the mask of probabilities specific to the selected class; a boolean array with shape (num_of_samples,) which contains True where class==selected_class, and False everywhere else\n                y (int): the selected class\n\n            Returns:\n                idxs (ndarray): An array of indexes of length 4\n        """"""\n        idxs = np.where(mask)[0]\n        # the most uncertain samples will have abs(probs-1/num_classes) close to 0;\n        return idxs[np.argsort(np.abs(self.probs[idxs,y]-(1/self.num_classes)))[:4]]\n\n    def most_by_correct(self, y, is_correct):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        # mult=-1 when the is_correct flag is true -> when we want to display the most correct classes we will make a descending sorting (argsort) because we want that the biggest probabilities to be displayed first.\n        # When is_correct is false, we want to display the most incorrect classes, so we want an ascending sorting since our interest is in the smallest probabilities.\n        mult = -1 if is_correct==True else 1\n        return self.most_by_mask(((self.preds == self.ds.y)==is_correct)\n                                 & (self.ds.y == y), y, mult)\n\n    def plot_by_correct(self, y, is_correct):\n        """""" Plots the images which correspond to the selected class (y) and to the specific case (prediction is correct - is_true=True, prediction is wrong - is_true=False)\n\n            Arguments:\n                y (int): the selected class\n                is_correct (boolean): a boolean flag (True, False) which specify the what to look for. Ex: True - most correct samples, False - most incorrect samples\n        """"""\n        return self.plot_val_with_title(self.most_by_correct(y, is_correct), y)\n\n    def most_by_uncertain(self, y):\n        """""" Extracts the predicted classes which correspond to the selected class (y) and have probabilities nearest to 1/number_of_classes (eg. 0.5 for 2 classes, 0.33 for 3 classes) for the selected class.\n\n            Arguments:\n                y (int): the selected class\n\n            Returns:\n                idxs (numpy.ndarray): An array of indexes (numpy.ndarray)\n        """"""\n        return self.most_uncertain_by_mask((self.ds.y == y), y)\n\n    def plot_most_correct(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most correct.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, True)\n    def plot_most_incorrect(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most incorrect.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_by_correct(y, False)\n    def plot_most_uncertain(self, y):\n        """""" Plots the images which correspond to the selected class (y) and are most uncertain i.e have probabilities nearest to 1/number_of_classes.\n\n            Arguments:\n                y (int): the selected class\n        """"""\n        return self.plot_val_with_title(self.most_by_uncertain(y), y)\n'"
fastai/courses/ml1/fastai/rnn_reg.py,16,"b'from .torch_imports import *\nfrom .core import *\nfrom functools import wraps\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nIS_TORCH_04 = LooseVersion(torch.__version__) >= LooseVersion(\'0.4\')\n\ndef dropout_mask(x, sz, dropout):\n    """""" Applies a dropout mask whose size is determined by passed argument \'sz\'.\n    Args:\n        x (nn.Variable): A torch Variable object\n        sz (tuple(int, int, int)): The expected size of the new tensor\n        dropout (float): The dropout fraction to apply\n\n    This method uses the bernoulli distribution to decide which activations to keep.\n    Additionally, the sampled activations is rescaled is using the factor 1/(1 - dropout).\n\n    In the example given below, one can see that approximately .8 fraction of the\n    returned tensors are zero. Rescaling with the factor 1/(1 - 0.8) returns a tensor\n    with 5\'s in the unit places.\n\n    The official link to the pytorch bernoulli function is here:\n        http://pytorch.org/docs/master/torch.html#torch.bernoulli\n\n    Examples:\n        >>> a_Var = torch.autograd.Variable(torch.Tensor(2, 3, 4).uniform_(0, 1), requires_grad=False)\n        >>> a_Var\n            Variable containing:\n            (0 ,.,.) =\n              0.6890  0.5412  0.4303  0.8918\n              0.3871  0.7944  0.0791  0.5979\n              0.4575  0.7036  0.6186  0.7217\n            (1 ,.,.) =\n              0.8354  0.1690  0.1734  0.8099\n              0.6002  0.2602  0.7907  0.4446\n              0.5877  0.7464  0.4257  0.3386\n            [torch.FloatTensor of size 2x3x4]\n        >>> a_mask = dropout_mask(a_Var.data, (1,a_Var.size(1),a_Var.size(2)), dropout=0.8)\n        >>> a_mask\n            (0 ,.,.) =\n              0  5  0  0\n              0  0  0  5\n              5  0  5  0\n            [torch.FloatTensor of size 1x3x4]\n    """"""\n    return x.new(*sz).bernoulli_(1-dropout)/(1-dropout)\n\n\nclass LockedDropout(nn.Module):\n    def __init__(self, p=0.5):\n        super().__init__()\n        self.p=p\n\n    def forward(self, x):\n        if not self.training or not self.p: return x\n        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n        return Variable(m, requires_grad=False) * x\n\n\nclass WeightDrop(torch.nn.Module):\n    """"""A custom torch layer that serves as a wrapper on another torch layer.\n    Primarily responsible for updating the weights in the wrapped module based\n    on a specified dropout.\n    """"""\n    def __init__(self, module, dropout, weights=[\'weight_hh_l0\']):\n        """""" Default constructor for the WeightDrop module\n\n        Args:\n            module (torch.nn.Module): A pytorch layer being wrapped\n            dropout (float): a dropout value to apply\n            weights (list(str)): the parameters of the wrapped **module**\n                which should be fractionally dropped.\n        """"""\n        super().__init__()\n        self.module,self.weights,self.dropout = module,weights,dropout\n        self._setup()\n\n    def _setup(self):\n        """""" for each string defined in self.weights, the corresponding\n        attribute in the wrapped module is referenced, then deleted, and subsequently\n        registered as a new parameter with a slightly modified name.\n\n        Args:\n            None\n\n         Returns:\n             None\n        """"""\n        if isinstance(self.module, torch.nn.RNNBase): self.module.flatten_parameters = noop\n        for name_w in self.weights:\n            w = getattr(self.module, name_w)\n            del self.module._parameters[name_w]\n            self.module.register_parameter(name_w + \'_raw\', nn.Parameter(w.data))\n\n\n    def _setweights(self):\n        """""" Uses pytorch\'s built-in dropout function to apply dropout to the parameters of\n        the wrapped module.\n\n        Args:\n            None\n        Returns:\n            None\n        """"""\n        for name_w in self.weights:\n            raw_w = getattr(self.module, name_w + \'_raw\')\n            w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n            setattr(self.module, name_w, w)\n\n    def forward(self, *args):\n        """""" updates weights and delegates the propagation of the tensor to the wrapped module\'s\n        forward method\n\n        Args:\n            *args: supplied arguments\n\n        Returns:\n            tensor obtained by running the forward method on the wrapped module.\n        """"""\n        self._setweights()\n        return self.module.forward(*args)\n\nclass EmbeddingDropout(nn.Module):\n\n    """""" Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\n    Uses the dropout_mask custom layer to achieve this.\n\n    Args:\n        embed (torch.nn.Embedding): An embedding torch layer\n        words (torch.nn.Variable): A torch variable\n        dropout (float): dropout fraction to apply to the embedding weights\n        scale (float): additional scaling to apply to the modified embedding weights\n\n    Returns:\n        tensor of size: (batch_size x seq_length x embedding_size)\n\n    Example:\n\n    >> embed = torch.nn.Embedding(10,3)\n    >> words = Variable(torch.LongTensor([[1,2,4,5] ,[4,3,2,9]]))\n    >> words.size()\n        (2,4)\n    >> embed_dropout_layer = EmbeddingDropout(embed)\n    >> dropout_out_ = embed_dropout_layer(embed, words, dropout=0.40)\n    >> dropout_out_\n        Variable containing:\n        (0 ,.,.) =\n          1.2549  1.8230  1.9367\n          0.0000 -0.0000  0.0000\n          2.2540 -0.1299  1.5448\n          0.0000 -0.0000 -0.0000\n\n        (1 ,.,.) =\n          2.2540 -0.1299  1.5448\n         -4.0457  2.4815 -0.2897\n          0.0000 -0.0000  0.0000\n          1.8796 -0.4022  3.8773\n        [torch.FloatTensor of size 2x4x3]\n    """"""\n\n    def __init__(self, embed):\n        super().__init__()\n        self.embed = embed\n\n    def forward(self, words, dropout=0.1, scale=None):\n        if dropout:\n            size = (self.embed.weight.size(0),1)\n            mask = Variable(dropout_mask(self.embed.weight.data, size, dropout))\n            masked_embed_weight = mask * self.embed.weight\n        else: masked_embed_weight = self.embed.weight\n\n        if scale: masked_embed_weight = scale * masked_embed_weight\n\n        padding_idx = self.embed.padding_idx\n        if padding_idx is None: padding_idx = -1\n\n        \n        if IS_TORCH_04:\n            X = F.embedding(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n        else:\n            X = self.embed._backend.Embedding.apply(words,\n                masked_embed_weight, padding_idx, self.embed.max_norm,\n                self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)\n\n        return X\n'"
fastai/courses/ml1/fastai/rnn_train.py,2,b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom .core import *\n\n'
fastai/courses/ml1/fastai/set_spawn.py,0,"b""from multiprocessing import set_start_method\nset_start_method('spawn')\n\n"""
fastai/courses/ml1/fastai/sgdr.py,1,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\nimport copy\n\n\nclass Callback:\n    \'\'\'\n    An abstract class that all callback(e.g., LossRecorder) classes extends from. \n    Must be extended before usage.\n    \'\'\'\n    def on_train_begin(self): pass\n    def on_batch_begin(self): pass\n    def on_phase_begin(self): pass\n    def on_epoch_end(self, metrics): pass\n    def on_phase_end(self): pass\n    def on_batch_end(self, metrics): pass\n    def on_train_end(self): pass\n\n# Useful for maintaining status of a long-running job.\n# \n# Usage:\n# learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\nclass LoggingCallback(Callback):\n    \'\'\'\n    A class useful for maintaining status of a long-running job.\n    e.g.: learn.fit(0.01, 1, callbacks = [LoggingCallback(save_path=""/tmp/log"")])\n    \'\'\'\n    def __init__(self, save_path):\n        super().__init__()\n        self.save_path=save_path\n    def on_train_begin(self):\n        self.batch = 0\n        self.epoch = 0\n        self.phase = 0\n        self.f = open(self.save_path, ""a"", 1)\n        self.log(""\\ton_train_begin"")\n    def on_batch_begin(self):\n        self.log(str(self.batch)+""\\ton_batch_begin"")\n    def on_phase_begin(self):\n        self.log(str(self.phase)+""\\ton_phase_begin"")\n    def on_epoch_end(self, metrics):\n        self.log(str(self.epoch)+""\\ton_epoch_end: ""+str(metrics))\n        self.epoch += 1\n    def on_phase_end(self):\n        self.log(str(self.phase)+""\\ton_phase_end"")\n        self.phase+=1\n    def on_batch_end(self, metrics):\n        self.log(str(self.batch)+""\\ton_batch_end: ""+str(metrics))\n        self.batch += 1\n    def on_train_end(self):\n        self.log(""\\ton_train_end"")\n        self.f.close()\n    def log(self, string):\n        self.f.write(time.strftime(""%Y-%m-%dT%H:%M:%S"")+""\\t""+string+""\\n"")\n        \nclass LossRecorder(Callback):\n    \'\'\'\n    Saves and displays loss functions and other metrics. \n    Default sched when none is specified in a learner. \n    \'\'\'\n    def __init__(self, layer_opt, save_path=\'\', record_mom=False, metrics=[]):\n        super().__init__()\n        self.layer_opt=layer_opt\n        self.init_lrs=np.array(layer_opt.lrs)\n        self.save_path, self.record_mom, self.metrics = save_path, record_mom, metrics\n\n    def on_train_begin(self):\n        self.losses,self.lrs,self.iterations = [],[],[]\n        self.val_losses, self.rec_metrics = [], []\n        if self.record_mom:\n            self.momentums = []\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n        self.save_metrics(metrics)\n\n    def on_batch_end(self, loss):\n        self.iteration += 1\n        self.lrs.append(self.layer_opt.lr)\n        self.iterations.append(self.iteration)\n        if isinstance(loss, list):\n            self.losses.append(loss[0])\n            self.save_metrics(loss[1:])\n        else: self.losses.append(loss)\n        if self.record_mom: self.momentums.append(self.layer_opt.mom)\n\n    def save_metrics(self,vals):\n        self.val_losses.append(vals[0][0] if isinstance(vals[0], Iterable) else vals[0])\n        if len(vals) > 2: self.rec_metrics.append(vals[1:])\n        elif len(vals) == 2: self.rec_metrics.append(vals[1])\n\n    def plot_loss(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        plots loss function as function of iterations. \n        When used in Jupyternotebook, plot will be displayed in notebook. Else, plot will be displayed in console and both plot and loss are saved in save_path. \n        \'\'\'\n        if not in_ipynb(): plt.switch_backend(\'agg\')\n        plt.plot(self.iterations[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'loss_plot.png\'))\n            np.save(os.path.join(self.save_path, \'losses.npy\'), self.losses[10:])\n\n    def plot_lr(self):\n        \'\'\'Plots learning rate in jupyter notebook or console, depending on the enviroment of the learner.\'\'\'\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        if self.record_mom:\n            fig, axs = plt.subplots(1,2,figsize=(12,4))\n            for i in range(0,2): axs[i].set_xlabel(\'iterations\')\n            axs[0].set_ylabel(\'learning rate\')\n            axs[1].set_ylabel(\'momentum\')\n            axs[0].plot(self.iterations,self.lrs)\n            axs[1].plot(self.iterations,self.momentums)   \n        else:\n            plt.xlabel(""iterations"")\n            plt.ylabel(""learning rate"")\n            plt.plot(self.iterations, self.lrs)\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n\n\nclass LR_Updater(LossRecorder):\n    \'\'\'\n    Abstract class where all Learning Rate updaters inherit from. (e.g., CirularLR)\n    Calculates and updates new learning rate and momentum at the end of each batch. \n    Have to be extended. \n    \'\'\'\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n\n    def on_batch_end(self, loss):\n        res = super().on_batch_end(loss)\n        self.update_lr()\n        if self.record_mom:\n            self.update_mom()\n        return res\n\n    def update_lr(self):\n        new_lrs = self.calc_lr(self.init_lrs)\n        self.layer_opt.set_lrs(new_lrs)\n    \n    def update_mom(self):\n        new_mom = self.calc_mom()\n        self.layer_opt.set_mom(new_mom)\n\n    @abstractmethod\n    def calc_lr(self, init_lrs): raise NotImplementedError\n    \n    @abstractmethod\n    def calc_mom(self): raise NotImplementedError\n\n\nclass LR_Finder(LR_Updater):\n    \'\'\'\n    Helps you find an optimal learning rate for a model, as per suggetion of 2015 CLR paper. \n    Learning rate is increased in linear or log scale, depending on user input, and the result of the loss funciton is retained and can be plotted later. \n    \'\'\'\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics = []):\n        self.linear, self.stop_dv = linear, True\n        ratio = end_lr/layer_opt.lr\n        self.lr_mult = (ratio/nb) if linear else ratio**(1/nb)\n        super().__init__(layer_opt,metrics=metrics)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.best=1e9\n\n    def calc_lr(self, init_lrs):\n        mult = self.lr_mult*self.iteration if self.linear else self.lr_mult**self.iteration\n        return init_lrs * mult\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_dv and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        return super().on_batch_end(metrics)\n\n    def plot(self, n_skip=10, n_skip_end=5):\n        \'\'\'\n        Plots the loss function with respect to learning rate, in log scale. \n        \'\'\'\n        plt.ylabel(""loss"")\n        plt.xlabel(""learning rate (log scale)"")\n        plt.plot(self.lrs[n_skip:-(n_skip_end+1)], self.losses[n_skip:-(n_skip_end+1)])\n        plt.xscale(\'log\')\n\nclass LR_Finder2(LR_Finder):\n    """"""\n        A variant of lr_find() that helps find the best learning rate. It doesn\'t do\n        an epoch but a fixed num of iterations (which may be more or less than an epoch\n        depending on your data).\n    """"""\n    def __init__(self, layer_opt, nb, end_lr=10, linear=False, metrics=[], stop_dv=True):\n        self.nb, self.metrics = nb, metrics\n        super().__init__(layer_opt, nb, end_lr, linear, metrics)\n        self.stop_dv = stop_dv\n\n    def on_batch_end(self, loss):\n        if self.iteration == self.nb:\n            return True\n        return super().on_batch_end(loss)\n\n    def plot(self, n_skip=10, n_skip_end=5, smoothed=True):\n        if self.metrics is None: self.metrics = []\n        n_plots = len(self.metrics)+2\n        fig, axs = plt.subplots(n_plots,figsize=(6,4*n_plots))\n        for i in range(0,n_plots): axs[i].set_xlabel(\'learning rate\')\n        axs[0].set_ylabel(\'training loss\')\n        axs[1].set_ylabel(\'validation loss\')\n        for i,m in enumerate(self.metrics): \n            axs[i+2].set_ylabel(m.__name__)\n            if len(self.metrics) == 1:\n                values = self.rec_metrics\n            else:\n                values = [rec[i] for rec in self.rec_metrics]\n            if smoothed: values = smooth_curve(values,0.98)\n            axs[i+2].plot(self.lrs[n_skip:-n_skip_end], values[n_skip:-n_skip_end])\n        plt_val_l = smooth_curve(self.val_losses, 0.98) if smoothed else self.val_losses\n        axs[0].plot(self.lrs[n_skip:-n_skip_end],self.losses[n_skip:-n_skip_end])\n        axs[1].plot(self.lrs[n_skip:-n_skip_end],plt_val_l[n_skip:-n_skip_end])\n\nclass CosAnneal(LR_Updater):\n    \'\'\' Learning rate scheduler that inpelements a cosine annealation schedule. \'\'\'\n    def __init__(self, layer_opt, nb, on_cycle_end=None, cycle_mult=1):\n        self.nb,self.on_cycle_end,self.cycle_mult = nb,on_cycle_end,cycle_mult\n        super().__init__(layer_opt)\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.iteration<self.nb/20:\n            self.cycle_iter += 1\n            return init_lrs/100.\n\n        cos_out = np.cos(np.pi*(self.cycle_iter)/self.nb) + 1\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            self.nb *= self.cycle_mult\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return init_lrs / 2 * cos_out\n\n\nclass CircularLR(LR_Updater):\n    \'\'\'\n    An learning rate updater that implements the CirularLearningRate (CLR) scheme. \n    Learning rate is increased then decreased linearly. \n    \'\'\'\n    def __init__(self, layer_opt, nb, div=4, cut_div=8, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.cut_div,self.on_cycle_end = nb,div,cut_div,on_cycle_end\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = 1 - (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = self.cycle_iter/cut_pt\n        res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n    \n    def calc_mom(self):\n        cut_pt = self.nb//self.cut_div\n        if self.cycle_iter>cut_pt:\n            pct = (self.cycle_iter - cut_pt)/(self.nb - cut_pt)\n        else: pct = 1 - self.cycle_iter/cut_pt\n        res = self.moms[1] + pct * (self.moms[0] - self.moms[1])\n        return res\n\nclass CircularLR_beta(LR_Updater):\n    def __init__(self, layer_opt, nb, div=10, pct=10, on_cycle_end=None, momentums=None):\n        self.nb,self.div,self.pct,self.on_cycle_end = nb,div,pct,on_cycle_end\n        self.cycle_nb = int(nb * (1-pct/100) / 2)\n        if momentums is not None:\n            self.moms = momentums\n        super().__init__(layer_opt, record_mom=(momentums is not None))\n\n    def on_train_begin(self):\n        self.cycle_iter,self.cycle_count=0,0\n        super().on_train_begin()\n\n    def calc_lr(self, init_lrs):\n        if self.cycle_iter>2 * self.cycle_nb:\n            pct = (self.cycle_iter - 2*self.cycle_nb)/(self.nb - 2*self.cycle_nb)\n            res = init_lrs * (1 + (pct * (1-100)/100)) / self.div\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = init_lrs * (1 + pct*(self.div-1)) / self.div\n        self.cycle_iter += 1\n        if self.cycle_iter==self.nb:\n            self.cycle_iter = 0\n            if self.on_cycle_end: self.on_cycle_end(self, self.cycle_count)\n            self.cycle_count += 1\n        return res\n\n    def calc_mom(self):\n        if self.cycle_iter>2*self.cycle_nb:\n            res = self.moms[0]\n        elif self.cycle_iter>self.cycle_nb:\n            pct = 1 - (self.cycle_iter - self.cycle_nb)/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        else:\n            pct = self.cycle_iter/self.cycle_nb\n            res = self.moms[0] + pct * (self.moms[1] - self.moms[0])\n        return res\n\n\nclass SaveBestModel(LossRecorder):\n    \n    """""" Save weights of the best model based during training.\n        If metrics are provided, the first metric in the list is used to\n        find the best model. \n        If no metrics are provided, the loss is used.\n        \n        Args:\n            model: the fastai model\n            lr: indicate to use test images; otherwise use validation images\n            name: the name of filename of the weights without \'.h5\'\n        \n        Usage:\n            Briefly, you have your model \'learn\' variable and call fit.\n            >>> learn.fit(lr, 2, cycle_len=2, cycle_mult=1, best_save_name=\'mybestmodel\')\n            ....\n            >>> learn.load(\'mybestmodel\')\n            \n            For more details see http://forums.fast.ai/t/a-code-snippet-to-save-the-best-model-during-training/12066\n \n    """"""\n    def __init__(self, model, layer_opt, metrics, name=\'best_model\'):\n        super().__init__(layer_opt)\n        self.name = name\n        self.model = model\n        self.best_loss = None\n        self.best_acc = None\n        self.save_method = self.save_when_only_loss if metrics==None else self.save_when_acc\n        \n    def save_when_only_loss(self, metrics):\n        loss = metrics[0]\n        if self.best_loss == None or loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n    \n    def save_when_acc(self, metrics):\n        loss, acc = metrics[0], metrics[1]\n        if self.best_acc == None or acc > self.best_acc:\n            self.best_acc = acc\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        elif acc == self.best_acc and  loss < self.best_loss:\n            self.best_loss = loss\n            self.model.save(f\'{self.name}\')\n        \n    def on_epoch_end(self, metrics):\n        super().on_epoch_end(metrics)\n        self.save_method(metrics)\n\n\nclass WeightDecaySchedule(Callback):\n    def __init__(self, layer_opt, batch_per_epoch, cycle_len, cycle_mult, n_cycles, norm_wds=False, wds_sched_mult=None):\n        """"""\n        Implements the weight decay schedule as mentioned in https://arxiv.org/abs/1711.05101\n\n        :param layer_opt: The LayerOptimizer\n        :param batch_per_epoch: Num batches in 1 epoch\n        :param cycle_len: Num epochs in initial cycle. Subsequent cycle_len = previous cycle_len * cycle_mult\n        :param cycle_mult: Cycle multiplier\n        :param n_cycles: Number of cycles to be executed\n        """"""\n        super().__init__()\n\n        self.layer_opt = layer_opt\n        self.batch_per_epoch = batch_per_epoch\n        self.init_wds = np.array(layer_opt.wds)  # Weights as set by user\n        self.init_lrs = np.array(layer_opt.lrs)  # Learning rates as set by user\n        self.new_wds = None                      # Holds the new weight decay factors, calculated in on_batch_begin()\n        self.param_groups_old = None             # Caches the old parameter values in on_batch_begin()\n        self.iteration = 0\n        self.epoch = 0\n        self.wds_sched_mult = wds_sched_mult\n        self.norm_wds = norm_wds\n        self.wds_history = list()\n\n        # Pre calculating the number of epochs in the cycle of current running epoch\n        self.epoch_to_num_cycles, i = dict(), 0\n        for cycle in range(n_cycles):\n            for _ in range(cycle_len):\n                self.epoch_to_num_cycles[i] = cycle_len\n                i += 1\n            cycle_len *= cycle_mult\n\n    def on_train_begin(self):\n        self.iteration = 0\n        self.epoch = 0\n\n    def on_batch_begin(self):\n        # Prepare for decay of weights\n\n        # Default weight decay (as provided by user)\n        wdn = self.init_wds\n\n        # Weight decay multiplier (The \'eta\' in the paper). Optional.\n        wdm = 1.0\n        if self.wds_sched_mult is not None:\n            wdm = self.wds_sched_mult(self)\n\n        # Weight decay normalized. Optional.\n        if self.norm_wds:\n            wdn = wdn / np.sqrt(self.batch_per_epoch * self.epoch_to_num_cycles[self.epoch])\n\n        # Final wds\n        self.new_wds = wdm * wdn\n\n        # Record the wds\n        self.wds_history.append(self.new_wds)\n\n        # Set weight_decay with zeros so that it is not applied in Adam, we will apply it outside in on_batch_end()\n        self.layer_opt.set_wds(torch.zeros(self.new_wds.size))\n        # We have to save the existing weights before the optimizer changes the values\n        self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n        self.iteration += 1\n\n    def on_batch_end(self, loss):\n        # Decay the weights\n        for group, group_old, wds in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.new_wds):\n            for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                if p.grad is None:\n                    continue\n                p.data = p.data.add(-wds, p_old.data)\n\n    def on_epoch_end(self, metrics):\n        self.epoch += 1\n\nclass DecayType(IntEnum):\n    \'\'\' Data class, each decay type is assigned a number. \'\'\'\n    NO = 1\n    LINEAR = 2\n    COSINE = 3\n    EXPONENTIAL = 4\n    POLYNOMIAL = 5\n\nclass DecayScheduler():\n    \'\'\'Given initial and endvalue, this class generates the next value depending on decay type and number of iterations. (by calling next_val().) \'\'\'\n\n    def __init__(self, dec_type, num_it, start_val, end_val=None, extra=None):\n        self.dec_type, self.nb, self.start_val, self.end_val, self.extra = dec_type, num_it, start_val, end_val, extra\n        self.it = 0\n        if self.end_val is None and not (self.dec_type in [1,4]): self.end_val = 0\n    \n    def next_val(self):\n        self.it += 1\n        if self.dec_type == DecayType.NO:\n            return self.start_val\n        elif self.dec_type == DecayType.LINEAR:\n            pct = self.it/self.nb\n            return self.start_val + pct * (self.end_val-self.start_val)\n        elif self.dec_type == DecayType.COSINE:\n            cos_out = np.cos(np.pi*(self.it)/self.nb) + 1\n            return self.end_val + (self.start_val-self.end_val) / 2 * cos_out\n        elif self.dec_type == DecayType.EXPONENTIAL:\n            ratio = self.end_val / self.start_val\n            return self.start_val * (ratio **  (self.it/self.nb))\n        elif self.dec_type == DecayType.POLYNOMIAL:\n            return self.end_val + (self.start_val-self.end_val) * (1 - self.it/self.nb)**self.extra\n        \n\nclass TrainingPhase():\n    \'\'\'\n    Object with training information for each phase, when multiple phases are involved during training.  \n    Used in fit_opt_sched in learner.py\n    \'\'\'\n    def __init__(self, epochs=1, opt_fn=optim.SGD, lr=1e-2, lr_decay=DecayType.NO, momentum=0.9,\n                momentum_decay=DecayType.NO, beta=None, wds=None, wd_loss=True):\n        """"""\n        Creates an object containing all the relevant informations for one part of a model training.\n\n        Args\n        epochs: number of epochs to train like this\n        opt_fn: an optimizer (example optim.Adam)\n        lr: one learning rate or a tuple of the form (start_lr,end_lr)\n          each of those can be a list/numpy array for differential learning rates\n        lr_decay: a DecayType object specifying how the learning rate should change\n        momentum: one momentum (or beta1 in case of Adam), or a tuple of the form (start_mom,end_mom)\n        momentum_decay: a DecayType object specifying how the momentum should change\n        beta: beta2 parameter of Adam or alpha parameter of RMSProp\n        wds: weight decay (can be an array for differential wds)\n        """"""\n        self.epochs, self.opt_fn, self.lr, self.momentum, self.beta, self.wds = epochs, opt_fn, lr, momentum, beta, wds\n        if isinstance(lr_decay,tuple): self.lr_decay, self.extra_lr = lr_decay\n        else: self.lr_decay, self.extra_lr = lr_decay, None\n        if isinstance(momentum_decay,tuple): self.mom_decay, self.extra_mom = momentum_decay\n        else: self.mom_decay, self.extra_mom = momentum_decay, None\n        self.wd_loss = wd_loss\n\n    def phase_begin(self, layer_opt, nb_batches):\n        self.layer_opt = layer_opt\n        if isinstance(self.lr, tuple): start_lr,end_lr = self.lr\n        else: start_lr, end_lr = self.lr, None\n        self.lr_sched = DecayScheduler(self.lr_decay, nb_batches * self.epochs, start_lr, end_lr, extra=self.extra_lr)\n        if isinstance(self.momentum, tuple): start_mom,end_mom = self.momentum\n        else: start_mom, end_mom = self.momentum, None\n        self.mom_sched = DecayScheduler(self.mom_decay, nb_batches * self.epochs, start_mom, end_mom, extra=self.extra_mom)\n        self.layer_opt.set_opt_fn(self.opt_fn)\n        self.layer_opt.set_lrs(start_lr)\n        self.layer_opt.set_mom(start_mom)\n        if self.beta is not None: self.layer_opt.set_beta(self.beta)\n        if self.wds is not None:\n            if not isinstance(self.wds, Iterable): self.wds=[self.wds]\n            if len(self.wds)==1: self.wds=self.wds*len(self.layer_opt.layer_groups) \n            if self.wd_loss: self.layer_opt.set_wds(self.wds)\n            else: self.layer_opt.set_wds([0] * len(self.wds))\n    \n    def on_batch_begin(self):\n        if not self.wd_loss: self.param_groups_old = copy.deepcopy(self.layer_opt.opt.param_groups)\n\n    def update(self):\n        new_lr, new_mom = self.lr_sched.next_val(), self.mom_sched.next_val()\n        self.layer_opt.set_lrs(new_lr)\n        self.layer_opt.set_mom(new_mom)\n        if not self.wd_loss: # Decay the weights outside of the loss\n            if not isinstance(new_lr, Iterable): new_lr=[new_lr]\n            if len(new_lr)==1: new_lr=new_lr*len(self.layer_opt.layer_groups)\n            for group, group_old, wds, lr in zip(self.layer_opt.opt.param_groups, self.param_groups_old, self.wds, new_lr):\n                for p, p_old in zip(group[\'params\'], group_old[\'params\']):\n                    if p.grad is None: continue\n                    p.data = p.data.add(-wds*lr, p_old.data)\n    \n\nclass OptimScheduler(LossRecorder):\n    \'\'\'Learning rate Scheduler for training involving multiple phases.\'\'\'\n\n    def __init__(self, layer_opt, phases, nb_batches, stop_div = False):\n        self.phases, self.nb_batches, self.stop_div = phases, nb_batches, stop_div\n        super().__init__(layer_opt, record_mom=True)\n\n    def on_train_begin(self):\n        super().on_train_begin()\n        self.phase,self.best=0,1e9\n    \n    def on_batch_begin(self):\n        self.phases[self.phase].on_batch_begin()\n        super().on_batch_begin()\n\n    def on_batch_end(self, metrics):\n        loss = metrics[0] if isinstance(metrics,list) else metrics\n        if self.stop_div and (math.isnan(loss) or loss>self.best*4):\n            return True\n        if (loss<self.best and self.iteration>10): self.best=loss\n        super().on_batch_end(metrics)\n        self.phases[self.phase].update()\n    \n    def on_phase_begin(self):\n        self.phases[self.phase].phase_begin(self.layer_opt, self.nb_batches)\n\n    def on_phase_end(self):\n        self.phase += 1\n\n    def plot_lr(self, show_text=True, show_moms=True):\n        """"""Plots the lr rate/momentum schedule""""""\n        phase_limits = [0]\n        for phase in self.phases:\n            phase_limits.append(phase_limits[-1] + self.nb_batches * phase.epochs)\n        if not in_ipynb():\n            plt.switch_backend(\'agg\')\n        np_plts = 2 if show_moms else 1\n        fig, axs = plt.subplots(1,np_plts,figsize=(6*np_plts,4))\n        if not show_moms: axs = [axs]\n        for i in range(np_plts): axs[i].set_xlabel(\'iterations\')\n        axs[0].set_ylabel(\'learning rate\')\n        axs[0].plot(self.iterations,self.lrs)\n        if show_moms:\n            axs[1].set_ylabel(\'momentum\')\n            axs[1].plot(self.iterations,self.momentums)\n        if show_text:   \n            for i, phase in enumerate(self.phases):\n                text = phase.opt_fn.__name__\n                if phase.wds is not None: text+=\'\\nwds=\'+str(phase.wds)\n                if phase.beta is not None: text+=\'\\nbeta=\'+str(phase.beta)\n                for k in range(np_plts):\n                    if i < len(self.phases)-1:\n                        draw_line(axs[k], phase_limits[i+1])\n                    draw_text(axs[k], (phase_limits[i]+phase_limits[i+1])/2, text) \n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, \'lr_plot.png\'))\n    \n    def plot(self, n_skip=10, n_skip_end=5, linear=None):\n        if linear is None: linear = self.phases[-1].lr_decay == DecayType.LINEAR\n        plt.ylabel(""loss"")\n        plt.plot(self.lrs[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if linear: plt.xlabel(""learning rate"")\n        else:\n            plt.xlabel(""learning rate (log scale)"")\n            plt.xscale(\'log\')\n\ndef draw_line(ax,x):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.plot([x,x],[ymin,ymax], color=\'red\', linestyle=\'dashed\')\n\ndef draw_text(ax,x, text):\n    xmin, xmax, ymin, ymax = ax.axis()\n    ax.text(x,(ymin+ymax)/2,text, horizontalalignment=\'center\', verticalalignment=\'center\', fontsize=14, alpha=0.5)\n\ndef smooth_curve(vals, beta):\n    avg_val = 0\n    smoothed = []\n    for (i,v) in enumerate(vals):\n        avg_val = beta * avg_val + (1-beta) * v\n        smoothed.append(avg_val/(1-beta**(i+1)))\n    return smoothed\n'"
fastai/courses/ml1/fastai/structured.py,0,"b'from .imports import *\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\n\ndef set_plot_sizes(sml, med, big):\n    plt.rc(\'font\', size=sml)          # controls default text sizes\n    plt.rc(\'axes\', titlesize=sml)     # fontsize of the axes title\n    plt.rc(\'axes\', labelsize=med)    # fontsize of the x and y labels\n    plt.rc(\'xtick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'ytick\', labelsize=sml)    # fontsize of the tick labels\n    plt.rc(\'legend\', fontsize=sml)    # legend fontsize\n    plt.rc(\'figure\', titlesize=big)  # fontsize of the figure title\n\ndef parallel_trees(m, fn, n_jobs=8):\n        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    """""" Draws a representation of a random forest in IPython.\n\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    """"""\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub(\'Tree {\',\n       f\'Tree {{ size={size}; ratio={ratio}\', s)))\n\ndef combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = (\'<M8[Y]\', \'<m8[M]\', \'<m8[D]\', \'<m8[W]\', \'<m8[h]\',\n             \'<m8[m]\', \'<m8[s]\', \'<m8[ms]\', \'<m8[us]\', \'<m8[ns]\')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\ndef get_sample(df,n):\n    """""" Gets a random sample of n rows from df, without replacement.\n\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    >>> get_sample(df, 2)\n       col1 col2\n    1     2    b\n    2     3    a\n    """"""\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef add_datepart(df, fldname, drop=True, time=False):\n    """"""add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({ \'A\' : pd.to_datetime([\'3/11/2000\', \'3/12/2000\', \'3/13/2000\'], infer_datetime_format=False) })\n    >>> df\n\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n\n    >>> add_datepart(df, \'A\')\n    >>> df\n\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    """"""\n    fld = df[fldname]\n    if not np.issubdtype(fld.dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub(\'[Dd]ate$\', \'\', fldname)\n    attr = [\'Year\', \'Month\', \'Week\', \'Day\', \'Dayofweek\', \'Dayofyear\',\n            \'Is_month_end\', \'Is_month_start\', \'Is_quarter_end\', \'Is_quarter_start\', \'Is_year_end\', \'Is_year_start\']\n    if time: attr = attr + [\'Hour\', \'Minute\', \'Second\']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + \'Elapsed\'] = fld.astype(np.int64) // 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n\ndef is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n\ndef train_cats(df):\n    """"""Change any columns of strings in a panda\'s dataframe to a column of\n    catagorical values. This applies the changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category\n    """"""\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype(\'category\').cat.as_ordered()\n\ndef apply_cats(df, trn):\n    """"""Changes any columns of strings in df into categorical variables using trn as\n    a template for the category codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values. The category codes are determined by trn.\n\n    trn: A pandas dataframe. When creating a category for df, it looks up the\n        what the category\'s code were in trn and makes those the category codes\n        for df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category {a : 1, b : 2}\n\n    >>> df2 = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'b\', \'a\', \'a\']})\n    >>> apply_cats(df2, df)\n\n           col1 col2\n        0     1    b\n        1     2    a\n        2     3    a\n\n    now the type of col is category {a : 1, b : 2}\n    """"""\n    for n,c in df.items():\n        if (n in trn.columns) and (trn[n].dtype.name==\'category\'):\n            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n\ndef fix_missing(df, col, name, na_dict):\n    """""" Fill missing data in a column of df with the median, and add a {name}_na column\n    which specifies if the data was missing.\n\n    Parameters:\n    -----------\n    df: The data frame that will be changed.\n\n    col: The column of data to fix by filling in missing data.\n\n    name: The name of the new filled column in df.\n\n    na_dict: A dictionary of values to create na\'s of and the value to insert. If\n        name is not a key of na_dict the median will fill any missing data. Also\n        if name is not a key of na_dict and there is no missing data in col, then\n        no {name}_na column is not created.\n\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1     2    2    True\n    2     3    2   False\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col2\'], \'col2\', {})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n\n    >>> df = pd.DataFrame({\'col1\' : [1, np.NaN, 3], \'col2\' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df[\'col1\'], \'col1\', {\'col1\' : 500})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1   500    2    True\n    2     3    2   False\n    """"""\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+\'_na\'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    """""" Changes the column col from a categorical type to it\'s integer codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. df[name] will be filled with the integer codes from\n        col.\n\n    col: The column you wish to change into the categories.\n    name: The column name you wish to insert into df. This column will hold the\n        integer codes.\n\n    max_n_cat: If col has more categories than max_n_cat it will not change the\n        it to its integer codes. If max_n_cat is None, then col will always be\n        converted.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> numericalize(df, df[\'col2\'], \'col3\', None)\n\n       col1 col2 col3\n    0     1    a    1\n    1     2    b    2\n    2     3    a    1\n    """"""\n    if not is_numeric_dtype(col) and ( max_n_cat is None or col.nunique()>max_n_cat):\n        df[name] = col.cat.codes+1\n\ndef scale_vars(df, mapper):\n    warnings.filterwarnings(\'ignore\', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper\n\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    """""" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n\n    y_fld: The name of the response variable\n\n    skip_flds: A list of fields that dropped from df.\n\n    ignore_flds: A list of fields that are ignored during processing.\n\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n\n    preproc_fn: A function that gets applied to df.\n\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n\n    subset: Takes a random subset of size subset from df.\n\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n\n        y: y is the response variable\n\n        nas: returns a dictionary of which nas it created, and the associated median.\n\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({\'col1\' : [1, 2, 3], \'col2\' : [\'a\', \'b\', \'a\']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> x, y, nas = proc_df(df, \'col1\')\n    >>> x\n\n       col2\n    0     1\n    1     2\n    2     1\n\n    >>> data = DataFrame(pet=[""cat"", ""dog"", ""dog"", ""fish"", ""cat"", ""dog"", ""cat"", ""fish""],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    """"""\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    df = df.copy()\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({\'cols\':df.columns, \'imp\':m.feature_importances_}\n                       ).sort_values(\'imp\', ascending=False)\n\ndef set_rf_samples(n):\n    """""" Changes Scikit learn\'s random forests to give each tree a random sample of\n    n random rows.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    """""" Undoes the changes produced by set_rf_samples.\n    """"""\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\ndef get_nn_mappers(df, cat_vars, contin_vars):\n    # Replace nulls with 0 for continuous, """" for categorical.\n    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n    for v in cat_vars: df[v].fillna(\'#NA#\', inplace=True)\n\n    # list of tuples, containing variable and instance of a transformer for that variable\n    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n    return DataFrameMapper(cat_maps).fit(df), DataFrameMapper(contin_maps).fit(df)\n'"
fastai/courses/ml1/fastai/swa.py,3,"b'""""""\n    From the paper:\n        Averaging Weights Leads to Wider Optima and Better Generalization\n        Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, Andrew Gordon Wilson\n        https://arxiv.org/abs/1803.05407\n        2018\n        \n    Author\'s implementation: https://github.com/timgaripov/swa\n""""""\n\nimport torch\nfrom .sgdr import *\nfrom .core import *\n\n\nclass SWA(Callback):\n    def __init__(self, model, swa_model, swa_start):\n        super().__init__()\n        self.model,self.swa_model,self.swa_start=model,swa_model,swa_start\n        \n    def on_train_begin(self):\n        self.epoch = 0\n        self.swa_n = 0\n\n    def on_epoch_end(self, metrics):\n        if (self.epoch + 1) >= self.swa_start:\n            self.update_average_model()\n            self.swa_n += 1\n            \n        self.epoch += 1\n            \n    def update_average_model(self):\n        # update running average of parameters\n        model_params = self.model.parameters()\n        swa_params = self.swa_model.parameters()\n        for model_param, swa_param in zip(model_params, swa_params):\n            swa_param.data *= self.swa_n\n            swa_param.data += model_param.data\n            swa_param.data /= (self.swa_n + 1)            \n    \ndef collect_bn_modules(module, bn_modules):\n    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n        bn_modules.append(module)\n\ndef fix_batchnorm(swa_model, train_dl):\n    """"""\n    During training, batch norm layers keep track of a running mean and\n    variance of the previous layer\'s activations. Because the parameters\n    of the SWA model are computed as the average of other models\' parameters,\n    the SWA model never sees the training data itself, and therefore has no\n    opportunity to compute the correct batch norm statistics. Before performing \n    inference with the SWA model, we perform a single pass over the training data\n    to calculate an accurate running mean and variance for each batch norm layer.\n    """"""\n    bn_modules = []\n    swa_model.apply(lambda module: collect_bn_modules(module, bn_modules))\n    \n    if not bn_modules: return\n\n    swa_model.train()\n\n    for module in bn_modules:\n        module.running_mean = torch.zeros_like(module.running_mean)\n        module.running_var = torch.ones_like(module.running_var)\n    \n    momenta = [m.momentum for m in bn_modules]\n\n    inputs_seen = 0\n\n    for (*x,y) in iter(train_dl):        \n        xs = V(x)\n        batch_size = xs[0].size(0)\n\n        momentum = batch_size / (inputs_seen + batch_size)\n        for module in bn_modules:\n            module.momentum = momentum\n                            \n        res = swa_model(*xs)        \n        \n        inputs_seen += batch_size\n                \n    for module, momentum in zip(bn_modules, momenta):\n        module.momentum = momentum    '"
fastai/courses/ml1/fastai/text.py,1,"b'from .core import *\nfrom .learner import *\nfrom .lm_rnn import *\nfrom torch.utils.data.sampler import Sampler\nimport spacy\nfrom spacy.symbols import ORTH\n\nre_tok = re.compile(f\'([{string.punctuation}\xe2\x80\x9c\xe2\x80\x9d\xc2\xa8\xc2\xab\xc2\xbb\xc2\xae\xc2\xb4\xc2\xb7\xc2\xba\xc2\xbd\xc2\xbe\xc2\xbf\xc2\xa1\xc2\xa7\xc2\xa3\xe2\x82\xa4\xe2\x80\x98\xe2\x80\x99])\')\ndef tokenize(s): return re_tok.sub(r\' \\1 \', s).split()\n\ndef texts_labels_from_folders(path, folders):\n    texts,labels = [],[]\n    for idx,label in enumerate(folders):\n        for fname in glob(os.path.join(path, label, \'*.*\')):\n            texts.append(open(fname, \'r\').read())\n            labels.append(idx)\n    return texts, np.array(labels).astype(np.int64)\n\ndef numericalize_tok(tokens, max_vocab=50000, min_freq=0, unk_tok=""_unk_"", pad_tok=""_pad_"", bos_tok=""_bos_"", eos_tok=""_eos_""):\n    """"""Takes in text tokens and returns int2tok and tok2int converters\n\n        Arguments:\n        tokens(list): List of tokens. Can be a list of strings, or a list of lists of strings.\n        max_vocab(int): Number of tokens to return in the vocab (sorted by frequency)\n        min_freq(int): Minimum number of instances a token must be present in order to be preserved.\n        unk_tok(str): Token to use when unknown tokens are encountered in the source text.\n        pad_tok(str): Token to use when padding sequences.\n    """"""\n    if isinstance(tokens, str):\n        raise ValueError(""Expected to receive a list of tokens. Received a string instead"")\n    if isinstance(tokens[0], list):\n        tokens = [p for o in tokens for p in o]\n    freq = Counter(tokens)\n    int2tok = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n    unk_id = 3\n    int2tok.insert(0, bos_tok)\n    int2tok.insert(1, pad_tok)\n    int2tok.insert(2, eos_tok)\n    int2tok.insert(unk_id, unk_tok)\n    tok2int = collections.defaultdict(lambda:unk_id, {v:k for k,v in enumerate(int2tok)})\n    return int2tok, tok2int\n\nclass Tokenizer():\n    def __init__(self, lang=\'en\'):\n        self.re_br = re.compile(r\'<\\s*br\\s*/?>\', re.IGNORECASE)\n        self.tok = spacy.load(lang)\n        for w in (\'<eos>\',\'<bos>\',\'<unk>\'):\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\n\n    def sub_br(self,x): return self.re_br.sub(""\\n"", x)\n\n    def spacy_tok(self,x):\n        return [t.text for t in self.tok.tokenizer(self.sub_br(x))]\n\n    re_rep = re.compile(r\'(\\S)(\\1{3,})\')\n    re_word_rep = re.compile(r\'(\\b\\w+\\W+)(\\1{3,})\')\n\n    @staticmethod\n    def replace_rep(m):\n        TK_REP = \'tk_rep\'\n        c,cc = m.groups()\n        return f\' {TK_REP} {len(cc)+1} {c} \'\n\n    @staticmethod\n    def replace_wrep(m):\n        TK_WREP = \'tk_wrep\'\n        c,cc = m.groups()\n        return f\' {TK_WREP} {len(cc.split())+1} {c} \'\n\n    @staticmethod\n    def do_caps(ss):\n        TOK_UP,TOK_SENT,TOK_MIX = \' t_up \',\' t_st \',\' t_mx \'\n        res = []\n        prev=\'.\'\n        re_word = re.compile(\'\\w\')\n        re_nonsp = re.compile(\'\\S\')\n        for s in re.findall(r\'\\w+|\\W+\', ss):\n            res += ([TOK_UP,s.lower()] if (s.isupper() and (len(s)>2))\n    #                 else [TOK_SENT,s.lower()] if (s.istitle() and re_word.search(prev))\n                    else [s.lower()])\n    #         if re_nonsp.search(s): prev = s\n        return \'\'.join(res)\n\n    def proc_text(self, s):\n        s = self.re_rep.sub(Tokenizer.replace_rep, s)\n        s = self.re_word_rep.sub(Tokenizer.replace_wrep, s)\n        s = Tokenizer.do_caps(s)\n        s = re.sub(r\'([/#])\', r\' \\1 \', s)\n        s = re.sub(\' {2,}\', \' \', s)\n        return self.spacy_tok(s)\n\n    @staticmethod\n    def proc_all(ss, lang):\n        tok = Tokenizer(lang)\n        return [tok.proc_text(s) for s in ss]\n\n    @staticmethod\n    def proc_all_mp(ss, lang=\'en\'):\n        ncpus = num_cpus()//2\n        with ProcessPoolExecutor(ncpus) as e:\n            return sum(e.map(Tokenizer.proc_all, ss, [lang]*len(ss)), [])\n\n\nclass TextDataset(Dataset):\n    def __init__(self, x, y, backwards=False, sos=None, eos=None):\n        self.x,self.y,self.backwards,self.sos,self.eos = x,y,backwards,sos,eos\n\n    def __getitem__(self, idx):\n        x = self.x[idx]\n        if self.backwards: x = list(reversed(x))\n        if self.eos is not None: x = x + [self.eos]\n        if self.sos is not None: x = [self.sos]+x\n        return np.array(x),self.y[idx]\n\n    def __len__(self): return len(self.x)\n\n\nclass SortSampler(Sampler):\n    def __init__(self, data_source, key): self.data_source,self.key = data_source,key\n    def __len__(self): return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(range(len(self.data_source)), key=self.key, reverse=True))\n\n\nclass SortishSampler(Sampler):\n    """"""Returns an iterator that traverses the the data in randomly ordered batches that are approximately the same size.\n    The max key size batch is always returned in the first call because of pytorch cuda memory allocation sequencing.\n    Without that max key returned first multiple buffers may be allocated when the first created isn\'t large enough\n    to hold the next in the sequence.\n    """"""\n    def __init__(self, data_source, key, bs):\n        self.data_source,self.key,self.bs = data_source,key,bs\n\n    def __len__(self): return len(self.data_source)\n\n    def __iter__(self):\n        idxs = np.random.permutation(len(self.data_source))\n        sz = self.bs*50\n        ck_idx = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n        sort_idx = np.concatenate([sorted(s, key=self.key, reverse=True) for s in ck_idx])\n        sz = self.bs\n        ck_idx = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n        max_ck = np.argmax([ck[0] for ck in ck_idx])  # find the chunk with the largest key,\n        ck_idx[0],ck_idx[max_ck] = ck_idx[max_ck],ck_idx[0]  # then make sure it goes first.\n        sort_idx = np.concatenate(np.random.permutation(ck_idx[1:]))\n        sort_idx = np.concatenate((ck_idx[0], sort_idx))\n        return iter(sort_idx)\n\n\nclass LanguageModelLoader():\n    """""" Returns a language model iterator that iterates through batches that are of length N(bptt,5)\n    The first batch returned is always bptt+25; the max possible width.  This is done because of they way that pytorch\n    allocates cuda memory in order to prevent multiple buffers from being created as the batch width grows.\n    """"""\n    def __init__(self, nums, bs, bptt, backwards=False):\n        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n        self.data = self.batchify(nums)\n        self.i,self.iter = 0,0\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i,self.iter = 0,0\n        while self.i < self.n-1 and self.iter<len(self):\n            if self.i == 0:\n                seq_len = self.bptt + 5 * 5\n            else:\n                bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n                seq_len = max(5, int(np.random.normal(bptt, 5)))\n            res = self.get_batch(self.i, seq_len)\n            self.i += seq_len\n            self.iter += 1\n            yield res\n\n    def __len__(self): return self.n // self.bptt - 1\n\n    def batchify(self, data):\n        nb = data.shape[0] // self.bs\n        data = np.array(data[:nb*self.bs])\n        data = data.reshape(self.bs, -1).T\n        if self.backwards: data=data[::-1]\n        return T(data)\n\n    def get_batch(self, i, seq_len):\n        source = self.data\n        seq_len = min(seq_len, len(source) - 1 - i)\n        return source[i:i+seq_len], source[i+1:i+1+seq_len].view(-1)\n\n\nclass LanguageModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [*zip(m.rnns, m.dropouths), (self.model[1], m.dropouti)]\n\n\nclass LanguageModelData():\n    def __init__(self, path, pad_idx, n_tok, trn_dl, val_dl, test_dl=None, **kwargs):\n        self.path,self.pad_idx,self.n_tok = path,pad_idx,n_tok\n        self.trn_dl,self.val_dl,self.test_dl = trn_dl,val_dl,test_dl\n\n    def get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n        m = get_language_model(self.n_tok, emb_sz, n_hid, n_layers, self.pad_idx, **kwargs)\n        model = LanguageModel(to_gpu(m))\n        return RNN_Learner(self, model, opt_fn=opt_fn)\n\n\nclass RNN_Learner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n\n    def _get_crit(self, data): return F.cross_entropy\n\n    def save_encoder(self, name): save_model(self.model[0], self.get_model_path(name))\n    def load_encoder(self, name): load_model(self.model[0], self.get_model_path(name))\n\n\nclass TextModel(BasicModel):\n    def get_layer_groups(self):\n        m = self.model[0]\n        return [(m.encoder, m.dropouti), *zip(m.rnns, m.dropouths), (self.model[1])]\n\n'"
fastai/courses/ml1/fastai/torch_imports.py,6,"b'import os\nimport torch, torchvision, torchtext\nfrom torch import nn, cuda, backends, FloatTensor, LongTensor, optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.nn.init import kaiming_uniform, kaiming_normal\nfrom torchvision.transforms import Compose\nfrom torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\nfrom torchvision.models import vgg16_bn, vgg19_bn\nfrom torchvision.models import densenet121, densenet161, densenet169, densenet201\n\nfrom .models.resnext_50_32x4d import resnext_50_32x4d\nfrom .models.resnext_101_32x4d import resnext_101_32x4d\nfrom .models.resnext_101_64x4d import resnext_101_64x4d\nfrom .models.wrn_50_2f import wrn_50_2f\nfrom .models.inceptionresnetv2 import InceptionResnetV2\nfrom .models.inceptionv4 import inceptionv4\nfrom .models.nasnet import nasnetalarge\nfrom .models.fa_resnet import *\n\nimport warnings\nwarnings.filterwarnings(\'ignore\', message=\'Implicit dimension choice\', category=UserWarning)\n\ndef children(m): return m if isinstance(m, (list, tuple)) else list(m.children())\ndef save_model(m, p): torch.save(m.state_dict(), p)\ndef load_model(m, p): m.load_state_dict(torch.load(p, map_location=lambda storage, loc: storage))\n\ndef load_pre(pre, f, fn):\n    m = f()\n    path = os.path.dirname(__file__)\n    if pre: load_model(m, f\'{path}/weights/{fn}.pth\')\n    return m\n\ndef _fastai_model(name, paper_title, paper_href):\n    def add_docs_wrapper(f):\n        f.__doc__ = f""""""{name} model from\n        `""{paper_title}"" <{paper_href}>`_\n\n        Args:\n           pre (bool): If True, returns a model pre-trained on ImageNet\n        """"""\n        return f\n    return add_docs_wrapper\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inception_4(pre): return children(inceptionv4(pretrained=pre))[0]\n\n@_fastai_model(\'Inception 4\', \'Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\',\n               \'https://arxiv.org/pdf/1602.07261.pdf\')\ndef inceptionresnet_2(pre): return load_pre(pre, InceptionResnetV2, \'inceptionresnetv2-d579a627\')\n\n@_fastai_model(\'ResNeXt 50\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext50(pre): return load_pre(pre, resnext_50_32x4d, \'resnext_50_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_32\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101(pre): return load_pre(pre, resnext_101_32x4d, \'resnext_101_32x4d\')\n\n@_fastai_model(\'ResNeXt 101_64\', \'Aggregated Residual Transformations for Deep Neural Networks\',\n               \'https://arxiv.org/abs/1611.05431\')\ndef resnext101_64(pre): return load_pre(pre, resnext_101_64x4d, \'resnext_101_64x4d\')\n\n@_fastai_model(\'Wide Residual Networks\', \'Wide Residual Networks\',\n               \'https://arxiv.org/pdf/1605.07146.pdf\')\ndef wrn(pre): return load_pre(pre, wrn_50_2f, \'wrn_50_2f\')\n\n@_fastai_model(\'Densenet-121\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn121(pre): return children(densenet121(pre))[0]\n\n@_fastai_model(\'Densenet-169\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn161(pre): return children(densenet161(pre))[0]\n\n@_fastai_model(\'Densenet-161\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn169(pre): return children(densenet169(pre))[0]\n\n@_fastai_model(\'Densenet-201\', \'Densely Connected Convolutional Networks\',\n               \'https://arxiv.org/pdf/1608.06993.pdf\')\ndef dn201(pre): return children(densenet201(pre))[0]\n\n@_fastai_model(\'Vgg-16 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg16(pre): return children(vgg16_bn(pre))[0]\n\n@_fastai_model(\'Vgg-19 with batch norm added\', \'Very Deep Convolutional Networks for Large-Scale Image Recognition\',\n               \'https://arxiv.org/pdf/1409.1556.pdf\')\ndef vgg19(pre): return children(vgg19_bn(pre))[0]\n\n'"
fastai/courses/ml1/fastai/transforms.py,0,"b'from .imports import *\nfrom .layer_optimizer import *\nfrom enum import IntEnum\n\ndef scale_min(im, targ, interpolation=cv2.INTER_AREA):\n    """""" Scales the image so that the smallest axis is of size targ.\n\n    Arguments:\n        im (array): image\n        targ (int): target size\n    """"""\n    r,c,*_ = im.shape\n    ratio = targ/min(r,c)\n    sz = (scale_to(c, ratio, targ), scale_to(r, ratio, targ))\n    return cv2.resize(im, sz, interpolation=interpolation)\n\ndef zoom_cv(x,z):\n    \'\'\'zooms the center of image x, by a factor of z+1 while retaining the origal image size and proportion. \'\'\'\n    if z==0: return x\n    r,c,*_ = x.shape\n    M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)\n    return cv2.warpAffine(x,M,(c,r))\n\ndef stretch_cv(x,sr,sc,interpolation=cv2.INTER_AREA):\n    \'\'\'stretches image x horizontally by sr+1, and vertically by sc+1 while retaining the origal image size and proportion.\'\'\'\n    if sr==0 and sc==0: return x\n    r,c,*_ = x.shape\n    x = cv2.resize(x, None, fx=sr+1, fy=sc+1, interpolation=interpolation)\n    nr,nc,*_ = x.shape\n    cr = (nr-r)//2; cc = (nc-c)//2\n    return x[cr:r+cr, cc:c+cc]\n\ndef dihedral(x, dih):\n    \'\'\'performs any of 8 90 rotations or flips for image x.\n    \'\'\'\n    x = np.rot90(x, dih%4)\n    return x if dih<4 else np.fliplr(x)\n\ndef lighting(im, b, c):\n    \'\'\' adjusts image\'s balance and contrast\'\'\'\n    if b==0 and c==1: return im\n    mu = np.average(im)\n    return np.clip((im-mu)*c+mu+b,0.,1.).astype(np.float32)\n\ndef rotate_cv(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\n    """""" Rotates an image by deg degrees\n\n    Arguments:\n        deg (float): degree to rotate.\n    """"""\n    r,c,*_ = im.shape\n    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\n    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)\n\ndef no_crop(im, min_sz=None, interpolation=cv2.INTER_AREA):\n    """""" Returns a squared resized image """"""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    return cv2.resize(im, (min_sz, min_sz), interpolation=interpolation)\n\ndef center_crop(im, min_sz=None):\n    """""" Returns a center crop of an image""""""\n    r,c,*_ = im.shape\n    if min_sz is None: min_sz = min(r,c)\n    start_r = math.ceil((r-min_sz)/2)\n    start_c = math.ceil((c-min_sz)/2)\n    return crop(im, start_r, start_c, min_sz)\n\ndef googlenet_resize(im, targ, min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p, interpolation=cv2.INTER_AREA):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ\n    \n    References:\n    1. https://arxiv.org/pdf/1409.4842.pdf\n    2. https://arxiv.org/pdf/1802.07888.pdf\n    """"""\n    h,w,*_ = im.shape\n    area = h*w\n    for _ in range(10):\n        targetArea = random.uniform(min_area_frac, 1.0) * area\n        aspectR = random.uniform(min_aspect_ratio, max_aspect_ratio)\n        ww = int(np.sqrt(targetArea * aspectR) + 0.5)\n        hh = int(np.sqrt(targetArea / aspectR) + 0.5)\n        if flip_hw_p:\n            ww, hh = hh, ww\n        if hh <= h and ww <= w:\n            x1 = 0 if w == ww else random.randint(0, w - ww)\n            y1 = 0 if h == hh else random.randint(0, h - hh)\n            out = im[y1:y1 + hh, x1:x1 + ww]\n            out = cv2.resize(out, (targ, targ), interpolation=interpolation)\n            return out\n    out = scale_min(im, targ, interpolation=interpolation)\n    out = center_crop(out)\n    return out\n\ndef cutout(im, n_holes, length):\n    \'\'\' cuts out n_holes number of square holes of size length in image at random locations. holes may be overlapping. \'\'\'\n    r,c,*_ = im.shape\n    mask = np.ones((r, c), np.int32)\n    for n in range(n_holes):\n        y = np.random.randint(length / 2, r - length / 2)\n        x = np.random.randint(length / 2, c - length / 2)\n\n        y1 = int(np.clip(y - length / 2, 0, r))\n        y2 = int(np.clip(y + length / 2, 0, r))\n        x1 = int(np.clip(x - length / 2, 0, c))\n        x2 = int(np.clip(x + length / 2, 0, c))\n        mask[y1: y2, x1: x2] = 0.\n    \n    mask = mask[:,:,None]\n    im = im * mask\n    return im\n\ndef scale_to(x, ratio, targ): \n    \'\'\'Calculate dimension of an image during scaling with aspect ratio\'\'\'\n    return max(math.floor(x*ratio), targ)\n\ndef crop(im, r, c, sz): \n    \'\'\'\n    crop image into a square of size sz, \n    \'\'\'\n    return im[r:r+sz, c:c+sz]\n\ndef det_dihedral(dih): return lambda x: dihedral(x, dih)\ndef det_stretch(sr, sc): return lambda x: stretch_cv(x, sr, sc)\ndef det_lighting(b, c): return lambda x: lighting(x, b, c)\ndef det_rotate(deg): return lambda x: rotate_cv(x, deg)\ndef det_zoom(zoom): return lambda x: zoom_cv(x, zoom)\n\ndef rand0(s): return random.random()*(s*2)-s\n\n\nclass TfmType(IntEnum):\n    """""" Type of transformation.\n    Parameters\n        IntEnum: predefined types of transformations\n            NO:    the default, y does not get transformed when x is transformed.\n            PIXEL: x and y are images and should be transformed in the same way.\n                   Example: image segmentation.\n            COORD: y are coordinates (i.e bounding boxes)\n            CLASS: y are class labels (same behaviour as PIXEL, except no normalization)\n    """"""\n    NO = 1\n    PIXEL = 2\n    COORD = 3\n    CLASS = 4\n\n\nclass Denormalize():\n    """""" De-normalizes an image, returning it to original format.\n    """"""\n    def __init__(self, m, s):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n    def __call__(self, x): return x*self.s+self.m\n\n\nclass Normalize():\n    """""" Normalizes an image to zero mean and unit standard deviation, given the mean m and std s of the original image """"""\n    def __init__(self, m, s, tfm_y=TfmType.NO):\n        self.m=np.array(m, dtype=np.float32)\n        self.s=np.array(s, dtype=np.float32)\n        self.tfm_y=tfm_y\n\n    def __call__(self, x, y=None):\n        x = (x-self.m)/self.s\n        if self.tfm_y==TfmType.PIXEL and y is not None: y = (y-self.m)/self.s\n        return x,y\n\nclass ChannelOrder():\n    \'\'\'\n    changes image array shape from (h, w, 3) to (3, h, w). \n    tfm_y decides the transformation done to the y element. \n    \'\'\'\n    def __init__(self, tfm_y=TfmType.NO): self.tfm_y=tfm_y\n\n    def __call__(self, x, y):\n        x = np.rollaxis(x, 2)\n        #if isinstance(y,np.ndarray) and (len(y.shape)==3):\n        if self.tfm_y==TfmType.PIXEL: y = np.rollaxis(y, 2)\n        elif self.tfm_y==TfmType.CLASS: y = y[...,0]\n        return x,y\n\n\ndef to_bb(YY, y=""deprecated""):\n    """"""Convert mask YY to a bounding box, assumes 0 as background nonzero object""""""\n    cols,rows = np.nonzero(YY)\n    if len(cols)==0: return np.zeros(4, dtype=np.float32)\n    top_row = np.min(rows)\n    left_col = np.min(cols)\n    bottom_row = np.max(rows)\n    right_col = np.max(cols)\n    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n\n\ndef coords2px(y, x):\n    """""" Transforming coordinates to pixels.\n\n    Arguments:\n        y : np array\n            vector in which (y[0], y[1]) and (y[2], y[3]) are the\n            the corners of a bounding box.\n        x : image\n            an image\n    Returns:\n        Y : image\n            of shape x.shape\n    """"""\n    rows = np.rint([y[0], y[0], y[2], y[2]]).astype(int)\n    cols = np.rint([y[1], y[3], y[1], y[3]]).astype(int)\n    r,c,*_ = x.shape\n    Y = np.zeros((r, c))\n    Y[rows, cols] = 1\n    return Y\n\n\nclass Transform():\n    """""" A class that represents a transform.\n\n    All other transforms should subclass it. All subclasses should override\n    do_transform.\n\n    Arguments\n    ---------\n        tfm_y : TfmType\n            type of transform\n    """"""\n    def __init__(self, tfm_y=TfmType.NO):\n        self.tfm_y=tfm_y\n        self.store = threading.local()\n\n    def set_state(self): pass\n    def __call__(self, x, y):\n        self.set_state()\n        x,y = ((self.transform(x),y) if self.tfm_y==TfmType.NO\n                else self.transform(x,y) if self.tfm_y in (TfmType.PIXEL, TfmType.CLASS)\n                else self.transform_coord(x,y))\n        return x, y\n\n    def transform_coord(self, x, y): return self.transform(x),y\n\n    def transform(self, x, y=None):\n        x = self.do_transform(x,False)\n        return (x, self.do_transform(y,True)) if y is not None else x\n\n    @abstractmethod\n    def do_transform(self, x, is_y): raise NotImplementedError\n\n\nclass CoordTransform(Transform):\n    """""" A coordinate transform.  """"""\n\n    @staticmethod\n    def make_square(y, x):\n        r,c,*_ = x.shape\n        y1 = np.zeros((r, c))\n        y = y.astype(np.int)\n        y1[y[0]:y[2], y[1]:y[3]] = 1.\n        return y1\n\n    def map_y(self, y0, x):\n        y = CoordTransform.make_square(y0, x)\n        y_tr = self.do_transform(y, True)\n        return to_bb(y_tr)\n\n    def transform_coord(self, x, ys):\n        yp = partition(ys, 4)\n        y2 = [self.map_y(y,x) for y in yp]\n        x = self.do_transform(x, False)\n        return x, np.concatenate(y2)\n\n\nclass AddPadding(CoordTransform):\n    """""" A class that represents adding paddings to an image.\n\n    The default padding is border_reflect\n    Arguments\n    ---------\n        pad : int\n            size of padding on top, bottom, left and right\n        mode:\n            type of cv2 padding modes. (e.g., constant, reflect, wrap, replicate. etc. )\n    """"""\n    def __init__(self, pad, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.pad,self.mode = pad,mode\n\n    def do_transform(self, im, is_y):\n        return cv2.copyMakeBorder(im, self.pad, self.pad, self.pad, self.pad, self.mode)\n\nclass CenterCrop(CoordTransform):\n    """""" A class that represents a Center Crop.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        sz: int\n            size of the crop.\n        tfm_y : TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.min_sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        return center_crop(x, self.sz_y if is_y else self.min_sz)\n\n\nclass RandomCrop(CoordTransform):\n    """""" A class that represents a Random Crop transformation.\n\n    This transforms (optionally) transforms x,y at with the same parameters.\n    Arguments\n    ---------\n        targ: int\n            target size of the crop.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, targ_sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz,self.sz_y = targ_sz,sz_y\n\n    def set_state(self):\n        self.store.rand_r = random.uniform(0, 1)\n        self.store.rand_c = random.uniform(0, 1)\n\n    def do_transform(self, x, is_y):\n        r,c,*_ = x.shape\n        sz = self.sz_y if is_y else self.targ_sz\n        start_r = np.floor(self.store.rand_r*(r-sz)).astype(int)\n        start_c = np.floor(self.store.rand_c*(c-sz)).astype(int)\n        return crop(x, start_r, start_c, sz)\n\n\nclass NoCrop(CoordTransform):\n    """"""  A transformation that resize to a square image without cropping.\n\n    This transforms (optionally) resizes x,y at with the same parameters.\n    Arguments:\n        targ: int\n            target size of the crop.\n        tfm_y (TfmType): type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return no_crop(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return no_crop(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass Scale(CoordTransform):\n    """""" A transformation that scales the min size to sz.\n\n    Arguments:\n        sz: int\n            target size to scale minimum size.\n        tfm_y: TfmType\n            type of y transformation.\n    """"""\n    def __init__(self, sz, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.sz_y = sz,sz_y\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.sz,   cv2.INTER_AREA   )\n\n\nclass RandomScale(CoordTransform):\n    """""" Scales an image so that the min size is a random number between [sz, sz*max_zoom]\n\n    This transforms (optionally) scales x,y at with the same parameters.\n    Arguments:\n        sz: int\n            target size\n        max_zoom: float\n            float >= 1.0\n        p : float\n            a probability for doing the random sizing\n        tfm_y: TfmType\n            type of y transform\n    """"""\n    def __init__(self, sz, max_zoom, p=0.75, tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.sz,self.max_zoom,self.p,self.sz_y = sz,max_zoom,p,sz_y\n\n    def set_state(self):\n        min_z = 1.\n        max_z = self.max_zoom\n        if isinstance(self.max_zoom, collections.Iterable):\n            min_z, max_z = self.max_zoom\n        self.store.mult = random.uniform(min_z, max_z) if random.random()<self.p else 1\n        self.store.new_sz = int(self.store.mult*self.sz)\n        if self.sz_y is not None: self.store.new_sz_y = int(self.store.mult*self.sz_y)\n\n\n    def do_transform(self, x, is_y):\n        if is_y: return scale_min(x, self.store.new_sz_y, cv2.INTER_AREA if self.tfm_y == TfmType.PIXEL else cv2.INTER_NEAREST)\n        else   : return scale_min(x, self.store.new_sz,   cv2.INTER_AREA   )\n\n\nclass RandomRotate(CoordTransform):\n    """""" Rotates images and (optionally) target y.\n\n    Rotating coordinates is treated differently for x and y on this\n    transform.\n     Arguments:\n        deg (float): degree to rotate.\n        p (float): probability of rotation\n        mode: type of border\n        tfm_y (TfmType): type of y transform\n    """"""\n    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.deg,self.p = deg,p\n        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n            self.modes = (mode,cv2.BORDER_CONSTANT)\n        else:\n            self.modes = (mode,mode)\n\n    def set_state(self):\n        self.store.rdeg = rand0(self.deg)\n        self.store.rp = random.random()<self.p\n\n    def do_transform(self, x, is_y):\n        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n                mode= self.modes[1] if is_y else self.modes[0],\n                interpolation=cv2.INTER_NEAREST if is_y else cv2.INTER_AREA)\n        return x\n\n\nclass RandomDihedral(CoordTransform):\n    """"""\n    Rotates images by random multiples of 90 degrees and/or reflection.\n    Please reference D8(dihedral group of order eight), the group of all symmetries of the square.\n    """"""\n    def set_state(self):\n        self.store.rot_times = random.randint(0,3)\n        self.store.do_flip = random.random()<0.5\n\n    def do_transform(self, x, is_y):\n        x = np.rot90(x, self.store.rot_times)\n        return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomFlip(CoordTransform):\n    def __init__(self, tfm_y=TfmType.NO, p=0.5):\n        super().__init__(tfm_y=tfm_y)\n        self.p=p\n\n    def set_state(self): self.store.do_flip = random.random()<self.p\n    def do_transform(self, x, is_y): return np.fliplr(x).copy() if self.store.do_flip else x\n\n\nclass RandomLighting(Transform):\n    def __init__(self, b, c, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.b,self.c = b,c\n\n    def set_state(self):\n        self.store.b_rand = rand0(self.b)\n        self.store.c_rand = rand0(self.c)\n\n    def do_transform(self, x, is_y):\n        if is_y and self.tfm_y != TfmType.PIXEL: return x\n        b = self.store.b_rand\n        c = self.store.c_rand\n        c = -1/(c-1) if c<0 else c+1\n        x = lighting(x, b, c)\n        return x\n\nclass RandomRotateZoom(CoordTransform):\n    """""" \n        Selects between a rotate, zoom, stretch, or no transform.\n        Arguments:\n            deg - maximum degrees of rotation.\n            zoom - maximum fraction of zoom.\n            stretch - maximum fraction of stretch.\n            ps - probabilities for each transform. List of length 4. The order for these probabilities is as listed respectively (4th probability is \'no transform\'.\n    """"""\n    def __init__(self, deg, zoom, stretch, ps=None, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        if ps is None: ps = [0.25,0.25,0.25,0.25]\n        assert len(ps) == 4, \'does not have 4 probabilities for p, it has %d\' % len(ps)\n        self.transforms = RandomRotate(deg, p=1, mode=mode, tfm_y=tfm_y), RandomZoom(zoom, tfm_y=tfm_y), RandomStretch(stretch,tfm_y=tfm_y)\n        self.pass_t = PassThru()\n        self.cum_ps = np.cumsum(ps)\n        assert self.cum_ps[3]==1, \'probabilites do not sum to 1; they sum to %d\' % self.cum_ps[3]\n\n    def set_state(self):\n        self.store.trans = self.pass_t\n        self.store.choice = self.cum_ps[3]*random.random()\n        for i in range(len(self.transforms)):\n            if self.store.choice < self.cum_ps[i]:\n                self.store.trans = self.transforms[i]\n                break\n        self.store.trans.set_state()\n\n    def do_transform(self, x, is_y): return self.store.trans.do_transform(x, is_y)\n\nclass RandomZoom(CoordTransform):\n    def __init__(self, zoom_max, zoom_min=0, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.zoom_max, self.zoom_min = zoom_max, zoom_min\n\n    def set_state(self):\n        self.store.zoom = self.zoom_min+(self.zoom_max-self.zoom_min)*random.random()\n\n    def do_transform(self, x, is_y):\n        return zoom_cv(x, self.store.zoom)\n\nclass RandomStretch(CoordTransform):\n    def __init__(self, max_stretch, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.max_stretch = max_stretch\n\n    def set_state(self):\n        self.store.stretch = self.max_stretch*random.random()\n        self.store.stretch_dir = random.randint(0,1)\n\n    def do_transform(self, x, is_y):\n        if self.store.stretch_dir==0: x = stretch_cv(x, self.store.stretch, 0)\n        else:                         x = stretch_cv(x, 0, self.store.stretch)\n        return x\n\nclass PassThru(CoordTransform):\n    def do_transform(self, x, is_y):\n        return x\n\nclass RandomBlur(Transform):\n    """"""\n    Adds a gaussian blur to the image at chance.\n    Multiple blur strengths can be configured, one of them is used by random chance.\n    """"""\n\n    def __init__(self, blur_strengths=5, probability=0.5, tfm_y=TfmType.NO):\n        # Blur strength must be an odd number, because it is used as a kernel size.\n        super().__init__(tfm_y)\n        self.blur_strengths = (np.array(blur_strengths, ndmin=1) * 2) - 1\n        if np.any(self.blur_strengths < 0):\n            raise ValueError(""all blur_strengths must be > 0"")\n        self.probability = probability\n        self.apply_transform = False\n\n    def set_state(self):\n        self.store.apply_transform = random.random() < self.probability\n        kernel_size = np.random.choice(self.blur_strengths)\n        self.store.kernel = (kernel_size, kernel_size)\n\n    def do_transform(self, x, is_y):\n        return cv2.GaussianBlur(src=x, ksize=self.store.kernel, sigmaX=0) if self.apply_transform else x\n\nclass Cutout(Transform):\n    def __init__(self, n_holes, length, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.n_holes,self.length = n_holes,length\n\n    def do_transform(self, img, is_y):\n        return cutout(img, self.n_holes, self.length)\n\nclass GoogleNetResize(CoordTransform):\n    """""" Randomly crops an image with an aspect ratio and returns a squared resized image of size targ \n    \n    Arguments:\n        targ_sz: int\n            target size\n        min_area_frac: float < 1.0\n            minimum area of the original image for cropping\n        min_aspect_ratio : float\n            minimum aspect ratio\n        max_aspect_ratio : float\n            maximum aspect ratio\n        flip_hw_p : float\n            probability for flipping magnitudes of height and width\n        tfm_y: TfmType\n            type of y transform\n    """"""\n\n    def __init__(self, targ_sz,\n                 min_area_frac=0.08, min_aspect_ratio=0.75, max_aspect_ratio=1.333, flip_hw_p=0.5,\n                 tfm_y=TfmType.NO, sz_y=None):\n        super().__init__(tfm_y)\n        self.targ_sz, self.tfm_y, self.sz_y = targ_sz, tfm_y, sz_y\n        self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.flip_hw_p = min_area_frac, min_aspect_ratio, max_aspect_ratio, flip_hw_p\n\n    def set_state(self):\n        # if self.random_state: random.seed(self.random_state)\n        self.store.fp = random.random()<self.flip_hw_p\n\n    def do_transform(self, x, is_y):\n        sz = self.sz_y if is_y else self.targ_sz\n        if is_y:\n            interpolation = cv2.INTER_NEAREST if self.tfm_y in (TfmType.COORD, TfmType.CLASS) else cv2.INTER_AREA\n        else:\n            interpolation = cv2.INTER_AREA\n        return googlenet_resize(x, sz, self.min_area_frac, self.min_aspect_ratio, self.max_aspect_ratio, self.store.fp, interpolation=interpolation)\n\n\ndef compose(im, y, fns):\n    """""" apply a collection of transformation functions fns to images\n    """"""\n    for fn in fns:\n        #pdb.set_trace()\n        im, y =fn(im, y)\n    return im if y is None else (im, y)\n\n\nclass CropType(IntEnum):\n    """""" Type of image cropping.\n    """"""\n    RANDOM = 1\n    CENTER = 2\n    NO = 3\n    GOOGLENET = 4\n\ncrop_fn_lu = {CropType.RANDOM: RandomCrop, CropType.CENTER: CenterCrop, CropType.NO: NoCrop, CropType.GOOGLENET: GoogleNetResize}\n\nclass Transforms():\n    def __init__(self, sz, tfms, normalizer, denorm, crop_type=CropType.CENTER,\n                 tfm_y=TfmType.NO, sz_y=None):\n        if sz_y is None: sz_y = sz\n        self.sz,self.denorm,self.norm,self.sz_y = sz,denorm,normalizer,sz_y\n        crop_tfm = crop_fn_lu[crop_type](sz, tfm_y, sz_y)\n        self.tfms = tfms\n        self.tfms.append(crop_tfm)\n        if normalizer is not None: self.tfms.append(normalizer)\n        self.tfms.append(ChannelOrder(tfm_y))\n\n    def __call__(self, im, y=None): return compose(im, y, self.tfms)\n    def __repr__(self): return str(self.tfms)\n\n\ndef image_gen(normalizer, denorm, sz, tfms=None, max_zoom=None, pad=0, crop_type=None,\n              tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, scale=None):\n    """"""\n    Generate a standard set of transformations\n\n    Arguments\n    ---------\n     normalizer :\n         image normalizing function\n     denorm :\n         image denormalizing function\n     sz :\n         size, sz_y = sz if not specified.\n     tfms :\n         iterable collection of transformation functions\n     max_zoom : float,\n         maximum zoom\n     pad : int,\n         padding on top, left, right and bottom\n     crop_type :\n         crop type\n     tfm_y :\n         y axis specific transformations\n     sz_y :\n         y size, height\n     pad_mode :\n         cv2 padding style: repeat, reflect, etc.\n\n    Returns\n    -------\n     type : ``Transforms``\n         transformer for specified image operations.\n\n    See Also\n    --------\n     Transforms: the transformer object returned by this function\n    """"""\n    if tfm_y is None: tfm_y=TfmType.NO\n    if tfms is None: tfms=[]\n    elif not isinstance(tfms, collections.Iterable): tfms=[tfms]\n    if sz_y is None: sz_y = sz\n    if scale is None:\n        scale = [RandomScale(sz, max_zoom, tfm_y=tfm_y, sz_y=sz_y) if max_zoom is not None\n                 else Scale(sz, tfm_y, sz_y=sz_y)]\n    elif not is_listy(scale): scale = [scale]\n    if pad: scale.append(AddPadding(pad, mode=pad_mode))\n    if crop_type!=CropType.GOOGLENET: tfms=scale+tfms\n    return Transforms(sz, tfms, normalizer, denorm, crop_type,\n                      tfm_y=tfm_y, sz_y=sz_y)\n\ndef noop(x):\n    """"""dummy function for do-nothing.\n    equivalent to: lambda x: x""""""\n    return x\n\ntransforms_basic    = [RandomRotate(10), RandomLighting(0.05, 0.05)]\ntransforms_side_on  = transforms_basic + [RandomFlip()]\ntransforms_top_down = transforms_basic + [RandomDihedral()]\n\nimagenet_stats = A([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n""""""Statistics pertaining to image data from image net. mean and std of the images of each color channel""""""\ninception_stats = A([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\ninception_models = (inception_4, inceptionresnet_2)\n\ndef tfms_from_stats(stats, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Given the statistics of the training image sets, returns separate training and validation transform functions\n    """"""\n    if aug_tfms is None: aug_tfms=[]\n    tfm_norm = Normalize(*stats, tfm_y=tfm_y if norm_y else TfmType.NO) if stats is not None else None\n    tfm_denorm = Denormalize(*stats) if stats is not None else None\n    val_crop = CropType.CENTER if crop_type in (CropType.RANDOM,CropType.GOOGLENET) else crop_type\n    val_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=val_crop,\n            tfm_y=tfm_y, sz_y=sz_y, scale=scale)\n    trn_tfm = image_gen(tfm_norm, tfm_denorm, sz, pad=pad, crop_type=crop_type,\n            tfm_y=tfm_y, sz_y=sz_y, tfms=aug_tfms, max_zoom=max_zoom, pad_mode=pad_mode, scale=scale)\n    return trn_tfm, val_tfm\n\n\ndef tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    """""" Returns separate transformers of images for training and validation.\n    Transformers are constructed according to the image statistics given b y the model. (See tfms_from_stats)\n\n    Arguments:\n        f_model: model, pretrained or not pretrained\n    """"""\n    stats = inception_stats if f_model in inception_models else imagenet_stats\n    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)\n\n'"
fastai/courses/ml1/fastai/transforms_pil.py,1,"b'import torch\nimport numpy as np\n\n\nclass Cutout(object):\n    """"""Randomly mask out one or more patches from an image.\n\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    """"""\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img (Tensor): Tensor image of size (C, H, W).\n        Returns:\n            Tensor: Image with n_holes of dimension length x length cut out of it.\n        """"""\n        h = img.size(1)\n        w = img.size(2)\n\n        mask = np.ones((h, w), np.float32)\n\n        for n in range(self.n_holes):\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.length / 2, 0, h)\n            y2 = np.clip(y + self.length / 2, 0, h)\n            x1 = np.clip(x - self.length / 2, 0, w)\n            x2 = np.clip(x + self.length / 2, 0, w)\n\n            mask[y1: y2, x1: x2] = 0.\n\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img = img * mask\n\n        return img\n'"
fastai/courses/ml1/fastai/utils.py,0,"b""import math, os, json, sys, re, numpy as np, pickle, PIL, scipy\nfrom PIL import Image\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nfrom operator import itemgetter, attrgetter, methodcaller\nfrom collections import OrderedDict\nimport itertools\nfrom itertools import chain\n\nimport pandas as pd\nfrom numpy.random import random, permutation, randn, normal, uniform, choice\nfrom numpy import newaxis\nfrom scipy import misc, ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.manifold import TSNE\nimport bcolz\n\nfrom IPython.lib.display import FileLink\n\nimport keras\nfrom keras import backend as K\nfrom keras.utils.data_utils import get_file\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\nfrom keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\nfrom keras.layers import Flatten, Dense, Dropout, Lambda\nfrom keras.regularizers import l2, l1\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.layers import deserialize as layer_from_config\nfrom keras.metrics import categorical_crossentropy, categorical_accuracy\nfrom keras.layers.convolutional import *\nfrom keras.preprocessing import image, sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom vgg16 import Vgg16\nnp.set_printoptions(precision=4, linewidth=100)\n\n\nto_bw = np.array([0.299, 0.587, 0.114])\n\ndef gray(img): return np.rollaxis(img, 0, 1).dot(to_bw)\ndef to_plot(img): return np.rollaxis(img, 0, 1).astype(np.uint8)\ndef plot(img): plt.imshow(to_plot(img))\n\ndef floor(x): return int(math.floor(x))\ndef ceil(x): return int(math.ceil(x))\n\ndef plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n    if type(ims[0]) is np.ndarray:\n        ims = np.array(ims).astype(np.uint8)\n        if (ims.shape[-1] != 3): ims = ims.transpose((0,2,3,1))\n    f = plt.figure(figsize=figsize)\n    \n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], interpolation=None if interp else 'none')\n\n\ndef do_clip(arr, mx):\n    clipped = np.clip(arr, (1-mx)/1, mx)\n    return clipped/clipped.sum(axis=1)[:, np.newaxis]\n\n\ndef wrap_config(layer):\n    return {'class_name': layer.__class__.__name__, 'config': layer.get_config()}\n\ndef copy_layer(layer): return layer_from_config(wrap_config(layer))\n\ndef copy_layers(layers): return [copy_layer(layer) for layer in layers]\n\ndef copy_weights(from_layers, to_layers):\n    for from_layer,to_layer in zip(from_layers, to_layers):\n        to_layer.set_weights(from_layer.get_weights())\n\ndef save_array(fname, arr):\n    c=bcolz.carray(arr, rootdir=fname, mode='w')\n    c.flush()\n\ndef load_array(fname): return bcolz.open(fname)[:]\n\ndef get_classes(path):\n    batches = get_batches(path+'train', shuffle=False, batch_size=1)\n    val_batches = get_batches(path+'valid', shuffle=False, batch_size=1)\n    test_batches = get_batches(path+'test', shuffle=False, batch_size=1)\n    return (val_batches.classes, batches.classes, onehot(val_batches.classes), onehot(batches.classes),\n        val_batches.filenames, batches.filenames, test_batches.filenames)\n\ndef limit_mem():\n    K.get_session().close()\n    cfg = K.tf.ConfigProto()\n    cfg.gpu_options.allow_growth = True\n    K.set_session(K.tf.Session(config=cfg))\n\nclass MixIterator(object):\n    def __init__(self, iters):\n        self.iters = iters\n        self.multi = type(iters) is list\n        if self.multi:\n            self.N = sum([it[0].N for it in self.iters])\n        else:\n            self.N = sum([it.N for it in self.iters])\n\n    def reset(self):\n        for it in self.iters: it.reset()\n\n    def __iter__(self):\n        return self\n\n    def next(self, *args, **kwargs):\n        if self.multi:\n            nexts = [[next(it) for it in o] for o in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n        else:\n            nexts = [next(it) for it in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n"""
fastai/fastai/models/cifar10/main_dxy.py,16,"b'from __future__ import division\n\nfrom senet import *\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--data_path\', default=\'./data\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', default=\'cifar10\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=64, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.05, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(0)\n\nif args.manualSeed is None: args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda: torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n  if not os.path.isdir(args.save_path): os.makedirs(args.save_path)\n  log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n  print_log(\'save path : {}\'.format(args.save_path), log)\n  state = {k: v for k, v in args._get_kwargs()}\n  print_log(state, log)\n  print_log(""Random Seed: {}"".format(args.manualSeed), log)\n  print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n  print_log(""torch  version : {}"".format(torch.__version__), log)\n  print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n\n  # Init dataset\n  if not os.path.isdir(args.data_path):\n    os.makedirs(args.data_path)\n\n  if args.dataset == \'cifar10\':\n    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n  elif args.dataset == \'cifar100\':\n    mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n    std = [x / 255 for x in [68.2, 65.4, 70.4]]\n  else:\n    assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n  train_transform = transforms.Compose(\n    [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n     transforms.Normalize(mean, std)])\n  test_transform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n  if args.dataset == \'cifar10\':\n    train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'cifar100\':\n    train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 100\n  elif args.dataset == \'svhn\':\n    train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'stl10\':\n    train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'imagenet\':\n    assert False, \'Do not finish imagenet code\'\n  else:\n    assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n  train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                         num_workers=args.workers, pin_memory=True)\n  test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                        num_workers=args.workers, pin_memory=True)\n\n  # Init model, criterion, and optimizer\n  #net = models.__dict__[args.arch](num_classes).cuda()\n  net = SENet34()\n\n  # define loss function (criterion) and optimizer\n  criterion = F.nll_loss\n  optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                weight_decay=state[\'decay\'], nesterov=True)\n\n  if args.use_cuda: net.cuda()\n\n  recorder = RecorderMeter(args.epochs)\n  # optionally resume from a checkpoint\n  if args.resume:\n    if os.path.isfile(args.resume):\n      print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n      checkpoint = torch.load(args.resume)\n      recorder = checkpoint[\'recorder\']\n      args.start_epoch = checkpoint[\'epoch\']\n      net.load_state_dict(checkpoint[\'state_dict\'])\n      optimizer.load_state_dict(checkpoint[\'optimizer\'])\n      print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n    else:\n      print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n  else:\n    print_log(""=> do not use any checkpoint for model"", log)\n\n  if args.evaluate:\n    validate(test_loader, net, criterion, log)\n    return\n\n  # Main loop\n  start_time = time.time()\n  epoch_time = AverageMeter()\n  for epoch in range(args.start_epoch, args.epochs):\n    current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n    need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n    print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n    # train for one epoch\n    train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n    # evaluate on validation set\n    val_acc,   val_los   = validate(test_loader, net, criterion, log)\n    is_best = recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n\n    save_checkpoint({\n      \'epoch\': epoch + 1,\n      \'state_dict\': net.state_dict(),\n      \'recorder\': recorder,\n      \'optimizer\' : optimizer.state_dict(),\n    }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    recorder.plot_curve( os.path.join(args.save_path, \'curve.png\') )\n\n  log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n  batch_time = AverageMeter()\n  data_time = AverageMeter()\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n  # switch to train mode\n  model.train()\n\n  end = time.time()\n  for i, (input, target) in enumerate(train_loader):\n    # measure data loading time\n    data_time.update(time.time() - end)\n\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input)\n    target_var = torch.autograd.Variable(target)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n    # compute gradient and do SGD step\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n  print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n        epoch, i, len(train_loader), batch_time=batch_time,\n        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n  return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n\n  # switch to evaluate mode\n  model.eval()\n\n  for i, (input, target) in enumerate(val_loader):\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input, volatile=True)\n    target_var = torch.autograd.Variable(target, volatile=True)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n  print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n  return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n  print(""{}"".format(print_string))\n  log.write(\'{}\\n\'.format(print_string))\n  log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n  filename = os.path.join(save_path, filename)\n  torch.save(state, filename)\n  if is_best:\n    bestname = os.path.join(save_path, \'model_best.pth.tar\')\n    shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n  """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n  lr = args.learning_rate\n  assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n  for (gamma, step) in zip(gammas, schedule):\n    if (epoch >= step):\n      lr = lr * gamma\n    else:\n      break\n  for param_group in optimizer.param_groups:\n    param_group[\'lr\'] = lr\n  return lr\n\ndef accuracy(output, target, topk=(1,)):\n  """"""Computes the precision@k for the specified values of k""""""\n  maxk = max(topk)\n  batch_size = target.size(0)\n\n  _, pred = output.topk(maxk, 1, True, True)\n  pred = pred.t()\n  correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n  res = []\n  for k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0)\n    res.append(correct_k.mul_(100.0 / batch_size))\n  return res\n\nif __name__ == \'__main__\':\n  main()\n'"
fastai/fastai/models/cifar10/main_kuangliu.py,15,"b""'''Train CIFAR10 with PyTorch.'''\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\n\nfrom senet import *\nfrom utils import progress_bar\nfrom torch.autograd import Variable\n\n\nparser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\nparser.add_argument('--lr', default=0.1, type=float, help='learning rate')\nparser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\nargs = parser.parse_args()\n\nuse_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(3)\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/ckpt.t7')\n    net = checkpoint['net']\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']\nelse:\n    print('==> Building model..')\n    # net = VGG('VGG19')\n    # net = ResNet18()\n    # net = PreActResNet18()\n    # net = GoogLeNet()\n    # net = DenseNet121()\n    # net = ResNeXt29_2x64d()\n    # net = MobileNet()\n    # net = DPN92()\n    # net = ShuffleNetG2()\n    net = SENet18()\n\nif use_cuda:\n    net.cuda()\n    #net = torch.nn.DataParallel(net, device_ids=(0,3))\n    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n    cudnn.benchmark = True\n\ncriterion = F.nll_loss\noptimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n\n# Training\ndef train(epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        optimizer.zero_grad()\n        inputs, targets = Variable(inputs), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n\n        test_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\n            'net': net,\n            'acc': acc,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt.t7')\n        best_acc = acc\n\n\nfor epoch in range(start_epoch, start_epoch+100):\n    train(epoch)\n    test(epoch)\n"""
fastai/fastai/models/cifar10/preact_resnet.py,3,"b""'''Pre-activation ResNet in PyTorch.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass PreActResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(PreActResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        return F.log_softmax(self.linear(out))\n\ndef PreActResNet18(): return PreActResNet(PreActBlock, [2,2,2,2])\ndef PreActResNet34(): return PreActResNet(PreActBlock, [3,4,6,3])\ndef PreActResNet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\ndef PreActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\ndef PreActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n\n"""
fastai/fastai/models/cifar10/resnext.py,3,"b'import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\nclass ResNeXtBottleneck(nn.Module):\n  expansion = 4\n  """"""\n  RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n  """"""\n  def __init__(self, inplanes, planes, cardinality, base_width, stride=1, downsample=None):\n    super(ResNeXtBottleneck, self).__init__()\n    self.downsample = downsample\n\n    D = int(math.floor(planes * (base_width/64.0)))\n    C = cardinality\n    self.conv_reduce = nn.Conv2d(inplanes, D*C, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_reduce = nn.BatchNorm2d(D*C)\n\n    self.conv_conv = nn.Conv2d(D*C, D*C, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n    self.bn = nn.BatchNorm2d(D*C)\n    self.conv_expand = nn.Conv2d(D*C, planes*4, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_expand = nn.BatchNorm2d(planes*4)\n\n  def forward(self, x):\n    residual = x\n\n    bottleneck = self.conv_reduce(x)\n    bottleneck = F.relu(self.bn_reduce(bottleneck), inplace=True)\n\n    bottleneck = self.conv_conv(bottleneck)\n    bottleneck = F.relu(self.bn(bottleneck), inplace=True)\n\n    bottleneck = self.conv_expand(bottleneck)\n    bottleneck = self.bn_expand(bottleneck)\n\n    if self.downsample is not None: residual = self.downsample(x)\n    return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n  """"""\n  ResNext optimized for the Cifar dataset, as specified in\n  https://arxiv.org/pdf/1611.05431.pdf\n  """"""\n  def __init__(self, block, depth, cardinality, base_width, num_classes):\n    super(CifarResNeXt, self).__init__()\n\n    # Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 9 == 0, \'depth should be one of 29, 38, 47, 56, 101\'\n    self.layer_blocks = (depth - 2) // 9\n\n    self.cardinality,self.base_width,self.num_classes,self.block = cardinality,base_width,num_classes,block\n\n    self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(64)\n\n    self.inplanes = 64\n    self.stage_1 = self._make_layer(64 , 1)\n    self.stage_2 = self._make_layer(128, 2)\n    self.stage_3 = self._make_layer(256, 2)\n    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n    self.classifier = nn.Linear(256*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, planes, stride=1):\n    downsample = None\n    exp_planes = planes * self.block.expansion\n    if stride != 1 or self.inplanes != exp_planes:\n      downsample = nn.Sequential(\n        nn.Conv2d(self.inplanes, exp_planes, kernel_size=1, stride=stride, bias=False),\n        nn.BatchNorm2d(exp_planes),\n      )\n\n    layers = []\n    layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width, stride, downsample))\n    self.inplanes = exp_planes\n    for i in range(1, self.layer_blocks):\n      layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return F.log_softmax(self.classifier(x))\n\ndef resnext29_16_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 16*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 16, 64, num_classes)\n  return model\n\ndef resnext29_8_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 8*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 8, 64, num_classes)\n  return model\n'"
fastai/fastai/models/cifar10/senet.py,3,"b""'''SENet in PyTorch.\n\nSENet is the winner of ImageNet-2017 (https://arxiv.org/abs/1709.01507).\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w  # New broadcasting feature from v0.2!\n\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w\n\n        out += shortcut\n        return out\n\n\nclass SENet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(SENet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        out = F.log_softmax(self.linear(out))\n        return out\n\n\ndef SENet18(): return SENet(PreActBlock, [2,2,2,2])\ndef SENet34(): return SENet(PreActBlock, [3,4,6,3])\n\n"""
fastai/fastai/models/cifar10/utils.py,0,"b'import os, sys, time\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n'"
fastai/fastai/models/cifar10/utils_kuangliu.py,5,"b""'''Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n'''\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\ndef get_mean_and_std(dataset):\n    '''Compute the mean and std value of dataset.'''\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print('==> Computing mean and std..')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    '''Init layer parameters.'''\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode='fan_out')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\n\n_, term_width = os.popen('stty size', 'r').read().split()\nterm_width = int(term_width)\n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f\n"""
fastai/fastai/models/cifar10/wideresnet.py,2,"b'# Cifar10 Wideresnet for Dawn Submission\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ...layers import *\n\ndef conv_2d(ni, nf, ks, stride): return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn(ni, init_zero=False):\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv_2d(ni, nf, ks, stride))\n\ndef noop(x): return x\n\nclass BasicBlock(nn.Module):\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        super().__init__()\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv_2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv_2d(ni, nf, 1, stride) if ni != nf else noop\n\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)\n        r = self.shortcut(x2)\n        x = self.conv1(x2)\n        if self.drop: x = self.drop(x)\n        x = self.conv2(x) * 0.2\n        return x.add_(r)\n\n\ndef _make_group(N, ni, nf, block, stride, drop_p):\n    return [block(ni if i == 0 else nf, nf, stride if i == 0 else 1, drop_p) for i in range(N)]\n\nclass WideResNet(nn.Module):\n    def __init__(self, num_groups, N, num_classes, k=1, drop_p=0.0, start_nf=16):\n        super().__init__()\n        n_channels = [start_nf]\n        for i in range(num_groups): n_channels.append(start_nf*(2**i)*k)\n\n        layers = [conv_2d(3, n_channels[0], 3, 1)]  # conv1\n        for i in range(num_groups):\n            layers += _make_group(N, n_channels[i], n_channels[i+1], BasicBlock, (1 if i==0 else 2), drop_p)\n\n        layers += [nn.BatchNorm2d(n_channels[3]), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),\n                   Flatten(), nn.Linear(n_channels[3], num_classes)]\n        self.features = nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef wrn_22(): return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.)\ndef wrn_22_k8(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.)\ndef wrn_22_k10(): return WideResNet(num_groups=3, N=3, num_classes=10, k=10, drop_p=0.)\ndef wrn_22_k8_p2(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.)\ndef wrn_28_k8(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.)\ndef wrn_28_k8_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.2)\n\n'"
fastai/tutorials/fastai/models/convert_torch.py,13,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.serialization import load_lua\n\nimport numpy as np\nimport os\nimport math\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        # result is Variables list [Variable1, Variable2, ...]\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        # result is a Variable\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef copy_param(m,n):\n    if m.weight is not None: n.weight.data.copy_(m.weight)\n    if m.bias is not None: n.bias.data.copy_(m.bias)\n    if hasattr(n,\'running_mean\'): n.running_mean.copy_(m.running_mean)\n    if hasattr(n,\'running_var\'): n.running_var.copy_(m.running_var)\n\ndef add_submodule(seq, *args):\n    for n in args:\n        seq.add_module(str(len(seq._modules)),n)\n\ndef lua_recursive_model(module,seq):\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            n = nn.Conv2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,bias=(m.bias is not None))\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'SpatialBatchNormalization\':\n            n = nn.BatchNorm2d(m.running_mean.size(0), m.eps, m.momentum, m.affine)\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'ReLU\':\n            n = nn.ReLU()\n            add_submodule(seq,n)\n        elif name == \'SpatialMaxPooling\':\n            n = nn.MaxPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialAveragePooling\':\n            n = nn.AvgPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialUpSamplingNearest\':\n            n = nn.UpsamplingNearest2d(scale_factor=m.scale_factor)\n            add_submodule(seq,n)\n        elif name == \'View\':\n            n = Lambda(lambda x: x.view(x.size(0),-1))\n            add_submodule(seq,n)\n        elif name == \'Linear\':\n            # Linear in pytorch only accept 2D input\n            n1 = Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\n            n2 = nn.Linear(m.weight.size(1),m.weight.size(0),bias=(m.bias is not None))\n            copy_param(m,n2)\n            n = nn.Sequential(n1,n2)\n            add_submodule(seq,n)\n        elif name == \'Dropout\':\n            m.inplace = False\n            n = nn.Dropout(m.p)\n            add_submodule(seq,n)\n        elif name == \'SoftMax\':\n            n = nn.Softmax()\n            add_submodule(seq,n)\n        elif name == \'Identity\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'SpatialFullConvolution\':\n            n = nn.ConvTranspose2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))\n            add_submodule(seq,n)\n        elif name == \'SpatialReplicationPadding\':\n            n = nn.ReplicationPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'SpatialReflectionPadding\':\n            n = nn.ReflectionPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'Copy\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'Narrow\':\n            n = Lambda(lambda x,a=(m.dimension,m.index,m.length): x.narrow(*a))\n            add_submodule(seq,n)\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = torch.legacy.nn.SpatialCrossMapLRN(m.size,m.alpha,m.beta,m.k)\n            n = Lambda(lambda x,lrn=lrn: Variable(lrn.forward(x.data)))\n            add_submodule(seq,n)\n        elif name == \'Sequential\':\n            n = nn.Sequential()\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'ConcatTable\': # output is list\n            n = LambdaMap(lambda x: x)\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'CAddTable\': # input is list\n            n = LambdaReduce(lambda x,y: x+y)\n            add_submodule(seq,n)\n        elif name == \'Concat\':\n            dim = m.dimension\n            n = LambdaReduce(lambda x,y,dim=dim: torch.cat((x,y),dim))\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'TorchObject\':\n            print(\'Not Implement\',name,real._typename)\n        else:\n            print(\'Not Implement\',name)\n\n\ndef lua_recursive_source(module):\n    s = []\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            s += [\'nn.Conv2d({},{},{},{},{},{},{},bias={}),#Conv2d\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,m.bias is not None)]\n        elif name == \'SpatialBatchNormalization\':\n            s += [\'nn.BatchNorm2d({},{},{},{}),#BatchNorm2d\'.format(m.running_mean.size(0), m.eps, m.momentum, m.affine)]\n        elif name == \'ReLU\':\n            s += [\'nn.ReLU()\']\n        elif name == \'SpatialMaxPooling\':\n            s += [\'nn.MaxPool2d({},{},{},ceil_mode={}),#MaxPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialAveragePooling\':\n            s += [\'nn.AvgPool2d({},{},{},ceil_mode={}),#AvgPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialUpSamplingNearest\':\n            s += [\'nn.UpsamplingNearest2d(scale_factor={})\'.format(m.scale_factor)]\n        elif name == \'View\':\n            s += [\'Lambda(lambda x: x.view(x.size(0),-1)), # View\']\n        elif name == \'Linear\':\n            s1 = \'Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\'\n            s2 = \'nn.Linear({},{},bias={})\'.format(m.weight.size(1),m.weight.size(0),(m.bias is not None))\n            s += [\'nn.Sequential({},{}),#Linear\'.format(s1,s2)]\n        elif name == \'Dropout\':\n            s += [\'nn.Dropout({})\'.format(m.p)]\n        elif name == \'SoftMax\':\n            s += [\'nn.Softmax()\']\n        elif name == \'Identity\':\n            s += [\'Lambda(lambda x: x), # Identity\']\n        elif name == \'SpatialFullConvolution\':\n            s += [\'nn.ConvTranspose2d({},{},{},{},{})\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))]\n        elif name == \'SpatialReplicationPadding\':\n            s += [\'nn.ReplicationPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'SpatialReflectionPadding\':\n            s += [\'nn.ReflectionPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'Copy\':\n            s += [\'Lambda(lambda x: x), # Copy\']\n        elif name == \'Narrow\':\n            s += [\'Lambda(lambda x,a={}: x.narrow(*a))\'.format((m.dimension,m.index,m.length))]\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = \'torch.legacy.nn.SpatialCrossMapLRN(*{})\'.format((m.size,m.alpha,m.beta,m.k))\n            s += [\'Lambda(lambda x,lrn={}: Variable(lrn.forward(x.data)))\'.format(lrn)]\n\n        elif name == \'Sequential\':\n            s += [\'nn.Sequential( # Sequential\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'ConcatTable\':\n            s += [\'LambdaMap(lambda x: x, # ConcatTable\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'CAddTable\':\n            s += [\'LambdaReduce(lambda x,y: x+y), # CAddTable\']\n        elif name == \'Concat\':\n            dim = m.dimension\n            s += [\'LambdaReduce(lambda x,y,dim={}: torch.cat((x,y),dim), # Concat\'.format(m.dimension)]\n            s += lua_recursive_source(m)\n            s += [\')\']\n        else:\n            s += \'# \' + name + \' Not Implement,\\n\'\n    s = map(lambda x: \'\\t{}\'.format(x),s)\n    return s\n\ndef simplify_source(s):\n    s = map(lambda x: x.replace(\',(1, 1),(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1e-05,0.1,True),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True)),#Linear\',\')), # Linear\'),s)\n    s = map(lambda x: x.replace(\')),#Linear\',\')), # Linear\'),s)\n    \n    s = map(lambda x: \'{},\\n\'.format(x),s)\n    s = map(lambda x: x[1:],s)\n    s = reduce(lambda x,y: x+y, s)\n    return s\n\ndef torch_to_pytorch(t7_filename,outputname=None):\n    model = load_lua(t7_filename,unknown_classes=True)\n    if type(model).__name__==\'hashable_uniq_dict\': model=model.model\n    model.gradInput = None\n    slist = lua_recursive_source(torch.legacy.nn.Sequential().add(model))\n    s = simplify_source(slist)\n    header = \'\'\'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\'\'\'\n    varname = t7_filename.replace(\'.t7\',\'\').replace(\'.\',\'_\').replace(\'-\',\'_\')\n    s = \'{}\\n\\n{} = {}\'.format(header,varname,s[:-2])\n\n    if outputname is None: outputname=varname\n    with open(outputname+\'.py\', ""w"") as pyfile:\n        pyfile.write(s)\n\n    n = nn.Sequential()\n    lua_recursive_model(model,n)\n    torch.save(n.state_dict(),outputname+\'.pth\')\n\n\nparser = argparse.ArgumentParser(description=\'Convert torch t7 model to pytorch\')\nparser.add_argument(\'--model\',\'-m\', type=str, required=True,\n                    help=\'torch model file in t7 format\')\nparser.add_argument(\'--output\', \'-o\', type=str, default=None,\n                    help=\'output file name prefix, xxx.py xxx.pth\')\nargs = parser.parse_args()\n\ntorch_to_pytorch(args.model,args.output)\n'"
fastai/tutorials/fastai/models/darknet.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .layers import *\n\nclass ConvBN(nn.Module):\n    ""convolutional layer then batchnorm""\n\n    def __init__(self, ch_in, ch_out, kernel_size = 3, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(ch_out, momentum=0.01)\n        self.relu = nn.LeakyReLU(0.1, inplace=True)\n\n    def forward(self, x): return self.relu(self.bn(self.conv(x)))\n\nclass DarknetBlock(nn.Module):\n    def __init__(self, ch_in):\n        super().__init__()\n        ch_hid = ch_in//2\n        self.conv1 = ConvBN(ch_in, ch_hid, kernel_size=1, stride=1, padding=0)\n        self.conv2 = ConvBN(ch_hid, ch_in, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x): return self.conv2(self.conv1(x)) + x\n\nclass Darknet(nn.Module):\n    ""Replicates the darknet classifier from the YOLOv3 paper (table 1)""\n\n    def make_group_layer(self, ch_in, num_blocks, stride=1):\n        layers = [ConvBN(ch_in,ch_in*2,stride=stride)]\n        for i in range(num_blocks): layers.append(DarknetBlock(ch_in*2))\n        return layers\n\n    def __init__(self, num_blocks, num_classes=1000, start_nf=32):\n        super().__init__()\n        nf = start_nf\n        layers = [ConvBN(3, nf, kernel_size=3, stride=1, padding=1)]\n        for i,nb in enumerate(num_blocks):\n            layers += self.make_group_layer(nf, nb, stride=(1 if i==1 else 2))\n            nf *= 2\n        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x): return self.layers(x)\n\ndef darknet_53(num_classes=1000):    return Darknet([1,2,8,8,4], num_classes)\ndef darknet_small(num_classes=1000): return Darknet([1,2,4,8,4], num_classes)\ndef darknet_mini(num_classes=1000): return Darknet([1,2,4,4,2], num_classes, start_nf=24)\ndef darknet_mini2(num_classes=1000): return Darknet([1,2,8,8,4], num_classes, start_nf=16)\ndef darknet_mini3(num_classes=1000): return Darknet([1,2,4,4], num_classes)\n\n'"
fastai/tutorials/fastai/models/fa_resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out += residual\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out += residual\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\ndef load(model, pre, name):\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    return model\n\ndef fa_resnet18(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [2, 2, 2, 2], **kwargs), pretrained, \'resnet18\')\ndef fa_resnet34(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [3, 4, 6, 3], **kwargs), pretrained, \'resnet34\')\ndef fa_resnet50(pretrained=False, **kwargs):  return load(ResNet(Bottleneck, [3, 4, 6, 3], **kwargs), pretrained, \'resnet50\')\ndef fa_resnet101(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 4, 23, 3], **kwargs), pretrained, \'resnet101\')\ndef fa_resnet152(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 8, 36, 3], **kwargs), pretrained, \'resnet152\')\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 ():  return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50():  return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck,[3, 4, 6, 3], k=1.125)\ndef vgg_resnet50():  return ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n\n'"
fastai/tutorials/fastai/models/inceptionresnetv2.py,31,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'http://webia.lip6.fr/~cadene/Downloads/inceptionresnetv2-d579a627.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_5b(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5b, self).__init__()\n\n        self.branch0 = BasicConv2d(192, 96, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(192, 48, kernel_size=1, stride=1),\n            BasicConv2d(48, 64, kernel_size=5, stride=1, padding=2)\n        ) \n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(192, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(192, 64, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block35(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block35, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(320, 32, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 48, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(48, 64, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.conv2d = nn.Conv2d(128, 320, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_6a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_6a, self).__init__()\n        \n        self.branch0 = BasicConv2d(320, 384, kernel_size=3, stride=2)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Block17(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block17, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(1088, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 128, kernel_size=1, stride=1),\n            BasicConv2d(128, 160, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(160, 192, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.conv2d = nn.Conv2d(384, 1088, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_7a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_7a, self).__init__()\n        \n        self.branch0 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(288, 320, kernel_size=3, stride=2)\n        )\n\n        self.branch3 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block8(nn.Module):\n\n    def __init__(self, scale=1.0, noReLU=False):\n        super(Block8, self).__init__()\n\n        self.scale = scale\n        self.noReLU = noReLU\n\n        self.branch0 = BasicConv2d(2080, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(2080, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,3), stride=1, padding=(0,1)),\n            BasicConv2d(224, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        )\n\n        self.conv2d = nn.Conv2d(448, 2080, kernel_size=1, stride=1)\n        if not self.noReLU:\n            self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        if not self.noReLU:\n            out = self.relu(out)\n        return out\n\n\nclass InceptionResnetV2(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionResnetV2, self).__init__()\n        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n        self.maxpool_5a = nn.MaxPool2d(3, stride=2)\n        self.mixed_5b = Mixed_5b()\n        self.repeat = nn.Sequential(\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17)\n        )\n        self.mixed_6a = Mixed_6a()\n        self.repeat_1 = nn.Sequential(\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10)\n        )\n        self.mixed_7a = Mixed_7a()\n        self.repeat_2 = nn.Sequential(\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20)\n        )\n        self.block8 = Block8(noReLU=True)\n        self.conv2d_7b = BasicConv2d(2080, 1536, kernel_size=1, stride=1)\n        self.avgpool_1a = nn.AdaptiveAvgPool2d((1,1))\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.conv2d_1a(x)\n        x = self.conv2d_2a(x)\n        x = self.conv2d_2b(x)\n        x = self.maxpool_3a(x)\n        x = self.conv2d_3b(x)\n        x = self.conv2d_4a(x)\n        x = self.maxpool_5a(x)\n        x = self.mixed_5b(x)\n        x = self.repeat(x)\n        x = self.mixed_6a(x)\n        x = self.repeat_1(x)\n        x = self.mixed_7a(x)\n        x = self.repeat_2(x)\n        x = self.block8(x)\n        x = self.conv2d_7b(x)\n        x = self.avgpool_1a(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\ndef inceptionresnetv2(pretrained=True):\n    r""""""InceptionResnetV2 model architecture from the\n    `""InceptionV4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (\'string\'): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionResnetV2()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_conv2d_nobn(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_5b(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_5x5\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_block35(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_6a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_block17(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef load_block8(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_1a\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2a\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2b\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_3b\', name_tf=\'Conv2d_3b_1x1\')\n    load_conv2d(state_dict, name_pth=\'conv2d_4a\', name_tf=\'Conv2d_4a_3x3\')\n\n    load_mixed_5b(state_dict, name_pth=\'mixed_5b\', name_tf=\'Mixed_5b\')\n\n    for i in range(10):\n        load_block35(state_dict, name_pth=\'repeat.\'+str(i), name_tf=\'Repeat/block35_\'+str(i+1))\n\n    load_mixed_6a(state_dict, name_pth=\'mixed_6a\', name_tf=\'Mixed_6a\')\n\n    for i in range(20):\n        load_block17(state_dict, name_pth=\'repeat_1.\'+str(i), name_tf=\'Repeat_1/block17_\'+str(i+1))\n\n    load_mixed_7a(state_dict, name_pth=\'mixed_7a\', name_tf=\'Mixed_7a\')\n\n    for i in range(9):\n        load_block8(state_dict, name_pth=\'repeat_2.\'+str(i), name_tf=\'Repeat_2/block8_\'+str(i+1))\n\n    load_block8(state_dict, name_pth=\'block8\', name_tf=\'Block8\')\n    load_conv2d(state_dict, name_pth=\'conv2d_7b\', name_tf=\'Conv2d_7b_1x1\')\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.ones(1,299,299,3)\n    #inputs[0] = torch.from_numpy(img)\n\n    inputs[0,0,0,0] = -1\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n\n    print(inputs.mean())\n    print(inputs.std())\n\n    #inputs.sub_(0.5).div_(0.5)\n    #inputs.sub_(inputs)\n    # 1, 3, 299, 299\n\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionResnetV2/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(outputs.sum())\n    print(outputs[0])\n    print(outputs_tf.sum())\n    print(outputs_tf[0])\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf_conv = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf_conv.transpose_(1,3)\n    output_tf_conv.transpose_(2,3)\n    output_tf_relu = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf_relu.transpose_(1,3)\n    output_tf_relu.transpose_(2,3)\n    h5f.close()\n    def test_dist_conv(self, input, output):\n        print(name, \'conv\', torch.dist(output.data, output_tf_conv))\n    module.conv.register_forward_hook(test_dist_conv)\n    def test_dist_relu(self, input, output):\n        print(name, \'relu\', torch.dist(output.data, output_tf_relu))\n    module.relu.register_forward_hook(test_dist_relu)\n\ndef test_conv2d_nobn(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, \'conv+bias\', torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_5b(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_5x5\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d(module.branch3[1], name+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef test_block35(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_6a(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef test_block17(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_1a_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef test_block8(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_3x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionResnetV2()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n    model.eval()\n\n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionresnetv2.pth\')\n    torch.save(state_dict, \'save/inceptionresnetv2_state.pth\')\n\n    test_conv2d(model.conv2d_1a, \'Conv2d_1a_3x3\')\n    test_conv2d(model.conv2d_2a, \'Conv2d_2a_3x3\')\n    test_conv2d(model.conv2d_2b, \'Conv2d_2b_3x3\')\n    test_conv2d(model.conv2d_3b, \'Conv2d_3b_1x1\')\n    test_conv2d(model.conv2d_4a, \'Conv2d_4a_3x3\')\n\n    test_mixed_5b(model.mixed_5b, \'Mixed_5b\')\n\n    for i in range(len(model.repeat._modules)):\n        test_block35(model.repeat[i], \'Repeat/block35_\'+str(i+1))\n\n    test_mixed_6a(model.mixed_6a, \'Mixed_6a\')\n\n    for i in range(len(model.repeat_1._modules)):\n        test_block17(model.repeat_1[i], \'Repeat_1/block17_\'+str(i+1))\n\n    test_mixed_7a(model.mixed_7a, \'Mixed_7a\')\n\n    for i in range(len(model.repeat_2._modules)):\n        test_block8(model.repeat_2[i], \'Repeat_2/block8_\'+str(i+1))\n\n    test_block8(model.block8, \'Block8\')\n\n    test_conv2d(model.conv2d_7b, \'Conv2d_7b_1x1\')\n\n    outputs = test(model)\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    #test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n\n'"
fastai/tutorials/fastai/models/inceptionv4.py,29,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'https://s3.amazonaws.com/pytorch/models/inceptionv4-58153ba9.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_3a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_3a, self).__init__()\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n\n    def forward(self, x):\n        x0 = self.maxpool(x)\n        x1 = self.conv(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_4a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_4a, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(64, 96, kernel_size=(3,3), stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_5a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5a, self).__init__()\n        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.conv(x)\n        x1 = self.maxpool(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Inception_A(nn.Module):\n\n    def __init__(self):\n        super(Inception_A, self).__init__()\n        self.block0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(384, 96, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_A(nn.Module):\n\n    def __init__(self):\n        super(Reduction_A, self).__init__()\n        self.block0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(224, 256, kernel_size=3, stride=2)\n        )\n        \n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_B(nn.Module):\n\n    def __init__(self):\n        super(Inception_B, self).__init__()\n        self.block0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n        \n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_B(nn.Module):\n\n    def __init__(self):\n        super(Reduction_B, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=3, stride=2)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(320, 320, kernel_size=3, stride=2)\n        )\n\n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_C(nn.Module):\n\n    def __init__(self):\n        super(Inception_C, self).__init__()\n        self.block0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        \n        self.block1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n        self.block2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3a = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3b = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        \n        x1_0 = self.block1_0(x)\n        x1_1a = self.block1_1a(x1_0)\n        x1_1b = self.block1_1b(x1_0)\n        x1 = torch.cat((x1_1a, x1_1b), 1)\n\n        x2_0 = self.block2_0(x)\n        x2_1 = self.block2_1(x2_0)\n        x2_2 = self.block2_2(x2_1)\n        x2_3a = self.block2_3a(x2_2)\n        x2_3b = self.block2_3b(x2_2)\n        x2 = torch.cat((x2_3a, x2_3b), 1)\n\n        x3 = self.block3(x)\n\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass InceptionV4(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionV4, self).__init__()\n        self.features = nn.Sequential(\n            BasicConv2d(3, 32, kernel_size=3, stride=2),\n            BasicConv2d(32, 32, kernel_size=3, stride=1),\n            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            Mixed_3a(),\n            Mixed_4a(),\n            Mixed_5a(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Reduction_A(), # Mixed_6a\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Reduction_B(), # Mixed_7a\n            Inception_C(),\n            Inception_C(),\n            Inception_C(),\n            nn.AdaptiveAvgPool2d((1,1))\n        )\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\n\ndef inceptionv4(pretrained=True):\n    r""""""InceptionV4 model architecture from the\n    `""Inception-v4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionV4()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_4a_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.3\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_mixed_5(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_6(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch2.3\', name_tf+\'/Branch_2/Conv2d_0d_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.4\', name_tf+\'/Branch_2/Conv2d_0e_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_7(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1a\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1b\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_1\', name_tf+\'/Branch_2/Conv2d_0b_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_2\', name_tf+\'/Branch_2/Conv2d_0c_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3a\', name_tf+\'/Branch_2/Conv2d_0d_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3b\', name_tf+\'/Branch_2/Conv2d_0e_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'features.0\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.1\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.2\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'features.3.conv\', name_tf=\'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.4\', name_tf=\'Mixed_4a\')\n\n    load_conv2d(state_dict, name_pth=\'features.5.conv\', name_tf=\'Mixed_5a/Branch_0/Conv2d_1a_3x3\')\n\n    load_mixed_5(state_dict, name_pth=\'features.6\', name_tf=\'Mixed_5b\')\n    load_mixed_5(state_dict, name_pth=\'features.7\', name_tf=\'Mixed_5c\')\n    load_mixed_5(state_dict, name_pth=\'features.8\', name_tf=\'Mixed_5d\')\n    load_mixed_5(state_dict, name_pth=\'features.9\', name_tf=\'Mixed_5e\')\n\n    load_conv2d(state_dict, name_pth=\'features.10.branch0\', name_tf=\'Mixed_6a/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.0\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.1\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.2\', name_tf=\'Mixed_6a/Branch_1/Conv2d_1a_3x3\')\n\n    load_mixed_6(state_dict, name_pth=\'features.11\', name_tf=\'Mixed_6b\')\n    load_mixed_6(state_dict, name_pth=\'features.12\', name_tf=\'Mixed_6c\')\n    load_mixed_6(state_dict, name_pth=\'features.13\', name_tf=\'Mixed_6d\')\n    load_mixed_6(state_dict, name_pth=\'features.14\', name_tf=\'Mixed_6e\')\n    load_mixed_6(state_dict, name_pth=\'features.15\', name_tf=\'Mixed_6f\')\n    load_mixed_6(state_dict, name_pth=\'features.16\', name_tf=\'Mixed_6g\')\n    load_mixed_6(state_dict, name_pth=\'features.17\', name_tf=\'Mixed_6h\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.18\', name_tf=\'Mixed_7a\')\n\n    load_mixed_7(state_dict, name_pth=\'features.19\', name_tf=\'Mixed_7b\')\n    load_mixed_7(state_dict, name_pth=\'features.20\', name_tf=\'Mixed_7c\')\n    load_mixed_7(state_dict, name_pth=\'features.21\', name_tf=\'Mixed_7d\')\n\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    model.eval()\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.zeros(1,299,299,3)\n    inputs[0] = torch.from_numpy(img)\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n    # 1, 3, 299, 299\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionV4/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionV4/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_4a_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d(module.branch1[3], name+\'/Branch_1/Conv2d_1a_3x3\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionV4()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n\n    # test_conv2d(model.features[0], \'Conv2d_1a_3x3\')\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    # test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n    \n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionv4.pth\')\n    torch.save(state_dict, \'save/inceptionv4_state.pth\')\n\n    outputs = test(model)\n\n\n'"
fastai/tutorials/fastai/models/nasnet.py,12,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\npretrained_settings = {\n    \'nasnetalarge\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1000\n        },\n        \'imagenet+background\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1001\n        }\n    }\n}\n\nclass MaxPoolPad(nn.Module):\n\n    def __init__(self):\n        super(MaxPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass AvgPoolPad(nn.Module):\n\n    def __init__(self, stride=2, padding=1):\n        super(AvgPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass SeparableConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n                                          stride=dw_stride,\n                                          padding=dw_padding,\n                                          bias=bias,\n                                          groups=in_channels)\n        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise_conv2d(x)\n        x = self.pointwise_conv2d(x)\n        return x\n\n\nclass BranchSeparables(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparables, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesStem(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparablesStem, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesReduction(BranchSeparables):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.padding(x)\n        x = self.separable_1(x)\n        x = x[:, :, 1:, 1:].contiguous()\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass CellStem0(nn.Module):\n\n    def __init__(self):\n        super(CellStem0, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(42, 42, 5, 2, 2)\n        self.comb_iter_0_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparablesStem(96, 42, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(42, 42, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x1 = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n        x_comb_iter_0_right = self.comb_iter_0_right(x)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n        x_comb_iter_1_right = self.comb_iter_1_right(x)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n        x_comb_iter_2_right = self.comb_iter_2_right(x)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass CellStem1(nn.Module):\n\n    def __init__(self):\n        super(CellStem1, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(168, 84, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(84, 84, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x_conv0, x_stem_0):\n        x_left = self.conv_1x1(x_stem_0)\n\n        x_relu = self.relu(x_conv0)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass FirstCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(FirstCell, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_relu = self.relu(x_prev)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NormalCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(NormalCell, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell0(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell0, self).__init__() \n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = MaxPoolPad()\n        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = AvgPoolPad()\n        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = MaxPoolPad()\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell1(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell1, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NASNetALarge(nn.Module):\n\n    def __init__(self, use_classifer=False, num_classes=1001):\n        super(NASNetALarge, self).__init__()\n        self.use_classifer,self.num_classes = use_classifer,num_classes\n\n        self.conv0 = nn.Sequential()\n        self.conv0.add_module(\'conv\', nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, padding=0, stride=2,\n                                                bias=False))\n        self.conv0.add_module(\'bn\', nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True))\n\n        self.cell_stem_0 = CellStem0()\n        self.cell_stem_1 = CellStem1()\n\n        self.cell_0 = FirstCell(in_channels_left=168, out_channels_left=84,\n                                in_channels_right=336, out_channels_right=168)\n        self.cell_1 = NormalCell(in_channels_left=336, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_2 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_3 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_4 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_5 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n\n        self.reduction_cell_0 = ReductionCell0(in_channels_left=1008, out_channels_left=336,\n                                               in_channels_right=1008, out_channels_right=336)\n\n        self.cell_6 = FirstCell(in_channels_left=1008, out_channels_left=168,\n                                in_channels_right=1344, out_channels_right=336)\n        self.cell_7 = NormalCell(in_channels_left=1344, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_8 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_9 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_10 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n        self.cell_11 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n\n        self.reduction_cell_1 = ReductionCell1(in_channels_left=2016, out_channels_left=672,\n                                               in_channels_right=2016, out_channels_right=672)\n\n        self.cell_12 = FirstCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2688, out_channels_right=672)\n        self.cell_13 = NormalCell(in_channels_left=2688, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_14 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_15 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_16 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_17 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout()\n        self.last_linear = nn.Linear(4032, self.num_classes)\n\n    def features(self, x):\n        x_conv0 = self.conv0(x)\n        x_stem_0 = self.cell_stem_0(x_conv0)\n        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n\n        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n        x_cell_4 = self.cell_4(x_cell_3, x_cell_2)\n        x_cell_5 = self.cell_5(x_cell_4, x_cell_3)\n\n        x_reduction_cell_0 = self.reduction_cell_0(x_cell_5, x_cell_4)\n\n        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_4)\n        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n        x_cell_10 = self.cell_10(x_cell_9, x_cell_8)\n        x_cell_11 = self.cell_11(x_cell_10, x_cell_9)\n\n        x_reduction_cell_1 = self.reduction_cell_1(x_cell_11, x_cell_10)\n\n        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_10)\n        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n        x_cell_16 = self.cell_16(x_cell_15, x_cell_14)\n        x_cell_17 = self.cell_17(x_cell_16, x_cell_15)\n        return self.relu(x_cell_17)\n\n    def classifier(self, x):\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        return F.log_softmax(self.linear(x))\n\n    def forward(self, x):\n        x = self.features(x)\n        if self.use_classifer: x = self.classifier(x)\n        return x\n\n\ndef nasnetalarge(num_classes=1000, pretrained=\'imagenet\'):\n    r""""""NASNetALarge model architecture from the\n    `""NASNet"" <https://arxiv.org/abs/1707.07012>`_ paper.\n    """"""\n    if pretrained:\n        settings = pretrained_settings[\'nasnetalarge\'][pretrained]\n        assert num_classes == settings[\'num_classes\'], \\\n            ""num_classes should be {}, but is {}"".format(settings[\'num_classes\'], num_classes)\n\n        # both \'imagenet\'&\'imagenet+background\' are loaded from same parameters\n        model = NASNetALarge(num_classes=1001)\n        model.load_state_dict(model_zoo.load_url(settings[\'url\']))\n\n        if pretrained == \'imagenet\':\n            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n            model.last_linear = new_last_linear\n\n        model.input_space = settings[\'input_space\']\n        model.input_size = settings[\'input_size\']\n        model.input_range = settings[\'input_range\']\n\n        model.mean = settings[\'mean\']\n        model.std = settings[\'std\']\n    else:\n        model = NASNetALarge(num_classes=num_classes)\n    return model\n'"
fastai/tutorials/fastai/models/resnet.py,4,"b""import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n__all__ = ['vgg_resnet50']\n\nmodel_urls = {\n    'vgg_resnet50': 'https://download.pytorch.org/models/vggresnet.pth',\n}\n\n\ndef conv(ni, nf, ks=3, stride=1):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, stride=stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out = residual + out\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out = residual + out\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [conv(3, 64, ks=7, stride=2)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv(self.inplanes, planes*block.expansion, ks=1, stride=stride),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 (): return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50(): return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck, [3, 4, 6, 3], k=1.125)\ndef vgg_resnet34(): return ResNet(BasicBlock, [3, 4, 6, 3], vgg_head=True)\ndef vgg_resnet50(pretrained=False):\n    model = ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n    if pretrained: model.load_state_dict(torch.load('/home/jhoward/.torch/models/vgg_resnet50.pth'))\n    return model\n\n"""
fastai/tutorials/fastai/models/resnext_101_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/tutorials/fastai/models/resnext_101_64x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_64x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/tutorials/fastai/models/resnext_50_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_50_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AdaptiveAvgPool2d(1),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)\n'"
fastai/tutorials/fastai/models/unet.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\n\ndef get_sfs_idxs(sfs, last=True):\n    """"""\n    Return the saved feature indexes that will be concatenated\n    Inputs:\n        sfs (list): saved features by hook function, in other words intermediate activations\n        last (bool): whether to concatenate only last different activation, or all from the encoder model\n    """"""\n    if last:\n        feature_szs = [sfs_feats.features.size()[-1] for sfs_feats in sfs]\n        sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n        if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n    else: sfs_idxs = list(range(len(sfs)))\n    return sfs_idxs\n\n\ndef conv_bn_relu(in_c, out_c, kernel_size, stride, padding):\n    return [\n        nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=stride, padding=padding),\n        nn.ReLU(),\n        nn.BatchNorm2d(out_c)]\n\n\nclass UnetBlock(nn.Module):\n    #TODO: ADAPT KERNEL SIZE, STRIDE AND PADDING SO THAT ANY SIZE DECAY WILL BE SUPPORTED\n    def __init__(self, up_in_c, x_in_c):\n        super().__init__()\n        self.upconv = nn.ConvTranspose2d(up_in_c, up_in_c // 2, 2, 2) # H, W -> 2H, 2W\n        self.conv1 = nn.Conv2d(x_in_c + up_in_c // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.conv2 = nn.Conv2d((x_in_c + up_in_c // 2) // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.bn = nn.BatchNorm2d((x_in_c + up_in_c // 2) // 2)\n\n    def forward(self, up_in, x_in):\n        up_out = self.upconv(up_in)\n        cat_x = torch.cat([up_out, x_in], dim=1)\n        x = F.relu(self.conv1(cat_x))\n        x = F.relu(self.conv2(x))\n        return self.bn(x)\n\nclass SaveFeatures():\n    """""" Extract pretrained activations""""""\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()\n\n\nclass DynamicUnet(nn.Module):\n    """"""\n    A dynamic implementation of Unet architecture, because calculating connections\n    and channels suck!. When an encoder is passed, this network will\n    automatically construct a decoder after the first single forward pass for any\n    given encoder architecture.\n\n    Decoder part is heavily based on the original Unet paper:\n    https://arxiv.org/abs/1505.04597.\n\n    Inputs:\n        encoder(nn.Module): Preferably a pretrained model, such as VGG or ResNet\n        last (bool): Whether to concat only last activation just before a size change\n        n_classes (int): Number of classes to output in final step of decoder\n\n    Important Note: If architecture directly reduces the dimension of an image as soon as the\n    first forward pass then output size will not be same as the input size, e.g. ResNet.\n    In order to resolve this problem architecture will add an additional extra conv transpose\n    layer. Also, currently Dynamic Unet expects size change to be H,W -> H/2, W/2. This is\n    not a problem for state-of-the-art architectures as they follow this pattern but it should\n    be changed for custom encoders that might have a different size decay.\n    """"""\n\n    def __init__(self, encoder, last=True, n_classes=3):\n        super().__init__()\n        self.encoder = encoder\n        self.n_children = len(list(encoder.children()))\n        self.sfs = [SaveFeatures(encoder[i]) for i in range(self.n_children)]\n        self.last = last\n        self.n_classes = n_classes\n\n    def forward(self, x):\n        # get imsize\n        imsize = x.size()[-2:]\n\n        # encoder output\n        x = F.relu(self.encoder(x))\n\n        # initialize sfs_idxs, sfs_szs, middle_in_c and middle_conv only once\n        if not hasattr(self, \'middle_conv\'):\n            self.sfs_szs = [sfs_feats.features.size() for sfs_feats in self.sfs]\n            self.sfs_idxs = get_sfs_idxs(self.sfs, self.last)\n            middle_in_c = self.sfs_szs[-1][1]\n            middle_conv = nn.Sequential(*conv_bn_relu(middle_in_c, middle_in_c * 2, 3, 1, 1),\n                                        *conv_bn_relu(middle_in_c * 2, middle_in_c, 3, 1, 1))\n            self.middle_conv = middle_conv\n\n        # middle conv\n        x = self.middle_conv(x)\n\n        # initialize upmodel, extra_block and 1x1 final conv\n        if not hasattr(self, \'upmodel\'):\n            x_copy = Variable(x.data, requires_grad=False)\n            upmodel = []\n            for idx in self.sfs_idxs[::-1]:\n                up_in_c, x_in_c = int(x_copy.size()[1]), int(self.sfs_szs[idx][1])\n                unet_block = UnetBlock(up_in_c, x_in_c)\n                upmodel.append(unet_block)\n                x_copy = unet_block(x_copy, self.sfs[idx].features)\n                self.upmodel = nn.Sequential(*upmodel)\n\n            if imsize != self.sfs_szs[0][-2:]:\n                extra_in_c = self.upmodel[-1].conv2.out_channels\n                self.extra_block = nn.ConvTranspose2d(extra_in_c, extra_in_c, 2, 2)\n\n            final_in_c = self.upmodel[-1].conv2.out_channels\n            self.final_conv = nn.Conv2d(final_in_c, self.n_classes, 1)\n\n        # run upsample\n        for block, idx in zip(self.upmodel, self.sfs_idxs[::-1]):\n            x = block(x, self.sfs[idx].features)\n        if hasattr(self, \'extra_block\'):\n            x = self.extra_block(x)\n\n        out = self.final_conv(x)\n        return out\n'"
fastai/tutorials/fastai/models/wideresnet.py,3,"b'# https://github.com/uoguelph-mlrg/Cutout\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super().__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut: x   = self.relu1(self.bn1(x))\n        else:                   out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super().__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x): return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super().__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert((depth - 4) % 6 == 0)\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear): m.bias.data.zero_()\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.adaptive_avg_pool2d(out, 1)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n'"
fastai/tutorials/fastai/models/wrn_50_2f.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef wrn_50_2f(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/dl1/fastai/models/convert_torch.py,13,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.serialization import load_lua\n\nimport numpy as np\nimport os\nimport math\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        # result is Variables list [Variable1, Variable2, ...]\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        # result is a Variable\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef copy_param(m,n):\n    if m.weight is not None: n.weight.data.copy_(m.weight)\n    if m.bias is not None: n.bias.data.copy_(m.bias)\n    if hasattr(n,\'running_mean\'): n.running_mean.copy_(m.running_mean)\n    if hasattr(n,\'running_var\'): n.running_var.copy_(m.running_var)\n\ndef add_submodule(seq, *args):\n    for n in args:\n        seq.add_module(str(len(seq._modules)),n)\n\ndef lua_recursive_model(module,seq):\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            n = nn.Conv2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,bias=(m.bias is not None))\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'SpatialBatchNormalization\':\n            n = nn.BatchNorm2d(m.running_mean.size(0), m.eps, m.momentum, m.affine)\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'ReLU\':\n            n = nn.ReLU()\n            add_submodule(seq,n)\n        elif name == \'SpatialMaxPooling\':\n            n = nn.MaxPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialAveragePooling\':\n            n = nn.AvgPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialUpSamplingNearest\':\n            n = nn.UpsamplingNearest2d(scale_factor=m.scale_factor)\n            add_submodule(seq,n)\n        elif name == \'View\':\n            n = Lambda(lambda x: x.view(x.size(0),-1))\n            add_submodule(seq,n)\n        elif name == \'Linear\':\n            # Linear in pytorch only accept 2D input\n            n1 = Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\n            n2 = nn.Linear(m.weight.size(1),m.weight.size(0),bias=(m.bias is not None))\n            copy_param(m,n2)\n            n = nn.Sequential(n1,n2)\n            add_submodule(seq,n)\n        elif name == \'Dropout\':\n            m.inplace = False\n            n = nn.Dropout(m.p)\n            add_submodule(seq,n)\n        elif name == \'SoftMax\':\n            n = nn.Softmax()\n            add_submodule(seq,n)\n        elif name == \'Identity\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'SpatialFullConvolution\':\n            n = nn.ConvTranspose2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))\n            add_submodule(seq,n)\n        elif name == \'SpatialReplicationPadding\':\n            n = nn.ReplicationPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'SpatialReflectionPadding\':\n            n = nn.ReflectionPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'Copy\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'Narrow\':\n            n = Lambda(lambda x,a=(m.dimension,m.index,m.length): x.narrow(*a))\n            add_submodule(seq,n)\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = torch.legacy.nn.SpatialCrossMapLRN(m.size,m.alpha,m.beta,m.k)\n            n = Lambda(lambda x,lrn=lrn: Variable(lrn.forward(x.data)))\n            add_submodule(seq,n)\n        elif name == \'Sequential\':\n            n = nn.Sequential()\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'ConcatTable\': # output is list\n            n = LambdaMap(lambda x: x)\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'CAddTable\': # input is list\n            n = LambdaReduce(lambda x,y: x+y)\n            add_submodule(seq,n)\n        elif name == \'Concat\':\n            dim = m.dimension\n            n = LambdaReduce(lambda x,y,dim=dim: torch.cat((x,y),dim))\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'TorchObject\':\n            print(\'Not Implement\',name,real._typename)\n        else:\n            print(\'Not Implement\',name)\n\n\ndef lua_recursive_source(module):\n    s = []\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            s += [\'nn.Conv2d({},{},{},{},{},{},{},bias={}),#Conv2d\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,m.bias is not None)]\n        elif name == \'SpatialBatchNormalization\':\n            s += [\'nn.BatchNorm2d({},{},{},{}),#BatchNorm2d\'.format(m.running_mean.size(0), m.eps, m.momentum, m.affine)]\n        elif name == \'ReLU\':\n            s += [\'nn.ReLU()\']\n        elif name == \'SpatialMaxPooling\':\n            s += [\'nn.MaxPool2d({},{},{},ceil_mode={}),#MaxPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialAveragePooling\':\n            s += [\'nn.AvgPool2d({},{},{},ceil_mode={}),#AvgPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialUpSamplingNearest\':\n            s += [\'nn.UpsamplingNearest2d(scale_factor={})\'.format(m.scale_factor)]\n        elif name == \'View\':\n            s += [\'Lambda(lambda x: x.view(x.size(0),-1)), # View\']\n        elif name == \'Linear\':\n            s1 = \'Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\'\n            s2 = \'nn.Linear({},{},bias={})\'.format(m.weight.size(1),m.weight.size(0),(m.bias is not None))\n            s += [\'nn.Sequential({},{}),#Linear\'.format(s1,s2)]\n        elif name == \'Dropout\':\n            s += [\'nn.Dropout({})\'.format(m.p)]\n        elif name == \'SoftMax\':\n            s += [\'nn.Softmax()\']\n        elif name == \'Identity\':\n            s += [\'Lambda(lambda x: x), # Identity\']\n        elif name == \'SpatialFullConvolution\':\n            s += [\'nn.ConvTranspose2d({},{},{},{},{})\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))]\n        elif name == \'SpatialReplicationPadding\':\n            s += [\'nn.ReplicationPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'SpatialReflectionPadding\':\n            s += [\'nn.ReflectionPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'Copy\':\n            s += [\'Lambda(lambda x: x), # Copy\']\n        elif name == \'Narrow\':\n            s += [\'Lambda(lambda x,a={}: x.narrow(*a))\'.format((m.dimension,m.index,m.length))]\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = \'torch.legacy.nn.SpatialCrossMapLRN(*{})\'.format((m.size,m.alpha,m.beta,m.k))\n            s += [\'Lambda(lambda x,lrn={}: Variable(lrn.forward(x.data)))\'.format(lrn)]\n\n        elif name == \'Sequential\':\n            s += [\'nn.Sequential( # Sequential\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'ConcatTable\':\n            s += [\'LambdaMap(lambda x: x, # ConcatTable\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'CAddTable\':\n            s += [\'LambdaReduce(lambda x,y: x+y), # CAddTable\']\n        elif name == \'Concat\':\n            dim = m.dimension\n            s += [\'LambdaReduce(lambda x,y,dim={}: torch.cat((x,y),dim), # Concat\'.format(m.dimension)]\n            s += lua_recursive_source(m)\n            s += [\')\']\n        else:\n            s += \'# \' + name + \' Not Implement,\\n\'\n    s = map(lambda x: \'\\t{}\'.format(x),s)\n    return s\n\ndef simplify_source(s):\n    s = map(lambda x: x.replace(\',(1, 1),(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1e-05,0.1,True),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True)),#Linear\',\')), # Linear\'),s)\n    s = map(lambda x: x.replace(\')),#Linear\',\')), # Linear\'),s)\n    \n    s = map(lambda x: \'{},\\n\'.format(x),s)\n    s = map(lambda x: x[1:],s)\n    s = reduce(lambda x,y: x+y, s)\n    return s\n\ndef torch_to_pytorch(t7_filename,outputname=None):\n    model = load_lua(t7_filename,unknown_classes=True)\n    if type(model).__name__==\'hashable_uniq_dict\': model=model.model\n    model.gradInput = None\n    slist = lua_recursive_source(torch.legacy.nn.Sequential().add(model))\n    s = simplify_source(slist)\n    header = \'\'\'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\'\'\'\n    varname = t7_filename.replace(\'.t7\',\'\').replace(\'.\',\'_\').replace(\'-\',\'_\')\n    s = \'{}\\n\\n{} = {}\'.format(header,varname,s[:-2])\n\n    if outputname is None: outputname=varname\n    with open(outputname+\'.py\', ""w"") as pyfile:\n        pyfile.write(s)\n\n    n = nn.Sequential()\n    lua_recursive_model(model,n)\n    torch.save(n.state_dict(),outputname+\'.pth\')\n\n\nparser = argparse.ArgumentParser(description=\'Convert torch t7 model to pytorch\')\nparser.add_argument(\'--model\',\'-m\', type=str, required=True,\n                    help=\'torch model file in t7 format\')\nparser.add_argument(\'--output\', \'-o\', type=str, default=None,\n                    help=\'output file name prefix, xxx.py xxx.pth\')\nargs = parser.parse_args()\n\ntorch_to_pytorch(args.model,args.output)\n'"
fastai/courses/dl1/fastai/models/darknet.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .layers import *\n\nclass ConvBN(nn.Module):\n    ""convolutional layer then batchnorm""\n\n    def __init__(self, ch_in, ch_out, kernel_size = 3, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(ch_out, momentum=0.01)\n        self.relu = nn.LeakyReLU(0.1, inplace=True)\n\n    def forward(self, x): return self.relu(self.bn(self.conv(x)))\n\nclass DarknetBlock(nn.Module):\n    def __init__(self, ch_in):\n        super().__init__()\n        ch_hid = ch_in//2\n        self.conv1 = ConvBN(ch_in, ch_hid, kernel_size=1, stride=1, padding=0)\n        self.conv2 = ConvBN(ch_hid, ch_in, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x): return self.conv2(self.conv1(x)) + x\n\nclass Darknet(nn.Module):\n    ""Replicates the darknet classifier from the YOLOv3 paper (table 1)""\n\n    def make_group_layer(self, ch_in, num_blocks, stride=1):\n        layers = [ConvBN(ch_in,ch_in*2,stride=stride)]\n        for i in range(num_blocks): layers.append(DarknetBlock(ch_in*2))\n        return layers\n\n    def __init__(self, num_blocks, num_classes=1000, start_nf=32):\n        super().__init__()\n        nf = start_nf\n        layers = [ConvBN(3, nf, kernel_size=3, stride=1, padding=1)]\n        for i,nb in enumerate(num_blocks):\n            layers += self.make_group_layer(nf, nb, stride=(1 if i==1 else 2))\n            nf *= 2\n        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x): return self.layers(x)\n\ndef darknet_53(num_classes=1000):    return Darknet([1,2,8,8,4], num_classes)\ndef darknet_small(num_classes=1000): return Darknet([1,2,4,8,4], num_classes)\ndef darknet_mini(num_classes=1000): return Darknet([1,2,4,4,2], num_classes, start_nf=24)\ndef darknet_mini2(num_classes=1000): return Darknet([1,2,8,8,4], num_classes, start_nf=16)\ndef darknet_mini3(num_classes=1000): return Darknet([1,2,4,4], num_classes)\n\n'"
fastai/courses/dl1/fastai/models/fa_resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out += residual\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out += residual\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\ndef load(model, pre, name):\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    return model\n\ndef fa_resnet18(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [2, 2, 2, 2], **kwargs), pretrained, \'resnet18\')\ndef fa_resnet34(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [3, 4, 6, 3], **kwargs), pretrained, \'resnet34\')\ndef fa_resnet50(pretrained=False, **kwargs):  return load(ResNet(Bottleneck, [3, 4, 6, 3], **kwargs), pretrained, \'resnet50\')\ndef fa_resnet101(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 4, 23, 3], **kwargs), pretrained, \'resnet101\')\ndef fa_resnet152(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 8, 36, 3], **kwargs), pretrained, \'resnet152\')\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 ():  return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50():  return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck,[3, 4, 6, 3], k=1.125)\ndef vgg_resnet50():  return ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n\n'"
fastai/courses/dl1/fastai/models/inceptionresnetv2.py,31,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'http://webia.lip6.fr/~cadene/Downloads/inceptionresnetv2-d579a627.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_5b(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5b, self).__init__()\n\n        self.branch0 = BasicConv2d(192, 96, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(192, 48, kernel_size=1, stride=1),\n            BasicConv2d(48, 64, kernel_size=5, stride=1, padding=2)\n        ) \n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(192, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(192, 64, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block35(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block35, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(320, 32, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 48, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(48, 64, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.conv2d = nn.Conv2d(128, 320, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_6a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_6a, self).__init__()\n        \n        self.branch0 = BasicConv2d(320, 384, kernel_size=3, stride=2)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Block17(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block17, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(1088, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 128, kernel_size=1, stride=1),\n            BasicConv2d(128, 160, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(160, 192, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.conv2d = nn.Conv2d(384, 1088, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_7a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_7a, self).__init__()\n        \n        self.branch0 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(288, 320, kernel_size=3, stride=2)\n        )\n\n        self.branch3 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block8(nn.Module):\n\n    def __init__(self, scale=1.0, noReLU=False):\n        super(Block8, self).__init__()\n\n        self.scale = scale\n        self.noReLU = noReLU\n\n        self.branch0 = BasicConv2d(2080, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(2080, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,3), stride=1, padding=(0,1)),\n            BasicConv2d(224, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        )\n\n        self.conv2d = nn.Conv2d(448, 2080, kernel_size=1, stride=1)\n        if not self.noReLU:\n            self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        if not self.noReLU:\n            out = self.relu(out)\n        return out\n\n\nclass InceptionResnetV2(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionResnetV2, self).__init__()\n        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n        self.maxpool_5a = nn.MaxPool2d(3, stride=2)\n        self.mixed_5b = Mixed_5b()\n        self.repeat = nn.Sequential(\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17)\n        )\n        self.mixed_6a = Mixed_6a()\n        self.repeat_1 = nn.Sequential(\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10)\n        )\n        self.mixed_7a = Mixed_7a()\n        self.repeat_2 = nn.Sequential(\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20)\n        )\n        self.block8 = Block8(noReLU=True)\n        self.conv2d_7b = BasicConv2d(2080, 1536, kernel_size=1, stride=1)\n        self.avgpool_1a = nn.AdaptiveAvgPool2d((1,1))\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.conv2d_1a(x)\n        x = self.conv2d_2a(x)\n        x = self.conv2d_2b(x)\n        x = self.maxpool_3a(x)\n        x = self.conv2d_3b(x)\n        x = self.conv2d_4a(x)\n        x = self.maxpool_5a(x)\n        x = self.mixed_5b(x)\n        x = self.repeat(x)\n        x = self.mixed_6a(x)\n        x = self.repeat_1(x)\n        x = self.mixed_7a(x)\n        x = self.repeat_2(x)\n        x = self.block8(x)\n        x = self.conv2d_7b(x)\n        x = self.avgpool_1a(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\ndef inceptionresnetv2(pretrained=True):\n    r""""""InceptionResnetV2 model architecture from the\n    `""InceptionV4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (\'string\'): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionResnetV2()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_conv2d_nobn(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_5b(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_5x5\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_block35(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_6a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_block17(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef load_block8(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_1a\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2a\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2b\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_3b\', name_tf=\'Conv2d_3b_1x1\')\n    load_conv2d(state_dict, name_pth=\'conv2d_4a\', name_tf=\'Conv2d_4a_3x3\')\n\n    load_mixed_5b(state_dict, name_pth=\'mixed_5b\', name_tf=\'Mixed_5b\')\n\n    for i in range(10):\n        load_block35(state_dict, name_pth=\'repeat.\'+str(i), name_tf=\'Repeat/block35_\'+str(i+1))\n\n    load_mixed_6a(state_dict, name_pth=\'mixed_6a\', name_tf=\'Mixed_6a\')\n\n    for i in range(20):\n        load_block17(state_dict, name_pth=\'repeat_1.\'+str(i), name_tf=\'Repeat_1/block17_\'+str(i+1))\n\n    load_mixed_7a(state_dict, name_pth=\'mixed_7a\', name_tf=\'Mixed_7a\')\n\n    for i in range(9):\n        load_block8(state_dict, name_pth=\'repeat_2.\'+str(i), name_tf=\'Repeat_2/block8_\'+str(i+1))\n\n    load_block8(state_dict, name_pth=\'block8\', name_tf=\'Block8\')\n    load_conv2d(state_dict, name_pth=\'conv2d_7b\', name_tf=\'Conv2d_7b_1x1\')\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.ones(1,299,299,3)\n    #inputs[0] = torch.from_numpy(img)\n\n    inputs[0,0,0,0] = -1\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n\n    print(inputs.mean())\n    print(inputs.std())\n\n    #inputs.sub_(0.5).div_(0.5)\n    #inputs.sub_(inputs)\n    # 1, 3, 299, 299\n\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionResnetV2/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(outputs.sum())\n    print(outputs[0])\n    print(outputs_tf.sum())\n    print(outputs_tf[0])\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf_conv = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf_conv.transpose_(1,3)\n    output_tf_conv.transpose_(2,3)\n    output_tf_relu = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf_relu.transpose_(1,3)\n    output_tf_relu.transpose_(2,3)\n    h5f.close()\n    def test_dist_conv(self, input, output):\n        print(name, \'conv\', torch.dist(output.data, output_tf_conv))\n    module.conv.register_forward_hook(test_dist_conv)\n    def test_dist_relu(self, input, output):\n        print(name, \'relu\', torch.dist(output.data, output_tf_relu))\n    module.relu.register_forward_hook(test_dist_relu)\n\ndef test_conv2d_nobn(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, \'conv+bias\', torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_5b(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_5x5\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d(module.branch3[1], name+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef test_block35(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_6a(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef test_block17(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_1a_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef test_block8(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_3x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionResnetV2()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n    model.eval()\n\n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionresnetv2.pth\')\n    torch.save(state_dict, \'save/inceptionresnetv2_state.pth\')\n\n    test_conv2d(model.conv2d_1a, \'Conv2d_1a_3x3\')\n    test_conv2d(model.conv2d_2a, \'Conv2d_2a_3x3\')\n    test_conv2d(model.conv2d_2b, \'Conv2d_2b_3x3\')\n    test_conv2d(model.conv2d_3b, \'Conv2d_3b_1x1\')\n    test_conv2d(model.conv2d_4a, \'Conv2d_4a_3x3\')\n\n    test_mixed_5b(model.mixed_5b, \'Mixed_5b\')\n\n    for i in range(len(model.repeat._modules)):\n        test_block35(model.repeat[i], \'Repeat/block35_\'+str(i+1))\n\n    test_mixed_6a(model.mixed_6a, \'Mixed_6a\')\n\n    for i in range(len(model.repeat_1._modules)):\n        test_block17(model.repeat_1[i], \'Repeat_1/block17_\'+str(i+1))\n\n    test_mixed_7a(model.mixed_7a, \'Mixed_7a\')\n\n    for i in range(len(model.repeat_2._modules)):\n        test_block8(model.repeat_2[i], \'Repeat_2/block8_\'+str(i+1))\n\n    test_block8(model.block8, \'Block8\')\n\n    test_conv2d(model.conv2d_7b, \'Conv2d_7b_1x1\')\n\n    outputs = test(model)\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    #test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n\n'"
fastai/courses/dl1/fastai/models/inceptionv4.py,29,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'https://s3.amazonaws.com/pytorch/models/inceptionv4-58153ba9.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_3a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_3a, self).__init__()\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n\n    def forward(self, x):\n        x0 = self.maxpool(x)\n        x1 = self.conv(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_4a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_4a, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(64, 96, kernel_size=(3,3), stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_5a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5a, self).__init__()\n        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.conv(x)\n        x1 = self.maxpool(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Inception_A(nn.Module):\n\n    def __init__(self):\n        super(Inception_A, self).__init__()\n        self.block0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(384, 96, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_A(nn.Module):\n\n    def __init__(self):\n        super(Reduction_A, self).__init__()\n        self.block0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(224, 256, kernel_size=3, stride=2)\n        )\n        \n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_B(nn.Module):\n\n    def __init__(self):\n        super(Inception_B, self).__init__()\n        self.block0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n        \n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_B(nn.Module):\n\n    def __init__(self):\n        super(Reduction_B, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=3, stride=2)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(320, 320, kernel_size=3, stride=2)\n        )\n\n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_C(nn.Module):\n\n    def __init__(self):\n        super(Inception_C, self).__init__()\n        self.block0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        \n        self.block1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n        self.block2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3a = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3b = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        \n        x1_0 = self.block1_0(x)\n        x1_1a = self.block1_1a(x1_0)\n        x1_1b = self.block1_1b(x1_0)\n        x1 = torch.cat((x1_1a, x1_1b), 1)\n\n        x2_0 = self.block2_0(x)\n        x2_1 = self.block2_1(x2_0)\n        x2_2 = self.block2_2(x2_1)\n        x2_3a = self.block2_3a(x2_2)\n        x2_3b = self.block2_3b(x2_2)\n        x2 = torch.cat((x2_3a, x2_3b), 1)\n\n        x3 = self.block3(x)\n\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass InceptionV4(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionV4, self).__init__()\n        self.features = nn.Sequential(\n            BasicConv2d(3, 32, kernel_size=3, stride=2),\n            BasicConv2d(32, 32, kernel_size=3, stride=1),\n            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            Mixed_3a(),\n            Mixed_4a(),\n            Mixed_5a(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Reduction_A(), # Mixed_6a\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Reduction_B(), # Mixed_7a\n            Inception_C(),\n            Inception_C(),\n            Inception_C(),\n            nn.AdaptiveAvgPool2d((1,1))\n        )\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\n\ndef inceptionv4(pretrained=True):\n    r""""""InceptionV4 model architecture from the\n    `""Inception-v4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionV4()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_4a_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.3\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_mixed_5(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_6(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch2.3\', name_tf+\'/Branch_2/Conv2d_0d_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.4\', name_tf+\'/Branch_2/Conv2d_0e_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_7(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1a\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1b\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_1\', name_tf+\'/Branch_2/Conv2d_0b_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_2\', name_tf+\'/Branch_2/Conv2d_0c_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3a\', name_tf+\'/Branch_2/Conv2d_0d_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3b\', name_tf+\'/Branch_2/Conv2d_0e_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'features.0\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.1\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.2\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'features.3.conv\', name_tf=\'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.4\', name_tf=\'Mixed_4a\')\n\n    load_conv2d(state_dict, name_pth=\'features.5.conv\', name_tf=\'Mixed_5a/Branch_0/Conv2d_1a_3x3\')\n\n    load_mixed_5(state_dict, name_pth=\'features.6\', name_tf=\'Mixed_5b\')\n    load_mixed_5(state_dict, name_pth=\'features.7\', name_tf=\'Mixed_5c\')\n    load_mixed_5(state_dict, name_pth=\'features.8\', name_tf=\'Mixed_5d\')\n    load_mixed_5(state_dict, name_pth=\'features.9\', name_tf=\'Mixed_5e\')\n\n    load_conv2d(state_dict, name_pth=\'features.10.branch0\', name_tf=\'Mixed_6a/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.0\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.1\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.2\', name_tf=\'Mixed_6a/Branch_1/Conv2d_1a_3x3\')\n\n    load_mixed_6(state_dict, name_pth=\'features.11\', name_tf=\'Mixed_6b\')\n    load_mixed_6(state_dict, name_pth=\'features.12\', name_tf=\'Mixed_6c\')\n    load_mixed_6(state_dict, name_pth=\'features.13\', name_tf=\'Mixed_6d\')\n    load_mixed_6(state_dict, name_pth=\'features.14\', name_tf=\'Mixed_6e\')\n    load_mixed_6(state_dict, name_pth=\'features.15\', name_tf=\'Mixed_6f\')\n    load_mixed_6(state_dict, name_pth=\'features.16\', name_tf=\'Mixed_6g\')\n    load_mixed_6(state_dict, name_pth=\'features.17\', name_tf=\'Mixed_6h\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.18\', name_tf=\'Mixed_7a\')\n\n    load_mixed_7(state_dict, name_pth=\'features.19\', name_tf=\'Mixed_7b\')\n    load_mixed_7(state_dict, name_pth=\'features.20\', name_tf=\'Mixed_7c\')\n    load_mixed_7(state_dict, name_pth=\'features.21\', name_tf=\'Mixed_7d\')\n\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    model.eval()\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.zeros(1,299,299,3)\n    inputs[0] = torch.from_numpy(img)\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n    # 1, 3, 299, 299\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionV4/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionV4/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_4a_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d(module.branch1[3], name+\'/Branch_1/Conv2d_1a_3x3\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionV4()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n\n    # test_conv2d(model.features[0], \'Conv2d_1a_3x3\')\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    # test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n    \n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionv4.pth\')\n    torch.save(state_dict, \'save/inceptionv4_state.pth\')\n\n    outputs = test(model)\n\n\n'"
fastai/courses/dl1/fastai/models/nasnet.py,12,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\npretrained_settings = {\n    \'nasnetalarge\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1000\n        },\n        \'imagenet+background\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1001\n        }\n    }\n}\n\nclass MaxPoolPad(nn.Module):\n\n    def __init__(self):\n        super(MaxPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass AvgPoolPad(nn.Module):\n\n    def __init__(self, stride=2, padding=1):\n        super(AvgPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass SeparableConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n                                          stride=dw_stride,\n                                          padding=dw_padding,\n                                          bias=bias,\n                                          groups=in_channels)\n        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise_conv2d(x)\n        x = self.pointwise_conv2d(x)\n        return x\n\n\nclass BranchSeparables(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparables, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesStem(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparablesStem, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesReduction(BranchSeparables):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.padding(x)\n        x = self.separable_1(x)\n        x = x[:, :, 1:, 1:].contiguous()\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass CellStem0(nn.Module):\n\n    def __init__(self):\n        super(CellStem0, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(42, 42, 5, 2, 2)\n        self.comb_iter_0_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparablesStem(96, 42, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(42, 42, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x1 = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n        x_comb_iter_0_right = self.comb_iter_0_right(x)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n        x_comb_iter_1_right = self.comb_iter_1_right(x)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n        x_comb_iter_2_right = self.comb_iter_2_right(x)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass CellStem1(nn.Module):\n\n    def __init__(self):\n        super(CellStem1, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(168, 84, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(84, 84, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x_conv0, x_stem_0):\n        x_left = self.conv_1x1(x_stem_0)\n\n        x_relu = self.relu(x_conv0)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass FirstCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(FirstCell, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_relu = self.relu(x_prev)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NormalCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(NormalCell, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell0(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell0, self).__init__() \n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = MaxPoolPad()\n        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = AvgPoolPad()\n        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = MaxPoolPad()\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell1(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell1, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NASNetALarge(nn.Module):\n\n    def __init__(self, use_classifer=False, num_classes=1001):\n        super(NASNetALarge, self).__init__()\n        self.use_classifer,self.num_classes = use_classifer,num_classes\n\n        self.conv0 = nn.Sequential()\n        self.conv0.add_module(\'conv\', nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, padding=0, stride=2,\n                                                bias=False))\n        self.conv0.add_module(\'bn\', nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True))\n\n        self.cell_stem_0 = CellStem0()\n        self.cell_stem_1 = CellStem1()\n\n        self.cell_0 = FirstCell(in_channels_left=168, out_channels_left=84,\n                                in_channels_right=336, out_channels_right=168)\n        self.cell_1 = NormalCell(in_channels_left=336, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_2 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_3 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_4 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_5 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n\n        self.reduction_cell_0 = ReductionCell0(in_channels_left=1008, out_channels_left=336,\n                                               in_channels_right=1008, out_channels_right=336)\n\n        self.cell_6 = FirstCell(in_channels_left=1008, out_channels_left=168,\n                                in_channels_right=1344, out_channels_right=336)\n        self.cell_7 = NormalCell(in_channels_left=1344, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_8 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_9 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_10 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n        self.cell_11 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n\n        self.reduction_cell_1 = ReductionCell1(in_channels_left=2016, out_channels_left=672,\n                                               in_channels_right=2016, out_channels_right=672)\n\n        self.cell_12 = FirstCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2688, out_channels_right=672)\n        self.cell_13 = NormalCell(in_channels_left=2688, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_14 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_15 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_16 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_17 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout()\n        self.last_linear = nn.Linear(4032, self.num_classes)\n\n    def features(self, x):\n        x_conv0 = self.conv0(x)\n        x_stem_0 = self.cell_stem_0(x_conv0)\n        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n\n        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n        x_cell_4 = self.cell_4(x_cell_3, x_cell_2)\n        x_cell_5 = self.cell_5(x_cell_4, x_cell_3)\n\n        x_reduction_cell_0 = self.reduction_cell_0(x_cell_5, x_cell_4)\n\n        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_4)\n        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n        x_cell_10 = self.cell_10(x_cell_9, x_cell_8)\n        x_cell_11 = self.cell_11(x_cell_10, x_cell_9)\n\n        x_reduction_cell_1 = self.reduction_cell_1(x_cell_11, x_cell_10)\n\n        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_10)\n        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n        x_cell_16 = self.cell_16(x_cell_15, x_cell_14)\n        x_cell_17 = self.cell_17(x_cell_16, x_cell_15)\n        return self.relu(x_cell_17)\n\n    def classifier(self, x):\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        return F.log_softmax(self.linear(x))\n\n    def forward(self, x):\n        x = self.features(x)\n        if self.use_classifer: x = self.classifier(x)\n        return x\n\n\ndef nasnetalarge(num_classes=1000, pretrained=\'imagenet\'):\n    r""""""NASNetALarge model architecture from the\n    `""NASNet"" <https://arxiv.org/abs/1707.07012>`_ paper.\n    """"""\n    if pretrained:\n        settings = pretrained_settings[\'nasnetalarge\'][pretrained]\n        assert num_classes == settings[\'num_classes\'], \\\n            ""num_classes should be {}, but is {}"".format(settings[\'num_classes\'], num_classes)\n\n        # both \'imagenet\'&\'imagenet+background\' are loaded from same parameters\n        model = NASNetALarge(num_classes=1001)\n        model.load_state_dict(model_zoo.load_url(settings[\'url\']))\n\n        if pretrained == \'imagenet\':\n            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n            model.last_linear = new_last_linear\n\n        model.input_space = settings[\'input_space\']\n        model.input_size = settings[\'input_size\']\n        model.input_range = settings[\'input_range\']\n\n        model.mean = settings[\'mean\']\n        model.std = settings[\'std\']\n    else:\n        model = NASNetALarge(num_classes=num_classes)\n    return model\n'"
fastai/courses/dl1/fastai/models/resnet.py,4,"b""import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n__all__ = ['vgg_resnet50']\n\nmodel_urls = {\n    'vgg_resnet50': 'https://download.pytorch.org/models/vggresnet.pth',\n}\n\n\ndef conv(ni, nf, ks=3, stride=1):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, stride=stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out = residual + out\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out = residual + out\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [conv(3, 64, ks=7, stride=2)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv(self.inplanes, planes*block.expansion, ks=1, stride=stride),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 (): return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50(): return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck, [3, 4, 6, 3], k=1.125)\ndef vgg_resnet34(): return ResNet(BasicBlock, [3, 4, 6, 3], vgg_head=True)\ndef vgg_resnet50(pretrained=False):\n    model = ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n    if pretrained: model.load_state_dict(torch.load('/home/jhoward/.torch/models/vgg_resnet50.pth'))\n    return model\n\n"""
fastai/courses/dl1/fastai/models/resnext_101_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/dl1/fastai/models/resnext_101_64x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_64x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/dl1/fastai/models/resnext_50_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_50_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AdaptiveAvgPool2d(1),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)\n'"
fastai/courses/dl1/fastai/models/unet.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\n\ndef get_sfs_idxs(sfs, last=True):\n    """"""\n    Return the saved feature indexes that will be concatenated\n    Inputs:\n        sfs (list): saved features by hook function, in other words intermediate activations\n        last (bool): whether to concatenate only last different activation, or all from the encoder model\n    """"""\n    if last:\n        feature_szs = [sfs_feats.features.size()[-1] for sfs_feats in sfs]\n        sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n        if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n    else: sfs_idxs = list(range(len(sfs)))\n    return sfs_idxs\n\n\ndef conv_bn_relu(in_c, out_c, kernel_size, stride, padding):\n    return [\n        nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=stride, padding=padding),\n        nn.ReLU(),\n        nn.BatchNorm2d(out_c)]\n\n\nclass UnetBlock(nn.Module):\n    #TODO: ADAPT KERNEL SIZE, STRIDE AND PADDING SO THAT ANY SIZE DECAY WILL BE SUPPORTED\n    def __init__(self, up_in_c, x_in_c):\n        super().__init__()\n        self.upconv = nn.ConvTranspose2d(up_in_c, up_in_c // 2, 2, 2) # H, W -> 2H, 2W\n        self.conv1 = nn.Conv2d(x_in_c + up_in_c // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.conv2 = nn.Conv2d((x_in_c + up_in_c // 2) // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.bn = nn.BatchNorm2d((x_in_c + up_in_c // 2) // 2)\n\n    def forward(self, up_in, x_in):\n        up_out = self.upconv(up_in)\n        cat_x = torch.cat([up_out, x_in], dim=1)\n        x = F.relu(self.conv1(cat_x))\n        x = F.relu(self.conv2(x))\n        return self.bn(x)\n\nclass SaveFeatures():\n    """""" Extract pretrained activations""""""\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()\n\n\nclass DynamicUnet(nn.Module):\n    """"""\n    A dynamic implementation of Unet architecture, because calculating connections\n    and channels suck!. When an encoder is passed, this network will\n    automatically construct a decoder after the first single forward pass for any\n    given encoder architecture.\n\n    Decoder part is heavily based on the original Unet paper:\n    https://arxiv.org/abs/1505.04597.\n\n    Inputs:\n        encoder(nn.Module): Preferably a pretrained model, such as VGG or ResNet\n        last (bool): Whether to concat only last activation just before a size change\n        n_classes (int): Number of classes to output in final step of decoder\n\n    Important Note: If architecture directly reduces the dimension of an image as soon as the\n    first forward pass then output size will not be same as the input size, e.g. ResNet.\n    In order to resolve this problem architecture will add an additional extra conv transpose\n    layer. Also, currently Dynamic Unet expects size change to be H,W -> H/2, W/2. This is\n    not a problem for state-of-the-art architectures as they follow this pattern but it should\n    be changed for custom encoders that might have a different size decay.\n    """"""\n\n    def __init__(self, encoder, last=True, n_classes=3):\n        super().__init__()\n        self.encoder = encoder\n        self.n_children = len(list(encoder.children()))\n        self.sfs = [SaveFeatures(encoder[i]) for i in range(self.n_children)]\n        self.last = last\n        self.n_classes = n_classes\n\n    def forward(self, x):\n        # get imsize\n        imsize = x.size()[-2:]\n\n        # encoder output\n        x = F.relu(self.encoder(x))\n\n        # initialize sfs_idxs, sfs_szs, middle_in_c and middle_conv only once\n        if not hasattr(self, \'middle_conv\'):\n            self.sfs_szs = [sfs_feats.features.size() for sfs_feats in self.sfs]\n            self.sfs_idxs = get_sfs_idxs(self.sfs, self.last)\n            middle_in_c = self.sfs_szs[-1][1]\n            middle_conv = nn.Sequential(*conv_bn_relu(middle_in_c, middle_in_c * 2, 3, 1, 1),\n                                        *conv_bn_relu(middle_in_c * 2, middle_in_c, 3, 1, 1))\n            self.middle_conv = middle_conv\n\n        # middle conv\n        x = self.middle_conv(x)\n\n        # initialize upmodel, extra_block and 1x1 final conv\n        if not hasattr(self, \'upmodel\'):\n            x_copy = Variable(x.data, requires_grad=False)\n            upmodel = []\n            for idx in self.sfs_idxs[::-1]:\n                up_in_c, x_in_c = int(x_copy.size()[1]), int(self.sfs_szs[idx][1])\n                unet_block = UnetBlock(up_in_c, x_in_c)\n                upmodel.append(unet_block)\n                x_copy = unet_block(x_copy, self.sfs[idx].features)\n                self.upmodel = nn.Sequential(*upmodel)\n\n            if imsize != self.sfs_szs[0][-2:]:\n                extra_in_c = self.upmodel[-1].conv2.out_channels\n                self.extra_block = nn.ConvTranspose2d(extra_in_c, extra_in_c, 2, 2)\n\n            final_in_c = self.upmodel[-1].conv2.out_channels\n            self.final_conv = nn.Conv2d(final_in_c, self.n_classes, 1)\n\n        # run upsample\n        for block, idx in zip(self.upmodel, self.sfs_idxs[::-1]):\n            x = block(x, self.sfs[idx].features)\n        if hasattr(self, \'extra_block\'):\n            x = self.extra_block(x)\n\n        out = self.final_conv(x)\n        return out\n'"
fastai/courses/dl1/fastai/models/wideresnet.py,3,"b'# https://github.com/uoguelph-mlrg/Cutout\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super().__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut: x   = self.relu1(self.bn1(x))\n        else:                   out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super().__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x): return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super().__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert((depth - 4) % 6 == 0)\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear): m.bias.data.zero_()\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.adaptive_avg_pool2d(out, 1)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n'"
fastai/courses/dl1/fastai/models/wrn_50_2f.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef wrn_50_2f(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/dl2/cgan/data/__init__.py,0,b''
fastai/courses/dl2/cgan/data/aligned_dataset.py,1,"b""import os.path\nimport random\nimport torchvision.transforms as transforms\nimport torch\nfrom .base_dataset import BaseDataset\nfrom .image_folder import make_dataset\nfrom PIL import Image\n\n\nclass AlignedDataset(BaseDataset):\n    def initialize(self, opt):\n        self.opt = opt\n        self.root = opt.dataroot\n        self.dir_AB = os.path.join(opt.dataroot, opt.phase)\n        self.AB_paths = sorted(make_dataset(self.dir_AB))\n        assert(opt.resize_or_crop == 'resize_and_crop')\n\n    def __getitem__(self, index):\n        AB_path = self.AB_paths[index]\n        AB = Image.open(AB_path).convert('RGB')\n        w, h = AB.size\n        w2 = int(w / 2)\n        A = AB.crop((0, 0, w2, h)).resize((self.opt.loadSize, self.opt.loadSize), Image.BICUBIC)\n        B = AB.crop((w2, 0, w, h)).resize((self.opt.loadSize, self.opt.loadSize), Image.BICUBIC)\n        A = transforms.ToTensor()(A)\n        B = transforms.ToTensor()(B)\n        w_offset = random.randint(0, max(0, self.opt.loadSize - self.opt.fineSize - 1))\n        h_offset = random.randint(0, max(0, self.opt.loadSize - self.opt.fineSize - 1))\n\n        A = A[:, h_offset:h_offset + self.opt.fineSize, w_offset:w_offset + self.opt.fineSize]\n        B = B[:, h_offset:h_offset + self.opt.fineSize, w_offset:w_offset + self.opt.fineSize]\n\n        A = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(A)\n        B = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(B)\n\n        if self.opt.which_direction == 'BtoA':\n            input_nc = self.opt.output_nc\n            output_nc = self.opt.input_nc\n        else:\n            input_nc = self.opt.input_nc\n            output_nc = self.opt.output_nc\n\n        if (not self.opt.no_flip) and random.random() < 0.5:\n            idx = [i for i in range(A.size(2) - 1, -1, -1)]\n            idx = torch.LongTensor(idx)\n            A = A.index_select(2, idx)\n            B = B.index_select(2, idx)\n\n        if input_nc == 1:  # RGB to gray\n            tmp = A[0, ...] * 0.299 + A[1, ...] * 0.587 + A[2, ...] * 0.114\n            A = tmp.unsqueeze(0)\n\n        if output_nc == 1:  # RGB to gray\n            tmp = B[0, ...] * 0.299 + B[1, ...] * 0.587 + B[2, ...] * 0.114\n            B = tmp.unsqueeze(0)\n\n        return {'A': A, 'B': B,\n                'A_paths': AB_path, 'B_paths': AB_path}\n\n    def __len__(self):\n        return len(self.AB_paths)\n\n    def name(self):\n        return 'AlignedDataset'\n"""
fastai/courses/dl2/cgan/data/base_data_loader.py,0,"b'class BaseDataLoader():\n    def __init__(self): pass\n    def load_data(): return None\n    def initialize(self, opt): self.opt = opt\n\n'"
fastai/courses/dl2/cgan/data/base_dataset.py,1,"b""import torch.utils.data as data\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n\nclass BaseDataset(data.Dataset):\n    def __init__(self):\n        super(BaseDataset, self).__init__()\n\n    def name(self):\n        return 'BaseDataset'\n\n    def initialize(self, opt):\n        pass\n\n\ndef get_transform(opt):\n    transform_list = []\n    if opt.resize_or_crop == 'resize_and_crop':\n        osize = [opt.loadSize, opt.loadSize]\n        transform_list.append(transforms.Scale(osize, Image.BICUBIC))\n        transform_list.append(transforms.RandomCrop(opt.fineSize))\n    elif opt.resize_or_crop == 'crop':\n        transform_list.append(transforms.RandomCrop(opt.fineSize))\n    elif opt.resize_or_crop == 'scale_width':\n        transform_list.append(transforms.Lambda(\n            lambda img: __scale_width(img, opt.fineSize)))\n    elif opt.resize_or_crop == 'scale_width_and_crop':\n        transform_list.append(transforms.Lambda(\n            lambda img: __scale_width(img, opt.loadSize)))\n        transform_list.append(transforms.RandomCrop(opt.fineSize))\n\n    if opt.isTrain and not opt.no_flip:\n        transform_list.append(transforms.RandomHorizontalFlip())\n\n    transform_list += [transforms.ToTensor(),\n                       transforms.Normalize((0.5, 0.5, 0.5),\n                                            (0.5, 0.5, 0.5))]\n    return transforms.Compose(transform_list)\n\n\ndef __scale_width(img, target_width):\n    ow, oh = img.size\n    if (ow == target_width):\n        return img\n    w = target_width\n    h = int(target_width * oh / ow)\n    return img.resize((w, h), Image.BICUBIC)\n"""
fastai/courses/dl2/cgan/data/custom_dataset_data_loader.py,2,"b'import torch.utils.data\nfrom .base_data_loader import BaseDataLoader\n\n\ndef CreateDataset(opt):\n    dataset = None\n    if opt.dataset_mode == \'aligned\':\n        from .aligned_dataset import AlignedDataset\n        dataset = AlignedDataset()\n    elif opt.dataset_mode == \'unaligned\':\n        from .unaligned_dataset import UnalignedDataset\n        dataset = UnalignedDataset()\n    elif opt.dataset_mode == \'single\':\n        from .single_dataset import SingleDataset\n        dataset = SingleDataset()\n    else:\n        raise ValueError(""Dataset [%s] not recognized."" % opt.dataset_mode)\n\n    print(""dataset [%s] was created"" % (dataset.name()))\n    dataset.initialize(opt)\n    return dataset\n\n\nclass CustomDatasetDataLoader(BaseDataLoader):\n    def initialize(self, opt):\n        BaseDataLoader.initialize(self, opt)\n        self.dataset = CreateDataset(opt)\n        self.dataloader = torch.utils.data.DataLoader(\n            self.dataset, batch_size=opt.batchSize,\n            shuffle=not opt.serial_batches, num_workers=int(opt.nThreads))\n\n    def __iter__(self):\n        for i, data in enumerate(self.dataloader):\n            if i >= self.opt.max_dataset_size: break\n            yield data\n\n    def name(self): return \'CustomDatasetDataLoader\'\n    def load_data(self): return self\n    def __len__(self): return min(len(self.dataset), self.opt.max_dataset_size)\n\n'"
fastai/courses/dl2/cgan/data/data_loader.py,0,b'from ..data.custom_dataset_data_loader import CustomDatasetDataLoader\n\ndef CreateDataLoader(opt):\n    data_loader = CustomDatasetDataLoader()\n    print(data_loader.name())\n    data_loader.initialize(opt)\n    return data_loader\n'
fastai/courses/dl2/cgan/data/image_folder.py,1,"b'###############################################################################\n# Code from\n# https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py\n# Modified the original code so that it also loads images from the current\n# directory as well as the subdirectories\n###############################################################################\n\nimport torch.utils.data as data\n\nfrom PIL import Image\nimport os\nimport os.path\n\nIMG_EXTENSIONS = [\n    \'.jpg\', \'.JPG\', \'.jpeg\', \'.JPEG\',\n    \'.png\', \'.PNG\', \'.ppm\', \'.PPM\', \'.bmp\', \'.BMP\',\n]\n\n\ndef is_image_file(filename):\n    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n\n\ndef make_dataset(dir):\n    images = []\n    assert os.path.isdir(dir), \'%s is not a valid directory\' % dir\n\n    for root, _, fnames in sorted(os.walk(dir)):\n        for fname in fnames:\n            if is_image_file(fname):\n                path = os.path.join(root, fname)\n                images.append(path)\n\n    return images\n\n\ndef default_loader(path):\n    return Image.open(path).convert(\'RGB\')\n\n\nclass ImageFolder(data.Dataset):\n\n    def __init__(self, root, transform=None, return_paths=False,\n                 loader=default_loader):\n        imgs = make_dataset(root)\n        if len(imgs) == 0:\n            raise(RuntimeError(""Found 0 images in: "" + root + ""\\n""\n                               ""Supported image extensions are: "" +\n                               "","".join(IMG_EXTENSIONS)))\n\n        self.root = root\n        self.imgs = imgs\n        self.transform = transform\n        self.return_paths = return_paths\n        self.loader = loader\n\n    def __getitem__(self, index):\n        path = self.imgs[index]\n        img = self.loader(path)\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.return_paths:\n            return img, path\n        else:\n            return img\n\n    def __len__(self):\n        return len(self.imgs)\n'"
fastai/courses/dl2/cgan/data/single_dataset.py,0,"b""import os.path\nfrom .base_dataset import BaseDataset, get_transform\nfrom .image_folder import make_dataset\nfrom PIL import Image\n\n\nclass SingleDataset(BaseDataset):\n    def initialize(self, opt):\n        self.opt = opt\n        self.root = opt.dataroot\n        self.dir_A = os.path.join(opt.dataroot)\n\n        self.A_paths = make_dataset(self.dir_A)\n\n        self.A_paths = sorted(self.A_paths)\n\n        self.transform = get_transform(opt)\n\n    def __getitem__(self, index):\n        A_path = self.A_paths[index]\n        A_img = Image.open(A_path).convert('RGB')\n        A = self.transform(A_img)\n        if self.opt.which_direction == 'BtoA':\n            input_nc = self.opt.output_nc\n        else:\n            input_nc = self.opt.input_nc\n\n        if input_nc == 1:  # RGB to gray\n            tmp = A[0, ...] * 0.299 + A[1, ...] * 0.587 + A[2, ...] * 0.114\n            A = tmp.unsqueeze(0)\n\n        return {'A': A, 'A_paths': A_path}\n\n    def __len__(self):\n        return len(self.A_paths)\n\n    def name(self):\n        return 'SingleImageDataset'\n"""
fastai/courses/dl2/cgan/data/unaligned_dataset.py,0,"b""import os.path\nfrom .base_dataset import BaseDataset, get_transform\nfrom .image_folder import make_dataset\nfrom PIL import Image\nimport random\n\n\nclass UnalignedDataset(BaseDataset):\n    def initialize(self, opt):\n        self.opt = opt\n        self.root = opt.dataroot\n        self.dir_A = os.path.join(opt.dataroot, opt.phase + 'A')\n        self.dir_B = os.path.join(opt.dataroot, opt.phase + 'B')\n\n        self.A_paths = make_dataset(self.dir_A)\n        self.B_paths = make_dataset(self.dir_B)\n\n        self.A_paths = sorted(self.A_paths)\n        self.B_paths = sorted(self.B_paths)\n        self.A_size = len(self.A_paths)\n        self.B_size = len(self.B_paths)\n        self.transform = get_transform(opt)\n\n    def __getitem__(self, index):\n        A_path = self.A_paths[index % self.A_size]\n        if self.opt.serial_batches:\n            index_B = index % self.B_size\n        else:\n            index_B = random.randint(0, self.B_size - 1)\n        B_path = self.B_paths[index_B]\n        # print('(A, B) = (%d, %d)' % (index_A, index_B))\n        A_img = Image.open(A_path).convert('RGB')\n        B_img = Image.open(B_path).convert('RGB')\n\n        A = self.transform(A_img)\n        B = self.transform(B_img)\n        if self.opt.which_direction == 'BtoA':\n            input_nc = self.opt.output_nc\n            output_nc = self.opt.input_nc\n        else:\n            input_nc = self.opt.input_nc\n            output_nc = self.opt.output_nc\n\n        if input_nc == 1:  # RGB to gray\n            tmp = A[0, ...] * 0.299 + A[1, ...] * 0.587 + A[2, ...] * 0.114\n            A = tmp.unsqueeze(0)\n\n        if output_nc == 1:  # RGB to gray\n            tmp = B[0, ...] * 0.299 + B[1, ...] * 0.587 + B[2, ...] * 0.114\n            B = tmp.unsqueeze(0)\n\n        return {'A': A, 'B': B, 'A_paths': A_path, 'B_paths': B_path}\n\n    def __len__(self): return max(self.A_size, self.B_size)\n\n    def name(self): return 'UnalignedDataset'\n"""
fastai/courses/dl2/cgan/models/__init__.py,0,b''
fastai/courses/dl2/cgan/models/base_model.py,4,"b""import os\nimport torch\n\n\nclass BaseModel():\n    def name(self): return 'BaseModel'\n\n    def initialize(self, opt):\n        self.opt = opt\n        self.gpu_ids = opt.gpu_ids\n        self.isTrain = opt.isTrain\n        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n\n    def set_input(self, input): self.input = input\n    def forward(self): pass\n    def test(self): pass\n    def get_image_paths(self): pass\n    def optimize_parameters(self): pass\n    def get_current_visuals(self): return self.input\n    def get_current_errors(self): return {}\n    def save(self, label): pass\n\n    # helper saving function that can be used by subclasses\n    def save_network(self, network, network_label, epoch_label, gpu_ids):\n        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n        save_path = os.path.join(self.save_dir, save_filename)\n        torch.save(network.cpu().state_dict(), save_path)\n        if len(gpu_ids) and torch.cuda.is_available(): network.cuda(gpu_ids[0])\n\n    # helper loading function that can be used by subclasses\n    def load_network(self, network, network_label, epoch_label):\n        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n        save_path = os.path.join(self.save_dir, save_filename)\n        network.load_state_dict(torch.load(save_path))\n\n    # update learning rate (called once every epoch)\n    def update_learning_rate(self):\n        for scheduler in self.schedulers: scheduler.step()\n        lr = self.optimizers[0].param_groups[0]['lr']\n        print('learning rate = %.7f' % lr)\n\n"""
fastai/courses/dl2/cgan/models/cycle_gan_model.py,6,"b""import torch\nfrom collections import OrderedDict\nfrom torch.autograd import Variable\nimport itertools\nfrom ..util import util\nfrom ..util.image_pool import ImagePool\nfrom .base_model import BaseModel\nfrom . import networks\n\n\nclass CycleGANModel(BaseModel):\n    def name(self):\n        return 'CycleGANModel'\n\n    def initialize(self, opt):\n        BaseModel.initialize(self, opt)\n        # load/define networks\n        # The naming conversion is different from those used in the paper\n        # Code (paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)\n\n        self.netG_A = networks.define_G(opt.input_nc, opt.output_nc,\n                                        opt.ngf, opt.which_model_netG, opt.norm, not opt.no_dropout, opt.init_type, self.gpu_ids)\n        self.netG_B = networks.define_G(opt.output_nc, opt.input_nc,\n                                        opt.ngf, opt.which_model_netG, opt.norm, not opt.no_dropout, opt.init_type, self.gpu_ids)\n\n        if self.isTrain:\n            use_sigmoid = opt.no_lsgan\n            self.netD_A = networks.define_D(opt.output_nc, opt.ndf,\n                                            opt.which_model_netD,\n                                            opt.n_layers_D, opt.norm, use_sigmoid, opt.init_type, self.gpu_ids)\n            self.netD_B = networks.define_D(opt.input_nc, opt.ndf,\n                                            opt.which_model_netD,\n                                            opt.n_layers_D, opt.norm, use_sigmoid, opt.init_type, self.gpu_ids)\n        if not self.isTrain or opt.continue_train:\n            which_epoch = opt.which_epoch\n            self.load_network(self.netG_A, 'G_A', which_epoch)\n            self.load_network(self.netG_B, 'G_B', which_epoch)\n            if self.isTrain:\n                self.load_network(self.netD_A, 'D_A', which_epoch)\n                self.load_network(self.netD_B, 'D_B', which_epoch)\n\n        if self.isTrain:\n            self.fake_A_pool = ImagePool(opt.pool_size)\n            self.fake_B_pool = ImagePool(opt.pool_size)\n            # define loss functions\n            self.criterionGAN = networks.GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n            self.criterionCycle = torch.nn.L1Loss()\n            self.criterionIdt = torch.nn.L1Loss()\n            # initialize optimizers\n            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()),\n                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizers = []\n            self.schedulers = []\n            self.optimizers.append(self.optimizer_G)\n            self.optimizers.append(self.optimizer_D_A)\n            self.optimizers.append(self.optimizer_D_B)\n            for optimizer in self.optimizers:\n                self.schedulers.append(networks.get_scheduler(optimizer, opt))\n\n        print('---------- Networks initialized -------------')\n        networks.print_network(self.netG_A)\n        networks.print_network(self.netG_B)\n        if self.isTrain:\n            networks.print_network(self.netD_A)\n            networks.print_network(self.netD_B)\n        print('-----------------------------------------------')\n\n    def set_input(self, input):\n        AtoB = self.opt.which_direction == 'AtoB'\n        input_A = input['A' if AtoB else 'B']\n        input_B = input['B' if AtoB else 'A']\n        if len(self.gpu_ids) > 0:\n            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n            input_B = input_B.cuda(self.gpu_ids[0], async=True)\n        self.input_A = input_A\n        self.input_B = input_B\n        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n\n    def forward(self):\n        self.real_A = Variable(self.input_A)\n        self.real_B = Variable(self.input_B)\n\n    def test(self):\n        real_A = Variable(self.input_A, volatile=True)\n        fake_B = self.netG_A(real_A)\n        self.rec_A = self.netG_B(fake_B).data\n        self.fake_B = fake_B.data\n\n        real_B = Variable(self.input_B, volatile=True)\n        fake_A = self.netG_B(real_B)\n        self.rec_B = self.netG_A(fake_A).data\n        self.fake_A = fake_A.data\n\n    # get image paths\n    def get_image_paths(self):\n        return self.image_paths\n\n    def backward_D_basic(self, netD, real, fake):\n        # Real\n        pred_real = netD(real)\n        loss_D_real = self.criterionGAN(pred_real, True)\n        # Fake\n        pred_fake = netD(fake.detach())\n        loss_D_fake = self.criterionGAN(pred_fake, False)\n        # Combined loss\n        loss_D = (loss_D_real + loss_D_fake) * 0.5\n        # backward\n        loss_D.backward()\n        return loss_D\n\n    def backward_D_A(self):\n        fake_B = self.fake_B_pool.query(self.fake_B)\n        loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n        self.loss_D_A = loss_D_A.data[0]\n\n    def backward_D_B(self):\n        fake_A = self.fake_A_pool.query(self.fake_A)\n        loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n        self.loss_D_B = loss_D_B.data[0]\n\n    def backward_G(self):\n        lambda_idt = self.opt.lambda_identity\n        lambda_A = self.opt.lambda_A\n        lambda_B = self.opt.lambda_B\n        # Identity loss\n        if lambda_idt > 0:\n            # G_A should be identity if real_B is fed.\n            idt_A = self.netG_A(self.real_B)\n            loss_idt_A = self.criterionIdt(idt_A, self.real_B) * lambda_B * lambda_idt\n            # G_B should be identity if real_A is fed.\n            idt_B = self.netG_B(self.real_A)\n            loss_idt_B = self.criterionIdt(idt_B, self.real_A) * lambda_A * lambda_idt\n\n            self.idt_A = idt_A.data\n            self.idt_B = idt_B.data\n            self.loss_idt_A = loss_idt_A.data[0]\n            self.loss_idt_B = loss_idt_B.data[0]\n        else:\n            loss_idt_A = 0\n            loss_idt_B = 0\n            self.loss_idt_A = 0\n            self.loss_idt_B = 0\n\n        # GAN loss D_A(G_A(A))\n        fake_B = self.netG_A(self.real_A)\n        pred_fake = self.netD_A(fake_B)\n        loss_G_A = self.criterionGAN(pred_fake, True)\n\n        # GAN loss D_B(G_B(B))\n        fake_A = self.netG_B(self.real_B)\n        pred_fake = self.netD_B(fake_A)\n        loss_G_B = self.criterionGAN(pred_fake, True)\n\n        # Forward cycle loss\n        rec_A = self.netG_B(fake_B)\n        loss_cycle_A = self.criterionCycle(rec_A, self.real_A) * lambda_A\n\n        # Backward cycle loss\n        rec_B = self.netG_A(fake_A)\n        loss_cycle_B = self.criterionCycle(rec_B, self.real_B) * lambda_B\n        # combined loss\n        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_idt_A + loss_idt_B\n        loss_G.backward()\n\n        self.fake_B = fake_B.data\n        self.fake_A = fake_A.data\n        self.rec_A = rec_A.data\n        self.rec_B = rec_B.data\n\n        self.loss_G_A = loss_G_A.data[0]\n        self.loss_G_B = loss_G_B.data[0]\n        self.loss_cycle_A = loss_cycle_A.data[0]\n        self.loss_cycle_B = loss_cycle_B.data[0]\n\n    def optimize_parameters(self):\n        # forward\n        self.forward()\n        # G_A and G_B\n        self.optimizer_G.zero_grad()\n        self.backward_G()\n        self.optimizer_G.step()\n        # D_A\n        self.optimizer_D_A.zero_grad()\n        self.backward_D_A()\n        self.optimizer_D_A.step()\n        # D_B\n        self.optimizer_D_B.zero_grad()\n        self.backward_D_B()\n        self.optimizer_D_B.step()\n\n    def get_current_errors(self):\n        ret_errors = OrderedDict([('D_A', self.loss_D_A), ('G_A', self.loss_G_A), ('Cyc_A', self.loss_cycle_A),\n                                  ('D_B', self.loss_D_B), ('G_B', self.loss_G_B), ('Cyc_B', self.loss_cycle_B)])\n        if self.opt.lambda_identity > 0.0:\n            ret_errors['idt_A'] = self.loss_idt_A\n            ret_errors['idt_B'] = self.loss_idt_B\n        return ret_errors\n\n    def get_current_visuals(self):\n        real_A = util.tensor2im(self.input_A)\n        fake_B = util.tensor2im(self.fake_B)\n        rec_A = util.tensor2im(self.rec_A)\n        real_B = util.tensor2im(self.input_B)\n        fake_A = util.tensor2im(self.fake_A)\n        rec_B = util.tensor2im(self.rec_B)\n        ret_visuals = OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('rec_A', rec_A),\n                                   ('real_B', real_B), ('fake_A', fake_A), ('rec_B', rec_B)])\n        if self.opt.isTrain and self.opt.lambda_identity > 0.0:\n            ret_visuals['idt_A'] = util.tensor2im(self.idt_A)\n            ret_visuals['idt_B'] = util.tensor2im(self.idt_B)\n        return ret_visuals\n\n    def save(self, label):\n        self.save_network(self.netG_A, 'G_A', label, self.gpu_ids)\n        self.save_network(self.netD_A, 'D_A', label, self.gpu_ids)\n        self.save_network(self.netG_B, 'G_B', label, self.gpu_ids)\n        self.save_network(self.netD_B, 'D_B', label, self.gpu_ids)\n\n    def load(self, label):\n        self.load_network(self.netG_A, 'G_A', label)\n        self.load_network(self.netD_A, 'D_A', label)\n        self.load_network(self.netG_B, 'G_B', label)\n        self.load_network(self.netD_B, 'D_B', label)"""
fastai/courses/dl2/cgan/models/models.py,0,"b'def create_model(opt):\n    model = None\n    print(opt.model)\n    if opt.model == \'cycle_gan\':\n        assert(opt.dataset_mode == \'unaligned\')\n        from .cycle_gan_model import CycleGANModel\n        model = CycleGANModel()\n    elif opt.model == \'pix2pix\':\n        assert(opt.dataset_mode == \'aligned\')\n        from .pix2pix_model import Pix2PixModel\n        model = Pix2PixModel()\n    elif opt.model == \'test\':\n        assert(opt.dataset_mode == \'single\')\n        from .test_model import TestModel\n        model = TestModel()\n    else:\n        raise ValueError(""Model [%s] not recognized."" % opt.model)\n    model.initialize(opt)\n    print(""model [%s] was created"" % (model.name()))\n    return model\n'"
fastai/courses/dl2/cgan/models/networks.py,12,"b""import torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport functools\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\n###############################################################################\n# Functions\n###############################################################################\n\n\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('Linear') != -1:\n        init.normal(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef weights_init_xavier(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.xavier_normal(m.weight.data, gain=0.02)\n    elif classname.find('Linear') != -1:\n        init.xavier_normal(m.weight.data, gain=0.02)\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    # print(classname)\n    if classname.find('Conv') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('Linear') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef weights_init_orthogonal(m):\n    classname = m.__class__.__name__\n    print(classname)\n    if classname.find('Conv') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.orthogonal(m.weight.data, gain=1)\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef init_weights(net, init_type='normal'):\n    print('initialization method [%s]' % init_type)\n    if init_type == 'normal':\n        net.apply(weights_init_normal)\n    elif init_type == 'xavier':\n        net.apply(weights_init_xavier)\n    elif init_type == 'kaiming':\n        net.apply(weights_init_kaiming)\n    elif init_type == 'orthogonal':\n        net.apply(weights_init_orthogonal)\n    else:\n        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n\n\ndef get_norm_layer(norm_type='instance'):\n    if norm_type == 'batch':\n        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n    elif norm_type == 'instance':\n        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n    elif norm_type == 'none':\n        norm_layer = None\n    else:\n        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n    return norm_layer\n\n\ndef get_scheduler(optimizer, opt):\n    if opt.lr_policy == 'lambda':\n        def lambda_rule(epoch):\n            lr_l = 1.0 - max(0, epoch + 1 + opt.epoch_count - opt.niter) / float(opt.niter_decay + 1)\n            return lr_l\n        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n    elif opt.lr_policy == 'step':\n        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n    elif opt.lr_policy == 'plateau':\n        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n    else:\n        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n    return scheduler\n\n\ndef define_G(input_nc, output_nc, ngf, which_model_netG, norm='batch', use_dropout=False, init_type='normal', gpu_ids=[]):\n    netG = None\n    use_gpu = len(gpu_ids) > 0\n    norm_layer = get_norm_layer(norm_type=norm)\n\n    if use_gpu:\n        assert(torch.cuda.is_available())\n\n    if which_model_netG == 'resnet_9blocks':\n        netG = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9, gpu_ids=gpu_ids)\n    elif which_model_netG == 'resnet_6blocks':\n        netG = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=6, gpu_ids=gpu_ids)\n    elif which_model_netG == 'unet_128':\n        netG = UnetGenerator(input_nc, output_nc, 7, ngf, norm_layer=norm_layer, use_dropout=use_dropout, gpu_ids=gpu_ids)\n    elif which_model_netG == 'unet_256':\n        netG = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout, gpu_ids=gpu_ids)\n    else:\n        raise NotImplementedError('Generator model name [%s] is not recognized' % which_model_netG)\n    if len(gpu_ids) > 0:\n        netG.cuda(gpu_ids[0])\n    init_weights(netG, init_type=init_type)\n    return netG\n\n\ndef define_D(input_nc, ndf, which_model_netD,\n             n_layers_D=3, norm='batch', use_sigmoid=False, init_type='normal', gpu_ids=[]):\n    netD = None\n    use_gpu = len(gpu_ids) > 0\n    norm_layer = get_norm_layer(norm_type=norm)\n\n    if use_gpu:\n        assert(torch.cuda.is_available())\n    if which_model_netD == 'basic':\n        netD = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer, use_sigmoid=use_sigmoid, gpu_ids=gpu_ids)\n    elif which_model_netD == 'n_layers':\n        netD = NLayerDiscriminator(input_nc, ndf, n_layers_D, norm_layer=norm_layer, use_sigmoid=use_sigmoid, gpu_ids=gpu_ids)\n    elif which_model_netD == 'pixel':\n        netD = PixelDiscriminator(input_nc, ndf, norm_layer=norm_layer, use_sigmoid=use_sigmoid, gpu_ids=gpu_ids)\n    else:\n        raise NotImplementedError('Discriminator model name [%s] is not recognized' %\n                                  which_model_netD)\n    if use_gpu:\n        netD.cuda(gpu_ids[0])\n    init_weights(netD, init_type=init_type)\n    return netD\n\n\ndef print_network(net):\n    num_params = 0\n    for param in net.parameters():\n        num_params += param.numel()\n    print(net)\n    print('Total number of parameters: %d' % num_params)\n\n\n##############################################################################\n# Classes\n##############################################################################\n\n\n# Defines the GAN loss which uses either LSGAN or the regular GAN.\n# When LSGAN is used, it is basically same as MSELoss,\n# but it abstracts away the need to create the target label tensor\n# that has the same size as the input\nclass GANLoss(nn.Module):\n    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,\n                 tensor=torch.FloatTensor):\n        super(GANLoss, self).__init__()\n        self.real_label = target_real_label\n        self.fake_label = target_fake_label\n        self.real_label_var = None\n        self.fake_label_var = None\n        self.Tensor = tensor\n        if use_lsgan:\n            self.loss = nn.MSELoss()\n        else:\n            self.loss = nn.BCELoss()\n\n    def get_target_tensor(self, input, target_is_real):\n        target_tensor = None\n        if target_is_real:\n            create_label = ((self.real_label_var is None) or\n                            (self.real_label_var.numel() != input.numel()))\n            if create_label:\n                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n                self.real_label_var = Variable(real_tensor, requires_grad=False)\n            target_tensor = self.real_label_var\n        else:\n            create_label = ((self.fake_label_var is None) or\n                            (self.fake_label_var.numel() != input.numel()))\n            if create_label:\n                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n            target_tensor = self.fake_label_var\n        return target_tensor\n\n    def __call__(self, input, target_is_real):\n        target_tensor = self.get_target_tensor(input, target_is_real)\n        return self.loss(input, target_tensor)\n\n\n# Defines the generator that consists of Resnet blocks between a few\n# downsampling/upsampling operations.\n# Code and idea originally from Justin Johnson's architecture.\n# https://github.com/jcjohnson/fast-neural-style/\nclass ResnetGenerator(nn.Module):\n    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, gpu_ids=[], padding_type='reflect'):\n        assert(n_blocks >= 0)\n        super(ResnetGenerator, self).__init__()\n        self.input_nc = input_nc\n        self.output_nc = output_nc\n        self.ngf = ngf\n        self.gpu_ids = gpu_ids\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n\n        model = [nn.ReflectionPad2d(3),\n                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0,\n                           bias=use_bias),\n                 norm_layer(ngf),\n                 nn.ReLU(True)]\n\n        n_downsampling = 2\n        for i in range(n_downsampling):\n            mult = 2**i\n            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n                                stride=2, padding=1, bias=use_bias),\n                      norm_layer(ngf * mult * 2),\n                      nn.ReLU(True)]\n\n        mult = 2**n_downsampling\n        for i in range(n_blocks):\n            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n\n        for i in range(n_downsampling):\n            mult = 2**(n_downsampling - i)\n            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n                                         kernel_size=3, stride=2,\n                                         padding=1, output_padding=1,\n                                         bias=use_bias),\n                      norm_layer(int(ngf * mult / 2)),\n                      nn.ReLU(True)]\n        model += [nn.ReflectionPad2d(3)]\n        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n        model += [nn.Tanh()]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, input):\n        if self.gpu_ids and isinstance(input.data, torch.cuda.FloatTensor):\n            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n        else:\n            return self.model(input)\n\n\n# Define a resnet block\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n        super(ResnetBlock, self).__init__()\n        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n\n    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n        conv_block = []\n        p = 0\n        if padding_type == 'reflect':\n            conv_block += [nn.ReflectionPad2d(1)]\n        elif padding_type == 'replicate':\n            conv_block += [nn.ReplicationPad2d(1)]\n        elif padding_type == 'zero':\n            p = 1\n        else:\n            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n\n        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n                       norm_layer(dim),\n                       nn.ReLU(True)]\n        if use_dropout:\n            conv_block += [nn.Dropout(0.5)]\n\n        p = 0\n        if padding_type == 'reflect':\n            conv_block += [nn.ReflectionPad2d(1)]\n        elif padding_type == 'replicate':\n            conv_block += [nn.ReplicationPad2d(1)]\n        elif padding_type == 'zero':\n            p = 1\n        else:\n            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n                       norm_layer(dim)]\n\n        return nn.Sequential(*conv_block)\n\n    def forward(self, x):\n        out = x + self.conv_block(x)\n        return out\n\n\n# Defines the Unet generator.\n# |num_downs|: number of downsamplings in UNet. For example,\n# if |num_downs| == 7, image of size 128x128 will become of size 1x1\n# at the bottleneck\nclass UnetGenerator(nn.Module):\n    def __init__(self, input_nc, output_nc, num_downs, ngf=64,\n                 norm_layer=nn.BatchNorm2d, use_dropout=False, gpu_ids=[]):\n        super(UnetGenerator, self).__init__()\n        self.gpu_ids = gpu_ids\n\n        # construct unet structure\n        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n        for i in range(num_downs - 5):\n            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n        unet_block = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n\n        self.model = unet_block\n\n    def forward(self, input):\n        if self.gpu_ids and isinstance(input.data, torch.cuda.FloatTensor):\n            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n        else:\n            return self.model(input)\n\n\n# Defines the submodule with skip connection.\n# X -------------------identity---------------------- X\n#   |-- downsampling -- |submodule| -- upsampling --|\nclass UnetSkipConnectionBlock(nn.Module):\n    def __init__(self, outer_nc, inner_nc, input_nc=None,\n                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n        super(UnetSkipConnectionBlock, self).__init__()\n        self.outermost = outermost\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n        if input_nc is None:\n            input_nc = outer_nc\n        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n                             stride=2, padding=1, bias=use_bias)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = norm_layer(inner_nc)\n        uprelu = nn.ReLU(True)\n        upnorm = norm_layer(outer_nc)\n\n        if outermost:\n            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n                                        kernel_size=4, stride=2,\n                                        padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n                                        kernel_size=4, stride=2,\n                                        padding=1, bias=use_bias)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n                                        kernel_size=4, stride=2,\n                                        padding=1, bias=use_bias)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n\n            if use_dropout:\n                model = down + [submodule] + up + [nn.Dropout(0.5)]\n            else:\n                model = down + [submodule] + up\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\n\n# Defines the PatchGAN discriminator with the specified arguments.\nclass NLayerDiscriminator(nn.Module):\n    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, gpu_ids=[]):\n        super(NLayerDiscriminator, self).__init__()\n        self.gpu_ids = gpu_ids\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n\n        kw = 4\n        padw = 1\n        sequence = [\n            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        nf_mult = 1\n        nf_mult_prev = 1\n        for n in range(1, n_layers):\n            nf_mult_prev = nf_mult\n            nf_mult = min(2**n, 8)\n            sequence += [\n                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n                norm_layer(ndf * nf_mult),\n                nn.LeakyReLU(0.2, True)\n            ]\n\n        nf_mult_prev = nf_mult\n        nf_mult = min(2**n_layers, 8)\n        sequence += [\n            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n            norm_layer(ndf * nf_mult),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n\n        if use_sigmoid:\n            sequence += [nn.Sigmoid()]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, input):\n        if len(self.gpu_ids) and isinstance(input.data, torch.cuda.FloatTensor):\n            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n        else:\n            return self.model(input)\n\n\nclass PixelDiscriminator(nn.Module):\n    def __init__(self, input_nc, ndf=64, norm_layer=nn.BatchNorm2d, use_sigmoid=False, gpu_ids=[]):\n        super(PixelDiscriminator, self).__init__()\n        self.gpu_ids = gpu_ids\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func == nn.InstanceNorm2d\n        else:\n            use_bias = norm_layer == nn.InstanceNorm2d\n\n        self.net = [\n            nn.Conv2d(input_nc, ndf, kernel_size=1, stride=1, padding=0),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(ndf, ndf * 2, kernel_size=1, stride=1, padding=0, bias=use_bias),\n            norm_layer(ndf * 2),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(ndf * 2, 1, kernel_size=1, stride=1, padding=0, bias=use_bias)]\n\n        if use_sigmoid:\n            self.net.append(nn.Sigmoid())\n\n        self.net = nn.Sequential(*self.net)\n\n    def forward(self, input):\n        if len(self.gpu_ids) and isinstance(input.data, torch.cuda.FloatTensor):\n            return nn.parallel.data_parallel(self.net, input, self.gpu_ids)\n        else:\n            return self.net(input)\n"""
fastai/courses/dl2/cgan/models/pix2pix_model.py,7,"b""import torch\nfrom collections import OrderedDict\nfrom torch.autograd import Variable\nfrom ..util import * \nfrom ..util.image_pool import ImagePool\nfrom .base_model import BaseModel\nfrom . import networks\n\nclass Pix2PixModel(BaseModel):\n    def name(self):\n        return 'Pix2PixModel'\n\n    def initialize(self, opt):\n        BaseModel.initialize(self, opt)\n        self.isTrain = opt.isTrain\n\n        # load/define networks\n        self.netG = networks.define_G(opt.input_nc, opt.output_nc, opt.ngf,\n                                      opt.which_model_netG, opt.norm, not opt.no_dropout, opt.init_type, self.gpu_ids)\n        if self.isTrain:\n            use_sigmoid = opt.no_lsgan\n            self.netD = networks.define_D(opt.input_nc + opt.output_nc, opt.ndf,\n                                          opt.which_model_netD,\n                                          opt.n_layers_D, opt.norm, use_sigmoid, opt.init_type, self.gpu_ids)\n        if not self.isTrain or opt.continue_train:\n            self.load_network(self.netG, 'G', opt.which_epoch)\n            if self.isTrain:\n                self.load_network(self.netD, 'D', opt.which_epoch)\n\n        if self.isTrain:\n            self.fake_AB_pool = ImagePool(opt.pool_size)\n            # define loss functions\n            self.criterionGAN = networks.GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n            self.criterionL1 = torch.nn.L1Loss()\n\n            # initialize optimizers\n            self.schedulers = []\n            self.optimizers = []\n            self.optimizer_G = torch.optim.Adam(self.netG.parameters(),\n                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizer_D = torch.optim.Adam(self.netD.parameters(),\n                                                lr=opt.lr, betas=(opt.beta1, 0.999))\n            self.optimizers.append(self.optimizer_G)\n            self.optimizers.append(self.optimizer_D)\n            for optimizer in self.optimizers:\n                self.schedulers.append(networks.get_scheduler(optimizer, opt))\n\n        print('---------- Networks initialized -------------')\n        networks.print_network(self.netG)\n        if self.isTrain:\n            networks.print_network(self.netD)\n        print('-----------------------------------------------')\n\n    def set_input(self, input):\n        AtoB = self.opt.which_direction == 'AtoB'\n        input_A = input['A' if AtoB else 'B']\n        input_B = input['B' if AtoB else 'A']\n        if len(self.gpu_ids) > 0:\n            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n            input_B = input_B.cuda(self.gpu_ids[0], async=True)\n        self.input_A = input_A\n        self.input_B = input_B\n        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n\n    def forward(self):\n        self.real_A = Variable(self.input_A)\n        self.fake_B = self.netG(self.real_A)\n        self.real_B = Variable(self.input_B)\n\n    # no backprop gradients\n    def test(self):\n        self.real_A = Variable(self.input_A, volatile=True)\n        self.fake_B = self.netG(self.real_A)\n        self.real_B = Variable(self.input_B, volatile=True)\n\n    # get image paths\n    def get_image_paths(self):\n        return self.image_paths\n\n    def backward_D(self):\n        # Fake\n        # stop backprop to the generator by detaching fake_B\n        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1).data)\n        pred_fake = self.netD(fake_AB.detach())\n        self.loss_D_fake = self.criterionGAN(pred_fake, False)\n\n        # Real\n        real_AB = torch.cat((self.real_A, self.real_B), 1)\n        pred_real = self.netD(real_AB)\n        self.loss_D_real = self.criterionGAN(pred_real, True)\n\n        # Combined loss\n        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n\n        self.loss_D.backward()\n\n    def backward_G(self):\n        # First, G(A) should fake the discriminator\n        fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n        pred_fake = self.netD(fake_AB)\n        self.loss_G_GAN = self.criterionGAN(pred_fake, True)\n\n        # Second, G(A) = B\n        self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B) * self.opt.lambda_A\n\n        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n\n        self.loss_G.backward()\n\n    def optimize_parameters(self):\n        self.forward()\n\n        self.optimizer_D.zero_grad()\n        self.backward_D()\n        self.optimizer_D.step()\n\n        self.optimizer_G.zero_grad()\n        self.backward_G()\n        self.optimizer_G.step()\n\n    def get_current_errors(self):\n        return OrderedDict([('G_GAN', self.loss_G_GAN.data[0]),\n                            ('G_L1', self.loss_G_L1.data[0]),\n                            ('D_real', self.loss_D_real.data[0]),\n                            ('D_fake', self.loss_D_fake.data[0])\n                            ])\n\n    def get_current_visuals(self):\n        real_A = util.tensor2im(self.real_A.data)\n        fake_B = util.tensor2im(self.fake_B.data)\n        real_B = util.tensor2im(self.real_B.data)\n        return OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('real_B', real_B)])\n\n    def save(self, label):\n        self.save_network(self.netG, 'G', label, self.gpu_ids)\n        self.save_network(self.netD, 'D', label, self.gpu_ids)\n\n    def load(self, label):\n        self.load_network(self.netG, 'G', label)\n        self.load_network(self.netD, 'D', label)\n"""
fastai/courses/dl2/cgan/models/test_model.py,1,"b""from torch.autograd import Variable\nfrom collections import OrderedDict\nfrom ..util import *\nfrom .base_model import BaseModel\nfrom . import networks\n\n\nclass TestModel(BaseModel):\n    def name(self):\n        return 'TestModel'\n\n    def initialize(self, opt):\n        assert(not opt.isTrain)\n        BaseModel.initialize(self, opt)\n        self.netG = networks.define_G(opt.input_nc, opt.output_nc,\n                                      opt.ngf, opt.which_model_netG,\n                                      opt.norm, not opt.no_dropout,\n                                      opt.init_type,\n                                      self.gpu_ids)\n        which_epoch = opt.which_epoch\n        self.load_network(self.netG, 'G', which_epoch)\n\n        print('---------- Networks initialized -------------')\n        networks.print_network(self.netG)\n        print('-----------------------------------------------')\n\n    def set_input(self, input):\n        # we need to use single_dataset mode\n        input_A = input['A']\n        if len(self.gpu_ids) > 0:\n            input_A = input_A.cuda(self.gpu_ids[0], async=True)\n        self.input_A = input_A\n        self.image_paths = input['A_paths']\n\n    def test(self):\n        self.real_A = Variable(self.input_A)\n        self.fake_B = self.netG(self.real_A)\n\n    # get image paths\n    def get_image_paths(self):\n        return self.image_paths\n\n    def get_current_visuals(self):\n        real_A = util.tensor2im(self.real_A.data)\n        fake_B = util.tensor2im(self.fake_B.data)\n        return OrderedDict([('real_A', real_A), ('fake_B', fake_B)])\n"""
fastai/courses/dl2/cgan/options/__init__.py,0,b''
fastai/courses/dl2/cgan/options/base_options.py,1,"b'import argparse\nimport os\nfrom ..util import util\nimport torch\n\n\nclass BaseOptions():\n    def __init__(self):\n        self.parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n        self.initialized = False\n\n    def initialize(self):\n        self.parser.add_argument(\'--dataroot\', required=True, help=\'path to images (should have subfolders trainA, trainB, valA, valB, etc)\')\n        self.parser.add_argument(\'--batchSize\', type=int, default=1, help=\'input batch size\')\n        self.parser.add_argument(\'--loadSize\', type=int, default=286, help=\'scale images to this size\')\n        self.parser.add_argument(\'--fineSize\', type=int, default=256, help=\'then crop to this size\')\n        self.parser.add_argument(\'--input_nc\', type=int, default=3, help=\'# of input image channels\')\n        self.parser.add_argument(\'--output_nc\', type=int, default=3, help=\'# of output image channels\')\n        self.parser.add_argument(\'--ngf\', type=int, default=64, help=\'# of gen filters in first conv layer\')\n        self.parser.add_argument(\'--ndf\', type=int, default=64, help=\'# of discrim filters in first conv layer\')\n        self.parser.add_argument(\'--which_model_netD\', type=str, default=\'basic\', help=\'selects model to use for netD\')\n        self.parser.add_argument(\'--which_model_netG\', type=str, default=\'resnet_9blocks\', help=\'selects model to use for netG\')\n        self.parser.add_argument(\'--n_layers_D\', type=int, default=3, help=\'only used if which_model_netD==n_layers\')\n        self.parser.add_argument(\'--gpu_ids\', type=str, default=\'0\', help=\'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU\')\n        self.parser.add_argument(\'--name\', type=str, default=\'experiment_name\', help=\'name of the experiment. It decides where to store samples and models\')\n        self.parser.add_argument(\'--dataset_mode\', type=str, default=\'unaligned\', help=\'chooses how datasets are loaded. [unaligned | aligned | single]\')\n        self.parser.add_argument(\'--model\', type=str, default=\'cycle_gan\',\n                                 help=\'chooses which model to use. cycle_gan, pix2pix, test\')\n        self.parser.add_argument(\'--which_direction\', type=str, default=\'AtoB\', help=\'AtoB or BtoA\')\n        self.parser.add_argument(\'--nThreads\', default=2, type=int, help=\'# threads for loading data\')\n        self.parser.add_argument(\'--checkpoints_dir\', type=str, default=\'./checkpoints\', help=\'models are saved here\')\n        self.parser.add_argument(\'--norm\', type=str, default=\'instance\', help=\'instance normalization or batch normalization\')\n        self.parser.add_argument(\'--serial_batches\', action=\'store_true\', help=\'if true, takes images in order to make batches, otherwise takes them randomly\')\n        self.parser.add_argument(\'--display_winsize\', type=int, default=256, help=\'display window size\')\n        self.parser.add_argument(\'--display_id\', type=int, default=1, help=\'window id of the web display\')\n        self.parser.add_argument(\'--display_port\', type=int, default=8097, help=\'visdom port of the web display\')\n        self.parser.add_argument(\'--no_dropout\', action=\'store_true\', help=\'no dropout for the generator\')\n        self.parser.add_argument(\'--max_dataset_size\', type=int, default=float(""inf""),\n                                 help=\'Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.\')\n        self.parser.add_argument(\'--resize_or_crop\', type=str, default=\'resize_and_crop\', help=\'scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]\')\n        self.parser.add_argument(\'--no_flip\', action=\'store_true\', help=\'if specified, do not flip the images for data augmentation\')\n        self.parser.add_argument(\'--init_type\', type=str, default=\'normal\', help=\'network initialization [normal|xavier|kaiming|orthogonal]\')\n\n        self.initialized = True\n\n    def parse(self, args=None):\n        if not self.initialized:\n            self.initialize()\n        self.opt = self.parser.parse_args(args)\n        self.opt.isTrain = self.isTrain   # train or test\n\n        str_ids = self.opt.gpu_ids.split(\',\')\n        self.opt.gpu_ids = []\n        for str_id in str_ids:\n            id = int(str_id)\n            if id >= 0:\n                self.opt.gpu_ids.append(id)\n\n        # set gpu ids\n        if len(self.opt.gpu_ids) > 0:\n            torch.cuda.set_device(self.opt.gpu_ids[0])\n\n        args = vars(self.opt)\n\n        print(\'------------ Options -------------\')\n        for k, v in sorted(args.items()):\n            print(\'%s: %s\' % (str(k), str(v)))\n        print(\'-------------- End ----------------\')\n\n        # save to the disk\n        expr_dir = os.path.join(self.opt.checkpoints_dir, self.opt.name)\n        util.mkdirs(expr_dir)\n        file_name = os.path.join(expr_dir, \'opt.txt\')\n        with open(file_name, \'wt\') as opt_file:\n            opt_file.write(\'------------ Options -------------\\n\')\n            for k, v in sorted(args.items()):\n                opt_file.write(\'%s: %s\\n\' % (str(k), str(v)))\n            opt_file.write(\'-------------- End ----------------\\n\')\n        return self.opt\n'"
fastai/courses/dl2/cgan/options/test_options.py,0,"b'from .base_options import BaseOptions\n\n\nclass TestOptions(BaseOptions):\n    def initialize(self):\n        BaseOptions.initialize(self)\n        self.parser.add_argument(\'--ntest\', type=int, default=float(""inf""), help=\'# of test examples.\')\n        self.parser.add_argument(\'--results_dir\', type=str, default=\'./results/\', help=\'saves results here.\')\n        self.parser.add_argument(\'--aspect_ratio\', type=float, default=1.0, help=\'aspect ratio of result images\')\n        self.parser.add_argument(\'--phase\', type=str, default=\'test\', help=\'train, val, test, etc\')\n        self.parser.add_argument(\'--which_epoch\', type=str, default=\'latest\', help=\'which epoch to load? set to latest to use latest cached model\')\n        self.parser.add_argument(\'--how_many\', type=int, default=50, help=\'how many test images to run\')\n        self.isTrain = False\n'"
fastai/courses/dl2/cgan/options/train_options.py,0,"b""from .base_options import BaseOptions\n\n\nclass TrainOptions(BaseOptions):\n    def initialize(self):\n        BaseOptions.initialize(self)\n        self.parser.add_argument('--display_freq', type=int, default=100, help='frequency of showing training results on screen')\n        self.parser.add_argument('--display_single_pane_ncols', type=int, default=0, help='if positive, display all images in a single visdom web panel with certain number of images per row.')\n        self.parser.add_argument('--update_html_freq', type=int, default=1000, help='frequency of saving training results to html')\n        self.parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n        self.parser.add_argument('--save_latest_freq', type=int, default=5000, help='frequency of saving the latest results')\n        self.parser.add_argument('--save_epoch_freq', type=int, default=5, help='frequency of saving checkpoints at the end of epochs')\n        self.parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n        self.parser.add_argument('--epoch_count', type=int, default=1, help='the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...')\n        self.parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n        self.parser.add_argument('--which_epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\n        self.parser.add_argument('--niter', type=int, default=100, help='# of iter at starting learning rate')\n        self.parser.add_argument('--niter_decay', type=int, default=100, help='# of iter to linearly decay learning rate to zero')\n        self.parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n        self.parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n        self.parser.add_argument('--no_lsgan', action='store_true', help='do *not* use least square GAN, if false, use vanilla GAN')\n        self.parser.add_argument('--lambda_A', type=float, default=10.0, help='weight for cycle loss (A -> B -> A)')\n        self.parser.add_argument('--lambda_B', type=float, default=10.0, help='weight for cycle loss (B -> A -> B)')\n        self.parser.add_argument('--lambda_identity', type=float, default=0.5,\n                                 help='use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss.'\n                                 'For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1')\n        self.parser.add_argument('--pool_size', type=int, default=50, help='the size of image buffer that stores previously generated images')\n        self.parser.add_argument('--no_html', action='store_true', help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/')\n        self.parser.add_argument('--lr_policy', type=str, default='lambda', help='learning rate policy: lambda|step|plateau')\n        self.parser.add_argument('--lr_decay_iters', type=int, default=50, help='multiply by a gamma every lr_decay_iters iterations')\n\n        self.isTrain = True\n"""
fastai/courses/dl2/cgan/util/__init__.py,0,b''
fastai/courses/dl2/cgan/util/get_data.py,0,"b'from __future__ import print_function\nimport os\nimport tarfile\nimport requests\nfrom warnings import warn\nfrom zipfile import ZipFile\nfrom bs4 import BeautifulSoup\nfrom os.path import abspath, isdir, join, basename\n\n\nclass GetData(object):\n    """"""\n\n    Download CycleGAN or Pix2Pix Data.\n\n    Args:\n        technique : str\n            One of: \'cyclegan\' or \'pix2pix\'.\n        verbose : bool\n            If True, print additional information.\n\n    Examples:\n        >>> from util.get_data import GetData\n        >>> gd = GetData(technique=\'cyclegan\')\n        >>> new_data_path = gd.get(save_path=\'./datasets\')  # options will be displayed.\n\n    """"""\n\n    def __init__(self, technique=\'cyclegan\', verbose=True):\n        url_dict = {\n            \'pix2pix\': \'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets\',\n            \'cyclegan\': \'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets\'\n        }\n        self.url = url_dict.get(technique.lower())\n        self._verbose = verbose\n\n    def _print(self, text):\n        if self._verbose:\n            print(text)\n\n    @staticmethod\n    def _get_options(r):\n        soup = BeautifulSoup(r.text, \'lxml\')\n        options = [h.text for h in soup.find_all(\'a\', href=True)\n                   if h.text.endswith((\'.zip\', \'tar.gz\'))]\n        return options\n\n    def _present_options(self):\n        r = requests.get(self.url)\n        options = self._get_options(r)\n        print(\'Options:\\n\')\n        for i, o in enumerate(options):\n            print(""{0}: {1}"".format(i, o))\n        choice = input(""\\nPlease enter the number of the ""\n                       ""dataset above you wish to download:"")\n        return options[int(choice)]\n\n    def _download_data(self, dataset_url, save_path):\n        if not isdir(save_path):\n            os.makedirs(save_path)\n\n        base = basename(dataset_url)\n        temp_save_path = join(save_path, base)\n\n        with open(temp_save_path, ""wb"") as f:\n            r = requests.get(dataset_url)\n            f.write(r.content)\n\n        if base.endswith(\'.tar.gz\'):\n            obj = tarfile.open(temp_save_path)\n        elif base.endswith(\'.zip\'):\n            obj = ZipFile(temp_save_path, \'r\')\n        else:\n            raise ValueError(""Unknown File Type: {0}."".format(base))\n\n        self._print(""Unpacking Data..."")\n        obj.extractall(save_path)\n        obj.close()\n        os.remove(temp_save_path)\n\n    def get(self, save_path, dataset=None):\n        """"""\n\n        Download a dataset.\n\n        Args:\n            save_path : str\n                A directory to save the data to.\n            dataset : str, optional\n                A specific dataset to download.\n                Note: this must include the file extension.\n                If None, options will be presented for you\n                to choose from.\n\n        Returns:\n            save_path_full : str\n                The absolute path to the downloaded data.\n\n        """"""\n        if dataset is None:\n            selected_dataset = self._present_options()\n        else:\n            selected_dataset = dataset\n\n        save_path_full = join(save_path, selected_dataset.split(\'.\')[0])\n\n        if isdir(save_path_full):\n            warn(""\\n\'{0}\' already exists. Voiding Download."".format(\n                save_path_full))\n        else:\n            self._print(\'Downloading Data...\')\n            url = ""{0}/{1}"".format(self.url, selected_dataset)\n            self._download_data(url, save_path=save_path)\n\n        return abspath(save_path_full)\n'"
fastai/courses/dl2/cgan/util/html.py,0,"b'import dominate\nfrom dominate.tags import *\nimport os\n\n\nclass HTML:\n    def __init__(self, web_dir, title, refresh=0):\n        self.title = title\n        self.web_dir = web_dir\n        self.img_dir = os.path.join(self.web_dir, \'images\')\n        if not os.path.exists(self.web_dir):\n            os.makedirs(self.web_dir)\n        if not os.path.exists(self.img_dir):\n            os.makedirs(self.img_dir)\n        # print(self.img_dir)\n\n        self.doc = dominate.document(title=title)\n        if refresh > 0:\n            with self.doc.head:\n                meta(http_equiv=""refresh"", content=str(refresh))\n\n    def get_image_dir(self):\n        return self.img_dir\n\n    def add_header(self, str):\n        with self.doc:\n            h3(str)\n\n    def add_table(self, border=1):\n        self.t = table(border=border, style=""table-layout: fixed;"")\n        self.doc.add(self.t)\n\n    def add_images(self, ims, txts, links, width=400):\n        self.add_table()\n        with self.t:\n            with tr():\n                for im, txt, link in zip(ims, txts, links):\n                    with td(style=""word-wrap: break-word;"", halign=""center"", valign=""top""):\n                        with p():\n                            with a(href=os.path.join(\'images\', link)):\n                                img(style=""width:%dpx"" % width, src=os.path.join(\'images\', im))\n                            br()\n                            p(txt)\n\n    def save(self):\n        html_file = \'%s/index.html\' % self.web_dir\n        f = open(html_file, \'wt\')\n        f.write(self.doc.render())\n        f.close()\n\n\nif __name__ == \'__main__\':\n    html = HTML(\'web/\', \'test_html\')\n    html.add_header(\'hello world\')\n\n    ims = []\n    txts = []\n    links = []\n    for n in range(4):\n        ims.append(\'image_%d.png\' % n)\n        txts.append(\'text_%d\' % n)\n        links.append(\'image_%d.png\' % n)\n    html.add_images(ims, txts, links)\n    html.save()\n'"
fastai/courses/dl2/cgan/util/image_pool.py,3,"b'import random\nimport torch\nfrom torch.autograd import Variable\n\n\nclass ImagePool():\n    def __init__(self, pool_size):\n        self.pool_size = pool_size\n        if self.pool_size > 0:\n            self.num_imgs = 0\n            self.images = []\n\n    def query(self, images):\n        if self.pool_size == 0:\n            return Variable(images)\n        return_images = []\n        for image in images:\n            image = torch.unsqueeze(image, 0)\n            if self.num_imgs < self.pool_size:\n                self.num_imgs = self.num_imgs + 1\n                self.images.append(image)\n                return_images.append(image)\n            else:\n                p = random.uniform(0, 1)\n                if p > 0.5:\n                    random_id = random.randint(0, self.pool_size - 1)\n                    tmp = self.images[random_id].clone()\n                    self.images[random_id] = image\n                    return_images.append(tmp)\n                else:\n                    return_images.append(image)\n        return_images = Variable(torch.cat(return_images, 0))\n        return return_images\n'"
fastai/courses/dl2/cgan/util/util.py,1,"b""from __future__ import print_function\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport os\n\n\n# Converts a Tensor into a Numpy array\n# |imtype|: the desired type of the converted numpy array\ndef tensor2im(image_tensor, imtype=np.uint8):\n    image_numpy = image_tensor[0].cpu().float().numpy()\n    if image_numpy.shape[0] == 1:\n        image_numpy = np.tile(image_numpy, (3, 1, 1))\n    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n    return image_numpy.astype(imtype)\n\n\ndef diagnose_network(net, name='network'):\n    mean = 0.0\n    count = 0\n    for param in net.parameters():\n        if param.grad is not None:\n            mean += torch.mean(torch.abs(param.grad.data))\n            count += 1\n    if count > 0:\n        mean = mean / count\n    print(name)\n    print(mean)\n\n\ndef save_image(image_numpy, image_path):\n    image_pil = Image.fromarray(image_numpy)\n    image_pil.save(image_path)\n\n\ndef print_numpy(x, val=True, shp=False):\n    x = x.astype(np.float64)\n    if shp:\n        print('shape,', x.shape)\n    if val:\n        x = x.flatten()\n        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))\n\n\ndef mkdirs(paths):\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)\n\n\ndef mkdir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n"""
fastai/courses/dl2/cgan/util/visualizer.py,0,"b'import numpy as np\nimport os\nimport ntpath\nimport time\nfrom . import util\nfrom . import html\nfrom scipy.misc import imresize\n\n\nclass Visualizer():\n    def __init__(self, opt):\n        # self.opt = opt\n        self.display_id = opt.display_id\n        self.use_html = opt.isTrain and not opt.no_html\n        self.win_size = opt.display_winsize\n        self.name = opt.name\n        self.opt = opt\n        self.saved = False\n        if self.display_id > 0:\n            import visdom\n            self.vis = visdom.Visdom(port=opt.display_port)\n\n        if self.use_html:\n            self.web_dir = os.path.join(opt.checkpoints_dir, opt.name, \'web\')\n            self.img_dir = os.path.join(self.web_dir, \'images\')\n            print(\'create web directory %s...\' % self.web_dir)\n            util.mkdirs([self.web_dir, self.img_dir])\n        self.log_name = os.path.join(opt.checkpoints_dir, opt.name, \'loss_log.txt\')\n        with open(self.log_name, ""a"") as log_file:\n            now = time.strftime(""%c"")\n            log_file.write(\'================ Training Loss (%s) ================\\n\' % now)\n\n    def reset(self):\n        self.saved = False\n\n    # |visuals|: dictionary of images to display or save\n    def display_current_results(self, visuals, epoch, save_result):\n        if self.display_id > 0:  # show images in the browser\n            ncols = self.opt.display_single_pane_ncols\n            if ncols > 0:\n                h, w = next(iter(visuals.values())).shape[:2]\n                table_css = """"""<style>\n                        table {border-collapse: separate; border-spacing:4px; white-space:nowrap; text-align:center}\n                        table td {width: %dpx; height: %dpx; padding: 4px; outline: 4px solid black}\n                        </style>"""""" % (w, h)\n                title = self.name\n                label_html = \'\'\n                label_html_row = \'\'\n                nrows = int(np.ceil(len(visuals.items()) / ncols))\n                images = []\n                idx = 0\n                for label, image_numpy in visuals.items():\n                    label_html_row += \'<td>%s</td>\' % label\n                    images.append(image_numpy.transpose([2, 0, 1]))\n                    idx += 1\n                    if idx % ncols == 0:\n                        label_html += \'<tr>%s</tr>\' % label_html_row\n                        label_html_row = \'\'\n                white_image = np.ones_like(image_numpy.transpose([2, 0, 1])) * 255\n                while idx % ncols != 0:\n                    images.append(white_image)\n                    label_html_row += \'<td></td>\'\n                    idx += 1\n                if label_html_row != \'\':\n                    label_html += \'<tr>%s</tr>\' % label_html_row\n                # pane col = image row\n                self.vis.images(images, nrow=ncols, win=self.display_id + 1,\n                                padding=2, opts=dict(title=title + \' images\'))\n                label_html = \'<table>%s</table>\' % label_html\n                self.vis.text(table_css + label_html, win=self.display_id + 2,\n                              opts=dict(title=title + \' labels\'))\n            else:\n                idx = 1\n                for label, image_numpy in visuals.items():\n                    self.vis.image(image_numpy.transpose([2, 0, 1]), opts=dict(title=label),\n                                   win=self.display_id + idx)\n                    idx += 1\n\n        if self.use_html and (save_result or not self.saved):  # save images to a html file\n            self.saved = True\n            for label, image_numpy in visuals.items():\n                img_path = os.path.join(self.img_dir, \'epoch%.3d_%s.png\' % (epoch, label))\n                util.save_image(image_numpy, img_path)\n            # update website\n            webpage = html.HTML(self.web_dir, \'Experiment name = %s\' % self.name, refresh=1)\n            for n in range(epoch, 0, -1):\n                webpage.add_header(\'epoch [%d]\' % n)\n                ims = []\n                txts = []\n                links = []\n\n                for label, image_numpy in visuals.items():\n                    img_path = \'epoch%.3d_%s.png\' % (n, label)\n                    ims.append(img_path)\n                    txts.append(label)\n                    links.append(img_path)\n                webpage.add_images(ims, txts, links, width=self.win_size)\n            webpage.save()\n\n    # errors: dictionary of error labels and values\n    def plot_current_errors(self, epoch, counter_ratio, opt, errors):\n        if not hasattr(self, \'plot_data\'):\n            self.plot_data = {\'X\': [], \'Y\': [], \'legend\': list(errors.keys())}\n        self.plot_data[\'X\'].append(epoch + counter_ratio)\n        self.plot_data[\'Y\'].append([errors[k] for k in self.plot_data[\'legend\']])\n        self.vis.line(\n            X=np.stack([np.array(self.plot_data[\'X\'])] * len(self.plot_data[\'legend\']), 1),\n            Y=np.array(self.plot_data[\'Y\']),\n            opts={\n                \'title\': self.name + \' loss over time\',\n                \'legend\': self.plot_data[\'legend\'],\n                \'xlabel\': \'epoch\',\n                \'ylabel\': \'loss\'},\n            win=self.display_id)\n\n    # errors: same format as |errors| of plotCurrentErrors\n    def print_current_errors(self, epoch, i, errors, t, t_data):\n        message = \'(epoch: %d, iters: %d, time: %.3f, data: %.3f) \' % (epoch, i, t, t_data)\n        for k, v in errors.items():\n            message += \'%s: %.3f \' % (k, v)\n\n        print(message)\n        with open(self.log_name, ""a"") as log_file:\n            log_file.write(\'%s\\n\' % message)\n\n    # save image to the disk\n    def save_images(self, webpage, visuals, image_path, aspect_ratio=1.0):\n        image_dir = webpage.get_image_dir()\n        short_path = ntpath.basename(image_path[0])\n        name = os.path.splitext(short_path)[0]\n\n        webpage.add_header(name)\n        ims = []\n        txts = []\n        links = []\n\n        for label, im in visuals.items():\n            image_name = \'%s_%s.png\' % (name, label)\n            save_path = os.path.join(image_dir, image_name)\n            h, w, _ = im.shape\n            if aspect_ratio > 1.0:\n                im = imresize(im, (h, int(w * aspect_ratio)), interp=\'bicubic\')\n            if aspect_ratio < 1.0:\n                im = imresize(im, (int(h / aspect_ratio), w), interp=\'bicubic\')\n            util.save_image(im, save_path)\n\n            ims.append(image_name)\n            txts.append(label)\n            links.append(image_name)\n        webpage.add_images(ims, txts, links, width=self.win_size)\n'"
fastai/courses/dl2/fastai/models/convert_torch.py,13,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.serialization import load_lua\n\nimport numpy as np\nimport os\nimport math\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        # result is Variables list [Variable1, Variable2, ...]\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        # result is a Variable\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef copy_param(m,n):\n    if m.weight is not None: n.weight.data.copy_(m.weight)\n    if m.bias is not None: n.bias.data.copy_(m.bias)\n    if hasattr(n,\'running_mean\'): n.running_mean.copy_(m.running_mean)\n    if hasattr(n,\'running_var\'): n.running_var.copy_(m.running_var)\n\ndef add_submodule(seq, *args):\n    for n in args:\n        seq.add_module(str(len(seq._modules)),n)\n\ndef lua_recursive_model(module,seq):\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            n = nn.Conv2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,bias=(m.bias is not None))\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'SpatialBatchNormalization\':\n            n = nn.BatchNorm2d(m.running_mean.size(0), m.eps, m.momentum, m.affine)\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'ReLU\':\n            n = nn.ReLU()\n            add_submodule(seq,n)\n        elif name == \'SpatialMaxPooling\':\n            n = nn.MaxPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialAveragePooling\':\n            n = nn.AvgPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialUpSamplingNearest\':\n            n = nn.UpsamplingNearest2d(scale_factor=m.scale_factor)\n            add_submodule(seq,n)\n        elif name == \'View\':\n            n = Lambda(lambda x: x.view(x.size(0),-1))\n            add_submodule(seq,n)\n        elif name == \'Linear\':\n            # Linear in pytorch only accept 2D input\n            n1 = Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\n            n2 = nn.Linear(m.weight.size(1),m.weight.size(0),bias=(m.bias is not None))\n            copy_param(m,n2)\n            n = nn.Sequential(n1,n2)\n            add_submodule(seq,n)\n        elif name == \'Dropout\':\n            m.inplace = False\n            n = nn.Dropout(m.p)\n            add_submodule(seq,n)\n        elif name == \'SoftMax\':\n            n = nn.Softmax()\n            add_submodule(seq,n)\n        elif name == \'Identity\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'SpatialFullConvolution\':\n            n = nn.ConvTranspose2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))\n            add_submodule(seq,n)\n        elif name == \'SpatialReplicationPadding\':\n            n = nn.ReplicationPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'SpatialReflectionPadding\':\n            n = nn.ReflectionPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'Copy\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'Narrow\':\n            n = Lambda(lambda x,a=(m.dimension,m.index,m.length): x.narrow(*a))\n            add_submodule(seq,n)\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = torch.legacy.nn.SpatialCrossMapLRN(m.size,m.alpha,m.beta,m.k)\n            n = Lambda(lambda x,lrn=lrn: Variable(lrn.forward(x.data)))\n            add_submodule(seq,n)\n        elif name == \'Sequential\':\n            n = nn.Sequential()\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'ConcatTable\': # output is list\n            n = LambdaMap(lambda x: x)\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'CAddTable\': # input is list\n            n = LambdaReduce(lambda x,y: x+y)\n            add_submodule(seq,n)\n        elif name == \'Concat\':\n            dim = m.dimension\n            n = LambdaReduce(lambda x,y,dim=dim: torch.cat((x,y),dim))\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'TorchObject\':\n            print(\'Not Implement\',name,real._typename)\n        else:\n            print(\'Not Implement\',name)\n\n\ndef lua_recursive_source(module):\n    s = []\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            s += [\'nn.Conv2d({},{},{},{},{},{},{},bias={}),#Conv2d\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,m.bias is not None)]\n        elif name == \'SpatialBatchNormalization\':\n            s += [\'nn.BatchNorm2d({},{},{},{}),#BatchNorm2d\'.format(m.running_mean.size(0), m.eps, m.momentum, m.affine)]\n        elif name == \'ReLU\':\n            s += [\'nn.ReLU()\']\n        elif name == \'SpatialMaxPooling\':\n            s += [\'nn.MaxPool2d({},{},{},ceil_mode={}),#MaxPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialAveragePooling\':\n            s += [\'nn.AvgPool2d({},{},{},ceil_mode={}),#AvgPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialUpSamplingNearest\':\n            s += [\'nn.UpsamplingNearest2d(scale_factor={})\'.format(m.scale_factor)]\n        elif name == \'View\':\n            s += [\'Lambda(lambda x: x.view(x.size(0),-1)), # View\']\n        elif name == \'Linear\':\n            s1 = \'Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\'\n            s2 = \'nn.Linear({},{},bias={})\'.format(m.weight.size(1),m.weight.size(0),(m.bias is not None))\n            s += [\'nn.Sequential({},{}),#Linear\'.format(s1,s2)]\n        elif name == \'Dropout\':\n            s += [\'nn.Dropout({})\'.format(m.p)]\n        elif name == \'SoftMax\':\n            s += [\'nn.Softmax()\']\n        elif name == \'Identity\':\n            s += [\'Lambda(lambda x: x), # Identity\']\n        elif name == \'SpatialFullConvolution\':\n            s += [\'nn.ConvTranspose2d({},{},{},{},{})\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))]\n        elif name == \'SpatialReplicationPadding\':\n            s += [\'nn.ReplicationPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'SpatialReflectionPadding\':\n            s += [\'nn.ReflectionPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'Copy\':\n            s += [\'Lambda(lambda x: x), # Copy\']\n        elif name == \'Narrow\':\n            s += [\'Lambda(lambda x,a={}: x.narrow(*a))\'.format((m.dimension,m.index,m.length))]\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = \'torch.legacy.nn.SpatialCrossMapLRN(*{})\'.format((m.size,m.alpha,m.beta,m.k))\n            s += [\'Lambda(lambda x,lrn={}: Variable(lrn.forward(x.data)))\'.format(lrn)]\n\n        elif name == \'Sequential\':\n            s += [\'nn.Sequential( # Sequential\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'ConcatTable\':\n            s += [\'LambdaMap(lambda x: x, # ConcatTable\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'CAddTable\':\n            s += [\'LambdaReduce(lambda x,y: x+y), # CAddTable\']\n        elif name == \'Concat\':\n            dim = m.dimension\n            s += [\'LambdaReduce(lambda x,y,dim={}: torch.cat((x,y),dim), # Concat\'.format(m.dimension)]\n            s += lua_recursive_source(m)\n            s += [\')\']\n        else:\n            s += \'# \' + name + \' Not Implement,\\n\'\n    s = map(lambda x: \'\\t{}\'.format(x),s)\n    return s\n\ndef simplify_source(s):\n    s = map(lambda x: x.replace(\',(1, 1),(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1e-05,0.1,True),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True)),#Linear\',\')), # Linear\'),s)\n    s = map(lambda x: x.replace(\')),#Linear\',\')), # Linear\'),s)\n    \n    s = map(lambda x: \'{},\\n\'.format(x),s)\n    s = map(lambda x: x[1:],s)\n    s = reduce(lambda x,y: x+y, s)\n    return s\n\ndef torch_to_pytorch(t7_filename,outputname=None):\n    model = load_lua(t7_filename,unknown_classes=True)\n    if type(model).__name__==\'hashable_uniq_dict\': model=model.model\n    model.gradInput = None\n    slist = lua_recursive_source(torch.legacy.nn.Sequential().add(model))\n    s = simplify_source(slist)\n    header = \'\'\'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\'\'\'\n    varname = t7_filename.replace(\'.t7\',\'\').replace(\'.\',\'_\').replace(\'-\',\'_\')\n    s = \'{}\\n\\n{} = {}\'.format(header,varname,s[:-2])\n\n    if outputname is None: outputname=varname\n    with open(outputname+\'.py\', ""w"") as pyfile:\n        pyfile.write(s)\n\n    n = nn.Sequential()\n    lua_recursive_model(model,n)\n    torch.save(n.state_dict(),outputname+\'.pth\')\n\n\nparser = argparse.ArgumentParser(description=\'Convert torch t7 model to pytorch\')\nparser.add_argument(\'--model\',\'-m\', type=str, required=True,\n                    help=\'torch model file in t7 format\')\nparser.add_argument(\'--output\', \'-o\', type=str, default=None,\n                    help=\'output file name prefix, xxx.py xxx.pth\')\nargs = parser.parse_args()\n\ntorch_to_pytorch(args.model,args.output)\n'"
fastai/courses/dl2/fastai/models/darknet.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .layers import *\n\nclass ConvBN(nn.Module):\n    ""convolutional layer then batchnorm""\n\n    def __init__(self, ch_in, ch_out, kernel_size = 3, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(ch_out, momentum=0.01)\n        self.relu = nn.LeakyReLU(0.1, inplace=True)\n\n    def forward(self, x): return self.relu(self.bn(self.conv(x)))\n\nclass DarknetBlock(nn.Module):\n    def __init__(self, ch_in):\n        super().__init__()\n        ch_hid = ch_in//2\n        self.conv1 = ConvBN(ch_in, ch_hid, kernel_size=1, stride=1, padding=0)\n        self.conv2 = ConvBN(ch_hid, ch_in, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x): return self.conv2(self.conv1(x)) + x\n\nclass Darknet(nn.Module):\n    ""Replicates the darknet classifier from the YOLOv3 paper (table 1)""\n\n    def make_group_layer(self, ch_in, num_blocks, stride=1):\n        layers = [ConvBN(ch_in,ch_in*2,stride=stride)]\n        for i in range(num_blocks): layers.append(DarknetBlock(ch_in*2))\n        return layers\n\n    def __init__(self, num_blocks, num_classes=1000, start_nf=32):\n        super().__init__()\n        nf = start_nf\n        layers = [ConvBN(3, nf, kernel_size=3, stride=1, padding=1)]\n        for i,nb in enumerate(num_blocks):\n            layers += self.make_group_layer(nf, nb, stride=(1 if i==1 else 2))\n            nf *= 2\n        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x): return self.layers(x)\n\ndef darknet_53(num_classes=1000):    return Darknet([1,2,8,8,4], num_classes)\ndef darknet_small(num_classes=1000): return Darknet([1,2,4,8,4], num_classes)\ndef darknet_mini(num_classes=1000): return Darknet([1,2,4,4,2], num_classes, start_nf=24)\ndef darknet_mini2(num_classes=1000): return Darknet([1,2,8,8,4], num_classes, start_nf=16)\ndef darknet_mini3(num_classes=1000): return Darknet([1,2,4,4], num_classes)\n\n'"
fastai/courses/dl2/fastai/models/fa_resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out += residual\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out += residual\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\ndef load(model, pre, name):\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    return model\n\ndef fa_resnet18(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [2, 2, 2, 2], **kwargs), pretrained, \'resnet18\')\ndef fa_resnet34(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [3, 4, 6, 3], **kwargs), pretrained, \'resnet34\')\ndef fa_resnet50(pretrained=False, **kwargs):  return load(ResNet(Bottleneck, [3, 4, 6, 3], **kwargs), pretrained, \'resnet50\')\ndef fa_resnet101(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 4, 23, 3], **kwargs), pretrained, \'resnet101\')\ndef fa_resnet152(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 8, 36, 3], **kwargs), pretrained, \'resnet152\')\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 ():  return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50():  return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck,[3, 4, 6, 3], k=1.125)\ndef vgg_resnet50():  return ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n\n'"
fastai/courses/dl2/fastai/models/inceptionresnetv2.py,31,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'http://webia.lip6.fr/~cadene/Downloads/inceptionresnetv2-d579a627.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_5b(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5b, self).__init__()\n\n        self.branch0 = BasicConv2d(192, 96, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(192, 48, kernel_size=1, stride=1),\n            BasicConv2d(48, 64, kernel_size=5, stride=1, padding=2)\n        ) \n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(192, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(192, 64, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block35(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block35, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(320, 32, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 48, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(48, 64, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.conv2d = nn.Conv2d(128, 320, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_6a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_6a, self).__init__()\n        \n        self.branch0 = BasicConv2d(320, 384, kernel_size=3, stride=2)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Block17(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block17, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(1088, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 128, kernel_size=1, stride=1),\n            BasicConv2d(128, 160, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(160, 192, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.conv2d = nn.Conv2d(384, 1088, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_7a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_7a, self).__init__()\n        \n        self.branch0 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(288, 320, kernel_size=3, stride=2)\n        )\n\n        self.branch3 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block8(nn.Module):\n\n    def __init__(self, scale=1.0, noReLU=False):\n        super(Block8, self).__init__()\n\n        self.scale = scale\n        self.noReLU = noReLU\n\n        self.branch0 = BasicConv2d(2080, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(2080, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,3), stride=1, padding=(0,1)),\n            BasicConv2d(224, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        )\n\n        self.conv2d = nn.Conv2d(448, 2080, kernel_size=1, stride=1)\n        if not self.noReLU:\n            self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        if not self.noReLU:\n            out = self.relu(out)\n        return out\n\n\nclass InceptionResnetV2(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionResnetV2, self).__init__()\n        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n        self.maxpool_5a = nn.MaxPool2d(3, stride=2)\n        self.mixed_5b = Mixed_5b()\n        self.repeat = nn.Sequential(\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17)\n        )\n        self.mixed_6a = Mixed_6a()\n        self.repeat_1 = nn.Sequential(\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10)\n        )\n        self.mixed_7a = Mixed_7a()\n        self.repeat_2 = nn.Sequential(\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20)\n        )\n        self.block8 = Block8(noReLU=True)\n        self.conv2d_7b = BasicConv2d(2080, 1536, kernel_size=1, stride=1)\n        self.avgpool_1a = nn.AdaptiveAvgPool2d((1,1))\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.conv2d_1a(x)\n        x = self.conv2d_2a(x)\n        x = self.conv2d_2b(x)\n        x = self.maxpool_3a(x)\n        x = self.conv2d_3b(x)\n        x = self.conv2d_4a(x)\n        x = self.maxpool_5a(x)\n        x = self.mixed_5b(x)\n        x = self.repeat(x)\n        x = self.mixed_6a(x)\n        x = self.repeat_1(x)\n        x = self.mixed_7a(x)\n        x = self.repeat_2(x)\n        x = self.block8(x)\n        x = self.conv2d_7b(x)\n        x = self.avgpool_1a(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\ndef inceptionresnetv2(pretrained=True):\n    r""""""InceptionResnetV2 model architecture from the\n    `""InceptionV4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (\'string\'): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionResnetV2()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_conv2d_nobn(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_5b(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_5x5\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_block35(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_6a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_block17(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef load_block8(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_1a\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2a\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2b\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_3b\', name_tf=\'Conv2d_3b_1x1\')\n    load_conv2d(state_dict, name_pth=\'conv2d_4a\', name_tf=\'Conv2d_4a_3x3\')\n\n    load_mixed_5b(state_dict, name_pth=\'mixed_5b\', name_tf=\'Mixed_5b\')\n\n    for i in range(10):\n        load_block35(state_dict, name_pth=\'repeat.\'+str(i), name_tf=\'Repeat/block35_\'+str(i+1))\n\n    load_mixed_6a(state_dict, name_pth=\'mixed_6a\', name_tf=\'Mixed_6a\')\n\n    for i in range(20):\n        load_block17(state_dict, name_pth=\'repeat_1.\'+str(i), name_tf=\'Repeat_1/block17_\'+str(i+1))\n\n    load_mixed_7a(state_dict, name_pth=\'mixed_7a\', name_tf=\'Mixed_7a\')\n\n    for i in range(9):\n        load_block8(state_dict, name_pth=\'repeat_2.\'+str(i), name_tf=\'Repeat_2/block8_\'+str(i+1))\n\n    load_block8(state_dict, name_pth=\'block8\', name_tf=\'Block8\')\n    load_conv2d(state_dict, name_pth=\'conv2d_7b\', name_tf=\'Conv2d_7b_1x1\')\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.ones(1,299,299,3)\n    #inputs[0] = torch.from_numpy(img)\n\n    inputs[0,0,0,0] = -1\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n\n    print(inputs.mean())\n    print(inputs.std())\n\n    #inputs.sub_(0.5).div_(0.5)\n    #inputs.sub_(inputs)\n    # 1, 3, 299, 299\n\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionResnetV2/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(outputs.sum())\n    print(outputs[0])\n    print(outputs_tf.sum())\n    print(outputs_tf[0])\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf_conv = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf_conv.transpose_(1,3)\n    output_tf_conv.transpose_(2,3)\n    output_tf_relu = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf_relu.transpose_(1,3)\n    output_tf_relu.transpose_(2,3)\n    h5f.close()\n    def test_dist_conv(self, input, output):\n        print(name, \'conv\', torch.dist(output.data, output_tf_conv))\n    module.conv.register_forward_hook(test_dist_conv)\n    def test_dist_relu(self, input, output):\n        print(name, \'relu\', torch.dist(output.data, output_tf_relu))\n    module.relu.register_forward_hook(test_dist_relu)\n\ndef test_conv2d_nobn(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, \'conv+bias\', torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_5b(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_5x5\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d(module.branch3[1], name+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef test_block35(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_6a(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef test_block17(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_1a_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef test_block8(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_3x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionResnetV2()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n    model.eval()\n\n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionresnetv2.pth\')\n    torch.save(state_dict, \'save/inceptionresnetv2_state.pth\')\n\n    test_conv2d(model.conv2d_1a, \'Conv2d_1a_3x3\')\n    test_conv2d(model.conv2d_2a, \'Conv2d_2a_3x3\')\n    test_conv2d(model.conv2d_2b, \'Conv2d_2b_3x3\')\n    test_conv2d(model.conv2d_3b, \'Conv2d_3b_1x1\')\n    test_conv2d(model.conv2d_4a, \'Conv2d_4a_3x3\')\n\n    test_mixed_5b(model.mixed_5b, \'Mixed_5b\')\n\n    for i in range(len(model.repeat._modules)):\n        test_block35(model.repeat[i], \'Repeat/block35_\'+str(i+1))\n\n    test_mixed_6a(model.mixed_6a, \'Mixed_6a\')\n\n    for i in range(len(model.repeat_1._modules)):\n        test_block17(model.repeat_1[i], \'Repeat_1/block17_\'+str(i+1))\n\n    test_mixed_7a(model.mixed_7a, \'Mixed_7a\')\n\n    for i in range(len(model.repeat_2._modules)):\n        test_block8(model.repeat_2[i], \'Repeat_2/block8_\'+str(i+1))\n\n    test_block8(model.block8, \'Block8\')\n\n    test_conv2d(model.conv2d_7b, \'Conv2d_7b_1x1\')\n\n    outputs = test(model)\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    #test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n\n'"
fastai/courses/dl2/fastai/models/inceptionv4.py,29,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'https://s3.amazonaws.com/pytorch/models/inceptionv4-58153ba9.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_3a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_3a, self).__init__()\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n\n    def forward(self, x):\n        x0 = self.maxpool(x)\n        x1 = self.conv(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_4a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_4a, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(64, 96, kernel_size=(3,3), stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_5a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5a, self).__init__()\n        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.conv(x)\n        x1 = self.maxpool(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Inception_A(nn.Module):\n\n    def __init__(self):\n        super(Inception_A, self).__init__()\n        self.block0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(384, 96, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_A(nn.Module):\n\n    def __init__(self):\n        super(Reduction_A, self).__init__()\n        self.block0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(224, 256, kernel_size=3, stride=2)\n        )\n        \n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_B(nn.Module):\n\n    def __init__(self):\n        super(Inception_B, self).__init__()\n        self.block0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n        \n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_B(nn.Module):\n\n    def __init__(self):\n        super(Reduction_B, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=3, stride=2)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(320, 320, kernel_size=3, stride=2)\n        )\n\n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_C(nn.Module):\n\n    def __init__(self):\n        super(Inception_C, self).__init__()\n        self.block0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        \n        self.block1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n        self.block2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3a = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3b = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        \n        x1_0 = self.block1_0(x)\n        x1_1a = self.block1_1a(x1_0)\n        x1_1b = self.block1_1b(x1_0)\n        x1 = torch.cat((x1_1a, x1_1b), 1)\n\n        x2_0 = self.block2_0(x)\n        x2_1 = self.block2_1(x2_0)\n        x2_2 = self.block2_2(x2_1)\n        x2_3a = self.block2_3a(x2_2)\n        x2_3b = self.block2_3b(x2_2)\n        x2 = torch.cat((x2_3a, x2_3b), 1)\n\n        x3 = self.block3(x)\n\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass InceptionV4(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionV4, self).__init__()\n        self.features = nn.Sequential(\n            BasicConv2d(3, 32, kernel_size=3, stride=2),\n            BasicConv2d(32, 32, kernel_size=3, stride=1),\n            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            Mixed_3a(),\n            Mixed_4a(),\n            Mixed_5a(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Reduction_A(), # Mixed_6a\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Reduction_B(), # Mixed_7a\n            Inception_C(),\n            Inception_C(),\n            Inception_C(),\n            nn.AdaptiveAvgPool2d((1,1))\n        )\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\n\ndef inceptionv4(pretrained=True):\n    r""""""InceptionV4 model architecture from the\n    `""Inception-v4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionV4()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_4a_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.3\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_mixed_5(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_6(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch2.3\', name_tf+\'/Branch_2/Conv2d_0d_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.4\', name_tf+\'/Branch_2/Conv2d_0e_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_7(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1a\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1b\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_1\', name_tf+\'/Branch_2/Conv2d_0b_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_2\', name_tf+\'/Branch_2/Conv2d_0c_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3a\', name_tf+\'/Branch_2/Conv2d_0d_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3b\', name_tf+\'/Branch_2/Conv2d_0e_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'features.0\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.1\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.2\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'features.3.conv\', name_tf=\'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.4\', name_tf=\'Mixed_4a\')\n\n    load_conv2d(state_dict, name_pth=\'features.5.conv\', name_tf=\'Mixed_5a/Branch_0/Conv2d_1a_3x3\')\n\n    load_mixed_5(state_dict, name_pth=\'features.6\', name_tf=\'Mixed_5b\')\n    load_mixed_5(state_dict, name_pth=\'features.7\', name_tf=\'Mixed_5c\')\n    load_mixed_5(state_dict, name_pth=\'features.8\', name_tf=\'Mixed_5d\')\n    load_mixed_5(state_dict, name_pth=\'features.9\', name_tf=\'Mixed_5e\')\n\n    load_conv2d(state_dict, name_pth=\'features.10.branch0\', name_tf=\'Mixed_6a/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.0\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.1\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.2\', name_tf=\'Mixed_6a/Branch_1/Conv2d_1a_3x3\')\n\n    load_mixed_6(state_dict, name_pth=\'features.11\', name_tf=\'Mixed_6b\')\n    load_mixed_6(state_dict, name_pth=\'features.12\', name_tf=\'Mixed_6c\')\n    load_mixed_6(state_dict, name_pth=\'features.13\', name_tf=\'Mixed_6d\')\n    load_mixed_6(state_dict, name_pth=\'features.14\', name_tf=\'Mixed_6e\')\n    load_mixed_6(state_dict, name_pth=\'features.15\', name_tf=\'Mixed_6f\')\n    load_mixed_6(state_dict, name_pth=\'features.16\', name_tf=\'Mixed_6g\')\n    load_mixed_6(state_dict, name_pth=\'features.17\', name_tf=\'Mixed_6h\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.18\', name_tf=\'Mixed_7a\')\n\n    load_mixed_7(state_dict, name_pth=\'features.19\', name_tf=\'Mixed_7b\')\n    load_mixed_7(state_dict, name_pth=\'features.20\', name_tf=\'Mixed_7c\')\n    load_mixed_7(state_dict, name_pth=\'features.21\', name_tf=\'Mixed_7d\')\n\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    model.eval()\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.zeros(1,299,299,3)\n    inputs[0] = torch.from_numpy(img)\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n    # 1, 3, 299, 299\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionV4/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionV4/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_4a_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d(module.branch1[3], name+\'/Branch_1/Conv2d_1a_3x3\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionV4()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n\n    # test_conv2d(model.features[0], \'Conv2d_1a_3x3\')\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    # test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n    \n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionv4.pth\')\n    torch.save(state_dict, \'save/inceptionv4_state.pth\')\n\n    outputs = test(model)\n\n\n'"
fastai/courses/dl2/fastai/models/nasnet.py,12,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\npretrained_settings = {\n    \'nasnetalarge\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1000\n        },\n        \'imagenet+background\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1001\n        }\n    }\n}\n\nclass MaxPoolPad(nn.Module):\n\n    def __init__(self):\n        super(MaxPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass AvgPoolPad(nn.Module):\n\n    def __init__(self, stride=2, padding=1):\n        super(AvgPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass SeparableConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n                                          stride=dw_stride,\n                                          padding=dw_padding,\n                                          bias=bias,\n                                          groups=in_channels)\n        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise_conv2d(x)\n        x = self.pointwise_conv2d(x)\n        return x\n\n\nclass BranchSeparables(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparables, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesStem(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparablesStem, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesReduction(BranchSeparables):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.padding(x)\n        x = self.separable_1(x)\n        x = x[:, :, 1:, 1:].contiguous()\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass CellStem0(nn.Module):\n\n    def __init__(self):\n        super(CellStem0, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(42, 42, 5, 2, 2)\n        self.comb_iter_0_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparablesStem(96, 42, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(42, 42, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x1 = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n        x_comb_iter_0_right = self.comb_iter_0_right(x)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n        x_comb_iter_1_right = self.comb_iter_1_right(x)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n        x_comb_iter_2_right = self.comb_iter_2_right(x)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass CellStem1(nn.Module):\n\n    def __init__(self):\n        super(CellStem1, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(168, 84, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(84, 84, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x_conv0, x_stem_0):\n        x_left = self.conv_1x1(x_stem_0)\n\n        x_relu = self.relu(x_conv0)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass FirstCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(FirstCell, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_relu = self.relu(x_prev)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NormalCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(NormalCell, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell0(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell0, self).__init__() \n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = MaxPoolPad()\n        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = AvgPoolPad()\n        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = MaxPoolPad()\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell1(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell1, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NASNetALarge(nn.Module):\n\n    def __init__(self, use_classifer=False, num_classes=1001):\n        super(NASNetALarge, self).__init__()\n        self.use_classifer,self.num_classes = use_classifer,num_classes\n\n        self.conv0 = nn.Sequential()\n        self.conv0.add_module(\'conv\', nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, padding=0, stride=2,\n                                                bias=False))\n        self.conv0.add_module(\'bn\', nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True))\n\n        self.cell_stem_0 = CellStem0()\n        self.cell_stem_1 = CellStem1()\n\n        self.cell_0 = FirstCell(in_channels_left=168, out_channels_left=84,\n                                in_channels_right=336, out_channels_right=168)\n        self.cell_1 = NormalCell(in_channels_left=336, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_2 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_3 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_4 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_5 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n\n        self.reduction_cell_0 = ReductionCell0(in_channels_left=1008, out_channels_left=336,\n                                               in_channels_right=1008, out_channels_right=336)\n\n        self.cell_6 = FirstCell(in_channels_left=1008, out_channels_left=168,\n                                in_channels_right=1344, out_channels_right=336)\n        self.cell_7 = NormalCell(in_channels_left=1344, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_8 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_9 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_10 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n        self.cell_11 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n\n        self.reduction_cell_1 = ReductionCell1(in_channels_left=2016, out_channels_left=672,\n                                               in_channels_right=2016, out_channels_right=672)\n\n        self.cell_12 = FirstCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2688, out_channels_right=672)\n        self.cell_13 = NormalCell(in_channels_left=2688, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_14 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_15 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_16 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_17 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout()\n        self.last_linear = nn.Linear(4032, self.num_classes)\n\n    def features(self, x):\n        x_conv0 = self.conv0(x)\n        x_stem_0 = self.cell_stem_0(x_conv0)\n        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n\n        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n        x_cell_4 = self.cell_4(x_cell_3, x_cell_2)\n        x_cell_5 = self.cell_5(x_cell_4, x_cell_3)\n\n        x_reduction_cell_0 = self.reduction_cell_0(x_cell_5, x_cell_4)\n\n        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_4)\n        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n        x_cell_10 = self.cell_10(x_cell_9, x_cell_8)\n        x_cell_11 = self.cell_11(x_cell_10, x_cell_9)\n\n        x_reduction_cell_1 = self.reduction_cell_1(x_cell_11, x_cell_10)\n\n        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_10)\n        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n        x_cell_16 = self.cell_16(x_cell_15, x_cell_14)\n        x_cell_17 = self.cell_17(x_cell_16, x_cell_15)\n        return self.relu(x_cell_17)\n\n    def classifier(self, x):\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        return F.log_softmax(self.linear(x))\n\n    def forward(self, x):\n        x = self.features(x)\n        if self.use_classifer: x = self.classifier(x)\n        return x\n\n\ndef nasnetalarge(num_classes=1000, pretrained=\'imagenet\'):\n    r""""""NASNetALarge model architecture from the\n    `""NASNet"" <https://arxiv.org/abs/1707.07012>`_ paper.\n    """"""\n    if pretrained:\n        settings = pretrained_settings[\'nasnetalarge\'][pretrained]\n        assert num_classes == settings[\'num_classes\'], \\\n            ""num_classes should be {}, but is {}"".format(settings[\'num_classes\'], num_classes)\n\n        # both \'imagenet\'&\'imagenet+background\' are loaded from same parameters\n        model = NASNetALarge(num_classes=1001)\n        model.load_state_dict(model_zoo.load_url(settings[\'url\']))\n\n        if pretrained == \'imagenet\':\n            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n            model.last_linear = new_last_linear\n\n        model.input_space = settings[\'input_space\']\n        model.input_size = settings[\'input_size\']\n        model.input_range = settings[\'input_range\']\n\n        model.mean = settings[\'mean\']\n        model.std = settings[\'std\']\n    else:\n        model = NASNetALarge(num_classes=num_classes)\n    return model\n'"
fastai/courses/dl2/fastai/models/resnet.py,4,"b""import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n__all__ = ['vgg_resnet50']\n\nmodel_urls = {\n    'vgg_resnet50': 'https://download.pytorch.org/models/vggresnet.pth',\n}\n\n\ndef conv(ni, nf, ks=3, stride=1):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, stride=stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out = residual + out\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out = residual + out\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [conv(3, 64, ks=7, stride=2)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv(self.inplanes, planes*block.expansion, ks=1, stride=stride),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 (): return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50(): return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck, [3, 4, 6, 3], k=1.125)\ndef vgg_resnet34(): return ResNet(BasicBlock, [3, 4, 6, 3], vgg_head=True)\ndef vgg_resnet50(pretrained=False):\n    model = ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n    if pretrained: model.load_state_dict(torch.load('/home/jhoward/.torch/models/vgg_resnet50.pth'))\n    return model\n\n"""
fastai/courses/dl2/fastai/models/resnext_101_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/dl2/fastai/models/resnext_101_64x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_64x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/dl2/fastai/models/resnext_50_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_50_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AdaptiveAvgPool2d(1),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)\n'"
fastai/courses/dl2/fastai/models/unet.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\n\ndef get_sfs_idxs(sfs, last=True):\n    """"""\n    Return the saved feature indexes that will be concatenated\n    Inputs:\n        sfs (list): saved features by hook function, in other words intermediate activations\n        last (bool): whether to concatenate only last different activation, or all from the encoder model\n    """"""\n    if last:\n        feature_szs = [sfs_feats.features.size()[-1] for sfs_feats in sfs]\n        sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n        if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n    else: sfs_idxs = list(range(len(sfs)))\n    return sfs_idxs\n\n\ndef conv_bn_relu(in_c, out_c, kernel_size, stride, padding):\n    return [\n        nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=stride, padding=padding),\n        nn.ReLU(),\n        nn.BatchNorm2d(out_c)]\n\n\nclass UnetBlock(nn.Module):\n    #TODO: ADAPT KERNEL SIZE, STRIDE AND PADDING SO THAT ANY SIZE DECAY WILL BE SUPPORTED\n    def __init__(self, up_in_c, x_in_c):\n        super().__init__()\n        self.upconv = nn.ConvTranspose2d(up_in_c, up_in_c // 2, 2, 2) # H, W -> 2H, 2W\n        self.conv1 = nn.Conv2d(x_in_c + up_in_c // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.conv2 = nn.Conv2d((x_in_c + up_in_c // 2) // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.bn = nn.BatchNorm2d((x_in_c + up_in_c // 2) // 2)\n\n    def forward(self, up_in, x_in):\n        up_out = self.upconv(up_in)\n        cat_x = torch.cat([up_out, x_in], dim=1)\n        x = F.relu(self.conv1(cat_x))\n        x = F.relu(self.conv2(x))\n        return self.bn(x)\n\nclass SaveFeatures():\n    """""" Extract pretrained activations""""""\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()\n\n\nclass DynamicUnet(nn.Module):\n    """"""\n    A dynamic implementation of Unet architecture, because calculating connections\n    and channels suck!. When an encoder is passed, this network will\n    automatically construct a decoder after the first single forward pass for any\n    given encoder architecture.\n\n    Decoder part is heavily based on the original Unet paper:\n    https://arxiv.org/abs/1505.04597.\n\n    Inputs:\n        encoder(nn.Module): Preferably a pretrained model, such as VGG or ResNet\n        last (bool): Whether to concat only last activation just before a size change\n        n_classes (int): Number of classes to output in final step of decoder\n\n    Important Note: If architecture directly reduces the dimension of an image as soon as the\n    first forward pass then output size will not be same as the input size, e.g. ResNet.\n    In order to resolve this problem architecture will add an additional extra conv transpose\n    layer. Also, currently Dynamic Unet expects size change to be H,W -> H/2, W/2. This is\n    not a problem for state-of-the-art architectures as they follow this pattern but it should\n    be changed for custom encoders that might have a different size decay.\n    """"""\n\n    def __init__(self, encoder, last=True, n_classes=3):\n        super().__init__()\n        self.encoder = encoder\n        self.n_children = len(list(encoder.children()))\n        self.sfs = [SaveFeatures(encoder[i]) for i in range(self.n_children)]\n        self.last = last\n        self.n_classes = n_classes\n\n    def forward(self, x):\n        # get imsize\n        imsize = x.size()[-2:]\n\n        # encoder output\n        x = F.relu(self.encoder(x))\n\n        # initialize sfs_idxs, sfs_szs, middle_in_c and middle_conv only once\n        if not hasattr(self, \'middle_conv\'):\n            self.sfs_szs = [sfs_feats.features.size() for sfs_feats in self.sfs]\n            self.sfs_idxs = get_sfs_idxs(self.sfs, self.last)\n            middle_in_c = self.sfs_szs[-1][1]\n            middle_conv = nn.Sequential(*conv_bn_relu(middle_in_c, middle_in_c * 2, 3, 1, 1),\n                                        *conv_bn_relu(middle_in_c * 2, middle_in_c, 3, 1, 1))\n            self.middle_conv = middle_conv\n\n        # middle conv\n        x = self.middle_conv(x)\n\n        # initialize upmodel, extra_block and 1x1 final conv\n        if not hasattr(self, \'upmodel\'):\n            x_copy = Variable(x.data, requires_grad=False)\n            upmodel = []\n            for idx in self.sfs_idxs[::-1]:\n                up_in_c, x_in_c = int(x_copy.size()[1]), int(self.sfs_szs[idx][1])\n                unet_block = UnetBlock(up_in_c, x_in_c)\n                upmodel.append(unet_block)\n                x_copy = unet_block(x_copy, self.sfs[idx].features)\n                self.upmodel = nn.Sequential(*upmodel)\n\n            if imsize != self.sfs_szs[0][-2:]:\n                extra_in_c = self.upmodel[-1].conv2.out_channels\n                self.extra_block = nn.ConvTranspose2d(extra_in_c, extra_in_c, 2, 2)\n\n            final_in_c = self.upmodel[-1].conv2.out_channels\n            self.final_conv = nn.Conv2d(final_in_c, self.n_classes, 1)\n\n        # run upsample\n        for block, idx in zip(self.upmodel, self.sfs_idxs[::-1]):\n            x = block(x, self.sfs[idx].features)\n        if hasattr(self, \'extra_block\'):\n            x = self.extra_block(x)\n\n        out = self.final_conv(x)\n        return out\n'"
fastai/courses/dl2/fastai/models/wideresnet.py,3,"b'# https://github.com/uoguelph-mlrg/Cutout\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super().__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut: x   = self.relu1(self.bn1(x))\n        else:                   out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super().__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x): return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super().__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert((depth - 4) % 6 == 0)\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear): m.bias.data.zero_()\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.adaptive_avg_pool2d(out, 1)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n'"
fastai/courses/dl2/fastai/models/wrn_50_2f.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef wrn_50_2f(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/ml1/fastai/models/convert_torch.py,13,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.serialization import load_lua\n\nimport numpy as np\nimport os\nimport math\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        # result is Variables list [Variable1, Variable2, ...]\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        # result is a Variable\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef copy_param(m,n):\n    if m.weight is not None: n.weight.data.copy_(m.weight)\n    if m.bias is not None: n.bias.data.copy_(m.bias)\n    if hasattr(n,\'running_mean\'): n.running_mean.copy_(m.running_mean)\n    if hasattr(n,\'running_var\'): n.running_var.copy_(m.running_var)\n\ndef add_submodule(seq, *args):\n    for n in args:\n        seq.add_module(str(len(seq._modules)),n)\n\ndef lua_recursive_model(module,seq):\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            n = nn.Conv2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,bias=(m.bias is not None))\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'SpatialBatchNormalization\':\n            n = nn.BatchNorm2d(m.running_mean.size(0), m.eps, m.momentum, m.affine)\n            copy_param(m,n)\n            add_submodule(seq,n)\n        elif name == \'ReLU\':\n            n = nn.ReLU()\n            add_submodule(seq,n)\n        elif name == \'SpatialMaxPooling\':\n            n = nn.MaxPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialAveragePooling\':\n            n = nn.AvgPool2d((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),ceil_mode=m.ceil_mode)\n            add_submodule(seq,n)\n        elif name == \'SpatialUpSamplingNearest\':\n            n = nn.UpsamplingNearest2d(scale_factor=m.scale_factor)\n            add_submodule(seq,n)\n        elif name == \'View\':\n            n = Lambda(lambda x: x.view(x.size(0),-1))\n            add_submodule(seq,n)\n        elif name == \'Linear\':\n            # Linear in pytorch only accept 2D input\n            n1 = Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\n            n2 = nn.Linear(m.weight.size(1),m.weight.size(0),bias=(m.bias is not None))\n            copy_param(m,n2)\n            n = nn.Sequential(n1,n2)\n            add_submodule(seq,n)\n        elif name == \'Dropout\':\n            m.inplace = False\n            n = nn.Dropout(m.p)\n            add_submodule(seq,n)\n        elif name == \'SoftMax\':\n            n = nn.Softmax()\n            add_submodule(seq,n)\n        elif name == \'Identity\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'SpatialFullConvolution\':\n            n = nn.ConvTranspose2d(m.nInputPlane,m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))\n            add_submodule(seq,n)\n        elif name == \'SpatialReplicationPadding\':\n            n = nn.ReplicationPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'SpatialReflectionPadding\':\n            n = nn.ReflectionPad2d((m.pad_l,m.pad_r,m.pad_t,m.pad_b))\n            add_submodule(seq,n)\n        elif name == \'Copy\':\n            n = Lambda(lambda x: x) # do nothing\n            add_submodule(seq,n)\n        elif name == \'Narrow\':\n            n = Lambda(lambda x,a=(m.dimension,m.index,m.length): x.narrow(*a))\n            add_submodule(seq,n)\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = torch.legacy.nn.SpatialCrossMapLRN(m.size,m.alpha,m.beta,m.k)\n            n = Lambda(lambda x,lrn=lrn: Variable(lrn.forward(x.data)))\n            add_submodule(seq,n)\n        elif name == \'Sequential\':\n            n = nn.Sequential()\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'ConcatTable\': # output is list\n            n = LambdaMap(lambda x: x)\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'CAddTable\': # input is list\n            n = LambdaReduce(lambda x,y: x+y)\n            add_submodule(seq,n)\n        elif name == \'Concat\':\n            dim = m.dimension\n            n = LambdaReduce(lambda x,y,dim=dim: torch.cat((x,y),dim))\n            lua_recursive_model(m,n)\n            add_submodule(seq,n)\n        elif name == \'TorchObject\':\n            print(\'Not Implement\',name,real._typename)\n        else:\n            print(\'Not Implement\',name)\n\n\ndef lua_recursive_source(module):\n    s = []\n    for m in module.modules:\n        name = type(m).__name__\n        real = m\n        if name == \'TorchObject\':\n            name = m._typename.replace(\'cudnn.\',\'\')\n            m = m._obj\n\n        if name == \'SpatialConvolution\':\n            if not hasattr(m,\'groups\'): m.groups=1\n            s += [\'nn.Conv2d({},{},{},{},{},{},{},bias={}),#Conv2d\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),1,m.groups,m.bias is not None)]\n        elif name == \'SpatialBatchNormalization\':\n            s += [\'nn.BatchNorm2d({},{},{},{}),#BatchNorm2d\'.format(m.running_mean.size(0), m.eps, m.momentum, m.affine)]\n        elif name == \'ReLU\':\n            s += [\'nn.ReLU()\']\n        elif name == \'SpatialMaxPooling\':\n            s += [\'nn.MaxPool2d({},{},{},ceil_mode={}),#MaxPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialAveragePooling\':\n            s += [\'nn.AvgPool2d({},{},{},ceil_mode={}),#AvgPool2d\'.format((m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH),m.ceil_mode)]\n        elif name == \'SpatialUpSamplingNearest\':\n            s += [\'nn.UpsamplingNearest2d(scale_factor={})\'.format(m.scale_factor)]\n        elif name == \'View\':\n            s += [\'Lambda(lambda x: x.view(x.size(0),-1)), # View\']\n        elif name == \'Linear\':\n            s1 = \'Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x )\'\n            s2 = \'nn.Linear({},{},bias={})\'.format(m.weight.size(1),m.weight.size(0),(m.bias is not None))\n            s += [\'nn.Sequential({},{}),#Linear\'.format(s1,s2)]\n        elif name == \'Dropout\':\n            s += [\'nn.Dropout({})\'.format(m.p)]\n        elif name == \'SoftMax\':\n            s += [\'nn.Softmax()\']\n        elif name == \'Identity\':\n            s += [\'Lambda(lambda x: x), # Identity\']\n        elif name == \'SpatialFullConvolution\':\n            s += [\'nn.ConvTranspose2d({},{},{},{},{})\'.format(m.nInputPlane,\n                m.nOutputPlane,(m.kW,m.kH),(m.dW,m.dH),(m.padW,m.padH))]\n        elif name == \'SpatialReplicationPadding\':\n            s += [\'nn.ReplicationPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'SpatialReflectionPadding\':\n            s += [\'nn.ReflectionPad2d({})\'.format((m.pad_l,m.pad_r,m.pad_t,m.pad_b))]\n        elif name == \'Copy\':\n            s += [\'Lambda(lambda x: x), # Copy\']\n        elif name == \'Narrow\':\n            s += [\'Lambda(lambda x,a={}: x.narrow(*a))\'.format((m.dimension,m.index,m.length))]\n        elif name == \'SpatialCrossMapLRN\':\n            lrn = \'torch.legacy.nn.SpatialCrossMapLRN(*{})\'.format((m.size,m.alpha,m.beta,m.k))\n            s += [\'Lambda(lambda x,lrn={}: Variable(lrn.forward(x.data)))\'.format(lrn)]\n\n        elif name == \'Sequential\':\n            s += [\'nn.Sequential( # Sequential\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'ConcatTable\':\n            s += [\'LambdaMap(lambda x: x, # ConcatTable\']\n            s += lua_recursive_source(m)\n            s += [\')\']\n        elif name == \'CAddTable\':\n            s += [\'LambdaReduce(lambda x,y: x+y), # CAddTable\']\n        elif name == \'Concat\':\n            dim = m.dimension\n            s += [\'LambdaReduce(lambda x,y,dim={}: torch.cat((x,y),dim), # Concat\'.format(m.dimension)]\n            s += lua_recursive_source(m)\n            s += [\')\']\n        else:\n            s += \'# \' + name + \' Not Implement,\\n\'\n    s = map(lambda x: \'\\t{}\'.format(x),s)\n    return s\n\ndef simplify_source(s):\n    s = map(lambda x: x.replace(\',(1, 1),(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1,1,bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#Conv2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',1e-05,0.1,True),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#BatchNorm2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\'),#MaxPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',(0, 0),ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',ceil_mode=False),#AvgPool2d\',\')\'),s)\n    s = map(lambda x: x.replace(\',bias=True)),#Linear\',\')), # Linear\'),s)\n    s = map(lambda x: x.replace(\')),#Linear\',\')), # Linear\'),s)\n    \n    s = map(lambda x: \'{},\\n\'.format(x),s)\n    s = map(lambda x: x[1:],s)\n    s = reduce(lambda x,y: x+y, s)\n    return s\n\ndef torch_to_pytorch(t7_filename,outputname=None):\n    model = load_lua(t7_filename,unknown_classes=True)\n    if type(model).__name__==\'hashable_uniq_dict\': model=model.model\n    model.gradInput = None\n    slist = lua_recursive_source(torch.legacy.nn.Sequential().add(model))\n    s = simplify_source(slist)\n    header = \'\'\'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\'\'\'\n    varname = t7_filename.replace(\'.t7\',\'\').replace(\'.\',\'_\').replace(\'-\',\'_\')\n    s = \'{}\\n\\n{} = {}\'.format(header,varname,s[:-2])\n\n    if outputname is None: outputname=varname\n    with open(outputname+\'.py\', ""w"") as pyfile:\n        pyfile.write(s)\n\n    n = nn.Sequential()\n    lua_recursive_model(model,n)\n    torch.save(n.state_dict(),outputname+\'.pth\')\n\n\nparser = argparse.ArgumentParser(description=\'Convert torch t7 model to pytorch\')\nparser.add_argument(\'--model\',\'-m\', type=str, required=True,\n                    help=\'torch model file in t7 format\')\nparser.add_argument(\'--output\', \'-o\', type=str, default=None,\n                    help=\'output file name prefix, xxx.py xxx.pth\')\nargs = parser.parse_args()\n\ntorch_to_pytorch(args.model,args.output)\n'"
fastai/courses/ml1/fastai/models/darknet.py,2,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom .layers import *\n\nclass ConvBN(nn.Module):\n    ""convolutional layer then batchnorm""\n\n    def __init__(self, ch_in, ch_out, kernel_size = 3, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(ch_in, ch_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(ch_out, momentum=0.01)\n        self.relu = nn.LeakyReLU(0.1, inplace=True)\n\n    def forward(self, x): return self.relu(self.bn(self.conv(x)))\n\nclass DarknetBlock(nn.Module):\n    def __init__(self, ch_in):\n        super().__init__()\n        ch_hid = ch_in//2\n        self.conv1 = ConvBN(ch_in, ch_hid, kernel_size=1, stride=1, padding=0)\n        self.conv2 = ConvBN(ch_hid, ch_in, kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x): return self.conv2(self.conv1(x)) + x\n\nclass Darknet(nn.Module):\n    ""Replicates the darknet classifier from the YOLOv3 paper (table 1)""\n\n    def make_group_layer(self, ch_in, num_blocks, stride=1):\n        layers = [ConvBN(ch_in,ch_in*2,stride=stride)]\n        for i in range(num_blocks): layers.append(DarknetBlock(ch_in*2))\n        return layers\n\n    def __init__(self, num_blocks, num_classes=1000, start_nf=32):\n        super().__init__()\n        nf = start_nf\n        layers = [ConvBN(3, nf, kernel_size=3, stride=1, padding=1)]\n        for i,nb in enumerate(num_blocks):\n            layers += self.make_group_layer(nf, nb, stride=(1 if i==1 else 2))\n            nf *= 2\n        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x): return self.layers(x)\n\ndef darknet_53(num_classes=1000):    return Darknet([1,2,8,8,4], num_classes)\ndef darknet_small(num_classes=1000): return Darknet([1,2,4,8,4], num_classes)\ndef darknet_mini(num_classes=1000): return Darknet([1,2,4,4,2], num_classes, start_nf=24)\ndef darknet_mini2(num_classes=1000): return Darknet([1,2,8,8,4], num_classes, start_nf=16)\ndef darknet_mini3(num_classes=1000): return Darknet([1,2,4,4], num_classes)\n\n'"
fastai/courses/ml1/fastai/models/fa_resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out += residual\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out += residual\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = bn(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = bn(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\ndef load(model, pre, name):\n    if pretrained: model.load_state_dict(model_zoo.load_url(model_urls[name]))\n    return model\n\ndef fa_resnet18(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [2, 2, 2, 2], **kwargs), pretrained, \'resnet18\')\ndef fa_resnet34(pretrained=False, **kwargs):  return load(ResNet(BasicBlock, [3, 4, 6, 3], **kwargs), pretrained, \'resnet34\')\ndef fa_resnet50(pretrained=False, **kwargs):  return load(ResNet(Bottleneck, [3, 4, 6, 3], **kwargs), pretrained, \'resnet50\')\ndef fa_resnet101(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 4, 23, 3], **kwargs), pretrained, \'resnet101\')\ndef fa_resnet152(pretrained=False, **kwargs): return load(ResNet(Bottleneck, [3, 8, 36, 3], **kwargs), pretrained, \'resnet152\')\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 ():  return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50():  return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck,[3, 4, 6, 3], k=1.125)\ndef vgg_resnet50():  return ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n\n'"
fastai/courses/ml1/fastai/models/inceptionresnetv2.py,31,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'http://webia.lip6.fr/~cadene/Downloads/inceptionresnetv2-d579a627.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_5b(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5b, self).__init__()\n\n        self.branch0 = BasicConv2d(192, 96, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(192, 48, kernel_size=1, stride=1),\n            BasicConv2d(48, 64, kernel_size=5, stride=1, padding=2)\n        ) \n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(192, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(192, 64, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block35(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block35, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(320, 32, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(320, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 48, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(48, 64, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.conv2d = nn.Conv2d(128, 320, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_6a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_6a, self).__init__()\n        \n        self.branch0 = BasicConv2d(320, 384, kernel_size=3, stride=2)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(320, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Block17(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super(Block17, self).__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(1088, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 128, kernel_size=1, stride=1),\n            BasicConv2d(128, 160, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(160, 192, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.conv2d = nn.Conv2d(384, 1088, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\nclass Mixed_7a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_7a, self).__init__()\n        \n        self.branch0 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 288, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(288, 320, kernel_size=3, stride=2)\n        )\n\n        self.branch3 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Block8(nn.Module):\n\n    def __init__(self, scale=1.0, noReLU=False):\n        super(Block8, self).__init__()\n\n        self.scale = scale\n        self.noReLU = noReLU\n\n        self.branch0 = BasicConv2d(2080, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(2080, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,3), stride=1, padding=(0,1)),\n            BasicConv2d(224, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        )\n\n        self.conv2d = nn.Conv2d(448, 2080, kernel_size=1, stride=1)\n        if not self.noReLU:\n            self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        if not self.noReLU:\n            out = self.relu(out)\n        return out\n\n\nclass InceptionResnetV2(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionResnetV2, self).__init__()\n        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n        self.maxpool_5a = nn.MaxPool2d(3, stride=2)\n        self.mixed_5b = Mixed_5b()\n        self.repeat = nn.Sequential(\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17)\n        )\n        self.mixed_6a = Mixed_6a()\n        self.repeat_1 = nn.Sequential(\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10)\n        )\n        self.mixed_7a = Mixed_7a()\n        self.repeat_2 = nn.Sequential(\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20)\n        )\n        self.block8 = Block8(noReLU=True)\n        self.conv2d_7b = BasicConv2d(2080, 1536, kernel_size=1, stride=1)\n        self.avgpool_1a = nn.AdaptiveAvgPool2d((1,1))\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.conv2d_1a(x)\n        x = self.conv2d_2a(x)\n        x = self.conv2d_2b(x)\n        x = self.maxpool_3a(x)\n        x = self.conv2d_3b(x)\n        x = self.conv2d_4a(x)\n        x = self.maxpool_5a(x)\n        x = self.mixed_5b(x)\n        x = self.repeat(x)\n        x = self.mixed_6a(x)\n        x = self.repeat_1(x)\n        x = self.mixed_7a(x)\n        x = self.repeat_2(x)\n        x = self.block8(x)\n        x = self.conv2d_7b(x)\n        x = self.avgpool_1a(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\ndef inceptionresnetv2(pretrained=True):\n    r""""""InceptionResnetV2 model architecture from the\n    `""InceptionV4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (\'string\'): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionResnetV2()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_conv2d_nobn(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_5b(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_5x5\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_block35(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_6a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_block17(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\ndef load_mixed_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef load_block8(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d_nobn(state_dict, name_pth+\'.conv2d\', name_tf+\'/Conv2d_1x1\')\n\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_1a\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2a\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'conv2d_2b\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'conv2d_3b\', name_tf=\'Conv2d_3b_1x1\')\n    load_conv2d(state_dict, name_pth=\'conv2d_4a\', name_tf=\'Conv2d_4a_3x3\')\n\n    load_mixed_5b(state_dict, name_pth=\'mixed_5b\', name_tf=\'Mixed_5b\')\n\n    for i in range(10):\n        load_block35(state_dict, name_pth=\'repeat.\'+str(i), name_tf=\'Repeat/block35_\'+str(i+1))\n\n    load_mixed_6a(state_dict, name_pth=\'mixed_6a\', name_tf=\'Mixed_6a\')\n\n    for i in range(20):\n        load_block17(state_dict, name_pth=\'repeat_1.\'+str(i), name_tf=\'Repeat_1/block17_\'+str(i+1))\n\n    load_mixed_7a(state_dict, name_pth=\'mixed_7a\', name_tf=\'Mixed_7a\')\n\n    for i in range(9):\n        load_block8(state_dict, name_pth=\'repeat_2.\'+str(i), name_tf=\'Repeat_2/block8_\'+str(i+1))\n\n    load_block8(state_dict, name_pth=\'block8\', name_tf=\'Block8\')\n    load_conv2d(state_dict, name_pth=\'conv2d_7b\', name_tf=\'Conv2d_7b_1x1\')\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.ones(1,299,299,3)\n    #inputs[0] = torch.from_numpy(img)\n\n    inputs[0,0,0,0] = -1\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n\n    print(inputs.mean())\n    print(inputs.std())\n\n    #inputs.sub_(0.5).div_(0.5)\n    #inputs.sub_(inputs)\n    # 1, 3, 299, 299\n\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionResnetV2/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(outputs.sum())\n    print(outputs[0])\n    print(outputs_tf.sum())\n    print(outputs_tf[0])\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf_conv = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf_conv.transpose_(1,3)\n    output_tf_conv.transpose_(2,3)\n    output_tf_relu = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf_relu.transpose_(1,3)\n    output_tf_relu.transpose_(2,3)\n    h5f.close()\n    def test_dist_conv(self, input, output):\n        print(name, \'conv\', torch.dist(output.data, output_tf_conv))\n    module.conv.register_forward_hook(test_dist_conv)\n    def test_dist_relu(self, input, output):\n        print(name, \'relu\', torch.dist(output.data, output_tf_relu))\n    module.relu.register_forward_hook(test_dist_relu)\n\ndef test_conv2d_nobn(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionResnetV2/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'conv_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, \'conv+bias\', torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_5b(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_5x5\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d(module.branch3[1], name+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef test_block35(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_0c_3x3\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_6a(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_3x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef test_block17(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\ndef test_mixed_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_1a_3x3\')\n    test_conv2d(module.branch2[0], name+\'/Branch_2/Conv2d_0a_1x1\')\n    test_conv2d(module.branch2[1], name+\'/Branch_2/Conv2d_0b_3x3\')\n    test_conv2d(module.branch2[2], name+\'/Branch_2/Conv2d_1a_3x3\')\n\ndef test_block8(module, name):\n    test_conv2d(module.branch0, name+\'/Branch_0/Conv2d_1x1\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x3\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_3x1\')\n    test_conv2d_nobn(module.conv2d, name+\'/Conv2d_1x1\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionResnetV2()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n    model.eval()\n\n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionresnetv2.pth\')\n    torch.save(state_dict, \'save/inceptionresnetv2_state.pth\')\n\n    test_conv2d(model.conv2d_1a, \'Conv2d_1a_3x3\')\n    test_conv2d(model.conv2d_2a, \'Conv2d_2a_3x3\')\n    test_conv2d(model.conv2d_2b, \'Conv2d_2b_3x3\')\n    test_conv2d(model.conv2d_3b, \'Conv2d_3b_1x1\')\n    test_conv2d(model.conv2d_4a, \'Conv2d_4a_3x3\')\n\n    test_mixed_5b(model.mixed_5b, \'Mixed_5b\')\n\n    for i in range(len(model.repeat._modules)):\n        test_block35(model.repeat[i], \'Repeat/block35_\'+str(i+1))\n\n    test_mixed_6a(model.mixed_6a, \'Mixed_6a\')\n\n    for i in range(len(model.repeat_1._modules)):\n        test_block17(model.repeat_1[i], \'Repeat_1/block17_\'+str(i+1))\n\n    test_mixed_7a(model.mixed_7a, \'Mixed_7a\')\n\n    for i in range(len(model.repeat_2._modules)):\n        test_block8(model.repeat_2[i], \'Repeat_2/block8_\'+str(i+1))\n\n    test_block8(model.block8, \'Block8\')\n\n    test_conv2d(model.conv2d_7b, \'Conv2d_7b_1x1\')\n\n    outputs = test(model)\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    #test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n\n'"
fastai/courses/ml1/fastai/models/inceptionv4.py,29,"b'import torch\nimport torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport os\nimport sys\n\nmodel_urls = {\n    \'imagenet\': \'https://s3.amazonaws.com/pytorch/models/inceptionv4-58153ba9.pth\'\n}\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\nclass Mixed_3a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_3a, self).__init__()\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n\n    def forward(self, x):\n        x0 = self.maxpool(x)\n        x1 = self.conv(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_4a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_4a, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(160, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(64, 96, kernel_size=(3,3), stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Mixed_5a(nn.Module):\n\n    def __init__(self):\n        super(Mixed_5a, self).__init__()\n        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n        self.maxpool = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.conv(x)\n        x1 = self.maxpool(x)\n        out = torch.cat((x0, x1), 1)\n        return out\n\nclass Inception_A(nn.Module):\n\n    def __init__(self):\n        super(Inception_A, self).__init__()\n        self.block0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(384, 64, kernel_size=1, stride=1),\n            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(384, 96, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_A(nn.Module):\n\n    def __init__(self):\n        super(Reduction_A, self).__init__()\n        self.block0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(384, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(224, 256, kernel_size=3, stride=2)\n        )\n        \n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_B(nn.Module):\n\n    def __init__(self):\n        super(Inception_B, self).__init__()\n        self.block0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n        \n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.block2 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n        )\n\n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        x3 = self.block3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass Reduction_B(nn.Module):\n\n    def __init__(self):\n        super(Reduction_B, self).__init__()\n\n        self.block0 = nn.Sequential(\n            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=3, stride=2)\n        )\n\n        self.block1 = nn.Sequential(\n            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n            BasicConv2d(320, 320, kernel_size=3, stride=2)\n        )\n\n        self.block2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        x1 = self.block1(x)\n        x2 = self.block2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\nclass Inception_C(nn.Module):\n\n    def __init__(self):\n        super(Inception_C, self).__init__()\n        self.block0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        \n        self.block1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n        self.block2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n        self.block2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3a = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n        self.block2_3b = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n        \n        self.block3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n        )\n\n    def forward(self, x):\n        x0 = self.block0(x)\n        \n        x1_0 = self.block1_0(x)\n        x1_1a = self.block1_1a(x1_0)\n        x1_1b = self.block1_1b(x1_0)\n        x1 = torch.cat((x1_1a, x1_1b), 1)\n\n        x2_0 = self.block2_0(x)\n        x2_1 = self.block2_1(x2_0)\n        x2_2 = self.block2_2(x2_1)\n        x2_3a = self.block2_3a(x2_2)\n        x2_3b = self.block2_3b(x2_2)\n        x2 = torch.cat((x2_3a, x2_3b), 1)\n\n        x3 = self.block3(x)\n\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\nclass InceptionV4(nn.Module):\n\n    def __init__(self, num_classes=1001):\n        super(InceptionV4, self).__init__()\n        self.features = nn.Sequential(\n            BasicConv2d(3, 32, kernel_size=3, stride=2),\n            BasicConv2d(32, 32, kernel_size=3, stride=1),\n            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            Mixed_3a(),\n            Mixed_4a(),\n            Mixed_5a(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Inception_A(),\n            Reduction_A(), # Mixed_6a\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Inception_B(),\n            Reduction_B(), # Mixed_7a\n            Inception_C(),\n            Inception_C(),\n            Inception_C(),\n            nn.AdaptiveAvgPool2d((1,1))\n        )\n        self.classif = nn.Linear(1536, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classif(x) \n        return x\n\n\ndef inceptionv4(pretrained=True):\n    r""""""InceptionV4 model architecture from the\n    `""Inception-v4, Inception-ResNet..."" <https://arxiv.org/abs/1602.07261>`_ paper.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = InceptionV4()\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'imagenet\']))\n    return model\n\n######################################################################\n## Load parameters from HDF5 to Dict\n######################################################################\n\ndef load_conv2d(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.conv.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).permute(3, 2, 0, 1)\n    out_planes = state_dict[name_pth+\'.conv.weight\'].size(0)\n    state_dict[name_pth+\'.bn.weight\'] = torch.ones(out_planes)\n    state_dict[name_pth+\'.bn.bias\'] = torch.from_numpy(h5f[\'beta\'][()])\n    state_dict[name_pth+\'.bn.running_mean\'] = torch.from_numpy(h5f[\'mean\'][()])\n    state_dict[name_pth+\'.bn.running_var\'] = torch.from_numpy(h5f[\'var\'][()])\n    h5f.close()\n\ndef load_linear(state_dict, name_pth, name_tf):\n    h5f = h5py.File(\'dump/InceptionV4/\'+name_tf+\'.h5\', \'r\')\n    state_dict[name_pth+\'.weight\'] = torch.from_numpy(h5f[\'weights\'][()]).t()\n    state_dict[name_pth+\'.bias\'] = torch.from_numpy(h5f[\'biases\'][()])\n    h5f.close()\n\ndef load_mixed_4a_7a(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0.0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch0.1\', name_tf+\'/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.3\', name_tf+\'/Branch_1/Conv2d_1a_3x3\')\n\ndef load_mixed_5(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_3x3\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_6(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1.1\', name_tf+\'/Branch_1/Conv2d_0b_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch1.2\', name_tf+\'/Branch_1/Conv2d_0c_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.1\', name_tf+\'/Branch_2/Conv2d_0b_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.2\', name_tf+\'/Branch_2/Conv2d_0c_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch2.3\', name_tf+\'/Branch_2/Conv2d_0d_7x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2.4\', name_tf+\'/Branch_2/Conv2d_0e_1x7\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\ndef load_mixed_7(state_dict, name_pth, name_tf):\n    load_conv2d(state_dict, name_pth+\'.branch0\', name_tf+\'/Branch_0/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_0\', name_tf+\'/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1a\', name_tf+\'/Branch_1/Conv2d_0b_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch1_1b\', name_tf+\'/Branch_1/Conv2d_0c_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_0\', name_tf+\'/Branch_2/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_1\', name_tf+\'/Branch_2/Conv2d_0b_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch2_2\', name_tf+\'/Branch_2/Conv2d_0c_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3a\', name_tf+\'/Branch_2/Conv2d_0d_1x3\')\n    load_conv2d(state_dict, name_pth+\'.branch2_3b\', name_tf+\'/Branch_2/Conv2d_0e_3x1\')\n    load_conv2d(state_dict, name_pth+\'.branch3.1\', name_tf+\'/Branch_3/Conv2d_0b_1x1\')\n\n\ndef load():\n    state_dict={}\n    \n    load_conv2d(state_dict, name_pth=\'features.0\', name_tf=\'Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.1\', name_tf=\'Conv2d_2a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.2\', name_tf=\'Conv2d_2b_3x3\')\n    \n    load_conv2d(state_dict, name_pth=\'features.3.conv\', name_tf=\'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.4\', name_tf=\'Mixed_4a\')\n\n    load_conv2d(state_dict, name_pth=\'features.5.conv\', name_tf=\'Mixed_5a/Branch_0/Conv2d_1a_3x3\')\n\n    load_mixed_5(state_dict, name_pth=\'features.6\', name_tf=\'Mixed_5b\')\n    load_mixed_5(state_dict, name_pth=\'features.7\', name_tf=\'Mixed_5c\')\n    load_mixed_5(state_dict, name_pth=\'features.8\', name_tf=\'Mixed_5d\')\n    load_mixed_5(state_dict, name_pth=\'features.9\', name_tf=\'Mixed_5e\')\n\n    load_conv2d(state_dict, name_pth=\'features.10.branch0\', name_tf=\'Mixed_6a/Branch_0/Conv2d_1a_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.0\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0a_1x1\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.1\', name_tf=\'Mixed_6a/Branch_1/Conv2d_0b_3x3\')\n    load_conv2d(state_dict, name_pth=\'features.10.branch1.2\', name_tf=\'Mixed_6a/Branch_1/Conv2d_1a_3x3\')\n\n    load_mixed_6(state_dict, name_pth=\'features.11\', name_tf=\'Mixed_6b\')\n    load_mixed_6(state_dict, name_pth=\'features.12\', name_tf=\'Mixed_6c\')\n    load_mixed_6(state_dict, name_pth=\'features.13\', name_tf=\'Mixed_6d\')\n    load_mixed_6(state_dict, name_pth=\'features.14\', name_tf=\'Mixed_6e\')\n    load_mixed_6(state_dict, name_pth=\'features.15\', name_tf=\'Mixed_6f\')\n    load_mixed_6(state_dict, name_pth=\'features.16\', name_tf=\'Mixed_6g\')\n    load_mixed_6(state_dict, name_pth=\'features.17\', name_tf=\'Mixed_6h\')\n\n    load_mixed_4a_7a(state_dict, name_pth=\'features.18\', name_tf=\'Mixed_7a\')\n\n    load_mixed_7(state_dict, name_pth=\'features.19\', name_tf=\'Mixed_7b\')\n    load_mixed_7(state_dict, name_pth=\'features.20\', name_tf=\'Mixed_7c\')\n    load_mixed_7(state_dict, name_pth=\'features.21\', name_tf=\'Mixed_7d\')\n\n    load_linear(state_dict, name_pth=\'classif\', name_tf=\'Logits\')\n\n    return state_dict\n\n######################################################################\n## Test\n######################################################################\n\ndef test(model):\n    model.eval()\n    from scipy import misc\n    img = misc.imread(\'lena_299.png\')\n    inputs = torch.zeros(1,299,299,3)\n    inputs[0] = torch.from_numpy(img)\n    inputs.transpose_(1,3)\n    inputs.transpose_(2,3)\n    # 1, 3, 299, 299\n    outputs = model.forward(torch.autograd.Variable(inputs))\n    h5f = h5py.File(\'dump/InceptionV4/Logits.h5\', \'r\')\n    outputs_tf = torch.from_numpy(h5f[\'out\'][()])\n    h5f.close()\n    outputs = torch.nn.functional.softmax(outputs)\n    print(torch.dist(outputs.data, outputs_tf))\n    return outputs\n \ndef test_conv2d(module, name):\n    #global output_tf\n    h5f = h5py.File(\'dump/InceptionV4/\'+name+\'.h5\', \'r\')\n    output_tf = torch.from_numpy(h5f[\'relu_out\'][()])\n    output_tf.transpose_(1,3)\n    output_tf.transpose_(2,3)\n    h5f.close()\n    def test_dist(self, input, output):\n        print(name, torch.dist(output.data, output_tf))\n    module.register_forward_hook(test_dist)\n\ndef test_mixed_4a_7a(module, name):\n    test_conv2d(module.branch0[0], name+\'/Branch_0/Conv2d_0a_1x1\')\n    test_conv2d(module.branch0[1], name+\'/Branch_0/Conv2d_1a_3x3\')\n    test_conv2d(module.branch1[0], name+\'/Branch_1/Conv2d_0a_1x1\')\n    test_conv2d(module.branch1[1], name+\'/Branch_1/Conv2d_0b_1x7\')\n    test_conv2d(module.branch1[2], name+\'/Branch_1/Conv2d_0c_7x1\')\n    test_conv2d(module.branch1[3], name+\'/Branch_1/Conv2d_1a_3x3\')\n\n######################################################################\n## Main\n######################################################################\n\nif __name__ == ""__main__"":\n\n    import h5py\n\n    model = InceptionV4()\n    state_dict = load()\n    model.load_state_dict(state_dict)\n\n    # test_conv2d(model.features[0], \'Conv2d_1a_3x3\')\n    # test_conv2d(model.features[1], \'Conv2d_2a_3x3\')\n    # test_conv2d(model.features[2], \'Conv2d_2b_3x3\')\n    # test_conv2d(model.features[3].conv, \'Mixed_3a/Branch_1/Conv2d_0a_3x3\')\n    # test_mixed_4a_7a(model.features[4], \'Mixed_4a\')\n    \n    os.system(\'mkdir -p save\')\n    torch.save(model, \'save/inceptionv4.pth\')\n    torch.save(state_dict, \'save/inceptionv4_state.pth\')\n\n    outputs = test(model)\n\n\n'"
fastai/courses/ml1/fastai/models/nasnet.py,12,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\n\npretrained_settings = {\n    \'nasnetalarge\': {\n        \'imagenet\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1000\n        },\n        \'imagenet+background\': {\n            \'url\': \'http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\',\n            \'input_space\': \'RGB\',\n            \'input_size\': [3, 331, 331], # resize 354\n            \'input_range\': [0, 1],\n            \'mean\': [0.5, 0.5, 0.5],\n            \'std\': [0.5, 0.5, 0.5],\n            \'num_classes\': 1001\n        }\n    }\n}\n\nclass MaxPoolPad(nn.Module):\n\n    def __init__(self):\n        super(MaxPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass AvgPoolPad(nn.Module):\n\n    def __init__(self, stride=2, padding=1):\n        super(AvgPoolPad, self).__init__()\n        self.pad = nn.ZeroPad2d((1, 0, 1, 0))\n        self.pool = nn.AvgPool2d(3, stride=stride, padding=padding, count_include_pad=False)\n\n    def forward(self, x):\n        x = self.pad(x)\n        x = self.pool(x)\n        x = x[:, :, 1:, 1:]\n        return x\n\n\nclass SeparableConv2d(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dw_kernel, dw_stride, dw_padding, bias=False):\n        super(SeparableConv2d, self).__init__()\n        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels, dw_kernel,\n                                          stride=dw_stride,\n                                          padding=dw_padding,\n                                          bias=bias,\n                                          groups=in_channels)\n        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels, 1, stride=1, bias=bias)\n\n    def forward(self, x):\n        x = self.depthwise_conv2d(x)\n        x = self.pointwise_conv2d(x)\n        return x\n\n\nclass BranchSeparables(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparables, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, in_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(in_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(in_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesStem(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias=False):\n        super(BranchSeparablesStem, self).__init__()\n        self.relu = nn.ReLU()\n        self.separable_1 = SeparableConv2d(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n        self.bn_sep_1 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n        self.relu1 = nn.ReLU()\n        self.separable_2 = SeparableConv2d(out_channels, out_channels, kernel_size, 1, padding, bias=bias)\n        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1, affine=True)\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.separable_1(x)\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass BranchSeparablesReduction(BranchSeparables):\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, z_padding=1, bias=False):\n        BranchSeparables.__init__(self, in_channels, out_channels, kernel_size, stride, padding, bias)\n        self.padding = nn.ZeroPad2d((z_padding, 0, z_padding, 0))\n\n    def forward(self, x):\n        x = self.relu(x)\n        x = self.padding(x)\n        x = self.separable_1(x)\n        x = x[:, :, 1:, 1:].contiguous()\n        x = self.bn_sep_1(x)\n        x = self.relu1(x)\n        x = self.separable_2(x)\n        x = self.bn_sep_2(x)\n        return x\n\n\nclass CellStem0(nn.Module):\n\n    def __init__(self):\n        super(CellStem0, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(42, 42, 5, 2, 2)\n        self.comb_iter_0_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparablesStem(96, 42, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparablesStem(96, 42, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(42, 42, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x):\n        x1 = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x1)\n        x_comb_iter_0_right = self.comb_iter_0_right(x)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x1)\n        x_comb_iter_1_right = self.comb_iter_1_right(x)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x1)\n        x_comb_iter_2_right = self.comb_iter_2_right(x)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x1)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass CellStem1(nn.Module):\n\n    def __init__(self):\n        super(CellStem1, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(168, 84, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(96, 42, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(84, 84, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(84, 84, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(84, 84, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x_conv0, x_stem_0):\n        x_left = self.conv_1x1(x_stem_0)\n\n        x_relu = self.relu(x_conv0)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_right = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_right)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_left)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_left)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass FirstCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(FirstCell, self).__init__()\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.relu = nn.ReLU()\n        self.path_1 = nn.Sequential()\n        self.path_1.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.path_2 = nn.ModuleList()\n        self.path_2.add_module(\'pad\', nn.ZeroPad2d((0, 1, 0, 1)))\n        self.path_2.add_module(\'avgpool\', nn.AvgPool2d(1, stride=2, count_include_pad=False))\n        self.path_2.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n\n        self.final_path_bn = nn.BatchNorm2d(out_channels_left * 2, eps=0.001, momentum=0.1, affine=True)\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_relu = self.relu(x_prev)\n        # path 1\n        x_path1 = self.path_1(x_relu)\n        # path 2\n        x_path2 = self.path_2.pad(x_relu)\n        x_path2 = x_path2[:, :, 1:, 1:]\n        x_path2 = self.path_2.avgpool(x_path2)\n        x_path2 = self.path_2.conv(x_path2)\n        # final path\n        x_left = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NormalCell(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(NormalCell, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 1, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_1_left = BranchSeparables(out_channels_left, out_channels_left, 5, 1, 2, bias=False)\n        self.comb_iter_1_right = BranchSeparables(out_channels_left, out_channels_left, 3, 1, 1, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_3_left = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_left)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2 = x_comb_iter_2_left + x_left\n\n        x_comb_iter_3_left = self.comb_iter_3_left(x_left)\n        x_comb_iter_3_right = self.comb_iter_3_right(x_left)\n        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_right\n\n        x_out = torch.cat([x_left, x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell0(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell0, self).__init__() \n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = MaxPoolPad()\n        self.comb_iter_1_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = AvgPoolPad()\n        self.comb_iter_2_right = BranchSeparablesReduction(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparablesReduction(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = MaxPoolPad()\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass ReductionCell1(nn.Module):\n\n    def __init__(self, in_channels_left, out_channels_left, in_channels_right, out_channels_right):\n        super(ReductionCell1, self).__init__()\n        self.conv_prev_1x1 = nn.Sequential()\n        self.conv_prev_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_prev_1x1.add_module(\'conv\', nn.Conv2d(in_channels_left, out_channels_left, 1, stride=1, bias=False))\n        self.conv_prev_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_left, eps=0.001, momentum=0.1, affine=True))\n\n        self.conv_1x1 = nn.Sequential()\n        self.conv_1x1.add_module(\'relu\', nn.ReLU())\n        self.conv_1x1.add_module(\'conv\', nn.Conv2d(in_channels_right, out_channels_right, 1, stride=1, bias=False))\n        self.conv_1x1.add_module(\'bn\', nn.BatchNorm2d(out_channels_right, eps=0.001, momentum=0.1, affine=True))\n\n        self.comb_iter_0_left = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n        self.comb_iter_0_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)\n        self.comb_iter_1_right = BranchSeparables(out_channels_right, out_channels_right, 7, 2, 3, bias=False)\n\n        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n        self.comb_iter_2_right = BranchSeparables(out_channels_right, out_channels_right, 5, 2, 2, bias=False)\n\n        self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False)\n\n        self.comb_iter_4_left = BranchSeparables(out_channels_right, out_channels_right, 3, 1, 1, bias=False)\n        self.comb_iter_4_right = nn.MaxPool2d(3, stride=2, padding=1)\n\n    def forward(self, x, x_prev):\n        x_left = self.conv_prev_1x1(x_prev)\n        x_right = self.conv_1x1(x)\n\n        x_comb_iter_0_left = self.comb_iter_0_left(x_right)\n        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n\n        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n        x_comb_iter_1_right = self.comb_iter_1_right(x_left)\n        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n\n        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n        x_comb_iter_2_right = self.comb_iter_2_right(x_left)\n        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n\n        x_comb_iter_3_right = self.comb_iter_3_right(x_comb_iter_0)\n        x_comb_iter_3 = x_comb_iter_3_right + x_comb_iter_1\n\n        x_comb_iter_4_left = self.comb_iter_4_left(x_comb_iter_0)\n        x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n\n        x_out = torch.cat([x_comb_iter_1, x_comb_iter_2, x_comb_iter_3, x_comb_iter_4], 1)\n        return x_out\n\n\nclass NASNetALarge(nn.Module):\n\n    def __init__(self, use_classifer=False, num_classes=1001):\n        super(NASNetALarge, self).__init__()\n        self.use_classifer,self.num_classes = use_classifer,num_classes\n\n        self.conv0 = nn.Sequential()\n        self.conv0.add_module(\'conv\', nn.Conv2d(in_channels=3, out_channels=96, kernel_size=3, padding=0, stride=2,\n                                                bias=False))\n        self.conv0.add_module(\'bn\', nn.BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True))\n\n        self.cell_stem_0 = CellStem0()\n        self.cell_stem_1 = CellStem1()\n\n        self.cell_0 = FirstCell(in_channels_left=168, out_channels_left=84,\n                                in_channels_right=336, out_channels_right=168)\n        self.cell_1 = NormalCell(in_channels_left=336, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_2 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_3 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_4 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n        self.cell_5 = NormalCell(in_channels_left=1008, out_channels_left=168,\n                                 in_channels_right=1008, out_channels_right=168)\n\n        self.reduction_cell_0 = ReductionCell0(in_channels_left=1008, out_channels_left=336,\n                                               in_channels_right=1008, out_channels_right=336)\n\n        self.cell_6 = FirstCell(in_channels_left=1008, out_channels_left=168,\n                                in_channels_right=1344, out_channels_right=336)\n        self.cell_7 = NormalCell(in_channels_left=1344, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_8 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_9 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2016, out_channels_right=336)\n        self.cell_10 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n        self.cell_11 = NormalCell(in_channels_left=2016, out_channels_left=336,\n                                  in_channels_right=2016, out_channels_right=336)\n\n        self.reduction_cell_1 = ReductionCell1(in_channels_left=2016, out_channels_left=672,\n                                               in_channels_right=2016, out_channels_right=672)\n\n        self.cell_12 = FirstCell(in_channels_left=2016, out_channels_left=336,\n                                 in_channels_right=2688, out_channels_right=672)\n        self.cell_13 = NormalCell(in_channels_left=2688, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_14 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_15 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_16 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n        self.cell_17 = NormalCell(in_channels_left=4032, out_channels_left=672,\n                                  in_channels_right=4032, out_channels_right=672)\n\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout()\n        self.last_linear = nn.Linear(4032, self.num_classes)\n\n    def features(self, x):\n        x_conv0 = self.conv0(x)\n        x_stem_0 = self.cell_stem_0(x_conv0)\n        x_stem_1 = self.cell_stem_1(x_conv0, x_stem_0)\n\n        x_cell_0 = self.cell_0(x_stem_1, x_stem_0)\n        x_cell_1 = self.cell_1(x_cell_0, x_stem_1)\n        x_cell_2 = self.cell_2(x_cell_1, x_cell_0)\n        x_cell_3 = self.cell_3(x_cell_2, x_cell_1)\n        x_cell_4 = self.cell_4(x_cell_3, x_cell_2)\n        x_cell_5 = self.cell_5(x_cell_4, x_cell_3)\n\n        x_reduction_cell_0 = self.reduction_cell_0(x_cell_5, x_cell_4)\n\n        x_cell_6 = self.cell_6(x_reduction_cell_0, x_cell_4)\n        x_cell_7 = self.cell_7(x_cell_6, x_reduction_cell_0)\n        x_cell_8 = self.cell_8(x_cell_7, x_cell_6)\n        x_cell_9 = self.cell_9(x_cell_8, x_cell_7)\n        x_cell_10 = self.cell_10(x_cell_9, x_cell_8)\n        x_cell_11 = self.cell_11(x_cell_10, x_cell_9)\n\n        x_reduction_cell_1 = self.reduction_cell_1(x_cell_11, x_cell_10)\n\n        x_cell_12 = self.cell_12(x_reduction_cell_1, x_cell_10)\n        x_cell_13 = self.cell_13(x_cell_12, x_reduction_cell_1)\n        x_cell_14 = self.cell_14(x_cell_13, x_cell_12)\n        x_cell_15 = self.cell_15(x_cell_14, x_cell_13)\n        x_cell_16 = self.cell_16(x_cell_15, x_cell_14)\n        x_cell_17 = self.cell_17(x_cell_16, x_cell_15)\n        return self.relu(x_cell_17)\n\n    def classifier(self, x):\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        return F.log_softmax(self.linear(x))\n\n    def forward(self, x):\n        x = self.features(x)\n        if self.use_classifer: x = self.classifier(x)\n        return x\n\n\ndef nasnetalarge(num_classes=1000, pretrained=\'imagenet\'):\n    r""""""NASNetALarge model architecture from the\n    `""NASNet"" <https://arxiv.org/abs/1707.07012>`_ paper.\n    """"""\n    if pretrained:\n        settings = pretrained_settings[\'nasnetalarge\'][pretrained]\n        assert num_classes == settings[\'num_classes\'], \\\n            ""num_classes should be {}, but is {}"".format(settings[\'num_classes\'], num_classes)\n\n        # both \'imagenet\'&\'imagenet+background\' are loaded from same parameters\n        model = NASNetALarge(num_classes=1001)\n        model.load_state_dict(model_zoo.load_url(settings[\'url\']))\n\n        if pretrained == \'imagenet\':\n            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n            model.last_linear = new_last_linear\n\n        model.input_space = settings[\'input_space\']\n        model.input_size = settings[\'input_size\']\n        model.input_range = settings[\'input_range\']\n\n        model.mean = settings[\'mean\']\n        model.std = settings[\'std\']\n    else:\n        model = NASNetALarge(num_classes=num_classes)\n    return model\n'"
fastai/courses/ml1/fastai/models/resnet.py,4,"b""import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom ..layers import *\n\n__all__ = ['vgg_resnet50']\n\nmodel_urls = {\n    'vgg_resnet50': 'https://download.pytorch.org/models/vggresnet.pth',\n}\n\n\ndef conv(ni, nf, ks=3, stride=1):\n    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn1(planes):\n    m = nn.BatchNorm1d(planes)\n    m.weight.data.fill_(1)\n    m.bias.data.zero_()\n    return m\n\ndef bn(planes, init_zero=False):\n    m = nn.BatchNorm2d(planes)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, stride=stride)\n        self.bn1 = bn(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv(planes, planes)\n        self.bn2 = bn(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.relu(out)\n        out = self.bn1(out)\n\n        out = self.conv2(out)\n\n        out = residual + out\n        out = self.relu(out)\n        out = self.bn2(out)\n\n        return out\n\n\nclass BottleneckFinal(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        out = residual + out\n        out = self.bn3(out)\n        out = self.relu(out)\n\n        return out\n\nclass BottleneckZero(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4, init_zero=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = conv(inplanes, planes, ks=1)\n        self.bn1 = bn(planes)\n        self.conv2 = conv(planes, planes, stride=stride)\n        self.bn2 = bn(planes)\n        self.conv3 = conv(planes, planes*4, ks=1)\n        self.bn3 = bn(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        if self.downsample is not None: residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        out = residual + out\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=1000, k=1, vgg_head=False):\n        super().__init__()\n        self.inplanes = 64\n\n        features = [conv(3, 64, ks=7, stride=2)\n            , bn(64) , nn.ReLU(inplace=True) , nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n            , self._make_layer(block, int(64*k), layers[0])\n            , self._make_layer(block, int(128*k), layers[1], stride=2)\n            , self._make_layer(block, int(256*k), layers[2], stride=2)\n            , self._make_layer(block, int(512*k), layers[3], stride=2)]\n        out_sz = int(512*k) * block.expansion\n\n        if vgg_head:\n            features += [nn.AdaptiveAvgPool2d(3), Flatten()\n                , nn.Linear(out_sz*3*3, 4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096,   4096), nn.ReLU(inplace=True), bn1(4096), nn.Dropout(0.25)\n                , nn.Linear(4096, num_classes)]\n        else: features += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(out_sz, num_classes)]\n\n        self.features = nn.Sequential(*features)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv(self.inplanes, planes*block.expansion, ks=1, stride=stride),\n                bn(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks): layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef bnf_resnet50 (): return ResNet(BottleneckFinal, [3, 4, 6, 3])\ndef bnz_resnet50 (): return ResNet(BottleneckZero, [3, 4, 6, 3])\ndef w5_resnet50 (): return ResNet(Bottleneck, [2, 3, 3, 2], k=1.5)\ndef w25_resnet50(): return ResNet(Bottleneck, [3, 4, 4, 3], k=1.25)\ndef w125_resnet50(): return ResNet(Bottleneck, [3, 4, 6, 3], k=1.125)\ndef vgg_resnet34(): return ResNet(BasicBlock, [3, 4, 6, 3], vgg_head=True)\ndef vgg_resnet50(pretrained=False):\n    model = ResNet(Bottleneck, [3, 4, 6, 3], vgg_head=True)\n    if pretrained: model.load_state_dict(torch.load('/home/jhoward/.torch/models/vgg_resnet50.pth'))\n    return model\n\n"""
fastai/courses/ml1/fastai/models/resnext_101_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/ml1/fastai/models/resnext_101_64x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_101_64x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(2, 2),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(2048,2048,(3, 3),(1, 1),(1, 1),1,64,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(2048,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/courses/ml1/fastai/models/resnext_50_32x4d.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef resnext_50_32x4d(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,32,bias=False),\n\t\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\t),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AdaptiveAvgPool2d(1),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)\n'"
fastai/courses/ml1/fastai/models/unet.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport numpy as np\n\ndef get_sfs_idxs(sfs, last=True):\n    """"""\n    Return the saved feature indexes that will be concatenated\n    Inputs:\n        sfs (list): saved features by hook function, in other words intermediate activations\n        last (bool): whether to concatenate only last different activation, or all from the encoder model\n    """"""\n    if last:\n        feature_szs = [sfs_feats.features.size()[-1] for sfs_feats in sfs]\n        sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n        if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n    else: sfs_idxs = list(range(len(sfs)))\n    return sfs_idxs\n\n\ndef conv_bn_relu(in_c, out_c, kernel_size, stride, padding):\n    return [\n        nn.Conv2d(in_c, out_c, kernel_size=kernel_size, stride=stride, padding=padding),\n        nn.ReLU(),\n        nn.BatchNorm2d(out_c)]\n\n\nclass UnetBlock(nn.Module):\n    #TODO: ADAPT KERNEL SIZE, STRIDE AND PADDING SO THAT ANY SIZE DECAY WILL BE SUPPORTED\n    def __init__(self, up_in_c, x_in_c):\n        super().__init__()\n        self.upconv = nn.ConvTranspose2d(up_in_c, up_in_c // 2, 2, 2) # H, W -> 2H, 2W\n        self.conv1 = nn.Conv2d(x_in_c + up_in_c // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.conv2 = nn.Conv2d((x_in_c + up_in_c // 2) // 2, (x_in_c + up_in_c // 2) // 2, 3, 1, 1)\n        self.bn = nn.BatchNorm2d((x_in_c + up_in_c // 2) // 2)\n\n    def forward(self, up_in, x_in):\n        up_out = self.upconv(up_in)\n        cat_x = torch.cat([up_out, x_in], dim=1)\n        x = F.relu(self.conv1(cat_x))\n        x = F.relu(self.conv2(x))\n        return self.bn(x)\n\nclass SaveFeatures():\n    """""" Extract pretrained activations""""""\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()\n\n\nclass DynamicUnet(nn.Module):\n    """"""\n    A dynamic implementation of Unet architecture, because calculating connections\n    and channels suck!. When an encoder is passed, this network will\n    automatically construct a decoder after the first single forward pass for any\n    given encoder architecture.\n\n    Decoder part is heavily based on the original Unet paper:\n    https://arxiv.org/abs/1505.04597.\n\n    Inputs:\n        encoder(nn.Module): Preferably a pretrained model, such as VGG or ResNet\n        last (bool): Whether to concat only last activation just before a size change\n        n_classes (int): Number of classes to output in final step of decoder\n\n    Important Note: If architecture directly reduces the dimension of an image as soon as the\n    first forward pass then output size will not be same as the input size, e.g. ResNet.\n    In order to resolve this problem architecture will add an additional extra conv transpose\n    layer. Also, currently Dynamic Unet expects size change to be H,W -> H/2, W/2. This is\n    not a problem for state-of-the-art architectures as they follow this pattern but it should\n    be changed for custom encoders that might have a different size decay.\n    """"""\n\n    def __init__(self, encoder, last=True, n_classes=3):\n        super().__init__()\n        self.encoder = encoder\n        self.n_children = len(list(encoder.children()))\n        self.sfs = [SaveFeatures(encoder[i]) for i in range(self.n_children)]\n        self.last = last\n        self.n_classes = n_classes\n\n    def forward(self, x):\n        # get imsize\n        imsize = x.size()[-2:]\n\n        # encoder output\n        x = F.relu(self.encoder(x))\n\n        # initialize sfs_idxs, sfs_szs, middle_in_c and middle_conv only once\n        if not hasattr(self, \'middle_conv\'):\n            self.sfs_szs = [sfs_feats.features.size() for sfs_feats in self.sfs]\n            self.sfs_idxs = get_sfs_idxs(self.sfs, self.last)\n            middle_in_c = self.sfs_szs[-1][1]\n            middle_conv = nn.Sequential(*conv_bn_relu(middle_in_c, middle_in_c * 2, 3, 1, 1),\n                                        *conv_bn_relu(middle_in_c * 2, middle_in_c, 3, 1, 1))\n            self.middle_conv = middle_conv\n\n        # middle conv\n        x = self.middle_conv(x)\n\n        # initialize upmodel, extra_block and 1x1 final conv\n        if not hasattr(self, \'upmodel\'):\n            x_copy = Variable(x.data, requires_grad=False)\n            upmodel = []\n            for idx in self.sfs_idxs[::-1]:\n                up_in_c, x_in_c = int(x_copy.size()[1]), int(self.sfs_szs[idx][1])\n                unet_block = UnetBlock(up_in_c, x_in_c)\n                upmodel.append(unet_block)\n                x_copy = unet_block(x_copy, self.sfs[idx].features)\n                self.upmodel = nn.Sequential(*upmodel)\n\n            if imsize != self.sfs_szs[0][-2:]:\n                extra_in_c = self.upmodel[-1].conv2.out_channels\n                self.extra_block = nn.ConvTranspose2d(extra_in_c, extra_in_c, 2, 2)\n\n            final_in_c = self.upmodel[-1].conv2.out_channels\n            self.final_conv = nn.Conv2d(final_in_c, self.n_classes, 1)\n\n        # run upsample\n        for block, idx in zip(self.upmodel, self.sfs_idxs[::-1]):\n            x = block(x, self.sfs[idx].features)\n        if hasattr(self, \'extra_block\'):\n            x = self.extra_block(x)\n\n        out = self.final_conv(x)\n        return out\n'"
fastai/courses/ml1/fastai/models/wideresnet.py,3,"b'# https://github.com/uoguelph-mlrg/Cutout\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super().__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut: x   = self.relu1(self.bn1(x))\n        else:                   out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super().__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x): return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super().__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert((depth - 4) % 6 == 0)\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear): m.bias.data.zero_()\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.adaptive_avg_pool2d(out, 1)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n'"
fastai/courses/ml1/fastai/models/wrn_50_2f.py,2,"b'\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom functools import reduce\n\nclass LambdaBase(nn.Sequential):\n    def __init__(self, fn, *args):\n        super(LambdaBase, self).__init__(*args)\n        self.lambda_func = fn\n\n    def forward_prepare(self, input):\n        output = []\n        for module in self._modules.values():\n            output.append(module(input))\n        return output if output else input\n\nclass Lambda(LambdaBase):\n    def forward(self, input):\n        return self.lambda_func(self.forward_prepare(input))\n\nclass LambdaMap(LambdaBase):\n    def forward(self, input):\n        return list(map(self.lambda_func,self.forward_prepare(input)))\n\nclass LambdaReduce(LambdaBase):\n    def forward(self, input):\n        return reduce(self.lambda_func,self.forward_prepare(input))\n\n\ndef wrn_50_2f(): return nn.Sequential( # Sequential,\n\tnn.Conv2d(3,64,(7, 7),(2, 2),(3, 3),1,1,bias=False),\n\tnn.BatchNorm2d(64),\n\tnn.ReLU(),\n\tnn.MaxPool2d((3, 3),(2, 2),(1, 1)),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(64,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,128,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,128,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(128),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(128,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,256,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,256,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(256),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(256,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,512,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,512,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(512),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(512,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.Sequential( # Sequential,\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(2, 2),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(2, 2),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t\tnn.Sequential( # Sequential,\n\t\t\tLambdaMap(lambda x: x, # ConcatTable,\n\t\t\t\tnn.Sequential( # Sequential,\n\t\t\t\t\tnn.Conv2d(2048,1024,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,1024,(3, 3),(1, 1),(1, 1),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(1024),\n\t\t\t\t\tnn.ReLU(),\n\t\t\t\t\tnn.Conv2d(1024,2048,(1, 1),(1, 1),(0, 0),1,1,bias=False),\n\t\t\t\t\tnn.BatchNorm2d(2048),\n\t\t\t\t),\n\t\t\t\tLambda(lambda x: x), # Identity,\n\t\t\t),\n\t\t\tLambdaReduce(lambda x,y: x+y), # CAddTable,\n\t\t\tnn.ReLU(),\n\t\t),\n\t),\n\tnn.AvgPool2d((7, 7),(1, 1)),\n\tLambda(lambda x: x.view(x.size(0),-1)), # View,\n\tnn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2048,1000)), # Linear,\n)'"
fastai/tutorials/fastai/models/cifar10/main_dxy.py,16,"b'from __future__ import division\n\nfrom senet import *\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--data_path\', default=\'./data\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', default=\'cifar10\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=64, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.05, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(0)\n\nif args.manualSeed is None: args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda: torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n  if not os.path.isdir(args.save_path): os.makedirs(args.save_path)\n  log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n  print_log(\'save path : {}\'.format(args.save_path), log)\n  state = {k: v for k, v in args._get_kwargs()}\n  print_log(state, log)\n  print_log(""Random Seed: {}"".format(args.manualSeed), log)\n  print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n  print_log(""torch  version : {}"".format(torch.__version__), log)\n  print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n\n  # Init dataset\n  if not os.path.isdir(args.data_path):\n    os.makedirs(args.data_path)\n\n  if args.dataset == \'cifar10\':\n    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n  elif args.dataset == \'cifar100\':\n    mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n    std = [x / 255 for x in [68.2, 65.4, 70.4]]\n  else:\n    assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n  train_transform = transforms.Compose(\n    [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n     transforms.Normalize(mean, std)])\n  test_transform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n  if args.dataset == \'cifar10\':\n    train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'cifar100\':\n    train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 100\n  elif args.dataset == \'svhn\':\n    train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'stl10\':\n    train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'imagenet\':\n    assert False, \'Do not finish imagenet code\'\n  else:\n    assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n  train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                         num_workers=args.workers, pin_memory=True)\n  test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                        num_workers=args.workers, pin_memory=True)\n\n  # Init model, criterion, and optimizer\n  #net = models.__dict__[args.arch](num_classes).cuda()\n  net = SENet34()\n\n  # define loss function (criterion) and optimizer\n  criterion = F.nll_loss\n  optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                weight_decay=state[\'decay\'], nesterov=True)\n\n  if args.use_cuda: net.cuda()\n\n  recorder = RecorderMeter(args.epochs)\n  # optionally resume from a checkpoint\n  if args.resume:\n    if os.path.isfile(args.resume):\n      print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n      checkpoint = torch.load(args.resume)\n      recorder = checkpoint[\'recorder\']\n      args.start_epoch = checkpoint[\'epoch\']\n      net.load_state_dict(checkpoint[\'state_dict\'])\n      optimizer.load_state_dict(checkpoint[\'optimizer\'])\n      print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n    else:\n      print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n  else:\n    print_log(""=> do not use any checkpoint for model"", log)\n\n  if args.evaluate:\n    validate(test_loader, net, criterion, log)\n    return\n\n  # Main loop\n  start_time = time.time()\n  epoch_time = AverageMeter()\n  for epoch in range(args.start_epoch, args.epochs):\n    current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n    need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n    print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n    # train for one epoch\n    train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n    # evaluate on validation set\n    val_acc,   val_los   = validate(test_loader, net, criterion, log)\n    is_best = recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n\n    save_checkpoint({\n      \'epoch\': epoch + 1,\n      \'state_dict\': net.state_dict(),\n      \'recorder\': recorder,\n      \'optimizer\' : optimizer.state_dict(),\n    }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    recorder.plot_curve( os.path.join(args.save_path, \'curve.png\') )\n\n  log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n  batch_time = AverageMeter()\n  data_time = AverageMeter()\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n  # switch to train mode\n  model.train()\n\n  end = time.time()\n  for i, (input, target) in enumerate(train_loader):\n    # measure data loading time\n    data_time.update(time.time() - end)\n\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input)\n    target_var = torch.autograd.Variable(target)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n    # compute gradient and do SGD step\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n  print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n        epoch, i, len(train_loader), batch_time=batch_time,\n        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n  return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n\n  # switch to evaluate mode\n  model.eval()\n\n  for i, (input, target) in enumerate(val_loader):\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input, volatile=True)\n    target_var = torch.autograd.Variable(target, volatile=True)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n  print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n  return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n  print(""{}"".format(print_string))\n  log.write(\'{}\\n\'.format(print_string))\n  log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n  filename = os.path.join(save_path, filename)\n  torch.save(state, filename)\n  if is_best:\n    bestname = os.path.join(save_path, \'model_best.pth.tar\')\n    shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n  """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n  lr = args.learning_rate\n  assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n  for (gamma, step) in zip(gammas, schedule):\n    if (epoch >= step):\n      lr = lr * gamma\n    else:\n      break\n  for param_group in optimizer.param_groups:\n    param_group[\'lr\'] = lr\n  return lr\n\ndef accuracy(output, target, topk=(1,)):\n  """"""Computes the precision@k for the specified values of k""""""\n  maxk = max(topk)\n  batch_size = target.size(0)\n\n  _, pred = output.topk(maxk, 1, True, True)\n  pred = pred.t()\n  correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n  res = []\n  for k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0)\n    res.append(correct_k.mul_(100.0 / batch_size))\n  return res\n\nif __name__ == \'__main__\':\n  main()\n'"
fastai/tutorials/fastai/models/cifar10/main_kuangliu.py,15,"b""'''Train CIFAR10 with PyTorch.'''\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\n\nfrom senet import *\nfrom utils import progress_bar\nfrom torch.autograd import Variable\n\n\nparser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\nparser.add_argument('--lr', default=0.1, type=float, help='learning rate')\nparser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\nargs = parser.parse_args()\n\nuse_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(3)\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/ckpt.t7')\n    net = checkpoint['net']\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']\nelse:\n    print('==> Building model..')\n    # net = VGG('VGG19')\n    # net = ResNet18()\n    # net = PreActResNet18()\n    # net = GoogLeNet()\n    # net = DenseNet121()\n    # net = ResNeXt29_2x64d()\n    # net = MobileNet()\n    # net = DPN92()\n    # net = ShuffleNetG2()\n    net = SENet18()\n\nif use_cuda:\n    net.cuda()\n    #net = torch.nn.DataParallel(net, device_ids=(0,3))\n    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n    cudnn.benchmark = True\n\ncriterion = F.nll_loss\noptimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n\n# Training\ndef train(epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        optimizer.zero_grad()\n        inputs, targets = Variable(inputs), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n\n        test_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\n            'net': net,\n            'acc': acc,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt.t7')\n        best_acc = acc\n\n\nfor epoch in range(start_epoch, start_epoch+100):\n    train(epoch)\n    test(epoch)\n"""
fastai/tutorials/fastai/models/cifar10/preact_resnet.py,3,"b""'''Pre-activation ResNet in PyTorch.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass PreActResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(PreActResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        return F.log_softmax(self.linear(out))\n\ndef PreActResNet18(): return PreActResNet(PreActBlock, [2,2,2,2])\ndef PreActResNet34(): return PreActResNet(PreActBlock, [3,4,6,3])\ndef PreActResNet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\ndef PreActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\ndef PreActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n\n"""
fastai/tutorials/fastai/models/cifar10/resnext.py,3,"b'import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\nclass ResNeXtBottleneck(nn.Module):\n  expansion = 4\n  """"""\n  RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n  """"""\n  def __init__(self, inplanes, planes, cardinality, base_width, stride=1, downsample=None):\n    super(ResNeXtBottleneck, self).__init__()\n    self.downsample = downsample\n\n    D = int(math.floor(planes * (base_width/64.0)))\n    C = cardinality\n    self.conv_reduce = nn.Conv2d(inplanes, D*C, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_reduce = nn.BatchNorm2d(D*C)\n\n    self.conv_conv = nn.Conv2d(D*C, D*C, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n    self.bn = nn.BatchNorm2d(D*C)\n    self.conv_expand = nn.Conv2d(D*C, planes*4, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_expand = nn.BatchNorm2d(planes*4)\n\n  def forward(self, x):\n    residual = x\n\n    bottleneck = self.conv_reduce(x)\n    bottleneck = F.relu(self.bn_reduce(bottleneck), inplace=True)\n\n    bottleneck = self.conv_conv(bottleneck)\n    bottleneck = F.relu(self.bn(bottleneck), inplace=True)\n\n    bottleneck = self.conv_expand(bottleneck)\n    bottleneck = self.bn_expand(bottleneck)\n\n    if self.downsample is not None: residual = self.downsample(x)\n    return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n  """"""\n  ResNext optimized for the Cifar dataset, as specified in\n  https://arxiv.org/pdf/1611.05431.pdf\n  """"""\n  def __init__(self, block, depth, cardinality, base_width, num_classes):\n    super(CifarResNeXt, self).__init__()\n\n    # Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 9 == 0, \'depth should be one of 29, 38, 47, 56, 101\'\n    self.layer_blocks = (depth - 2) // 9\n\n    self.cardinality,self.base_width,self.num_classes,self.block = cardinality,base_width,num_classes,block\n\n    self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(64)\n\n    self.inplanes = 64\n    self.stage_1 = self._make_layer(64 , 1)\n    self.stage_2 = self._make_layer(128, 2)\n    self.stage_3 = self._make_layer(256, 2)\n    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n    self.classifier = nn.Linear(256*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, planes, stride=1):\n    downsample = None\n    exp_planes = planes * self.block.expansion\n    if stride != 1 or self.inplanes != exp_planes:\n      downsample = nn.Sequential(\n        nn.Conv2d(self.inplanes, exp_planes, kernel_size=1, stride=stride, bias=False),\n        nn.BatchNorm2d(exp_planes),\n      )\n\n    layers = []\n    layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width, stride, downsample))\n    self.inplanes = exp_planes\n    for i in range(1, self.layer_blocks):\n      layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return F.log_softmax(self.classifier(x))\n\ndef resnext29_16_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 16*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 16, 64, num_classes)\n  return model\n\ndef resnext29_8_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 8*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 8, 64, num_classes)\n  return model\n'"
fastai/tutorials/fastai/models/cifar10/senet.py,3,"b""'''SENet in PyTorch.\n\nSENet is the winner of ImageNet-2017 (https://arxiv.org/abs/1709.01507).\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w  # New broadcasting feature from v0.2!\n\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w\n\n        out += shortcut\n        return out\n\n\nclass SENet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(SENet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        out = F.log_softmax(self.linear(out))\n        return out\n\n\ndef SENet18(): return SENet(PreActBlock, [2,2,2,2])\ndef SENet34(): return SENet(PreActBlock, [3,4,6,3])\n\n"""
fastai/tutorials/fastai/models/cifar10/utils.py,0,"b'import os, sys, time\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n'"
fastai/tutorials/fastai/models/cifar10/utils_kuangliu.py,5,"b""'''Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n'''\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\ndef get_mean_and_std(dataset):\n    '''Compute the mean and std value of dataset.'''\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print('==> Computing mean and std..')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    '''Init layer parameters.'''\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode='fan_out')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\n\n_, term_width = os.popen('stty size', 'r').read().split()\nterm_width = int(term_width)\n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f\n"""
fastai/tutorials/fastai/models/cifar10/wideresnet.py,2,"b'# Cifar10 Wideresnet for Dawn Submission\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ...layers import *\n\ndef conv_2d(ni, nf, ks, stride): return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn(ni, init_zero=False):\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv_2d(ni, nf, ks, stride))\n\ndef noop(x): return x\n\nclass BasicBlock(nn.Module):\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        super().__init__()\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv_2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv_2d(ni, nf, 1, stride) if ni != nf else noop\n\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)\n        r = self.shortcut(x2)\n        x = self.conv1(x2)\n        if self.drop: x = self.drop(x)\n        x = self.conv2(x) * 0.2\n        return x.add_(r)\n\n\ndef _make_group(N, ni, nf, block, stride, drop_p):\n    return [block(ni if i == 0 else nf, nf, stride if i == 0 else 1, drop_p) for i in range(N)]\n\nclass WideResNet(nn.Module):\n    def __init__(self, num_groups, N, num_classes, k=1, drop_p=0.0, start_nf=16):\n        super().__init__()\n        n_channels = [start_nf]\n        for i in range(num_groups): n_channels.append(start_nf*(2**i)*k)\n\n        layers = [conv_2d(3, n_channels[0], 3, 1)]  # conv1\n        for i in range(num_groups):\n            layers += _make_group(N, n_channels[i], n_channels[i+1], BasicBlock, (1 if i==0 else 2), drop_p)\n\n        layers += [nn.BatchNorm2d(n_channels[3]), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),\n                   Flatten(), nn.Linear(n_channels[3], num_classes)]\n        self.features = nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef wrn_22(): return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.)\ndef wrn_22_k8(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.)\ndef wrn_22_k10(): return WideResNet(num_groups=3, N=3, num_classes=10, k=10, drop_p=0.)\ndef wrn_22_k8_p2(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.)\ndef wrn_28_k8(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.)\ndef wrn_28_k8_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.2)\n\n'"
fastai/courses/dl1/fastai/models/cifar10/main_dxy.py,16,"b'from __future__ import division\n\nfrom senet import *\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--data_path\', default=\'./data\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', default=\'cifar10\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=64, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.05, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(0)\n\nif args.manualSeed is None: args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda: torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n  if not os.path.isdir(args.save_path): os.makedirs(args.save_path)\n  log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n  print_log(\'save path : {}\'.format(args.save_path), log)\n  state = {k: v for k, v in args._get_kwargs()}\n  print_log(state, log)\n  print_log(""Random Seed: {}"".format(args.manualSeed), log)\n  print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n  print_log(""torch  version : {}"".format(torch.__version__), log)\n  print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n\n  # Init dataset\n  if not os.path.isdir(args.data_path):\n    os.makedirs(args.data_path)\n\n  if args.dataset == \'cifar10\':\n    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n  elif args.dataset == \'cifar100\':\n    mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n    std = [x / 255 for x in [68.2, 65.4, 70.4]]\n  else:\n    assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n  train_transform = transforms.Compose(\n    [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n     transforms.Normalize(mean, std)])\n  test_transform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n  if args.dataset == \'cifar10\':\n    train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'cifar100\':\n    train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 100\n  elif args.dataset == \'svhn\':\n    train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'stl10\':\n    train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'imagenet\':\n    assert False, \'Do not finish imagenet code\'\n  else:\n    assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n  train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                         num_workers=args.workers, pin_memory=True)\n  test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                        num_workers=args.workers, pin_memory=True)\n\n  # Init model, criterion, and optimizer\n  #net = models.__dict__[args.arch](num_classes).cuda()\n  net = SENet34()\n\n  # define loss function (criterion) and optimizer\n  criterion = F.nll_loss\n  optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                weight_decay=state[\'decay\'], nesterov=True)\n\n  if args.use_cuda: net.cuda()\n\n  recorder = RecorderMeter(args.epochs)\n  # optionally resume from a checkpoint\n  if args.resume:\n    if os.path.isfile(args.resume):\n      print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n      checkpoint = torch.load(args.resume)\n      recorder = checkpoint[\'recorder\']\n      args.start_epoch = checkpoint[\'epoch\']\n      net.load_state_dict(checkpoint[\'state_dict\'])\n      optimizer.load_state_dict(checkpoint[\'optimizer\'])\n      print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n    else:\n      print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n  else:\n    print_log(""=> do not use any checkpoint for model"", log)\n\n  if args.evaluate:\n    validate(test_loader, net, criterion, log)\n    return\n\n  # Main loop\n  start_time = time.time()\n  epoch_time = AverageMeter()\n  for epoch in range(args.start_epoch, args.epochs):\n    current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n    need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n    print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n    # train for one epoch\n    train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n    # evaluate on validation set\n    val_acc,   val_los   = validate(test_loader, net, criterion, log)\n    is_best = recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n\n    save_checkpoint({\n      \'epoch\': epoch + 1,\n      \'state_dict\': net.state_dict(),\n      \'recorder\': recorder,\n      \'optimizer\' : optimizer.state_dict(),\n    }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    recorder.plot_curve( os.path.join(args.save_path, \'curve.png\') )\n\n  log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n  batch_time = AverageMeter()\n  data_time = AverageMeter()\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n  # switch to train mode\n  model.train()\n\n  end = time.time()\n  for i, (input, target) in enumerate(train_loader):\n    # measure data loading time\n    data_time.update(time.time() - end)\n\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input)\n    target_var = torch.autograd.Variable(target)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n    # compute gradient and do SGD step\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n  print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n        epoch, i, len(train_loader), batch_time=batch_time,\n        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n  return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n\n  # switch to evaluate mode\n  model.eval()\n\n  for i, (input, target) in enumerate(val_loader):\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input, volatile=True)\n    target_var = torch.autograd.Variable(target, volatile=True)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n  print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n  return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n  print(""{}"".format(print_string))\n  log.write(\'{}\\n\'.format(print_string))\n  log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n  filename = os.path.join(save_path, filename)\n  torch.save(state, filename)\n  if is_best:\n    bestname = os.path.join(save_path, \'model_best.pth.tar\')\n    shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n  """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n  lr = args.learning_rate\n  assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n  for (gamma, step) in zip(gammas, schedule):\n    if (epoch >= step):\n      lr = lr * gamma\n    else:\n      break\n  for param_group in optimizer.param_groups:\n    param_group[\'lr\'] = lr\n  return lr\n\ndef accuracy(output, target, topk=(1,)):\n  """"""Computes the precision@k for the specified values of k""""""\n  maxk = max(topk)\n  batch_size = target.size(0)\n\n  _, pred = output.topk(maxk, 1, True, True)\n  pred = pred.t()\n  correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n  res = []\n  for k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0)\n    res.append(correct_k.mul_(100.0 / batch_size))\n  return res\n\nif __name__ == \'__main__\':\n  main()\n'"
fastai/courses/dl1/fastai/models/cifar10/main_kuangliu.py,15,"b""'''Train CIFAR10 with PyTorch.'''\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\n\nfrom senet import *\nfrom utils import progress_bar\nfrom torch.autograd import Variable\n\n\nparser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\nparser.add_argument('--lr', default=0.1, type=float, help='learning rate')\nparser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\nargs = parser.parse_args()\n\nuse_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(3)\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/ckpt.t7')\n    net = checkpoint['net']\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']\nelse:\n    print('==> Building model..')\n    # net = VGG('VGG19')\n    # net = ResNet18()\n    # net = PreActResNet18()\n    # net = GoogLeNet()\n    # net = DenseNet121()\n    # net = ResNeXt29_2x64d()\n    # net = MobileNet()\n    # net = DPN92()\n    # net = ShuffleNetG2()\n    net = SENet18()\n\nif use_cuda:\n    net.cuda()\n    #net = torch.nn.DataParallel(net, device_ids=(0,3))\n    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n    cudnn.benchmark = True\n\ncriterion = F.nll_loss\noptimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n\n# Training\ndef train(epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        optimizer.zero_grad()\n        inputs, targets = Variable(inputs), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n\n        test_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\n            'net': net,\n            'acc': acc,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt.t7')\n        best_acc = acc\n\n\nfor epoch in range(start_epoch, start_epoch+100):\n    train(epoch)\n    test(epoch)\n"""
fastai/courses/dl1/fastai/models/cifar10/preact_resnet.py,3,"b""'''Pre-activation ResNet in PyTorch.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass PreActResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(PreActResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        return F.log_softmax(self.linear(out))\n\ndef PreActResNet18(): return PreActResNet(PreActBlock, [2,2,2,2])\ndef PreActResNet34(): return PreActResNet(PreActBlock, [3,4,6,3])\ndef PreActResNet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\ndef PreActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\ndef PreActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n\n"""
fastai/courses/dl1/fastai/models/cifar10/resnext.py,3,"b'import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\nclass ResNeXtBottleneck(nn.Module):\n  expansion = 4\n  """"""\n  RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n  """"""\n  def __init__(self, inplanes, planes, cardinality, base_width, stride=1, downsample=None):\n    super(ResNeXtBottleneck, self).__init__()\n    self.downsample = downsample\n\n    D = int(math.floor(planes * (base_width/64.0)))\n    C = cardinality\n    self.conv_reduce = nn.Conv2d(inplanes, D*C, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_reduce = nn.BatchNorm2d(D*C)\n\n    self.conv_conv = nn.Conv2d(D*C, D*C, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n    self.bn = nn.BatchNorm2d(D*C)\n    self.conv_expand = nn.Conv2d(D*C, planes*4, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_expand = nn.BatchNorm2d(planes*4)\n\n  def forward(self, x):\n    residual = x\n\n    bottleneck = self.conv_reduce(x)\n    bottleneck = F.relu(self.bn_reduce(bottleneck), inplace=True)\n\n    bottleneck = self.conv_conv(bottleneck)\n    bottleneck = F.relu(self.bn(bottleneck), inplace=True)\n\n    bottleneck = self.conv_expand(bottleneck)\n    bottleneck = self.bn_expand(bottleneck)\n\n    if self.downsample is not None: residual = self.downsample(x)\n    return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n  """"""\n  ResNext optimized for the Cifar dataset, as specified in\n  https://arxiv.org/pdf/1611.05431.pdf\n  """"""\n  def __init__(self, block, depth, cardinality, base_width, num_classes):\n    super(CifarResNeXt, self).__init__()\n\n    # Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 9 == 0, \'depth should be one of 29, 38, 47, 56, 101\'\n    self.layer_blocks = (depth - 2) // 9\n\n    self.cardinality,self.base_width,self.num_classes,self.block = cardinality,base_width,num_classes,block\n\n    self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(64)\n\n    self.inplanes = 64\n    self.stage_1 = self._make_layer(64 , 1)\n    self.stage_2 = self._make_layer(128, 2)\n    self.stage_3 = self._make_layer(256, 2)\n    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n    self.classifier = nn.Linear(256*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, planes, stride=1):\n    downsample = None\n    exp_planes = planes * self.block.expansion\n    if stride != 1 or self.inplanes != exp_planes:\n      downsample = nn.Sequential(\n        nn.Conv2d(self.inplanes, exp_planes, kernel_size=1, stride=stride, bias=False),\n        nn.BatchNorm2d(exp_planes),\n      )\n\n    layers = []\n    layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width, stride, downsample))\n    self.inplanes = exp_planes\n    for i in range(1, self.layer_blocks):\n      layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return F.log_softmax(self.classifier(x))\n\ndef resnext29_16_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 16*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 16, 64, num_classes)\n  return model\n\ndef resnext29_8_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 8*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 8, 64, num_classes)\n  return model\n'"
fastai/courses/dl1/fastai/models/cifar10/senet.py,3,"b""'''SENet in PyTorch.\n\nSENet is the winner of ImageNet-2017 (https://arxiv.org/abs/1709.01507).\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w  # New broadcasting feature from v0.2!\n\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w\n\n        out += shortcut\n        return out\n\n\nclass SENet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(SENet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        out = F.log_softmax(self.linear(out))\n        return out\n\n\ndef SENet18(): return SENet(PreActBlock, [2,2,2,2])\ndef SENet34(): return SENet(PreActBlock, [3,4,6,3])\n\n"""
fastai/courses/dl1/fastai/models/cifar10/utils.py,0,"b'import os, sys, time\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n'"
fastai/courses/dl1/fastai/models/cifar10/utils_kuangliu.py,5,"b""'''Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n'''\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\ndef get_mean_and_std(dataset):\n    '''Compute the mean and std value of dataset.'''\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print('==> Computing mean and std..')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    '''Init layer parameters.'''\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode='fan_out')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\n\n_, term_width = os.popen('stty size', 'r').read().split()\nterm_width = int(term_width)\n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f\n"""
fastai/courses/dl1/fastai/models/cifar10/wideresnet.py,2,"b'# Cifar10 Wideresnet for Dawn Submission\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ...layers import *\n\ndef conv_2d(ni, nf, ks, stride): return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn(ni, init_zero=False):\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv_2d(ni, nf, ks, stride))\n\ndef noop(x): return x\n\nclass BasicBlock(nn.Module):\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        super().__init__()\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv_2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv_2d(ni, nf, 1, stride) if ni != nf else noop\n\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)\n        r = self.shortcut(x2)\n        x = self.conv1(x2)\n        if self.drop: x = self.drop(x)\n        x = self.conv2(x) * 0.2\n        return x.add_(r)\n\n\ndef _make_group(N, ni, nf, block, stride, drop_p):\n    return [block(ni if i == 0 else nf, nf, stride if i == 0 else 1, drop_p) for i in range(N)]\n\nclass WideResNet(nn.Module):\n    def __init__(self, num_groups, N, num_classes, k=1, drop_p=0.0, start_nf=16):\n        super().__init__()\n        n_channels = [start_nf]\n        for i in range(num_groups): n_channels.append(start_nf*(2**i)*k)\n\n        layers = [conv_2d(3, n_channels[0], 3, 1)]  # conv1\n        for i in range(num_groups):\n            layers += _make_group(N, n_channels[i], n_channels[i+1], BasicBlock, (1 if i==0 else 2), drop_p)\n\n        layers += [nn.BatchNorm2d(n_channels[3]), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),\n                   Flatten(), nn.Linear(n_channels[3], num_classes)]\n        self.features = nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef wrn_22(): return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.)\ndef wrn_22_k8(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.)\ndef wrn_22_k10(): return WideResNet(num_groups=3, N=3, num_classes=10, k=10, drop_p=0.)\ndef wrn_22_k8_p2(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.)\ndef wrn_28_k8(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.)\ndef wrn_28_k8_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.2)\n\n'"
fastai/courses/dl2/fastai/models/cifar10/main_dxy.py,16,"b'from __future__ import division\n\nfrom senet import *\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--data_path\', default=\'./data\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', default=\'cifar10\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=64, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.05, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(0)\n\nif args.manualSeed is None: args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda: torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n  if not os.path.isdir(args.save_path): os.makedirs(args.save_path)\n  log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n  print_log(\'save path : {}\'.format(args.save_path), log)\n  state = {k: v for k, v in args._get_kwargs()}\n  print_log(state, log)\n  print_log(""Random Seed: {}"".format(args.manualSeed), log)\n  print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n  print_log(""torch  version : {}"".format(torch.__version__), log)\n  print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n\n  # Init dataset\n  if not os.path.isdir(args.data_path):\n    os.makedirs(args.data_path)\n\n  if args.dataset == \'cifar10\':\n    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n  elif args.dataset == \'cifar100\':\n    mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n    std = [x / 255 for x in [68.2, 65.4, 70.4]]\n  else:\n    assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n  train_transform = transforms.Compose(\n    [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n     transforms.Normalize(mean, std)])\n  test_transform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n  if args.dataset == \'cifar10\':\n    train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'cifar100\':\n    train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 100\n  elif args.dataset == \'svhn\':\n    train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'stl10\':\n    train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'imagenet\':\n    assert False, \'Do not finish imagenet code\'\n  else:\n    assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n  train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                         num_workers=args.workers, pin_memory=True)\n  test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                        num_workers=args.workers, pin_memory=True)\n\n  # Init model, criterion, and optimizer\n  #net = models.__dict__[args.arch](num_classes).cuda()\n  net = SENet34()\n\n  # define loss function (criterion) and optimizer\n  criterion = F.nll_loss\n  optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                weight_decay=state[\'decay\'], nesterov=True)\n\n  if args.use_cuda: net.cuda()\n\n  recorder = RecorderMeter(args.epochs)\n  # optionally resume from a checkpoint\n  if args.resume:\n    if os.path.isfile(args.resume):\n      print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n      checkpoint = torch.load(args.resume)\n      recorder = checkpoint[\'recorder\']\n      args.start_epoch = checkpoint[\'epoch\']\n      net.load_state_dict(checkpoint[\'state_dict\'])\n      optimizer.load_state_dict(checkpoint[\'optimizer\'])\n      print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n    else:\n      print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n  else:\n    print_log(""=> do not use any checkpoint for model"", log)\n\n  if args.evaluate:\n    validate(test_loader, net, criterion, log)\n    return\n\n  # Main loop\n  start_time = time.time()\n  epoch_time = AverageMeter()\n  for epoch in range(args.start_epoch, args.epochs):\n    current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n    need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n    print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n    # train for one epoch\n    train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n    # evaluate on validation set\n    val_acc,   val_los   = validate(test_loader, net, criterion, log)\n    is_best = recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n\n    save_checkpoint({\n      \'epoch\': epoch + 1,\n      \'state_dict\': net.state_dict(),\n      \'recorder\': recorder,\n      \'optimizer\' : optimizer.state_dict(),\n    }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    recorder.plot_curve( os.path.join(args.save_path, \'curve.png\') )\n\n  log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n  batch_time = AverageMeter()\n  data_time = AverageMeter()\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n  # switch to train mode\n  model.train()\n\n  end = time.time()\n  for i, (input, target) in enumerate(train_loader):\n    # measure data loading time\n    data_time.update(time.time() - end)\n\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input)\n    target_var = torch.autograd.Variable(target)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n    # compute gradient and do SGD step\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n  print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n        epoch, i, len(train_loader), batch_time=batch_time,\n        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n  return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n\n  # switch to evaluate mode\n  model.eval()\n\n  for i, (input, target) in enumerate(val_loader):\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input, volatile=True)\n    target_var = torch.autograd.Variable(target, volatile=True)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n  print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n  return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n  print(""{}"".format(print_string))\n  log.write(\'{}\\n\'.format(print_string))\n  log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n  filename = os.path.join(save_path, filename)\n  torch.save(state, filename)\n  if is_best:\n    bestname = os.path.join(save_path, \'model_best.pth.tar\')\n    shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n  """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n  lr = args.learning_rate\n  assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n  for (gamma, step) in zip(gammas, schedule):\n    if (epoch >= step):\n      lr = lr * gamma\n    else:\n      break\n  for param_group in optimizer.param_groups:\n    param_group[\'lr\'] = lr\n  return lr\n\ndef accuracy(output, target, topk=(1,)):\n  """"""Computes the precision@k for the specified values of k""""""\n  maxk = max(topk)\n  batch_size = target.size(0)\n\n  _, pred = output.topk(maxk, 1, True, True)\n  pred = pred.t()\n  correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n  res = []\n  for k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0)\n    res.append(correct_k.mul_(100.0 / batch_size))\n  return res\n\nif __name__ == \'__main__\':\n  main()\n'"
fastai/courses/dl2/fastai/models/cifar10/main_kuangliu.py,15,"b""'''Train CIFAR10 with PyTorch.'''\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\n\nfrom senet import *\nfrom utils import progress_bar\nfrom torch.autograd import Variable\n\n\nparser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\nparser.add_argument('--lr', default=0.1, type=float, help='learning rate')\nparser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\nargs = parser.parse_args()\n\nuse_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(3)\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/ckpt.t7')\n    net = checkpoint['net']\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']\nelse:\n    print('==> Building model..')\n    # net = VGG('VGG19')\n    # net = ResNet18()\n    # net = PreActResNet18()\n    # net = GoogLeNet()\n    # net = DenseNet121()\n    # net = ResNeXt29_2x64d()\n    # net = MobileNet()\n    # net = DPN92()\n    # net = ShuffleNetG2()\n    net = SENet18()\n\nif use_cuda:\n    net.cuda()\n    #net = torch.nn.DataParallel(net, device_ids=(0,3))\n    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n    cudnn.benchmark = True\n\ncriterion = F.nll_loss\noptimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n\n# Training\ndef train(epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        optimizer.zero_grad()\n        inputs, targets = Variable(inputs), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n\n        test_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\n            'net': net,\n            'acc': acc,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt.t7')\n        best_acc = acc\n\n\nfor epoch in range(start_epoch, start_epoch+100):\n    train(epoch)\n    test(epoch)\n"""
fastai/courses/dl2/fastai/models/cifar10/preact_resnet.py,3,"b""'''Pre-activation ResNet in PyTorch.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass PreActResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(PreActResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        return F.log_softmax(self.linear(out))\n\ndef PreActResNet18(): return PreActResNet(PreActBlock, [2,2,2,2])\ndef PreActResNet34(): return PreActResNet(PreActBlock, [3,4,6,3])\ndef PreActResNet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\ndef PreActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\ndef PreActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n\n"""
fastai/courses/dl2/fastai/models/cifar10/resnext.py,3,"b'import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\nclass ResNeXtBottleneck(nn.Module):\n  expansion = 4\n  """"""\n  RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n  """"""\n  def __init__(self, inplanes, planes, cardinality, base_width, stride=1, downsample=None):\n    super(ResNeXtBottleneck, self).__init__()\n    self.downsample = downsample\n\n    D = int(math.floor(planes * (base_width/64.0)))\n    C = cardinality\n    self.conv_reduce = nn.Conv2d(inplanes, D*C, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_reduce = nn.BatchNorm2d(D*C)\n\n    self.conv_conv = nn.Conv2d(D*C, D*C, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n    self.bn = nn.BatchNorm2d(D*C)\n    self.conv_expand = nn.Conv2d(D*C, planes*4, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_expand = nn.BatchNorm2d(planes*4)\n\n  def forward(self, x):\n    residual = x\n\n    bottleneck = self.conv_reduce(x)\n    bottleneck = F.relu(self.bn_reduce(bottleneck), inplace=True)\n\n    bottleneck = self.conv_conv(bottleneck)\n    bottleneck = F.relu(self.bn(bottleneck), inplace=True)\n\n    bottleneck = self.conv_expand(bottleneck)\n    bottleneck = self.bn_expand(bottleneck)\n\n    if self.downsample is not None: residual = self.downsample(x)\n    return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n  """"""\n  ResNext optimized for the Cifar dataset, as specified in\n  https://arxiv.org/pdf/1611.05431.pdf\n  """"""\n  def __init__(self, block, depth, cardinality, base_width, num_classes):\n    super(CifarResNeXt, self).__init__()\n\n    # Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 9 == 0, \'depth should be one of 29, 38, 47, 56, 101\'\n    self.layer_blocks = (depth - 2) // 9\n\n    self.cardinality,self.base_width,self.num_classes,self.block = cardinality,base_width,num_classes,block\n\n    self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(64)\n\n    self.inplanes = 64\n    self.stage_1 = self._make_layer(64 , 1)\n    self.stage_2 = self._make_layer(128, 2)\n    self.stage_3 = self._make_layer(256, 2)\n    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n    self.classifier = nn.Linear(256*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, planes, stride=1):\n    downsample = None\n    exp_planes = planes * self.block.expansion\n    if stride != 1 or self.inplanes != exp_planes:\n      downsample = nn.Sequential(\n        nn.Conv2d(self.inplanes, exp_planes, kernel_size=1, stride=stride, bias=False),\n        nn.BatchNorm2d(exp_planes),\n      )\n\n    layers = []\n    layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width, stride, downsample))\n    self.inplanes = exp_planes\n    for i in range(1, self.layer_blocks):\n      layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return F.log_softmax(self.classifier(x))\n\ndef resnext29_16_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 16*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 16, 64, num_classes)\n  return model\n\ndef resnext29_8_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 8*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 8, 64, num_classes)\n  return model\n'"
fastai/courses/dl2/fastai/models/cifar10/senet.py,3,"b""'''SENet in PyTorch.\n\nSENet is the winner of ImageNet-2017 (https://arxiv.org/abs/1709.01507).\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w  # New broadcasting feature from v0.2!\n\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w\n\n        out += shortcut\n        return out\n\n\nclass SENet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(SENet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        out = F.log_softmax(self.linear(out))\n        return out\n\n\ndef SENet18(): return SENet(PreActBlock, [2,2,2,2])\ndef SENet34(): return SENet(PreActBlock, [3,4,6,3])\n\n"""
fastai/courses/dl2/fastai/models/cifar10/utils.py,0,"b'import os, sys, time\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n'"
fastai/courses/dl2/fastai/models/cifar10/utils_kuangliu.py,5,"b""'''Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n'''\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\ndef get_mean_and_std(dataset):\n    '''Compute the mean and std value of dataset.'''\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print('==> Computing mean and std..')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    '''Init layer parameters.'''\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode='fan_out')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\n\n_, term_width = os.popen('stty size', 'r').read().split()\nterm_width = int(term_width)\n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f\n"""
fastai/courses/dl2/fastai/models/cifar10/wideresnet.py,2,"b'# Cifar10 Wideresnet for Dawn Submission\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ...layers import *\n\ndef conv_2d(ni, nf, ks, stride): return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn(ni, init_zero=False):\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv_2d(ni, nf, ks, stride))\n\ndef noop(x): return x\n\nclass BasicBlock(nn.Module):\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        super().__init__()\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv_2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv_2d(ni, nf, 1, stride) if ni != nf else noop\n\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)\n        r = self.shortcut(x2)\n        x = self.conv1(x2)\n        if self.drop: x = self.drop(x)\n        x = self.conv2(x) * 0.2\n        return x.add_(r)\n\n\ndef _make_group(N, ni, nf, block, stride, drop_p):\n    return [block(ni if i == 0 else nf, nf, stride if i == 0 else 1, drop_p) for i in range(N)]\n\nclass WideResNet(nn.Module):\n    def __init__(self, num_groups, N, num_classes, k=1, drop_p=0.0, start_nf=16):\n        super().__init__()\n        n_channels = [start_nf]\n        for i in range(num_groups): n_channels.append(start_nf*(2**i)*k)\n\n        layers = [conv_2d(3, n_channels[0], 3, 1)]  # conv1\n        for i in range(num_groups):\n            layers += _make_group(N, n_channels[i], n_channels[i+1], BasicBlock, (1 if i==0 else 2), drop_p)\n\n        layers += [nn.BatchNorm2d(n_channels[3]), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),\n                   Flatten(), nn.Linear(n_channels[3], num_classes)]\n        self.features = nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef wrn_22(): return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.)\ndef wrn_22_k8(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.)\ndef wrn_22_k10(): return WideResNet(num_groups=3, N=3, num_classes=10, k=10, drop_p=0.)\ndef wrn_22_k8_p2(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.)\ndef wrn_28_k8(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.)\ndef wrn_28_k8_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.2)\n\n'"
fastai/courses/ml1/fastai/models/cifar10/main_dxy.py,16,"b'from __future__ import division\n\nfrom senet import *\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'--data_path\', default=\'./data\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', default=\'cifar10\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=64, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.05, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(0)\n\nif args.manualSeed is None: args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda: torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n  if not os.path.isdir(args.save_path): os.makedirs(args.save_path)\n  log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n  print_log(\'save path : {}\'.format(args.save_path), log)\n  state = {k: v for k, v in args._get_kwargs()}\n  print_log(state, log)\n  print_log(""Random Seed: {}"".format(args.manualSeed), log)\n  print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n  print_log(""torch  version : {}"".format(torch.__version__), log)\n  print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n\n  # Init dataset\n  if not os.path.isdir(args.data_path):\n    os.makedirs(args.data_path)\n\n  if args.dataset == \'cifar10\':\n    mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n    std = [x / 255 for x in [63.0, 62.1, 66.7]]\n  elif args.dataset == \'cifar100\':\n    mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n    std = [x / 255 for x in [68.2, 65.4, 70.4]]\n  else:\n    assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n  train_transform = transforms.Compose(\n    [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n     transforms.Normalize(mean, std)])\n  test_transform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n  if args.dataset == \'cifar10\':\n    train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'cifar100\':\n    train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n    test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n    num_classes = 100\n  elif args.dataset == \'svhn\':\n    train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'stl10\':\n    train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n    test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n    num_classes = 10\n  elif args.dataset == \'imagenet\':\n    assert False, \'Do not finish imagenet code\'\n  else:\n    assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n  train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                         num_workers=args.workers, pin_memory=True)\n  test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                        num_workers=args.workers, pin_memory=True)\n\n  # Init model, criterion, and optimizer\n  #net = models.__dict__[args.arch](num_classes).cuda()\n  net = SENet34()\n\n  # define loss function (criterion) and optimizer\n  criterion = F.nll_loss\n  optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                weight_decay=state[\'decay\'], nesterov=True)\n\n  if args.use_cuda: net.cuda()\n\n  recorder = RecorderMeter(args.epochs)\n  # optionally resume from a checkpoint\n  if args.resume:\n    if os.path.isfile(args.resume):\n      print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n      checkpoint = torch.load(args.resume)\n      recorder = checkpoint[\'recorder\']\n      args.start_epoch = checkpoint[\'epoch\']\n      net.load_state_dict(checkpoint[\'state_dict\'])\n      optimizer.load_state_dict(checkpoint[\'optimizer\'])\n      print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n    else:\n      print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n  else:\n    print_log(""=> do not use any checkpoint for model"", log)\n\n  if args.evaluate:\n    validate(test_loader, net, criterion, log)\n    return\n\n  # Main loop\n  start_time = time.time()\n  epoch_time = AverageMeter()\n  for epoch in range(args.start_epoch, args.epochs):\n    current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n    need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n    print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n    # train for one epoch\n    train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n    # evaluate on validation set\n    val_acc,   val_los   = validate(test_loader, net, criterion, log)\n    is_best = recorder.update(epoch, train_los, train_acc, val_los, val_acc)\n\n    save_checkpoint({\n      \'epoch\': epoch + 1,\n      \'state_dict\': net.state_dict(),\n      \'recorder\': recorder,\n      \'optimizer\' : optimizer.state_dict(),\n    }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n    # measure elapsed time\n    epoch_time.update(time.time() - start_time)\n    start_time = time.time()\n    recorder.plot_curve( os.path.join(args.save_path, \'curve.png\') )\n\n  log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n  batch_time = AverageMeter()\n  data_time = AverageMeter()\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n  # switch to train mode\n  model.train()\n\n  end = time.time()\n  for i, (input, target) in enumerate(train_loader):\n    # measure data loading time\n    data_time.update(time.time() - end)\n\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input)\n    target_var = torch.autograd.Variable(target)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n    # compute gradient and do SGD step\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # measure elapsed time\n    batch_time.update(time.time() - end)\n    end = time.time()\n\n  print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n        epoch, i, len(train_loader), batch_time=batch_time,\n        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n  return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n  losses = AverageMeter()\n  top1 = AverageMeter()\n  top5 = AverageMeter()\n\n  # switch to evaluate mode\n  model.eval()\n\n  for i, (input, target) in enumerate(val_loader):\n    if args.use_cuda:\n      target = target.cuda(async=True)\n      input = input.cuda()\n    input_var = torch.autograd.Variable(input, volatile=True)\n    target_var = torch.autograd.Variable(target, volatile=True)\n\n    # compute output\n    output = model(input_var)\n    loss = criterion(output, target_var)\n\n    # measure accuracy and record loss\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    losses.update(loss.data[0], input.size(0))\n    top1.update(prec1[0], input.size(0))\n    top5.update(prec5[0], input.size(0))\n\n  print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n  return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n  print(""{}"".format(print_string))\n  log.write(\'{}\\n\'.format(print_string))\n  log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n  filename = os.path.join(save_path, filename)\n  torch.save(state, filename)\n  if is_best:\n    bestname = os.path.join(save_path, \'model_best.pth.tar\')\n    shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n  """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n  lr = args.learning_rate\n  assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n  for (gamma, step) in zip(gammas, schedule):\n    if (epoch >= step):\n      lr = lr * gamma\n    else:\n      break\n  for param_group in optimizer.param_groups:\n    param_group[\'lr\'] = lr\n  return lr\n\ndef accuracy(output, target, topk=(1,)):\n  """"""Computes the precision@k for the specified values of k""""""\n  maxk = max(topk)\n  batch_size = target.size(0)\n\n  _, pred = output.topk(maxk, 1, True, True)\n  pred = pred.t()\n  correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n  res = []\n  for k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0)\n    res.append(correct_k.mul_(100.0 / batch_size))\n  return res\n\nif __name__ == \'__main__\':\n  main()\n'"
fastai/courses/ml1/fastai/models/cifar10/main_kuangliu.py,15,"b""'''Train CIFAR10 with PyTorch.'''\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\n\nfrom senet import *\nfrom utils import progress_bar\nfrom torch.autograd import Variable\n\n\nparser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\nparser.add_argument('--lr', default=0.1, type=float, help='learning rate')\nparser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\nargs = parser.parse_args()\n\nuse_cuda = torch.cuda.is_available()\ntorch.cuda.set_device(3)\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/ckpt.t7')\n    net = checkpoint['net']\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']\nelse:\n    print('==> Building model..')\n    # net = VGG('VGG19')\n    # net = ResNet18()\n    # net = PreActResNet18()\n    # net = GoogLeNet()\n    # net = DenseNet121()\n    # net = ResNeXt29_2x64d()\n    # net = MobileNet()\n    # net = DPN92()\n    # net = ShuffleNetG2()\n    net = SENet18()\n\nif use_cuda:\n    net.cuda()\n    #net = torch.nn.DataParallel(net, device_ids=(0,3))\n    #net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n    cudnn.benchmark = True\n\ncriterion = F.nll_loss\noptimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n\n# Training\ndef train(epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        optimizer.zero_grad()\n        inputs, targets = Variable(inputs), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n\n        test_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\n            'net': net,\n            'acc': acc,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt.t7')\n        best_acc = acc\n\n\nfor epoch in range(start_epoch, start_epoch+100):\n    train(epoch)\n    test(epoch)\n"""
fastai/courses/ml1/fastai/models/cifar10/preact_resnet.py,3,"b""'''Pre-activation ResNet in PyTorch.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass PreActResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(PreActResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        return F.log_softmax(self.linear(out))\n\ndef PreActResNet18(): return PreActResNet(PreActBlock, [2,2,2,2])\ndef PreActResNet34(): return PreActResNet(PreActBlock, [3,4,6,3])\ndef PreActResNet50(): return PreActResNet(PreActBottleneck, [3,4,6,3])\ndef PreActResNet101(): return PreActResNet(PreActBottleneck, [3,4,23,3])\ndef PreActResNet152(): return PreActResNet(PreActBottleneck, [3,8,36,3])\n\n"""
fastai/courses/ml1/fastai/models/cifar10/resnext.py,3,"b'import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\nclass ResNeXtBottleneck(nn.Module):\n  expansion = 4\n  """"""\n  RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n  """"""\n  def __init__(self, inplanes, planes, cardinality, base_width, stride=1, downsample=None):\n    super(ResNeXtBottleneck, self).__init__()\n    self.downsample = downsample\n\n    D = int(math.floor(planes * (base_width/64.0)))\n    C = cardinality\n    self.conv_reduce = nn.Conv2d(inplanes, D*C, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_reduce = nn.BatchNorm2d(D*C)\n\n    self.conv_conv = nn.Conv2d(D*C, D*C, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n    self.bn = nn.BatchNorm2d(D*C)\n    self.conv_expand = nn.Conv2d(D*C, planes*4, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_expand = nn.BatchNorm2d(planes*4)\n\n  def forward(self, x):\n    residual = x\n\n    bottleneck = self.conv_reduce(x)\n    bottleneck = F.relu(self.bn_reduce(bottleneck), inplace=True)\n\n    bottleneck = self.conv_conv(bottleneck)\n    bottleneck = F.relu(self.bn(bottleneck), inplace=True)\n\n    bottleneck = self.conv_expand(bottleneck)\n    bottleneck = self.bn_expand(bottleneck)\n\n    if self.downsample is not None: residual = self.downsample(x)\n    return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n  """"""\n  ResNext optimized for the Cifar dataset, as specified in\n  https://arxiv.org/pdf/1611.05431.pdf\n  """"""\n  def __init__(self, block, depth, cardinality, base_width, num_classes):\n    super(CifarResNeXt, self).__init__()\n\n    # Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 9 == 0, \'depth should be one of 29, 38, 47, 56, 101\'\n    self.layer_blocks = (depth - 2) // 9\n\n    self.cardinality,self.base_width,self.num_classes,self.block = cardinality,base_width,num_classes,block\n\n    self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(64)\n\n    self.inplanes = 64\n    self.stage_1 = self._make_layer(64 , 1)\n    self.stage_2 = self._make_layer(128, 2)\n    self.stage_3 = self._make_layer(256, 2)\n    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n    self.classifier = nn.Linear(256*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, planes, stride=1):\n    downsample = None\n    exp_planes = planes * self.block.expansion\n    if stride != 1 or self.inplanes != exp_planes:\n      downsample = nn.Sequential(\n        nn.Conv2d(self.inplanes, exp_planes, kernel_size=1, stride=stride, bias=False),\n        nn.BatchNorm2d(exp_planes),\n      )\n\n    layers = []\n    layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width, stride, downsample))\n    self.inplanes = exp_planes\n    for i in range(1, self.layer_blocks):\n      layers.append(self.block(self.inplanes, planes, self.cardinality, self.base_width))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return F.log_softmax(self.classifier(x))\n\ndef resnext29_16_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 16*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 16, 64, num_classes)\n  return model\n\ndef resnext29_8_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 8*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 8, 64, num_classes)\n  return model\n'"
fastai/courses/ml1/fastai/models/cifar10/senet.py,3,"b""'''SENet in PyTorch.\n\nSENet is the winner of ImageNet-2017 (https://arxiv.org/abs/1709.01507).\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w  # New broadcasting feature from v0.2!\n\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w\n\n        out += shortcut\n        return out\n\n\nclass SENet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(SENet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.adaptive_max_pool2d(out, 1)\n        out = out.view(out.size(0), -1)\n        out = F.log_softmax(self.linear(out))\n        return out\n\n\ndef SENet18(): return SENet(PreActBlock, [2,2,2,2])\ndef SENet34(): return SENet(PreActBlock, [3,4,6,3])\n\n"""
fastai/courses/ml1/fastai/models/cifar10/utils.py,0,"b'import os, sys, time\nimport numpy as np\nimport matplotlib\nmatplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n'"
fastai/courses/ml1/fastai/models/cifar10/utils_kuangliu.py,5,"b""'''Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n'''\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\ndef get_mean_and_std(dataset):\n    '''Compute the mean and std value of dataset.'''\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print('==> Computing mean and std..')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    '''Init layer parameters.'''\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode='fan_out')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\n\n_, term_width = os.popen('stty size', 'r').read().split()\nterm_width = int(term_width)\n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f\n"""
fastai/courses/ml1/fastai/models/cifar10/wideresnet.py,2,"b'# Cifar10 Wideresnet for Dawn Submission\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ...layers import *\n\ndef conv_2d(ni, nf, ks, stride): return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n\ndef bn(ni, init_zero=False):\n    m = nn.BatchNorm2d(ni)\n    m.weight.data.fill_(0 if init_zero else 1)\n    m.bias.data.zero_()\n    return m\n\ndef bn_relu_conv(ni, nf, ks, stride, init_zero=False):\n    bn_initzero = bn(ni, init_zero=init_zero)\n    return nn.Sequential(bn_initzero, nn.ReLU(inplace=True), conv_2d(ni, nf, ks, stride))\n\ndef noop(x): return x\n\nclass BasicBlock(nn.Module):\n    def __init__(self, ni, nf, stride, drop_p=0.0):\n        super().__init__()\n        self.bn = nn.BatchNorm2d(ni)\n        self.conv1 = conv_2d(ni, nf, 3, stride)\n        self.conv2 = bn_relu_conv(nf, nf, 3, 1)\n        self.drop = nn.Dropout(drop_p, inplace=True) if drop_p else None\n        self.shortcut = conv_2d(ni, nf, 1, stride) if ni != nf else noop\n\n    def forward(self, x):\n        x2 = F.relu(self.bn(x), inplace=True)\n        r = self.shortcut(x2)\n        x = self.conv1(x2)\n        if self.drop: x = self.drop(x)\n        x = self.conv2(x) * 0.2\n        return x.add_(r)\n\n\ndef _make_group(N, ni, nf, block, stride, drop_p):\n    return [block(ni if i == 0 else nf, nf, stride if i == 0 else 1, drop_p) for i in range(N)]\n\nclass WideResNet(nn.Module):\n    def __init__(self, num_groups, N, num_classes, k=1, drop_p=0.0, start_nf=16):\n        super().__init__()\n        n_channels = [start_nf]\n        for i in range(num_groups): n_channels.append(start_nf*(2**i)*k)\n\n        layers = [conv_2d(3, n_channels[0], 3, 1)]  # conv1\n        for i in range(num_groups):\n            layers += _make_group(N, n_channels[i], n_channels[i+1], BasicBlock, (1 if i==0 else 2), drop_p)\n\n        layers += [nn.BatchNorm2d(n_channels[3]), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d(1),\n                   Flatten(), nn.Linear(n_channels[3], num_classes)]\n        self.features = nn.Sequential(*layers)\n\n    def forward(self, x): return self.features(x)\n\n\ndef wrn_22(): return WideResNet(num_groups=3, N=3, num_classes=10, k=6, drop_p=0.)\ndef wrn_22_k8(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.)\ndef wrn_22_k10(): return WideResNet(num_groups=3, N=3, num_classes=10, k=10, drop_p=0.)\ndef wrn_22_k8_p2(): return WideResNet(num_groups=3, N=3, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.)\ndef wrn_28_k8(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.)\ndef wrn_28_k8_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=8, drop_p=0.2)\ndef wrn_28_p2(): return WideResNet(num_groups=3, N=4, num_classes=10, k=6, drop_p=0.2)\n\n'"
