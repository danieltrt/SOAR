file_path,api_count,code
original_train.py,19,"b'# https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py\nimport argparse\nimport os, sys\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models\nfrom utils import convert_secs2time, time_string, time_file_str\n#from models import print_log\nimport models\nimport random\nimport numpy as np\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--save_dir\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\', help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=100, type=int, metavar=\'N\', help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int, metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float, metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\', help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float, metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 100)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\n\nargs.prefix = time_file_str()\n\ndef main():\n    best_prec1 = 0\n\n    if not os.path.isdir(args.save_dir):\n      os.makedirs(args.save_dir)\n    log = open(os.path.join(args.save_dir, \'{}.{}.log\'.format(args.arch,args.prefix)), \'w\')\n\n    # version information\n    print_log(""PyThon  version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""PyTorch version : {}"".format(torch.__version__), log)\n    print_log(""cuDNN   version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Vision  version : {}"".format(torchvision.__version__), log)\n    # create model\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](pretrained=False)\n    print_log(""=> Model : {}"".format(model), log)\n    print_log(""=> parameter : {}"".format(args), log)\n\n    if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n      model.features = torch.nn.DataParallel(model.features)\n      model.cuda()\n    else:\n      model = torch.nn.DataParallel(model).cuda()\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay,\n                                nesterov=True)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"".format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=args.workers, pin_memory=True, sampler=None)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    filename = os.path.join(args.save_dir, \'checkpoint.{}.{}.pth.tar\'.format(args.arch, args.prefix))\n    bestname = os.path.join(args.save_dir, \'best.{}.{}.pth.tar\'.format(args.arch, args.prefix))\n\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.val * (args.epochs-epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n        print_log(\' [{:s}] :: {:3d}/{:3d} ----- [{:s}] {:s}\'.format(args.arch, epoch, args.epochs, time_string(), need_time), log)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, log)\n        # evaluate on validation set\n        val_acc_2 = validate(val_loader, model, criterion, log)\n\n        # remember best prec@1 and save checkpoint\n        is_best = val_acc_2 > best_prec1\n        best_prec1 = max(val_acc_2, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, filename, bestname)\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n    log.close()\n\n\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5), log)\n\n\ndef validate(val_loader, model, criterion, log):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5), log)\n\n    print_log(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n    return top1.avg\n\n\ndef save_checkpoint(state, is_best, filename, bestname):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, bestname)\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n  \n  \nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nif __name__ == \'__main__\':\n    main()\n'"
pruning_cifar10.py,46,"b'from __future__ import division\n\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time, timing\nimport models\nimport numpy as np\nimport pickle\nfrom scipy.spatial import distance\nimport pdb\n\nmodel_names = sorted(name for name in models.__dict__\n                     if name.islower() and not name.startswith(""__"")\n                     and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\',\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'],\n                    help=\'Choose between Cifar10/100 and ImageNet.\')\nparser.add_argument(\'--arch\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names,\n                    help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnext29_8_64)\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=128, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.1, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225],\n                    help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1],\n                    help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--ngpu\', type=int, default=1, help=\'0 = CPU.\')\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\n# compress rate\nparser.add_argument(\'--rate_norm\', type=float, default=0.9, help=\'the remaining ratio of pruning based on Norm\')\nparser.add_argument(\'--rate_dist\', type=float, default=0.1, help=\'the reducing ratio of pruning based on Distance\')\n\nparser.add_argument(\'--layer_begin\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--use_state_dict\', dest=\'use_state_dict\', action=\'store_true\', help=\'use state dcit or not\')\nparser.add_argument(\'--use_pretrain\', dest=\'use_pretrain\', action=\'store_true\', help=\'use pre-trained model or not\')\nparser.add_argument(\'--pretrain_path\', default=\'\', type=str, help=\'..path of pre-trained model\')\nparser.add_argument(\'--dist_type\', default=\'l2\', type=str, choices=[\'l2\', \'l1\', \'cos\'], help=\'distance type of GM\')\n\nargs = parser.parse_args()\nargs.use_cuda = args.ngpu > 0 and torch.cuda.is_available()\n\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\n\ndef main():\n    # Init logger\n    if not os.path.isdir(args.save_path):\n        os.makedirs(args.save_path)\n    log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n    print_log(\'save path : {}\'.format(args.save_path), log)\n    state = {k: v for k, v in args._get_kwargs()}\n    print_log(state, log)\n    print_log(""Random Seed: {}"".format(args.manualSeed), log)\n    print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""torch  version : {}"".format(torch.__version__), log)\n    print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Norm Pruning Rate: {}"".format(args.rate_norm), log)\n    print_log(""Distance Pruning Rate: {}"".format(args.rate_dist), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    print_log(""use pretrain: {}"".format(args.use_pretrain), log)\n    print_log(""Pretrain path: {}"".format(args.pretrain_path), log)\n    print_log(""Dist type: {}"".format(args.dist_type), log)\n\n    # Init dataset\n    if not os.path.isdir(args.data_path):\n        os.makedirs(args.data_path)\n\n    if args.dataset == \'cifar10\':\n        mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n        std = [x / 255 for x in [63.0, 62.1, 66.7]]\n    elif args.dataset == \'cifar100\':\n        mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n        std = [x / 255 for x in [68.2, 65.4, 70.4]]\n    else:\n        assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n    train_transform = transforms.Compose(\n        [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n         transforms.Normalize(mean, std)])\n    test_transform = transforms.Compose(\n        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n    if args.dataset == \'cifar10\':\n        train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'cifar100\':\n        train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 100\n    elif args.dataset == \'svhn\':\n        train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'stl10\':\n        train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'imagenet\':\n        assert False, \'Do not finish imagenet code\'\n    else:\n        assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                                               num_workers=args.workers, pin_memory=True)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                                              num_workers=args.workers, pin_memory=True)\n\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    # Init model, criterion, and optimizer\n    net = models.__dict__[args.arch](num_classes)\n    print_log(""=> network :\\n {}"".format(net), log)\n\n    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n\n    # define loss function (criterion) and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                                weight_decay=state[\'decay\'], nesterov=True)\n\n    if args.use_cuda:\n        net.cuda()\n        criterion.cuda()\n\n    if args.use_pretrain:\n        if os.path.isfile(args.pretrain_path):\n            print_log(""=> loading pretrain model \'{}\'"".format(args.pretrain_path), log)\n        else:\n            dir = \'/data/yahe/cifar10_base/\'\n            # dir = \'/data/uts521/yang/progress/cifar10_base/\'\n            whole_path = dir + \'cifar10_\' + args.arch + \'_base\'\n            args.pretrain_path = whole_path + \'/checkpoint.pth.tar\'\n            print_log(""Pretrain path: {}"".format(args.pretrain_path), log)\n        pretrain = torch.load(args.pretrain_path)\n        if args.use_state_dict:\n            net.load_state_dict(pretrain[\'state_dict\'])\n        else:\n            net = pretrain[\'state_dict\']\n\n    recorder = RecorderMeter(args.epochs)\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            recorder = checkpoint[\'recorder\']\n            args.start_epoch = checkpoint[\'epoch\']\n            if args.use_state_dict:\n                net.load_state_dict(checkpoint[\'state_dict\'])\n            else:\n                net = checkpoint[\'state_dict\']\n\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"".format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n    else:\n        print_log(""=> do not use any checkpoint for {} model"".format(args.arch), log)\n\n    if args.evaluate:\n        time1 = time.time()\n        validate(test_loader, net, criterion, log)\n        time2 = time.time()\n        print(\'function took %0.3f ms\' % ((time2 - time1) * 1000.0))\n        return\n\n    m = Mask(net)\n    m.init_length()\n    print(""-"" * 10 + ""one epoch begin"" + ""-"" * 10)\n    print(""remaining ratio of pruning : Norm is %f"" % args.rate_norm)\n    print(""reducing ratio of pruning : Distance is %f"" % args.rate_dist)\n    print(""total remaining ratio is %f"" % (args.rate_norm - args.rate_dist))\n\n    val_acc_1, val_los_1 = validate(test_loader, net, criterion, log)\n\n    print("" accu before is: %.3f %%"" % val_acc_1)\n\n    m.model = net\n\n    m.init_mask(args.rate_norm, args.rate_dist, args.dist_type)\n    #    m.if_zero()\n    m.do_mask()\n    m.do_similar_mask()\n    net = m.model\n    #    m.if_zero()\n    if args.use_cuda:\n        net = net.cuda()\n    val_acc_2, val_los_2 = validate(test_loader, net, criterion, log)\n    print("" accu after is: %s %%"" % val_acc_2)\n\n    # Main loop\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    small_filter_index = []\n    large_filter_index = []\n\n    for epoch in range(args.start_epoch, args.epochs):\n        current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs - epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n        print_log(\n            \'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs,\n                                                                                   need_time, current_learning_rate) \\\n            + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False),\n                                                               100 - recorder.max_accuracy(False)), log)\n\n        # train for one epoch\n        train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log, m)\n\n        # evaluate on validation set\n        val_acc_1, val_los_1 = validate(test_loader, net, criterion, log)\n        if epoch % args.epoch_prune == 0 or epoch == args.epochs - 1:\n            m.model = net\n            m.if_zero()\n            m.init_mask(args.rate_norm, args.rate_dist, args.dist_type)\n            m.do_mask()\n            m.do_similar_mask()\n            m.if_zero()\n            net = m.model\n            if args.use_cuda:\n                net = net.cuda()\n\n        val_acc_2, val_los_2 = validate(test_loader, net, criterion, log)\n\n        is_best = recorder.update(epoch, train_los, train_acc, val_los_2, val_acc_2)\n\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': net,\n            \'recorder\': recorder,\n            \'optimizer\': optimizer.state_dict(),\n        }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n        recorder.plot_curve(os.path.join(args.save_path, \'curve.png\'))\n\n    log.close()\n\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log, m):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        # Mask grad for iteration\n        m.do_grad_mask()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n                      \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n                epoch, i, len(train_loader), batch_time=batch_time,\n                data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n    print_log(\n        \'  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5,\n                                                                                              error1=100 - top1.avg),\n        log)\n    return top1.avg, losses.avg\n\n\ndef validate(val_loader, model, criterion, log):\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    for i, (input, target) in enumerate(val_loader):\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n    print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5,\n                                                                                                   error1=100 - top1.avg),\n              log)\n\n    return top1.avg, losses.avg\n\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\n\ndef save_checkpoint(state, is_best, save_path, filename):\n    filename = os.path.join(save_path, filename)\n    torch.save(state, filename)\n    if is_best:\n        bestname = os.path.join(save_path, \'model_best.pth.tar\')\n        shutil.copyfile(filename, bestname)\n\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.learning_rate\n    assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n    for (gamma, step) in zip(gammas, schedule):\n        if (epoch >= step):\n            lr = lr * gamma\n        else:\n            break\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\ndef save_obj(obj, name):\n    with open(\'obj/\' + name + \'.pkl\', \'wb\') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n\n\ndef load_obj(name):\n    with open(\'obj/\' + name + \'.pkl\', \'rb\') as f:\n        return pickle.load(f)\n\n\nclass Mask:\n    def __init__(self, model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.distance_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n        self.filter_small_index = {}\n        self.filter_large_index = {}\n        self.similar_matrix = {}\n        self.norm_matrix = {}\n\n    def get_codebook(self, weight_torch, compress_rate, length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n\n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n\n        threshold = weight_sort[int(length * (1 - compress_rate))]\n        weight_np[weight_np <= -threshold] = 1\n        weight_np[weight_np >= threshold] = 1\n        weight_np[weight_np != 1] = 0\n\n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch, compress_rate, length):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n            #            norm1_sort = np.sort(norm1_np)\n            #            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(filter_index)):\n                codebook[filter_index[x] * kernel_length: (filter_index[x] + 1) * kernel_length] = 0\n\n            print(""filter codebook done"")\n        else:\n            pass\n        return codebook\n\n    def get_filter_index(self, weight_torch, compress_rate, length):\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            # norm1 = torch.norm(weight_vec, 1, 1)\n            # norm1_np = norm1.cpu().numpy()\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_small_index = []\n            filter_large_index = []\n            filter_large_index = norm2_np.argsort()[filter_pruned_num:]\n            filter_small_index = norm2_np.argsort()[:filter_pruned_num]\n            #            norm1_sort = np.sort(norm1_np)\n            #            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            # print(""filter index done"")\n        else:\n            pass\n        return filter_small_index, filter_large_index\n\n    # optimize for fast ccalculation\n    def get_filter_similar(self, weight_torch, compress_rate, distance_rate, length, dist_type=""l2""):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            similar_pruned_num = int(weight_torch.size()[0] * distance_rate)\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n\n            if dist_type == ""l2"" or ""cos"":\n                norm = torch.norm(weight_vec, 2, 1)\n                norm_np = norm.cpu().numpy()\n            elif dist_type == ""l1"":\n                norm = torch.norm(weight_vec, 1, 1)\n                norm_np = norm.cpu().numpy()\n            filter_small_index = []\n            filter_large_index = []\n            filter_large_index = norm_np.argsort()[filter_pruned_num:]\n            filter_small_index = norm_np.argsort()[:filter_pruned_num]\n\n            # # distance using pytorch function\n            # similar_matrix = torch.zeros((len(filter_large_index), len(filter_large_index)))\n            # for x1, x2 in enumerate(filter_large_index):\n            #     for y1, y2 in enumerate(filter_large_index):\n            #         # cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n            #         # similar_matrix[x1, y1] = cos(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0]\n            #         pdist = torch.nn.PairwiseDistance(p=2)\n            #         similar_matrix[x1, y1] = pdist(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0][0]\n            # # more similar with other filter indicates large in the sum of row\n            # similar_sum = torch.sum(torch.abs(similar_matrix), 0).numpy()\n\n            # distance using numpy function\n            indices = torch.LongTensor(filter_large_index).cuda()\n            weight_vec_after_norm = torch.index_select(weight_vec, 0, indices).cpu().numpy()\n            # for euclidean distance\n            if dist_type == ""l2"" or ""l1"":\n                similar_matrix = distance.cdist(weight_vec_after_norm, weight_vec_after_norm, \'euclidean\')\n            elif dist_type == ""cos"":  # for cos similarity\n                similar_matrix = 1 - distance.cdist(weight_vec_after_norm, weight_vec_after_norm, \'cosine\')\n            similar_sum = np.sum(np.abs(similar_matrix), axis=0)\n\n            # for distance similar: get the filter index with largest similarity == small distance\n            similar_large_index = similar_sum.argsort()[similar_pruned_num:]\n            similar_small_index = similar_sum.argsort()[:  similar_pruned_num]\n            similar_index_for_filter = [filter_large_index[i] for i in similar_small_index]\n\n            print(\'filter_large_index\', filter_large_index)\n            print(\'filter_small_index\', filter_small_index)\n            print(\'similar_sum\', similar_sum)\n            print(\'similar_large_index\', similar_large_index)\n            print(\'similar_small_index\', similar_small_index)\n            print(\'similar_index_for_filter\', similar_index_for_filter)\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(similar_index_for_filter)):\n                codebook[\n                similar_index_for_filter[x] * kernel_length: (similar_index_for_filter[x] + 1) * kernel_length] = 0\n            print(""similar index done"")\n        else:\n            pass\n        return codebook\n\n    def convert2tensor(self, x):\n        x = torch.FloatTensor(x)\n        return x\n\n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size[index] = item.size()\n\n        for index1 in self.model_size:\n            for index2 in range(0, len(self.model_size[index1])):\n                if index2 == 0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n\n    def init_rate(self, rate_norm_per_layer, rate_dist_per_layer):\n        for index, item in enumerate(self.model.parameters()):\n            self.compress_rate[index] = 1\n            self.distance_rate[index] = 1\n        for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n            self.compress_rate[key] = rate_norm_per_layer\n            self.distance_rate[key] = rate_dist_per_layer\n        # different setting for  different architecture\n        if args.arch == \'resnet20\':\n            last_index = 57\n        elif args.arch == \'resnet32\':\n            last_index = 93\n        elif args.arch == \'resnet56\':\n            last_index = 165\n        elif args.arch == \'resnet110\':\n            last_index = 327\n        # to jump the last fc layer\n        self.mask_index = [x for x in range(0, last_index, 3)]\n\n    #        self.mask_index =  [x for x in range (0,330,3)]\n\n    def init_mask(self, rate_norm_per_layer, rate_dist_per_layer, dist_type):\n        self.init_rate(rate_norm_per_layer, rate_dist_per_layer)\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                # mask for norm criterion\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],\n                                                           self.model_length[index])\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.use_cuda:\n                    self.mat[index] = self.mat[index].cuda()\n\n                # # get result about filter index\n                # self.filter_small_index[index], self.filter_large_index[index] = \\\n                #     self.get_filter_index(item.data, self.compress_rate[index], self.model_length[index])\n\n                # mask for distance criterion\n                self.similar_matrix[index] = self.get_filter_similar(item.data, self.compress_rate[index],\n                                                                     self.distance_rate[index],\n                                                                     self.model_length[index], dist_type=dist_type)\n                self.similar_matrix[index] = self.convert2tensor(self.similar_matrix[index])\n                if args.use_cuda:\n                    self.similar_matrix[index] = self.similar_matrix[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def do_similar_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.data.view(self.model_length[index])\n                b = a * self.similar_matrix[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask similar Done"")\n\n    def do_grad_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.grad.data.view(self.model_length[index])\n                # reverse the mask of model\n                # b = a * (1 - self.mat[index])\n                b = a * self.mat[index]\n                b = b * self.similar_matrix[index]\n                item.grad.data = b.view(self.model_size[index])\n        # print(""grad zero Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n            if (index in self.mask_index):\n                # if index == 0:\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n\n                print(\n                    ""number of nonzero weight is %d, zero is %d"" % (np.count_nonzero(b), len(b) - np.count_nonzero(b)))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
pruning_imagenet.py,55,"b'# https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py\nimport argparse\nimport os, sys\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models\nfrom utils import convert_secs2time, time_string, time_file_str, timing\n# from models import print_log\nimport models\nimport random\nimport numpy as np\nfrom scipy.spatial import distance\nfrom collections import OrderedDict\n\nmodel_names = sorted(name for name in models.__dict__\n                     if name.islower() and not name.startswith(""__"")\n                     and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--save_dir\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                         \' | \'.join(model_names) +\n                         \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=100, type=int, metavar=\'N\', help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int, metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float, metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\', help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float, metavar=\'W\',\n                    help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 100)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\nparser.add_argument(\'--use_pretrain\', dest=\'use_pretrain\', action=\'store_true\', help=\'use pre-trained model or not\')\n\n# compress rate\nparser.add_argument(\'--rate_norm\', type=float, default=0.9, help=\'the remaining ratio of pruning based on Norm\')\nparser.add_argument(\'--rate_dist\', type=float, default=0.1, help=\'the reducing ratio of pruning based on Distance\')\n\nparser.add_argument(\'--layer_begin\', type=int, default=3, help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=3, help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1, help=\'epoch interval of pruning\')\nparser.add_argument(\'--skip_downsample\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--use_sparse\', dest=\'use_sparse\', action=\'store_true\', help=\'use sparse model as initial or not\')\nparser.add_argument(\'--sparse\',\n                    default=\'/data/yahe/imagenet/resnet50-rate-0.7/checkpoint.resnet50.2018-01-07-9744.pth.tar\',\n                    type=str, metavar=\'PATH\', help=\'path of sparse model\')\nparser.add_argument(\'--lr_adjust\', type=int, default=30, help=\'number of epochs that change learning rate\')\nparser.add_argument(\'--VGG_pruned_style\', choices=[""CP_5x"", ""Thinet_conv""],\n                    help=\'number of epochs that change learning rate\')\n\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\n\nargs.prefix = time_file_str()\n\n\ndef main():\n    best_prec1 = 0\n\n    if not os.path.isdir(args.save_dir):\n        os.makedirs(args.save_dir)\n    log = open(os.path.join(args.save_dir, \'{}.{}.log\'.format(args.arch, args.prefix)), \'w\')\n\n    # version information\n    print_log(""PyThon  version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""PyTorch version : {}"".format(torch.__version__), log)\n    print_log(""cuDNN   version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Vision  version : {}"".format(torchvision.__version__), log)\n    # create model\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](pretrained=args.use_pretrain)\n    if args.use_sparse:\n        model = import_sparse(model)\n    print_log(""=> Model : {}"".format(model), log)\n    print_log(""=> parameter : {}"".format(args), log)\n    print_log(""Norm Pruning Rate: {}"".format(args.rate_norm), log)\n    print_log(""Distance Pruning Rate: {}"".format(args.rate_dist), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    print_log(""Skip downsample : {}"".format(args.skip_downsample), log)\n    print_log(""Workers         : {}"".format(args.workers), log)\n    print_log(""Learning-Rate   : {}"".format(args.lr), log)\n    print_log(""Use Pre-Trained : {}"".format(args.use_pretrain), log)\n    print_log(""lr adjust : {}"".format(args.lr_adjust), log)\n    print_log(""VGG pruned style : {}"".format(args.VGG_pruned_style), log)\n\n    if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n        model.features = torch.nn.DataParallel(model.features)\n        model.cuda()\n    else:\n        model = torch.nn.DataParallel(model).cuda()\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay,\n                                nesterov=True)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"".format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=args.workers, pin_memory=True, sampler=None)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion, log)\n        return\n\n    filename = os.path.join(args.save_dir, \'checkpoint.{:}.{:}.pth.tar\'.format(args.arch, args.prefix))\n    bestname = os.path.join(args.save_dir, \'best.{:}.{:}.pth.tar\'.format(args.arch, args.prefix))\n\n    m = Mask(model)\n\n    m.init_length()\n    print(""-"" * 10 + ""one epoch begin"" + ""-"" * 10)\n    print(""remaining ratio of pruning : Norm is %f"" % args.rate_norm)\n    print(""reducing ratio of pruning : Distance is %f"" % args.rate_dist)\n    print(""total remaining ratio is %f"" % (args.rate_norm - args.rate_dist))\n\n    m.model = model\n\n    m.init_mask(args.rate_norm, args.rate_dist)\n    # m.if_zero()\n    m.do_mask()\n    m.do_similar_mask()\n    model = m.model\n    m.if_zero()\n    if args.use_cuda:\n        model = model.cuda()\n    val_acc_2 = validate(val_loader, model, criterion, log)\n    print("">>>>> accu after is: {:}"".format(val_acc_2))\n\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.val * (args.epochs - epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n        print_log(\n            \' [{:s}] :: {:3d}/{:3d} ----- [{:s}] {:s}\'.format(args.arch, epoch, args.epochs, time_string(), need_time),\n            log)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, log, m)\n        # evaluate on validation set\n        val_acc_1 = validate(val_loader, model, criterion, log)\n        if epoch % args.epoch_prune == 0 or epoch == args.epochs - 1:\n            m.model = model\n            m.if_zero()\n            m.init_mask(args.rate_norm, args.rate_dist)\n            m.do_mask()\n            m.do_similar_mask()\n            m.if_zero()\n            model = m.model\n            if args.use_cuda:\n                model = model.cuda()\n\n        val_acc_2 = validate(val_loader, model, criterion, log)\n\n        # remember best prec@1 and save checkpoint\n        is_best = val_acc_2 > best_prec1\n        best_prec1 = max(val_acc_2, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\': optimizer.state_dict(),\n        }, is_best, filename, bestname)\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n    log.close()\n\n\ndef import_sparse(model):\n    checkpoint = torch.load(args.sparse)\n    new_state_dict = OrderedDict()\n    for k, v in checkpoint[\'state_dict\'].items():\n        name = k[7:]  # remove `module.`\n        new_state_dict[name] = v\n    model.load_state_dict(new_state_dict)\n    print(""sparse_model_loaded"")\n    return model\n\n\ndef train(train_loader, model, criterion, optimizer, epoch, log, m):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n\n        # Mask grad for iteration\n        m.do_grad_mask()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Epoch: [{0}][{1}/{2}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                epoch, i, len(train_loader), batch_time=batch_time,\n                data_time=data_time, loss=losses, top1=top1, top5=top5), log)\n\n\ndef validate(val_loader, model, criterion, log):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                i, len(val_loader), batch_time=batch_time, loss=losses,\n                top1=top1, top5=top5), log)\n\n    print_log(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5,\n                                                                                           error1=100 - top1.avg), log)\n\n    return top1.avg\n\n\ndef save_checkpoint(state, is_best, filename, bestname):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, bestname)\n\n\ndef print_log(print_string, log):\n    print(""{:}"".format(print_string))\n    log.write(\'{:}\\n\'.format(print_string))\n    log.flush()\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // args.lr_adjust))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass Mask:\n    def __init__(self, model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.distance_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n        self.filter_small_index = {}\n        self.filter_large_index = {}\n        self.similar_matrix = {}\n\n    def get_codebook(self, weight_torch, compress_rate, length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n\n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n\n        threshold = weight_sort[int(length * (1 - compress_rate))]\n        weight_np[weight_np <= -threshold] = 1\n        weight_np[weight_np >= threshold] = 1\n        weight_np[weight_np != 1] = 0\n\n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch, compress_rate, length):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            # norm1 = torch.norm(weight_vec, 1, 1)\n            # norm1_np = norm1.cpu().numpy()\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n            #            norm1_sort = np.sort(norm1_np)\n            #            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(filter_index)):\n                codebook[filter_index[x] * kernel_length: (filter_index[x] + 1) * kernel_length] = 0\n            print(""filter codebook done"")\n        elif len(weight_torch.size()) == 2:\n            weight_torch = weight_torch.view(weight_torch.size()[0], weight_torch.size()[1], 1, 1)\n            codebook = self.get_filter_codebook(weight_torch, compress_rate, length)\n            print(""filter codebook for fc done"")\n        else:\n            pass\n        return codebook\n\n    @timing\n    def get_filter_similar_old(self, weight_torch, compress_rate, distance_rate, length):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            similar_pruned_num = int(weight_torch.size()[0] * distance_rate)\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            # norm1 = torch.norm(weight_vec, 1, 1)\n            # norm1_np = norm1.cpu().numpy()\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_small_index = []\n            filter_large_index = []\n            filter_large_index = norm2_np.argsort()[filter_pruned_num:]\n            filter_small_index = norm2_np.argsort()[:filter_pruned_num]\n            print(\'weight_vec.size\', weight_vec.size())\n            # distance using pytorch function\n            similar_matrix = torch.zeros((len(filter_large_index), len(filter_large_index)))\n            for x1, x2 in enumerate(filter_large_index):\n                for y1, y2 in enumerate(filter_large_index):\n                    # cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n                    # similar_matrix[x1, y1] = cos(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0]\n                    pdist = torch.nn.PairwiseDistance(p=2)\n                    # print(\'weight_vec[x2].size\', weight_vec[x2].size())\n                    similar_matrix[x1, y1] = pdist(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0][0]\n                    # print(\'weight_vec[x2].size after\', weight_vec[x2].size())\n            # more similar with other filter indicates large in the sum of row\n            similar_sum = torch.sum(torch.abs(similar_matrix), 0).numpy()\n\n            # for distance similar: get the filter index with largest similarity == small distance\n            similar_large_index = similar_sum.argsort()[similar_pruned_num:]\n            similar_small_index = similar_sum.argsort()[:  similar_pruned_num]\n            similar_index_for_filter = [filter_large_index[i] for i in similar_small_index]\n\n            print(\'filter_large_index\', filter_large_index)\n            print(\'filter_small_index\', filter_small_index)\n            print(\'similar_sum\', similar_sum)\n            print(\'similar_large_index\', similar_large_index)\n            print(\'similar_small_index\', similar_small_index)\n            print(\'similar_index_for_filter\', similar_index_for_filter)\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(similar_index_for_filter)):\n                codebook[\n                similar_index_for_filter[x] * kernel_length: (similar_index_for_filter[x] + 1) * kernel_length] = 0\n            print(""similar index done"")\n        else:\n            pass\n        return codebook\n\n    # optimize for fast ccalculation\n    def get_filter_similar(self, weight_torch, compress_rate, distance_rate, length):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            similar_pruned_num = int(weight_torch.size()[0] * distance_rate)\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            # norm1 = torch.norm(weight_vec, 1, 1)\n            # norm1_np = norm1.cpu().numpy()\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_small_index = []\n            filter_large_index = []\n            filter_large_index = norm2_np.argsort()[filter_pruned_num:]\n            filter_small_index = norm2_np.argsort()[:filter_pruned_num]\n\n            # # distance using pytorch function\n            # similar_matrix = torch.zeros((len(filter_large_index), len(filter_large_index)))\n            # for x1, x2 in enumerate(filter_large_index):\n            #     for y1, y2 in enumerate(filter_large_index):\n            #         # cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n            #         # similar_matrix[x1, y1] = cos(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0]\n            #         pdist = torch.nn.PairwiseDistance(p=2)\n            #         similar_matrix[x1, y1] = pdist(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0][0]\n            # # more similar with other filter indicates large in the sum of row\n            # similar_sum = torch.sum(torch.abs(similar_matrix), 0).numpy()\n\n            # distance using numpy function\n            indices = torch.LongTensor(filter_large_index).cuda()\n            weight_vec_after_norm = torch.index_select(weight_vec, 0, indices).cpu().numpy()\n            # for euclidean distance\n            similar_matrix = distance.cdist(weight_vec_after_norm, weight_vec_after_norm, \'euclidean\')\n            # for cos similarity\n            # similar_matrix = 1 - distance.cdist(weight_vec_after_norm, weight_vec_after_norm, \'cosine\')\n            similar_sum = np.sum(np.abs(similar_matrix), axis=0)\n\n            # for distance similar: get the filter index with largest similarity == small distance\n            similar_large_index = similar_sum.argsort()[similar_pruned_num:]\n            similar_small_index = similar_sum.argsort()[:  similar_pruned_num]\n            similar_index_for_filter = [filter_large_index[i] for i in similar_small_index]\n\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(similar_index_for_filter)):\n                codebook[\n                similar_index_for_filter[x] * kernel_length: (similar_index_for_filter[x] + 1) * kernel_length] = 0\n            print(""similar index done"")\n        else:\n            pass\n        return codebook\n\n    def convert2tensor(self, x):\n        x = torch.FloatTensor(x)\n        return x\n\n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size[index] = item.size()\n\n        for index1 in self.model_size:\n            for index2 in range(0, len(self.model_size[index1])):\n                if index2 == 0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n\n    def init_rate(self, rate_norm_per_layer, rate_dist_per_layer):\n        if \'vgg\' in args.arch:\n            cfg_official = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n            cfg_CP_5x = [24, 22, 41, 51, 108, 89, 111, 184, 276, 228, 512, 512, 512]\n            # cfg = [32, 64, 128, 128, 256, 256, 256, 256, 256, 256, 256, 256, 256]\n            cfg_Thinet_conv = [32, 32, 64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512]\n            if args.VGG_pruned_style == ""CP_5x"":\n                cfg_now = cfg_CP_5x\n            elif args.VGG_pruned_style == ""Thinet_conv"":\n                cfg_now = cfg_Thinet_conv\n\n            cfg_index = 0\n            previous_cfg = True\n            for index, item in enumerate(self.model.named_parameters()):\n                self.compress_rate[index] = 1\n                if len(item[1].size()) == 4:\n                    if not previous_cfg:\n                        self.compress_rate[index] = rate_norm_per_layer\n                        self.distance_rate[index] = rate_dist_per_layer\n                        self.mask_index.append(index)\n                        print(item[0], ""self.mask_index"", self.mask_index)\n                    else:\n                        self.compress_rate[index] = 1\n                        self.distance_rate[index] = 1 - cfg_now[cfg_index] / item[1].size()[0]\n                        self.mask_index.append(index)\n                        print(item[0], ""self.mask_index"", self.mask_index, cfg_index, cfg_now[cfg_index])\n                        cfg_index += 1\n        elif ""resnet"" in args.arch:\n            for index, item in enumerate(self.model.parameters()):\n                self.compress_rate[index] = 1\n                self.distance_rate[index] = 1\n            for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n                self.compress_rate[key] = rate_norm_per_layer\n                self.distance_rate[key] = rate_dist_per_layer\n            # different setting for  different architecture\n            if args.arch == \'resnet18\':\n                # last index include last fc layer\n                last_index = 60\n                skip_list = [21, 36, 51]\n            elif args.arch == \'resnet34\':\n                last_index = 108\n                skip_list = [27, 54, 93]\n            elif args.arch == \'resnet50\':\n                last_index = 159\n                skip_list = [12, 42, 81, 138]\n            elif args.arch == \'resnet101\':\n                last_index = 312\n                skip_list = [12, 42, 81, 291]\n            elif args.arch == \'resnet152\':\n                last_index = 465\n                skip_list = [12, 42, 117, 444]\n            self.mask_index = [x for x in range(0, last_index, 3)]\n            # skip downsample layer\n            if args.skip_downsample == 1:\n                for x in skip_list:\n                    self.compress_rate[x] = 1\n                    self.mask_index.remove(x)\n                    print(self.mask_index)\n            else:\n                pass\n\n    def init_mask(self, rate_norm_per_layer, rate_dist_per_layer):\n        self.init_rate(rate_norm_per_layer, rate_dist_per_layer)\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                # mask for norm criterion\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],\n                                                           self.model_length[index])\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.use_cuda:\n                    self.mat[index] = self.mat[index].cuda()\n\n                # mask for distance criterion\n                self.similar_matrix[index] = self.get_filter_similar(item.data, self.compress_rate[index],\n                                                                     self.distance_rate[index],\n                                                                     self.model_length[index])\n                self.similar_matrix[index] = self.convert2tensor(self.similar_matrix[index])\n                if args.use_cuda:\n                    self.similar_matrix[index] = self.similar_matrix[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def do_similar_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.data.view(self.model_length[index])\n                b = a * self.similar_matrix[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask similar Done"")\n\n    def do_grad_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.grad.data.view(self.model_length[index])\n                # reverse the mask of model\n                # b = a * (1 - self.mat[index])\n                b = a * self.mat[index]\n                b = b * self.similar_matrix[index]\n                item.grad.data = b.view(self.model_size[index])\n        # print(""grad zero Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                # if index in [x for x in range(args.layer_begin, args.layer_end + 1, args.layer_inter)]:\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n\n                print(""layer: %d, number of nonzero weight is %d, zero is %d"" % (\n                    index, np.count_nonzero(b), len(b) - np.count_nonzero(b)))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
utils.py,0,"b'import os, sys, time\nimport numpy as np\nimport matplotlib\n# matplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\nimport random\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n\ndef timing(f):\n    def wrap(*args):\n        time1 = time.time()\n        ret = f(*args)\n        time2 = time.time()\n        print (\'%s function took %0.3f ms\' % (f.__name__, (time2-time1)*1000.0))\n        return ret\n    return wrap'"
VGG_cifar/PFEC_finetune.py,14,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--refine\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the pruned model to be fine tuned\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=40, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.001, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, \n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data/cifar.python\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(\'./data/cifar.python\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data/cifar.python\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(\'./data/cifar.python\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.refine:\n    checkpoint = torch.load(args.refine)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth, cfg=checkpoint[\'cfg\'])\n    model.load_state_dict(checkpoint[\'state_dict\'])\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\ndef train(epoch):\n    model.train()\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    train(epoch)\n    prec1 = test()\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n'"
VGG_cifar/PFEC_vggprune.py,10,"b'import argparse\nimport numpy as np\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nfrom models import *\n\n\n# Prune settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR prune\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar10\',\n                    help=\'training dataset (default: cifar10)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--depth\', type=int, default=16,\n                    help=\'depth of the vgg\')\nparser.add_argument(\'--model\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to the model (default: none)\')\nparser.add_argument(\'--save\', default=\'.\', type=str, metavar=\'PATH\',\n                    help=\'path to save pruned model (default: none)\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nmodel = vgg(dataset=args.dataset, depth=args.depth)\nif args.cuda:\n    model.cuda()\n\nif args.model:\n    if os.path.isfile(args.model):\n        print(""=> loading checkpoint \'{}\'"".format(args.model))\n        checkpoint = torch.load(args.model)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.model, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\nprint(\'Pre-processing Successful!\')\n\n# simple test model after Pre-processing prune (simple set BN scales to zeros)\ndef test(model):\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n    if args.dataset == \'cifar10\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'./data/cifar.python\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    elif args.dataset == \'cifar100\':\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'./data/cifar.python\', train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    else:\n        raise ValueError(""No valid dataset is given."")\n    model.eval()\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\nacc = test(model)\ncfg = [32, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 256, 256, 256, \'M\', 256, 256, 256]\n\ncfg_mask = []\nlayer_id = 0\nfor m in model.modules():\n    if isinstance(m, nn.Conv2d):\n        out_channels = m.weight.data.shape[0]\n        if out_channels == cfg[layer_id]:\n            cfg_mask.append(torch.ones(out_channels))\n            layer_id += 1\n            continue\n        weight_copy = m.weight.data.abs().clone()\n        weight_copy = weight_copy.cpu().numpy()\n        L1_norm = np.sum(weight_copy, axis=(1, 2, 3))\n        arg_max = np.argsort(L1_norm)\n        arg_max_rev = arg_max[::-1][:cfg[layer_id]]\n        assert arg_max_rev.size == cfg[layer_id], ""size of arg_max_rev not correct""\n        mask = torch.zeros(out_channels)\n        mask[arg_max_rev.tolist()] = 1\n        cfg_mask.append(mask)\n        layer_id += 1\n    elif isinstance(m, nn.MaxPool2d):\n        layer_id += 1\n\n\nnewmodel = vgg(dataset=args.dataset, cfg=cfg)\nif args.cuda:\n    newmodel.cuda()\n\nstart_mask = torch.ones(3)\nlayer_id_in_cfg = 0\nend_mask = cfg_mask[layer_id_in_cfg]\nfor [m0, m1] in zip(model.modules(), newmodel.modules()):\n    if isinstance(m0, nn.BatchNorm2d):\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n        if idx1.size == 1:\n            idx1 = np.resize(idx1,(1,))\n        m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n        m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n        m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n        m1.running_var = m0.running_var[idx1.tolist()].clone()\n        layer_id_in_cfg += 1\n        start_mask = end_mask\n        if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n            end_mask = cfg_mask[layer_id_in_cfg]\n    elif isinstance(m0, nn.Conv2d):\n        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n        print(\'In shape: {:d}, Out shape {:d}.\'.format(idx0.size, idx1.size))\n        if idx0.size == 1:\n            idx0 = np.resize(idx0, (1,))\n        if idx1.size == 1:\n            idx1 = np.resize(idx1, (1,))\n        w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n        w1 = w1[idx1.tolist(), :, :, :].clone()\n        m1.weight.data = w1.clone()\n    elif isinstance(m0, nn.Linear):\n        if layer_id_in_cfg == len(cfg_mask):\n            idx0 = np.squeeze(np.argwhere(np.asarray(cfg_mask[-1].cpu().numpy())))\n            if idx0.size == 1:\n                idx0 = np.resize(idx0, (1,))\n            m1.weight.data = m0.weight.data[:, idx0].clone()\n            m1.bias.data = m0.bias.data.clone()\n            layer_id_in_cfg += 1\n            continue\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n    elif isinstance(m0, nn.BatchNorm1d):\n        m1.weight.data = m0.weight.data.clone()\n        m1.bias.data = m0.bias.data.clone()\n        m1.running_mean = m0.running_mean.clone()\n        m1.running_var = m0.running_var.clone()\n\ntorch.save({\'cfg\': cfg, \'state_dict\': newmodel.state_dict()}, os.path.join(args.save, \'pruned.pth.tar\'))\nprint(newmodel)\nmodel = newmodel\nacc = test(model)\n\nnum_parameters = sum([param.nelement() for param in newmodel.parameters()])\nwith open(os.path.join(args.save, ""prune.txt""), ""w"") as fp:\n    fp.write(""Number of parameters: \\n""+str(num_parameters)+""\\n"")\n    fp.write(""Test accuracy: \\n""+str(acc)+""\\n"")\n'"
VGG_cifar/__init__.py,0,b'# -*- coding=utf-8 -*-\n# @Mail:   beanocean@outlook.com\n# @D&T:    Mon 07 Jan 2019 15:43:41 AEDT\n\n\nfrom ..models import *\n'
VGG_cifar/main_cifar_vgg.py,13,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport models\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str,\n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save):\n    os.makedirs(args.save)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\nif args.dataset == \'cifar10\':\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(args.data_path, train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR10(args.data_path, train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\nelse:\n    train_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(args.data_path, train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.Pad(4),\n                           transforms.RandomCrop(32),\n                           transforms.RandomHorizontalFlip(),\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.CIFAR100(args.data_path, train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\nmodel = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\nif args.resume:\n    if os.path.isfile(args.resume):\n        print(""=> loading checkpoint \'{}\'"".format(args.resume))\n        checkpoint = torch.load(args.resume)\n        args.start_epoch = checkpoint[\'epoch\']\n        best_prec1 = checkpoint[\'best_prec1\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n              .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n    else:\n        print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\ndef train(epoch):\n    model.train()\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    return correct / float(len(test_loader.dataset))\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\nbest_prec1 = 0.\nfor epoch in range(args.start_epoch, args.epochs):\n    if epoch in [args.epochs*0.5, args.epochs*0.75]:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= 0.1\n    train(epoch)\n    prec1 = test()\n    is_best = prec1 > best_prec1\n    best_prec1 = max(prec1, best_prec1)\n    save_checkpoint({\n        \'epoch\': epoch + 1,\n        \'state_dict\': model.state_dict(),\n        \'best_prec1\': best_prec1,\n        \'optimizer\': optimizer.state_dict(),\n        \'cfg\': model.cfg\n    }, is_best, filepath=args.save)\n'"
VGG_cifar/main_cifar_vgg_log.py,16,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport os, sys, shutil, time, random\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport models\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\',\n                    help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\',\n                    help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\',\n                    help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save_path\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str,\n                    help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int,\n                    help=\'depth of the neural network\')\nparser.add_argument(\'--use_scratch\', dest=\'use_scratch\', action=\'store_true\', help=\'save scratch model or not\')\nparser.add_argument(\'--train_scratch\', default=\'\', type=str, metavar=\'PATH\', help=\'train the small scratch model\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save_path):\n    os.makedirs(args.save_path)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n\n\ndef main():\n    # Init logger\n    if not os.path.isdir(args.save_path):\n        os.makedirs(args.save_path)\n    log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.seed)), \'w\')\n    print_log(\'save path : {}\'.format(args.save_path), log)\n    state = {k: v for k, v in args._get_kwargs()}\n    print_log(state, log)\n    print_log(""Random Seed: {}"".format(args.seed), log)\n    print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""torch  version : {}"".format(torch.__version__), log)\n    print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n\n    if args.dataset == \'cifar10\':\n        train_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(args.data_path, train=True, download=True,\n                             transform=transforms.Compose([\n                                 transforms.Pad(4),\n                                 transforms.RandomCrop(32),\n                                 transforms.RandomHorizontalFlip(),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                             ])),\n            batch_size=args.batch_size, shuffle=True, **kwargs)\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(args.data_path, train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n            ])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n    else:\n        train_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(args.data_path, train=True, download=True,\n                              transform=transforms.Compose([\n                                  transforms.Pad(4),\n                                  transforms.RandomCrop(32),\n                                  transforms.RandomHorizontalFlip(),\n                                  transforms.ToTensor(),\n                                  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                              ])),\n            batch_size=args.batch_size, shuffle=True, **kwargs)\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(args.data_path, train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n            ])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n    print_log(""=> network :\\n {}"".format(model), log)\n\n    if args.cuda:\n        model.cuda()\n\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n                  .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    # for training from scratch\n    if args.use_scratch and not args.train_scratch:\n        model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n        save_checkpoint({\n            \'epoch\': 0,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': 0,\n            \'optimizer\': optimizer.state_dict(),\n            \'cfg\': model.cfg\n        }, is_best=0, filepath=args.save_path)\n        return\n    elif args.train_scratch:\n        model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth,\n                                           cfg=[32, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 256, 256, 256, \'M\', 256,\n                                                256, 256])\n        if os.path.isfile(args.train_scratch):\n            print(""=> loading pruned scratch model \'{}\'"".format(args.train_scratch))\n            checkpoint = torch.load(args.train_scratch)\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n        else:\n            print(""=> no pruned scratch model found at \'{}\'"".format(args.train_scratch))\n    else:\n        pass\n\n    if args.cuda:\n        model.cuda()\n\n    best_prec1 = 0.\n    for epoch in range(args.start_epoch, args.epochs):\n        if epoch in [args.epochs * 0.5, args.epochs * 0.75]:\n            for param_group in optimizer.param_groups:\n                param_group[\'lr\'] *= 0.1\n        train(train_loader, model, optimizer, epoch, log)\n        prec1 = test(test_loader, model, log)\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\': optimizer.state_dict(),\n            \'cfg\': model.cfg\n        }, is_best, filepath=args.save_path)\n\n\ndef train(train_loader, model, optimizer, epoch, log, m=0):\n    model.train()\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print_log(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                       100. * batch_idx / len(train_loader), loss.data[0]), log)\n\n\ndef test(test_loader, model, log):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0]  # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print_log(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)), log)\n    return correct / float(len(test_loader.dataset))\n\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
VGG_cifar/pruning_cifar_vgg.py,55,"b'from __future__ import print_function\nimport argparse\nimport numpy as np\nimport os\nimport shutil\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport os, sys, shutil, time, random\nfrom scipy.spatial import distance\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nimport models\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch Slimming CIFAR training\')\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, default=\'cifar100\', help=\'training dataset (default: cifar100)\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=256, metavar=\'N\',\n                    help=\'input batch size for testing (default: 256)\')\nparser.add_argument(\'--epochs\', type=int, default=160, metavar=\'N\', help=\'number of epochs to train (default: 160)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--lr\', type=float, default=0.1, metavar=\'LR\', help=\'learning rate (default: 0.1)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\', help=\'SGD momentum (default: 0.9)\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float, metavar=\'W\',\n                    help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False, help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\', help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--save_path\', default=\'./logs\', type=str, metavar=\'PATH\',\n                    help=\'path to save prune model (default: current directory)\')\nparser.add_argument(\'--arch\', default=\'vgg\', type=str, help=\'architecture to use\')\nparser.add_argument(\'--depth\', default=16, type=int, help=\'depth of the neural network\')\n# compress rate\nparser.add_argument(\'--rate_norm\', type=float, default=0.9, help=\'the remaining ratio of pruning based on Norm\')\nparser.add_argument(\'--rate_dist\', type=float, default=0.1, help=\'the reducing ratio of pruning based on Distance\')\n\n# compress parameter\nparser.add_argument(\'--layer_begin\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--dist_type\', default=\'l2\', type=str, choices=[\'l2\', \'l1\', \'cos\'], help=\'distance type of GM\')\n\n# pretrain model\nparser.add_argument(\'--use_state_dict\', dest=\'use_state_dict\', action=\'store_true\', help=\'use state dcit or not\')\nparser.add_argument(\'--use_pretrain\', dest=\'use_pretrain\', action=\'store_true\', help=\'use pre-trained model or not\')\nparser.add_argument(\'--pretrain_path\', default=\'\', type=str, help=\'..path of pre-trained model\')\nparser.add_argument(\'--use_precfg\', dest=\'use_precfg\', action=\'store_true\', help=\'use precfg or not\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\nif not os.path.exists(args.save_path):\n    os.makedirs(args.save_path)\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\n\n\ndef main():\n    # Init logger\n    if not os.path.isdir(args.save_path):\n        os.makedirs(args.save_path)\n    log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.seed)), \'w\')\n    print_log(\'save path : {}\'.format(args.save_path), log)\n    state = {k: v for k, v in args._get_kwargs()}\n    print_log(state, log)\n    print_log(""Random Seed: {}"".format(args.seed), log)\n    print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""torch  version : {}"".format(torch.__version__), log)\n    print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Norm Pruning Rate: {}"".format(args.rate_norm), log)\n    print_log(""Distance Pruning Rate: {}"".format(args.rate_dist), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    print_log(""use pretrain: {}"".format(args.use_pretrain), log)\n    print_log(""Pretrain path: {}"".format(args.pretrain_path), log)\n    print_log(""Dist type: {}"".format(args.dist_type), log)\n    print_log(""Pre cfg: {}"".format(args.use_precfg), log)\n\n    if args.dataset == \'cifar10\':\n        train_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(args.data_path, train=True, download=True,\n                             transform=transforms.Compose([\n                                 transforms.Pad(4),\n                                 transforms.RandomCrop(32),\n                                 transforms.RandomHorizontalFlip(),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                             ])),\n            batch_size=args.batch_size, shuffle=True, **kwargs)\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(args.data_path, train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n            ])),\n            batch_size=args.test_batch_size, shuffle=False, **kwargs)\n    else:\n        train_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(args.data_path, train=True, download=True,\n                              transform=transforms.Compose([\n                                  transforms.Pad(4),\n                                  transforms.RandomCrop(32),\n                                  transforms.RandomHorizontalFlip(),\n                                  transforms.ToTensor(),\n                                  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n                              ])),\n            batch_size=args.batch_size, shuffle=True, **kwargs)\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(args.data_path, train=False, transform=transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n            ])),\n            batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](dataset=args.dataset, depth=args.depth)\n    print_log(""=> network :\\n {}"".format(model), log)\n\n    if args.cuda:\n        model.cuda()\n\n    if args.use_pretrain:\n        if os.path.isfile(args.pretrain_path):\n            print_log(""=> loading pretrain model \'{}\'"".format(args.pretrain_path), log)\n        else:\n            dir = \'/home/yahe/compress/filter_similarity/logs/main_2\'\n            args.pretrain_path = dir + \'/checkpoint.pth.tar\'\n            print_log(""Pretrain path: {}"".format(args.pretrain_path), log)\n        pretrain = torch.load(args.pretrain_path)\n        if args.use_state_dict:\n            model.load_state_dict(pretrain[\'state_dict\'])\n        else:\n            model = pretrain[\'state_dict\']\n\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model = models.vgg(dataset=\'cifar10\', depth=16, cfg=checkpoint[\'cfg\'])\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {}) Prec1: {:f}""\n                  .format(args.resume, checkpoint[\'epoch\'], best_prec1))\n            if args.cuda:\n                model = model.cuda()\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    if args.evaluate:\n        time1 = time.time()\n        test(test_loader, model, log)\n        time2 = time.time()\n        print(\'function took %0.3f ms\' % ((time2 - time1) * 1000.0))\n        return\n\n    m = Mask(model)\n    m.init_length()\n    print(""-"" * 10 + ""one epoch begin"" + ""-"" * 10)\n    print(""remaining ratio of pruning : Norm is %f"" % args.rate_norm)\n    print(""reducing ratio of pruning : Distance is %f"" % args.rate_dist)\n    print(""total remaining ratio is %f"" % (args.rate_norm - args.rate_dist))\n\n    val_acc_1 = test(test_loader, model, log)\n\n    print("" accu before is: %.3f %%"" % val_acc_1)\n\n    m.model = model\n\n    m.init_mask(args.rate_norm, args.rate_dist, args.dist_type)\n    #    m.if_zero()\n    m.do_mask()\n    m.do_similar_mask()\n    model = m.model\n    #    m.if_zero()\n    if args.cuda:\n        model = model.cuda()\n    val_acc_2 = test(test_loader, model, log)\n    print("" accu after is: %s %%"" % val_acc_2)\n\n    best_prec1 = 0.\n    for epoch in range(args.start_epoch, args.epochs):\n        if epoch in [args.epochs * 0.5, args.epochs * 0.75]:\n            for param_group in optimizer.param_groups:\n                param_group[\'lr\'] *= 0.1\n        train(train_loader, model, optimizer, epoch, log)\n        prec1 = test(test_loader, model, log)\n\n        if epoch % args.epoch_prune == 0 or epoch == args.epochs - 1:\n            m.model = model\n            m.if_zero()\n            m.init_mask(args.rate_norm, args.rate_dist, args.dist_type)\n            m.do_mask()\n            m.do_similar_mask()\n            # small_filter_index.append(m.filter_small_index)\n            # large_filter_index.append(m.filter_large_index)\n            # save_obj(small_filter_index, \'small_filter_index_2\')\n            # save_obj(large_filter_index, \'large_filter_index_2\')\n            m.if_zero()\n            model = m.model\n            if args.cuda:\n                model = model.cuda()\n            val_acc_2 = test(test_loader, model, log)\n        is_best = val_acc_2 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\': optimizer.state_dict(),\n            \'cfg\': model.cfg\n        }, is_best, filepath=args.save_path)\n\n\ndef train(train_loader, model, optimizer, epoch, log, m=0):\n    model.train()\n    avg_loss = 0.\n    train_acc = 0.\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        avg_loss += loss.data[0]\n        pred = output.data.max(1, keepdim=True)[1]\n        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print_log(\'Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                       100. * batch_idx / len(train_loader), loss.data[0]), log)\n\n\ndef test(test_loader, model, log):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, size_average=False).data[0]  # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print_log(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)), log)\n    return correct / float(len(test_loader.dataset))\n\n\ndef save_checkpoint(state, is_best, filepath):\n    torch.save(state, os.path.join(filepath, \'checkpoint.pth.tar\'))\n    if is_best:\n        shutil.copyfile(os.path.join(filepath, \'checkpoint.pth.tar\'), os.path.join(filepath, \'model_best.pth.tar\'))\n\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\n\nclass Mask:\n    def __init__(self, model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.distance_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n        self.filter_small_index = {}\n        self.filter_large_index = {}\n        self.similar_matrix = {}\n        self.norm_matrix = {}\n        self.cfg = [32, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 256, 256, 256, \'M\', 256, 256, 256]\n\n    def get_codebook(self, weight_torch, compress_rate, length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n\n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n\n        threshold = weight_sort[int(length * (1 - compress_rate))]\n        weight_np[weight_np <= -threshold] = 1\n        weight_np[weight_np >= threshold] = 1\n        weight_np[weight_np != 1] = 0\n\n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch, compress_rate, length):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n            #            norm1_sort = np.sort(norm1_np)\n            #            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(filter_index)):\n                codebook[filter_index[x] * kernel_length: (filter_index[x] + 1) * kernel_length] = 0\n\n            print(""filter codebook done"")\n        else:\n            pass\n        return codebook\n\n    def get_filter_index(self, weight_torch, compress_rate, length):\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            # norm1 = torch.norm(weight_vec, 1, 1)\n            # norm1_np = norm1.cpu().numpy()\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_small_index = []\n            filter_large_index = []\n            filter_large_index = norm2_np.argsort()[filter_pruned_num:]\n            filter_small_index = norm2_np.argsort()[:filter_pruned_num]\n            #            norm1_sort = np.sort(norm1_np)\n            #            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            # print(""filter index done"")\n        else:\n            pass\n        return filter_small_index, filter_large_index\n\n    def get_filter_similar_old(self, weight_torch, compress_rate, distance_rate, length):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            similar_pruned_num = int(weight_torch.size()[0] * distance_rate)\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            # norm1 = torch.norm(weight_vec, 1, 1)\n            # norm1_np = norm1.cpu().numpy()\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_small_index = []\n            filter_large_index = []\n            filter_large_index = norm2_np.argsort()[filter_pruned_num:]\n            filter_small_index = norm2_np.argsort()[:filter_pruned_num]\n            print(\'weight_vec.size\', weight_vec.size())\n            # distance using pytorch function\n            similar_matrix = torch.zeros((len(filter_large_index), len(filter_large_index)))\n            for x1, x2 in enumerate(filter_large_index):\n                for y1, y2 in enumerate(filter_large_index):\n                    # cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n                    # similar_matrix[x1, y1] = cos(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0]\n                    pdist = torch.nn.PairwiseDistance(p=2)\n                    # print(\'weight_vec[x2].size\', weight_vec[x2].size())\n                    similar_matrix[x1, y1] = pdist(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0][0]\n                    # print(\'weight_vec[x2].size after\', weight_vec[x2].size())\n            # more similar with other filter indicates large in the sum of row\n            similar_sum = torch.sum(torch.abs(similar_matrix), 0).numpy()\n\n            # for cos similar: get the filter index with largest similarity\n            # similar_pruned_num = len(similar_sum) - similar_pruned_num\n            # similar_large_index = similar_sum.argsort()[similar_pruned_num:]\n            # similar_small_index = similar_sum.argsort()[:  similar_pruned_num]\n            # similar_index_for_filter = [filter_large_index[i] for i in similar_large_index]\n\n            # for distance similar: get the filter index with largest similarity == small distance\n            similar_large_index = similar_sum.argsort()[similar_pruned_num:]\n            similar_small_index = similar_sum.argsort()[:  similar_pruned_num]\n            similar_index_for_filter = [filter_large_index[i] for i in similar_small_index]\n\n            print(\'filter_large_index\', filter_large_index)\n            print(\'filter_small_index\', filter_small_index)\n            print(\'similar_sum\', similar_sum)\n            print(\'similar_large_index\', similar_large_index)\n            print(\'similar_small_index\', similar_small_index)\n            print(\'similar_index_for_filter\', similar_index_for_filter)\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(similar_index_for_filter)):\n                codebook[\n                similar_index_for_filter[x] * kernel_length: (similar_index_for_filter[x] + 1) * kernel_length] = 0\n            print(""similar index done"")\n        else:\n            pass\n        return codebook\n\n    # optimize for fast ccalculation\n    def get_filter_similar(self, weight_torch, compress_rate, distance_rate, length, dist_type=""l2""):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            similar_pruned_num = int(weight_torch.size()[0] * distance_rate)\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n\n            if dist_type == ""l2"" or ""cos"":\n                norm = torch.norm(weight_vec, 2, 1)\n                norm_np = norm.cpu().numpy()\n            elif dist_type == ""l1"":\n                norm = torch.norm(weight_vec, 1, 1)\n                norm_np = norm.cpu().numpy()\n            filter_small_index = []\n            filter_large_index = []\n            filter_large_index = norm_np.argsort()[filter_pruned_num:]\n            filter_small_index = norm_np.argsort()[:filter_pruned_num]\n\n            # # distance using pytorch function\n            # similar_matrix = torch.zeros((len(filter_large_index), len(filter_large_index)))\n            # for x1, x2 in enumerate(filter_large_index):\n            #     for y1, y2 in enumerate(filter_large_index):\n            #         # cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n            #         # similar_matrix[x1, y1] = cos(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0]\n            #         pdist = torch.nn.PairwiseDistance(p=2)\n            #         similar_matrix[x1, y1] = pdist(weight_vec[x2].view(1, -1), weight_vec[y2].view(1, -1))[0][0]\n            # # more similar with other filter indicates large in the sum of row\n            # similar_sum = torch.sum(torch.abs(similar_matrix), 0).numpy()\n\n            # distance using numpy function\n            indices = torch.LongTensor(filter_large_index).cuda()\n            weight_vec_after_norm = torch.index_select(weight_vec, 0, indices).cpu().numpy()\n            # for euclidean distance\n            if dist_type == ""l2"" or ""l1"":\n                similar_matrix = distance.cdist(weight_vec_after_norm, weight_vec_after_norm, \'euclidean\')\n            elif dist_type == ""cos"":  # for cos similarity\n                similar_matrix = 1 - distance.cdist(weight_vec_after_norm, weight_vec_after_norm, \'cosine\')\n            similar_sum = np.sum(np.abs(similar_matrix), axis=0)\n\n            # print(\'similar_matrix 1\',similar_matrix.cpu().numpy())\n            # print(\'similar_matrix 2\', similar_matrix_2)\n            # # print(\'similar_matrix 3\', similar_matrix_3)\n            # result = np.absolute(similar_matrix.cpu().numpy() - similar_matrix_2)\n            # print(\'result\',result)\n            # print(\'similar_matrix\',similar_matrix.cpu().numpy())\n            # print(\'similar_matrix_2\', similar_matrix_2)\n            # print(\'result\', similar_matrix.cpu().numpy()-similar_matrix_2)\n            # print(\'similar_sum\',similar_sum)\n            # print(\'similar_sum_2\', similar_sum_2)\n            # print(\'result sum\', similar_sum-similar_sum_2)\n\n            # for cos similar: get the filter index with largest similarity\n            # similar_pruned_num = len(similar_sum) - similar_pruned_num\n            # similar_large_index = similar_sum.argsort()[similar_pruned_num:]\n            # similar_small_index = similar_sum.argsort()[:  similar_pruned_num]\n            # similar_index_for_filter = [filter_large_index[i] for i in similar_large_index]\n\n            # for distance similar: get the filter index with largest similarity == small distance\n            similar_large_index = similar_sum.argsort()[similar_pruned_num:]\n            similar_small_index = similar_sum.argsort()[:  similar_pruned_num]\n            similar_index_for_filter = [filter_large_index[i] for i in similar_small_index]\n\n            print(\'filter_large_index\', filter_large_index)\n            print(\'filter_small_index\', filter_small_index)\n            print(\'similar_sum\', similar_sum)\n            print(\'similar_large_index\', similar_large_index)\n            print(\'similar_small_index\', similar_small_index)\n            print(\'similar_index_for_filter\', similar_index_for_filter)\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(similar_index_for_filter)):\n                codebook[\n                similar_index_for_filter[x] * kernel_length: (similar_index_for_filter[x] + 1) * kernel_length] = 0\n            print(""similar index done"")\n        else:\n            pass\n        return codebook\n\n    def convert2tensor(self, x):\n        x = torch.FloatTensor(x)\n        return x\n\n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size[index] = item.size()\n\n        for index1 in self.model_size:\n            for index2 in range(0, len(self.model_size[index1])):\n                if index2 == 0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n\n    def init_rate(self, rate_norm_per_layer, rate_dist_per_layer, pre_cfg=True):\n        if args.arch == \'vgg\':\n            cfg = [32, 64, 128, 128, 256, 256, 256, 256, 256, 256, 256, 256, 256]\n            cfg_index = 0\n            for index, item in enumerate(self.model.named_parameters()):\n                self.compress_rate[index] = 1\n                self.distance_rate[index] = 1\n                if len(item[1].size()) == 4:\n                    print(item[1].size())\n                    if not pre_cfg:\n                        self.compress_rate[index] = rate_norm_per_layer\n                        self.distance_rate[index] = rate_dist_per_layer\n                        self.mask_index.append(index)\n                        print(item[0], ""self.mask_index"", self.mask_index)\n                    else:\n                        self.compress_rate[index] = rate_norm_per_layer\n                        self.distance_rate[index] = 1 - cfg[cfg_index] / item[1].size()[0]\n                        self.mask_index.append(index)\n                        print(item[0], ""self.mask_index"", self.mask_index, cfg_index, cfg[cfg_index], item[1].size()[0],\n                              self.distance_rate[index], )\n                        print(""self.distance_rate"", self.distance_rate)\n                        cfg_index += 1\n        # for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n        #     self.compress_rate[key] = rate_norm_per_layer\n        #     self.distance_rate[key] = rate_dist_per_layer\n        # different setting for  different architecture\n        # if args.arch == \'resnet20\':\n        #     last_index = 57\n        # elif args.arch == \'resnet32\':\n        #     last_index = 93\n        # elif args.arch == \'resnet56\':\n        #     last_index = 165\n        # elif args.arch == \'resnet110\':\n        #     last_index = 327\n        # # to jump the last fc layer\n        # self.mask_index = [x for x in range(0, last_index, 3)]\n\n    def init_mask(self, rate_norm_per_layer, rate_dist_per_layer, dist_type):\n        self.init_rate(rate_norm_per_layer, rate_dist_per_layer, pre_cfg=args.use_precfg)\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                # mask for norm criterion\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],\n                                                           self.model_length[index])\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.cuda:\n                    self.mat[index] = self.mat[index].cuda()\n\n                # # get result about filter index\n                # self.filter_small_index[index], self.filter_large_index[index] = \\\n                #     self.get_filter_index(item.data, self.compress_rate[index], self.model_length[index])\n\n                # mask for distance criterion\n                self.similar_matrix[index] = self.get_filter_similar(item.data, self.compress_rate[index],\n                                                                     self.distance_rate[index],\n                                                                     self.model_length[index], dist_type=dist_type)\n                self.similar_matrix[index] = self.convert2tensor(self.similar_matrix[index])\n                if args.cuda:\n                    self.similar_matrix[index] = self.similar_matrix[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def do_similar_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.data.view(self.model_length[index])\n                b = a * self.similar_matrix[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask similar Done"")\n\n    def do_grad_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if index in self.mask_index:\n                a = item.grad.data.view(self.model_length[index])\n                # reverse the mask of model\n                # b = a * (1 - self.mat[index])\n                b = a * self.mat[index]\n                b = b * self.similar_matrix[index]\n                item.grad.data = b.view(self.model_size[index])\n        # print(""grad zero Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n            if (index in self.mask_index):\n                # if index == 0:\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n                print(\n                    ""number of nonzero weight is %d, zero is %d"" % (np.count_nonzero(b), len(b) - np.count_nonzero(b)))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
functions/cal_flop.py,0,"b'# calculate flop for ResNet on imagenet\n\n\ndef basic(layer, layer_index, channel, width, prune_rate):\n    flop = 0\n\n    def even_odd(flop, index, add, rate):\n        if index % 2 == 0:\n            flop += add * (prune_rate ** 2)\n        elif index % 2 != 0:\n            flop += add * (prune_rate)\n        return flop\n\n    for index in range(0, layer, 1):\n        if index == 0:\n            flop += channel[0] * 112 * 112 * 7 * 7 * 3 * prune_rate\n        elif index in [1, 2]:\n            flop += channel[0] * width[0] * width[0] * 9 * channel[0] * (prune_rate ** 2)\n\n        elif index > 2 and index <= layer_index[0]:\n            add = channel[0] * width[0] * width[0] * 9 * channel[0]\n            flop = even_odd(flop, index, add, prune_rate)\n\n        elif index > layer_index[0] and index <= layer_index[1]:\n            add = channel[1] * width[1] * width[1] * 9 * channel[1]\n            flop = even_odd(flop, index, add, prune_rate)\n\n        elif index > layer_index[1] and index <= layer_index[2]:\n            add = channel[2] * width[2] * width[2] * 9 * channel[2]\n            flop = even_odd(flop, index, add, prune_rate)\n\n        elif index > layer_index[2] and index <= layer_index[3]:\n            add = channel[3] * width[3] * width[3] * 9 * channel[3]\n            flop = even_odd(flop, index, add, prune_rate)\n\n    less1 = channel[1] * width[1] * width[1] * 9 * channel[1] * (prune_rate) - channel[1] * width[1] * width[1] * 9 * \\\n            channel[0] * (prune_rate)\n    less2 = channel[2] * width[2] * width[2] * 9 * channel[2] * (prune_rate) - channel[2] * width[2] * width[2] * 9 * \\\n            channel[1] * (prune_rate)\n    less2 = channel[3] * width[3] * width[3] * 9 * channel[3] * (prune_rate) - channel[3] * width[3] * width[3] * 9 * \\\n            channel[2] * (prune_rate)\n    flop = flop - less1 - less2\n    return flop\n\n\ndef bottle(layer, block, channel, width, prune_rate):\n    def second_block(channel, width, prune_rate):\n        flop = 0\n        flop += channel * width * width * 1 * 1 * (channel * 4) * prune_rate\n        flop += channel * width * width * 3 * 3 * channel * (prune_rate ** 2)\n        flop += (channel * 4) * width * width * 1 * 1 * channel * (prune_rate ** 2)\n        return flop\n\n    def first_block(input_channel, channel, width, prune_rate):\n        flop = 0\n        flop += channel * width * width * 1 * 1 * input_channel * prune_rate\n        flop += channel * width * width * 3 * 3 * channel * (prune_rate ** 2)\n        flop += (channel * 4) * width * width * 1 * 1 * channel * (prune_rate ** 2)\n        downsample = (channel * 4) * width * width * 1 * 1 * input_channel\n        flop += downsample\n        return flop\n\n    flop = 0\n    flop += channel[0] * 112 * 112 * 7 * 7 * 3 * prune_rate\n    #        print(flop)\n\n    for index, num in enumerate(block):\n        if index == 0:\n            flop += first_block(64 * prune_rate, channel[0], width[0], prune_rate)\n            flop += (num - 1) * second_block(channel[0], width[0], prune_rate)\n        elif index == 1:\n            flop += first_block(channel[0] * 4, channel[1], width[1], prune_rate)\n            flop += (num - 1) * second_block(channel[1], width[1], prune_rate)\n        elif index == 2:\n            flop += first_block(channel[1] * 4, channel[2], width[2], prune_rate)\n            flop += (num - 1) * second_block(channel[2], width[2], prune_rate)\n        elif index == 3:\n            flop += first_block(channel[2] * 4, channel[3], width[3], prune_rate)\n            flop += (num - 1) * second_block(channel[3], width[3], prune_rate)\n    return flop\n\n\ndef imagenet_flop(layer=18, prune_rate=1):\n    flop = 0\n    if layer == 18:\n        block = [2, 2, 2, 2]\n        conv_in_blcok = 2\n    elif layer == 34:\n        block = [3, 4, 6, 3]\n        conv_in_blcok = 2\n    elif layer == 50:\n        block = [3, 4, 6, 3]\n        conv_in_blcok = 3\n    elif layer == 101:\n        block = [3, 4, 23, 3]\n        conv_in_blcok = 3\n    elif layer == 152:\n        block = [3, 8, 36, 3]\n        conv_in_blcok = 3\n    else:\n        print(""wrong layer"")\n\n    channel = [64, 128, 256, 512]\n    width = [56, 28, 14, 7]\n\n    layer_interval = [conv_in_blcok * i for i in block]\n    layer_index = [sum(layer_interval[:k + 1]) for k in range(0, len(layer_interval))]\n    print(layer_index)\n\n    if layer in [18, 34]:\n        flop = basic(layer, layer_index, channel, width, prune_rate)\n    elif layer in [50, 101, 152]:\n        flop = bottle(layer, block, channel, width, prune_rate)\n        print(\'bottle structure\')\n    print(flop)\n    return flop\n\n\ndef cal(func, layer, rate):\n    print(1 - int(func(layer, rate)) / int(func(layer, 1)))\n\n\ndef cifar_resnet_flop(layer=110, prune_rate=1):\n    \'\'\'\n    :param layer: the layer of Resnet for Cifar, including 110, 56, 32, 20\n    :param prune_rate: 1 means baseline\n    :return: flop of the network\n    \'\'\'\n    flop = 0\n    channel = [16, 32, 64]\n    width = [32, 16, 8]\n\n    stage = int(layer / 3)\n    for index in range(0, layer, 1):\n        if index == 0:  # first conv layer before block\n            flop += channel[0] * width[0] * width[0] * 9 * 3 * prune_rate\n        elif index in [1, 2]:  # first block of first stage\n            flop += channel[0] * width[0] * width[0] * 9 * channel[0] * (prune_rate ** 2)\n        elif 2 < index <= stage:  # other blocks of first stage\n            if index % 2 != 0:\n                # first layer of block, only output channal reduced, input channel remain the same\n                flop += channel[0] * width[0] * width[0] * 9 * channel[0] * (prune_rate)\n            elif index % 2 == 0:\n                # second layer of block, both input and output channal reduced\n                flop += channel[0] * width[0] * width[0] * 9 * channel[0] * (prune_rate ** 2)\n        elif stage < index <= stage * 2:  # second stage\n            if index % 2 != 0:\n                flop += channel[1] * width[1] * width[1] * 9 * channel[1] * (prune_rate)\n            elif index % 2 == 0:\n                flop += channel[1] * width[1] * width[1] * 9 * channel[1] * (prune_rate ** 2)\n        elif stage * 2 < index <= stage * 3:  # third stage\n            if index % 2 != 0:\n                flop += channel[2] * width[2] * width[2] * 9 * channel[2] * (prune_rate)\n            elif index % 2 == 0:\n                flop += channel[2] * width[2] * width[2] * 9 * channel[2] * (prune_rate ** 2)\n\n    # offset for dimension change between blocks\n    offset1 = channel[1] * width[1] * width[1] * 9 * channel[1] * prune_rate - channel[1] * width[1] * width[1] * 9 * \\\n            channel[0] * prune_rate\n    offset2 = channel[2] * width[2] * width[2] * 9 * channel[2] * prune_rate - channel[2] * width[2] * width[2] * 9 * \\\n            channel[1] * prune_rate\n    flop = flop - offset1 - offset2\n    print(flop)\n    return flop\n\n\ndef cal_res(layer, rate):\n    flop_rate = 1 - int(cifar_resnet_flop(layer, rate)) / int(cifar_resnet_flop(layer, 1))\n    print(flop_rate)\n    return flop_rate\n\nif __name__ == \'__main__\':\n    cal_res(110, 0.6)\n    cal_res(110, 0.5)\n\n    # imagenet_flop(50, 1)\n    # imagenet_flop(50, 0.9)\n    # imagenet_flop(101, 1)\n    # cal(imagenet_flop, 101, 0.7)\n    # a=[]\n    # for x in range(9, 0, -1):\n    #     print(""*"" * 100,x)\n    #     flop = round(cal_res(110, x / 10),5 )\n    #     a.append(flop)\n    # print(0,a)\n    print(1)\n'"
functions/infer_pruned.py,12,"b'# https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py\nimport argparse\nimport os\nimport shutil\nimport pdb, time\nfrom collections import OrderedDict\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom utils import convert_secs2time, time_string, time_file_str\nimport models\nimport numpy as np\n\nmodel_names = sorted(name for name in models.__dict__\n                     if name.islower() and not name.startswith(""__"")\n                     and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\', help=\'path to dataset\')\nparser.add_argument(\'--save_dir\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names,\n                    help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int, metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float, metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--print-freq\', \'-p\', default=5, type=int, metavar=\'N\', help=\'print frequency (default: 100)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\n# compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--skip_downsample\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\nparser.add_argument(\'--eval_small\', dest=\'eval_small\', action=\'store_true\', help=\'whether a big or small model\')\nparser.add_argument(\'--small_model\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\n\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\n\nargs.prefix = time_file_str()\n\n\ndef main():\n    best_prec1 = 0\n\n    if not os.path.isdir(args.save_dir):\n        os.makedirs(args.save_dir)\n    log = open(os.path.join(args.save_dir, \'gpu-time.{}.{}.log\'.format(args.arch, args.prefix)), \'w\')\n\n    # create model\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](pretrained=False)\n    print_log(""=> Model : {}"".format(model), log)\n    print_log(""=> parameter : {}"".format(args), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    print_log(""Skip downsample : {}"".format(args.skip_downsample), log)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            state_dict = checkpoint[\'state_dict\']\n            state_dict = remove_module_dict(state_dict)\n            model.load_state_dict(state_dict)\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"".format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            # transforms.Scale(256),\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    if args.evaluate:\n        print_log(""eval true"", log)\n        if not args.eval_small:\n            big_model = model.cuda()\n            print_log(\'Evaluate: big model\', log)\n            print_log(\'big model accu: {}\'.format(validate(val_loader, big_model, criterion, log)), log)\n        else:\n            print_log(\'Evaluate: small model\', log)\n            if args.small_model:\n                if os.path.isfile(args.small_model):\n                    print_log(""=> loading small model \'{}\'"".format(args.small_model), log)\n                    small_model = torch.load(args.small_model)\n                    for x, y in zip(small_model.named_parameters(), model.named_parameters()):\n                        print_log(""name of layer: {}\\n\\t *** small model {}\\n\\t *** big model {}"".format(x[0], x[1].size(),\n                                                                                                         y[1].size()), log)\n                    if args.use_cuda:\n                        small_model = small_model.cuda()\n                    print_log(\'small model accu: {}\'.format(validate(val_loader, small_model, criterion, log)), log)\n                else:\n                    print_log(""=> no small model found at \'{}\'"".format(args.small_model), log)\n        return\n\n\ndef validate(val_loader, model, criterion, log):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        # target = target.cuda(async=True)\n        if args.use_cuda:\n            input, target = input.cuda(), target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                i, len(val_loader), batch_time=batch_time, loss=losses,\n                top1=top1, top5=top5), log)\n\n    print_log(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5,\n                                                                                           error1=100 - top1.avg), log)\n\n    return top1.avg\n\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\ndef remove_module_dict(state_dict):\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = name[7:] if name.startswith(""module."") else name  # remove `module.`\n        new_state_dict[name] = v\n    return new_state_dict\n\n\nif __name__ == \'__main__\':\n    main()\n'"
models/__init__.py,0,"b'""""""The models subpackage contains definitions for the following model\narchitectures:\n-  `ResNeXt` for CIFAR10 CIFAR100\nYou can construct a model with random weights by calling its constructor:\n.. code:: python\n    import models\n    resnext29_16_64 = models.ResNeXt29_16_64(num_classes)\n    resnext29_8_64 = models.ResNeXt29_8_64(num_classes)\n    resnet20 = models.ResNet20(num_classes)\n    resnet32 = models.ResNet32(num_classes)\n\n\n.. ResNext: https://arxiv.org/abs/1611.05431\n""""""\n\nfrom .resnext import resnext29_8_64, resnext29_16_64\nfrom .resnet import resnet20, resnet32, resnet44, resnet56, resnet110\nfrom .resnet_mod import resnet_mod20, resnet_mod32, resnet_mod44, resnet_mod56, resnet_mod110\n\nfrom .preresnet import preresnet20, preresnet32, preresnet44, preresnet56, preresnet110\nfrom .caffe_cifar import caffe_cifar\nfrom .densenet import densenet100_12\n\n# imagenet based resnet\nfrom .imagenet_resnet import resnet18, resnet34, resnet50, resnet101, resnet152\n# cifar based resnet\nfrom .resnet import CifarResNet, ResNetBasicblock\n\n# cifar based resnet pruned\nfrom .resnet_small import resnet20_small, resnet32_small, resnet44_small, resnet56_small, resnet110_small\n# imagenet based resnet pruned\n# from .imagenet_resnet_small import resnet18_small, resnet34_small, resnet50_small, resnet101_small, resnet152_small\nfrom .imagenet_resnet_small import resnet18_small, resnet34_small, resnet50_small, resnet101_small, resnet152_small\n\n\nfrom .vgg_cifar10 import *\nfrom .vgg import *\n'"
models/caffe_cifar.py,4,"b""from __future__ import division\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\n## http://torch.ch/blog/2015/07/30/cifar.html\nclass CifarCaffeNet(nn.Module):\n  def __init__(self, num_classes):\n    super(CifarCaffeNet, self).__init__()\n\n    self.num_classes = num_classes\n\n    self.block_1 = nn.Sequential(\n      nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n      nn.MaxPool2d(kernel_size=3, stride=2),\n      nn.ReLU(),\n      nn.BatchNorm2d(32))\n\n    self.block_2 = nn.Sequential(\n      nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n      nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n      nn.ReLU(),\n      nn.AvgPool2d(kernel_size=3, stride=2),\n      nn.BatchNorm2d(64))\n\n    self.block_3 = nn.Sequential(\n      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n      nn.Conv2d(64,128, kernel_size=3, stride=1, padding=1),\n      nn.ReLU(),\n      nn.AvgPool2d(kernel_size=3, stride=2),\n      nn.BatchNorm2d(128))\n\n    self.classifier = nn.Linear(128*9, self.num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def forward(self, x):\n    x = self.block_1.forward(x)\n    x = self.block_2.forward(x)\n    x = self.block_3.forward(x)\n    x = x.view(x.size(0), -1)\n    #print ('{}'.format(x.size()))\n    return self.classifier(x)\n\ndef caffe_cifar(num_classes=10):\n  model = CifarCaffeNet(num_classes)\n  return model\n"""
models/densenet.py,5,"b'import math, torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Bottleneck(nn.Module):\n  def __init__(self, nChannels, growthRate):\n    super(Bottleneck, self).__init__()\n    interChannels = 4*growthRate\n    self.bn1 = nn.BatchNorm2d(nChannels)\n    self.conv1 = nn.Conv2d(nChannels, interChannels, kernel_size=1, bias=False)\n    self.bn2 = nn.BatchNorm2d(interChannels)\n    self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3, padding=1, bias=False)\n\n  def forward(self, x):\n    out = self.conv1(F.relu(self.bn1(x)))\n    out = self.conv2(F.relu(self.bn2(out)))\n    out = torch.cat((x, out), 1)\n    return out\n\nclass SingleLayer(nn.Module):\n  def __init__(self, nChannels, growthRate):\n    super(SingleLayer, self).__init__()\n    self.bn1 = nn.BatchNorm2d(nChannels)\n    self.conv1 = nn.Conv2d(nChannels, growthRate, kernel_size=3, padding=1, bias=False)\n\n  def forward(self, x):\n    out = self.conv1(F.relu(self.bn1(x)))\n    out = torch.cat((x, out), 1)\n    return out\n\nclass Transition(nn.Module):\n  def __init__(self, nChannels, nOutChannels):\n    super(Transition, self).__init__()\n    self.bn1 = nn.BatchNorm2d(nChannels)\n    self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1, bias=False)\n\n  def forward(self, x):\n    out = self.conv1(F.relu(self.bn1(x)))\n    out = F.avg_pool2d(out, 2)\n    return out\n\nclass DenseNet(nn.Module):\n  def __init__(self, growthRate, depth, reduction, nClasses, bottleneck):\n    super(DenseNet, self).__init__()\n\n    if bottleneck:  nDenseBlocks = int( (depth-4) / 6 )\n    else         :  nDenseBlocks = int( (depth-4) / 3 )\n\n    nChannels = 2*growthRate\n    self.conv1 = nn.Conv2d(3, nChannels, kernel_size=3, padding=1, bias=False)\n\n    self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n    nChannels += nDenseBlocks*growthRate\n    nOutChannels = int(math.floor(nChannels*reduction))\n    self.trans1 = Transition(nChannels, nOutChannels)\n\n    nChannels = nOutChannels\n    self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n    nChannels += nDenseBlocks*growthRate\n    nOutChannels = int(math.floor(nChannels*reduction))\n    self.trans2 = Transition(nChannels, nOutChannels)\n\n    nChannels = nOutChannels\n    self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n    nChannels += nDenseBlocks*growthRate\n\n    self.bn1 = nn.BatchNorm2d(nChannels)\n    self.fc = nn.Linear(nChannels, nClasses)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        m.bias.data.zero_()\n\n  def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n    layers = []\n    for i in range(int(nDenseBlocks)):\n      if bottleneck:\n        layers.append(Bottleneck(nChannels, growthRate))\n      else:\n        layers.append(SingleLayer(nChannels, growthRate))\n      nChannels += growthRate\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    out = self.conv1(x)\n    out = self.trans1(self.dense1(out))\n    out = self.trans2(self.dense2(out))\n    out = self.dense3(out)\n    out = torch.squeeze(F.avg_pool2d(F.relu(self.bn1(out)), 8))\n    out = F.log_softmax(self.fc(out))\n    return out\n\ndef densenet100_12(num_classes=10):\n  model = DenseNet(12, 100, 0.5, num_classes, False)\n  return model\n'"
models/imagenet_resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\']\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        # self.relu = nn.ReLU(inplace=False)\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n        print(\'ResNet-18 Use pretrained model for initalization\')\n    return model\n\n\ndef resnet34(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n        print(\'ResNet-34 Use pretrained model for initalization\')\n    return model\n\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n        print(\'ResNet-50 Use pretrained model for initalization\')\n    return model\n\n\ndef resnet101(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n        print(\'ResNet-101 Use pretrained model for initalization\')\n    return model\n\n\ndef resnet152(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n        print(\'ResNet-152 Use pretrained model for initalization\')\n    return model\n'"
models/imagenet_resnet_small.py,12,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\nimport torch\nimport time\n\n__all__ = [\'ResNet_small\', \'resnet18_small\', \'resnet34_small\', \'resnet50_small\', \'resnet101_small\', \'resnet152_small\']\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes_after_prune, planes_expand, planes_before_prune, index, bn_value, stride=1,\n                 downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes_after_prune, stride)\n        self.bn1 = nn.BatchNorm2d(planes_after_prune)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes_after_prune, planes_after_prune)\n        self.bn2 = nn.BatchNorm2d(planes_after_prune)\n        self.downsample = downsample\n        self.stride = stride\n\n        # for residual index match\n        self.index = Variable(index)\n        # for bn add\n        self.bn_value = bn_value\n\n        # self.out = torch.autograd.Variable(\n        #     torch.rand(batch, self.planes_before_prune, 64 * 56 // self.planes_before_prune,\n        #                64 * 56 // self.planes_before_prune), volatile=True).cuda()\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        # setting: without index match\n        # out += residual\n        # out = self.relu(out)\n\n        # setting: with index match\n        residual += self.bn_value.cuda()\n        residual.index_add_(1, self.index.cuda(), out)\n\n        residual = self.relu(residual)\n\n        return residual\n\n\nclass Bottleneck(nn.Module):\n    # expansion is not accurately equals to 4\n    expansion = 4\n\n    def __init__(self, inplanes, planes_after_prune, planes_expand, planes_before_prune, index, bn_value, stride=1,\n                 downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes_after_prune, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes_after_prune)\n        self.conv2 = nn.Conv2d(planes_after_prune, planes_after_prune, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes_after_prune)\n\n        # setting: for accuracy expansion\n        self.conv3 = nn.Conv2d(planes_after_prune, planes_expand, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes_expand)\n\n        # setting: original resnet, expansion = 4\n        # self.conv3 = nn.Conv2d(planes, planes_before_prune * 4, kernel_size=1, bias=False)\n        # self.bn3 = nn.BatchNorm2d(planes_before_prune * 4)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n        # for residual index match\n        self.index = Variable(index)\n        # for bn add\n        self.bn_value = bn_value\n\n        # self.extend = torch.autograd.Variable(\n        #     torch.rand(self.planes_before_prune * 4, 64 * 56 // self.planes_before_prune,\n        #                64 * 56 // self.planes_before_prune), volatile=True).cuda()\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        # setting: without index match\n        # print(""residual size{},out size{} "".format(residual.size(),   out.size()))\n        # out += residual\n        # out = self.relu(out)\n\n        # setting: with index match\n        residual += self.bn_value.cuda()\n        residual.index_add_(1, self.index.cuda(), out)\n\n        residual = self.relu(residual)\n\n        return residual\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\nclass ResNet_small(nn.Module):\n\n    def __init__(self, block, layers, index, bn_value,\n                 num_for_construct=[64, 64, 64 * 4, 128, 128 * 4, 256, 256 * 4, 512, 512 * 4],\n                 num_classes=1000):\n        super(ResNet_small, self).__init__()\n        self.inplanes = num_for_construct[0]\n\n        self.conv1 = nn.Conv2d(3, num_for_construct[0], kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(num_for_construct[0])\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        # setting: expansion = 4\n        # self.layer1 = self._make_layer(block, num_for_construct[1], num_for_construct[1] * 4, 64, index,  layers[0])\n        # self.layer2 = self._make_layer(block, num_for_construct[2], num_for_construct[2] * 4, 128, index,  layers[1], stride=2)\n        # self.layer3 = self._make_layer(block, num_for_construct[3], num_for_construct[3] * 4, 256, index,  layers[2], stride=2)\n        # self.layer4 = self._make_layer(block, num_for_construct[4], num_for_construct[4] * 4, 512, index,  layers[3], stride=2)\n\n        # setting: expansion may not accuracy equal to 4\n        self.index_layer1 = {key: index[key] for key in index.keys() if \'layer1\' in key}\n        self.index_layer2 = {key: index[key] for key in index.keys() if \'layer2\' in key}\n        self.index_layer3 = {key: index[key] for key in index.keys() if \'layer3\' in key}\n        self.index_layer4 = {key: index[key] for key in index.keys() if \'layer4\' in key}\n        self.bn_layer1 = {key: bn_value[key] for key in bn_value.keys() if \'layer1\' in key}\n        self.bn_layer2 = {key: bn_value[key] for key in bn_value.keys() if \'layer2\' in key}\n        self.bn_layer3 = {key: bn_value[key] for key in bn_value.keys() if \'layer3\' in key}\n        self.bn_layer4 = {key: bn_value[key] for key in bn_value.keys() if \'layer4\' in key}\n        # print(""bn_layer1"", bn_layer1.keys(), bn_layer2.keys(), bn_layer3.keys(), bn_layer4.keys())\n\n        self.layer1 = self._make_layer(block, num_for_construct[1], num_for_construct[2], 64, self.index_layer1, self.bn_layer1,\n                                       layers[0])\n        self.layer2 = self._make_layer(block, num_for_construct[3], num_for_construct[4], 128, self.index_layer2, self.bn_layer2,\n                                       layers[1], stride=2)\n        self.layer3 = self._make_layer(block, num_for_construct[5], num_for_construct[6], 256, self.index_layer3, self.bn_layer3,\n                                       layers[2], stride=2)\n        self.layer4 = self._make_layer(block, num_for_construct[7], num_for_construct[8], 512, self.index_layer4, self.bn_layer4,\n                                       layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes_after_prune, planes_expand, planes_before_prune, index, bn_layer, blocks,\n                    stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes_before_prune * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes_before_prune * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes_before_prune * block.expansion),\n            )\n        print(""before pruning is {}, after pruning is {}:"".format(planes_before_prune,planes_after_prune))\n\n        # setting: accu number for_construct expansion\n        index_block_0_dict = {key: index[key] for key in index.keys() if \'0.conv3\' in key}\n        index_block_0_value = list(index_block_0_dict.values())[0]\n\n        bn_layer_0_value = list(bn_layer.values())[0]\n\n        layers = []\n        layers.append(\n            block(self.inplanes, planes_after_prune, planes_expand, planes_before_prune, index_block_0_value,\n                  bn_layer_0_value,\n                  stride, downsample))\n        #        self.inplanes = planes * block.expansion\n        self.inplanes = planes_before_prune * block.expansion\n\n        for i in range(1, blocks):\n            index_block_i_dict = {key: index[key] for key in index.keys() if (str(i) + \'.conv3\') in key}\n            index_block_i_value = list(index_block_i_dict.values())[0]\n\n            bn_layer_i = {key: bn_layer[key] for key in bn_layer.keys() if (str(i) + \'.bn3\') in key}\n            bn_layer_i_value = list(bn_layer_i.values())[0]\n            layers.append(\n                block(self.inplanes, planes_after_prune, planes_expand, planes_before_prune, index_block_i_value,\n                      bn_layer_i_value,\n                      ))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet18_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n    return model\n\n\ndef resnet34_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model\n\n\ndef resnet50_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef resnet101_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n    return model\n\n\ndef resnet152_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n    return model\n'"
models/preresnet.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom .res_utils import DownsampleA, DownsampleC\nimport math\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  def __init__(self, inplanes, planes, stride, downsample, Type):\n    super(ResNetBasicblock, self).__init__()\n\n    self.Type = Type\n\n    self.bn_a = nn.BatchNorm2d(inplanes)\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n    self.bn_b = nn.BatchNorm2d(planes)\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n    self.relu = nn.ReLU(inplace=True)\n    self.downsample = downsample\n\n  def forward(self, x):\n    residual = x\n\n    basicblock = self.bn_a(x)\n    basicblock = self.relu(basicblock)\n\n    if self.Type == \'both_preact\':\n      residual = basicblock\n    elif self.Type != \'normal\':\n      assert False, \'Unknow type : {}\'.format(self.Type)\n\n    basicblock = self.conv_a(basicblock)\n\n    basicblock = self.bn_b(basicblock)\n    basicblock = self.relu(basicblock)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(residual)\n    \n    return residual + basicblock\n\nclass CifarPreResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, block, depth, num_classes):\n    """""" Constructor\n    Args:\n      depth: number of layers.\n      num_classes: number of classes\n      base_width: base width\n    """"""\n    super(CifarPreResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 2) // 6\n    print (\'CifarPreResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n\n    self.num_classes = num_classes\n\n    self.conv_3x3 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n\n    self.inplanes = 16\n    self.stage_1 = self._make_layer(block, 16, layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, 32, layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, 64, layer_blocks, 2)\n    self.lastact = nn.Sequential(nn.BatchNorm2d(64*block.expansion), nn.ReLU(inplace=True))\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        #m.bias.data.zero_()\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, planes, blocks, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n      downsample = DownsampleA(self.inplanes, planes * block.expansion, stride)\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample, \'both_preact\'))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes, 1, None, \'normal\'))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_3x3(x)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.lastact(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return self.classifier(x)\n\ndef preresnet20(num_classes=10):\n  """"""Constructs a ResNet-20 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 20, num_classes)\n  return model\n\ndef preresnet32(num_classes=10):\n  """"""Constructs a ResNet-32 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 32, num_classes)\n  return model\n\ndef preresnet44(num_classes=10):\n  """"""Constructs a ResNet-44 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 44, num_classes)\n  return model\n\ndef preresnet56(num_classes=10):\n  """"""Constructs a ResNet-56 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 56, num_classes)\n  return model\n\ndef preresnet110(num_classes=10):\n  """"""Constructs a ResNet-110 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 110, num_classes)\n  return model\n'"
models/res_utils.py,3,"b""import torch\nimport torch.nn as nn\n\nclass DownsampleA(nn.Module):  \n\n  def __init__(self, nIn, nOut, stride):\n    super(DownsampleA, self).__init__() \n    self.avg = nn.AvgPool2d(kernel_size=1, stride=stride)   \n\n  def forward(self, x):   \n    x = self.avg(x)  \n    return torch.cat((x, x.mul(0)), 1)  \n\nclass DownsampleC(nn.Module):     \n\n  def __init__(self, nIn, nOut, stride):\n    super(DownsampleC, self).__init__()\n    assert stride != 1 or nIn != nOut\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=1, stride=stride, padding=0, bias=False)\n\n  def forward(self, x):\n    x = self.conv(x)\n    return x\n\nclass DownsampleD(nn.Module):\n\n  def __init__(self, nIn, nOut, stride):\n    super(DownsampleD, self).__init__()\n    assert stride == 2\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=2, stride=stride, padding=0, bias=False)\n    self.bn   = nn.BatchNorm2d(nOut)\n\n  def forward(self, x):\n    x = self.conv(x)\n    x = self.bn(x)\n    return x\n#\n#class SelectiveSequential(nn.Module):\n#    def __init__(self, to_select, modules_dict):\n#        super(SelectiveSequential, self).__init__()\n#        for key, module in modules_dict.items():\n#            self.add_module(key, module)\n#        self._to_select = to_select\n#    \n#    def forward(self,x):\n#        list = []\n#        for name, module in self._modules.items():\n#            x = module(x)\n#            if name in self._to_select:\n#                list.append(x)\n#        return list\n#    \n#class FeatureExtractor(nn.Module):\n#    def __init__(self, submodule, extracted_layers):\n#        super(FeatureExtractor, self).__init__()\n#        self.submodule = submodule\n#\n#    def forward(self, x):\n#        outputs = []\n#        for name, module in self.submodule._modules.items():\n#            x = module(x)\n#            if name in self.extracted_layers:\n#                outputs += [x]\n#        return outputs + [x]\n#    \n#original_model = torchvision.models.alexnet(pretrained=True)\n#\n#class AlexNetConv4(nn.Module):\n#    def __init__(self):\n#        super(AlexNetConv4, self).__init__()\n#        self.features = nn.Sequential(\n#            # stop at conv4\n#            *list(original_model.features.children())[:-3]\n#        )\n#    def forward(self, x):\n#        x = self.features(x)\n#        return x\n#\n#model = AlexNetConv4()\n#\n#\n#extract_feature = {}\n#count = 0\n#def save_hook(module, input, output):\n##    global hook_key\n#    global count\n#    temp = torch.zeros(output.size())\n#    temp.copy_(output.data)\n#    extract_feature[count] = temp\n#    count += 1\n#    print(extract_feature)\n#    \n#class Myextract(nn.Module):\n#    \n#    def __init__(self, model):\n#        super(Myextract, self).__init__()\n#        self.model = model\n#        self.extract_feature = {}\n#        self.hook_key = {}\n#        self.count= 0\n#        \n#    def add_hook(self):  \n#        for key, module in model._modules.items():\n#            if 'stage' in key:\n#                i = 1\n#                for block in module.children():\n##                    self.get_key( key + '_block_' + str(i))\n#                    self.add_hook_block(key + '_block_' + str(i), module)\n#                    i = i+1\n#                print(i)\n#            else:\n#                self.get_key (key)\n#                module.register_forward_hook (save_hook)\n#            print('add hook  done')\n#\n#    def add_hook_block(self,key,module):\n##        module.bn_a.register_forward_hook (self.save(key+'_bn_a'))\n##        module.bn_b.register_forward_hook (self.save(key+'_bn_b'))\n#        self.get_key(key+'_bn_a')\n#        module.bn_a.register_forward_hook (save_hook)\n#        self.get_key(key+'_bn_b')\n#        module.bn_b.register_forward_hook (save_hook)\n#        print('add hook block done')\n#        \n#\n#    def get_key(self, key):\n#        self.count += 1\n#        self.hook_key[self.count] = key\n#\n#    def run(self):\n#        self.add_hook()\n#        \n#        \n#model.layer2.conv1.register_forward_hook (hook)"""
models/resnet.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom .res_utils import DownsampleA, DownsampleC, DownsampleD\nimport math\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  """"""\n  RexNet basicblock (https://github.com/facebook/fb.resnet.torch/blob/master/models/resnet.lua)\n  """"""\n  def __init__(self, inplanes, planes, stride=1, downsample=None):\n    super(ResNetBasicblock, self).__init__()\n\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn_a = nn.BatchNorm2d(planes)\n\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_b = nn.BatchNorm2d(planes)\n\n    self.downsample = downsample\n\n  def forward(self, x):\n    residual = x\n\n    basicblock = self.conv_a(x)\n    basicblock = self.bn_a(basicblock)\n    basicblock = F.relu(basicblock, inplace=True)\n\n    basicblock = self.conv_b(basicblock)\n    basicblock = self.bn_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(x)\n    \n    return F.relu(residual + basicblock, inplace=True)\n\nclass CifarResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, block, depth, num_classes):\n    """""" Constructor\n    Args:\n      depth: number of layers.\n      num_classes: number of classes\n      base_width: base width\n    """"""\n    super(CifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 2) // 6\n    print (\'CifarResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n\n    self.num_classes = num_classes\n\n    self.conv_1_3x3 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(16)\n\n    self.inplanes = 16\n    self.stage_1 = self._make_layer(block, 16, layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, 32, layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, 64, layer_blocks, 2)\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        #m.bias.data.zero_()\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, planes, blocks, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n      downsample = DownsampleA(self.inplanes, planes * block.expansion, stride)\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return self.classifier(x)\n\ndef resnet20(num_classes=10):\n  """"""Constructs a ResNet-20 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 20, num_classes)\n  return model\n\ndef resnet32(num_classes=10):\n  """"""Constructs a ResNet-32 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 32, num_classes)\n  return model\n\ndef resnet44(num_classes=10):\n  """"""Constructs a ResNet-44 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 44, num_classes)\n  return model\n\ndef resnet56(num_classes=10):\n  """"""Constructs a ResNet-56 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 56, num_classes)\n  return model\n\ndef resnet110(num_classes=10):\n  """"""Constructs a ResNet-110 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 110, num_classes)\n  return model\n'"
models/resnet_feature.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom .res_utils import DownsampleA, DownsampleC, DownsampleD\nimport math\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  """"""\n  RexNet basicblock (https://github.com/facebook/fb.resnet.torch/blob/master/models/resnet.lua)\n  """"""\n  def __init__(self, inplanes, planes, stride=1, downsample=None):\n    super(ResNetBasicblock, self).__init__()\n\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn_a = nn.BatchNorm2d(planes)\n\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_b = nn.BatchNorm2d(planes)\n\n    self.downsample = downsample\n\n  def forward(self, x):\n    residual = x\n\n    basicblock = self.conv_a(x)\n    basicblock = self.bn_a(basicblock)\n    basicblock = F.relu(basicblock, inplace=True)\n\n    basicblock = self.conv_b(basicblock)\n    basicblock = self.bn_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(x)\n    \n    return F.relu(residual + basicblock, inplace=True)\n\nclass CifarResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, block, depth, num_classes):\n    """""" Constructor\n    Args:\n      depth: number of layers.\n      num_classes: number of classes\n      base_width: base width\n    """"""\n    super(CifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 2) // 6\n    print (\'CifarResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n\n    self.num_classes = num_classes\n\n    self.conv_1_3x3 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(16)\n\n    self.inplanes = 16\n    self.stage_1 = self._make_layer(block, 16, layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, 32, layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, 64, layer_blocks, 2)\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        #m.bias.data.zero_()\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, planes, blocks, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n      downsample = DownsampleA(self.inplanes, planes * block.expansion, stride)\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return self.classifier(x)\n\ndef resnet20(num_classes=10):\n  """"""Constructs a ResNet-20 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 20, num_classes)\n  return model\n\ndef resnet32(num_classes=10):\n  """"""Constructs a ResNet-32 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 32, num_classes)\n  return model\n\ndef resnet44(num_classes=10):\n  """"""Constructs a ResNet-44 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 44, num_classes)\n  return model\n\ndef resnet56(num_classes=10):\n  """"""Constructs a ResNet-56 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 56, num_classes)\n  return model\n\ndef resnet110(num_classes=10):\n  """"""Constructs a ResNet-110 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 110, num_classes)\n  return model\n'"
models/resnet_mod.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom .res_utils import DownsampleA, DownsampleC, DownsampleD\nimport math\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  """"""\n  RexNet basicblock (https://github.com/facebook/fb.resnet.torch/blob/master/models/resnet.lua)\n  """"""\n  def __init__(self, inplanes, planes, stride=1, downsample=None):\n    super(ResNetBasicblock, self).__init__()\n\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn_a = nn.BatchNorm2d(planes)\n\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_b = nn.BatchNorm2d(planes)\n\n    self.downsample = downsample\n\n  def forward(self, x):\n    if isinstance(x, list):\n      x, is_list, features = x[0], True, x[1:]\n    else:\n      is_list, features = False, None\n    residual = x\n\n    conv_a = self.conv_a(x)\n    bn_a = self.bn_a(conv_a)\n    relu_a = F.relu(bn_a, inplace=True)\n\n    conv_b = self.conv_b(relu_a)\n    bn_b = self.bn_b(conv_b)\n\n    if self.downsample is not None:\n      residual = self.downsample(x)\n    \n    output = F.relu(residual + bn_b, inplace=True)\n    \n    if is_list:\n      return [output] + features + [bn_a, bn_b]\n    else:\n      return output\n\nclass CifarResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, block, depth, num_classes):\n    """""" Constructor\n    Args:\n      depth: number of layers.\n      num_classes: number of classes\n      base_width: base width\n    """"""\n    super(CifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 2) // 6\n    print (\'CifarResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n\n    self.num_classes = num_classes\n\n    self.conv_1_3x3 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(16)\n\n    self.inplanes = 16\n    self.stage_1 = self._make_layer(block, 16, layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, 32, layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, 64, layer_blocks, 2)\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        #m.bias.data.zero_()\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, planes, blocks, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n      downsample = DownsampleA(self.inplanes, planes * block.expansion, stride)\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    if isinstance(x, list):\n      assert len(x) == 1, \'The length of inputs must be one vs {}\'.format(len(x))\n      x, is_list = x[0], True\n    else:\n      x, is_list = x, False\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n\n    if is_list: x = [x]\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    if is_list:\n      x, features = x[0], x[1:]\n    else:\n      features = None\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    cls = self.classifier(x)\n\n    if is_list: return cls, features\n    else:       return cls\n\ndef resnet_mod20(num_classes=10):\n  """"""Constructs a ResNet-20 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 20, num_classes)\n  return model\n\ndef resnet_mod32(num_classes=10):\n  """"""Constructs a ResNet-32 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 32, num_classes)\n  return model\n\ndef resnet_mod44(num_classes=10):\n  """"""Constructs a ResNet-44 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 44, num_classes)\n  return model\n\ndef resnet_mod56(num_classes=10):\n  """"""Constructs a ResNet-56 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 56, num_classes)\n  return model\n\ndef resnet_mod110(num_classes=10):\n  """"""Constructs a ResNet-110 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 110, num_classes)\n  return model\n'"
models/resnet_small.py,11,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\n#from .res_utils import DownsampleA, DownsampleC, DownsampleD\nimport math,time\n\nclass DownsampleA(nn.Module):  \n\n  def __init__(self, nIn, nOut, stride):\n    super(DownsampleA, self).__init__() \n    self.avg = nn.AvgPool2d(kernel_size=1, stride=stride)   \n\n  def forward(self, x):   \n    x = self.avg(x)  \n    return torch.cat((x, x.mul(0)), 1)  \n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  """"""\n  RexNet basicblock (https://github.com/facebook/fb.resnet.torch/blob/master/models/resnet.lua)\n  """"""\n  def __init__(self, inplanes, planes, supply, index, stride=1, downsample=None):\n    super(ResNetBasicblock, self).__init__()\n\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn_a = nn.BatchNorm2d(planes)\n\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_b = nn.BatchNorm2d(planes)\n\n    self.downsample = downsample\n    self.inplanes = inplanes\n    self.index = index\n    self.supply = supply\n    self.size = 0\n    self.out = torch.autograd.Variable(torch.rand(128, self.supply, 16*32//self.supply, 16*32//self.supply))\n    self.i = 0\n    self.time = []\n    self.sum = []\n    \n  def forward(self, x):\n        \n    residual = x\n\n    basicblock = self.conv_a(x)\n    basicblock = self.bn_a(basicblock)\n    basicblock = F.relu(basicblock, inplace=True)\n\n    basicblock = self.conv_b(basicblock)\n    basicblock = self.bn_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(x)\n    \n    out = self.out\n#    out.zero_()\n#    out = torch.FloatTensor(self.inplanes, basicblock.size()[1], basicblock.size()[2]).zero_()\n#    out.index_add_(0, self.index[0], residual.data)\n#    out.index_add_(0, self.index[1], basicblock.data)\n#    out = torch.rand(self.inplanes, basicblock.size()[1], basicblock.size()[2])\n#    time1 =time.time()\n#    self.i += 1\n#    if  self.i  == 1:\n#      self.out = torch.autograd.Variable(torch.rand(basicblock.size()[0], self.supply, basicblock.size()[2], basicblock.size()[3]))\n#      print(""set out"")\n#      print(self.i,basicblock.size()[0])\n#    elif self.i in [79]:\n#      self.out = torch.autograd.Variable(torch.rand(basicblock.size()[0], self.supply, basicblock.size()[2], basicblock.size()[3]))\n#    else:\n#      print(self.i)\n#      pass\n#    out = self.out.cuda()\n#    time2 = time.time()\n#    print (\'function took %0.3f ms\' % ((time2-time1)*1000.0))\n#    self.time.append((time2-time1)*1000.0)\n#    self.sum.append(sum(self.time))\n#    print(""sum:"",self.sum)\n#    print(\'                                            self.time %f\',self.time)\n#    time2 = time.time()\n#\n#    self.out = torch.autograd.Variable(torch.rand(basicblock.size()[0], self.supply, basicblock.size()[2], basicblock.size()[3]))\n#    out = self.out.cuda()\n#    time3 = time.time()\n#    print (\'function                 took %0.3f ms\' % ((time2-time1)*1000.0))\n#\n#    print (\'function took %0.3f ms\' % ((time3-time2)*1000.0))\n#    self.time .append((time3-time2)*1000.0)\n#    #print(\'                                            self.time %f\',self.time)\n##    print(""sum:"",sum(self.time))\n#    self.sum .append(sum(self.time))\n#    print(self.sum)\n    return F.relu(out, inplace=True)\n\nclass CifarResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, block, depth, num_classes, index, rate=[16, 16, 32, 64, 16, 32, 64]):\n    """""" Constructor\n    Args:\n      depth: number of layers.\n      num_classes: number of classes\n      base_width: base width\n    """"""\n    super(CifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model   \n    assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 2) // 6\n    self.stage_num = (depth - 2) // 3\n    print (\'CifarResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n    self.num_classes = num_classes\n    self.rate = rate\n    print(layer_blocks)\n    self.conv_1_3x3 = nn.Conv2d(3, rate[0], kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(rate[0])\n    self.inplanes = rate[0]\n    self.stage_1 = self._make_layer(block, rate[4], rate[1], rate[4], index, layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, rate[5], rate[2], rate[5], index, layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, rate[6], rate[3], rate[6], index, layer_blocks, 2)\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        #m.bias.data.zero_()\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, inplanes, planes, supply, index, blocks, stride=1):\n    downsample = None\n    if stride != 1 :\n        \n      downsample = DownsampleA(self.inplanes, planes * block.expansion, stride)\n    layers = []\n\n#    print(\'first inplane, out plane, supply\', self.inplanes,planes,supply)\n    \n    layers.append(block(self.inplanes, planes, supply, index, stride, downsample))\n#    self.inplanes = planes * block.expansion\n\n    self.inplanes = inplanes \n#    print(\'seconde inplane, out plane,supply\', self.inplanes,planes,supply)\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes, supply, index))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n#    print(x.size())\n#    x = torch.autograd.Variable(torch.rand(x.size()[0], 16, x.size()[2], x.size()[3])).cuda()\n\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return self.classifier(x)\n\ndef resnet20_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-20 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 20, num_classes, index, rate)\n  return model\n\ndef resnet32_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-32 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 32, num_classes,index, rate)\n  return model\n\ndef resnet44_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-44 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 44, num_classes,index, rate)\n  return model\n\ndef resnet56_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-56 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 56, num_classes,index, rate)\n  return model\n\ndef resnet110_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-110 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 110, num_classes,index, rate)\n  return model\n'"
models/resnet_small_V3.py,6,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\n#from .res_utils import DownsampleA, DownsampleC, DownsampleD\nimport math\n\nclass DownsampleA(nn.Module):  \n\n  def __init__(self, nIn, nOut, stride):\n    super(DownsampleA, self).__init__() \n    self.avg = nn.AvgPool2d(kernel_size=1, stride=stride)   \n\n  def forward(self, x):   \n    x = self.avg(x)  \n    return torch.cat((x, x.mul(0)), 1)  \n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  """"""\n  RexNet basicblock (https://github.com/facebook/fb.resnet.torch/blob/master/models/resnet.lua)\n  """"""\n  def __init__(self, inplanes, planes, index, stride=1, downsample=None):\n    super(ResNetBasicblock, self).__init__()\n\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn_a = nn.BatchNorm2d(planes)\n\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_b = nn.BatchNorm2d(planes)\n\n    self.downsample = downsample\n    self.inplanes = inplanes\n    self.index = index\n    \n  def forward(self, x):\n    residual = x\n\n    basicblock = self.conv_a(x)\n    basicblock = self.bn_a(basicblock)\n    basicblock = F.relu(basicblock, inplace=True)\n\n    basicblock = self.conv_b(basicblock)\n    basicblock = self.bn_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(x)\n    \n#    out = self.out.cuda()\n#    out.zero_()\n#    out = torch.FloatTensor(self.inplanes, basicblock.size()[1], basicblock.size()[2]).zero_()\n#    out.index_add_(0, self.index[0], residual.data)\n#    out.index_add_(0, self.index[1], basicblock.data)\n    out = torch.rand(self.inplanes, basicblock.size()[1], basicblock.size()[2])\n\n    return F.relu(out, inplace=True)\n\nclass CifarResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, block, depth, num_classes, index, rate=[16, 16, 32, 64, 16, 32, 64]):\n    """""" Constructor\n    Args:\n      depth: number of layers.\n      num_classes: number of classes\n      base_width: base width\n    """"""\n    super(CifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model   \n    assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 2) // 6\n    self.stage_num = (depth - 2) // 3\n    print (\'CifarResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n    print(len(index))\n    self.num_classes = num_classes\n    self.rate = rate\n    self.index = index\n    \n    self.conv_1_3x3 = nn.Conv2d(3, rate[0], kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(rate[0])\n    print(len(index[1 : self.stage_num + 1]))\n    self.inplanes = rate[0]\n    self.stage_1 = self._make_layer(block, rate[4], rate[1], index[1 : self.stage_num + 1], layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, rate[5], rate[2], index[self.stage_num + 1 : self.stage_num * 2 + 1], layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, rate[6], rate[3], index[self.stage_num * 2 + 1 : self.stage_num * 3 + 1], layer_blocks, 2)\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        #m.bias.data.zero_()\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, inplanes, planes, index, blocks, stride=1):\n    downsample = None\n    if stride != 1 :\n        \n      downsample = DownsampleA(self.inplanes, planes * block.expansion, stride)\n#    print(self.inplanes)\n    layers = []\n    i=0\n    j=2\n    \n    layers.append(block(self.inplanes, planes, index[i:j], stride, downsample))\n#    self.inplanes = planes * block.expansion\n    i += 2\n    j += 2\n    \n    self.inplanes = inplanes \n    print(inplanes)\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes,index[i:j]))\n      i += 2\n      j += 2\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return self.classifier(x)\n\ndef resnet20_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-20 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 20, num_classes, index, rate)\n  return model\n\ndef resnet32_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-32 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 32, num_classes,index, rate)\n  return model\n\ndef resnet44_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-44 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 44, num_classes,index, rate)\n  return model\n\ndef resnet56_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-56 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 56, num_classes,index, rate)\n  return model\n\ndef resnet110_small(index, rate,num_classes=10):\n  """"""Constructs a ResNet-110 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 110, num_classes,index, rate)\n  return model\n'"
models/resnext.py,3,"b'import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\nclass ResNeXtBottleneck(nn.Module):\n  expansion = 4\n  """"""\n  RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n  """"""\n  def __init__(self, inplanes, planes, cardinality, base_width, stride=1, downsample=None):\n    super(ResNeXtBottleneck, self).__init__()\n\n    D = int(math.floor(planes * (base_width/64.0)))\n    C = cardinality\n\n    self.conv_reduce = nn.Conv2d(inplanes, D*C, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_reduce = nn.BatchNorm2d(D*C)\n\n    self.conv_conv = nn.Conv2d(D*C, D*C, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n    self.bn = nn.BatchNorm2d(D*C)\n\n    self.conv_expand = nn.Conv2d(D*C, planes*4, kernel_size=1, stride=1, padding=0, bias=False)\n    self.bn_expand = nn.BatchNorm2d(planes*4)\n\n    self.downsample = downsample\n\n  def forward(self, x):\n    residual = x\n\n    bottleneck = self.conv_reduce(x)\n    bottleneck = F.relu(self.bn_reduce(bottleneck), inplace=True)\n\n    bottleneck = self.conv_conv(bottleneck)\n    bottleneck = F.relu(self.bn(bottleneck), inplace=True)\n\n    bottleneck = self.conv_expand(bottleneck)\n    bottleneck = self.bn_expand(bottleneck)\n\n    if self.downsample is not None:\n      residual = self.downsample(x)\n    \n    return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n  """"""\n  ResNext optimized for the Cifar dataset, as specified in\n  https://arxiv.org/pdf/1611.05431.pdf\n  """"""\n  def __init__(self, block, depth, cardinality, base_width, num_classes):\n    super(CifarResNeXt, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 9 == 0, \'depth should be one of 29, 38, 47, 56, 101\'\n    layer_blocks = (depth - 2) // 9\n\n    self.cardinality = cardinality\n    self.base_width = base_width\n    self.num_classes = num_classes\n\n    self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(64)\n\n    self.inplanes = 64\n    self.stage_1 = self._make_layer(block, 64 , layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, 128, layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, 256, layer_blocks, 2)\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(256*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, planes, blocks, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n      downsample = nn.Sequential(\n        nn.Conv2d(self.inplanes, planes * block.expansion,\n              kernel_size=1, stride=stride, bias=False),\n        nn.BatchNorm2d(planes * block.expansion),\n      )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, self.cardinality, self.base_width, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes, self.cardinality, self.base_width))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return self.classifier(x)\n\ndef resnext29_16_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 16*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 16, 64, num_classes)\n  return model\n\ndef resnext29_8_64(num_classes=10):\n  """"""Constructs a ResNeXt-29, 8*64d model for CIFAR-10 (by default)\n  \n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNeXt(ResNeXtBottleneck, 29, 8, 64, num_classes)\n  return model\n'"
models/vgg.py,10,"b'import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport math\n\n\n__all__ = [\n    \'VGG\', \'vgg11\', \'vgg11_bn\', \'vgg13\', \'vgg13_bn\', \'vgg16\', \'vgg16_bn\',\n    \'vgg19_bn\', \'vgg19\',\n]\n\n\nmodel_urls = {\n    \'vgg11\': \'https://download.pytorch.org/models/vgg11-bbd30ac9.pth\',\n    \'vgg13\': \'https://download.pytorch.org/models/vgg13-c768596a.pth\',\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n    \'vgg19\': \'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\',\n    \'vgg11_bn\': \'https://download.pytorch.org/models/vgg11_bn-6002323d.pth\',\n    \'vgg13_bn\': \'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth\',\n    \'vgg16_bn\': \'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\',\n    \'vgg19_bn\': \'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\',\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes),\n        )\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfg = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'B\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'D\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512, \'M\'],\n    \'E\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512, \'M\'],\n}\n\n\ndef vgg11(pretrained=False, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg11\']))\n    return model\n\n\ndef vgg11_bn(pretrained=False, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\'], batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg11_bn\']))\n    return model\n\n\ndef vgg13(pretrained=False, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg13\']))\n    return model\n\n\ndef vgg13_bn(pretrained=False, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\'], batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg13_bn\']))\n    return model\n\n\ndef vgg16(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model\n\n\ndef vgg16_bn(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\'], batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16_bn\']))\n    return model\n\n\ndef vgg19(pretrained=False, **kwargs):\n    """"""VGG 19-layer model (configuration ""E"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg19\']))\n    return model\n\n\ndef vgg19_bn(pretrained=False, **kwargs):\n    """"""VGG 19-layer model (configuration \'E\') with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\'], batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg19_bn\']))\n    return model\n'"
models/vgg_cifar.py,3,"b""import math\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\n__all__ = ['vgg']\n\ndefaultcfg = {\n    11 : [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n    13 : [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n    16 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n    19 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n}\n\nclass vgg(nn.Module):\n    def __init__(self, dataset='cifar10', depth=19, init_weights=True, cfg=None):\n        super(vgg, self).__init__()\n        if cfg is None:\n            cfg = defaultcfg[depth]\n\n        self.cfg = cfg\n\n        self.feature = self.make_layers(cfg, True)\n\n        if dataset == 'cifar10':\n            num_classes = 10\n        elif dataset == 'cifar100':\n            num_classes = 100\n        self.classifier = nn.Sequential(\n              nn.Linear(cfg[-1], 512),\n              nn.BatchNorm1d(512),\n              nn.ReLU(inplace=True),\n              nn.Linear(512, num_classes)\n            )\n        if init_weights:\n            self._initialize_weights()\n\n    def make_layers(self, cfg, batch_norm=False):\n        layers = []\n        in_channels = 3\n        for v in cfg:\n            if v == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.feature(x)\n        x = nn.AvgPool2d(2)(x)\n        x = x.view(x.size(0), -1)\n        y = self.classifier(x)\n        return y\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\nif __name__ == '__main__':\n    net = vgg()\n    x = Variable(torch.FloatTensor(16, 3, 40, 40))\n    y = net(x)\n    print(y.data.shape)"""
models/vgg_cifar10.py,6,"b'import math\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n__all__ = [\'vgg\']\n\ndefaultcfg = {\n    11: [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512],\n    13: [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512],\n    16: [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512],\n    19: [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512],\n}\n\n\nclass vgg(nn.Module):\n    def __init__(self, dataset=\'cifar10\', depth=19, init_weights=True, cfg=None):\n        super(vgg, self).__init__()\n        if cfg is None:\n            cfg = defaultcfg[depth]\n\n        self.cfg = cfg\n\n        self.feature = self.make_layers(cfg, True)\n\n        if dataset == \'cifar10\':\n            num_classes = 10\n        elif dataset == \'cifar100\':\n            num_classes = 100\n        self.classifier = nn.Sequential(\n            nn.Linear(cfg[-1], 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, num_classes)\n        )\n        if init_weights:\n            self._initialize_weights()\n\n    def make_layers(self, cfg, batch_norm=False):\n        layers = []\n        in_channels = 3\n        for v in cfg:\n            if v == \'M\':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.feature(x)\n        x = nn.AvgPool2d(2)(x)\n        x = x.view(x.size(0), -1)\n        y = self.classifier(x)\n        return y\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(0.5)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\nif __name__ == \'__main__\':\n    net = vgg(depth=16)\n    x = Variable(torch.FloatTensor(16, 3, 40, 40))\n    y = net(x)\n    print(y.data.shape)\n    a = []\n    for x, y in enumerate(net.named_parameters()):\n        print(x, y[0], y[1].size())\n    #\n    # for index, m in enumerate(net.modules()):\n    #     print(index,m)\n    #     if isinstance(m, nn.Conv2d):\n    #         print(""conv"",index, m)\n    # import numpy as np\n    # cfg = [32, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 256, 256, 256, \'M\', 256, 256, 256]\n    #\n    # cfg_mask = []\n    # layer_id = 0\n    # for m in net.modules():\n    #     if isinstance(m, nn.Conv2d):\n    #         out_channels = m.weight.data.shape[0]\n    #         if out_channels == cfg[layer_id]:\n    #             cfg_mask.append(torch.ones(out_channels))\n    #             layer_id += 1\n    #             continue\n    #         weight_copy = m.weight.data.abs().clone()\n    #         weight_copy = weight_copy.cpu().numpy()\n    #         L1_norm = np.sum(weight_copy, axis=(1, 2, 3))\n    #         arg_max = np.argsort(L1_norm)\n    #         arg_max_rev = arg_max[::-1][:cfg[layer_id]]\n    #         assert arg_max_rev.size == cfg[layer_id], ""size of arg_max_rev not correct""\n    #         mask = torch.zeros(out_channels)\n    #         mask[arg_max_rev.tolist()] = 1\n    #         cfg_mask.append(mask)\n    #         layer_id += 1\n    #     elif isinstance(m, nn.MaxPool2d):\n    #         layer_id += 1\n    #\n    # newmodel = vgg(dataset=\'cifar10\', cfg=cfg)\n    # newmodel.cuda()\n    #\n    # start_mask = torch.ones(3)\n    # layer_id_in_cfg = 0\n    # end_mask = cfg_mask[layer_id_in_cfg]\n    # for [m0, m1] in zip(net.modules(), newmodel.modules()):\n    #     if isinstance(m0, nn.BatchNorm2d):\n    #         idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n    #         if idx1.size == 1:\n    #             idx1 = np.resize(idx1, (1,))\n    #         m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n    #         m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n    #         m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n    #         m1.running_var = m0.running_var[idx1.tolist()].clone()\n    #         layer_id_in_cfg += 1\n    #         start_mask = end_mask\n    #         if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n    #             end_mask = cfg_mask[layer_id_in_cfg]\n    #     elif isinstance(m0, nn.Conv2d):\n    #         idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n    #         idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n    #         print(\'In shape: {:d}, Out shape {:d}.\'.format(idx0.size, idx1.size))\n    #         if idx0.size == 1:\n    #             idx0 = np.resize(idx0, (1,))\n    #         if idx1.size == 1:\n    #             idx1 = np.resize(idx1, (1,))\n    #         w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n    #         w1 = w1[idx1.tolist(), :, :, :].clone()\n    #         m1.weight.data = w1.clone()\n    #     elif isinstance(m0, nn.Linear):\n    #         if layer_id_in_cfg == len(cfg_mask):\n    #             idx0 = np.squeeze(np.argwhere(np.asarray(cfg_mask[-1].cpu().numpy())))\n    #             if idx0.size == 1:\n    #                 idx0 = np.resize(idx0, (1,))\n    #             m1.weight.data = m0.weight.data[:, idx0].clone()\n    #             m1.bias.data = m0.bias.data.clone()\n    #             layer_id_in_cfg += 1\n    #             continue\n    #         m1.weight.data = m0.weight.data.clone()\n    #         m1.bias.data = m0.bias.data.clone()\n    #     elif isinstance(m0, nn.BatchNorm1d):\n    #         m1.weight.data = m0.weight.data.clone()\n    #         m1.bias.data = m0.bias.data.clone()\n    #         m1.running_mean = m0.running_mean.clone()\n    #         m1.running_var = m0.running_var.clone()\n    # for m in net.modules():\n    #     if isinstance(m, nn.Conv2d):\n    #         a.append(m)\n    #         print(m)\n    print(1)\n'"
