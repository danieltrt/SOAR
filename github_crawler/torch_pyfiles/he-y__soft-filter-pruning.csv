file_path,api_count,code
infer_pruned.py,12,"b'# https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py\nimport argparse\nimport os\nimport shutil\nimport pdb, time\nfrom collections import OrderedDict\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n# from utils import convert_secs2time, time_string, time_file_str\nimport models\nimport numpy as np\n\nmodel_names = sorted(name for name in models.__dict__\n                     if name.islower() and not name.startswith(""__"")\n                     and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\', help=\'path to dataset\')\nparser.add_argument(\'--save_dir\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names,\n                    help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int, metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float, metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--print-freq\', \'-p\', default=5, type=int, metavar=\'N\', help=\'print frequency (default: 100)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\n# compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--skip_downsample\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\nparser.add_argument(\'--eval_small\', dest=\'eval_small\', action=\'store_true\', help=\'whether a big or small model\')\nparser.add_argument(\'--small_model\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\n\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\n\n\n\ndef main():\n    best_prec1 = 0\n\n    if not os.path.isdir(args.save_dir):\n        os.makedirs(args.save_dir)\n    log = open(os.path.join(args.save_dir, \'gpu-time.{}.log\'.format(args.arch)), \'w\')\n\n    # create model\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](pretrained=False)\n    print_log(""=> Model : {}"".format(model), log)\n    print_log(""=> parameter : {}"".format(args), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    print_log(""Skip downsample : {}"".format(args.skip_downsample), log)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            state_dict = checkpoint[\'state_dict\']\n            state_dict = remove_module_dict(state_dict)\n            model.load_state_dict(state_dict)\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"".format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            # transforms.Scale(256),\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    if args.evaluate:\n        print_log(""eval true"", log)\n        if not args.eval_small:\n            big_model = model.cuda()\n            print_log(\'Evaluate: big model\', log)\n            print_log(\'big model accu: {}\'.format(validate(val_loader, big_model, criterion, log)), log)\n        else:\n            print_log(\'Evaluate: small model\', log)\n            if args.small_model:\n                if os.path.isfile(args.small_model):\n                    print_log(""=> loading small model \'{}\'"".format(args.small_model), log)\n                    small_model = torch.load(args.small_model)\n                    for x, y in zip(small_model.named_parameters(), model.named_parameters()):\n                        print_log(""name of layer: {}\\n\\t *** small model {}\\n\\t *** big model {}"".format(x[0], x[1].size(),\n                                                                                                         y[1].size()), log)\n                    if args.use_cuda:\n                        small_model = small_model.cuda()\n                    print_log(\'small model accu: {}\'.format(validate(val_loader, small_model, criterion, log)), log)\n                else:\n                    print_log(""=> no small model found at \'{}\'"".format(args.small_model), log)\n        return\n\n\ndef validate(val_loader, model, criterion, log):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        # target = target.cuda(async=True)\n        if args.use_cuda:\n            input, target = input.cuda(), target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                i, len(val_loader), batch_time=batch_time, loss=losses,\n                top1=top1, top5=top5), log)\n\n    print_log(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5,\n                                                                                           error1=100 - top1.avg), log)\n\n    return top1.avg\n\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\ndef remove_module_dict(state_dict):\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k[7:]  # remove `module.`\n        new_state_dict[name] = v\n    return new_state_dict\n\n\nif __name__ == \'__main__\':\n    main()'"
original_train.py,19,"b'# https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py\nimport argparse\nimport os, sys\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models\nfrom utils import convert_secs2time, time_string, time_file_str\n#from models import print_log\nimport models\nimport random\nimport numpy as np\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--save_dir\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\', help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=100, type=int, metavar=\'N\', help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int, metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float, metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\', help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float, metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 100)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\n\nargs.prefix = time_file_str()\n\ndef main():\n    best_prec1 = 0\n\n    if not os.path.isdir(args.save_dir):\n      os.makedirs(args.save_dir)\n    log = open(os.path.join(args.save_dir, \'{}.{}.log\'.format(args.arch,args.prefix)), \'w\')\n\n    # version information\n    print_log(""PyThon  version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""PyTorch version : {}"".format(torch.__version__), log)\n    print_log(""cuDNN   version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Vision  version : {}"".format(torchvision.__version__), log)\n    # create model\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](pretrained=False)\n    print_log(""=> Model : {}"".format(model), log)\n    print_log(""=> parameter : {}"".format(args), log)\n\n    if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n      model.features = torch.nn.DataParallel(model.features)\n      model.cuda()\n    else:\n      model = torch.nn.DataParallel(model).cuda()\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay,\n                                nesterov=True)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"".format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=args.workers, pin_memory=True, sampler=None)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion)\n        return\n\n    filename = os.path.join(args.save_dir, \'checkpoint.{}.{}.pth.tar\'.format(args.arch, args.prefix))\n    bestname = os.path.join(args.save_dir, \'best.{}.{}.pth.tar\'.format(args.arch, args.prefix))\n\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.val * (args.epochs-epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n        print_log(\' [{:s}] :: {:3d}/{:3d} ----- [{:s}] {:s}\'.format(args.arch, epoch, args.epochs, time_string(), need_time), log)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, log)\n        # evaluate on validation set\n        val_acc_2 = validate(val_loader, model, criterion, log)\n\n        # remember best prec@1 and save checkpoint\n        is_best = val_acc_2 > best_prec1\n        best_prec1 = max(val_acc_2, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, filename, bestname)\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n    log.close()\n\n\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses, top1=top1, top5=top5), log)\n\n\ndef validate(val_loader, model, criterion, log):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Test: [{0}/{1}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                  \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                  \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                   i, len(val_loader), batch_time=batch_time, loss=losses,\n                   top1=top1, top5=top5), log)\n\n    print_log(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n    return top1.avg\n\n\ndef save_checkpoint(state, is_best, filename, bestname):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, bestname)\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n  \n  \nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nif __name__ == \'__main__\':\n    main()\n'"
pruning_cifar10_resnet.py,25,"b'from __future__ import division\n\nimport os, sys, shutil, time, random\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom utils import AverageMeter, RecorderMeter, time_string, convert_secs2time\nimport models\nimport numpy as np\n\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'Trains ResNeXt on CIFAR or ImageNet\', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\'data_path\', type=str, help=\'Path to dataset\')\nparser.add_argument(\'--dataset\', type=str, choices=[\'cifar10\', \'cifar100\', \'imagenet\', \'svhn\', \'stl10\'], help=\'Choose between Cifar10/100 and ImageNet.\')\nparser.add_argument(\'--arch\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names, help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnext29_8_64)\')\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=300, help=\'Number of epochs to train.\')\nparser.add_argument(\'--batch_size\', type=int, default=128, help=\'Batch size.\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.1, help=\'The Learning Rate.\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', type=float, default=0.0005, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[150, 225], help=\'Decrease learning rate at these epochs.\')\nparser.add_argument(\'--gammas\', type=float, nargs=\'+\', default=[0.1, 0.1], help=\'LR is multiplied by gamma on schedule, number of gammas should be equal to schedule\')\n# Checkpoints\nparser.add_argument(\'--print_freq\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 200)\')\nparser.add_argument(\'--save_path\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start_epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\n# Acceleration\nparser.add_argument(\'--ngpu\', type=int, default=1, help=\'0 = CPU.\')\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers (default: 2)\')\n# random seed\nparser.add_argument(\'--manualSeed\', type=int, help=\'manual seed\')\n#compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--layer_begin\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1,  help=\'compress layer of model\')\nparser.add_argument(\'--use_state_dict\', dest=\'use_state_dict\', action=\'store_true\', help=\'use state dcit or not\')\n\n\nargs = parser.parse_args()\nargs.use_cuda = args.ngpu>0 and torch.cuda.is_available()\n\nif args.manualSeed is None:\n    args.manualSeed = random.randint(1, 10000)\nrandom.seed(args.manualSeed)\ntorch.manual_seed(args.manualSeed)\nif args.use_cuda:\n    torch.cuda.manual_seed_all(args.manualSeed)\ncudnn.benchmark = True\n\ndef main():\n    # Init logger\n    if not os.path.isdir(args.save_path):\n        os.makedirs(args.save_path)\n    log = open(os.path.join(args.save_path, \'log_seed_{}.txt\'.format(args.manualSeed)), \'w\')\n    print_log(\'save path : {}\'.format(args.save_path), log)\n    state = {k: v for k, v in args._get_kwargs()}\n    print_log(state, log)\n    print_log(""Random Seed: {}"".format(args.manualSeed), log)\n    print_log(""python version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""torch  version : {}"".format(torch.__version__), log)\n    print_log(""cudnn  version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    # Init dataset\n    if not os.path.isdir(args.data_path):\n        os.makedirs(args.data_path)\n\n    if args.dataset == \'cifar10\':\n        mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n        std = [x / 255 for x in [63.0, 62.1, 66.7]]\n    elif args.dataset == \'cifar100\':\n        mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n        std = [x / 255 for x in [68.2, 65.4, 70.4]]\n    else:\n        assert False, ""Unknow dataset : {}"".format(args.dataset)\n\n    train_transform = transforms.Compose(\n        [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n         transforms.Normalize(mean, std)])\n    test_transform = transforms.Compose(\n        [transforms.ToTensor(), transforms.Normalize(mean, std)])\n\n    if args.dataset == \'cifar10\':\n        train_data = dset.CIFAR10(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR10(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'cifar100\':\n        train_data = dset.CIFAR100(args.data_path, train=True, transform=train_transform, download=True)\n        test_data = dset.CIFAR100(args.data_path, train=False, transform=test_transform, download=True)\n        num_classes = 100\n    elif args.dataset == \'svhn\':\n        train_data = dset.SVHN(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.SVHN(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'stl10\':\n        train_data = dset.STL10(args.data_path, split=\'train\', transform=train_transform, download=True)\n        test_data = dset.STL10(args.data_path, split=\'test\', transform=test_transform, download=True)\n        num_classes = 10\n    elif args.dataset == \'imagenet\':\n        assert False, \'Do not finish imagenet code\'\n    else:\n        assert False, \'Do not support dataset : {}\'.format(args.dataset)\n\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n                                                 num_workers=args.workers, pin_memory=True)\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, shuffle=False,\n                                                num_workers=args.workers, pin_memory=True)\n\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    # Init model, criterion, and optimizer\n    net = models.__dict__[args.arch](num_classes)\n    print_log(""=> network :\\n {}"".format(net), log)\n\n    net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n\n\n\n    # define loss function (criterion) and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n\n    optimizer = torch.optim.SGD(net.parameters(), state[\'learning_rate\'], momentum=state[\'momentum\'],\n                                weight_decay=state[\'decay\'], nesterov=True)\n\n    if args.use_cuda:\n        net.cuda()\n        criterion.cuda()\n\n    recorder = RecorderMeter(args.epochs)\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            recorder = checkpoint[\'recorder\']\n            args.start_epoch = checkpoint[\'epoch\']\n            if args.use_state_dict:\n                net.load_state_dict(checkpoint[\'state_dict\'])\n            else:\n                net = checkpoint[\'state_dict\']\n                \n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"" .format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n    else:\n        print_log(""=> do not use any checkpoint for {} model"".format(args.arch), log)\n\n    if args.evaluate:\n        time1 = time.time()\n        validate(test_loader, net, criterion, log)\n        time2 = time.time()\n        print (\'function took %0.3f ms\' % ((time2-time1)*1000.0))\n        return\n\n    m=Mask(net)\n    \n    m.init_length()\n    \n    comp_rate =  args.rate\n    print(""-""*10+""one epoch begin""+""-""*10)\n    print(""the compression rate now is %f"" % comp_rate)\n\n    val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n\n    print("" accu before is: %.3f %%"" % val_acc_1)\n    \n    m.model = net\n    \n    m.init_mask(comp_rate)\n#    m.if_zero()\n    m.do_mask()\n    net = m.model\n#    m.if_zero()\n    if args.use_cuda:\n        net = net.cuda()    \n    val_acc_2,   val_los_2   = validate(test_loader, net, criterion, log)\n    print("" accu after is: %s %%"" % val_acc_2)\n    \n\n    # Main loop\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        current_learning_rate = adjust_learning_rate(optimizer, epoch, args.gammas, args.schedule)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.avg * (args.epochs-epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n\n        print_log(\'\\n==>>{:s} [Epoch={:03d}/{:03d}] {:s} [learning_rate={:6.4f}]\'.format(time_string(), epoch, args.epochs, need_time, current_learning_rate) \\\n                                + \' [Best : Accuracy={:.2f}, Error={:.2f}]\'.format(recorder.max_accuracy(False), 100-recorder.max_accuracy(False)), log)\n\n        # train for one epoch\n        train_acc, train_los = train(train_loader, net, criterion, optimizer, epoch, log)\n\n        # evaluate on validation set\n        val_acc_1,   val_los_1   = validate(test_loader, net, criterion, log)\n        if (epoch % args.epoch_prune ==0 or epoch == args.epochs-1):\n            m.model = net\n            m.if_zero()\n            m.init_mask(comp_rate)\n            m.do_mask()\n            m.if_zero()\n            net = m.model \n            if args.use_cuda:\n                net = net.cuda()  \n            \n        val_acc_2,   val_los_2   = validate(test_loader, net, criterion, log)\n    \n        \n        is_best = recorder.update(epoch, train_los, train_acc, val_los_2, val_acc_2)\n\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': net,\n            \'recorder\': recorder,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best, args.save_path, \'checkpoint.pth.tar\')\n\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n        #recorder.plot_curve( os.path.join(args.save_path, \'curve.png\') )\n\n    log.close()\n\n# train function (forward, backward, update)\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'  Epoch: [{:03d}][{:03d}/{:03d}]   \'\n                        \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})   \'\n                        \'Data {data_time.val:.3f} ({data_time.avg:.3f})   \'\n                        \'Loss {loss.val:.4f} ({loss.avg:.4f})   \'\n                        \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})   \'\n                        \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})   \'.format(\n                        epoch, i, len(train_loader), batch_time=batch_time,\n                        data_time=data_time, loss=losses, top1=top1, top5=top5) + time_string(), log)\n    print_log(\'  **Train** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n    return top1.avg, losses.avg\n\ndef validate(val_loader, model, criterion, log):\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    for i, (input, target) in enumerate(val_loader):\n        if args.use_cuda:\n            target = target.cuda(async=True)\n            input = input.cuda()\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n    print_log(\'  **Test** Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5, error1=100-top1.avg), log)\n\n    return top1.avg, losses.avg\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\ndef save_checkpoint(state, is_best, save_path, filename):\n    filename = os.path.join(save_path, filename)\n    torch.save(state, filename)\n    if is_best:\n        bestname = os.path.join(save_path, \'model_best.pth.tar\')\n        shutil.copyfile(filename, bestname)\n\ndef adjust_learning_rate(optimizer, epoch, gammas, schedule):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.learning_rate\n    assert len(gammas) == len(schedule), ""length of gammas and schedule should be equal""\n    for (gamma, step) in zip(gammas, schedule):\n        if (epoch >= step):\n            lr = lr * gamma\n        else:\n            break\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass Mask:\n    def __init__(self,model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n        \n    \n    def get_codebook(self, weight_torch,compress_rate,length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n    \n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n        \n        threshold = weight_sort[int (length * (1-compress_rate) )]\n        weight_np [weight_np <= -threshold  ] = 1\n        weight_np [weight_np >= threshold  ] = 1\n        weight_np [weight_np !=1  ] = 0\n        \n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch,compress_rate,length):\n        codebook = np.ones(length)\n        if len( weight_torch.size())==4:\n            filter_pruned_num = int(weight_torch.size()[0]*(1-compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0],-1)\n            norm2 = torch.norm(weight_vec,2,1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n#            norm1_sort = np.sort(norm1_np)\n#            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n            kernel_length = weight_torch.size()[1] *weight_torch.size()[2] *weight_torch.size()[3]\n            for x in range(0,len(filter_index)):\n                codebook [filter_index[x] *kernel_length : (filter_index[x]+1) *kernel_length] = 0\n\n            print(""filter codebook done"")\n        else:\n            pass\n        return codebook\n    \n    def convert2tensor(self,x):\n        x = torch.FloatTensor(x)\n        return x\n    \n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size [index] = item.size()\n        \n        for index1 in self.model_size:\n            for index2 in range(0,len(self.model_size[index1])):\n                if index2 ==0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n                    \n    def init_rate(self, layer_rate):\n        for index, item in enumerate(self.model.parameters()):\n            self.compress_rate [index] = 1\n        for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n            self.compress_rate[key]= layer_rate\n        #different setting for  different architecture\n        if args.arch == \'resnet20\':\n            last_index = 57\n        elif args.arch == \'resnet32\':\n            last_index = 93\n        elif args.arch == \'resnet56\':\n            last_index = 165\n        elif args.arch == \'resnet110\':\n            last_index = 327\n        self.mask_index =  [x for x in range (0,last_index,3)]\n#        self.mask_index =  [x for x in range (0,330,3)]\n        \n    def init_mask(self,layer_rate):\n        self.init_rate(layer_rate)\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],self.model_length[index] )\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.use_cuda:\n                    self.mat[index] = self.mat[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if(index in self.mask_index):\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n#            if(index in self.mask_index):\n            if(index ==0):\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n                \n                print(""number of nonzero weight is %d, zero is %d"" %( np.count_nonzero(b),len(b)- np.count_nonzero(b)))\n        \nif __name__ == \'__main__\':\n    main()\n'"
pruning_train.py,29,"b'# https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py\nimport argparse\nimport os, sys\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models\nfrom utils import convert_secs2time, time_string, time_file_str\n# from models import print_log\nimport models\nimport random\nimport numpy as np\nfrom collections import OrderedDict\n\nmodel_names = sorted(name for name in models.__dict__\n                     if name.islower() and not name.startswith(""__"")\n                     and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--save_dir\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                         \' | \'.join(model_names) +\n                         \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=100, type=int, metavar=\'N\', help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int, metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float, metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\', help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float, metavar=\'W\',\n                    help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=200, type=int, metavar=\'N\', help=\'print frequency (default: 100)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'evaluate model on validation set\')\nparser.add_argument(\'--use_pretrain\', dest=\'use_pretrain\', action=\'store_true\', help=\'use pre-trained model or not\')\n# compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--layer_begin\', type=int, default=3, help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=3, help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--skip_downsample\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--use_sparse\', dest=\'use_sparse\', action=\'store_true\', help=\'use sparse model as initial or not\')\nparser.add_argument(\'--sparse\',\n                    default=\'/data/yahe/imagenet/resnet50-rate-0.7/checkpoint.resnet50.2018-01-07-9744.pth.tar\',\n                    type=str, metavar=\'PATH\', help=\'path of sparse model\')\nparser.add_argument(\'--lr_adjust\', type=int, default=30, help=\'number of epochs that change learning rate\')\n\n\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\n\nargs.prefix = time_file_str()\n\n\ndef main():\n    best_prec1 = 0\n\n    if not os.path.isdir(args.save_dir):\n        os.makedirs(args.save_dir)\n    log = open(os.path.join(args.save_dir, \'{}.{}.log\'.format(args.arch, args.prefix)), \'w\')\n\n    # version information\n    print_log(""PyThon  version : {}"".format(sys.version.replace(\'\\n\', \' \')), log)\n    print_log(""PyTorch version : {}"".format(torch.__version__), log)\n    print_log(""cuDNN   version : {}"".format(torch.backends.cudnn.version()), log)\n    print_log(""Vision  version : {}"".format(torchvision.__version__), log)\n    # create model\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](pretrained=True)\n    if args.use_sparse:\n        model = import_sparse(model)\n    print_log(""=> Model : {}"".format(model), log)\n    print_log(""=> parameter : {}"".format(args), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    print_log(""Skip downsample : {}"".format(args.skip_downsample), log)\n    print_log(""Workers         : {}"".format(args.workers), log)\n    print_log(""Learning-Rate   : {}"".format(args.lr), log)\n    print_log(""Use Pre-Trained : {}"".format(args.use_pretrain), log)\n    print_log(""lr adjust : {}"".format(args.lr_adjust), log)\n\n    if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n        model.features = torch.nn.DataParallel(model.features)\n        model.cuda()\n    else:\n        model = torch.nn.DataParallel(model).cuda()\n\n    # define loss function (criterion) and optimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay,\n                                nesterov=True)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"".format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolder(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=args.workers, pin_memory=True, sampler=None)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    if args.evaluate:\n        validate(val_loader, model, criterion, log)\n        return\n\n    filename = os.path.join(args.save_dir, \'checkpoint.{:}.{:}.pth.tar\'.format(args.arch, args.prefix))\n    bestname = os.path.join(args.save_dir, \'best.{:}.{:}.pth.tar\'.format(args.arch, args.prefix))\n\n    m = Mask(model)\n\n    m.init_length()\n    print(""-"" * 10 + ""one epoch begin"" + ""-"" * 10)\n    print(""the compression rate now is {:}"".format(args.rate))\n\n    val_acc_1 = validate(val_loader, model, criterion, log)\n\n    print("">>>>> accu before is: {:}"".format(val_acc_1))\n\n    m.model = model\n\n    m.init_mask(args.rate)\n    # m.if_zero()\n    m.do_mask()\n    model = m.model\n    # m.if_zero()\n    if args.use_cuda:\n        model = model.cuda()\n    val_acc_2 = validate(val_loader, model, criterion, log)\n    print("">>>>> accu after is: {:}"".format(val_acc_2))\n\n    start_time = time.time()\n    epoch_time = AverageMeter()\n    for epoch in range(args.start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        need_hour, need_mins, need_secs = convert_secs2time(epoch_time.val * (args.epochs - epoch))\n        need_time = \'[Need: {:02d}:{:02d}:{:02d}]\'.format(need_hour, need_mins, need_secs)\n        print_log(\n            \' [{:s}] :: {:3d}/{:3d} ----- [{:s}] {:s}\'.format(args.arch, epoch, args.epochs, time_string(), need_time),\n            log)\n\n        # train for one epoch\n        train(train_loader, model, criterion, optimizer, epoch, log)\n        # evaluate on validation set\n        val_acc_1 = validate(val_loader, model, criterion, log)\n        if (epoch % args.epoch_prune == 0 or epoch == args.epochs - 1):\n            #        if (random.randint(1,args.epoch_prune)==1 or epoch == args.epochs-1):\n            m.model = model\n            m.if_zero()\n            m.init_mask(args.rate)\n            m.do_mask()\n            m.if_zero()\n            model = m.model\n            if args.use_cuda:\n                model = model.cuda()\n\n        val_acc_2 = validate(val_loader, model, criterion, log)\n\n        # remember best prec@1 and save checkpoint\n        is_best = val_acc_2 > best_prec1\n        best_prec1 = max(val_acc_2, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'best_prec1\': best_prec1,\n            \'optimizer\': optimizer.state_dict(),\n        }, is_best, filename, bestname)\n        # measure elapsed time\n        epoch_time.update(time.time() - start_time)\n        start_time = time.time()\n    log.close()\n\n\ndef import_sparse(model):\n    checkpoint = torch.load(args.sparse)\n    new_state_dict = OrderedDict()\n    for k, v in checkpoint[\'state_dict\'].items():\n        name = k[7:]  # remove `module.`\n        new_state_dict[name] = v\n    model.load_state_dict(new_state_dict)\n    print(""sparse_model_loaded"")\n    return model\n\n\ndef train(train_loader, model, criterion, optimizer, epoch, log):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Epoch: [{0}][{1}/{2}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                epoch, i, len(train_loader), batch_time=batch_time,\n                data_time=data_time, loss=losses, top1=top1, top5=top5), log)\n\n\ndef validate(val_loader, model, criterion, log):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        target = target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                i, len(val_loader), batch_time=batch_time, loss=losses,\n                top1=top1, top5=top5), log)\n\n    print_log(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5,\n                                                                                           error1=100 - top1.avg), log)\n\n    return top1.avg\n\n\ndef save_checkpoint(state, is_best, filename, bestname):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, bestname)\n\n\ndef print_log(print_string, log):\n    print(""{:}"".format(print_string))\n    log.write(\'{:}\\n\'.format(print_string))\n    log.flush()\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr * (0.1 ** (epoch // args.lr_adjust))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nclass Mask:\n    def __init__(self, model):\n        self.model_size = {}\n        self.model_length = {}\n        self.compress_rate = {}\n        self.mat = {}\n        self.model = model\n        self.mask_index = []\n\n    def get_codebook(self, weight_torch, compress_rate, length):\n        weight_vec = weight_torch.view(length)\n        weight_np = weight_vec.cpu().numpy()\n\n        weight_abs = np.abs(weight_np)\n        weight_sort = np.sort(weight_abs)\n\n        threshold = weight_sort[int(length * (1 - compress_rate))]\n        weight_np[weight_np <= -threshold] = 1\n        weight_np[weight_np >= threshold] = 1\n        weight_np[weight_np != 1] = 0\n\n        print(""codebook done"")\n        return weight_np\n\n    def get_filter_codebook(self, weight_torch, compress_rate, length):\n        codebook = np.ones(length)\n        if len(weight_torch.size()) == 4:\n            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n            # norm1 = torch.norm(weight_vec, 1, 1)\n            # norm1_np = norm1.cpu().numpy()\n            norm2 = torch.norm(weight_vec, 2, 1)\n            norm2_np = norm2.cpu().numpy()\n            filter_index = norm2_np.argsort()[:filter_pruned_num]\n            #            norm1_sort = np.sort(norm1_np)\n            #            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n            for x in range(0, len(filter_index)):\n                codebook[filter_index[x] * kernel_length: (filter_index[x] + 1) * kernel_length] = 0\n\n            print(""filter codebook done"")\n        else:\n            pass\n        return codebook\n\n    def convert2tensor(self, x):\n        x = torch.FloatTensor(x)\n        return x\n\n    def init_length(self):\n        for index, item in enumerate(self.model.parameters()):\n            self.model_size[index] = item.size()\n\n        for index1 in self.model_size:\n            for index2 in range(0, len(self.model_size[index1])):\n                if index2 == 0:\n                    self.model_length[index1] = self.model_size[index1][0]\n                else:\n                    self.model_length[index1] *= self.model_size[index1][index2]\n\n    def init_rate(self, layer_rate):\n        if \'vgg\' in args.arch:\n            cfg_5x = [24, 22, 41, 51, 108, 89, 111, 184, 276, 228, 512, 512, 512]\n            cfg_official = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n            # cfg = [32, 64, 128, 128, 256, 256, 256, 256, 256, 256, 256, 256, 256]\n            cfg_index = 0\n            pre_cfg = True\n            for index, item in enumerate(self.model.named_parameters()):\n                self.compress_rate[index] = 1\n                if len(item[1].size()) == 4:\n                    print(item[1].size())\n                    if not pre_cfg:\n                        self.compress_rate[index] = layer_rate\n                        self.mask_index.append(index)\n                        print(item[0], ""self.mask_index"", self.mask_index)\n                    else:\n                        self.compress_rate[index] =  1 - cfg_5x[cfg_index] / item[1].size()[0]\n                        self.mask_index.append(index)\n                        print(item[0], ""self.mask_index"", self.mask_index, cfg_index, cfg_5x[cfg_index], item[1].size()[0],\n                               )\n                        cfg_index += 1\n        elif ""resnet"" in args.arch:\n            for index, item in enumerate(self.model.parameters()):\n                self.compress_rate[index] = 1\n            for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n                self.compress_rate[key] = layer_rate\n            if args.arch == \'resnet18\':\n                # last index include last fc layer\n                last_index = 60\n                skip_list = [21, 36, 51]\n            elif args.arch == \'resnet34\':\n                last_index = 108\n                skip_list = [27, 54, 93]\n            elif args.arch == \'resnet50\':\n                last_index = 159\n                skip_list = [12, 42, 81, 138]\n            elif args.arch == \'resnet101\':\n                last_index = 312\n                skip_list = [12, 42, 81, 291]\n            elif args.arch == \'resnet152\':\n                last_index = 465\n                skip_list = [12, 42, 117, 444]\n            self.mask_index = [x for x in range(0, last_index, 3)]\n            # skip downsample layer\n            if args.skip_downsample == 1:\n                for x in skip_list:\n                    self.compress_rate[x] = 1\n                    self.mask_index.remove(x)\n                    print(self.mask_index)\n            else:\n                pass\n\n    def init_mask(self, layer_rate):\n        self.init_rate(layer_rate)\n        for index, item in enumerate(self.model.parameters()):\n            if (index in self.mask_index):\n                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],\n                                                           self.model_length[index])\n                self.mat[index] = self.convert2tensor(self.mat[index])\n                if args.use_cuda:\n                    self.mat[index] = self.mat[index].cuda()\n        print(""mask Ready"")\n\n    def do_mask(self):\n        for index, item in enumerate(self.model.parameters()):\n            if (index in self.mask_index):\n                a = item.data.view(self.model_length[index])\n                b = a * self.mat[index]\n                item.data = b.view(self.model_size[index])\n        print(""mask Done"")\n\n    def if_zero(self):\n        for index, item in enumerate(self.model.parameters()):\n            #            if(index in self.mask_index):\n            if index in [x for x in range(args.layer_begin, args.layer_end + 1, args.layer_inter)]:\n                a = item.data.view(self.model_length[index])\n                b = a.cpu().numpy()\n\n                print(""layer: %d, number of nonzero weight is %d, zero is %d"" % (\n                    index, np.count_nonzero(b), len(b) - np.count_nonzero(b)))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
utils.py,0,"b'import os, sys, time\nimport numpy as np\nimport random\n\nclass AverageMeter(object):\n  """"""Computes and stores the average and current value""""""\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.val = 0\n    self.avg = 0\n    self.sum = 0\n    self.count = 0\n\n  def update(self, val, n=1):\n    self.val = val\n    self.sum += val * n\n    self.count += n\n    self.avg = self.sum / self.count\n\n\nclass RecorderMeter(object):\n  """"""Computes and stores the minimum loss value and its epoch index""""""\n  def __init__(self, total_epoch):\n    self.reset(total_epoch)\n\n  def reset(self, total_epoch):\n    assert total_epoch > 0\n    self.total_epoch   = total_epoch\n    self.current_epoch = 0\n    self.epoch_losses  = np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_losses  = self.epoch_losses - 1\n\n    self.epoch_accuracy= np.zeros((self.total_epoch, 2), dtype=np.float32) # [epoch, train/val]\n    self.epoch_accuracy= self.epoch_accuracy\n\n  def update(self, idx, train_loss, train_acc, val_loss, val_acc):\n    assert idx >= 0 and idx < self.total_epoch, \'total_epoch : {} , but update with the {} index\'.format(self.total_epoch, idx)\n    self.epoch_losses  [idx, 0] = train_loss\n    self.epoch_losses  [idx, 1] = val_loss\n    self.epoch_accuracy[idx, 0] = train_acc\n    self.epoch_accuracy[idx, 1] = val_acc\n    self.current_epoch = idx + 1\n    return self.max_accuracy(False) == val_acc\n\n  def max_accuracy(self, istrain):\n    if self.current_epoch <= 0: return 0\n    if istrain: return self.epoch_accuracy[:self.current_epoch, 0].max()\n    else:       return self.epoch_accuracy[:self.current_epoch, 1].max()\n  \n  def plot_curve(self, save_path):\n    title = \'the accuracy/loss curve of train/val\'\n    dpi = 80  \n    width, height = 1200, 800\n    legend_fontsize = 10\n    scale_distance = 48.8\n    figsize = width / float(dpi), height / float(dpi)\n\n    fig = plt.figure(figsize=figsize)\n    x_axis = np.array([i for i in range(self.total_epoch)]) # epochs\n    y_axis = np.zeros(self.total_epoch)\n\n    plt.xlim(0, self.total_epoch)\n    plt.ylim(0, 100)\n    interval_y = 5\n    interval_x = 5\n    plt.xticks(np.arange(0, self.total_epoch + interval_x, interval_x))\n    plt.yticks(np.arange(0, 100 + interval_y, interval_y))\n    plt.grid()\n    plt.title(title, fontsize=20)\n    plt.xlabel(\'the training epoch\', fontsize=16)\n    plt.ylabel(\'accuracy\', fontsize=16)\n  \n    y_axis[:] = self.epoch_accuracy[:, 0]\n    plt.plot(x_axis, y_axis, color=\'g\', linestyle=\'-\', label=\'train-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_accuracy[:, 1]\n    plt.plot(x_axis, y_axis, color=\'y\', linestyle=\'-\', label=\'valid-accuracy\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    \n    y_axis[:] = self.epoch_losses[:, 0]\n    plt.plot(x_axis, y_axis*50, color=\'g\', linestyle=\':\', label=\'train-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    y_axis[:] = self.epoch_losses[:, 1]\n    plt.plot(x_axis, y_axis*50, color=\'y\', linestyle=\':\', label=\'valid-loss-x50\', lw=2)\n    plt.legend(loc=4, fontsize=legend_fontsize)\n\n    if save_path is not None:\n      fig.savefig(save_path, dpi=dpi, bbox_inches=\'tight\')\n      print (\'---- save figure {} into {}\'.format(title, save_path))\n    plt.close(fig)\n    \n\ndef time_string():\n  ISOTIMEFORMAT=\'%Y-%m-%d %X\'\n  string = \'[{}]\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string\n\ndef convert_secs2time(epoch_time):\n  need_hour = int(epoch_time / 3600)\n  need_mins = int((epoch_time - 3600*need_hour) / 60)\n  need_secs = int(epoch_time - 3600*need_hour - 60*need_mins)\n  return need_hour, need_mins, need_secs\n\ndef time_file_str():\n  ISOTIMEFORMAT=\'%Y-%m-%d\'\n  string = \'{}\'.format(time.strftime( ISOTIMEFORMAT, time.gmtime(time.time()) ))\n  return string + \'-{}\'.format(random.randint(1, 10000))\n'"
models/__init__.py,0,"b'""""""The models subpackage contains definitions for the following model\narchitectures:\n-  `ResNeXt` for CIFAR10 CIFAR100\nYou can construct a model with random weights by calling its constructor:\n.. code:: python\n    import models\n    resnet20 = models.ResNet20(num_classes)\n    resnet32 = models.ResNet32(num_classes)\n\n\n.. ResNext: https://arxiv.org/abs/1611.05431\n""""""\n\nfrom .resnet import resnet20, resnet32, resnet44, resnet56, resnet110\nfrom .preresnet import preresnet20, preresnet32, preresnet44, preresnet56, preresnet110\nfrom .caffe_cifar import caffe_cifar\n\nfrom .imagenet_resnet import resnet18, resnet34, resnet50, resnet101, resnet152\nfrom .alexnet import alexnet\nfrom .vgg import vgg11, vgg13, vgg16, vgg19, vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn \n\nfrom .imagenet_resnet_small import resnet18_small, resnet34_small, resnet50_small, resnet101_small, resnet152_small\n'"
models/alexnet.py,3,"b'import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\n\n\n__all__ = [\'AlexNet\', \'alexnet\']\n\n\nmodel_urls = {\n    \'alexnet\': \'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\',\n}\n\n\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=1000):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), 256 * 6 * 6)\n        x = self.classifier(x)\n        return x\n\n\ndef alexnet(pretrained=False, **kwargs):\n    r""""""AlexNet model architecture from the\n    `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = AlexNet(**kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'alexnet\']))\n    return model\n'"
models/caffe_cifar.py,4,"b""from __future__ import division\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport math\n\n## http://torch.ch/blog/2015/07/30/cifar.html\nclass CifarCaffeNet(nn.Module):\n  def __init__(self, num_classes):\n    super(CifarCaffeNet, self).__init__()\n\n    self.num_classes = num_classes\n\n    self.block_1 = nn.Sequential(\n      nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n      nn.MaxPool2d(kernel_size=3, stride=2),\n      nn.ReLU(),\n      nn.BatchNorm2d(32))\n\n    self.block_2 = nn.Sequential(\n      nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n      nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n      nn.ReLU(),\n      nn.AvgPool2d(kernel_size=3, stride=2),\n      nn.BatchNorm2d(64))\n\n    self.block_3 = nn.Sequential(\n      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n      nn.Conv2d(64,128, kernel_size=3, stride=1, padding=1),\n      nn.ReLU(),\n      nn.AvgPool2d(kernel_size=3, stride=2),\n      nn.BatchNorm2d(128))\n\n    self.classifier = nn.Linear(128*9, self.num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def forward(self, x):\n    x = self.block_1.forward(x)\n    x = self.block_2.forward(x)\n    x = self.block_3.forward(x)\n    x = x.view(x.size(0), -1)\n    #print ('{}'.format(x.size()))\n    return self.classifier(x)\n\ndef caffe_cifar(num_classes=10):\n  model = CifarCaffeNet(num_classes)\n  return model\n"""
models/imagenet_resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\']\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n    return model\n\n\ndef resnet34(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model\n\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef resnet101(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n    return model\n\n\ndef resnet152(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n    return model\n\n\n#def resnet18(num_classes=1000):\n#    """"""Constructs a ResNet-18 model.\n#\n#    Args:\n#        pretrained (bool): If True, returns a model pre-trained on ImageNet\n#    """"""\n#    model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n#    return model\n#\n#\n#def resnet34(num_classes=1000):\n#    """"""Constructs a ResNet-34 model.\n#\n#    Args:\n#        pretrained (bool): If True, returns a model pre-trained on ImageNet\n#    """"""\n#    model = ResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n#    return model\n#\n#\n#def resnet50(num_classes=1000):\n#    """"""Constructs a ResNet-50 model.\n#\n#    Args:\n#        pretrained (bool): If True, returns a model pre-trained on ImageNet\n#    """"""\n#    model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes)\n#    return model\n#\n#\n#def resnet101(num_classes=1000):\n#    """"""Constructs a ResNet-101 model.\n#\n#    Args:\n#        pretrained (bool): If True, returns a model pre-trained on ImageNet\n#    """"""\n#    model = ResNet(Bottleneck, [3, 4, 23, 3], num_classes)\n#    return model\n#\n#\n#def resnet152(num_classes=1000):\n#    """"""Constructs a ResNet-152 model.\n#\n#    Args:\n#        pretrained (bool): If True, returns a model pre-trained on ImageNet\n#    """"""\n#    model = ResNet(Bottleneck, [3, 8, 36, 3], num_classes)\n#    return model\n'"
models/imagenet_resnet_small.py,12,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom torch.autograd import Variable\nimport torch\nimport time\n\n__all__ = [\'ResNet_small\', \'resnet18_small\', \'resnet34_small\', \'resnet50_small\', \'resnet101_small\', \'resnet152_small\']\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes_after_prune, planes_expand, planes_before_prune, index, bn_value, stride=1,\n                 downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes_after_prune, stride)\n        self.bn1 = nn.BatchNorm2d(planes_after_prune)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes_after_prune, planes_after_prune)\n        self.bn2 = nn.BatchNorm2d(planes_after_prune)\n        self.downsample = downsample\n        self.stride = stride\n\n        # for residual index match\n        self.index = Variable(index)\n        # for bn add\n        self.bn_value = bn_value\n\n        # self.out = torch.autograd.Variable(\n        #     torch.rand(batch, self.planes_before_prune, 64 * 56 // self.planes_before_prune,\n        #                64 * 56 // self.planes_before_prune), volatile=True).cuda()\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        # setting: without index match\n        # out += residual\n        # out = self.relu(out)\n\n        # setting: with index match\n        residual += self.bn_value.cuda()\n        residual.index_add_(1, self.index.cuda(), out)\n\n        residual = self.relu(residual)\n\n        return residual\n\n\nclass Bottleneck(nn.Module):\n    # expansion is not accurately equals to 4\n    expansion = 4\n\n    def __init__(self, inplanes, planes_after_prune, planes_expand, planes_before_prune, index, bn_value, stride=1,\n                 downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes_after_prune, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes_after_prune)\n        self.conv2 = nn.Conv2d(planes_after_prune, planes_after_prune, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes_after_prune)\n\n        # setting: for accuracy expansion\n        self.conv3 = nn.Conv2d(planes_after_prune, planes_expand, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes_expand)\n\n        # setting: original resnet, expansion = 4\n        # self.conv3 = nn.Conv2d(planes, planes_before_prune * 4, kernel_size=1, bias=False)\n        # self.bn3 = nn.BatchNorm2d(planes_before_prune * 4)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n        # for residual index match\n        self.index = Variable(index)\n        # for bn add\n        self.bn_value = bn_value\n\n        # self.extend = torch.autograd.Variable(\n        #     torch.rand(self.planes_before_prune * 4, 64 * 56 // self.planes_before_prune,\n        #                64 * 56 // self.planes_before_prune), volatile=True).cuda()\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        # setting: without index match\n        # print(""residual size{},out size{} "".format(residual.size(),   out.size()))\n        # out += residual\n        # out = self.relu(out)\n\n        # setting: with index match\n        residual += self.bn_value.cuda()\n        residual.index_add_(1, self.index.cuda(), out)\n\n        residual = self.relu(residual)\n\n        return residual\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\nclass ResNet_small(nn.Module):\n\n    def __init__(self, block, layers, index, bn_value,\n                 num_for_construct=[64, 64, 64 * 4, 128, 128 * 4, 256, 256 * 4, 512, 512 * 4],\n                 num_classes=1000):\n        super(ResNet_small, self).__init__()\n        self.inplanes = num_for_construct[0]\n\n        self.conv1 = nn.Conv2d(3, num_for_construct[0], kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(num_for_construct[0])\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        # setting: expansion = 4\n        # self.layer1 = self._make_layer(block, num_for_construct[1], num_for_construct[1] * 4, 64, index,  layers[0])\n        # self.layer2 = self._make_layer(block, num_for_construct[2], num_for_construct[2] * 4, 128, index,  layers[1], stride=2)\n        # self.layer3 = self._make_layer(block, num_for_construct[3], num_for_construct[3] * 4, 256, index,  layers[2], stride=2)\n        # self.layer4 = self._make_layer(block, num_for_construct[4], num_for_construct[4] * 4, 512, index,  layers[3], stride=2)\n\n        # setting: expansion may not accuracy equal to 4\n        self.index_layer1 = {key: index[key] for key in index.keys() if \'layer1\' in key}\n        self.index_layer2 = {key: index[key] for key in index.keys() if \'layer2\' in key}\n        self.index_layer3 = {key: index[key] for key in index.keys() if \'layer3\' in key}\n        self.index_layer4 = {key: index[key] for key in index.keys() if \'layer4\' in key}\n        self.bn_layer1 = {key: bn_value[key] for key in bn_value.keys() if \'layer1\' in key}\n        self.bn_layer2 = {key: bn_value[key] for key in bn_value.keys() if \'layer2\' in key}\n        self.bn_layer3 = {key: bn_value[key] for key in bn_value.keys() if \'layer3\' in key}\n        self.bn_layer4 = {key: bn_value[key] for key in bn_value.keys() if \'layer4\' in key}\n        # print(""bn_layer1"", bn_layer1.keys(), bn_layer2.keys(), bn_layer3.keys(), bn_layer4.keys())\n\n        self.layer1 = self._make_layer(block, num_for_construct[1], num_for_construct[2], 64, self.index_layer1, self.bn_layer1,\n                                       layers[0])\n        self.layer2 = self._make_layer(block, num_for_construct[3], num_for_construct[4], 128, self.index_layer2, self.bn_layer2,\n                                       layers[1], stride=2)\n        self.layer3 = self._make_layer(block, num_for_construct[5], num_for_construct[6], 256, self.index_layer3, self.bn_layer3,\n                                       layers[2], stride=2)\n        self.layer4 = self._make_layer(block, num_for_construct[7], num_for_construct[8], 512, self.index_layer4, self.bn_layer4,\n                                       layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes_after_prune, planes_expand, planes_before_prune, index, bn_layer, blocks,\n                    stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes_before_prune * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes_before_prune * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes_before_prune * block.expansion),\n            )\n        print(""before pruning is {}, after pruning is {}:"".format(planes_before_prune,planes_after_prune))\n\n        # setting: accu number for_construct expansion\n        index_block_0_dict = {key: index[key] for key in index.keys() if \'0.conv3\' in key}\n        index_block_0_value = list(index_block_0_dict.values())[0]\n\n        bn_layer_0_value = list(bn_layer.values())[0]\n\n        layers = []\n        layers.append(\n            block(self.inplanes, planes_after_prune, planes_expand, planes_before_prune, index_block_0_value,\n                  bn_layer_0_value,\n                  stride, downsample))\n        #        self.inplanes = planes * block.expansion\n        self.inplanes = planes_before_prune * block.expansion\n\n        for i in range(1, blocks):\n            index_block_i_dict = {key: index[key] for key in index.keys() if (str(i) + \'.conv3\') in key}\n            index_block_i_value = list(index_block_i_dict.values())[0]\n\n            bn_layer_i = {key: bn_layer[key] for key in bn_layer.keys() if (str(i) + \'.bn3\') in key}\n            bn_layer_i_value = list(bn_layer_i.values())[0]\n            layers.append(\n                block(self.inplanes, planes_after_prune, planes_expand, planes_before_prune, index_block_i_value,\n                      bn_layer_i_value,\n                      ))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet18_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n    return model\n\n\ndef resnet34_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model\n\n\ndef resnet50_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef resnet101_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n    return model\n\n\ndef resnet152_small(pretrained=False, **kwargs):\n    """"""Constructs a ResNet_small-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet_small(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n    return model\n'"
models/preresnet.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom .res_utils import DownsampleA, DownsampleC\nimport math\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  def __init__(self, inplanes, planes, stride, downsample, Type):\n    super(ResNetBasicblock, self).__init__()\n\n    self.Type = Type\n\n    self.bn_a = nn.BatchNorm2d(inplanes)\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n    self.bn_b = nn.BatchNorm2d(planes)\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n    self.relu = nn.ReLU(inplace=True)\n    self.downsample = downsample\n\n  def forward(self, x):\n    residual = x\n\n    basicblock = self.bn_a(x)\n    basicblock = self.relu(basicblock)\n\n    if self.Type == \'both_preact\':\n      residual = basicblock\n    elif self.Type != \'normal\':\n      assert False, \'Unknow type : {}\'.format(self.Type)\n\n    basicblock = self.conv_a(basicblock)\n\n    basicblock = self.bn_b(basicblock)\n    basicblock = self.relu(basicblock)\n    basicblock = self.conv_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(residual)\n    \n    return residual + basicblock\n\nclass CifarPreResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, block, depth, num_classes):\n    """""" Constructor\n    Args:\n      depth: number of layers.\n      num_classes: number of classes\n      base_width: base width\n    """"""\n    super(CifarPreResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 2) // 6\n    print (\'CifarPreResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n\n    self.num_classes = num_classes\n\n    self.conv_3x3 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n\n    self.inplanes = 16\n    self.stage_1 = self._make_layer(block, 16, layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, 32, layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, 64, layer_blocks, 2)\n    self.lastact = nn.Sequential(nn.BatchNorm2d(64*block.expansion), nn.ReLU(inplace=True))\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        #m.bias.data.zero_()\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, planes, blocks, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n      downsample = DownsampleA(self.inplanes, planes * block.expansion, stride)\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample, \'both_preact\'))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes, 1, None, \'normal\'))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_3x3(x)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.lastact(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return self.classifier(x)\n\ndef preresnet20(num_classes=10):\n  """"""Constructs a ResNet-20 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 20, num_classes)\n  return model\n\ndef preresnet32(num_classes=10):\n  """"""Constructs a ResNet-32 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 32, num_classes)\n  return model\n\ndef preresnet44(num_classes=10):\n  """"""Constructs a ResNet-44 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 44, num_classes)\n  return model\n\ndef preresnet56(num_classes=10):\n  """"""Constructs a ResNet-56 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 56, num_classes)\n  return model\n\ndef preresnet110(num_classes=10):\n  """"""Constructs a ResNet-110 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarPreResNet(ResNetBasicblock, 110, num_classes)\n  return model\n'"
models/res_utils.py,2,"b'import torch\nimport torch.nn as nn\n\nclass DownsampleA(nn.Module):  \n\n  def __init__(self, nIn, nOut, stride):\n    super(DownsampleA, self).__init__() \n    assert stride == 2    \n    self.avg = nn.AvgPool2d(kernel_size=1, stride=stride)   \n\n  def forward(self, x):   \n    x = self.avg(x)  \n    return torch.cat((x, x.mul(0)), 1)  \n\nclass DownsampleC(nn.Module):     \n\n  def __init__(self, nIn, nOut, stride):\n    super(DownsampleC, self).__init__()\n    assert stride != 1 or nIn != nOut\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=1, stride=stride, padding=0, bias=False)\n\n  def forward(self, x):\n    x = self.conv(x)\n    return x\n\nclass DownsampleD(nn.Module):\n\n  def __init__(self, nIn, nOut, stride):\n    super(DownsampleD, self).__init__()\n    assert stride == 2\n    self.conv = nn.Conv2d(nIn, nOut, kernel_size=2, stride=stride, padding=0, bias=False)\n    self.bn   = nn.BatchNorm2d(nOut)\n\n  def forward(self, x):\n    x = self.conv(x)\n    x = self.bn(x)\n    return x\n'"
models/resnet.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom .res_utils import DownsampleA, DownsampleC, DownsampleD\nimport math\n\n\nclass ResNetBasicblock(nn.Module):\n  expansion = 1\n  """"""\n  RexNet basicblock (https://github.com/facebook/fb.resnet.torch/blob/master/models/resnet.lua)\n  """"""\n  def __init__(self, inplanes, planes, stride=1, downsample=None):\n    super(ResNetBasicblock, self).__init__()\n\n    self.conv_a = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n    self.bn_a = nn.BatchNorm2d(planes)\n\n    self.conv_b = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_b = nn.BatchNorm2d(planes)\n\n    self.downsample = downsample\n\n  def forward(self, x):\n    residual = x\n\n    basicblock = self.conv_a(x)\n    basicblock = self.bn_a(basicblock)\n    basicblock = F.relu(basicblock, inplace=True)\n\n    basicblock = self.conv_b(basicblock)\n    basicblock = self.bn_b(basicblock)\n\n    if self.downsample is not None:\n      residual = self.downsample(x)\n    \n    return F.relu(residual + basicblock, inplace=True)\n\nclass CifarResNet(nn.Module):\n  """"""\n  ResNet optimized for the Cifar dataset, as specified in\n  https://arxiv.org/abs/1512.03385.pdf\n  """"""\n  def __init__(self, block, depth, num_classes):\n    """""" Constructor\n    Args:\n      depth: number of layers.\n      num_classes: number of classes\n      base_width: base width\n    """"""\n    super(CifarResNet, self).__init__()\n\n    #Model type specifies number of layers for CIFAR-10 and CIFAR-100 model\n    assert (depth - 2) % 6 == 0, \'depth should be one of 20, 32, 44, 56, 110\'\n    layer_blocks = (depth - 2) // 6\n    print (\'CifarResNet : Depth : {} , Layers for each block : {}\'.format(depth, layer_blocks))\n\n    self.num_classes = num_classes\n\n    self.conv_1_3x3 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n    self.bn_1 = nn.BatchNorm2d(16)\n\n    self.inplanes = 16\n    self.stage_1 = self._make_layer(block, 16, layer_blocks, 1)\n    self.stage_2 = self._make_layer(block, 32, layer_blocks, 2)\n    self.stage_3 = self._make_layer(block, 64, layer_blocks, 2)\n    self.avgpool = nn.AvgPool2d(8)\n    self.classifier = nn.Linear(64*block.expansion, num_classes)\n\n    for m in self.modules():\n      if isinstance(m, nn.Conv2d):\n        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n        m.weight.data.normal_(0, math.sqrt(2. / n))\n        #m.bias.data.zero_()\n      elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n      elif isinstance(m, nn.Linear):\n        init.kaiming_normal(m.weight)\n        m.bias.data.zero_()\n\n  def _make_layer(self, block, planes, blocks, stride=1):\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n      downsample = DownsampleA(self.inplanes, planes * block.expansion, stride)\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n      layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n  def forward(self, x):\n    x = self.conv_1_3x3(x)\n    x = F.relu(self.bn_1(x), inplace=True)\n    x = self.stage_1(x)\n    x = self.stage_2(x)\n    x = self.stage_3(x)\n    x = self.avgpool(x)\n    x = x.view(x.size(0), -1)\n    return self.classifier(x)\n\ndef resnet20(num_classes=10):\n  """"""Constructs a ResNet-20 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 20, num_classes)\n  return model\n\ndef resnet32(num_classes=10):\n  """"""Constructs a ResNet-32 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 32, num_classes)\n  return model\n\ndef resnet44(num_classes=10):\n  """"""Constructs a ResNet-44 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 44, num_classes)\n  return model\n\ndef resnet56(num_classes=10):\n  """"""Constructs a ResNet-56 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 56, num_classes)\n  return model\n\ndef resnet110(num_classes=10):\n  """"""Constructs a ResNet-110 model for CIFAR-10 (by default)\n  Args:\n    num_classes (uint): number of classes\n  """"""\n  model = CifarResNet(ResNetBasicblock, 110, num_classes)\n  return model\n'"
models/vgg.py,10,"b'import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport math\n\n\n__all__ = [\n    \'VGG\', \'vgg11\', \'vgg11_bn\', \'vgg13\', \'vgg13_bn\', \'vgg16\', \'vgg16_bn\',\n    \'vgg19_bn\', \'vgg19\',\n]\n\n\nmodel_urls = {\n    \'vgg11\': \'https://download.pytorch.org/models/vgg11-bbd30ac9.pth\',\n    \'vgg13\': \'https://download.pytorch.org/models/vgg13-c768596a.pth\',\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n    \'vgg19\': \'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\',\n    \'vgg11_bn\': \'https://download.pytorch.org/models/vgg11_bn-6002323d.pth\',\n    \'vgg13_bn\': \'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth\',\n    \'vgg16_bn\': \'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\',\n    \'vgg19_bn\': \'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\',\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes),\n        )\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\n\ndef make_layers(cfg, batch_norm=False):\n    layers = []\n    in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfg = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'B\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'D\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512, \'M\'],\n    \'E\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512, \'M\'],\n}\n\n\ndef vgg11(pretrained=False, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg11\']))\n    return model\n\n\ndef vgg11_bn(pretrained=False, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\'], batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg11_bn\']))\n    return model\n\n\ndef vgg13(pretrained=False, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg13\']))\n    return model\n\n\ndef vgg13_bn(pretrained=False, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\'], batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg13_bn\']))\n    return model\n\n\ndef vgg16(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model\n\n\ndef vgg16_bn(pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\'], batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16_bn\']))\n    return model\n\n\ndef vgg19(pretrained=False, **kwargs):\n    """"""VGG 19-layer model (configuration ""E"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\']), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg19\']))\n    return model\n\n\ndef vgg19_bn(pretrained=False, **kwargs):\n    """"""VGG 19-layer model (configuration \'E\') with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\'], batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg19_bn\']))\n    return model\n'"
utils/cifar_resnet_flop.py,0,"b'def cifar_resnet_flop(layer=110, prune_rate=1):\n    \'\'\'\n    :param layer: the layer of Resnet for Cifar, including 110, 56, 32, 20\n    :param prune_rate: 1 means baseline\n    :return: flop of the network\n    \'\'\'\n    flop = 0\n    channel = [16, 32, 64]\n    width = [32, 16, 8]\n\n    stage = int(layer / 3)\n    for index in range(0, layer, 1):\n        if index == 0:  # first conv layer before block\n            flop += channel[0] * width[0] * width[0] * 9 * 3 * prune_rate\n        elif index in [1, 2]:  # first block of first stage\n            flop += channel[0] * width[0] * width[0] * 9 * channel[0] * (prune_rate ** 2)\n        elif 2 < index <= stage:  # other blocks of first stage\n            if index % 2 != 0:\n                # first layer of block, only output channal reduced, input channel remain the same\n                flop += channel[0] * width[0] * width[0] * 9 * channel[0] * (prune_rate)\n            elif index % 2 == 0:\n                # second layer of block, both input and output channal reduced\n                flop += channel[0] * width[0] * width[0] * 9 * channel[0] * (prune_rate ** 2)\n        elif stage < index <= stage * 2:  # second stage\n            if index % 2 != 0:\n                flop += channel[1] * width[1] * width[1] * 9 * channel[1] * (prune_rate)\n            elif index % 2 == 0:\n                flop += channel[1] * width[1] * width[1] * 9 * channel[1] * (prune_rate ** 2)\n        elif stage * 2 < index <= stage * 3:  # third stage\n            if index % 2 != 0:\n                flop += channel[2] * width[2] * width[2] * 9 * channel[2] * (prune_rate)\n            elif index % 2 == 0:\n                flop += channel[2] * width[2] * width[2] * 9 * channel[2] * (prune_rate ** 2)\n\n    # offset for dimension change between blocks\n    offset1 = channel[1] * width[1] * width[1] * 9 * channel[1] * prune_rate - channel[1] * width[1] * width[1] * 9 * \\\n              channel[0] * prune_rate\n    offset2 = channel[2] * width[2] * width[2] * 9 * channel[2] * prune_rate - channel[2] * width[2] * width[2] * 9 * \\\n              channel[1] * prune_rate\n    flop = flop - offset1 - offset2\n    # print(flop)\n    return flop\n\n\ndef cal_cifar_resnet_flop(layer, prune_rate):\n    \'\'\'\n    :param layer:  the layer of Resnet for Cifar, including 110, 56, 32, 20\n    :param prune_rate: 1 means baseline\n    :return:\n    \'\'\'\n    pruned_flop = cifar_resnet_flop(layer, prune_rate)\n    baseline_flop = cifar_resnet_flop(layer, 1)\n\n    print(\n        ""pruning rate of layer {:d} is {:.1f}, pruned FLOP is {:.0f}, ""\n        ""baseline FLOP is {:.0f}, FLOP reduction rate is {:.4f}""\n        .format(layer, prune_rate, pruned_flop, baseline_flop, 1 - pruned_flop / baseline_flop))\n\n\nif __name__ == \'__main__\':\n    layer_list = [110, 56, 32, 20]\n    pruning_rate_list = [0.9, 0.8, 0.7]\n    for layer in layer_list:\n        for pruning_rate in pruning_rate_list:\n            cal_cifar_resnet_flop(layer, pruning_rate)\n'"
utils/get_small_model.py,29,"b'# https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py\nimport argparse\nimport os,sys\nimport shutil\nimport pdb, time\nfrom collections import OrderedDict\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\nfrom utils import convert_secs2time, time_string, time_file_str\n# from models import print_log\nimport models\nimport random\nimport numpy as np\nimport copy\n\nmodel_names = sorted(name for name in models.__dict__\n                     if name.islower() and not name.startswith(""__"")\n                     and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\', help=\'path to dataset\')\nparser.add_argument(\'--save_dir\', type=str, default=\'./\', help=\'Folder to save checkpoints and log.\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\', choices=model_names,\n                    help=\'model architecture: \' + \' | \'.join(model_names) + \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int, metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.1, type=float, metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--print-freq\', \'-p\', default=5, type=int, metavar=\'N\', help=\'print frequency (default: 100)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\n# compress rate\nparser.add_argument(\'--rate\', type=float, default=0.9, help=\'compress rate of model\')\nparser.add_argument(\'--layer_begin\', type=int, default=3, help=\'compress layer of model\')\nparser.add_argument(\'--layer_end\', type=int, default=3, help=\'compress layer of model\')\nparser.add_argument(\'--layer_inter\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--epoch_prune\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--skip_downsample\', type=int, default=1, help=\'compress layer of model\')\nparser.add_argument(\'--get_small\', dest=\'get_small\', action=\'store_true\', help=\'whether a big or small model\')\n\nargs = parser.parse_args()\nargs.use_cuda = torch.cuda.is_available()\n\nargs.prefix = time_file_str()\n\n\ndef main():\n    best_prec1 = 0\n\n    if not os.path.isdir(args.save_dir):\n        os.makedirs(args.save_dir)\n    log = open(os.path.join(args.save_dir, \'gpu-time.{}.{}.log\'.format(args.arch, args.prefix)), \'w\')\n\n    # create model\n    print_log(""=> creating model \'{}\'"".format(args.arch), log)\n    model = models.__dict__[args.arch](pretrained=False)\n    print_log(""=> Model : {}"".format(model), log)\n    print_log(""=> parameter : {}"".format(args), log)\n    print_log(""Compress Rate: {}"".format(args.rate), log)\n    print_log(""Layer Begin: {}"".format(args.layer_begin), log)\n    print_log(""Layer End: {}"".format(args.layer_end), log)\n    print_log(""Layer Inter: {}"".format(args.layer_inter), log)\n    print_log(""Epoch prune: {}"".format(args.epoch_prune), log)\n    print_log(""Skip downsample : {}"".format(args.skip_downsample), log)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print_log(""=> loading checkpoint \'{}\'"".format(args.resume), log)\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            state_dict = checkpoint[\'state_dict\']\n            state_dict = remove_module_dict(state_dict)\n            model.load_state_dict(state_dict)\n            print_log(""=> loaded checkpoint \'{}\' (epoch {})"".format(args.resume, checkpoint[\'epoch\']), log)\n        else:\n            print_log(""=> no checkpoint found at \'{}\'"".format(args.resume), log)\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolder(valdir, transforms.Compose([\n            # transforms.Scale(256),\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    if args.get_small:\n        big_path = os.path.join(args.save_dir, ""big_model.pt"")\n        torch.save(model, big_path)\n        small_model = get_small_model(model.cpu())\n        # small_model = torch.load(\'small_model.pt\')\n        small_path = os.path.join(args.save_dir, ""small_model.pt"")\n        torch.save(small_model, small_path)\n\n        if args.use_cuda:\n            model = model.cuda()\n            small_model = small_model.cuda()\n        print(\'evaluate: big\')\n        print(\'big model accu\', validate(val_loader, model, criterion, log))\n\n        print(\'evaluate: small\')\n        print(\'small model accu\', validate(val_loader, small_model, criterion, log))\n\n\ndef validate(val_loader, model, criterion, log):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    top5 = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (input, target) in enumerate(val_loader):\n        # target = target.cuda(async=True)\n        if args.use_cuda:\n            input, target = input.cuda(), target.cuda(async=True)\n        input_var = torch.autograd.Variable(input, volatile=True)\n        target_var = torch.autograd.Variable(target, volatile=True)\n\n        # compute output\n        output = model(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n        losses.update(loss.data[0], input.size(0))\n        top1.update(prec1[0], input.size(0))\n        top5.update(prec5[0], input.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print_log(\'Test: [{0}/{1}]\\t\'\n                      \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                      \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'\n                      \'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t\'\n                      \'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\'.format(\n                i, len(val_loader), batch_time=batch_time, loss=losses,\n                top1=top1, top5=top5), log)\n\n    print_log(\' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}\'.format(top1=top1, top5=top5,\n                                                                                           error1=100 - top1.avg), log)\n\n    return top1.avg\n\n\ndef save_checkpoint(state, is_best, filename, bestname):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, bestname)\n\n\ndef print_log(print_string, log):\n    print(""{}"".format(print_string))\n    log.write(\'{}\\n\'.format(print_string))\n    log.flush()\n\n\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\ndef remove_module_dict(state_dict):\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k[7:]  # remove `module.`\n        new_state_dict[name] = v\n    return new_state_dict\n\n\ndef import_sparse(model):\n    checkpoint = torch.load(\'/data/yahe/imagenet/resnet50-rate-0.7/checkpoint.resnet50.2018-01-07-9744.pth.tar\')\n    new_state_dict = OrderedDict()\n    for k, v in checkpoint[\'state_dict\'].items():\n        name = k[7:]  # remove `module.`\n        new_state_dict[name] = v\n    model.load_state_dict(new_state_dict)\n    print(""sparse_model_loaded"")\n    return model\n\n\ndef check_channel(tensor):\n    size_0 = tensor.size()[0]\n    size_1 = tensor.size()[1] * tensor.size()[2] * tensor.size()[3]\n    tensor_resize = tensor.view(size_0, -1)\n    # indicator: if the channel contain all zeros\n    channel_if_zero = np.zeros(size_0)\n    for x in range(0, size_0, 1):\n        channel_if_zero[x] = np.count_nonzero(tensor_resize[x].cpu().numpy()) != 0\n    # indices = (torch.LongTensor(channel_if_zero) != 0 ).nonzero().view(-1)\n\n    indices_nonzero = torch.LongTensor((channel_if_zero != 0).nonzero()[0])\n    # indices_nonzero = torch.LongTensor((channel_if_zero != 0).nonzero()[0])\n\n    zeros = (channel_if_zero == 0).nonzero()[0]\n    indices_zero = torch.LongTensor(zeros) if zeros != [] else []\n\n    return indices_zero, indices_nonzero\n\n\ndef extract_para(big_model):\n    \'\'\'\n    :param model:\n    :param batch_size:\n    :return: num_for_construc: number of remaining filter,\n             [conv1,stage1,stage1_expend,stage2,stage2_expend,stage3,stage3_expend,stage4,stage4_expend]\n\n             kept_filter_per_layer: number of remaining filters for every layer\n             kept_index_per_layer: filter index of remaining channel\n             model: small model\n    \'\'\'\n    item = list(big_model.state_dict().items())\n    print(""length of state dict is"", len(item))\n    try:\n        assert len(item) in [102, 182, 267, 522]\n        print(""state dict length is one of 102, 182, 267, 522"")\n    except AssertionError as e:\n        print(""False state dict"")\n\n    # indices_list = []\n    kept_index_per_layer = {}\n    kept_filter_per_layer = {}\n    pruned_index_per_layer = {}\n\n    for x in range(0, len(item) - 2, 5):\n        indices_zero, indices_nonzero = check_channel(item[x][1])\n        # indices_list.append(indices_nonzero)\n        pruned_index_per_layer[item[x][0]] = indices_zero\n        kept_index_per_layer[item[x][0]] = indices_nonzero\n        kept_filter_per_layer[item[x][0]] = indices_nonzero.shape[0]\n\n    # add \'module.\' if state_dict are store in parallel format\n    # state_dict = [\'module.\' + x for x in state_dict]\n\n    if len(item) == 102 or len(item) == 182:\n        basic_block_flag = [\'conv1.weight\',\n                            \'layer1.0.conv1.weight\', \'layer1.0.conv2.weight\',\n                            \'layer2.0.conv1.weight\', \'layer2.0.conv2.weight\',\n                            \'layer3.0.conv1.weight\', \'layer3.0.conv2.weight\',\n                            \'layer4.0.conv1.weight\', \'layer4.0.conv2.weight\']\n        constrct_flag = basic_block_flag\n        block_flag = ""conv2""\n    elif len(item) == 267 or len(item) == 522:\n        bottle_block_flag = [\'conv1.weight\',\n                             \'layer1.0.conv1.weight\', \'layer1.0.conv3.weight\',\n                             \'layer2.0.conv1.weight\', \'layer2.0.conv3.weight\',\n                             \'layer3.0.conv1.weight\', \'layer3.0.conv3.weight\',\n                             \'layer4.0.conv1.weight\', \'layer4.0.conv3.weight\']\n        constrct_flag = bottle_block_flag\n        block_flag = ""conv3""\n\n    # number of nonzero channel in conv1, and four stages\n    num_for_construct = []\n    for key in constrct_flag:\n        num_for_construct.append(kept_filter_per_layer[key])\n\n    index_for_construct = dict(\n        (key, value) for (key, value) in kept_index_per_layer.items() if block_flag in key)\n    bn_value = get_bn_value(big_model, block_flag, pruned_index_per_layer)\n    if len(item) == 102:\n        small_model = models.resnet18_small(index=kept_index_per_layer, bn_value=bn_value,\n                                            num_for_construct=num_for_construct)\n    if len(item) == 182:\n        small_model = models.resnet34_small(index=kept_index_per_layer, bn_value=bn_value,\n                                            num_for_construct=num_for_construct)\n    if len(item) == 267:\n        small_model = models.resnet50_small(index=kept_index_per_layer, bn_value=bn_value,\n                                            num_for_construct=num_for_construct)\n    if len(item) == 522:\n        small_model = models.resnet101_small(index=kept_index_per_layer, bn_value=bn_value,\n                                             num_for_construct=num_for_construct)\n    return kept_index_per_layer, pruned_index_per_layer, block_flag, small_model\n\n\ndef get_bn_value(big_model, block_flag, pruned_index_per_layer):\n    big_model.eval()\n    bn_flag = ""bn3"" if block_flag == ""conv3"" else ""bn2""\n    key_bn = [x for x in big_model.state_dict().keys() if ""bn3"" in x]\n    layer_flag_list = [[x[0:6], x[7], x[9:12], x] for x in key_bn if ""weight"" in x]\n    # layer_flag_list = [[\'layer1\', ""0"", ""bn3"",\'layer1.0.bn3.weight\']]\n    bn_value = {}\n\n    for layer_flag in layer_flag_list:\n        module_bn = big_model._modules.get(layer_flag[0])._modules.get(layer_flag[1])._modules.get(layer_flag[2])\n        num_feature = module_bn.num_features\n        act_bn = module_bn(Variable(torch.zeros(1, num_feature, 1, 1)))\n\n        index_name = layer_flag[3].replace(""bn"", ""conv"")\n        index = Variable(torch.LongTensor(pruned_index_per_layer[index_name]))\n        act_bn = torch.index_select(act_bn, 1, index)\n\n        select = Variable(torch.zeros(1, num_feature, 1, 1))\n        select.index_add_(1, index, act_bn)\n\n        bn_value[layer_flag[3]] = select\n    return bn_value\n\n\ndef get_small_model(big_model):\n    indice_dict, pruned_index_per_layer, block_flag, small_model = extract_para(big_model)\n    big_state_dict = big_model.state_dict()\n    small_state_dict = {}\n    keys_list = list(big_state_dict.keys())\n    # print(""keys_list"", keys_list)\n    for index, [key, value] in enumerate(big_state_dict.items()):\n        # all the conv layer excluding downsample layer\n        flag_conv_ex_down = not \'bn\' in key and not \'downsample\' in key and not \'fc\' in key\n        # downsample conv layer\n        flag_down = \'downsample.0\' in key\n        # value for \'output\' dimension: all the conv layer including downsample layer\n        if flag_conv_ex_down or flag_down:\n            small_state_dict[key] = torch.index_select(value, 0, indice_dict[key])\n            conv_index = keys_list.index(key)\n            # 4 following bn layer, bn_weight, bn_bias, bn_runningmean, bn_runningvar\n            for offset in range(1, 5, 1):\n                bn_key = keys_list[conv_index + offset]\n                small_state_dict[bn_key] = torch.index_select(big_state_dict[bn_key], 0, indice_dict[key])\n            # value for \'input\' dimension\n            if flag_conv_ex_down:\n                # first layer of first block\n                if \'layer1.0.conv1.weight\' in key:\n                    small_state_dict[key] = torch.index_select(small_state_dict[key], 1, indice_dict[\'conv1.weight\'])\n                # just conv1 of block, the input dimension should not change for shortcut\n                elif not ""conv1"" in key:\n                    conv_index = keys_list.index(key)\n                    # get the last con layer\n                    key_for_input = keys_list[conv_index - 5]\n                    # print(""key_for_input"", key, key_for_input)\n                    small_state_dict[key] = torch.index_select(small_state_dict[key], 1, indice_dict[key_for_input])\n            # only the first downsample layer should change as conv1 reduced\n            elif \'layer1.0.downsample.0.weight\' in key:\n                small_state_dict[key] = torch.index_select(small_state_dict[key], 1, indice_dict[\'conv1.weight\'])\n        elif \'fc\' in key:\n            small_state_dict[key] = value\n\n    if len(set(big_state_dict.keys()) - set(small_state_dict.keys())) != 0:\n        print(""different keys of big and small model"",\n              sorted(set(big_state_dict.keys()) - set(small_state_dict.keys())))\n        for x, y in zip(small_state_dict.keys(), small_model.state_dict().keys()):\n            if small_state_dict[x].size() != small_model.state_dict()[y].size():\n                print(""difference with model and dict"", x, small_state_dict[x].size(),\n                      small_model.state_dict()[y].size())\n\n    small_model.load_state_dict(small_state_dict)\n\n    return small_model\n\n\nif __name__ == \'__main__\':\n    main()\n'"
utils/infer_pruned.py,0,b''
