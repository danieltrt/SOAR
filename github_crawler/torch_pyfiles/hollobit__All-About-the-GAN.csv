file_path,api_count,code
update.py,0,"b'# -*- coding: utf-8 -*-\n"""""" Update Readme.md and cumulative_gans.jpg """"""\nfrom __future__ import print_function\nfrom __future__ import division\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sys\nimport datetime\nimport pandas as pd\nimport csv\nimport json\nimport os\n\ndef load_data():\n    """""" Load GANs data from the AllGAN.csv file """"""\n    import csv\n    import codecs\n\n    with codecs.open(\'AllGAN-r2.tsv\',""rbU"", ""utf-8"") as fid:\n        reader = csv.DictReader(fid, delimiter=\'\\t\')\n        gans = [row for row in reader]\n    return gans\n\n\ndef update_readme(gans):\n    """""" Update the Readme.md text file from a Jinja2 template """"""\n    import jinja2 as j2\n\n    gans.sort(key=lambda v: v[\'Title\'].upper())\n    j2_env = j2.Environment(loader=j2.FileSystemLoader(\'.\'),\n                            trim_blocks=True, lstrip_blocks=True)\n\n    j2_env.globals[\'nowts\'] = datetime.datetime.now()\n\n    with open(\'README-one.md\', \'w\') as fid:\n        print(j2_env.get_template(\'README.j2.md\').render(gans=gans), file=fid)\n\ndef update_index(gans):\n    """""" Update the index.html text file from a Jinja2 template """"""\n    import jinja2 as j2\n\n    try:\n        gans.sort(key=lambda v: ((int(v[\'Year\']) if v[\'Year\'].isdigit() else v[\'Year\'])\n        , (int(v[\'Month\']) if v[\'Month\'].isdigit() else v[\'Month\'])), reverse=True)\n    except:\n        pass\n    j2_env = j2.Environment(loader=j2.FileSystemLoader(\'.\'),\n                            trim_blocks=True, lstrip_blocks=True)\n\n    j2_env.globals[\'nowts\'] = datetime.datetime.now()\n\n    with open(\'docs/index.html\', \'w\') as fid:\n        print(j2_env.get_template(\'INDEX.j2.md\').render(gans=gans), file=fid)\n\n\ndef update_figure(gans):\n    """""" Update the figure cumulative_gans.jpg """"""\n    data = np.array([int(gan[\'Year\']) + int(gan[\'Month\']) / 12\n                     for gan in gans])\n    x_range = int(np.ceil(np.max(data) - np.min(data)) * 12) + 1\n    y_range = int(np.ceil(data.size / 10)) * 10 + 1\n\n    with plt.style.context(""seaborn""):\n        plt.hist(data, x_range, cumulative=""True"")\n        plt.xticks(range(2014, 2018))\n        plt.yticks(np.arange(0, y_range, 15))\n        plt.title(""Cumulative number of named GAN papers by month"")\n        plt.xlabel(""Year"")\n        plt.ylabel(""Total number of papers"")\n        plt.savefig(\'cumulative_gans.jpg\')\n\ndef update_wordcloud_title():\n    """""" Update the figure wordcloud_title.jpg """"""\n\n    data = pd.read_csv(\'AllGAN-r2.tsv\',delimiter=\'\\t\', encoding=\'utf-8\')\n\n#    tmp_data = data[\'Title\'].split("" "") for x in data\n\n#    count_list = list([list(x) for x in data[\'Title\'].value_counts().reset_index().values])\n\n#    wordcloud = WordCloud(stopwords=STOPWORDS,relative_scaling = 0.2,\n#                        max_words=2000, background_color=\'white\').generate_from_frequencies(tmp_data)\n    stopwords = set(STOPWORDS)\n    #ganstop = [\'Generative\',\'Adversarial\', \'Networks\', \'Network\', \'GAN\', \'GANs\', \'using\', \'Learning\', \'Training\', \'Generation\',\n    #        \'Neural\', \'Net\', \'Model\', \'Nets\', \'Deep\', \'Based\', \'Via\', \'Conditional\', \'Models\', \'Examples\']\n    #stopwords.add(ganstop)\n\n    stopwords.add(\'Generative\')\n    stopwords.add(\'Adversarial\')\n    stopwords.add(\'Networks\')\n    stopwords.add(\'Network\')\n    stopwords.add(\'GAN\')\n    stopwords.add(\'GANs\')\n    stopwords.add(\'using\')\n    stopwords.add(\'Learning\')\n    stopwords.add(\'Training\')\n    stopwords.add(\'Generation\')\n    stopwords.add(\'Neural\')\n    stopwords.add(\'Net\')\n    stopwords.add(\'Model\')\n    stopwords.add(\'Nets\')\n    stopwords.add(\'Deep\')\n    stopwords.add(\'Based\')\n    stopwords.add(\'Via\')\n    stopwords.add(\'Conditional\')\n    stopwords.add(\'Models\')\n    stopwords.add(\'Examples\')\n\n    wordcloud = WordCloud(stopwords=stopwords,relative_scaling = 0.2, random_state=3,\n                    max_words=2000, background_color=\'white\').generate(\' \'.join(data[\'Title\']))\n\n    plt.figure(figsize=(12,12))\n    plt.imshow(wordcloud, interpolation=""bilinear"")\n    plt.axis(""off"")\n    #plt.show()\n    #plt.savefig(\'wordcloud_title.png\')\n    wordcloud.to_file(\'wordcloud_title.png\')\n    wordcloud.to_file(\'docs/png/wordcloud_title.png\')\n\ndef update_wordcloud_category():\n    """""" Update the figure wordcloud_category.jpg """"""\n\n    data = pd.read_csv(\'AllGAN-r2.tsv\',delimiter=\'\\t\', encoding=\'utf-8\')\n\n    wordcloud = WordCloud(stopwords=STOPWORDS,relative_scaling = 0.2, random_state=3,\n                max_words=2000, background_color=\'white\').generate(\' \'.join(data[\'Category\']))\n\n    plt.figure(figsize=(12,12))\n    plt.imshow(wordcloud, interpolation=""bilinear"")\n    plt.axis(""off"")\n    #plt.show()\n    #plt.savefig(\'wordcloud_title.png\')\n    wordcloud.to_file(\'wordcloud_category.png\')\n    wordcloud.to_file(\'docs/png/wordcloud_category.png\')\n\ndef update_wordcloud_abbr():\n    """""" Update the figure wordcloud_category.jpg """"""\n\n    data = pd.read_csv(\'AllGAN-r2.tsv\',delimiter=\'\\t\', encoding=\'utf-8\')\n\n    wordcloud = WordCloud(stopwords=STOPWORDS,relative_scaling = 0.2, random_state=3,\n                max_words=2000, background_color=\'white\').generate(\' \'.join(data[\'Abbr.\']))\n\n    plt.figure(figsize=(12,12))\n    plt.imshow(wordcloud, interpolation=""bilinear"")\n    plt.axis(""off"")\n    #plt.show()\n    #plt.savefig(\'wordcloud_title.png\')\n    wordcloud.to_file(\'wordcloud_abbr.png\')\n    wordcloud.to_file(\'docs/png/wordcloud_abbr.png\')\n\ndef update_csv2json():\n\n#    COLUMNS = (\'Mnum\',\'Abbr.\',\'Title\',\'Year\',\'Month\',\'Citations\',\'pdf\',\'Arxiv\',\'Official_Code\',\'Tensorflow\',\'PyTorch\',\'KERAS\',\t\'Stars\',\'Web\',\'No\',\'SN\',\'Medical\',\'Category\')\n    with open(\'AllGan-r2.tsv\', \'r\') as f:\n        reader = csv.DictReader(f, delimiter=\'\\t\')\n        rows = list(reader)\n\n    with open(\'docs/AllGan.json\', \'w\') as f:\n        f.write(json.dumps(rows, sort_keys=False, separators=(\',\', \': \'), ensure_ascii=False, indent=4))\n\nif __name__ == \'__main__\':\n    try:\n        reload(sys)  # Python 2\n        sys.setdefaultencoding(\'utf-8\')\n    except NameError:\n        pass         # Python 3\n\n    GANS = load_data()\n    update_wordcloud_title()\n    update_wordcloud_category()\n    update_wordcloud_abbr()\n    update_readme(GANS)\n    update_index(GANS)\n    update_csv2json()\n#    update_figure(GANS)\n'"
