file_path,api_count,code
cifar/easy_mixup.py,18,"b'\'\'\'Train CIFAR10 with PyTorch.\'\'\'\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\nimport csv\n\nfrom models import *\nfrom utils import progress_bar, mixup_data, mixup_criterion\nfrom torch.autograd import Variable\n\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10 Training\')\nparser.add_argument(\'--resume\', \'-r\', action=\'store_true\', help=\'resume from checkpoint\')\nparser.add_argument(\'--sess\', default=\'mixup_default\', type=str, help=\'session id\')\nparser.add_argument(\'--seed\', default=0, type=int, help=\'rng seed\')\nparser.add_argument(\'--alpha\', default=1., type=float, help=\'interpolation strength (uniform=1., ERM=0.)\')\nparser.add_argument(\'--decay\', default=1e-4, type=float, help=\'weight decay (default=1e-4)\')\nargs = parser.parse_args()\n\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available()\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\nbatch_size = 128\nbase_learning_rate = 0.1\nif use_cuda:\n    # data parallel\n    n_gpu = torch.cuda.device_count()\n    batch_size *= n_gpu\n    base_learning_rate *= n_gpu\n\n# Data\nprint(\'==> Preparing data..\')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(root=\'./data\', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root=\'./data\', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n\nclasses = (\'plane\', \'car\', \'bird\', \'cat\', \'deer\', \'dog\', \'frog\', \'horse\', \'ship\', \'truck\')\n\n# Model\nif args.resume:\n    # Load checkpoint.\n    print(\'==> Resuming from checkpoint..\')\n    assert os.path.isdir(\'checkpoint\'), \'Error: no checkpoint directory found!\'\n    checkpoint = torch.load(\'./checkpoint/ckpt.t7.\' + args.sess + \'_\' + str(args.seed))\n    net = checkpoint[\'net\']\n    best_acc = checkpoint[\'acc\']\n    start_epoch = checkpoint[\'epoch\'] + 1\n    torch.set_rng_state(checkpoint[\'rng_state\'])\nelse:\n    print(\'==> Building model..\')\n    # net = VGG(\'VGG19\')\n    net = PreActResNet18()\n    # net = ResNet18()\n    # net = GoogLeNet()\n    # net = DenseNet121()\n    # net = ResNeXt29_2x64d()\n    # net = MobileNet()\n    # net = DPN92()\n    # net = ShuffleNetG2()\n    # net = SENet18()\n\nresult_folder = \'./results/\'\nif not os.path.exists(result_folder):\n    os.makedirs(result_folder)\n\nlogname = result_folder + net.__class__.__name__ + \'_\' + args.sess + \'_\' + str(args.seed) + \'.csv\'\n\nif use_cuda:\n    net.cuda()\n    net = torch.nn.DataParallel(net)\n    print(\'Using\', torch.cuda.device_count(), \'GPUs.\')\n    cudnn.benchmark = True\n    print(\'Using CUDA..\')\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=base_learning_rate, momentum=0.9, weight_decay=args.decay)\n\n# Training\ndef train(epoch):\n    print(\'\\nEpoch: %d\' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        # generate mixed inputs, two one-hot label vectors and mixing coefficient\n        inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, args.alpha, use_cuda)\n        optimizer.zero_grad()\n        inputs, targets_a, targets_b = Variable(inputs), Variable(targets_a), Variable(targets_b)\n        outputs = net(inputs)\n\n        loss_func = mixup_criterion(targets_a, targets_b, lam)\n        loss = loss_func(criterion, outputs)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += lam * predicted.eq(targets_a.data).cpu().sum() + (1 - lam) * predicted.eq(targets_b.data).cpu().sum()\n\n        progress_bar(batch_idx, len(trainloader), \'Loss: %.3f | Acc: %.3f%% (%d/%d)\'\n            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n    return (train_loss/batch_idx, 100.*correct/total)\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(testloader):\n        if use_cuda:\n            inputs, targets = inputs.cuda(), targets.cuda()\n        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n\n        test_loss += loss.data[0]\n        _, predicted = torch.max(outputs.data, 1)\n        total += targets.size(0)\n        correct += predicted.eq(targets.data).cpu().sum()\n\n        progress_bar(batch_idx, len(testloader), \'Loss: %.3f | Acc: %.3f%% (%d/%d)\'\n            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        best_acc = acc\n        checkpoint(acc, epoch)\n    return (test_loss/batch_idx, 100.*correct/total)\n\ndef checkpoint(acc, epoch):\n    # Save checkpoint.\n    print(\'Saving..\')\n    state = {\n        \'net\': net,\n        \'acc\': acc,\n        \'epoch\': epoch,\n        \'rng_state\': torch.get_rng_state()\n    }\n    if not os.path.isdir(\'checkpoint\'):\n        os.mkdir(\'checkpoint\')\n    torch.save(state, \'./checkpoint/ckpt.t7.\' + args.sess + \'_\' + str(args.seed))\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""decrease the learning rate at 100 and 150 epoch""""""\n    lr = base_learning_rate\n    if epoch <= 9 and lr > 0.1:\n        # warm-up training for large minibatch\n        lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n    if epoch >= 100:\n        lr /= 10\n    if epoch >= 150:\n        lr /= 10\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\nif not os.path.exists(logname):\n    with open(logname, \'w\') as logfile:\n        logwriter = csv.writer(logfile, delimiter=\',\')\n        logwriter.writerow([\'epoch\', \'train loss\', \'train acc\', \'test loss\', \'test acc\'])\n\nfor epoch in range(start_epoch, 200):\n    adjust_learning_rate(optimizer, epoch)\n    train_loss, train_acc = train(epoch)\n    test_loss, test_acc = test(epoch)\n    with open(logname, \'a\') as logfile:\n        logwriter = csv.writer(logfile, delimiter=\',\')\n        logwriter.writerow([epoch, train_loss, train_acc, test_loss, test_acc])\n'"
cifar/utils.py,7,"b""'''Some helper functions for PyTorch, including:\n    - get_mean_and_std: calculate the mean and std value of dataset.\n    - msr_init: net parameter initialization.\n    - progress_bar: progress bar mimic xlua.progress.\n'''\nimport os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\n\nimport numpy as np\nimport torch\n\ndef mixup_data(x, y, alpha=1.0, use_cuda=True):\n\n    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0.:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index,:]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(y_a, y_b, lam):\n    return lambda criterion, pred: lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\ndef get_mean_and_std(dataset):\n    '''Compute the mean and std value of dataset.'''\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print('==> Computing mean and std..')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    '''Init layer parameters.'''\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode='fan_out')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\n\n_, term_width = os.popen('stty size', 'r').read().split()\nterm_width = int(term_width)\n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\n\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f\n"""
gan/example_gan.py,23,"b'import matplotlib\nmatplotlib.use(\'Agg\')\n\nfrom matplotlib import pyplot as plt\nimport torch\nfrom torch.autograd import Variable, grad\nfrom torch.nn.functional import binary_cross_entropy_with_logits as bce\n\nfrom tqdm import tqdm\n\nimport os\n\nif not os.path.exists(\'./samples\'):\n    os.makedirs(\'./samples\')\n\nn_iterations = 20001\nn_latent = 2\nn_layers = 3\nn_hidden = 512\nbs = 128\nextraD = 5\nuse_cuda = True\n\nfor shape in [\'ring\', \'grid\']:\n    for n_latent in [2, 5, 10]:\n        for mixup in [0, 0.1, 0.2, 0.5, 1]:\n\n            class Perceptron(torch.nn.Module):\n                def __init__(self, sizes, final=None):\n                    super(Perceptron, self).__init__()\n                    layers = []\n                    for i in range(len(sizes) - 1):\n                        layers.append(torch.nn.Linear(sizes[i], sizes[i + 1]))\n                        if i != (len(sizes) - 2):\n                            layers.append(torch.nn.ReLU(inplace=True))\n                    if final is not None:\n                        layers.append(final())\n                    self.net = torch.nn.Sequential(*layers)\n\n                def forward(self, x):\n                    return self.net(x)\n\n            def plot(x, y, mixup, iteration):\n                lims = (x.min() - .25, x.max() + .25)\n                plt.figure(figsize=(2, 2))\n                plt.plot(x[:, 0], x[:, 1], \'.\', label=\'real\')\n                plt.plot(y[:, 0], y[:, 1], \'.\', alpha=0.25, label=\'fake\')\n                plt.axis(\'off\')\n                plt.gca().axes.get_xaxis().set_visible(False)\n                plt.gca().axes.get_yaxis().set_visible(False)\n                plt.xlim(*lims)\n                plt.ylim(*lims)\n                plt.tight_layout(0, 0, 0)\n                plt.show()\n                plt.savefig(""images/example_z=%d_%s_%1.1f_%06d.png"" %\n                            (n_latent, shape, mixup, iteration),\n                            bbox_inches=\'tight\', pad_inches=0)\n                plt.close()\n\n            def means_circle(k=8):\n                p = 3.14159265359\n                t = torch.linspace(0, 2 * p - (2 * p / k), k)\n                m = torch.cat((torch.sin(t).view(-1, 1),\n                               torch.cos(t).view(-1, 1)), 1)\n                return m\n\n            def means_grid(k=25):\n                m = torch.zeros(k, 2)\n                s = int(torch.sqrt(torch.Tensor([k]))[0] / 2)\n                cnt = 0\n                for i in range(- s, s + 1):\n                    for j in range(- s, s + 1):\n                        m[cnt][0] = i\n                        m[cnt][1] = j\n                        cnt += 1\n                return m / s\n\n            def sample_real(n, shape, std=0.01):\n                if shape == \'ring\':\n                    m = means_circle()\n                else:\n                    m = means_grid()\n                i = torch.zeros(n).random_(m.size(0)).long()\n                s = torch.randn(n, 2) * std + m[i]\n                s = Variable(s, requires_grad=True)\n                if use_cuda:\n                    s = s.cuda()\n                return s\n\n            def sample_noise(bs, d):\n                z = torch.randn(bs, d)\n                z = Variable(z, requires_grad=True)\n                if use_cuda:\n                    z = z.cuda()\n                return z\n\n            netD = Perceptron([2] + [n_hidden] * n_layers + [1])\n            netG = Perceptron([n_latent] + [n_hidden] * n_layers + [2])\n\n            if use_cuda:\n                netD.cuda()\n                netG.cuda()\n\n            optD = torch.optim.Adam(netD.parameters())\n            optG = torch.optim.Adam(netG.parameters())\n\n            p_real = sample_real(1000, shape)\n            p_nois = sample_noise(1000, n_latent)\n\n            def mixup_batch(mixup=0.0):\n                def one_batch():\n                    real = sample_real(bs, shape)\n                    fake = netG(sample_noise(bs, n_latent))\n                    data = torch.cat((real, fake))\n                    ones = Variable(torch.ones(real.size(0), 1))\n                    zeros = Variable(torch.zeros(fake.size(0), 1))\n                    perm = torch.randperm(data.size(0)).view(-1).long()\n                    if use_cuda:\n                        ones = ones.cuda()\n                        zeros = zeros.cuda()\n                        perm = perm.cuda()\n                    labels = torch.cat((ones, zeros))\n                    return data[perm], labels[perm]\n\n                d1, l1 = one_batch()\n                if mixup == 0:\n                    return d1, l1\n                d2, l2 = one_batch()\n                alpha = Variable(torch.randn(d1.size(0), 1).uniform_(0, mixup))\n                if use_cuda:\n                    alpha = alpha.cuda()\n                d = alpha * d1 + (1. - alpha) * d2\n                l = alpha * l1 + (1. - alpha) * l2\n                return d, l\n\n            for iteration in tqdm(range(n_iterations)):\n                for extra in range(extraD):\n                    data, labels = mixup_batch(mixup)\n\n                    optD.zero_grad()\n                    lossD = bce(netD(data), labels)\n                    lossD.backward()\n                    optD.step()\n\n                data, labels = mixup_batch(0)\n\n                optG.zero_grad()\n                lossG = - bce(netD(data), labels)\n                lossG.backward()\n                optG.step()\n\n                if iteration in [10, 100, 1000, 10000, 20000]:\n                    plot_real = p_real.cpu().data.numpy()\n                    plot_fake = netG(p_nois).cpu().data.numpy()\n                    torch.save((plot_real, plot_fake),\n                               \'samples/example_z=%d_%s_%1.1f_%06d.pt\' %\n                               (n_latent, shape, mixup, iteration))\n                    plot(plot_real, plot_fake, mixup, iteration)\n'"
cifar/models/__init__.py,0,b'from .vgg import *\nfrom .dpn import *\nfrom .lenet import *\nfrom .senet import *\nfrom .resnet import *\nfrom .resnext import *\nfrom .pnasnet import *\nfrom .densenet import *\nfrom .googlenet import *\nfrom .mobilenet import *\nfrom .shufflenet import *\nfrom .preact_resnet import *\n'
cifar/models/densenet.py,5,"b""'''DenseNet in PyTorch.'''\nimport math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass Bottleneck(nn.Module):\n    def __init__(self, in_planes, growth_rate):\n        super(Bottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n\n    def forward(self, x):\n        out = self.conv1(F.relu(self.bn1(x)))\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = torch.cat([out,x], 1)\n        return out\n\n\nclass Transition(nn.Module):\n    def __init__(self, in_planes, out_planes):\n        super(Transition, self).__init__()\n        self.bn = nn.BatchNorm2d(in_planes)\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n\n    def forward(self, x):\n        out = self.conv(F.relu(self.bn(x)))\n        out = F.avg_pool2d(out, 2)\n        return out\n\n\nclass DenseNet(nn.Module):\n    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\n        super(DenseNet, self).__init__()\n        self.growth_rate = growth_rate\n\n        num_planes = 2*growth_rate\n        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n\n        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\n        num_planes += nblocks[0]*growth_rate\n        out_planes = int(math.floor(num_planes*reduction))\n        self.trans1 = Transition(num_planes, out_planes)\n        num_planes = out_planes\n\n        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\n        num_planes += nblocks[1]*growth_rate\n        out_planes = int(math.floor(num_planes*reduction))\n        self.trans2 = Transition(num_planes, out_planes)\n        num_planes = out_planes\n\n        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\n        num_planes += nblocks[2]*growth_rate\n        out_planes = int(math.floor(num_planes*reduction))\n        self.trans3 = Transition(num_planes, out_planes)\n        num_planes = out_planes\n\n        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\n        num_planes += nblocks[3]*growth_rate\n\n        self.bn = nn.BatchNorm2d(num_planes)\n        self.linear = nn.Linear(num_planes, num_classes)\n\n    def _make_dense_layers(self, block, in_planes, nblock):\n        layers = []\n        for i in range(nblock):\n            layers.append(block(in_planes, self.growth_rate))\n            in_planes += self.growth_rate\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.trans1(self.dense1(out))\n        out = self.trans2(self.dense2(out))\n        out = self.trans3(self.dense3(out))\n        out = self.dense4(out)\n        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\ndef DenseNet121():\n    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\n\ndef DenseNet169():\n    return DenseNet(Bottleneck, [6,12,32,32], growth_rate=32)\n\ndef DenseNet201():\n    return DenseNet(Bottleneck, [6,12,48,32], growth_rate=32)\n\ndef DenseNet161():\n    return DenseNet(Bottleneck, [6,12,36,24], growth_rate=48)\n\ndef densenet_cifar():\n    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=12)\n\ndef test_densenet():\n    net = densenet_cifar()\n    x = torch.randn(1,3,32,32)\n    y = net(Variable(x))\n    print(y)\n\n# test_densenet()\n"""
cifar/models/dpn.py,5,"b""'''Dual Path Networks in PyTorch.'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass Bottleneck(nn.Module):\n    def __init__(self, last_planes, in_planes, out_planes, dense_depth, stride, first_layer):\n        super(Bottleneck, self).__init__()\n        self.out_planes = out_planes\n        self.dense_depth = dense_depth\n\n        self.conv1 = nn.Conv2d(last_planes, in_planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv2 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=32, bias=False)\n        self.bn2 = nn.BatchNorm2d(in_planes)\n        self.conv3 = nn.Conv2d(in_planes, out_planes+dense_depth, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_planes+dense_depth)\n\n        self.shortcut = nn.Sequential()\n        if first_layer:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(last_planes, out_planes+dense_depth, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_planes+dense_depth)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        x = self.shortcut(x)\n        d = self.out_planes\n        out = torch.cat([x[:,:d,:,:]+out[:,:d,:,:], x[:,d:,:,:], out[:,d:,:,:]], 1)\n        out = F.relu(out)\n        return out\n\n\nclass DPN(nn.Module):\n    def __init__(self, cfg):\n        super(DPN, self).__init__()\n        in_planes, out_planes = cfg['in_planes'], cfg['out_planes']\n        num_blocks, dense_depth = cfg['num_blocks'], cfg['dense_depth']\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.last_planes = 64\n        self.layer1 = self._make_layer(in_planes[0], out_planes[0], num_blocks[0], dense_depth[0], stride=1)\n        self.layer2 = self._make_layer(in_planes[1], out_planes[1], num_blocks[1], dense_depth[1], stride=2)\n        self.layer3 = self._make_layer(in_planes[2], out_planes[2], num_blocks[2], dense_depth[2], stride=2)\n        self.layer4 = self._make_layer(in_planes[3], out_planes[3], num_blocks[3], dense_depth[3], stride=2)\n        self.linear = nn.Linear(out_planes[3]+(num_blocks[3]+1)*dense_depth[3], 10)\n\n    def _make_layer(self, in_planes, out_planes, num_blocks, dense_depth, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for i,stride in enumerate(strides):\n            layers.append(Bottleneck(self.last_planes, in_planes, out_planes, dense_depth, stride, i==0))\n            self.last_planes = out_planes + (i+2) * dense_depth\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef DPN26():\n    cfg = {\n        'in_planes': (96,192,384,768),\n        'out_planes': (256,512,1024,2048),\n        'num_blocks': (2,2,2,2),\n        'dense_depth': (16,32,24,128)\n    }\n    return DPN(cfg)\n\ndef DPN92():\n    cfg = {\n        'in_planes': (96,192,384,768),\n        'out_planes': (256,512,1024,2048),\n        'num_blocks': (3,4,20,3),\n        'dense_depth': (16,32,24,128)\n    }\n    return DPN(cfg)\n\n\ndef test():\n    net = DPN92()\n    x = Variable(torch.randn(1,3,32,32))\n    y = net(x)\n    print(y)\n\n# test()\n"""
cifar/models/googlenet.py,5,"b""'''GoogLeNet with PyTorch.'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass Inception(nn.Module):\n    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n        super(Inception, self).__init__()\n        # 1x1 conv branch\n        self.b1 = nn.Sequential(\n            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n            nn.BatchNorm2d(n1x1),\n            nn.ReLU(True),\n        )\n\n        # 1x1 conv -> 3x3 conv branch\n        self.b2 = nn.Sequential(\n            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n            nn.BatchNorm2d(n3x3red),\n            nn.ReLU(True),\n            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n            nn.BatchNorm2d(n3x3),\n            nn.ReLU(True),\n        )\n\n        # 1x1 conv -> 5x5 conv branch\n        self.b3 = nn.Sequential(\n            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n            nn.BatchNorm2d(n5x5red),\n            nn.ReLU(True),\n            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n            nn.BatchNorm2d(n5x5),\n            nn.ReLU(True),\n            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n            nn.BatchNorm2d(n5x5),\n            nn.ReLU(True),\n        )\n\n        # 3x3 pool -> 1x1 conv branch\n        self.b4 = nn.Sequential(\n            nn.MaxPool2d(3, stride=1, padding=1),\n            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n            nn.BatchNorm2d(pool_planes),\n            nn.ReLU(True),\n        )\n\n    def forward(self, x):\n        y1 = self.b1(x)\n        y2 = self.b2(x)\n        y3 = self.b3(x)\n        y4 = self.b4(x)\n        return torch.cat([y1,y2,y3,y4], 1)\n\n\nclass GoogLeNet(nn.Module):\n    def __init__(self):\n        super(GoogLeNet, self).__init__()\n        self.pre_layers = nn.Sequential(\n            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n            nn.BatchNorm2d(192),\n            nn.ReLU(True),\n        )\n\n        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n\n        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n\n        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n\n        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n\n        self.avgpool = nn.AvgPool2d(8, stride=1)\n        self.linear = nn.Linear(1024, 10)\n\n    def forward(self, x):\n        out = self.pre_layers(x)\n        out = self.a3(out)\n        out = self.b3(out)\n        out = self.maxpool(out)\n        out = self.a4(out)\n        out = self.b4(out)\n        out = self.c4(out)\n        out = self.d4(out)\n        out = self.e4(out)\n        out = self.maxpool(out)\n        out = self.a5(out)\n        out = self.b5(out)\n        out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n# net = GoogLeNet()\n# x = torch.randn(1,3,32,32)\n# y = net(Variable(x))\n# print(y.size())\n"""
cifar/models/lenet.py,2,"b""'''LeNet in PyTorch.'''\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass LeNet(nn.Module):\n    def __init__(self):\n        super(LeNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1   = nn.Linear(16*5*5, 120)\n        self.fc2   = nn.Linear(120, 84)\n        self.fc3   = nn.Linear(84, 10)\n\n    def forward(self, x):\n        out = F.relu(self.conv1(x))\n        out = F.max_pool2d(out, 2)\n        out = F.relu(self.conv2(out))\n        out = F.max_pool2d(out, 2)\n        out = out.view(out.size(0), -1)\n        out = F.relu(self.fc1(out))\n        out = F.relu(self.fc2(out))\n        out = self.fc3(out)\n        return out\n"""
cifar/models/mobilenet.py,4,"b'\'\'\'MobileNet in PyTorch.\n\nSee the paper ""MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications""\nfor more details.\n\'\'\'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass Block(nn.Module):\n    \'\'\'Depthwise conv + Pointwise conv\'\'\'\n    def __init__(self, in_planes, out_planes, stride=1):\n        super(Block, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        return out\n\n\nclass MobileNet(nn.Module):\n    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n\n    def __init__(self, num_classes=10):\n        super(MobileNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.layers = self._make_layers(in_planes=32)\n        self.linear = nn.Linear(1024, num_classes)\n\n    def _make_layers(self, in_planes):\n        layers = []\n        for x in self.cfg:\n            out_planes = x if isinstance(x, int) else x[0]\n            stride = 1 if isinstance(x, int) else x[1]\n            layers.append(Block(in_planes, out_planes, stride))\n            in_planes = out_planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layers(out)\n        out = F.avg_pool2d(out, 2)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef test():\n    net = MobileNet()\n    x = torch.randn(1,3,32,32)\n    y = net(Variable(x))\n    print(y.size())\n\n# test()\n'"
cifar/models/pnasnet.py,5,"b""'''PNASNet in PyTorch.\n\nPaper: Progressive Neural Architecture Search\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass SepConv(nn.Module):\n    '''Separable Convolution.'''\n    def __init__(self, in_planes, out_planes, kernel_size, stride):\n        super(SepConv, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, out_planes,\n                               kernel_size, stride,\n                               padding=(kernel_size-1)//2,\n                               bias=False, groups=in_planes)\n        self.bn1 = nn.BatchNorm2d(out_planes)\n\n    def forward(self, x):\n        return self.bn1(self.conv1(x))\n\n\nclass CellA(nn.Module):\n    def __init__(self, in_planes, out_planes, stride=1):\n        super(CellA, self).__init__()\n        self.stride = stride\n        self.sep_conv1 = SepConv(in_planes, out_planes, kernel_size=7, stride=stride)\n        if stride==2:\n            self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n            self.bn1 = nn.BatchNorm2d(out_planes)\n\n    def forward(self, x):\n        y1 = self.sep_conv1(x)\n        y2 = F.max_pool2d(x, kernel_size=3, stride=self.stride, padding=1)\n        if self.stride==2:\n            y2 = self.bn1(self.conv1(y2))\n        return F.relu(y1+y2)\n\nclass CellB(nn.Module):\n    def __init__(self, in_planes, out_planes, stride=1):\n        super(CellB, self).__init__()\n        self.stride = stride\n        # Left branch\n        self.sep_conv1 = SepConv(in_planes, out_planes, kernel_size=7, stride=stride)\n        self.sep_conv2 = SepConv(in_planes, out_planes, kernel_size=3, stride=stride)\n        # Right branch\n        self.sep_conv3 = SepConv(in_planes, out_planes, kernel_size=5, stride=stride)\n        if stride==2:\n            self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n            self.bn1 = nn.BatchNorm2d(out_planes)\n        # Reduce channels\n        self.conv2 = nn.Conv2d(2*out_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n\n    def forward(self, x):\n        # Left branch\n        y1 = self.sep_conv1(x)\n        y2 = self.sep_conv2(x)\n        # Right branch\n        y3 = F.max_pool2d(x, kernel_size=3, stride=self.stride, padding=1)\n        if self.stride==2:\n            y3 = self.bn1(self.conv1(y3))\n        y4 = self.sep_conv3(x)\n        # Concat & reduce channels\n        b1 = F.relu(y1+y2)\n        b2 = F.relu(y3+y4)\n        y = torch.cat([b1,b2], 1)\n        return F.relu(self.bn2(self.conv2(y)))\n\nclass PNASNet(nn.Module):\n    def __init__(self, cell_type, num_cells, num_planes):\n        super(PNASNet, self).__init__()\n        self.in_planes = num_planes\n        self.cell_type = cell_type\n\n        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(num_planes)\n\n        self.layer1 = self._make_layer(num_planes, num_cells=6)\n        self.layer2 = self._downsample(num_planes*2)\n        self.layer3 = self._make_layer(num_planes*2, num_cells=6)\n        self.layer4 = self._downsample(num_planes*4)\n        self.layer5 = self._make_layer(num_planes*4, num_cells=6)\n\n        self.linear = nn.Linear(num_planes*4, 10)\n\n    def _make_layer(self, planes, num_cells):\n        layers = []\n        for _ in range(num_cells):\n            layers.append(self.cell_type(self.in_planes, planes, stride=1))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def _downsample(self, planes):\n        layer = self.cell_type(self.in_planes, planes, stride=2)\n        self.in_planes = planes\n        return layer\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = F.avg_pool2d(out, 8)\n        out = self.linear(out.view(out.size(0), -1))\n        return out\n\n\ndef PNASNetA():\n    return PNASNet(CellA, num_cells=6, num_planes=44)\n\ndef PNASNetB():\n    return PNASNet(CellB, num_cells=6, num_planes=32)\n\n\ndef test():\n    net = PNASNetB()\n    print(net)\n    x = Variable(torch.randn(1,3,32,32))\n    y = net(x)\n    print(y)\n\n# test()\n"""
cifar/models/preact_resnet.py,4,"b""'''Pre-activation ResNet in PyTorch.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass PreActResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(PreActResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef PreActResNet18():\n    return PreActResNet(PreActBlock, [2,2,2,2])\n\ndef PreActResNet34():\n    return PreActResNet(PreActBlock, [3,4,6,3])\n\ndef PreActResNet50():\n    return PreActResNet(PreActBottleneck, [3,4,6,3])\n\ndef PreActResNet101():\n    return PreActResNet(PreActBottleneck, [3,4,23,3])\n\ndef PreActResNet152():\n    return PreActResNet(PreActBottleneck, [3,8,36,3])\n\n\ndef test():\n    net = PreActResNet18()\n    y = net(Variable(torch.randn(1,3,32,32)))\n    print(y.size())\n\n# test()\n"""
cifar/models/resnet.py,4,"b""'''ResNet in PyTorch.\n\nFor Pre-activation ResNet, see 'preact_resnet.py'.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2,2,2,2])\n\ndef ResNet34():\n    return ResNet(BasicBlock, [3,4,6,3])\n\ndef ResNet50():\n    return ResNet(Bottleneck, [3,4,6,3])\n\ndef ResNet101():\n    return ResNet(Bottleneck, [3,4,23,3])\n\ndef ResNet152():\n    return ResNet(Bottleneck, [3,8,36,3])\n\n\ndef test():\n    net = ResNet18()\n    y = net(Variable(torch.randn(1,3,32,32)))\n    print(y.size())\n\n# test()\n"""
cifar/models/resnext.py,4,"b'\'\'\'ResNeXt in PyTorch.\n\nSee the paper ""Aggregated Residual Transformations for Deep Neural Networks"" for more details.\n\'\'\'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass Block(nn.Module):\n    \'\'\'Grouped convolution block.\'\'\'\n    expansion = 2\n\n    def __init__(self, in_planes, cardinality=32, bottleneck_width=4, stride=1):\n        super(Block, self).__init__()\n        group_width = cardinality * bottleneck_width\n        self.conv1 = nn.Conv2d(in_planes, group_width, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(group_width)\n        self.conv2 = nn.Conv2d(group_width, group_width, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n        self.bn2 = nn.BatchNorm2d(group_width)\n        self.conv3 = nn.Conv2d(group_width, self.expansion*group_width, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*group_width)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*group_width:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*group_width, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*group_width)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNeXt(nn.Module):\n    def __init__(self, num_blocks, cardinality, bottleneck_width, num_classes=10):\n        super(ResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.bottleneck_width = bottleneck_width\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(num_blocks[0], 1)\n        self.layer2 = self._make_layer(num_blocks[1], 2)\n        self.layer3 = self._make_layer(num_blocks[2], 2)\n        # self.layer4 = self._make_layer(num_blocks[3], 2)\n        self.linear = nn.Linear(cardinality*bottleneck_width*8, num_classes)\n\n    def _make_layer(self, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(Block(self.in_planes, self.cardinality, self.bottleneck_width, stride))\n            self.in_planes = Block.expansion * self.cardinality * self.bottleneck_width\n        # Increase bottleneck_width by 2 after each stage.\n        self.bottleneck_width *= 2\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        # out = self.layer4(out)\n        out = F.avg_pool2d(out, 8)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNeXt29_2x64d():\n    return ResNeXt(num_blocks=[3,3,3], cardinality=2, bottleneck_width=64)\n\ndef ResNeXt29_4x64d():\n    return ResNeXt(num_blocks=[3,3,3], cardinality=4, bottleneck_width=64)\n\ndef ResNeXt29_8x64d():\n    return ResNeXt(num_blocks=[3,3,3], cardinality=8, bottleneck_width=64)\n\ndef ResNeXt29_32x4d():\n    return ResNeXt(num_blocks=[3,3,3], cardinality=32, bottleneck_width=4)\n\ndef test_resnext():\n    net = ResNeXt29_2x64d()\n    x = torch.randn(1,3,32,32)\n    y = net(Variable(x))\n    print(y.size())\n\n# test_resnext()\n'"
cifar/models/senet.py,4,"b""'''SENet in PyTorch.\n\nSENet is the winner of ImageNet-2017. The paper is not released yet.\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)  # Use nn.Conv2d instead of nn.Linear\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w  # New broadcasting feature from v0.2!\n\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBlock(nn.Module):\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n        # SE layers\n        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n\n        # Squeeze\n        w = F.avg_pool2d(out, out.size(2))\n        w = F.relu(self.fc1(w))\n        w = F.sigmoid(self.fc2(w))\n        # Excitation\n        out = out * w\n\n        out += shortcut\n        return out\n\n\nclass SENet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(SENet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef SENet18():\n    return SENet(PreActBlock, [2,2,2,2])\n\n\ndef test():\n    net = SENet18()\n    y = net(Variable(torch.randn(1,3,32,32)))\n    print(y.size())\n\n# test()\n"""
cifar/models/shufflenet.py,5,"b'\'\'\'ShuffleNet in PyTorch.\n\nSee the paper ""ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"" for more details.\n\'\'\'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass ShuffleBlock(nn.Module):\n    def __init__(self, groups):\n        super(ShuffleBlock, self).__init__()\n        self.groups = groups\n\n    def forward(self, x):\n        \'\'\'Channel shuffle: [N,C,H,W] -> [N,g,C/g,H,W] -> [N,C/g,g,H,w] -> [N,C,H,W]\'\'\'\n        N,C,H,W = x.size()\n        g = self.groups\n        return x.view(N,g,C/g,H,W).permute(0,2,1,3,4).contiguous().view(N,C,H,W)\n\n\nclass Bottleneck(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, groups):\n        super(Bottleneck, self).__init__()\n        self.stride = stride\n\n        mid_planes = out_planes/4\n        g = 1 if in_planes==24 else groups\n        self.conv1 = nn.Conv2d(in_planes, mid_planes, kernel_size=1, groups=g, bias=False)\n        self.bn1 = nn.BatchNorm2d(mid_planes)\n        self.shuffle1 = ShuffleBlock(groups=g)\n        self.conv2 = nn.Conv2d(mid_planes, mid_planes, kernel_size=3, stride=stride, padding=1, groups=mid_planes, bias=False)\n        self.bn2 = nn.BatchNorm2d(mid_planes)\n        self.conv3 = nn.Conv2d(mid_planes, out_planes, kernel_size=1, groups=groups, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_planes)\n\n        self.shortcut = nn.Sequential()\n        if stride == 2:\n            self.shortcut = nn.Sequential(nn.AvgPool2d(3, stride=2, padding=1))\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.shuffle1(out)\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        res = self.shortcut(x)\n        out = F.relu(torch.cat([out,res], 1)) if self.stride==2 else F.relu(out+res)\n        return out\n\n\nclass ShuffleNet(nn.Module):\n    def __init__(self, cfg):\n        super(ShuffleNet, self).__init__()\n        out_planes = cfg[\'out_planes\']\n        num_blocks = cfg[\'num_blocks\']\n        groups = cfg[\'groups\']\n\n        self.conv1 = nn.Conv2d(3, 24, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(24)\n        self.in_planes = 24\n        self.layer1 = self._make_layer(out_planes[0], num_blocks[0], groups)\n        self.layer2 = self._make_layer(out_planes[1], num_blocks[1], groups)\n        self.layer3 = self._make_layer(out_planes[2], num_blocks[2], groups)\n        self.linear = nn.Linear(out_planes[2], 10)\n\n    def _make_layer(self, out_planes, num_blocks, groups):\n        layers = []\n        for i in range(num_blocks):\n            stride = 2 if i == 0 else 1\n            cat_planes = self.in_planes if i == 0 else 0\n            layers.append(Bottleneck(self.in_planes, out_planes-cat_planes, stride=stride, groups=groups))\n            self.in_planes = out_planes\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ShuffleNetG2():\n    cfg = {\n        \'out_planes\': [200,400,800],\n        \'num_blocks\': [4,8,4],\n        \'groups\': 2\n    }\n    return ShuffleNet(cfg)\n\ndef ShuffleNetG3():\n    cfg = {\n        \'out_planes\': [240,480,960],\n        \'num_blocks\': [4,8,4],\n        \'groups\': 3\n    }\n    return ShuffleNet(cfg)\n\n\ndef test():\n    net = ShuffleNetG2()\n    x = Variable(torch.randn(1,3,32,32))\n    y = net(x)\n    print(y)\n\n# test()\n'"
cifar/models/vgg.py,4,"b""'''VGG11/13/16/19 in Pytorch.'''\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ncfg = {\n    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n}\n\n\nclass VGG(nn.Module):\n    def __init__(self, vgg_name):\n        super(VGG, self).__init__()\n        self.features = self._make_layers(cfg[vgg_name])\n        self.classifier = nn.Linear(512, 10)\n\n    def forward(self, x):\n        out = self.features(x)\n        out = out.view(out.size(0), -1)\n        out = self.classifier(out)\n        return out\n\n    def _make_layers(self, cfg):\n        layers = []\n        in_channels = 3\n        for x in cfg:\n            if x == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n                           nn.BatchNorm2d(x),\n                           nn.ReLU(inplace=True)]\n                in_channels = x\n        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n        return nn.Sequential(*layers)\n\n# net = VGG('VGG11')\n# x = torch.randn(2,3,32,32)\n# print(net(Variable(x)).size())\n"""
