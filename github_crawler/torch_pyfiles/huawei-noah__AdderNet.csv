file_path,api_count,code
adder.py,6,"b""'''\r\nCopyright (C) 2020. Huawei Technologies Co., Ltd. All rights reserved.\r\nThis program is free software; you can redistribute it and/or modify\r\nit under the terms of BSD 3-Clause License.\r\nThis program is distributed in the hope that it will be useful,\r\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\r\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\r\nBSD 3-Clause License for more details.\r\n'''\r\nimport torch\r\nimport torch.nn as nn\r\nimport numpy as np\r\nfrom torch.autograd import Function\r\nimport math\r\n\r\ndef adder2d_function(X, W, stride=1, padding=0):\r\n    n_filters, d_filter, h_filter, w_filter = W.size()\r\n    n_x, d_x, h_x, w_x = X.size()\r\n\r\n    h_out = (h_x - h_filter + 2 * padding) / stride + 1\r\n    w_out = (w_x - w_filter + 2 * padding) / stride + 1\r\n\r\n    h_out, w_out = int(h_out), int(w_out)\r\n    X_col = torch.nn.functional.unfold(X.view(1, -1, h_x, w_x), h_filter, dilation=1, padding=padding, stride=stride).view(n_x, -1, h_out*w_out)\r\n    X_col = X_col.permute(1,2,0).contiguous().view(X_col.size(1),-1)\r\n    W_col = W.view(n_filters, -1)\r\n    \r\n    out = -torch.cdist(W_col,X_col.transpose(0,1),1)\r\n    \r\n    out = out.view(n_filters, h_out, w_out, n_x)\r\n    out = out.permute(3, 0, 1, 2).contiguous()\r\n    \r\n    return out\r\n\r\n    \r\nclass adder2d(nn.Module):\r\n\r\n    def __init__(self,input_channel,output_channel,kernel_size, stride=1, padding=0, bias = False):\r\n        super(adder2d, self).__init__()\r\n        self.stride = stride\r\n        self.padding = padding\r\n        self.input_channel = input_channel\r\n        self.output_channel = output_channel\r\n        self.kernel_size = kernel_size\r\n        self.adder = torch.nn.Parameter(nn.init.normal_(torch.randn(output_channel,input_channel,kernel_size,kernel_size)))\r\n        self.bias = bias\r\n        if bias:\r\n            self.b = torch.nn.Parameter(nn.init.uniform_(torch.zeros(output_channel)))\r\n\r\n    def forward(self, x):\r\n        output = adder2d_function(x,self.adder, self.stride, self.padding)\r\n        if self.bias:\r\n            output += self.b.unsqueeze(0).unsqueeze(2).unsqueeze(3)\r\n        \r\n        return output\r\n    \r\n    """
resnet20.py,1,"b'# 2020.01.10-Replaced conv with adder\r\n#            Huawei Technologies Co., Ltd. <foss@huawei.com>\r\n\r\nimport adder\r\nimport torch.nn as nn\r\n\r\n\r\ndef conv3x3(in_planes, out_planes, stride=1):\r\n    "" 3x3 convolution with padding ""\r\n    return adder.adder2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n\r\n\r\nclass BasicBlock(nn.Module):\r\n    expansion=1\r\n\r\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n        super(BasicBlock, self).__init__()\r\n        self.conv1 = conv3x3(inplanes, planes, stride = stride)\r\n        self.bn1 = nn.BatchNorm2d(planes)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.conv2 = conv3x3(planes, planes)\r\n        self.bn2 = nn.BatchNorm2d(planes)\r\n        self.downsample = downsample\r\n        self.stride = stride\r\n\r\n    def forward(self, x):\r\n        residual = x\r\n\r\n        out = self.conv1(x)\r\n        out = self.bn1(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv2(out)\r\n        out = self.bn2(out)\r\n\r\n        if self.downsample is not None:\r\n            residual = self.downsample(x)\r\n\r\n        out += residual\r\n        out = self.relu(out)\r\n\r\n        return out\r\n\r\n\r\nclass ResNet(nn.Module):\r\n\r\n    def __init__(self, block, layers, num_classes=10):\r\n        super(ResNet, self).__init__()\r\n        self.inplanes = 16\r\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.bn1 = nn.BatchNorm2d(16)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.layer1 = self._make_layer(block, 16, layers[0])\r\n        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\r\n        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\r\n        self.avgpool = nn.AvgPool2d(8, stride=1)\r\n        self.fc = nn.Conv2d(64 * block.expansion, num_classes, 1, bias=False)\r\n        self.bn2 = nn.BatchNorm2d(num_classes)\r\n        \r\n        for m in self.modules():\r\n            if isinstance(m, nn.BatchNorm2d):\r\n                m.weight.data.fill_(1)\r\n                m.bias.data.zero_()\r\n         \r\n    def _make_layer(self, block, planes, blocks, stride=1):\r\n        downsample = None\r\n        if stride != 1 or self.inplanes != planes * block.expansion:\r\n            downsample = nn.Sequential(\r\n                adder.adder2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\r\n                nn.BatchNorm2d(planes * block.expansion)\r\n            )\r\n\r\n        layers = []\r\n        layers.append(block(inplanes = self.inplanes, planes = planes, stride = stride, downsample = downsample))\r\n        self.inplanes = planes * block.expansion\r\n        for _ in range(1, blocks):\r\n            layers.append(block(inplanes = self.inplanes, planes = planes))\r\n\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.bn1(x)\r\n        x = self.relu(x)\r\n\r\n        x = self.layer1(x)\r\n        x = self.layer2(x)\r\n        x = self.layer3(x)\r\n\r\n        x = self.avgpool(x)\r\n        x = self.fc(x)\r\n        x = self.bn2(x)\r\n\r\n        return x.view(x.size(0), -1)\r\n\r\n\r\ndef resnet20(**kwargs):\r\n    return ResNet(BasicBlock, [3, 3, 3], **kwargs)\r\n   '"
resnet50.py,1,"b'# 2020.01.10-Replaced conv with adder\r\n#            Huawei Technologies Co., Ltd. <foss@huawei.com>\r\n\r\nimport torch.nn as nn\r\nimport adder\r\n\r\n\r\ndef conv3x3(in_planes, out_planes, stride=1):\r\n    """"""3x3 convolution with padding""""""\r\n    return adder.adder2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n                     padding=1, bias=False)\r\n\r\n\r\ndef conv1x1(in_planes, out_planes, stride=1):\r\n    """"""1x1 convolution""""""\r\n    return adder.adder2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\r\n\r\n\r\nclass Bottleneck(nn.Module):\r\n    expansion = 4\r\n\r\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\r\n        super(Bottleneck, self).__init__()\r\n        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\r\n        self.conv1 = conv1x1(inplanes, planes)\r\n        self.bn1 = nn.BatchNorm2d(planes)\r\n        self.conv2 = conv3x3(planes, planes, stride)\r\n        self.bn2 = nn.BatchNorm2d(planes)\r\n        self.conv3 = conv1x1(planes, planes * self.expansion)\r\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.downsample = downsample\r\n        self.stride = stride\r\n\r\n    def forward(self, x):\r\n        identity = x\r\n\r\n        out = self.conv1(x)\r\n        out = self.bn1(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv2(out)\r\n        out = self.bn2(out)\r\n        out = self.relu(out)\r\n\r\n        out = self.conv3(out)\r\n        out = self.bn3(out)\r\n\r\n        if self.downsample is not None:\r\n            identity = self.downsample(x)\r\n\r\n        out += identity\r\n        out = self.relu(out)\r\n\r\n        return out\r\n\r\n\r\nclass ResNet(nn.Module):\r\n\r\n    def __init__(self, block, layers, num_classes=1000):\r\n        super(ResNet, self).__init__()\r\n        self.inplanes = 64\r\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\r\n                               bias=False)\r\n        self.bn1 = nn.BatchNorm2d(64)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n        self.layer1 = self._make_layer(block, 64, layers[0])\r\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\r\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\r\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\r\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n        self.fc = nn.Conv2d(512 * block.expansion, num_classes, 1)\r\n        self.bn2 = nn.BatchNorm2d(num_classes)\r\n\r\n        for m in self.modules():\r\n            if isinstance(m, nn.Conv2d):\r\n                nn.init.kaiming_normal_(m.weight, mode=\'fan_out\', nonlinearity=\'relu\')\r\n            elif isinstance(m, nn.BatchNorm2d):\r\n                nn.init.constant_(m.weight, 1)\r\n                nn.init.constant_(m.bias, 0)\r\n\r\n\r\n    def _make_layer(self, block, planes, blocks, stride=1):\r\n        downsample = None\r\n        if stride != 1 or self.inplanes != planes * block.expansion:\r\n            downsample = nn.Sequential(\r\n                conv1x1(self.inplanes, planes * block.expansion, stride),\r\n                nn.BatchNorm2d(planes * block.expansion),\r\n            )\r\n\r\n        layers = []\r\n        layers.append(block(self.inplanes, planes, stride, downsample))\r\n        self.inplanes = planes * block.expansion\r\n        for _ in range(1, blocks):\r\n            layers.append(block(self.inplanes, planes))\r\n\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.bn1(x)\r\n        x = self.relu(x)\r\n        x = self.maxpool(x)\r\n\r\n        x = self.layer1(x)\r\n        x = self.layer2(x)\r\n        x = self.layer3(x)\r\n        x = self.layer4(x)\r\n\r\n        x = self.avgpool(x)\r\n        x = self.fc(x)\r\n        x = self.bn2(x)\r\n\r\n        return x.view(x.size(0), -1)\r\n\r\n\r\n\r\ndef resnet50(**kwargs):\r\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\r\n    return model\r\n\r\n\r\n'"
test.py,7,"b'# 2020.01.10-Changed for testing AdderNets\r\n#            Huawei Technologies Co., Ltd. <foss@huawei.com>\r\n\r\nimport argparse\r\nimport os\r\nimport torch\r\nimport torch.backends.cudnn as cudnn\r\nimport torchvision.transforms as transforms\r\nimport torchvision.datasets as datasets\r\n\r\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\r\nparser.add_argument(\'--dataset\', type=str, default=\'ImageNet\', choices=[\'cifar10\',\'ImageNet\'])\r\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\r\n                    help=\'number of data loading workers (default: 4)\')\r\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\r\n                    metavar=\'N\',\r\n                    help=\'mini-batch size (default: 256), this is the total \'\r\n                         \'batch size of all GPUs on the current node when \'\r\n                         \'using Data Parallel or Distributed Data Parallel\')\r\nparser.add_argument(\'--data_dir\', type=str,\r\n                    help=\'path to dataset\',default=""/cache/imagenet/val/"")\r\nparser.add_argument(\'--model_dir\', type=str,\r\n                    help=\'path to dataset\',default=""models/ResNet50-AdderNet.pth"")\r\nbest_acc1 = 0\r\nargs, unparsed = parser.parse_known_args()\r\n\r\ndef main():\r\n\r\n    # create model\r\n    if args.dataset == \'cifar10\':\r\n        import resnet20\r\n        model = resnet20.resnet20()\r\n    elif args.dataset == \'ImageNet\':\r\n        import resnet50\r\n        model = resnet50.resnet50()\r\n        \r\n    model = torch.nn.DataParallel(model).cuda()\r\n    \r\n    model.load_state_dict(torch.load(args.model_dir))\r\n\r\n    cudnn.benchmark = True\r\n\r\n    # Data loading code\r\n    \r\n    if args.dataset == \'cifar10\':\r\n        val_loader = torch.utils.data.DataLoader(\r\n            datasets.CIFAR10(args.data_dir, train=False, transform = transforms.Compose([\r\n                transforms.ToTensor(),\r\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\r\n            ])),\r\n            batch_size=args.batch_size, shuffle=False,\r\n            num_workers=args.workers, pin_memory=True)\r\n    elif args.dataset == \'ImageNet\':\r\n        val_loader = torch.utils.data.DataLoader(\r\n            datasets.ImageFolder(args.data_dir, transforms.Compose([\r\n                transforms.Resize(256),\r\n                transforms.CenterCrop(224),\r\n                transforms.ToTensor(),\r\n                transforms.Normalize(mean=[0.485, 0.456, 0.406],\r\n                                         std=[0.229, 0.224, 0.225])\r\n            ])),\r\n            batch_size=args.batch_size, shuffle=False,\r\n            num_workers=args.workers, pin_memory=True)\r\n\r\n    acc1 = validate(val_loader, model)\r\n\r\n\r\ndef validate(val_loader, model):\r\n    top1 = AverageMeter()\r\n    top5 = AverageMeter()\r\n\r\n    model.eval()\r\n\r\n    with torch.no_grad():\r\n        for i, (input, target) in enumerate(val_loader):\r\n            input = input.cuda(non_blocking=True)\r\n            target = target.cuda(non_blocking=True)\r\n\r\n            # compute output\r\n            output = model(input)\r\n\r\n            # measure accuracy and record loss\r\n            acc1, acc5 = accuracy(output, target, topk=(1, 5))\r\n            top1.update(acc1[0], input.size(0))\r\n            top5.update(acc5[0], input.size(0))\r\n\r\n            print(\' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\'\r\n                  .format(top1=top1, top5=top5))\r\n\r\n    return top1.avg\r\n\r\n\r\nclass AverageMeter(object):\r\n    """"""Computes and stores the average and current value""""""\r\n    def __init__(self):\r\n        self.reset()\r\n\r\n    def reset(self):\r\n        self.val = 0\r\n        self.avg = 0\r\n        self.sum = 0\r\n        self.count = 0\r\n\r\n    def update(self, val, n=1):\r\n        self.val = val\r\n        self.sum += val * n\r\n        self.count += n\r\n        self.avg = self.sum / self.count\r\n\r\n\r\n\r\ndef accuracy(output, target, topk=(1,)):\r\n    """"""Computes the accuracy over the k top predictions for the specified values of k""""""\r\n    with torch.no_grad():\r\n        maxk = max(topk)\r\n        batch_size = target.size(0)\r\n\r\n        _, pred = output.topk(maxk, 1, True, True)\r\n        pred = pred.t()\r\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\r\n\r\n        res = []\r\n        for k in topk:\r\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\r\n            res.append(correct_k.mul_(100.0 / batch_size))\r\n        return res\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()'"
