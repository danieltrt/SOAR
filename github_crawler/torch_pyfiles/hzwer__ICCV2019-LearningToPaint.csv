file_path,api_count,code
baseline/env.py,6,"b'import sys\nimport json\nimport torch\nimport numpy as np\nimport argparse\nimport torchvision.transforms as transforms\nimport cv2\nfrom DRL.ddpg import decode\nfrom utils.util import *\nfrom PIL import Image\nfrom torchvision import transforms, utils\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\naug = transforms.Compose(\n            [transforms.ToPILImage(),\n             transforms.RandomHorizontalFlip(),\n             ])\n\nwidth = 128\nconvas_area = width * width\n\nimg_train = []\nimg_test = []\ntrain_num = 0\ntest_num = 0\n\nclass Paint:\n    def __init__(self, batch_size, max_step):\n        self.batch_size = batch_size\n        self.max_step = max_step\n        self.action_space = (13)\n        self.observation_space = (self.batch_size, width, width, 7)\n        self.test = False\n        \n    def load_data(self):\n        # CelebA\n        global train_num, test_num\n        for i in range(200000):\n            img_id = \'%06d\' % (i + 1)\n            try:\n                img = cv2.imread(\'./data/img_align_celeba/\' + img_id + \'.jpg\', cv2.IMREAD_UNCHANGED)\n                img = cv2.resize(img, (width, width))\n                if i > 2000:                \n                    train_num += 1\n                    img_train.append(img)\n                else:\n                    test_num += 1\n                    img_test.append(img)\n            finally:\n                if (i + 1) % 10000 == 0:                    \n                    print(\'loaded {} images\'.format(i + 1))\n        print(\'finish loading data, {} training images, {} testing images\'.format(str(train_num), str(test_num)))\n        \n    def pre_data(self, id, test):\n        if test:\n            img = img_test[id]\n        else:\n            img = img_train[id]\n        if not test:\n            img = aug(img)\n        img = np.asarray(img)\n        return np.transpose(img, (2, 0, 1))\n    \n    def reset(self, test=False, begin_num=False):\n        self.test = test\n        self.imgid = [0] * self.batch_size\n        self.gt = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n        for i in range(self.batch_size):\n            if test:\n                id = (i + begin_num)  % test_num\n            else:\n                id = np.random.randint(train_num)\n            self.imgid[i] = id\n            self.gt[i] = torch.tensor(self.pre_data(id, test))\n        self.tot_reward = ((self.gt.float() / 255) ** 2).mean(1).mean(1).mean(1)\n        self.stepnum = 0\n        self.canvas = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n        self.lastdis = self.ini_dis = self.cal_dis()\n        return self.observation()\n    \n    def observation(self):\n        # canvas B * 3 * width * width\n        # gt B * 3 * width * width\n        # T B * 1 * width * width\n        ob = []\n        T = torch.ones([self.batch_size, 1, width, width], dtype=torch.uint8) * self.stepnum\n        return torch.cat((self.canvas, self.gt, T.to(device)), 1) # canvas, img, T\n\n    def cal_trans(self, s, t):\n        return (s.transpose(0, 3) * t).transpose(0, 3)\n    \n    def step(self, action):\n        self.canvas = (decode(action, self.canvas.float() / 255) * 255).byte()\n        self.stepnum += 1\n        ob = self.observation()\n        done = (self.stepnum == self.max_step)\n        reward = self.cal_reward() # np.array([0.] * self.batch_size)\n        return ob.detach(), reward, np.array([done] * self.batch_size), None\n\n    def cal_dis(self):\n        return (((self.canvas.float() - self.gt.float()) / 255) ** 2).mean(1).mean(1).mean(1)\n    \n    def cal_reward(self):\n        dis = self.cal_dis()\n        reward = (self.lastdis - dis) / (self.ini_dis + 1e-8)\n        self.lastdis = dis\n        return to_numpy(reward)\n'"
baseline/test.py,14,"b'import os\nimport cv2\nimport torch\nimport numpy as np\nimport argparse\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom DRL.actor import *\nfrom Renderer.stroke_gen import *\nfrom Renderer.model import *\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\nwidth = 128\n\nparser = argparse.ArgumentParser(description=\'Learning to Paint\')\nparser.add_argument(\'--max_step\', default=40, type=int, help=\'max length for episode\')\nparser.add_argument(\'--actor\', default=\'./model/Paint-run1/actor.pkl\', type=str, help=\'Actor model\')\nparser.add_argument(\'--renderer\', default=\'./renderer.pkl\', type=str, help=\'renderer model\')\nparser.add_argument(\'--img\', default=\'image/test.png\', type=str, help=\'test image\')\nparser.add_argument(\'--imgid\', default=0, type=int, help=\'set begin number for generated image\')\nparser.add_argument(\'--divide\', default=4, type=int, help=\'divide the target image to get better resolution\')\nargs = parser.parse_args()\n\ncanvas_cnt = args.divide * args.divide\nT = torch.ones([1, 1, width, width], dtype=torch.float32).to(device)\nimg = cv2.imread(args.img, cv2.IMREAD_COLOR)\norigin_shape = (img.shape[1], img.shape[0])\n\ncoord = torch.zeros([1, 2, width, width])\nfor i in range(width):\n    for j in range(width):\n        coord[0, 0, i, j] = i / (width - 1.)\n        coord[0, 1, i, j] = j / (width - 1.)\ncoord = coord.to(device) # Coordconv\n\nDecoder = FCN()\nDecoder.load_state_dict(torch.load(args.renderer))\n\ndef decode(x, canvas): # b * (10 + 3)\n    x = x.view(-1, 10 + 3)\n    stroke = 1 - Decoder(x[:, :10])\n    stroke = stroke.view(-1, width, width, 1)\n    color_stroke = stroke * x[:, -3:].view(-1, 1, 1, 3)\n    stroke = stroke.permute(0, 3, 1, 2)\n    color_stroke = color_stroke.permute(0, 3, 1, 2)\n    stroke = stroke.view(-1, 5, 1, width, width)\n    color_stroke = color_stroke.view(-1, 5, 3, width, width)\n    res = []\n    for i in range(5):\n        canvas = canvas * (1 - stroke[:, i]) + color_stroke[:, i]\n        res.append(canvas)\n    return canvas, res\n\ndef small2large(x):\n    # (d * d, width, width) -> (d * width, d * width)    \n    x = x.reshape(args.divide, args.divide, width, width, -1)\n    x = np.transpose(x, (0, 2, 1, 3, 4))\n    x = x.reshape(args.divide * width, args.divide * width, -1)\n    return x\n\ndef large2small(x):\n    # (d * width, d * width) -> (d * d, width, width)\n    x = x.reshape(args.divide, width, args.divide, width, 3)\n    x = np.transpose(x, (0, 2, 1, 3, 4))\n    x = x.reshape(canvas_cnt, width, width, 3)\n    return x\n\ndef smooth(img):\n    def smooth_pix(img, tx, ty):\n        if tx == args.divide * width - 1 or ty == args.divide * width - 1 or tx == 0 or ty == 0: \n            return img\n        img[tx, ty] = (img[tx, ty] + img[tx + 1, ty] + img[tx, ty + 1] + img[tx - 1, ty] + img[tx, ty - 1] + img[tx + 1, ty - 1] + img[tx - 1, ty + 1] + img[tx - 1, ty - 1] + img[tx + 1, ty + 1]) / 9\n        return img\n\n    for p in range(args.divide):\n        for q in range(args.divide):\n            x = p * width\n            y = q * width\n            for k in range(width):\n                img = smooth_pix(img, x + k, y + width - 1)\n                if q != args.divide - 1:\n                    img = smooth_pix(img, x + k, y + width)\n            for k in range(width):\n                img = smooth_pix(img, x + width - 1, y + k)\n                if p != args.divide - 1:\n                    img = smooth_pix(img, x + width, y + k)\n    return img\n\ndef save_img(res, imgid, divide=False):\n    output = res.detach().cpu().numpy() # d * d, 3, width, width    \n    output = np.transpose(output, (0, 2, 3, 1))\n    if divide:\n        output = small2large(output)\n        output = smooth(output)\n    else:\n        output = output[0]\n    output = (output * 255).astype(\'uint8\')\n    output = cv2.resize(output, origin_shape)\n    cv2.imwrite(\'output/generated\' + str(imgid) + \'.png\', output)\n\nactor = ResNet(9, 18, 65) # action_bundle = 5, 65 = 5 * 13\nactor.load_state_dict(torch.load(args.actor))\nactor = actor.to(device).eval()\nDecoder = Decoder.to(device).eval()\n\ncanvas = torch.zeros([1, 3, width, width]).to(device)\n\npatch_img = cv2.resize(img, (width * args.divide, width * args.divide))\npatch_img = large2small(patch_img)\npatch_img = np.transpose(patch_img, (0, 3, 1, 2))\npatch_img = torch.tensor(patch_img).to(device).float() / 255.\n\nimg = cv2.resize(img, (width, width))\nimg = img.reshape(1, width, width, 3)\nimg = np.transpose(img, (0, 3, 1, 2))\nimg = torch.tensor(img).to(device).float() / 255.\n\nos.system(\'mkdir output\')\n\nwith torch.no_grad():\n    if args.divide != 1:\n        args.max_step = args.max_step // 2\n    for i in range(args.max_step):\n        stepnum = T * i / args.max_step\n        actions = actor(torch.cat([canvas, img, stepnum, coord], 1))\n        canvas, res = decode(actions, canvas)\n        print(\'canvas step {}, L2Loss = {}\'.format(i, ((canvas - img) ** 2).mean()))\n        for j in range(5):\n            save_img(res[j], args.imgid)\n            args.imgid += 1\n    if args.divide != 1:\n        canvas = canvas[0].detach().cpu().numpy()\n        canvas = np.transpose(canvas, (1, 2, 0))    \n        canvas = cv2.resize(canvas, (width * args.divide, width * args.divide))\n        canvas = large2small(canvas)\n        canvas = np.transpose(canvas, (0, 3, 1, 2))\n        canvas = torch.tensor(canvas).to(device).float()\n        coord = coord.expand(canvas_cnt, 2, width, width)\n        T = T.expand(canvas_cnt, 1, width, width)\n        for i in range(args.max_step):\n            stepnum = T * i / args.max_step\n            actions = actor(torch.cat([canvas, patch_img, stepnum, coord], 1))\n            canvas, res = decode(actions, canvas)\n            print(\'divided canvas step {}, L2Loss = {}\'.format(i, ((canvas - patch_img) ** 2).mean()))\n            for j in range(5):\n                save_img(res[j], args.imgid, True)\n                args.imgid += 1\n'"
baseline/train.py,4,"b'#!/usr/bin/env python3\nimport cv2\nimport random\nimport numpy as np\nimport argparse\nfrom DRL.evaluator import Evaluator\nfrom utils.util import *\nfrom utils.tensorboard import TensorBoard\nimport time\n\nexp = os.path.abspath(\'.\').split(\'/\')[-1]\nwriter = TensorBoard(\'../train_log/{}\'.format(exp))\nos.system(\'ln -sf ../train_log/{} ./log\'.format(exp))\nos.system(\'mkdir ./model\')\n\ndef train(agent, env, evaluate):\n    train_times = args.train_times\n    env_batch = args.env_batch\n    validate_interval = args.validate_interval\n    max_step = args.max_step\n    debug = args.debug\n    episode_train_times = args.episode_train_times\n    resume = args.resume\n    output = args.output\n    time_stamp = time.time()\n    step = episode = episode_steps = 0\n    tot_reward = 0.\n    observation = None\n    noise_factor = args.noise_factor\n    while step <= train_times:\n        step += 1\n        episode_steps += 1\n        # reset if it is the start of episode\n        if observation is None:\n            observation = env.reset()\n            agent.reset(observation, noise_factor)    \n        action = agent.select_action(observation, noise_factor=noise_factor)\n        observation, reward, done, _ = env.step(action)\n        agent.observe(reward, observation, done, step)\n        if (episode_steps >= max_step and max_step):\n            if step > args.warmup:\n                # [optional] evaluate\n                if episode > 0 and validate_interval > 0 and episode % validate_interval == 0:\n                    reward, dist = evaluate(env, agent.select_action, debug=debug)\n                    if debug: prRed(\'Step_{:07d}: mean_reward:{:.3f} mean_dist:{:.3f} var_dist:{:.3f}\'.format(step - 1, np.mean(reward), np.mean(dist), np.var(dist)))\n                    writer.add_scalar(\'validate/mean_reward\', np.mean(reward), step)\n                    writer.add_scalar(\'validate/mean_dist\', np.mean(dist), step)\n                    writer.add_scalar(\'validate/var_dist\', np.var(dist), step)\n                    agent.save_model(output)\n            train_time_interval = time.time() - time_stamp\n            time_stamp = time.time()\n            tot_Q = 0.\n            tot_value_loss = 0.\n            if step > args.warmup:\n                if step < 10000 * max_step:\n                    lr = (3e-4, 1e-3)\n                elif step < 20000 * max_step:\n                    lr = (1e-4, 3e-4)\n                else:\n                    lr = (3e-5, 1e-4)\n                for i in range(episode_train_times):\n                    Q, value_loss = agent.update_policy(lr)\n                    tot_Q += Q.data.cpu().numpy()\n                    tot_value_loss += value_loss.data.cpu().numpy()\n                writer.add_scalar(\'train/critic_lr\', lr[0], step)\n                writer.add_scalar(\'train/actor_lr\', lr[1], step)\n                writer.add_scalar(\'train/Q\', tot_Q / episode_train_times, step)\n                writer.add_scalar(\'train/critic_loss\', tot_value_loss / episode_train_times, step)\n            if debug: prBlack(\'#{}: steps:{} interval_time:{:.2f} train_time:{:.2f}\' \\\n                .format(episode, step, train_time_interval, time.time()-time_stamp)) \n            time_stamp = time.time()\n            # reset\n            observation = None\n            episode_steps = 0\n            episode += 1\n    \nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'Learning to Paint\')\n\n    # hyper-parameter\n    parser.add_argument(\'--warmup\', default=400, type=int, help=\'timestep without training but only filling the replay memory\')\n    parser.add_argument(\'--discount\', default=0.95**5, type=float, help=\'discount factor\')\n    parser.add_argument(\'--batch_size\', default=96, type=int, help=\'minibatch size\')\n    parser.add_argument(\'--rmsize\', default=800, type=int, help=\'replay memory size\')\n    parser.add_argument(\'--env_batch\', default=96, type=int, help=\'concurrent environment number\')\n    parser.add_argument(\'--tau\', default=0.001, type=float, help=\'moving average for target network\')\n    parser.add_argument(\'--max_step\', default=40, type=int, help=\'max length for episode\')\n    parser.add_argument(\'--noise_factor\', default=0, type=float, help=\'noise level for parameter space noise\')\n    parser.add_argument(\'--validate_interval\', default=50, type=int, help=\'how many episodes to perform a validation\')\n    parser.add_argument(\'--validate_episodes\', default=5, type=int, help=\'how many episode to perform during validation\')\n    parser.add_argument(\'--train_times\', default=2000000, type=int, help=\'total traintimes\')\n    parser.add_argument(\'--episode_train_times\', default=10, type=int, help=\'train times for each episode\')    \n    parser.add_argument(\'--resume\', default=None, type=str, help=\'Resuming model path for testing\')\n    parser.add_argument(\'--output\', default=\'./model\', type=str, help=\'Resuming model path for testing\')\n    parser.add_argument(\'--debug\', dest=\'debug\', action=\'store_true\', help=\'print some info\')\n    parser.add_argument(\'--seed\', default=1234, type=int, help=\'random seed\')\n    \n    args = parser.parse_args()    \n    args.output = get_output_folder(args.output, ""Paint"")\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    if torch.cuda.is_available(): torch.cuda.manual_seed_all(args.seed)\n    random.seed(args.seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True\n    from DRL.ddpg import DDPG\n    from DRL.multi import fastenv\n    fenv = fastenv(args.max_step, args.env_batch, writer)\n    agent = DDPG(args.batch_size, args.env_batch, args.max_step, \\\n                 args.tau, args.discount, args.rmsize, \\\n                 writer, args.resume, args.output)\n    evaluate = Evaluator(args, writer)\n    print(\'observation_space\', fenv.observation_space, \'action_space\', fenv.action_space)\n    train(agent, fenv, evaluate)\n'"
baseline/train_renderer.py,8,"b'import cv2\nimport torch\nimport numpy as np\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom utils.tensorboard import TensorBoard\nfrom Renderer.model import FCN\nfrom Renderer.stroke_gen import *\n\nwriter = TensorBoard(""../train_log/"")\nimport torch.optim as optim\n\ncriterion = nn.MSELoss()\nnet = FCN()\noptimizer = optim.Adam(net.parameters(), lr=3e-6)\nbatch_size = 64\n\nuse_cuda = torch.cuda.is_available()\nstep = 0\n\n\ndef save_model():\n    if use_cuda:\n        net.cpu()\n    torch.save(net.state_dict(), ""../renderer.pkl"")\n    if use_cuda:\n        net.cuda()\n\n\ndef load_weights():\n    pretrained_dict = torch.load(""../renderer.pkl"")\n    model_dict = net.state_dict()\n    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n    model_dict.update(pretrained_dict)\n    net.load_state_dict(model_dict)\n\n\nload_weights()\nwhile step < 500000:\n    net.train()\n    train_batch = []\n    ground_truth = []\n    for i in range(batch_size):\n        f = np.random.uniform(0, 1, 10)\n        train_batch.append(f)\n        ground_truth.append(draw(f))\n\n    train_batch = torch.tensor(train_batch).float()\n    ground_truth = torch.tensor(ground_truth).float()\n    if use_cuda:\n        net = net.cuda()\n        train_batch = train_batch.cuda()\n        ground_truth = ground_truth.cuda()\n    gen = net(train_batch)\n    optimizer.zero_grad()\n    loss = criterion(gen, ground_truth)\n    loss.backward()\n    optimizer.step()\n    print(step, loss.item())\n    if step < 200000:\n        lr = 1e-4\n    elif step < 400000:\n        lr = 1e-5\n    else:\n        lr = 1e-6\n    for param_group in optimizer.param_groups:\n        param_group[""lr""] = lr\n    writer.add_scalar(""train/loss"", loss.item(), step)\n    if step % 100 == 0:\n        net.eval()\n        gen = net(train_batch)\n        loss = criterion(gen, ground_truth)\n        writer.add_scalar(""val/loss"", loss.item(), step)\n        for i in range(32):\n            G = gen[i].cpu().data.numpy()\n            GT = ground_truth[i].cpu().data.numpy()\n            writer.add_image(""train/gen{}.png"".format(i), G, step)\n            writer.add_image(""train/ground_truth{}.png"".format(i), GT, step)\n    if step % 1000 == 0:\n        save_model()\n    step += 1\n'"
baseline_modelfree/env.py,6,"b'import sys\nimport json\nimport torch\nimport numpy as np\nimport argparse\nimport torchvision.transforms as transforms\nimport cv2\nfrom DRL.ddpg import decode\nfrom utils.util import *\nfrom PIL import Image\nfrom torchvision import transforms, utils\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\naug = transforms.Compose(\n            [transforms.ToPILImage(),\n             transforms.RandomHorizontalFlip(),\n             ])\n\nwidth = 128\nconvas_area = width * width\n\nimg_train = []\nimg_test = []\ntrain_num = 0\ntest_num = 0\n\nclass Paint:\n    def __init__(self, batch_size, max_step):\n        self.batch_size = batch_size\n        self.max_step = max_step\n        self.action_space = (13)\n        self.observation_space = (self.batch_size, width, width, 7)\n        self.test = False\n        \n    def load_data(self):\n        # CelebA\n        global train_num, test_num\n        for i in range(200000):            \n            img_id = \'%06d\' % (i + 1)\n            try:\n                img = cv2.imread(\'../data/img_align_celeba/\' + img_id + \'.jpg\', cv2.IMREAD_UNCHANGED)\n                img = cv2.resize(img, (width, width))\n                if i > 2000:                \n                    train_num += 1\n                    img_train.append(img)\n                else:\n                    test_num += 1\n                    img_test.append(img)\n            finally:\n                if (i + 1) % 10000 == 0:\n                    print(\'loaded {} images\'.format(i + 1))\n        print(\'finish loading data, {} training images, {} testing images\'.format(str(train_num), str(test_num)))\n        \n    def pre_data(self, id, test):\n        if test:\n            img = img_test[id]\n        else:\n            img = img_train[id]\n        if not test:\n            img = aug(img)\n        img = np.asarray(img)\n        return np.transpose(img, (2, 0, 1))\n    \n    def reset(self, test=False, begin_num=False):\n        self.test = test\n        self.imgid = [0] * self.batch_size\n        self.gt = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n        for i in range(self.batch_size):\n            if test:\n                id = (i + begin_num)  % test_num\n            else:\n                id = np.random.randint(train_num)\n            self.imgid[i] = id\n            self.gt[i] = torch.tensor(self.pre_data(id, test))\n        self.tot_reward = ((self.gt.float() / 255) ** 2).mean(1).mean(1).mean(1)\n        self.stepnum = 0\n        self.canvas = torch.zeros([self.batch_size, 3, width, width], dtype=torch.uint8).to(device)\n        self.lastdis = self.ini_dis = self.cal_dis()\n        return self.observation()\n    \n    def observation(self):\n        # canvas B * 3 * width * width\n        # gt B * 3 * width * width\n        # T B * 1 * width * width\n        ob = []\n        T = torch.ones([self.batch_size, 1, width, width], dtype=torch.uint8) * self.stepnum\n        return torch.cat((self.canvas, self.gt, T.to(device)), 1) # canvas, img, T\n\n    def cal_trans(self, s, t):\n        return (s.transpose(0, 3) * t).transpose(0, 3)\n    \n    def step(self, action):\n        self.canvas = (decode(action, self.canvas.float() / 255) * 255).byte()\n        self.stepnum += 1\n        ob = self.observation()\n        done = (self.stepnum == self.max_step)\n        reward = self.cal_reward() # np.array([0.] * self.batch_size)\n        return ob.detach(), reward, np.array([done] * self.batch_size), None\n\n    def cal_dis(self):\n        return (((self.canvas.float() - self.gt.float()) / 255) ** 2).mean(1).mean(1).mean(1)\n    \n    def cal_reward(self):\n        dis = self.cal_dis()\n        reward = (self.lastdis - dis) / (self.ini_dis + 1e-8)\n        self.lastdis = dis\n        return to_numpy(reward)\n'"
baseline_modelfree/test.py,14,"b'import os\nimport cv2\nimport torch\nimport numpy as np\nimport argparse\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom DRL.actor import *\nfrom Renderer.stroke_gen import *\nfrom Renderer.model import *\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\nwidth = 128\n\nparser = argparse.ArgumentParser(description=\'Learning to Paint\')\nparser.add_argument(\'--max_step\', default=40, type=int, help=\'max length for episode\')\nparser.add_argument(\'--actor\', default=\'./model/Paint-run1/actor.pkl\', type=str, help=\'Actor model\')\nparser.add_argument(\'--renderer\', default=\'./renderer.pkl\', type=str, help=\'renderer model\')\nparser.add_argument(\'--img\', default=\'image/test.png\', type=str, help=\'test image\')\nparser.add_argument(\'--imgid\', default=0, type=int, help=\'set begin number for generated image\')\nparser.add_argument(\'--divide\', default=4, type=int, help=\'divide the target image to get better resolution\')\nargs = parser.parse_args()\n\ncanvas_cnt = args.divide * args.divide\nT = torch.ones([1, 1, width, width], dtype=torch.float32).to(device)\nimg = cv2.imread(args.img, cv2.IMREAD_COLOR)\norigin_shape = (img.shape[1], img.shape[0])\n\ncoord = torch.zeros([1, 2, width, width])\nfor i in range(width):\n    for j in range(width):\n        coord[0, 0, i, j] = i / (width - 1.)\n        coord[0, 1, i, j] = j / (width - 1.)\ncoord = coord.to(device) # Coordconv\n\nDecoder = FCN()\nDecoder.load_state_dict(torch.load(args.renderer))\n\ndef decode(x, canvas): # b * (10 + 3)\n    x = x.view(-1, 10 + 3)\n    stroke = 1 - Decoder(x[:, :10])\n    stroke = stroke.view(-1, width, width, 1)\n    color_stroke = stroke * x[:, -3:].view(-1, 1, 1, 3)\n    stroke = stroke.permute(0, 3, 1, 2)\n    color_stroke = color_stroke.permute(0, 3, 1, 2)\n    stroke = stroke.view(-1, 5, 1, width, width)\n    color_stroke = color_stroke.view(-1, 5, 3, width, width)\n    res = []\n    for i in range(5):\n        canvas = canvas * (1 - stroke[:, i]) + color_stroke[:, i]\n        res.append(canvas)\n    return canvas, res\n\ndef small2large(x):\n    # (d * d, width, width) -> (d * width, d * width)    \n    x = x.reshape(args.divide, args.divide, width, width, -1)\n    x = np.transpose(x, (0, 2, 1, 3, 4))\n    x = x.reshape(args.divide * width, args.divide * width, -1)\n    return x\n\ndef large2small(x):\n    # (d * width, d * width) -> (d * d, width, width)\n    x = x.reshape(args.divide, width, args.divide, width, 3)\n    x = np.transpose(x, (0, 2, 1, 3, 4))\n    x = x.reshape(canvas_cnt, width, width, 3)\n    return x\n\ndef smooth(img):\n    def smooth_pix(img, tx, ty):\n        if tx == args.divide * width - 1 or ty == args.divide * width - 1 or tx == 0 or ty == 0: \n            return img\n        img[tx, ty] = (img[tx, ty] + img[tx + 1, ty] + img[tx, ty + 1] + img[tx - 1, ty] + img[tx, ty - 1] + img[tx + 1, ty - 1] + img[tx - 1, ty + 1] + img[tx - 1, ty - 1] + img[tx + 1, ty + 1]) / 9\n        return img\n\n    for p in range(args.divide):\n        for q in range(args.divide):\n            x = p * width\n            y = q * width\n            for k in range(width):\n                img = smooth_pix(img, x + k, y + width - 1)\n                if q != args.divide - 1:\n                    img = smooth_pix(img, x + k, y + width)\n            for k in range(width):\n                img = smooth_pix(img, x + width - 1, y + k)\n                if p != args.divide - 1:\n                    img = smooth_pix(img, x + width, y + k)\n    return img\n\ndef save_img(res, imgid, divide=False):\n    output = res.detach().cpu().numpy() # d * d, 3, width, width    \n    output = np.transpose(output, (0, 2, 3, 1))\n    if divide:\n        output = small2large(output)\n        output = smooth(output)\n    else:\n        output = output[0]\n    output = (output * 255).astype(\'uint8\')\n    output = cv2.resize(output, origin_shape)\n    cv2.imwrite(\'output/generated\' + str(imgid) + \'.png\', output)\n\nactor = ResNet(9, 18, 65) # action_bundle = 5, 65 = 5 * 13\nactor.load_state_dict(torch.load(args.actor))\nactor = actor.to(device).eval()\nDecoder = Decoder.to(device).eval()\n\ncanvas = torch.zeros([1, 3, width, width]).to(device)\n\npatch_img = cv2.resize(img, (width * args.divide, width * args.divide))\npatch_img = large2small(patch_img)\npatch_img = np.transpose(patch_img, (0, 3, 1, 2))\npatch_img = torch.tensor(patch_img).to(device).float() / 255.\n\nimg = cv2.resize(img, (width, width))\nimg = img.reshape(1, width, width, 3)\nimg = np.transpose(img, (0, 3, 1, 2))\nimg = torch.tensor(img).to(device).float() / 255.\n\nos.system(\'mkdir output\')\n\nwith torch.no_grad():\n    if args.divide != 1:\n        args.max_step = args.max_step // 2\n    for i in range(args.max_step):\n        stepnum = T * i / args.max_step\n        actions = actor(torch.cat([canvas, img, stepnum, coord], 1))\n        canvas, res = decode(actions, canvas)\n        print(\'canvas step {}, L2Loss = {}\'.format(i, ((canvas - img) ** 2).mean()))\n        for j in range(5):\n            save_img(res[j], args.imgid)\n            args.imgid += 1\n    if args.divide != 1:\n        canvas = canvas[0].detach().cpu().numpy()\n        canvas = np.transpose(canvas, (1, 2, 0))    \n        canvas = cv2.resize(canvas, (width * args.divide, width * args.divide))\n        canvas = large2small(canvas)\n        canvas = np.transpose(canvas, (0, 3, 1, 2))\n        canvas = torch.tensor(canvas).to(device).float()\n        coord = coord.expand(canvas_cnt, 2, width, width)\n        T = T.expand(canvas_cnt, 1, width, width)\n        for i in range(args.max_step):\n            stepnum = T * i / args.max_step\n            actions = actor(torch.cat([canvas, patch_img, stepnum, coord], 1))\n            canvas, res = decode(actions, canvas)\n            print(\'divided canvas step {}, L2Loss = {}\'.format(i, ((canvas - patch_img) ** 2).mean()))\n            for j in range(5):\n                save_img(res[j], args.imgid, True)\n                args.imgid += 1\n'"
baseline_modelfree/train.py,4,"b'#!/usr/bin/env python3\nimport cv2\nimport random\nimport numpy as np\nimport argparse\nfrom DRL.evaluator import Evaluator\nfrom utils.util import *\nfrom utils.tensorboard import TensorBoard\nimport time\n\nexp = os.path.abspath(\'.\').split(\'/\')[-1]\nwriter = TensorBoard(\'../train_log/{}\'.format(exp))\nos.system(\'ln -sf ../train_log/{} ./log\'.format(exp))\nos.system(\'mkdir ./model\')\n\ndef train(agent, env, evaluate):\n    train_times = args.train_times\n    env_batch = args.env_batch\n    validate_interval = args.validate_interval\n    max_step = args.max_step\n    debug = args.debug\n    episode_train_times = args.episode_train_times\n    resume = args.resume\n    output = args.output\n    time_stamp = time.time()\n    step = episode = episode_steps = 0\n    tot_reward = 0.\n    observation = None\n    noise_factor = args.noise_factor\n    while step <= train_times:\n        step += 1\n        episode_steps += 1\n        # reset if it is the start of episode\n        if observation is None:\n            observation = env.reset()\n            agent.reset(observation, noise_factor)    \n        action = agent.select_action(observation, noise_factor=noise_factor)\n        observation, reward, done, _ = env.step(action)\n        agent.observe(reward, observation, done, step)\n        if (episode_steps >= max_step and max_step):\n            if step > args.warmup:\n                # [optional] evaluate\n                if episode > 0 and validate_interval > 0 and episode % validate_interval == 0:\n                    reward, dist = evaluate(env, agent.select_action, debug=debug)\n                    if debug: prRed(\'Step_{:07d}: mean_reward:{:.3f} mean_dist:{:.3f} var_dist:{:.3f}\'.format(step - 1, np.mean(reward), np.mean(dist), np.var(dist)))\n                    writer.add_scalar(\'validate/mean_reward\', np.mean(reward), step)\n                    writer.add_scalar(\'validate/mean_dist\', np.mean(dist), step)\n                    writer.add_scalar(\'validate/var_dist\', np.var(dist), step)\n                    agent.save_model(output)\n            train_time_interval = time.time() - time_stamp\n            time_stamp = time.time()\n            tot_Q = 0.\n            tot_value_loss = 0.\n            if step > args.warmup:\n                if step < 10000 * max_step:\n                    lr = (3e-4, 1e-3)\n                elif step < 20000 * max_step:\n                    lr = (1e-4, 3e-4)\n                else:\n                    lr = (3e-5, 1e-4)\n                for i in range(episode_train_times):\n                    Q, value_loss = agent.update_policy(lr)\n                    tot_Q += Q.data.cpu().numpy()\n                    tot_value_loss += value_loss.data.cpu().numpy()\n                writer.add_scalar(\'train/critic_lr\', lr[0], step)\n                writer.add_scalar(\'train/actor_lr\', lr[1], step)\n                writer.add_scalar(\'train/Q\', tot_Q / episode_train_times, step)\n                writer.add_scalar(\'train/critic_loss\', tot_value_loss / episode_train_times, step)\n            if debug: prBlack(\'#{}: steps:{} interval_time:{:.2f} train_time:{:.2f}\' \\\n                .format(episode, step, train_time_interval, time.time()-time_stamp)) \n            time_stamp = time.time()\n            # reset\n            observation = None\n            episode_steps = 0\n            episode += 1\n    \nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'Learning to Paint\')\n\n    # hyper-parameter\n    parser.add_argument(\'--warmup\', default=400, type=int, help=\'timestep without training but only filling the replay memory\')\n    parser.add_argument(\'--discount\', default=0.95**5, type=float, help=\'discount factor\')\n    parser.add_argument(\'--batch_size\', default=96, type=int, help=\'minibatch size\')\n    parser.add_argument(\'--rmsize\', default=800, type=int, help=\'replay memory size\')\n    parser.add_argument(\'--env_batch\', default=96, type=int, help=\'concurrent environment number\')\n    parser.add_argument(\'--tau\', default=0.001, type=float, help=\'moving average for target network\')\n    parser.add_argument(\'--max_step\', default=40, type=int, help=\'max length for episode\')\n    parser.add_argument(\'--noise_factor\', default=0.05, type=float, help=\'noise level for parameter space noise\')\n    parser.add_argument(\'--validate_interval\', default=50, type=int, help=\'how many episodes to perform a validation\')\n    parser.add_argument(\'--validate_episodes\', default=5, type=int, help=\'how many episode to perform during validation\')\n    parser.add_argument(\'--train_times\', default=2000000, type=int, help=\'total traintimes\')\n    parser.add_argument(\'--episode_train_times\', default=10, type=int, help=\'train times for each episode\')    \n    parser.add_argument(\'--resume\', default=None, type=str, help=\'Resuming model path for testing\')\n    parser.add_argument(\'--output\', default=\'./model\', type=str, help=\'Resuming model path for testing\')\n    parser.add_argument(\'--debug\', dest=\'debug\', action=\'store_true\', help=\'print some info\')\n    parser.add_argument(\'--seed\', default=1234, type=int, help=\'random seed\')\n    \n    args = parser.parse_args()    \n    args.output = get_output_folder(args.output, ""Paint"")\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    if torch.cuda.is_available(): torch.cuda.manual_seed_all(args.seed)\n    random.seed(args.seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = False\n    from DRL.ddpg import DDPG\n    from DRL.multi import fastenv\n    fenv = fastenv(args.max_step, args.env_batch, writer)\n    agent = DDPG(args.batch_size, args.env_batch, args.max_step, \\\n                 args.tau, args.discount, args.rmsize, \\\n                 writer, args.resume, args.output)\n    evaluate = Evaluator(args, writer)\n    print(\'observation_space\', fenv.observation_space, \'action_space\', fenv.action_space)\n    train(agent, fenv, evaluate)\n'"
baseline_modelfree/train_renderer.py,8,"b'import cv2\nimport torch\nimport numpy as np\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom utils.tensorboard import TensorBoard\nfrom Renderer.model import FCN\nfrom Renderer.stroke_gen import *\n\nwriter = TensorBoard(""../train_log/"")\nimport torch.optim as optim\n\ncriterion = nn.MSELoss()\nnet = FCN()\noptimizer = optim.Adam(net.parameters(), lr=3e-6)\nbatch_size = 64\n\nuse_cuda = torch.cuda.is_available()\nstep = 0\n\n\ndef save_model():\n    if use_cuda:\n        net.cpu()\n    torch.save(net.state_dict(), ""../renderer.pkl"")\n    if use_cuda:\n        net.cuda()\n\n\ndef load_weights():\n    pretrained_dict = torch.load(""../renderer.pkl"")\n    model_dict = net.state_dict()\n    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n    model_dict.update(pretrained_dict)\n    net.load_state_dict(model_dict)\n\n\nload_weights()\nwhile step < 500000:\n    net.train()\n    train_batch = []\n    ground_truth = []\n    for i in range(batch_size):\n        f = np.random.uniform(0, 1, 10)\n        train_batch.append(f)\n        ground_truth.append(draw(f))\n\n    train_batch = torch.tensor(train_batch).float()\n    ground_truth = torch.tensor(ground_truth).float()\n    if use_cuda:\n        net = net.cuda()\n        train_batch = train_batch.cuda()\n        ground_truth = ground_truth.cuda()\n    gen = net(train_batch)\n    optimizer.zero_grad()\n    loss = criterion(gen, ground_truth)\n    loss.backward()\n    optimizer.step()\n    print(step, loss.item())\n    if step < 200000:\n        lr = 1e-4\n    elif step < 400000:\n        lr = 1e-5\n    else:\n        lr = 1e-6\n    for param_group in optimizer.param_groups:\n        param_group[""lr""] = lr\n    writer.add_scalar(""train/loss"", loss.item(), step)\n    if step % 100 == 0:\n        net.eval()\n        gen = net(train_batch)\n        loss = criterion(gen, ground_truth)\n        writer.add_scalar(""val/loss"", loss.item(), step)\n        for i in range(32):\n            G = gen[i].cpu().data.numpy()\n            GT = ground_truth[i].cpu().data.numpy()\n            writer.add_image(""train/gen{}.png"".format(i), G, step)\n            writer.add_image(""train/ground_truth{}.png"".format(i), GT, step)\n    if step % 1000 == 0:\n        save_model()\n    step += 1\n'"
baseline/DRL/actor.py,5,"b'import numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils.weight_norm as weightNorm\n\nfrom torch.autograd import Variable\nimport sys\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return (nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False))\n\ndef cfg(depth):\n    depth_lst = [18, 34, 50, 101, 152]\n    assert (depth in depth_lst), ""Error : Resnet depth should be either 18, 34, 50, 101, 152""\n    cf_dict = {\n        \'18\': (BasicBlock, [2,2,2,2]),\n        \'34\': (BasicBlock, [3,4,6,3]),\n        \'50\': (Bottleneck, [3,4,6,3]),\n        \'101\':(Bottleneck, [3,4,23,3]),\n        \'152\':(Bottleneck, [3,8,36,3]),\n    }\n\n    return cf_dict[str(depth)]\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                (nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = (nn.Conv2d(in_planes, planes, kernel_size=1, bias=False))\n        self.conv2 = (nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False))\n        self.conv3 = (nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False))\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                (nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)),\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, num_inputs, depth, num_outputs):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        block, num_blocks = cfg(depth)\n\n        self.conv1 = conv3x3(num_inputs, 64, 2)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=2)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.fc = nn.Linear(512, num_outputs)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = F.avg_pool2d(x, 4)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        x = torch.sigmoid(x)\n        return x\n'"
baseline/DRL/critic.py,5,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils.weight_norm as weightNorm\n\nfrom torch.autograd import Variable\nimport sys\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return weightNorm(nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True))\n\nclass TReLU(nn.Module):\n    def __init__(self):\n        super(TReLU, self).__init__()\n        self.alpha = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n        self.alpha.data.fill_(0)\n        \n    def forward(self, x):\n        x = F.relu(x - self.alpha) + self.alpha\n        return x\n\ndef cfg(depth):\n    depth_lst = [18, 34, 50, 101, 152]\n    assert (depth in depth_lst), ""Error : Resnet depth should be either 18, 34, 50, 101, 152""\n    cf_dict = {\n        \'18\': (BasicBlock, [2,2,2,2]),\n        \'34\': (BasicBlock, [3,4,6,3]),\n        \'50\': (Bottleneck, [3,4,6,3]),\n        \'101\':(Bottleneck, [3,4,23,3]),\n        \'152\':(Bottleneck, [3,8,36,3]),\n    }\n\n    return cf_dict[str(depth)]\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.conv2 = conv3x3(planes, planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                weightNorm(nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True)),\n            )\n        self.relu_1 = TReLU()\n        self.relu_2 = TReLU()\n\n    def forward(self, x):\n        out = self.relu_1(self.conv1(x))\n        out = self.conv2(out)\n        out += self.shortcut(x)\n        out = self.relu_2(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = weightNorm(nn.Conv2d(in_planes, planes, kernel_size=1, bias=True))\n        self.conv2 = weightNorm(nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True))\n        self.conv3 = weightNorm(nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=True))\n        self.relu_1 = TReLU()\n        self.relu_2 = TReLU()\n        self.relu_3 = TReLU()\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                weightNorm(nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True)),\n            )\n\n    def forward(self, x):\n        out = self.relu_1(self.conv1(x))\n        out = self.relu_2(self.conv2(out))\n        out = self.conv3(out)\n        out += self.shortcut(x)\n        out = self.relu_3(out)\n\n        return out\n\nclass ResNet_wobn(nn.Module):\n    def __init__(self, num_inputs, depth, num_outputs):\n        super(ResNet_wobn, self).__init__()\n        self.in_planes = 64\n\n        block, num_blocks = cfg(depth)\n\n        self.conv1 = conv3x3(num_inputs, 64, 2)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=2)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.fc = nn.Linear(512, num_outputs)\n        self.relu_1 = TReLU()\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.relu_1(self.conv1(x))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = F.avg_pool2d(x, 4)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n'"
baseline/DRL/ddpg.py,16,"b'import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom Renderer.model import *\nfrom DRL.rpm import rpm\nfrom DRL.actor import *\nfrom DRL.critic import *\nfrom DRL.wgan import *\nfrom utils.util import *\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\ncoord = torch.zeros([1, 2, 128, 128])\nfor i in range(128):\n    for j in range(128):\n        coord[0, 0, i, j] = i / 127.\n        coord[0, 1, i, j] = j / 127.\ncoord = coord.to(device)\n\ncriterion = nn.MSELoss()\n\nDecoder = FCN()\nDecoder.load_state_dict(torch.load(\'../renderer.pkl\'))\n\ndef decode(x, canvas): # b * (10 + 3)\n    x = x.view(-1, 10 + 3)\n    stroke = 1 - Decoder(x[:, :10])\n    stroke = stroke.view(-1, 128, 128, 1)\n    color_stroke = stroke * x[:, -3:].view(-1, 1, 1, 3)\n    stroke = stroke.permute(0, 3, 1, 2)\n    color_stroke = color_stroke.permute(0, 3, 1, 2)\n    stroke = stroke.view(-1, 5, 1, 128, 128)\n    color_stroke = color_stroke.view(-1, 5, 3, 128, 128)\n    for i in range(5):\n        canvas = canvas * (1 - stroke[:, i]) + color_stroke[:, i]\n    return canvas\n\ndef cal_trans(s, t):\n    return (s.transpose(0, 3) * t).transpose(0, 3)\n    \nclass DDPG(object):\n    def __init__(self, batch_size=64, env_batch=1, max_step=40, \\\n                 tau=0.001, discount=0.9, rmsize=800, \\\n                 writer=None, resume=None, output_path=None):\n\n        self.max_step = max_step\n        self.env_batch = env_batch\n        self.batch_size = batch_size        \n\n        self.actor = ResNet(9, 18, 65) # target, canvas, stepnum, coordconv 3 + 3 + 1 + 2\n        self.actor_target = ResNet(9, 18, 65)\n        self.critic = ResNet_wobn(3 + 9, 18, 1) # add the last canvas for better prediction\n        self.critic_target = ResNet_wobn(3 + 9, 18, 1) \n\n        self.actor_optim  = Adam(self.actor.parameters(), lr=1e-2)\n        self.critic_optim  = Adam(self.critic.parameters(), lr=1e-2)\n\n        if (resume != None):\n            self.load_weights(resume)\n\n        hard_update(self.actor_target, self.actor)\n        hard_update(self.critic_target, self.critic)\n        \n        # Create replay buffer\n        self.memory = rpm(rmsize * max_step)\n\n        # Hyper-parameters\n        self.tau = tau\n        self.discount = discount\n\n        # Tensorboard\n        self.writer = writer\n        self.log = 0\n        \n        self.state = [None] * self.env_batch # Most recent state\n        self.action = [None] * self.env_batch # Most recent action\n        self.choose_device()        \n\n    def play(self, state, target=False):\n        state = torch.cat((state[:, :6].float() / 255, state[:, 6:7].float() / self.max_step, coord.expand(state.shape[0], 2, 128, 128)), 1)\n        if target:\n            return self.actor_target(state)\n        else:\n            return self.actor(state)\n\n    def update_gan(self, state):\n        canvas = state[:, :3]\n        gt = state[:, 3 : 6]\n        fake, real, penal = update(canvas.float() / 255, gt.float() / 255)\n        if self.log % 20 == 0:\n            self.writer.add_scalar(\'train/gan_fake\', fake, self.log)\n            self.writer.add_scalar(\'train/gan_real\', real, self.log)\n            self.writer.add_scalar(\'train/gan_penal\', penal, self.log)       \n        \n    def evaluate(self, state, action, target=False):\n        T = state[:, 6 : 7]\n        gt = state[:, 3 : 6].float() / 255\n        canvas0 = state[:, :3].float() / 255\n        canvas1 = decode(action, canvas0)\n        gan_reward = cal_reward(canvas1, gt) - cal_reward(canvas0, gt)\n        # L2_reward = ((canvas0 - gt) ** 2).mean(1).mean(1).mean(1) - ((canvas1 - gt) ** 2).mean(1).mean(1).mean(1)        \n        coord_ = coord.expand(state.shape[0], 2, 128, 128)\n        merged_state = torch.cat([canvas0, canvas1, gt, (T + 1).float() / self.max_step, coord_], 1)\n        # canvas0 is not necessarily added\n        if target:\n            Q = self.critic_target(merged_state)\n            return (Q + gan_reward), gan_reward\n        else:\n            Q = self.critic(merged_state)\n            if self.log % 20 == 0:\n                self.writer.add_scalar(\'train/expect_reward\', Q.mean(), self.log)\n                self.writer.add_scalar(\'train/gan_reward\', gan_reward.mean(), self.log)\n            return (Q + gan_reward), gan_reward\n    \n    def update_policy(self, lr):\n        self.log += 1\n        \n        for param_group in self.critic_optim.param_groups:\n            param_group[\'lr\'] = lr[0]\n        for param_group in self.actor_optim.param_groups:\n            param_group[\'lr\'] = lr[1]\n            \n        # Sample batch\n        state, action, reward, \\\n            next_state, terminal = self.memory.sample_batch(self.batch_size, device)\n\n        self.update_gan(next_state)\n        \n        with torch.no_grad():\n            next_action = self.play(next_state, True)\n            target_q, _ = self.evaluate(next_state, next_action, True)\n            target_q = self.discount * ((1 - terminal.float()).view(-1, 1)) * target_q\n                \n        cur_q, step_reward = self.evaluate(state, action)\n        target_q += step_reward.detach()\n        \n        value_loss = criterion(cur_q, target_q)\n        self.critic.zero_grad()\n        value_loss.backward(retain_graph=True)\n        self.critic_optim.step()\n\n        action = self.play(state)\n        pre_q, _ = self.evaluate(state.detach(), action)\n        policy_loss = -pre_q.mean()\n        self.actor.zero_grad()\n        policy_loss.backward(retain_graph=True)\n        self.actor_optim.step()\n        \n        # Target update\n        soft_update(self.actor_target, self.actor, self.tau)\n        soft_update(self.critic_target, self.critic, self.tau)\n\n        return -policy_loss, value_loss\n\n    def observe(self, reward, state, done, step):\n        s0 = torch.tensor(self.state, device=\'cpu\')\n        a = to_tensor(self.action, ""cpu"")\n        r = to_tensor(reward, ""cpu"")\n        s1 = torch.tensor(state, device=\'cpu\')\n        d = to_tensor(done.astype(\'float32\'), ""cpu"")\n        for i in range(self.env_batch):\n            self.memory.append([s0[i], a[i], r[i], s1[i], d[i]])\n        self.state = state\n\n    def noise_action(self, noise_factor, state, action):\n        noise = np.zeros(action.shape)\n        for i in range(self.env_batch):\n            action[i] = action[i] + np.random.normal(0, self.noise_level[i], action.shape[1:]).astype(\'float32\')\n        return np.clip(action.astype(\'float32\'), 0, 1)\n    \n    def select_action(self, state, return_fix=False, noise_factor=0):\n        self.eval()\n        with torch.no_grad():\n            action = self.play(state)\n            action = to_numpy(action)\n        if noise_factor > 0:        \n            action = self.noise_action(noise_factor, state, action)\n        self.train()\n        self.action = action\n        if return_fix:\n            return action\n        return self.action\n\n    def reset(self, obs, factor):\n        self.state = obs\n        self.noise_level = np.random.uniform(0, factor, self.env_batch)\n\n    def load_weights(self, path):\n        if path is None: return\n        self.actor.load_state_dict(torch.load(\'{}/actor.pkl\'.format(path)))\n        self.critic.load_state_dict(torch.load(\'{}/critic.pkl\'.format(path)))\n        load_gan(path)\n        \n    def save_model(self, path):\n        self.actor.cpu()\n        self.critic.cpu()\n        torch.save(self.actor.state_dict(),\'{}/actor.pkl\'.format(path))\n        torch.save(self.critic.state_dict(),\'{}/critic.pkl\'.format(path))\n        save_gan(path)\n        self.choose_device()\n\n    def eval(self):\n        self.actor.eval()\n        self.actor_target.eval()\n        self.critic.eval()\n        self.critic_target.eval()\n    \n    def train(self):\n        self.actor.train()\n        self.actor_target.train()\n        self.critic.train()\n        self.critic_target.train()\n    \n    def choose_device(self):\n        Decoder.to(device)\n        self.actor.to(device)\n        self.actor_target.to(device)\n        self.critic.to(device)\n        self.critic_target.to(device)\n'"
baseline/DRL/evaluator.py,0,"b'import numpy as np\nfrom utils.util import *\n\nclass Evaluator(object):\n\n    def __init__(self, args, writer):    \n        self.validate_episodes = args.validate_episodes\n        self.max_step = args.max_step\n        self.env_batch = args.env_batch\n        self.writer = writer\n        self.log = 0\n\n    def __call__(self, env, policy, debug=False):        \n        observation = None\n        for episode in range(self.validate_episodes):\n            # reset at the start of episode\n            observation = env.reset(test=True, episode=episode)\n            episode_steps = 0\n            episode_reward = 0.     \n            assert observation is not None            \n            # start episode\n            episode_reward = np.zeros(self.env_batch)\n            while (episode_steps < self.max_step or not self.max_step):\n                action = policy(observation)\n                observation, reward, done, (step_num) = env.step(action)\n                episode_reward += reward\n                episode_steps += 1\n                env.save_image(self.log, episode_steps)\n            dist = env.get_dist()\n            self.log += 1\n        return episode_reward, dist\n'"
baseline/DRL/multi.py,3,"b'import cv2\nimport torch\nimport numpy as np\nfrom env import Paint\nfrom utils.util import *\nfrom DRL.ddpg import decode\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\nclass fastenv():\n    def __init__(self, \n                 max_episode_length=10, env_batch=64, \\\n                 writer=None):\n        self.max_episode_length = max_episode_length\n        self.env_batch = env_batch\n        self.env = Paint(self.env_batch, self.max_episode_length)\n        self.env.load_data()\n        self.observation_space = self.env.observation_space\n        self.action_space = self.env.action_space\n        self.writer = writer\n        self.test = False\n        self.log = 0\n\n    def save_image(self, log, step):\n        for i in range(self.env_batch):\n            if self.env.imgid[i] <= 10:\n                canvas = cv2.cvtColor((to_numpy(self.env.canvas[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n                self.writer.add_image(\'{}/canvas_{}.png\'.format(str(self.env.imgid[i]), str(step)), canvas, log)\n        if step == self.max_episode_length:\n            for i in range(self.env_batch):\n                if self.env.imgid[i] < 50:\n                    gt = cv2.cvtColor((to_numpy(self.env.gt[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n                    canvas = cv2.cvtColor((to_numpy(self.env.canvas[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n                    self.writer.add_image(str(self.env.imgid[i]) + \'/_target.png\', gt, log)\n                    self.writer.add_image(str(self.env.imgid[i]) + \'/_canvas.png\', canvas, log)\n    \n    def step(self, action):\n        with torch.no_grad():\n            ob, r, d, _ = self.env.step(torch.tensor(action).to(device))\n        if d[0]:\n            if not self.test:\n                self.dist = self.get_dist()\n                for i in range(self.env_batch):\n                    self.writer.add_scalar(\'train/dist\', self.dist[i], self.log)\n                    self.log += 1\n        return ob, r, d, _\n\n    def get_dist(self):\n        return to_numpy((((self.env.gt.float() - self.env.canvas.float()) / 255) ** 2).mean(1).mean(1).mean(1))\n        \n    def reset(self, test=False, episode=0):\n        self.test = test\n        ob = self.env.reset(self.test, episode * self.env_batch)\n        return ob\n'"
baseline/DRL/rpm.py,2,"b""# from collections import deque\nimport numpy as np\nimport random\nimport torch\nimport pickle as pickle\n\nclass rpm(object):\n    # replay memory\n    def __init__(self, buffer_size):\n        self.buffer_size = buffer_size\n        self.buffer = []\n        self.index = 0\n        \n    def append(self, obj):\n        if self.size() > self.buffer_size:\n            print('buffer size larger than set value, trimming...')\n            self.buffer = self.buffer[(self.size() - self.buffer_size):]\n        elif self.size() == self.buffer_size:\n            self.buffer[self.index] = obj\n            self.index += 1\n            self.index %= self.buffer_size\n        else:\n            self.buffer.append(obj)\n\n    def size(self):\n        return len(self.buffer)\n\n    def sample_batch(self, batch_size, device, only_state=False):\n        if self.size() < batch_size:\n            batch = random.sample(self.buffer, self.size())\n        else:\n            batch = random.sample(self.buffer, batch_size)\n\n        if only_state:\n            res = torch.stack(tuple(item[3] for item in batch), dim=0)            \n            return res.to(device)\n        else:\n            item_count = 5\n            res = []\n            for i in range(5):\n                k = torch.stack(tuple(item[i] for item in batch), dim=0)\n                res.append(k.to(device))\n            return res[0], res[1], res[2], res[3], res[4]\n"""
baseline/DRL/wgan.py,15,"b'import torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.optim import Adam, SGD\nfrom torch import autograd\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.autograd import grad as torch_grad\nimport torch.nn.utils.weight_norm as weightNorm\nfrom utils.util import *\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\ndim = 128\nLAMBDA = 10 # Gradient penalty lambda hyperparameter\n\nclass TReLU(nn.Module):\n    def __init__(self):\n            super(TReLU, self).__init__()\n            self.alpha = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n            self.alpha.data.fill_(0)\n\n    def forward(self, x):\n        x = F.relu(x - self.alpha) + self.alpha\n        return x\n\nclass Discriminator(nn.Module):\n        def __init__(self):\n            super(Discriminator, self).__init__()\n\n            self.conv0 = weightNorm(nn.Conv2d(6, 16, 5, 2, 2))\n            self.conv1 = weightNorm(nn.Conv2d(16, 32, 5, 2, 2))\n            self.conv2 = weightNorm(nn.Conv2d(32, 64, 5, 2, 2))\n            self.conv3 = weightNorm(nn.Conv2d(64, 128, 5, 2, 2))\n            self.conv4 = weightNorm(nn.Conv2d(128, 1, 5, 2, 2))\n            self.relu0 = TReLU()\n            self.relu1 = TReLU()\n            self.relu2 = TReLU()\n            self.relu3 = TReLU()\n\n        def forward(self, x):\n            x = self.conv0(x)\n            x = self.relu0(x)\n            x = self.conv1(x)\n            x = self.relu1(x)\n            x = self.conv2(x)\n            x = self.relu2(x)\n            x = self.conv3(x)\n            x = self.relu3(x)\n            x = self.conv4(x)\n            x = F.avg_pool2d(x, 4)\n            x = x.view(-1, 1)\n            return x\n\nnetD = Discriminator()\ntarget_netD = Discriminator()\nnetD = netD.to(device)\ntarget_netD = target_netD.to(device)\nhard_update(target_netD, netD)\n\noptimizerD = Adam(netD.parameters(), lr=3e-4, betas=(0.5, 0.999))\ndef cal_gradient_penalty(netD, real_data, fake_data, batch_size):\n    alpha = torch.rand(batch_size, 1)\n    alpha = alpha.expand(batch_size, int(real_data.nelement()/batch_size)).contiguous()\n    alpha = alpha.view(batch_size, 6, dim, dim)\n    alpha = alpha.to(device)\n    fake_data = fake_data.view(batch_size, 6, dim, dim)\n    interpolates = Variable(alpha * real_data.data + ((1 - alpha) * fake_data.data), requires_grad=True)\n    disc_interpolates = netD(interpolates)\n    gradients = autograd.grad(disc_interpolates, interpolates,\n                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n                              create_graph=True, retain_graph=True)[0]\n    gradients = gradients.view(gradients.size(0), -1)\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n    return gradient_penalty\n\ndef cal_reward(fake_data, real_data):\n    return target_netD(torch.cat([real_data, fake_data], 1))\n\ndef save_gan(path):\n    netD.cpu()\n    torch.save(netD.state_dict(),\'{}/wgan.pkl\'.format(path))\n    netD.to(device)\n\ndef load_gan(path):\n    netD.load_state_dict(torch.load(\'{}/wgan.pkl\'.format(path)))\n\ndef update(fake_data, real_data):\n    fake_data = fake_data.detach()\n    real_data = real_data.detach()\n    fake = torch.cat([real_data, fake_data], 1)\n    real = torch.cat([real_data, real_data], 1)\n    D_real = netD(real)\n    D_fake = netD(fake)\n    gradient_penalty = cal_gradient_penalty(netD, real, fake, real.shape[0])\n    optimizerD.zero_grad()\n    D_cost = D_fake.mean() - D_real.mean() + gradient_penalty\n    D_cost.backward()\n    optimizerD.step()\n    soft_update(target_netD, netD, 0.001)\n    return D_fake.mean(), D_real.mean(), gradient_penalty\n'"
baseline/Renderer/__init__.py,0,b''
baseline/Renderer/model.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils.weight_norm as weightNorm\n\nclass FCN(nn.Module):\n    def __init__(self):\n        super(FCN, self).__init__()\n        self.fc1 = (nn.Linear(10, 512))\n        self.fc2 = (nn.Linear(512, 1024))\n        self.fc3 = (nn.Linear(1024, 2048))\n        self.fc4 = (nn.Linear(2048, 4096))\n        self.conv1 = (nn.Conv2d(16, 32, 3, 1, 1))\n        self.conv2 = (nn.Conv2d(32, 32, 3, 1, 1))\n        self.conv3 = (nn.Conv2d(8, 16, 3, 1, 1))\n        self.conv4 = (nn.Conv2d(16, 16, 3, 1, 1))\n        self.conv5 = (nn.Conv2d(4, 8, 3, 1, 1))\n        self.conv6 = (nn.Conv2d(8, 4, 3, 1, 1))\n        self.pixel_shuffle = nn.PixelShuffle(2)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = x.view(-1, 16, 16, 16)\n        x = F.relu(self.conv1(x))\n        x = self.pixel_shuffle(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = self.pixel_shuffle(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = self.pixel_shuffle(self.conv6(x))\n        x = torch.sigmoid(x)\n        return 1 - x.view(-1, 128, 128)\n'"
baseline/Renderer/stroke_gen.py,0,"b""import cv2\nimport numpy as np\n\ndef normal(x, width):\n    return (int)(x * (width - 1) + 0.5)\n\ndef draw(f, width=128):\n    x0, y0, x1, y1, x2, y2, z0, z2, w0, w2 = f\n    x1 = x0 + (x2 - x0) * x1\n    y1 = y0 + (y2 - y0) * y1\n    x0 = normal(x0, width * 2)\n    x1 = normal(x1, width * 2)\n    x2 = normal(x2, width * 2)\n    y0 = normal(y0, width * 2)\n    y1 = normal(y1, width * 2)\n    y2 = normal(y2, width * 2)\n    z0 = (int)(1 + z0 * width // 2)\n    z2 = (int)(1 + z2 * width // 2)\n    canvas = np.zeros([width * 2, width * 2]).astype('float32')\n    tmp = 1. / 100\n    for i in range(100):\n        t = i * tmp\n        x = (int)((1-t) * (1-t) * x0 + 2 * t * (1-t) * x1 + t * t * x2)\n        y = (int)((1-t) * (1-t) * y0 + 2 * t * (1-t) * y1 + t * t * y2)\n        z = (int)((1-t) * z0 + t * z2)\n        w = (1-t) * w0 + t * w2\n        cv2.circle(canvas, (y, x), z, w, -1)\n    return 1 - cv2.resize(canvas, dsize=(width, width))\n"""
baseline/utils/tensorboard.py,0,"b'import PIL\nimport scipy.misc\nfrom io import BytesIO\nimport tensorboardX as tb\nfrom tensorboardX.summary import Summary\n\nclass TensorBoard(object):\n    def __init__(self, model_dir):\n        self.summary_writer = tb.FileWriter(model_dir)\n\n    def add_image(self, tag, img, step):\n        summary = Summary()\n        bio = BytesIO()\n\n        if type(img) == str:\n            img = PIL.Image.open(img)\n        elif type(img) == PIL.Image.Image:\n            pass\n        else:\n            img = scipy.misc.toimage(img)\n\n        img.save(bio, format=""png"")\n        image_summary = Summary.Image(encoded_image_string=bio.getvalue())\n        summary.value.add(tag=tag, image=image_summary)\n        self.summary_writer.add_summary(summary, global_step=step)\n\n    def add_scalar(self, tag, value, step):\n        summary = Summary(value=[Summary.Value(tag=tag, simple_value=value)])\n        self.summary_writer.add_summary(summary, global_step=step)\n'"
baseline/utils/util.py,3,"b'import os\nimport torch\nfrom torch.autograd import Variable\n\nUSE_CUDA = torch.cuda.is_available()\n\ndef prRed(prt): print(""\\033[91m {}\\033[00m"" .format(prt))\ndef prGreen(prt): print(""\\033[92m {}\\033[00m"" .format(prt))\ndef prYellow(prt): print(""\\033[93m {}\\033[00m"" .format(prt))\ndef prLightPurple(prt): print(""\\033[94m {}\\033[00m"" .format(prt))\ndef prPurple(prt): print(""\\033[95m {}\\033[00m"" .format(prt))\ndef prCyan(prt): print(""\\033[96m {}\\033[00m"" .format(prt))\ndef prLightGray(prt): print(""\\033[97m {}\\033[00m"" .format(prt))\ndef prBlack(prt): print(""\\033[98m {}\\033[00m"" .format(prt))\n\ndef to_numpy(var):\n    return var.cpu().data.numpy() if USE_CUDA else var.data.numpy()\n\ndef to_tensor(ndarray, device):\n    return torch.tensor(ndarray, dtype=torch.float, device=device)\n\ndef soft_update(target, source, tau):\n    for target_param, param in zip(target.parameters(), source.parameters()):\n        target_param.data.copy_(\n            target_param.data * (1.0 - tau) + param.data * tau\n        )\n\ndef hard_update(target, source):\n    for m1, m2 in zip(target.modules(), source.modules()):\n        m1._buffers = m2._buffers.copy()\n    for target_param, param in zip(target.parameters(), source.parameters()):\n            target_param.data.copy_(param.data)\n\ndef get_output_folder(parent_dir, env_name):\n    """"""Return save folder.\n\n    Assumes folders in the parent_dir have suffix -run{run\n    number}. Finds the highest run number and sets the output folder\n    to that number + 1. This is just convenient so that if you run the\n    same script multiple times tensorboard can plot all of the results\n    on the same plots with different names.\n\n    Parameters\n    ----------\n    parent_dir: str\n      Path of the directory containing all experiment runs.\n\n    Returns\n    -------\n    parent_dir/run_dir\n      Path to this run\'s save directory.\n    """"""\n    os.makedirs(parent_dir, exist_ok=True)\n    experiment_id = 0\n    for folder_name in os.listdir(parent_dir):\n        if not os.path.isdir(os.path.join(parent_dir, folder_name)):\n            continue\n        try:\n            folder_name = int(folder_name.split(\'-run\')[-1])\n            if folder_name > experiment_id:\n                experiment_id = folder_name\n        except:\n            pass\n    experiment_id += 1\n\n    parent_dir = os.path.join(parent_dir, env_name)\n    parent_dir = parent_dir + \'-run{}\'.format(experiment_id)\n    os.makedirs(parent_dir, exist_ok=True)\n    return parent_dir\n'"
baseline_modelfree/DRL/actor.py,5,"b'import numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils.weight_norm as weightNorm\n\nfrom torch.autograd import Variable\nimport sys\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return (nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False))\n\ndef cfg(depth):\n    depth_lst = [18, 34, 50, 101, 152]\n    assert (depth in depth_lst), ""Error : Resnet depth should be either 18, 34, 50, 101, 152""\n    cf_dict = {\n        \'18\': (BasicBlock, [2,2,2,2]),\n        \'34\': (BasicBlock, [3,4,6,3]),\n        \'50\': (Bottleneck, [3,4,6,3]),\n        \'101\':(Bottleneck, [3,4,23,3]),\n        \'152\':(Bottleneck, [3,8,36,3]),\n    }\n\n    return cf_dict[str(depth)]\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                (nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = (nn.Conv2d(in_planes, planes, kernel_size=1, bias=False))\n        self.conv2 = (nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False))\n        self.conv3 = (nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False))\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                (nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)),\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, num_inputs, depth, num_outputs):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        block, num_blocks = cfg(depth)\n\n        self.conv1 = conv3x3(num_inputs, 64, 2)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=2)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.fc = nn.Linear(512, num_outputs)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = F.avg_pool2d(x, 4)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        x = torch.sigmoid(x)\n        return x\n'"
baseline_modelfree/DRL/critic.py,9,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils.weight_norm as weightNorm\n\nfrom torch.autograd import Variable\nimport sys\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return weightNorm(nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True))\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\ncoord = torch.zeros([1, 2, 64, 64])\nfor i in range(64):\n    for j in range(64):\n        coord[0, 0, i, j] = i / 63.\n        coord[0, 1, i, j] = j / 63.\n        coord = coord.to(device)        \n\nclass TReLU(nn.Module):\n    def __init__(self):\n        super(TReLU, self).__init__()\n        self.alpha = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n        self.alpha.data.fill_(0)\n        \n    def forward(self, x):\n        x = F.relu(x - self.alpha) + self.alpha\n        return x\n\ndef cfg(depth):\n    depth_lst = [18, 34, 50, 101, 152]\n    assert (depth in depth_lst), ""Error : Resnet depth should be either 18, 34, 50, 101, 152""\n    cf_dict = {\n        \'18\': (BasicBlock, [2,2,2,2]),\n        \'34\': (BasicBlock, [3,4,6,3]),\n        \'50\': (Bottleneck, [3,4,6,3]),\n        \'101\':(Bottleneck, [3,4,23,3]),\n        \'152\':(Bottleneck, [3,8,36,3]),\n    }\n\n    return cf_dict[str(depth)]\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.conv2 = conv3x3(planes, planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                weightNorm(nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True)),\n            )\n        self.relu_1 = TReLU()\n        self.relu_2 = TReLU()\n\n    def forward(self, x):\n        out = self.relu_1(self.conv1(x))\n        out = self.conv2(out)\n        out += self.shortcut(x)\n        out = self.relu_2(out)\n\n        return out\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = weightNorm(nn.Conv2d(in_planes, planes, kernel_size=1, bias=True))\n        self.conv2 = weightNorm(nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True))\n        self.conv3 = weightNorm(nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=True))\n        self.relu_1 = TReLU()\n        self.relu_2 = TReLU()\n        self.relu_3 = TReLU()\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                weightNorm(nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=True)),\n            )\n\n    def forward(self, x):\n        out = self.relu_1(self.conv1(x))\n        out = self.relu_2(self.conv2(out))\n        out = self.conv3(out)\n        out += self.shortcut(x)\n        out = self.relu_3(out)\n\n        return out\n\nclass ResNet_wobn(nn.Module):\n    def __init__(self, num_inputs, depth, num_outputs):\n        super(ResNet_wobn, self).__init__()\n        self.in_planes = 64\n\n        block, num_blocks = cfg(depth)\n        self.conv0 = conv3x3(num_inputs, 32, 2) # 64        \n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=2) # 32\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2) # 16\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=1)\n        self.conv4 = weightNorm(nn.Conv2d(512, 1, 1, 1, 0))\n        self.relu_1 = TReLU()\n        self.conv1 = weightNorm(nn.Conv2d(65 + 2, 64, 1, 1, 0))        \n        self.conv2 = weightNorm(nn.Conv2d(64, 64, 1, 1, 0))\n        self.conv3 = weightNorm(nn.Conv2d(64, 32, 1, 1, 0))\n        self.relu_2 = TReLU()\n        self.relu_3 = TReLU()\n        self.relu_4 = TReLU()\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n\n        return nn.Sequential(*layers)\n\n    def a2img(self, x):\n        tmp = coord.expand(x.shape[0], 2, 64, 64)\n        x = x.repeat(64, 64, 1, 1).permute(2, 3, 0, 1)\n        x = self.relu_2(self.conv1(torch.cat([x, tmp], 1)))\n        x = self.relu_3(self.conv2(x))\n        x = self.relu_4(self.conv3(x))\n        return x\n        \n    def forward(self, input):\n        x, a = input\n        a = self.a2img(a)\n        x = self.relu_1(self.conv0(x))\n        x = torch.cat([x, a], 1)        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.conv4(x)\n        return x.view(x.size(0), 64)\n'"
baseline_modelfree/DRL/ddpg.py,17,"b'import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom Renderer.model import *\nfrom DRL.rpm import rpm\nfrom DRL.actor import *\nfrom DRL.critic import *\nfrom DRL.wgan import *\nfrom utils.util import *\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\ncoord = torch.zeros([1, 2, 128, 128])\nfor i in range(128):\n    for j in range(128):\n        coord[0, 0, i, j] = i / 127.\n        coord[0, 1, i, j] = j / 127.\ncoord = coord.to(device)\n\ncriterion = nn.MSELoss()\n\nDecoder = FCN()\nDecoder.load_state_dict(torch.load(\'../renderer.pkl\'))\n\ndef decode(x, canvas): # b * (10 + 3)\n    x = x.view(-1, 10 + 3)\n    stroke = 1 - Decoder(x[:, :10])\n    stroke = stroke.view(-1, 128, 128, 1)\n    color_stroke = stroke * x[:, -3:].view(-1, 1, 1, 3)\n    stroke = stroke.permute(0, 3, 1, 2)\n    color_stroke = color_stroke.permute(0, 3, 1, 2)\n    stroke = stroke.view(-1, 5, 1, 128, 128)\n    color_stroke = color_stroke.view(-1, 5, 3, 128, 128)\n    for i in range(5):\n        canvas = canvas * (1 - stroke[:, i]) + color_stroke[:, i]\n    return canvas\n\ndef cal_trans(s, t):\n    return (s.transpose(0, 3) * t).transpose(0, 3)\n    \nclass DDPG(object):\n    def __init__(self, batch_size=64, env_batch=1, max_step=40, \\\n                 tau=0.001, discount=0.9, rmsize=800, \\\n                 writer=None, resume=None, output_path=None):\n\n        self.max_step = max_step\n        self.env_batch = env_batch\n        self.batch_size = batch_size        \n\n        self.actor = ResNet(9, 18, 65) # target, canvas, stepnum, coordconv 3 + 3 + 1 + 2\n        self.actor_target = ResNet(9, 18, 65)\n        self.critic = ResNet_wobn(9, 18, 1)\n        self.critic_target = ResNet_wobn(9, 18, 1) \n\n        self.actor_optim  = Adam(self.actor.parameters(), lr=1e-2)\n        self.critic_optim  = Adam(self.critic.parameters(), lr=1e-2)\n\n        if (resume != None):\n            self.load_weights(resume)\n\n        hard_update(self.actor_target, self.actor)\n        hard_update(self.critic_target, self.critic)\n        \n        # Create replay buffer\n        self.memory = rpm(rmsize * max_step)\n\n        # Hyper-parameters\n        self.tau = tau\n        self.discount = discount\n\n        # Tensorboard\n        self.writer = writer\n        self.log = 0\n        \n        self.state = [None] * self.env_batch # Most recent state\n        self.action = [None] * self.env_batch # Most recent action\n        self.choose_device()        \n\n    def play(self, state, target=False):\n        state = torch.cat((state[:, :6].float() / 255, state[:, 6:7].float() / self.max_step, coord.expand(state.shape[0], 2, 128, 128)), 1)\n        if target:\n            return self.actor_target(state)\n        else:\n            return self.actor(state)\n\n    def update_gan(self, state):\n        canvas = state[:, :3]\n        gt = state[:, 3 : 6]\n        fake, real, penal = update(canvas.float() / 255, gt.float() / 255)\n        if self.log % 20 == 0:\n            self.writer.add_scalar(\'train/gan_fake\', fake, self.log)\n            self.writer.add_scalar(\'train/gan_real\', real, self.log)\n            self.writer.add_scalar(\'train/gan_penal\', penal, self.log)       \n        \n    def evaluate(self, state, action, target=False):\n        T = state[:, 6 : 7]\n        gt = state[:, 3 : 6].float() / 255\n        canvas0 = state[:, :3].float() / 255\n        with torch.no_grad(): # model free\n            canvas1 = decode(action, canvas0)\n        gan_reward = cal_reward(canvas1, gt) - cal_reward(canvas0, gt) # (batchsize, 64)\n        # L2_reward = ((canvas0 - gt) ** 2).mean(1).mean(1).mean(1) - ((canvas1 - gt) ** 2).mean(1).mean(1).mean(1)        \n        coord_ = coord.expand(state.shape[0], 2, 128, 128)\n        merged_state = torch.cat([canvas0, gt, (T + 1).float() / self.max_step, coord_], 1)\n        if target:\n            Q = self.critic_target([merged_state, action])\n            return Q, gan_reward\n        else:\n            Q = self.critic([merged_state, action])\n            if self.log % 20 == 0:\n                self.writer.add_scalar(\'train/expect_reward\', Q.mean(), self.log)\n                self.writer.add_scalar(\'train/gan_reward\', gan_reward.mean(), self.log)\n            return Q, gan_reward\n    \n    def update_policy(self, lr):\n        self.log += 1\n        \n        for param_group in self.critic_optim.param_groups:\n            param_group[\'lr\'] = lr[0]\n        for param_group in self.actor_optim.param_groups:\n            param_group[\'lr\'] = lr[1]\n            \n        # Sample batch\n        state, action, reward, \\\n            next_state, terminal = self.memory.sample_batch(self.batch_size, device)\n\n        self.update_gan(next_state)\n        \n        with torch.no_grad():\n            next_action = self.play(next_state, True)\n            target_q, _ = self.evaluate(next_state, next_action, True)\n            target_q = self.discount * ((1 - terminal.float()).view(-1, 1)) * target_q\n                \n        cur_q, step_reward = self.evaluate(state, action)\n        target_q += step_reward.detach()\n        \n        value_loss = criterion(cur_q, target_q)\n        self.critic.zero_grad()\n        value_loss.backward(retain_graph=True)\n        self.critic_optim.step()\n\n        action = self.play(state)\n        pre_q, _ = self.evaluate(state.detach(), action)\n        policy_loss = -pre_q.mean()\n        self.actor.zero_grad()\n        policy_loss.backward(retain_graph=True)\n        self.actor_optim.step()\n        \n        # Target update\n        soft_update(self.actor_target, self.actor, self.tau)\n        soft_update(self.critic_target, self.critic, self.tau)\n\n        return -policy_loss, value_loss\n\n    def observe(self, reward, state, done, step):\n        s0 = torch.tensor(self.state, device=\'cpu\')\n        a = to_tensor(self.action, ""cpu"")\n        r = to_tensor(reward, ""cpu"")\n        s1 = torch.tensor(state, device=\'cpu\')\n        d = to_tensor(done.astype(\'float32\'), ""cpu"")\n        for i in range(self.env_batch):\n            self.memory.append([s0[i], a[i], r[i], s1[i], d[i]])\n        self.state = state\n\n    def noise_action(self, noise_factor, state, action):\n        noise = np.zeros(action.shape)\n        for i in range(self.env_batch):\n            action[i] = action[i] + np.random.normal(0, self.noise_level[i], action.shape[1:]).astype(\'float32\')\n        return np.clip(action.astype(\'float32\'), 0, 1)\n    \n    def select_action(self, state, return_fix=False, noise_factor=0):\n        self.eval()\n        with torch.no_grad():\n            action = self.play(state)\n            action = to_numpy(action)\n        if noise_factor > 0:        \n            action = self.noise_action(noise_factor, state, action)\n        self.train()\n        self.action = action\n        if return_fix:\n            return action\n        return self.action\n\n    def reset(self, obs, factor):\n        self.state = obs\n        self.noise_level = np.random.uniform(0, factor, self.env_batch)\n\n    def load_weights(self, path):\n        if path is None: return\n        self.actor.load_state_dict(torch.load(\'{}/actor.pkl\'.format(path)))\n        self.critic.load_state_dict(torch.load(\'{}/critic.pkl\'.format(path)))\n        load_gan(path)\n        \n    def save_model(self, path):\n        self.actor.cpu()\n        self.critic.cpu()\n        torch.save(self.actor.state_dict(),\'{}/actor.pkl\'.format(path))\n        torch.save(self.critic.state_dict(),\'{}/critic.pkl\'.format(path))\n        save_gan(path)\n        self.choose_device()\n\n    def eval(self):\n        self.actor.eval()\n        self.actor_target.eval()\n        self.critic.eval()\n        self.critic_target.eval()\n    \n    def train(self):\n        self.actor.train()\n        self.actor_target.train()\n        self.critic.train()\n        self.critic_target.train()\n    \n    def choose_device(self):\n        Decoder.to(device)\n        self.actor.to(device)\n        self.actor_target.to(device)\n        self.critic.to(device)\n        self.critic_target.to(device)\n'"
baseline_modelfree/DRL/evaluator.py,0,"b'import numpy as np\nfrom utils.util import *\n\nclass Evaluator(object):\n\n    def __init__(self, args, writer):    \n        self.validate_episodes = args.validate_episodes\n        self.max_step = args.max_step\n        self.env_batch = args.env_batch\n        self.writer = writer\n        self.log = 0\n\n    def __call__(self, env, policy, debug=False):        \n        observation = None\n        for episode in range(self.validate_episodes):\n            # reset at the start of episode\n            observation = env.reset(test=True, episode=episode)\n            episode_steps = 0\n            episode_reward = 0.     \n            assert observation is not None            \n            # start episode\n            episode_reward = np.zeros(self.env_batch)\n            while (episode_steps < self.max_step or not self.max_step):\n                action = policy(observation)\n                observation, reward, done, (step_num) = env.step(action)\n                episode_reward += reward\n                episode_steps += 1\n                env.save_image(self.log, episode_steps)\n            dist = env.get_dist()\n            self.log += 1\n        return episode_reward, dist\n'"
baseline_modelfree/DRL/multi.py,3,"b'import cv2\nimport torch\nimport numpy as np\nfrom env import Paint\nfrom utils.util import *\nfrom DRL.ddpg import decode\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\nclass fastenv():\n    def __init__(self, \n                 max_episode_length=10, env_batch=64, \\\n                 writer=None):\n        self.max_episode_length = max_episode_length\n        self.env_batch = env_batch\n        self.env = Paint(self.env_batch, self.max_episode_length)\n        self.env.load_data()\n        self.observation_space = self.env.observation_space\n        self.action_space = self.env.action_space\n        self.writer = writer\n        self.test = False\n        self.log = 0\n\n    def save_image(self, log, step):\n        for i in range(self.env_batch):\n            if self.env.imgid[i] <= 10:\n                canvas = cv2.cvtColor((to_numpy(self.env.canvas[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n                self.writer.add_image(\'{}/canvas_{}.png\'.format(str(self.env.imgid[i]), str(step)), canvas, log)\n        if step == self.max_episode_length:\n            for i in range(self.env_batch):\n                if self.env.imgid[i] < 50:\n                    gt = cv2.cvtColor((to_numpy(self.env.gt[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n                    canvas = cv2.cvtColor((to_numpy(self.env.canvas[i].permute(1, 2, 0))), cv2.COLOR_BGR2RGB)\n                    self.writer.add_image(str(self.env.imgid[i]) + \'/_target.png\', gt, log)\n                    self.writer.add_image(str(self.env.imgid[i]) + \'/_canvas.png\', canvas, log)\n    \n    def step(self, action):\n        with torch.no_grad():\n            ob, r, d, _ = self.env.step(torch.tensor(action).to(device))\n        if d[0]:\n            if not self.test:\n                self.dist = self.get_dist()\n                for i in range(self.env_batch):\n                    self.writer.add_scalar(\'train/dist\', self.dist[i], self.log)\n                    self.log += 1\n        return ob, r, d, _\n\n    def get_dist(self):\n        return to_numpy((((self.env.gt.float() - self.env.canvas.float()) / 255) ** 2).mean(1).mean(1).mean(1))\n        \n    def reset(self, test=False, episode=0):\n        self.test = test\n        ob = self.env.reset(self.test, episode * self.env_batch)\n        return ob\n'"
baseline_modelfree/DRL/rpm.py,2,"b""# from collections import deque\nimport numpy as np\nimport random\nimport torch\nimport pickle as pickle\n\nclass rpm(object):\n    # replay memory\n    def __init__(self, buffer_size):\n        self.buffer_size = buffer_size\n        self.buffer = []\n        self.index = 0\n        \n    def append(self, obj):\n        if self.size() > self.buffer_size:\n            print('buffer size larger than set value, trimming...')\n            self.buffer = self.buffer[(self.size() - self.buffer_size):]\n        elif self.size() == self.buffer_size:\n            self.buffer[self.index] = obj\n            self.index += 1\n            self.index %= self.buffer_size\n        else:\n            self.buffer.append(obj)\n\n    def size(self):\n        return len(self.buffer)\n\n    def sample_batch(self, batch_size, device, only_state=False):\n        if self.size() < batch_size:\n            batch = random.sample(self.buffer, self.size())\n        else:\n            batch = random.sample(self.buffer, batch_size)\n\n        if only_state:\n            res = torch.stack(tuple(item[3] for item in batch), dim=0)            \n            return res.to(device)\n        else:\n            item_count = 5\n            res = []\n            for i in range(5):\n                k = torch.stack(tuple(item[i] for item in batch), dim=0)\n                res.append(k.to(device))\n            return res[0], res[1], res[2], res[3], res[4]\n"""
baseline_modelfree/DRL/wgan.py,15,"b'import torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.optim import Adam, SGD\nfrom torch import autograd\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.autograd import grad as torch_grad\nimport torch.nn.utils.weight_norm as weightNorm\nfrom utils.util import *\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\ndim = 128\nLAMBDA = 10 # Gradient penalty lambda hyperparameter\n\nclass TReLU(nn.Module):\n    def __init__(self):\n            super(TReLU, self).__init__()\n            self.alpha = nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n            self.alpha.data.fill_(0)\n\n    def forward(self, x):\n        x = F.relu(x - self.alpha) + self.alpha\n        return x\n\nclass Discriminator(nn.Module):\n        def __init__(self):\n            super(Discriminator, self).__init__()\n\n            self.conv0 = weightNorm(nn.Conv2d(6, 16, 5, 2, 2))\n            self.conv1 = weightNorm(nn.Conv2d(16, 32, 5, 2, 2))\n            self.conv2 = weightNorm(nn.Conv2d(32, 64, 5, 2, 2))\n            self.conv3 = weightNorm(nn.Conv2d(64, 128, 5, 2, 2))\n            self.conv4 = weightNorm(nn.Conv2d(128, 1, 1, 1, 0))\n            self.relu0 = TReLU()\n            self.relu1 = TReLU()\n            self.relu2 = TReLU()\n            self.relu3 = TReLU()\n\n        def forward(self, x):\n            x = self.conv0(x)\n            x = self.relu0(x)\n            x = self.conv1(x)\n            x = self.relu1(x)\n            x = self.conv2(x)\n            x = self.relu2(x)\n            x = self.conv3(x)\n            x = self.relu3(x)\n            x = self.conv4(x)\n            x = x.view(-1, 64) # Patch Q\n            return x\n\nnetD = Discriminator()\ntarget_netD = Discriminator()\nnetD = netD.to(device)\ntarget_netD = target_netD.to(device)\nhard_update(target_netD, netD)\n\noptimizerD = Adam(netD.parameters(), lr=3e-4, betas=(0.5, 0.999))\ndef cal_gradient_penalty(netD, real_data, fake_data, batch_size):\n    alpha = torch.rand(batch_size, 1)\n    alpha = alpha.expand(batch_size, int(real_data.nelement()/batch_size)).contiguous()\n    alpha = alpha.view(batch_size, 6, dim, dim)\n    alpha = alpha.to(device)\n    fake_data = fake_data.view(batch_size, 6, dim, dim)\n    interpolates = Variable(alpha * real_data.data + ((1 - alpha) * fake_data.data), requires_grad=True)\n    disc_interpolates = netD(interpolates)\n    gradients = autograd.grad(disc_interpolates, interpolates,\n                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n                              create_graph=True, retain_graph=True)[0]\n    gradients = gradients.view(gradients.size(0), -1)\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n    return gradient_penalty\n\ndef cal_reward(fake_data, real_data):\n    return target_netD(torch.cat([real_data, fake_data], 1))\n\ndef save_gan(path):\n    netD.cpu()\n    torch.save(netD.state_dict(),\'{}/wgan.pkl\'.format(path))\n    netD.to(device)\n\ndef load_gan(path):\n    netD.load_state_dict(torch.load(\'{}/wgan.pkl\'.format(path)))\n\ndef update(fake_data, real_data):\n    fake_data = fake_data.detach()\n    real_data = real_data.detach()\n    fake = torch.cat([real_data, fake_data], 1)\n    real = torch.cat([real_data, real_data], 1)\n    D_real = netD(real)\n    D_fake = netD(fake)\n    gradient_penalty = cal_gradient_penalty(netD, real, fake, real.shape[0])\n    optimizerD.zero_grad()\n    D_cost = D_fake.mean() - D_real.mean() + gradient_penalty\n    D_cost.backward()\n    optimizerD.step()\n    soft_update(target_netD, netD, 0.001)\n    return D_fake.mean(), D_real.mean(), gradient_penalty\n'"
baseline_modelfree/Renderer/__init__.py,0,b''
baseline_modelfree/Renderer/model.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils.weight_norm as weightNorm\n\nclass FCN(nn.Module):\n    def __init__(self):\n        super(FCN, self).__init__()\n        self.fc1 = (nn.Linear(10, 512))\n        self.fc2 = (nn.Linear(512, 1024))\n        self.fc3 = (nn.Linear(1024, 2048))\n        self.fc4 = (nn.Linear(2048, 4096))\n        self.conv1 = (nn.Conv2d(16, 32, 3, 1, 1))\n        self.conv2 = (nn.Conv2d(32, 32, 3, 1, 1))\n        self.conv3 = (nn.Conv2d(8, 16, 3, 1, 1))\n        self.conv4 = (nn.Conv2d(16, 16, 3, 1, 1))\n        self.conv5 = (nn.Conv2d(4, 8, 3, 1, 1))\n        self.conv6 = (nn.Conv2d(8, 4, 3, 1, 1))\n        self.pixel_shuffle = nn.PixelShuffle(2)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = x.view(-1, 16, 16, 16)\n        x = F.relu(self.conv1(x))\n        x = self.pixel_shuffle(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = self.pixel_shuffle(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = self.pixel_shuffle(self.conv6(x))\n        x = torch.sigmoid(x)\n        return 1 - x.view(-1, 128, 128)\n'"
baseline_modelfree/Renderer/stroke_gen.py,0,"b""import cv2\nimport numpy as np\n\ndef normal(x, width):\n    return (int)(x * (width - 1) + 0.5)\n\ndef draw(f, width=128):\n    x0, y0, x1, y1, x2, y2, z0, z2, w0, w2 = f\n    x1 = x0 + (x2 - x0) * x1\n    y1 = y0 + (y2 - y0) * y1\n    x0 = normal(x0, width * 2)\n    x1 = normal(x1, width * 2)\n    x2 = normal(x2, width * 2)\n    y0 = normal(y0, width * 2)\n    y1 = normal(y1, width * 2)\n    y2 = normal(y2, width * 2)\n    z0 = (int)(1 + z0 * width // 2)\n    z2 = (int)(1 + z2 * width // 2)\n    canvas = np.zeros([width * 2, width * 2]).astype('float32')\n    tmp = 1. / 100\n    for i in range(100):\n        t = i * tmp\n        x = (int)((1-t) * (1-t) * x0 + 2 * t * (1-t) * x1 + t * t * x2)\n        y = (int)((1-t) * (1-t) * y0 + 2 * t * (1-t) * y1 + t * t * y2)\n        z = (int)((1-t) * z0 + t * z2)\n        w = (1-t) * w0 + t * w2\n        cv2.circle(canvas, (y, x), z, w, -1)\n    return 1 - cv2.resize(canvas, dsize=(width, width))\n"""
baseline_modelfree/utils/tensorboard.py,0,"b'import PIL\nimport scipy.misc\nfrom io import BytesIO\nimport tensorboardX as tb\nfrom tensorboardX.summary import Summary\n\nclass TensorBoard(object):\n    def __init__(self, model_dir):\n        self.summary_writer = tb.FileWriter(model_dir)\n\n    def add_image(self, tag, img, step):\n        summary = Summary()\n        bio = BytesIO()\n\n        if type(img) == str:\n            img = PIL.Image.open(img)\n        elif type(img) == PIL.Image.Image:\n            pass\n        else:\n            img = PIL.Image.fromarray(img)\n\n        img.save(bio, format=""png"")\n        image_summary = Summary.Image(encoded_image_string=bio.getvalue())\n        summary.value.add(tag=tag, image=image_summary)\n        self.summary_writer.add_summary(summary, global_step=step)\n\n    def add_scalar(self, tag, value, step):\n        summary = Summary(value=[Summary.Value(tag=tag, simple_value=value)])\n        self.summary_writer.add_summary(summary, global_step=step)\n'"
baseline_modelfree/utils/util.py,3,"b'import os\nimport torch\nfrom torch.autograd import Variable\n\nUSE_CUDA = torch.cuda.is_available()\n\ndef prRed(prt): print(""\\033[91m {}\\033[00m"" .format(prt))\ndef prGreen(prt): print(""\\033[92m {}\\033[00m"" .format(prt))\ndef prYellow(prt): print(""\\033[93m {}\\033[00m"" .format(prt))\ndef prLightPurple(prt): print(""\\033[94m {}\\033[00m"" .format(prt))\ndef prPurple(prt): print(""\\033[95m {}\\033[00m"" .format(prt))\ndef prCyan(prt): print(""\\033[96m {}\\033[00m"" .format(prt))\ndef prLightGray(prt): print(""\\033[97m {}\\033[00m"" .format(prt))\ndef prBlack(prt): print(""\\033[98m {}\\033[00m"" .format(prt))\n\ndef to_numpy(var):\n    return var.cpu().data.numpy() if USE_CUDA else var.data.numpy()\n\ndef to_tensor(ndarray, device):\n    return torch.tensor(ndarray, dtype=torch.float, device=device)\n\ndef soft_update(target, source, tau):\n    for target_param, param in zip(target.parameters(), source.parameters()):\n        target_param.data.copy_(\n            target_param.data * (1.0 - tau) + param.data * tau\n        )\n\ndef hard_update(target, source):\n    for m1, m2 in zip(target.modules(), source.modules()):\n        m1._buffers = m2._buffers.copy()\n    for target_param, param in zip(target.parameters(), source.parameters()):\n            target_param.data.copy_(param.data)\n\ndef get_output_folder(parent_dir, env_name):\n    """"""Return save folder.\n\n    Assumes folders in the parent_dir have suffix -run{run\n    number}. Finds the highest run number and sets the output folder\n    to that number + 1. This is just convenient so that if you run the\n    same script multiple times tensorboard can plot all of the results\n    on the same plots with different names.\n\n    Parameters\n    ----------\n    parent_dir: str\n      Path of the directory containing all experiment runs.\n\n    Returns\n    -------\n    parent_dir/run_dir\n      Path to this run\'s save directory.\n    """"""\n    os.makedirs(parent_dir, exist_ok=True)\n    experiment_id = 0\n    for folder_name in os.listdir(parent_dir):\n        if not os.path.isdir(os.path.join(parent_dir, folder_name)):\n            continue\n        try:\n            folder_name = int(folder_name.split(\'-run\')[-1])\n            if folder_name > experiment_id:\n                experiment_id = folder_name\n        except:\n            pass\n    experiment_id += 1\n\n    parent_dir = os.path.join(parent_dir, env_name)\n    parent_dir = parent_dir + \'-run{}\'.format(experiment_id)\n    os.makedirs(parent_dir, exist_ok=True)\n    return parent_dir\n'"
