file_path,api_count,code
test.py,10,"b""import numpy as np\nimport os\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.utils.data as data\nfrom config import get_test_config\nfrom data import ModelNet40\nfrom models import MeshNet\nfrom utils import append_feature, calculate_map\n\n\ncfg = get_test_config()\nos.environ['CUDA_VISIBLE_DEVICES'] = cfg['cuda_devices']\n\n\ndata_set = ModelNet40(cfg=cfg['dataset'], part='test')\ndata_loader = data.DataLoader(data_set, batch_size=1, num_workers=4, shuffle=True, pin_memory=False)\n\n\ndef test_model(model):\n\n    correct_num = 0\n    ft_all, lbl_all = None, None\n\n    for i, (centers, corners, normals, neighbor_index, targets) in enumerate(data_loader):\n        centers = Variable(torch.cuda.FloatTensor(centers.cuda()))\n        corners = Variable(torch.cuda.FloatTensor(corners.cuda()))\n        normals = Variable(torch.cuda.FloatTensor(normals.cuda()))\n        neighbor_index = Variable(torch.cuda.LongTensor(neighbor_index.cuda()))\n        targets = Variable(torch.cuda.LongTensor(targets.cuda()))\n\n        outputs, feas = model(centers, corners, normals, neighbor_index)\n        _, preds = torch.max(outputs, 1)\n\n        if preds[0] == targets[0]:\n            correct_num += 1\n\n        ft_all = append_feature(ft_all, feas.detach())\n        lbl_all = append_feature(lbl_all, targets.detach(), flaten=True)\n\n    print('Accuracy: {:.4f}'.format(float(correct_num) / len(data_set)))\n    print('mAP: {:.4f}'.format(calculate_map(ft_all, lbl_all)))\n\n\nif __name__ == '__main__':\n\n    model = MeshNet(cfg=cfg['MeshNet'], require_fea=True)\n    model.cuda()\n    model = nn.DataParallel(model)\n    model.load_state_dict(torch.load(cfg['load_model']))\n    model.eval()\n\n    test_model(model)\n"""
train.py,14,"b""import copy\nimport os\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nfrom config import get_train_config\nfrom data import ModelNet40\nfrom models import MeshNet\nfrom utils import append_feature, calculate_map\n\n\ncfg = get_train_config()\nos.environ['CUDA_VISIBLE_DEVICES'] = cfg['cuda_devices']\n\n\ndata_set = {\n    x: ModelNet40(cfg=cfg['dataset'], part=x) for x in ['train', 'test']\n}\ndata_loader = {\n    x: data.DataLoader(data_set[x], batch_size=cfg['batch_size'], num_workers=4, shuffle=True, pin_memory=False)\n    for x in ['train', 'test']\n}\n\n\ndef train_model(model, criterion, optimizer, scheduler, cfg):\n\n    best_acc = 0.0\n    best_map = 0.0\n    best_model_wts = copy.deepcopy(model.state_dict())\n\n    for epoch in range(1, cfg['max_epoch']):\n\n        print('-' * 60)\n        print('Epoch: {} / {}'.format(epoch, cfg['max_epoch']))\n        print('-' * 60)\n\n        for phrase in ['train', 'test']:\n\n            if phrase == 'train':\n                scheduler.step()\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n            ft_all, lbl_all = None, None\n\n            for i, (centers, corners, normals, neighbor_index, targets) in enumerate(data_loader[phrase]):\n\n                optimizer.zero_grad()\n\n                centers = Variable(torch.cuda.FloatTensor(centers.cuda()))\n                corners = Variable(torch.cuda.FloatTensor(corners.cuda()))\n                normals = Variable(torch.cuda.FloatTensor(normals.cuda()))\n                neighbor_index = Variable(torch.cuda.LongTensor(neighbor_index.cuda()))\n                targets = Variable(torch.cuda.LongTensor(targets.cuda()))\n\n                with torch.set_grad_enabled(phrase == 'train'):\n                    outputs, feas = model(centers, corners, normals, neighbor_index)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, targets)\n\n                    if phrase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    if phrase == 'test':\n                        ft_all = append_feature(ft_all, feas.detach())\n                        lbl_all = append_feature(lbl_all, targets.detach(), flaten=True)\n\n                    running_loss += loss.item() * centers.size(0)\n                    running_corrects += torch.sum(preds == targets.data)\n\n            epoch_loss = running_loss / len(data_set[phrase])\n            epoch_acc = running_corrects.double() / len(data_set[phrase])\n\n            if phrase == 'train':\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phrase, epoch_loss, epoch_acc))\n\n            if phrase == 'test':\n                epoch_map = calculate_map(ft_all, lbl_all)\n                if epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                if epoch_map > best_map:\n                    best_map = epoch_map\n                if epoch % 10 == 0:\n                    torch.save(copy.deepcopy(model.state_dict()), 'ckpt_root/{}.pkl'.format(epoch))\n\n                print('{} Loss: {:.4f} Acc: {:.4f} mAP: {:.4f}'.format(phrase, epoch_loss, epoch_acc, epoch_map))\n\n    return best_model_wts\n\n\nif __name__ == '__main__':\n\n    model = MeshNet(cfg=cfg['MeshNet'], require_fea=True)\n    model.cuda()\n    model = nn.DataParallel(model)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=cfg['lr'], momentum=cfg['momentum'], weight_decay=cfg['weight_decay'])\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=cfg['milestones'], gamma=cfg['gamma'])\n\n    best_model_wts = train_model(model, criterion, optimizer, scheduler, cfg)\n    torch.save(best_model_wts, os.path.join(cfg['ckpt'], 'MeshNet_best.pkl'))\n"""
config/__init__.py,0,"b'from .config import get_train_config, get_test_config\n'"
config/config.py,0,"b""import os\nimport os.path as osp\nimport yaml\n\n\ndef _check_dir(dir, make_dir=True):\n    if not osp.exists(dir):\n        if make_dir:\n            print('Create directory {}'.format(dir))\n            os.mkdir(dir)\n        else:\n            raise Exception('Directory not exist: {}'.format(dir))\n\n\ndef get_train_config(config_file='config/train_config.yaml'):\n    with open(config_file, 'r') as f:\n        cfg = yaml.load(f)\n\n    _check_dir(cfg['dataset']['data_root'], make_dir=False)\n    _check_dir(cfg['ckpt_root'])\n\n    return cfg\n\n\ndef get_test_config(config_file='config/test_config.yaml'):\n    with open(config_file, 'r') as f:\n        cfg = yaml.load(f)\n\n    _check_dir(cfg['dataset']['data_root'], make_dir=False)\n\n    return cfg\n"""
data/ModelNet40.py,5,"b""import numpy as np\nimport os\nimport torch\nimport torch.utils.data as data\n\ntype_to_index_map = {\n    'night_stand': 0, 'range_hood': 1, 'plant': 2, 'chair': 3, 'tent': 4,\n    'curtain': 5, 'piano': 6, 'dresser': 7, 'desk': 8, 'bed': 9,\n    'sink': 10,  'laptop':11, 'flower_pot': 12, 'car': 13, 'stool': 14,\n    'vase': 15, 'monitor': 16, 'airplane': 17, 'stairs': 18, 'glass_box': 19,\n    'bottle': 20, 'guitar': 21, 'cone': 22,  'toilet': 23, 'bathtub': 24,\n    'wardrobe': 25, 'radio': 26,  'person': 27, 'xbox': 28, 'bowl': 29,\n    'cup': 30, 'door': 31,  'tv_stand': 32,  'mantel': 33, 'sofa': 34,\n    'keyboard': 35, 'bookshelf': 36,  'bench': 37, 'table': 38, 'lamp': 39\n}\n\n\nclass ModelNet40(data.Dataset):\n\n    def __init__(self, cfg, part='train'):\n        self.root = cfg['data_root']\n        self.augment_data = cfg['augment_data']\n        self.max_faces = cfg['max_faces']\n        self.part = part\n\n        self.data = []\n        for type in os.listdir(self.root):\n            type_index = type_to_index_map[type]\n            type_root = os.path.join(os.path.join(self.root, type), part)\n            for filename in os.listdir(type_root):\n                if filename.endswith('.npz'):\n                    self.data.append((os.path.join(type_root, filename), type_index))\n\n    def __getitem__(self, i):\n        path, type = self.data[i]\n        data = np.load(path)\n        face = data['face']\n        neighbor_index = data['neighbor_index']\n\n        # data augmentation\n        if self.augment_data and self.part == 'train':\n            sigma, clip = 0.01, 0.05\n            jittered_data = np.clip(sigma * np.random.randn(*face[:, :12].shape), -1 * clip, clip)\n            face = np.concatenate((face[:, :12] + jittered_data, face[:, 12:]), 1)\n\n        # fill for n < max_faces with randomly picked faces\n        num_point = len(face)\n        if num_point < self.max_faces:\n            fill_face = []\n            fill_neighbor_index = []\n            for i in range(self.max_faces - num_point):\n                index = np.random.randint(0, num_point)\n                fill_face.append(face[index])\n                fill_neighbor_index.append(neighbor_index[index])\n            face = np.concatenate((face, np.array(fill_face)))\n            neighbor_index = np.concatenate((neighbor_index, np.array(fill_neighbor_index)))\n\n        # to tensor\n        face = torch.from_numpy(face).float()\n        neighbor_index = torch.from_numpy(neighbor_index).long()\n        target = torch.tensor(type, dtype=torch.long)\n\n        # reorganize\n        face = face.permute(1, 0).contiguous()\n        centers, corners, normals = face[:3], face[3:12], face[12:]\n        corners = corners - torch.cat([centers, centers, centers], 0)\n\n        return centers, corners, normals, neighbor_index, target\n\n    def __len__(self):\n        return len(self.data)\n"""
data/__init__.py,0,b'from .ModelNet40 import ModelNet40\n'
data/preprocess.py,0,"b""import glob as glob\nimport numpy as np\nimport os\nimport pymesh\n\n\ndef find_neighbor(faces, faces_contain_this_vertex, vf1, vf2, except_face):\n    for i in (faces_contain_this_vertex[vf1] & faces_contain_this_vertex[vf2]):\n        if i != except_face:\n            face = faces[i].tolist()\n            face.remove(vf1)\n            face.remove(vf2)\n            return i\n\n    return except_face\n\n\nif __name__ == '__main__':\n\n    root = 'ModelNet40_simplification'\n    new_root = 'ModelNet40_MeshNet'\n\n    for type in os.listdir(root):\n        for phrase in ['train', 'test']:\n            type_path = os.path.join(root, type)\n            phrase_path = os.path.join(type_path, phrase)\n            if not os.path.exists(type_path):\n                os.mkdir(os.path.join(new_root, type))\n            if not os.path.exists(phrase_path):\n                os.mkdir(phrase)\n\n            files = glob.glob(os.path.join(phrase_path, '*.off'))\n            for file in files:\n                # load mesh\n                mesh = pymesh.load_mesh(file)\n\n                # clean up\n                mesh, _ = pymesh.remove_isolated_vertices(mesh)\n                mesh, _ = pymesh.remove_duplicated_vertices(mesh)\n\n                # get elements\n                vertices = mesh.vertices.copy()\n                faces = mesh.faces.copy()\n\n                # move to center\n                center = (np.max(vertices, 0) + np.min(vertices, 0)) / 2\n                vertices -= center\n\n                # normalize\n                max_len = np.max(vertices[:, 0]**2 + vertices[:, 1]**2 + vertices[:, 2]**2)\n                vertices /= np.sqrt(max_len)\n\n                # get normal vector\n                mesh = pymesh.form_mesh(vertices, faces)\n                mesh.add_attribute('face_normal')\n                face_normal = mesh.get_face_attribute('face_normal')\n\n                # get neighbors\n                faces_contain_this_vertex = []\n                for i in range(len(vertices)):\n                    faces_contain_this_vertex.append(set([]))\n                centers = []\n                corners = []\n                for i in range(len(faces)):\n                    [v1, v2, v3] = faces[i]\n                    x1, y1, z1 = vertices[v1]\n                    x2, y2, z2 = vertices[v2]\n                    x3, y3, z3 = vertices[v3]\n                    centers.append([(x1 + x2 + x3) / 3, (y1 + y2 + y3) / 3, (z1 + z2 + z3) / 3])\n                    corners.append([x1, y1, z1, x2, y2, z2, x3, y3, z3])\n                    faces_contain_this_vertex[v1].add(i)\n                    faces_contain_this_vertex[v2].add(i)\n                    faces_contain_this_vertex[v3].add(i)\n\n                neighbors = []\n                for i in range(len(faces)):\n                    [v1, v2, v3] = faces[i]\n                    n1 = find_neighbor(faces, faces_contain_this_vertex, v1, v2, i)\n                    n2 = find_neighbor(faces, faces_contain_this_vertex, v2, v3, i)\n                    n3 = find_neighbor(faces, faces_contain_this_vertex, v3, v1, i)\n                    neighbors.append([n1, n2, n3])\n\n                centers = np.array(centers)\n                corners = np.array(corners)\n                faces = np.concatenate([centers, corners, face_normal], axis=1)\n                neighbors = np.array(neighbors)\n\n                _, filename = os.path.split(file)\n                np.savez(new_root + type + '/' + phrase + '/' + filename[:-4] + '.npz',\n                         faces=faces, neighbors=neighbors)\n\n                print(file)\n"""
models/MeshNet.py,5,"b""import torch\nimport torch.nn as nn\nfrom models import SpatialDescriptor, StructuralDescriptor, MeshConvolution\n\n\nclass MeshNet(nn.Module):\n\n    def __init__(self, cfg, require_fea=False):\n        super(MeshNet, self).__init__()\n        self.require_fea = require_fea\n\n        self.spatial_descriptor = SpatialDescriptor()\n        self.structural_descriptor = StructuralDescriptor(cfg['structural_descriptor'])\n        self.mesh_conv1 = MeshConvolution(cfg['mesh_convolution'], 64, 131, 256, 256)\n        self.mesh_conv2 = MeshConvolution(cfg['mesh_convolution'], 256, 256, 512, 512)\n        self.fusion_mlp = nn.Sequential(\n            nn.Conv1d(1024, 1024, 1),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n        )\n        self.concat_mlp = nn.Sequential(\n            nn.Conv1d(1792, 1024, 1),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(256, 40)\n        )\n\n    def forward(self, centers, corners, normals, neighbor_index):\n        spatial_fea0 = self.spatial_descriptor(centers)\n        structural_fea0 = self.structural_descriptor(corners, normals, neighbor_index)\n\n        spatial_fea1, structural_fea1 = self.mesh_conv1(spatial_fea0, structural_fea0, neighbor_index)\n        spatial_fea2, structural_fea2 = self.mesh_conv2(spatial_fea1, structural_fea1, neighbor_index)\n        spatial_fea3 = self.fusion_mlp(torch.cat([spatial_fea2, structural_fea2], 1))\n\n        fea = self.concat_mlp(torch.cat([spatial_fea1, spatial_fea2, spatial_fea3], 1))\n        fea = torch.max(fea, dim=2)[0]\n        fea = fea.reshape(fea.size(0), -1)\n        fea = self.classifier[:-1](fea)\n        cls = self.classifier[-1:](fea)\n\n        if self.require_fea:\n            return cls, fea / torch.norm(fea)\n        else:\n            return cls\n"""
models/__init__.py,0,"b'from .layers import SpatialDescriptor, StructuralDescriptor, MeshConvolution\nfrom .MeshNet import MeshNet\n'"
models/layers.py,23,"b""import numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn.parameter import Parameter\n\n\nclass FaceRotateConvolution(nn.Module):\n\n    def __init__(self):\n        super(FaceRotateConvolution, self).__init__()\n        self.rotate_mlp = nn.Sequential(\n            nn.Conv1d(6, 32, 1),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Conv1d(32, 32, 1),\n            nn.BatchNorm1d(32),\n            nn.ReLU()\n        )\n        self.fusion_mlp = nn.Sequential(\n            nn.Conv1d(32, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU()\n        )\n\n    def forward(self, corners):\n\n        fea = (self.rotate_mlp(corners[:, :6]) +\n               self.rotate_mlp(corners[:, 3:9]) +\n               self.rotate_mlp(torch.cat([corners[:, 6:], corners[:, :3]], 1))) / 3\n\n        return self.fusion_mlp(fea)\n\n\nclass FaceKernelCorrelation(nn.Module):\n\n    def __init__(self, num_kernel=64, sigma=0.2):\n        super(FaceKernelCorrelation, self).__init__()\n        self.num_kernel = num_kernel\n        self.sigma = sigma\n        self.weight_alpha = Parameter(torch.rand(1, num_kernel, 4) * np.pi)\n        self.weight_beta = Parameter(torch.rand(1, num_kernel, 4) * 2 * np.pi)\n        self.bn = nn.BatchNorm1d(num_kernel)\n        self.relu = nn.ReLU()\n\n    def forward(self, normals, neighbor_index):\n\n        b, _, n = normals.size()\n\n        center = normals.unsqueeze(2).expand(-1, -1, self.num_kernel, -1).unsqueeze(4)\n        neighbor = torch.gather(normals.unsqueeze(3).expand(-1, -1, -1, 3), 2,\n                                neighbor_index.unsqueeze(1).expand(-1, 3, -1, -1))\n        neighbor = neighbor.unsqueeze(2).expand(-1, -1, self.num_kernel, -1, -1)\n\n        fea = torch.cat([center, neighbor], 4)\n        fea = fea.unsqueeze(5).expand(-1, -1, -1, -1, -1, 4)\n        weight = torch.cat([torch.sin(self.weight_alpha) * torch.cos(self.weight_beta),\n                            torch.sin(self.weight_alpha) * torch.sin(self.weight_beta),\n                            torch.cos(self.weight_alpha)], 0)\n        weight = weight.unsqueeze(0).expand(b, -1, -1, -1)\n        weight = weight.unsqueeze(3).expand(-1, -1, -1, n, -1)\n        weight = weight.unsqueeze(4).expand(-1, -1, -1, -1, 4, -1)\n\n        dist = torch.sum((fea - weight)**2, 1)\n        fea = torch.sum(torch.sum(np.e**(dist / (-2 * self.sigma**2)), 4), 3) / 16\n\n        return self.relu(self.bn(fea))\n\n\nclass SpatialDescriptor(nn.Module):\n\n    def __init__(self):\n        super(SpatialDescriptor, self).__init__()\n\n        self.spatial_mlp = nn.Sequential(\n            nn.Conv1d(3, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n        )\n\n    def forward(self, centers):\n        return self.spatial_mlp(centers)\n\n\nclass StructuralDescriptor(nn.Module):\n\n    def __init__(self, cfg):\n        super(StructuralDescriptor, self).__init__()\n\n        self.FRC = FaceRotateConvolution()\n        self.FKC = FaceKernelCorrelation(cfg['num_kernel'], cfg['sigma'])\n        self.structural_mlp = nn.Sequential(\n            nn.Conv1d(64 + 3 + cfg['num_kernel'], 131, 1),\n            nn.BatchNorm1d(131),\n            nn.ReLU(),\n            nn.Conv1d(131, 131, 1),\n            nn.BatchNorm1d(131),\n            nn.ReLU(),\n        )\n\n    def forward(self, corners, normals, neighbor_index):\n        structural_fea1 = self.FRC(corners)\n        structural_fea2 = self.FKC(normals, neighbor_index)\n\n        return self.structural_mlp(torch.cat([structural_fea1, structural_fea2, normals], 1))\n\n\nclass MeshConvolution(nn.Module):\n\n    def __init__(self, cfg, spatial_in_channel, structural_in_channel, spatial_out_channel, structural_out_channel):\n        super(MeshConvolution, self).__init__()\n\n        self.spatial_in_channel = spatial_in_channel\n        self.structural_in_channel = structural_in_channel\n        self.spatial_out_channel = spatial_out_channel\n        self.structural_out_channel = structural_out_channel\n\n        assert cfg['aggregation_method'] in ['Concat', 'Max', 'Average']\n        self.aggregation_method = cfg['aggregation_method']\n\n        self.combination_mlp = nn.Sequential(\n            nn.Conv1d(self.spatial_in_channel + self.structural_in_channel, self.spatial_out_channel, 1),\n            nn.BatchNorm1d(self.spatial_out_channel),\n            nn.ReLU(),\n        )\n\n        if self.aggregation_method == 'Concat':\n            self.concat_mlp = nn.Sequential(\n                nn.Conv2d(self.structural_in_channel * 2, self.structural_in_channel, 1),\n                nn.BatchNorm2d(self.structural_in_channel),\n                nn.ReLU(),\n            )\n\n        self.aggregation_mlp = nn.Sequential(\n            nn.Conv1d(self.structural_in_channel, self.structural_out_channel, 1),\n            nn.BatchNorm1d(self.structural_out_channel),\n            nn.ReLU(),\n        )\n\n    def forward(self, spatial_fea, structural_fea, neighbor_index):\n        b, _, n = spatial_fea.size()\n\n        # Combination\n        spatial_fea = self.combination_mlp(torch.cat([spatial_fea, structural_fea], 1))\n\n        # Aggregation\n        if self.aggregation_method == 'Concat':\n            structural_fea = torch.cat([structural_fea.unsqueeze(3).expand(-1, -1, -1, 3),\n                                        torch.gather(structural_fea.unsqueeze(3).expand(-1, -1, -1, 3), 2,\n                                                     neighbor_index.unsqueeze(1).expand(-1, self.structural_in_channel,\n                                                                                        -1, -1))], 1)\n            structural_fea = self.concat_mlp(structural_fea)\n            structural_fea = torch.max(structural_fea, 3)[0]\n\n        elif self.aggregation_method == 'Max':\n            structural_fea = torch.cat([structural_fea.unsqueeze(3),\n                                        torch.gather(structural_fea.unsqueeze(3).expand(-1, -1, -1, 3), 2,\n                                                     neighbor_index.unsqueeze(1).expand(-1, self.structural_in_channel,\n                                                                                        -1, -1))], 3)\n            structural_fea = torch.max(structural_fea, 3)[0]\n\n        elif self.aggregation_method == 'Average':\n            structural_fea = torch.cat([structural_fea.unsqueeze(3),\n                                        torch.gather(structural_fea.unsqueeze(3).expand(-1, -1, -1, 3), 2,\n                                                     neighbor_index.unsqueeze(1).expand(-1, self.structural_in_channel,\n                                                                                        -1, -1))], 3)\n            structural_fea = torch.sum(structural_fea, dim=3) / 4\n\n        structural_fea = self.aggregation_mlp(structural_fea)\n\n        return spatial_fea, structural_fea\n"""
utils/__init__.py,0,"b'from .retrival import append_feature, calculate_map\n'"
utils/retrival.py,0,"b""import os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# all 2468 shapes\ntop_k = 1000\n\n\ndef append_feature(raw, data, flaten=False):\n    data = np.array(data)\n    if flaten:\n        data = data.reshape(-1, 1)\n    if raw is None:\n        raw = np.array(data)\n    else:\n        raw = np.vstack((raw, data))\n    return raw\n\n\ndef Eu_dis_mat_fast(X):\n    aa = np.sum(np.multiply(X, X), 1)\n    ab = X*X.T\n    D = aa+aa.T - 2*ab\n    D[D<0] = 0\n    D = np.sqrt(D)\n    D = np.maximum(D, D.T)\n    return D\n\n\ndef calculate_map(fts, lbls, dis_mat=None):\n    if dis_mat is None:\n        dis_mat = Eu_dis_mat_fast(np.mat(fts))\n    num = len(lbls)\n    mAP = 0\n    for i in range(num):\n        scores = dis_mat[:, i]\n        targets = (lbls == lbls[i]).astype(np.uint8)\n        sortind = np.argsort(scores, 0)[:top_k]\n        truth = targets[sortind]\n        sum = 0\n        precision = []\n        for j in range(top_k):\n            if truth[j]:\n                sum+=1\n                precision.append(sum*1.0/(j + 1))\n        if len(precision) == 0:\n            ap = 0\n        else:\n            for ii in range(len(precision)):\n                precision[ii] = max(precision[ii:])\n            ap = np.array(precision).mean()\n        mAP += ap\n        # print(f'{i+1}/{num}\\tap:{ap:.3f}\\t')\n    mAP = mAP/num\n    return mAP\n\n\ndef cal_pr(cfg, des_mat, lbls, save=True, draw=False):\n    num = len(lbls)\n    precisions = []\n    recalls = []\n    ans = []\n    for i in range(num):\n        scores = des_mat[:, i]\n        targets = (lbls == lbls[i]).astype(np.uint8)\n        sortind = np.argsort(scores, 0)[:top_k]\n        truth = targets[sortind]\n        tmp = 0\n        sum = truth[:top_k].sum()\n        precision = []\n        recall = []\n        for j in range(top_k):\n            if truth[j]:\n                tmp+=1\n                # precision.append(sum/(j + 1))\n            recall.append(tmp*1.0/sum)\n            precision.append(tmp*1.0/(j+1))\n        precisions.append(precision)\n        for j in range(len(precision)):\n            precision[j] = max(precision[j:])\n        recalls.append(recall)\n        tmp = []\n        for ii in range(11):\n            min_des = 100\n            val = 0\n            for j in range(top_k):\n                if abs(recall[j] - ii * 0.1) < min_des:\n                    min_des = abs(recall[j] - ii * 0.1)\n                    val = precision[j]\n            tmp.append(val)\n        print('%d/%d'%(i+1, num))\n        ans.append(tmp)\n    ans = np.array(ans).mean(0)\n    if save:\n        save_dir = os.path.join(cfg.result_sub_folder, 'pr.csv')\n        np.savetxt(save_dir, np.array(ans), fmt='%.3f', delimiter=',')\n    if draw:\n        plt.plot(ans)\n        plt.show()\n\n\ndef test():\n    scores = [0.23, 0.76, 0.01, 0.91, 0.13, 0.45, 0.12, 0.03, 0.38, 0.11, 0.03, 0.09, 0.65, 0.07, 0.12, 0.24, 0.1, 0.23, 0.46, 0.08]\n    gt_label = [0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n    scores = np.array(scores)\n    targets = np.array(gt_label).astype(np.uint8)\n    sortind = np.argsort(scores, 0)[::-1]\n    truth = targets[sortind]\n    sum = 0\n    precision = []\n    for j in range(20):\n        if truth[j]:\n            sum += 1\n            precision.append(sum / (j + 1))\n    if len(precision) == 0:\n        ap = 0\n    else:\n        for i in range(len(precision)):\n            precision[i] = max(precision[i:])\n        ap = np.array(precision).mean()\n    print(ap)\n\n\nif __name__ == '__main__':\n    test()\n"""
