file_path,api_count,code
main.py,1,"b'from __future__ import print_function\n\nimport argparse\n\nfrom torch.utils.data import DataLoader\n\nfrom DBPN.solver import DBPNTrainer\nfrom DRCN.solver import DRCNTrainer\nfrom EDSR.solver import EDSRTrainer\nfrom FSRCNN.solver import FSRCNNTrainer\nfrom SRCNN.solver import SRCNNTrainer\nfrom SRGAN.solver import SRGANTrainer\nfrom SubPixelCNN.solver import SubPixelTrainer\nfrom VDSR.solver import VDSRTrainer\nfrom dataset.data import get_training_set, get_test_set\n\n# ===========================================================\n# Training settings\n# ===========================================================\nparser = argparse.ArgumentParser(description=\'PyTorch Super Res Example\')\n# hyper-parameters\nparser.add_argument(\'--batchSize\', type=int, default=1, help=\'training batch size\')\nparser.add_argument(\'--testBatchSize\', type=int, default=1, help=\'testing batch size\')\nparser.add_argument(\'--nEpochs\', type=int, default=20, help=\'number of epochs to train for\')\nparser.add_argument(\'--lr\', type=float, default=0.01, help=\'Learning Rate. Default=0.01\')\nparser.add_argument(\'--seed\', type=int, default=123, help=\'random seed to use. Default=123\')\n\n# model configuration\nparser.add_argument(\'--upscale_factor\', \'-uf\',  type=int, default=4, help=""super resolution upscale factor"")\nparser.add_argument(\'--model\', \'-m\', type=str, default=\'srgan\', help=\'choose which model is going to use\')\n\nargs = parser.parse_args()\n\n\ndef main():\n    # ===========================================================\n    # Set train dataset & test dataset\n    # ===========================================================\n    print(\'===> Loading datasets\')\n    train_set = get_training_set(args.upscale_factor)\n    test_set = get_test_set(args.upscale_factor)\n    training_data_loader = DataLoader(dataset=train_set, batch_size=args.batchSize, shuffle=True)\n    testing_data_loader = DataLoader(dataset=test_set, batch_size=args.testBatchSize, shuffle=False)\n\n    if args.model == \'sub\':\n        model = SubPixelTrainer(args, training_data_loader, testing_data_loader)\n    elif args.model == \'srcnn\':\n        model = SRCNNTrainer(args, training_data_loader, testing_data_loader)\n    elif args.model == \'vdsr\':\n        model = VDSRTrainer(args, training_data_loader, testing_data_loader)\n    elif args.model == \'edsr\':\n        model = EDSRTrainer(args, training_data_loader, testing_data_loader)\n    elif args.model == \'fsrcnn\':\n        model = FSRCNNTrainer(args, training_data_loader, testing_data_loader)\n    elif args.model == \'drcn\':\n        model = DRCNTrainer(args, training_data_loader, testing_data_loader)\n    elif args.model == \'srgan\':\n        model = SRGANTrainer(args, training_data_loader, testing_data_loader)\n    elif args.model == \'dbpn\':\n        model = DBPNTrainer(args, training_data_loader, testing_data_loader)\n    else:\n        raise Exception(""the model does not exist"")\n\n    model.run()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
progress_bar.py,0,"b""import sys\nimport time\n\nTOTAL_BAR_LENGTH = 80\nLAST_T = time.time()\nBEGIN_T = LAST_T\n\n\ndef progress_bar(current, total, msg=None):\n    global LAST_T, BEGIN_T\n    if current == 0:\n        BEGIN_T = time.time()  # Reset for new bar.\n\n    current_len = int(TOTAL_BAR_LENGTH * (current + 1) / total)\n    rest_len = int(TOTAL_BAR_LENGTH - current_len) - 1\n\n    sys.stdout.write(' %d/%d' % (current + 1, total))\n    sys.stdout.write(' [')\n    for i in range(current_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    current_time = time.time()\n    step_time = current_time - LAST_T\n    LAST_T = current_time\n    total_time = current_time - BEGIN_T\n\n    time_used = '  Step: %s' % format_time(step_time)\n    time_used += ' | Tot: %s' % format_time(total_time)\n    if msg:\n        time_used += ' | ' + msg\n\n    msg = time_used\n    sys.stdout.write(msg)\n\n    if current < total - 1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\n\n# return the formatted time\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    seconds_final = int(seconds)\n    seconds = seconds - seconds_final\n    millis = int(seconds*1000)\n\n    output = ''\n    time_index = 1\n    if days > 0:\n        output += str(days) + 'D'\n        time_index += 1\n    if hours > 0 and time_index <= 2:\n        output += str(hours) + 'h'\n        time_index += 1\n    if minutes > 0 and time_index <= 2:\n        output += str(minutes) + 'm'\n        time_index += 1\n    if seconds_final > 0 and time_index <= 2:\n        output += str(seconds_final) + 's'\n        time_index += 1\n    if millis > 0 and time_index <= 2:\n        output += str(millis) + 'ms'\n        time_index += 1\n    if output == '':\n        output = '0ms'\n    return output\n"""
super_resolve.py,4,"b""from __future__ import print_function\nimport argparse\nimport torch\nimport torch.backends.cudnn as cudnn\nfrom PIL import Image\nfrom torchvision.transforms import ToTensor\n\nimport numpy as np\n\n# ===========================================================\n# Argument settings\n# ===========================================================\nparser = argparse.ArgumentParser(description='PyTorch Super Res Example')\nparser.add_argument('--input', type=str, required=False, default='/home/ic/Desktop/super-resolution/dataset/BSDS300/images/val/3096.jpg', help='input image to use')\nparser.add_argument('--model', type=str, default='model_path.pth', help='model file to use')\nparser.add_argument('--output', type=str, default='test.jpg', help='where to save the output image')\nargs = parser.parse_args()\nprint(args)\n\n\n# ===========================================================\n# input image setting\n# ===========================================================\nGPU_IN_USE = torch.cuda.is_available()\nimg = Image.open(args.input).convert('YCbCr')\ny, cb, cr = img.split()\n\n\n# ===========================================================\n# model import & setting\n# ===========================================================\ndevice = torch.device('cuda' if GPU_IN_USE else 'cpu')\nmodel = torch.load(args.model, map_location=lambda storage, loc: storage)\nmodel = model.to(device)\ndata = (ToTensor()(y)).view(1, -1, y.size[1], y.size[0])\ndata = data.to(device)\n\nif GPU_IN_USE:\n    cudnn.benchmark = True\n\n\n# ===========================================================\n# output and save image\n# ===========================================================\nout = model(data)\nout = out.cpu()\nout_img_y = out.data[0].numpy()\nout_img_y *= 255.0\nout_img_y = out_img_y.clip(0, 255)\nout_img_y = Image.fromarray(np.uint8(out_img_y[0]), mode='L')\n\nout_img_cb = cb.resize(out_img_y.size, Image.BICUBIC)\nout_img_cr = cr.resize(out_img_y.size, Image.BICUBIC)\nout_img = Image.merge('YCbCr', [out_img_y, out_img_cb, out_img_cr]).convert('RGB')\n\nout_img.save(args.output)\nprint('output image saved to ', args.output)\n"""
DBPN/model.py,105,"b'import torch\nimport math\nimport torch.nn as nn\n\n\nclass DBPN(nn.Module):\n    def __init__(self, num_channels, base_channels, feat_channels, num_stages, scale_factor):\n        super(DBPN, self).__init__()\n\n        if scale_factor == 2:\n            kernel_size = 6\n            stride = 2\n            padding = 2\n        elif scale_factor == 4:\n            kernel_size = 8\n            stride = 4\n            padding = 2\n        elif scale_factor == 8:\n            kernel_size = 12\n            stride = 8\n            padding = 2\n        else:\n            kernel_size = None\n            stride = None\n            padding = None\n            Warning(""please choose the scale factor from 2, 4, 8"")\n            exit()\n\n        # Initial Feature Extraction\n        self.feat0 = ConvBlock(num_channels, feat_channels, 3, 1, 1, activation=\'prelu\', norm=None)\n        self.feat1 = ConvBlock(feat_channels, base_channels, 1, 1, 0, activation=\'prelu\', norm=None)\n        # Back-projection stages\n        self.up1 = UpBlock(base_channels, kernel_size, stride, padding)\n        self.down1 = DownBlock(base_channels, kernel_size, stride, padding)\n        self.up2 = UpBlock(base_channels, kernel_size, stride, padding)\n        self.down2 = D_DownBlock(base_channels, kernel_size, stride, padding, 2)\n        self.up3 = D_UpBlock(base_channels, kernel_size, stride, padding, 2)\n        self.down3 = D_DownBlock(base_channels, kernel_size, stride, padding, 3)\n        self.up4 = D_UpBlock(base_channels, kernel_size, stride, padding, 3)\n        self.down4 = D_DownBlock(base_channels, kernel_size, stride, padding, 4)\n        self.up5 = D_UpBlock(base_channels, kernel_size, stride, padding, 4)\n        self.down5 = D_DownBlock(base_channels, kernel_size, stride, padding, 5)\n        self.up6 = D_UpBlock(base_channels, kernel_size, stride, padding, 5)\n        self.down6 = D_DownBlock(base_channels, kernel_size, stride, padding, 6)\n        self.up7 = D_UpBlock(base_channels, kernel_size, stride, padding, 6)\n        # Reconstruction\n        self.output_conv = ConvBlock(num_stages * base_channels, num_channels, 3, 1, 1, activation=None, norm=None)\n\n    def weight_init(self):\n        for m in self._modules:\n            class_name = m.__class__.__name__\n            if class_name.find(\'Conv2d\') != -1:\n                torch.nn.init.kaiming_normal(m.weight)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif class_name.find(\'ConvTranspose2d\') != -1:\n                torch.nn.init.kaiming_normal(m.weight)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def forward(self, x):\n        x = self.feat0(x)\n        x = self.feat1(x)\n\n        h1 = self.up1(x)\n        l1 = self.down1(h1)\n        h2 = self.up2(l1)\n\n        concat_h = torch.cat((h2, h1), 1)\n        l = self.down2(concat_h)\n\n        concat_l = torch.cat((l, l1), 1)\n        h = self.up3(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down3(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up4(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down4(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up5(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down5(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up6(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down6(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up7(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        x = self.output_conv(concat_h)\n\n        return x\n\n\nclass DBPNS(nn.Module):\n    def __init__(self, num_channels, base_channels, feat_channels, num_stages, scale_factor):\n        super(DBPNS, self).__init__()\n\n        if scale_factor == 2:\n            kernel_size = 6\n            stride = 2\n            padding = 2\n        elif scale_factor == 4:\n            kernel_size = 8\n            stride = 4\n            padding = 2\n        elif scale_factor == 8:\n            kernel_size = 12\n            stride = 8\n            padding = 2\n        else:\n            kernel_size = None\n            stride = None\n            padding = None\n            Warning(""please choose the scale factor from 2, 4, 8"")\n            exit()\n\n        # Initial Feature Extraction\n        self.feat0 = ConvBlock(num_channels, feat_channels, 3, 1, 1, activation=\'prelu\', norm=None)\n        self.feat1 = ConvBlock(feat_channels, base_channels, 1, 1, 0, activation=\'prelu\', norm=None)\n        # Back-projection stages\n        self.up1 = UpBlock(base_channels, kernel_size, stride, padding)\n        self.down1 = DownBlock(base_channels, kernel_size, stride, padding)\n        self.up2 = UpBlock(base_channels, kernel_size, stride, padding)\n        # Reconstruction\n        self.output_conv = ConvBlock(num_stages * base_channels, num_channels, 3, 1, 1, activation=None, norm=None)\n\n    def weight_init(self):\n        for m in self._modules:\n            class_name = m.__class__.__name__\n            if class_name.find(\'Conv2d\') != -1:\n                torch.nn.init.kaiming_normal(m.weight)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif class_name.find(\'ConvTranspose2d\') != -1:\n                torch.nn.init.kaiming_normal(m.weight)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def forward(self, x):\n        x = self.feat0(x)\n        x = self.feat1(x)\n\n        h1 = self.up1(x)\n        h2 = self.up2(self.down1(h1))\n\n        x = self.output_conv(torch.cat((h2, h1), 1))\n\n        return x\n\n\nclass DBPNLL(nn.Module):\n    def __init__(self, num_channels, base_channels, feat_channels, num_stages, scale_factor):\n        super(DBPNLL, self).__init__()\n\n        if scale_factor == 2:\n            kernel_size = 6\n            stride = 2\n            padding = 2\n        elif scale_factor == 4:\n            kernel_size = 8\n            stride = 4\n            padding = 2\n        elif scale_factor == 8:\n            kernel_size = 12\n            stride = 8\n            padding = 2\n        else:\n            kernel_size = None\n            stride = None\n            padding = None\n            Warning(""please choose the scale factor from 2, 4, 8"")\n            exit()\n\n        # Initial Feature Extraction\n        self.feat0 = ConvBlock(num_channels, feat_channels, 3, 1, 1, activation=\'prelu\', norm=None)\n        self.feat1 = ConvBlock(feat_channels, base_channels, 1, 1, 0, activation=\'prelu\', norm=None)\n        # Back-projection stages\n        self.up1 = UpBlock(base_channels, kernel_size, stride, padding)\n        self.down1 = DownBlock(base_channels, kernel_size, stride, padding)\n        self.up2 = UpBlock(base_channels, kernel_size, stride, padding)\n        self.down2 = D_DownBlock(base_channels, kernel_size, stride, padding, 2)\n        self.up3 = D_UpBlock(base_channels, kernel_size, stride, padding, 2)\n        self.down3 = D_DownBlock(base_channels, kernel_size, stride, padding, 3)\n        self.up4 = D_UpBlock(base_channels, kernel_size, stride, padding, 3)\n        self.down4 = D_DownBlock(base_channels, kernel_size, stride, padding, 4)\n        self.up5 = D_UpBlock(base_channels, kernel_size, stride, padding, 4)\n        self.down5 = D_DownBlock(base_channels, kernel_size, stride, padding, 5)\n        self.up6 = D_UpBlock(base_channels, kernel_size, stride, padding, 5)\n        self.down6 = D_DownBlock(base_channels, kernel_size, stride, padding, 6)\n        self.up7 = D_UpBlock(base_channels, kernel_size, stride, padding, 6)\n        self.down7 = D_DownBlock(base_channels, kernel_size, stride, padding, 7)\n        self.up8 = D_UpBlock(base_channels, kernel_size, stride, padding, 7)\n        self.down8 = D_DownBlock(base_channels, kernel_size, stride, padding, 8)\n        self.up9 = D_UpBlock(base_channels, kernel_size, stride, padding, 8)\n        self.down9 = D_DownBlock(base_channels, kernel_size, stride, padding, 9)\n        self.up10 = D_UpBlock(base_channels, kernel_size, stride, padding, 9)\n        # Reconstruction\n        self.output_conv = ConvBlock(num_stages * base_channels, num_channels, 3, 1, 1, activation=None, norm=None)\n\n    def weight_init(self):\n        for m in self._modules:\n            class_name = m.__class__.__name__\n            if class_name.find(\'Conv2d\') != -1:\n                torch.nn.init.kaiming_normal(m.weight)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif class_name.find(\'ConvTranspose2d\') != -1:\n                torch.nn.init.kaiming_normal(m.weight)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n\n    def forward(self, x):\n        x = self.feat0(x)\n        x = self.feat1(x)\n\n        h1 = self.up1(x)\n        l1 = self.down1(h1)\n        h2 = self.up2(l1)\n\n        concat_h = torch.cat((h2, h1), 1)\n        l = self.down2(concat_h)\n\n        concat_l = torch.cat((l, l1), 1)\n        h = self.up3(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down3(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up4(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down4(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up5(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down5(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up6(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down6(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up7(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down7(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up8(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down8(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up9(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        l = self.down9(concat_h)\n\n        concat_l = torch.cat((l, concat_l), 1)\n        h = self.up10(concat_l)\n\n        concat_h = torch.cat((h, concat_h), 1)\n        x = self.output_conv(concat_h)\n\n        return x\n\n\n############################################################################################\n# Base models\n############################################################################################\n\n\nclass DenseBlock(torch.nn.Module):\n    def __init__(self, input_size, output_size, bias=True, activation=\'relu\', norm=\'batch\'):\n        super(DenseBlock, self).__init__()\n        self.fc = torch.nn.Linear(input_size, output_size, bias=bias)\n\n        self.norm = norm\n        if self.norm == \'batch\':\n            self.bn = torch.nn.BatchNorm1d(output_size)\n        elif self.norm == \'instance\':\n            self.bn = torch.nn.InstanceNorm1d(output_size)\n\n        self.activation = activation\n        if self.activation == \'relu\':\n            self.act = torch.nn.ReLU(True)\n        elif self.activation == \'prelu\':\n            self.act = torch.nn.PReLU()\n        elif self.activation == \'lrelu\':\n            self.act = torch.nn.LeakyReLU(0.2, True)\n        elif self.activation == \'tanh\':\n            self.act = torch.nn.Tanh()\n        elif self.activation == \'sigmoid\':\n            self.act = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        if self.norm is not None:\n            out = self.bn(self.fc(x))\n        else:\n            out = self.fc(x)\n\n        if self.activation is not None:\n            return self.act(out)\n        else:\n            return out\n\n\nclass ConvBlock(torch.nn.Module):\n    def __init__(self, input_size, output_size, kernel_size=3, stride=1, padding=1, bias=True, activation=\'prelu\',\n                 norm=None):\n        super(ConvBlock, self).__init__()\n        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n\n        self.norm = norm\n        if self.norm == \'batch\':\n            self.bn = torch.nn.BatchNorm2d(output_size)\n        elif self.norm == \'instance\':\n            self.bn = torch.nn.InstanceNorm2d(output_size)\n\n        self.activation = activation\n        if self.activation == \'relu\':\n            self.act = torch.nn.ReLU(True)\n        elif self.activation == \'prelu\':\n            self.act = torch.nn.PReLU()\n        elif self.activation == \'lrelu\':\n            self.act = torch.nn.LeakyReLU(0.2, True)\n        elif self.activation == \'tanh\':\n            self.act = torch.nn.Tanh()\n        elif self.activation == \'sigmoid\':\n            self.act = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        if self.norm is not None:\n            out = self.bn(self.conv(x))\n        else:\n            out = self.conv(x)\n\n        if self.activation is not None:\n            return self.act(out)\n        else:\n            return out\n\n\nclass DeconvBlock(torch.nn.Module):\n    def __init__(self, input_size, output_size, kernel_size=4, stride=2, padding=1, bias=True, activation=\'prelu\',\n                 norm=None):\n        super(DeconvBlock, self).__init__()\n        self.deconv = torch.nn.ConvTranspose2d(input_size, output_size, kernel_size, stride, padding, bias=bias)\n\n        self.norm = norm\n        if self.norm == \'batch\':\n            self.bn = torch.nn.BatchNorm2d(output_size)\n        elif self.norm == \'instance\':\n            self.bn = torch.nn.InstanceNorm2d(output_size)\n\n        self.activation = activation\n        if self.activation == \'relu\':\n            self.act = torch.nn.ReLU(True)\n        elif self.activation == \'prelu\':\n            self.act = torch.nn.PReLU()\n        elif self.activation == \'lrelu\':\n            self.act = torch.nn.LeakyReLU(0.2, True)\n        elif self.activation == \'tanh\':\n            self.act = torch.nn.Tanh()\n        elif self.activation == \'sigmoid\':\n            self.act = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        if self.norm is not None:\n            out = self.bn(self.deconv(x))\n        else:\n            out = self.deconv(x)\n\n        if self.activation is not None:\n            return self.act(out)\n        else:\n            return out\n\n\nclass ResnetBlock(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=3, stride=1, padding=1, bias=True, activation=\'prelu\', norm=\'batch\'):\n        super(ResnetBlock, self).__init__()\n        self.conv1 = torch.nn.Conv2d(num_filter, num_filter, kernel_size, stride, padding, bias=bias)\n        self.conv2 = torch.nn.Conv2d(num_filter, num_filter, kernel_size, stride, padding, bias=bias)\n\n        self.norm = norm\n        if self.norm == \'batch\':\n            self.bn = torch.nn.BatchNorm2d(num_filter)\n        elif norm == \'instance\':\n            self.bn = torch.nn.InstanceNorm2d(num_filter)\n\n        self.activation = activation\n        if self.activation == \'relu\':\n            self.act = torch.nn.ReLU(True)\n        elif self.activation == \'prelu\':\n            self.act = torch.nn.PReLU()\n        elif self.activation == \'lrelu\':\n            self.act = torch.nn.LeakyReLU(0.2, True)\n        elif self.activation == \'tanh\':\n            self.act = torch.nn.Tanh()\n        elif self.activation == \'sigmoid\':\n            self.act = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        residual = x\n        if self.norm is not None:\n            out = self.bn(self.conv1(x))\n        else:\n            out = self.conv1(x)\n\n        if self.activation is not None:\n            out = self.act(out)\n\n        if self.norm is not None:\n            out = self.bn(self.conv2(out))\n        else:\n            out = self.conv2(out)\n\n        out = torch.add(out, residual)\n        return out\n\n\nclass UpBlock(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, bias=True, activation=\'prelu\', norm=None):\n        super(UpBlock, self).__init__()\n        self.up_conv1 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.up_conv2 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.up_conv3 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n\n    def forward(self, x):\n        h0 = self.up_conv1(x)\n        l0 = self.up_conv2(h0)\n        h1 = self.up_conv3(l0 - x)\n        return h1 + h0\n\n\nclass UpBlockPix(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, scale=4, bias=True, activation=\'prelu\', norm=None):\n        super(UpBlockPix, self).__init__()\n        self.up_conv1 = Upsampler(scale, num_filter)\n        self.up_conv2 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.up_conv3 = Upsampler(scale, num_filter)\n\n    def forward(self, x):\n        h0 = self.up_conv1(x)\n        l0 = self.up_conv2(h0)\n        h1 = self.up_conv3(l0 - x)\n        return h1 + h0\n\n\nclass D_UpBlock(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, num_stages=1, bias=True, activation=\'prelu\',\n                 norm=None):\n        super(D_UpBlock, self).__init__()\n        self.conv = ConvBlock(num_filter * num_stages, num_filter, 1, 1, 0, activation=activation, norm=None)\n        self.up_conv1 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.up_conv2 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.up_conv3 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n\n    def forward(self, x):\n        x = self.conv(x)\n        h0 = self.up_conv1(x)\n        l0 = self.up_conv2(h0)\n        h1 = self.up_conv3(l0 - x)\n        return h1 + h0\n\n\nclass D_UpBlockPix(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, num_stages=1, scale=4, bias=True,\n                 activation=\'prelu\', norm=None):\n        super(D_UpBlockPix, self).__init__()\n        self.conv = ConvBlock(num_filter * num_stages, num_filter, 1, 1, 0, activation=activation, norm=None)\n        self.up_conv1 = Upsampler(scale, num_filter)\n        self.up_conv2 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.up_conv3 = Upsampler(scale, num_filter)\n\n    def forward(self, x):\n        x = self.conv(x)\n        h0 = self.up_conv1(x)\n        l0 = self.up_conv2(h0)\n        h1 = self.up_conv3(l0 - x)\n        return h1 + h0\n\n\nclass DownBlock(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, bias=True, activation=\'prelu\', norm=None):\n        super(DownBlock, self).__init__()\n        self.down_conv1 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.down_conv2 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.down_conv3 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n\n    def forward(self, x):\n        l0 = self.down_conv1(x)\n        h0 = self.down_conv2(l0)\n        l1 = self.down_conv3(h0 - x)\n        return l1 + l0\n\n\nclass DownBlockPix(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, scale=4, bias=True, activation=\'prelu\',\n                 norm=None):\n        super(DownBlockPix, self).__init__()\n        self.down_conv1 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.down_conv2 = Upsampler(scale, num_filter)\n        self.down_conv3 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n\n    def forward(self, x):\n        l0 = self.down_conv1(x)\n        h0 = self.down_conv2(l0)\n        l1 = self.down_conv3(h0 - x)\n        return l1 + l0\n\n\nclass D_DownBlock(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, num_stages=1, bias=True, activation=\'prelu\',\n                 norm=None):\n        super(D_DownBlock, self).__init__()\n        self.conv = ConvBlock(num_filter * num_stages, num_filter, 1, 1, 0, activation=activation, norm=None)\n        self.down_conv1 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.down_conv2 = DeconvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.down_conv3 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n\n    def forward(self, x):\n        x = self.conv(x)\n        l0 = self.down_conv1(x)\n        h0 = self.down_conv2(l0)\n        l1 = self.down_conv3(h0 - x)\n        return l1 + l0\n\n\nclass D_DownBlockPix(torch.nn.Module):\n    def __init__(self, num_filter, kernel_size=8, stride=4, padding=2, num_stages=1, scale=4, bias=True,\n                 activation=\'prelu\', norm=None):\n        super(D_DownBlockPix, self).__init__()\n        self.conv = ConvBlock(num_filter * num_stages, num_filter, 1, 1, 0, activation=activation, norm=None)\n        self.down_conv1 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n        self.down_conv2 = Upsampler(scale, num_filter)\n        self.down_conv3 = ConvBlock(num_filter, num_filter, kernel_size, stride, padding, activation=activation, norm=None)\n\n    def forward(self, x):\n        x = self.conv(x)\n        l0 = self.down_conv1(x)\n        h0 = self.down_conv2(l0)\n        l1 = self.down_conv3(h0 - x)\n        return l1 + l0\n\n\nclass PSBlock(torch.nn.Module):\n    def __init__(self, input_size, output_size, scale_factor, kernel_size=3, stride=1, padding=1, bias=True,\n                 activation=\'prelu\', norm=\'batch\'):\n        super(PSBlock, self).__init__()\n        self.conv = torch.nn.Conv2d(input_size, output_size * scale_factor ** 2, kernel_size, stride, padding,\n                                    bias=bias)\n        self.ps = torch.nn.PixelShuffle(scale_factor)\n\n        self.norm = norm\n        if self.norm == \'batch\':\n            self.bn = torch.nn.BatchNorm2d(output_size)\n        elif norm == \'instance\':\n            self.bn = torch.nn.InstanceNorm2d(output_size)\n\n        self.activation = activation\n        if self.activation == \'relu\':\n            self.act = torch.nn.ReLU(True)\n        elif self.activation == \'prelu\':\n            self.act = torch.nn.PReLU()\n        elif self.activation == \'lrelu\':\n            self.act = torch.nn.LeakyReLU(0.2, True)\n        elif self.activation == \'tanh\':\n            self.act = torch.nn.Tanh()\n        elif self.activation == \'sigmoid\':\n            self.act = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        if self.norm is not None:\n            out = self.bn(self.ps(self.conv(x)))\n        else:\n            out = self.ps(self.conv(x))\n\n        if self.activation is not None:\n            out = self.act(out)\n        return out\n\n\nclass Upsampler(torch.nn.Module):\n    def __init__(self, scale, n_feat, bn=False, act=\'prelu\', bias=True):\n        super(Upsampler, self).__init__()\n        modules = []\n        for _ in range(int(math.log(scale, 2))):\n            modules.append(ConvBlock(n_feat, 4 * n_feat, 3, 1, 1, bias, activation=None, norm=None))\n            modules.append(torch.nn.PixelShuffle(2))\n            if bn:\n                modules.append(torch.nn.BatchNorm2d(n_feat))\n            # modules.append(torch.nn.PReLU())\n        self.up = torch.nn.Sequential(*modules)\n\n        self.activation = act\n        if self.activation == \'relu\':\n            self.act = torch.nn.ReLU(True)\n        elif self.activation == \'prelu\':\n            self.act = torch.nn.PReLU()\n        elif self.activation == \'lrelu\':\n            self.act = torch.nn.LeakyReLU(0.2, True)\n        elif self.activation == \'tanh\':\n            self.act = torch.nn.Tanh()\n        elif self.activation == \'sigmoid\':\n            self.act = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        out = self.up(x)\n        if self.activation is not None:\n            out = self.act(out)\n        return out\n\n\nclass Upsample2xBlock(torch.nn.Module):\n    def __init__(self, input_size, output_size, bias=True, upsample=\'deconv\', activation=\'relu\', norm=\'batch\'):\n        super(Upsample2xBlock, self).__init__()\n        scale_factor = 2\n        # 1. Deconvolution (Transposed convolution)\n        if upsample == \'deconv\':\n            self.upsample = DeconvBlock(input_size, output_size,\n                                        kernel_size=4, stride=2, padding=1,\n                                        bias=bias, activation=activation, norm=norm)\n\n        # 2. Sub-pixel convolution (Pixel shuffler)\n        elif upsample == \'ps\':\n            self.upsample = PSBlock(input_size, output_size, scale_factor=scale_factor,\n                                    bias=bias, activation=activation, norm=norm)\n\n        # 3. Resize and Convolution\n        elif upsample == \'rnc\':\n            self.upsample = torch.nn.Sequential(\n                torch.nn.Upsample(scale_factor=scale_factor, mode=\'nearest\'),\n                ConvBlock(input_size, output_size,\n                          kernel_size=3, stride=1, padding=1,\n                          bias=bias, activation=activation, norm=norm)\n            )\n\n    def forward(self, x):\n        out = self.upsample(x)\n        return out\n'"
DBPN/solver.py,9,"b'from __future__ import print_function\nfrom math import log10\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom DBPN.model import DBPN, DBPNS, DBPNLL\nfrom progress_bar import progress_bar\n\n\nclass DBPNTrainer(object):\n    def __init__(self, config, training_loader, testing_loader):\n        super(DBPNTrainer, self).__init__()\n        self.GPU_IN_USE = torch.cuda.is_available()\n        self.device = torch.device(\'cuda\' if self.GPU_IN_USE else \'cpu\')\n        self.model = None\n        self.lr = config.lr\n        self.nEpochs = config.nEpochs\n        self.criterion = None\n        self.optimizer = None\n        self.scheduler = None\n        self.seed = config.seed\n        self.upscale_factor = config.upscale_factor\n        self.training_loader = training_loader\n        self.testing_loader = testing_loader\n\n    def build_model(self):\n        self.model = DBPN(num_channels=1, base_channels=64, feat_channels=256, num_stages=7,\n                          scale_factor=self.upscale_factor).to(self.device)\n        self.model.weight_init()\n        self.criterion = nn.L1Loss()\n        torch.manual_seed(self.seed)\n\n        if self.GPU_IN_USE:\n            torch.cuda.manual_seed(self.seed)\n            cudnn.benchmark = True\n            self.criterion.cuda()\n\n        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n        self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[50, 75, 100], gamma=0.5)  # lr decay\n\n    def save(self):\n        model_out_path = ""model_path.pth""\n        torch.save(self.model, model_out_path)\n        print(""Checkpoint saved to {}"".format(model_out_path))\n\n    def train(self):\n        self.model.train()\n        train_loss = 0\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            data, target = data.to(self.device), target.to(self.device)\n            self.optimizer.zero_grad()\n            loss = self.criterion(self.model(data), target)\n            train_loss += loss.item()\n            loss.backward()\n            self.optimizer.step()\n            progress_bar(batch_num, len(self.training_loader), \'Loss: %.4f\' % (train_loss / (batch_num + 1)))\n\n        print(""    Average Loss: {:.4f}"".format(train_loss / len(self.training_loader)))\n\n    def test(self):\n        self.model.eval()\n        avg_psnr = 0\n\n        with torch.no_grad():\n            for batch_num, (data, target) in enumerate(self.testing_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                prediction = self.model(data)\n                mse = self.criterion(prediction, target)\n                psnr = 10 * log10(1 / mse.item())\n                avg_psnr += psnr\n                progress_bar(batch_num, len(self.testing_loader), \'PSNR: %.4f\' % (avg_psnr / (batch_num + 1)))\n\n        print(""    Average PSNR: {:.4f} dB"".format(avg_psnr / len(self.testing_loader)))\n\n    def run(self):\n        self.build_model()\n        for epoch in range(1, self.nEpochs + 1):\n            print(""\\n===> Epoch {} starts:"".format(epoch))\n            self.train()\n            self.test()\n            self.scheduler.step(epoch)\n            if epoch == self.nEpochs:\n                self.save()\n'"
DRCN/model.py,9,"b""import torch\nimport torch.nn as nn\n\n\nclass Net(torch.nn.Module):\n    def __init__(self, num_channels, base_channel, num_recursions, device):\n        super(Net, self).__init__()\n        self.num_recursions = num_recursions\n        self.embedding_layer = nn.Sequential(\n            nn.Conv2d(num_channels, base_channel, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(base_channel, base_channel, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n        self.conv_block = nn.Sequential(nn.Conv2d(base_channel, base_channel, kernel_size=3, stride=1, padding=1),\n                                        nn.ReLU(inplace=True))\n\n        self.reconstruction_layer = nn.Sequential(\n            nn.Conv2d(base_channel, base_channel, kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(base_channel, num_channels, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.w_init = torch.ones(self.num_recursions) / self.num_recursions\n        self.w = self.w_init.to(device)\n\n    def forward(self, x):\n        h0 = self.embedding_layer(x)\n\n        h = [h0]\n        for d in range(self.num_recursions):\n            h.append(self.conv_block(h[d]))\n\n        y_d_ = list()\n        out_sum = 0\n        for d in range(self.num_recursions):\n            y_d_.append(self.reconstruction_layer(h[d+1]))\n            out_sum += torch.mul(y_d_[d], self.w[d])\n        out_sum = torch.mul(out_sum, 1.0 / (torch.sum(self.w)))\n\n        final_out = torch.add(out_sum, x)\n\n        return y_d_, final_out\n\n    def weight_init(self):\n        for m in self._modules:\n            weights_init_kaiming(m)\n\n\ndef weights_init_kaiming(m):\n    class_name = m.__class__.__name__\n    if class_name.find('Linear') != -1:\n        torch.nn.init.kaiming_normal_(m.weight)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif class_name.find('Conv2d') != -1:\n        torch.nn.init.kaiming_normal_(m.weight)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif class_name.find('ConvTranspose2d') != -1:\n        torch.nn.init.kaiming_normal_(m.weight)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif class_name.find('Norm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        if m.bias is not None:\n            m.bias.data.zero_()\n"""
DRCN/solver.py,13,"b'from __future__ import print_function\nfrom math import log10\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torchvision.transforms as transforms\nfrom DRCN.model import Net\nfrom progress_bar import progress_bar\nfrom PIL import Image\n\n\nclass DRCNTrainer(object):\n    def __init__(self, config, training_loader, testing_loader):\n        super(DRCNTrainer, self).__init__()\n        self.GPU_IN_USE = torch.cuda.is_available()\n        self.device = torch.device(\'cuda\' if self.GPU_IN_USE else \'cpu\')\n        self.model = None\n        self.lr = config.lr\n        self.nEpochs = config.nEpochs\n        self.criterion = None\n        self.optimizer = None\n        self.scheduler = None\n        self.seed = config.seed\n        self.upscale_factor = config.upscale_factor\n        self.training_loader = training_loader\n        self.testing_loader = testing_loader\n\n        # DRCN setup\n        self.momentum = 0.9\n        self.weight_decay = 0.0001\n        self.loss_alpha = 1.0\n        self.loss_alpha_zero_epoch = 25\n        self.loss_alpha_decay = self.loss_alpha / self.loss_alpha_zero_epoch\n        self.loss_beta = 0.001\n        self.num_recursions = 16\n\n    def build_model(self):\n        self.model = Net(num_channels=1, base_channel=64, num_recursions=self.num_recursions, device=self.device).to(self.device)\n        self.model.weight_init()\n        self.criterion = nn.MSELoss()\n        torch.manual_seed(self.seed)\n\n        if self.GPU_IN_USE:\n            torch.cuda.manual_seed(self.seed)\n            cudnn.benchmark = True\n            self.criterion.cuda()\n\n        # setup optimizer and scheduler\n        param_groups = [{\'params\': list(self.model.parameters())}]\n        param_groups += [{\'params\': [self.model.w]}]\n        self.optimizer = optim.Adam(param_groups, lr=self.lr)\n        self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[50, 75, 100], gamma=0.5)  # lr decay\n\n    def img_preprocess(self, data, interpolation=\'bicubic\'):\n        if interpolation == \'bicubic\':\n            interpolation = Image.BICUBIC\n        elif interpolation == \'bilinear\':\n            interpolation = Image.BILINEAR\n        elif interpolation == \'nearest\':\n            interpolation = Image.NEAREST\n\n        size = list(data.shape)\n\n        if len(size) == 4:\n            target_height = int(size[2] * self.upscale_factor)\n            target_width = int(size[3] * self.upscale_factor)\n            out_data = torch.FloatTensor(size[0], size[1], target_height, target_width)\n            for i, img in enumerate(data):\n                transform = transforms.Compose([transforms.ToPILImage(),\n                                                transforms.Resize((target_width, target_height), interpolation=interpolation),\n                                                transforms.ToTensor()])\n\n                out_data[i, :, :, :] = transform(img)\n            return out_data\n        else:\n            target_height = int(size[1] * self.upscale_factor)\n            target_width = int(size[2] * self.upscale_factor)\n            transform = transforms.Compose([transforms.ToPILImage(),\n                                            transforms.Resize((target_width, target_height), interpolation=interpolation),\n                                            transforms.ToTensor()])\n            return transform(data)\n\n    def save(self):\n        model_out_path = ""DRCN_model_path.pth""\n        torch.save(self.model, model_out_path)\n        print(""Checkpoint saved to {}"".format(model_out_path))\n\n    def train(self):\n        """"""\n        data: [torch.cuda.FloatTensor], 4 batches: [64, 64, 64, 8]\n        """"""\n        self.model.train()\n        train_loss = 0\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            data = self.img_preprocess(data)  # resize input image size\n            data, target = data.to(self.device), target.to(self.device)\n            target_d, output = self.model(data)\n\n            # loss1\n            loss_1 = 0\n            for d in range(self.num_recursions):\n                loss_1 += (self.criterion(target_d[d], target) / self.num_recursions)\n\n            # loss2\n            loss_2 = self.criterion(output, target)\n\n            # regularization\n            reg_term = 0\n            for theta in self.model.parameters():\n                reg_term += torch.mean(torch.sum(theta ** 2))\n\n            # total loss\n            loss = self.loss_alpha * loss_1 + (1 - self.loss_alpha) * loss_2 + self.loss_beta * reg_term\n            loss.backward()\n\n            train_loss += loss.item()\n            self.optimizer.step()\n            progress_bar(batch_num, len(self.training_loader), \'Loss: %.4f\' % (train_loss / (batch_num + 1)))\n\n        print(""    Average Loss: {:.4f}"".format(train_loss / len(self.training_loader)))\n\n    def test(self):\n        """"""\n        data: [torch.cuda.FloatTensor], 10 batches: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n        """"""\n        self.model.eval()\n        avg_psnr = 0\n\n        with torch.no_grad():\n            for batch_num, (data, target) in enumerate(self.testing_loader):\n                data = self.img_preprocess(data)  # resize input image size\n                data, target = data.to(self.device), target.to(self.device)\n                _, prediction = self.model(data)\n                mse = self.criterion(prediction, target)\n                psnr = 10 * log10(1 / mse.item())\n                avg_psnr += psnr\n                progress_bar(batch_num, len(self.testing_loader), \'PSNR: %.4f\' % (avg_psnr / (batch_num + 1)))\n\n        print(""    Average PSNR: {:.4f} dB"".format(avg_psnr / len(self.testing_loader)))\n\n    def run(self):\n        self.build_model()\n        for epoch in range(1, self.nEpochs + 1):\n            print(""\\n===> Epoch {} starts:"".format(epoch))\n            self.loss_alpha = max(0.0, self.loss_alpha - self.loss_alpha_decay)\n            self.train()\n            self.test()\n            self.scheduler.step(epoch)\n            if epoch == self.nEpochs:\n                self.save()\n'"
EDSR/model.py,3,"b'import math\n\nimport torch\nimport torch.nn as nn\n\n\nclass Net(nn.Module):\n    def __init__(self, num_channels, base_channel, upscale_factor, num_residuals):\n        super(Net, self).__init__()\n\n        self.input_conv = nn.Conv2d(num_channels, base_channel, kernel_size=3, stride=1, padding=1)\n\n        resnet_blocks = []\n        for _ in range(num_residuals):\n            resnet_blocks.append(ResnetBlock(base_channel, kernel=3, stride=1, padding=1))\n        self.residual_layers = nn.Sequential(*resnet_blocks)\n\n        self.mid_conv = nn.Conv2d(base_channel, base_channel, kernel_size=3, stride=1, padding=1)\n\n        upscale = []\n        for _ in range(int(math.log2(upscale_factor))):\n            upscale.append(PixelShuffleBlock(base_channel, base_channel, upscale_factor=2))\n        self.upscale_layers = nn.Sequential(*upscale)\n\n        self.output_conv = nn.Conv2d(base_channel, num_channels, kernel_size=3, stride=1, padding=1)\n\n    def weight_init(self, mean=0.0, std=0.02):\n        for m in self._modules:\n            normal_init(self._modules[m], mean, std)\n\n    def forward(self, x):\n        x = self.input_conv(x)\n        residual = x\n        x = self.residual_layers(x)\n        x = self.mid_conv(x)\n        x = torch.add(x, residual)\n        x = self.upscale_layers(x)\n        x = self.output_conv(x)\n        return x\n\n\ndef normal_init(m, mean, std):\n    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n        m.weight.data.normal_(mean, std)\n        if m.bias is not None:\n            m.bias.data.zero_()\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, num_channel, kernel=3, stride=1, padding=1):\n        super(ResnetBlock, self).__init__()\n        self.conv1 = nn.Conv2d(num_channel, num_channel, kernel, stride, padding)\n        self.conv2 = nn.Conv2d(num_channel, num_channel, kernel, stride, padding)\n        self.bn = nn.BatchNorm2d(num_channel)\n        self.activation = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        residual = x\n        x = self.bn(self.conv1(x))\n        x = self.activation(x)\n        x = self.bn(self.conv2(x))\n        x = torch.add(x, residual)\n        return x\n\n\nclass PixelShuffleBlock(nn.Module):\n    def __init__(self, in_channel, out_channel, upscale_factor, kernel=3, stride=1, padding=1):\n        super(PixelShuffleBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channel, out_channel * upscale_factor ** 2, kernel, stride, padding)\n        self.ps = nn.PixelShuffle(upscale_factor)\n\n    def forward(self, x):\n        x = self.ps(self.conv(x))\n        return x\n'"
EDSR/solver.py,10,"b'from __future__ import print_function\n\nfrom math import log10\n\nimport torch\nimport torch.backends.cudnn as cudnn\n\nfrom EDSR.model import Net\nfrom progress_bar import progress_bar\n\n\nclass EDSRTrainer(object):\n    def __init__(self, config, training_loader, testing_loader):\n        super(EDSRTrainer, self).__init__()\n        self.GPU_IN_USE = torch.cuda.is_available()\n        self.device = torch.device(\'cuda\' if self.GPU_IN_USE else \'cpu\')\n        self.model = None\n        self.lr = config.lr\n        self.nEpochs = config.nEpochs\n        self.criterion = None\n        self.optimizer = None\n        self.scheduler = None\n        self.seed = config.seed\n        self.upscale_factor = config.upscale_factor\n        self.training_loader = training_loader\n        self.testing_loader = testing_loader\n\n    def build_model(self):\n        self.model = Net(num_channels=1, upscale_factor=self.upscale_factor, base_channel=64, num_residuals=4).to(self.device)\n        self.model.weight_init(mean=0.0, std=0.02)\n        self.criterion = torch.nn.L1Loss()\n        torch.manual_seed(self.seed)\n\n        if self.GPU_IN_USE:\n            torch.cuda.manual_seed(self.seed)\n            cudnn.benchmark = True\n            self.criterion.cuda()\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr, betas=(0.9, 0.999), eps=1e-8)\n        self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[50, 75, 100], gamma=0.5)  # lr decay\n\n    def save(self):\n        model_out_path = ""EDSR_model_path.pth""\n        torch.save(self.model, model_out_path)\n        print(""Checkpoint saved to {}"".format(model_out_path))\n\n    def train(self):\n        self.model.train()\n        train_loss = 0\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            data, target = data.to(self.device), target.to(self.device)\n            self.optimizer.zero_grad()\n            loss = self.criterion(self.model(data), target)\n            train_loss += loss.item()\n            loss.backward()\n            self.optimizer.step()\n            progress_bar(batch_num, len(self.training_loader), \'Loss: %.4f\' % (train_loss / (batch_num + 1)))\n\n        print(""    Average Loss: {:.4f}"".format(train_loss / len(self.training_loader)))\n\n    def test(self):\n        self.model.eval()\n        avg_psnr = 0\n\n        with torch.no_grad():\n            for batch_num, (data, target) in enumerate(self.testing_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                prediction = self.model(data)\n                mse = self.criterion(prediction, target)\n                psnr = 10 * log10(1 / mse.item())\n                avg_psnr += psnr\n                progress_bar(batch_num, len(self.testing_loader), \'PSNR: %.4f\' % (avg_psnr / (batch_num + 1)))\n\n        print(""    Average PSNR: {:.4f} dB"".format(avg_psnr / len(self.testing_loader)))\n\n    def run(self):\n        self.build_model()\n        for epoch in range(1, self.nEpochs + 1):\n            print(""\\n===> Epoch {} starts:"".format(epoch))\n            self.train()\n            self.test()\n            self.scheduler.step(epoch)\n            if epoch == self.nEpochs:\n                self.save()\n'"
FSRCNN/model.py,3,"b'import torch\nimport torch.nn as nn\n\n\nclass Net(torch.nn.Module):\n    def __init__(self, num_channels, upscale_factor, d=64, s=12, m=4):\n        super(Net, self).__init__()\n\n        self.first_part = nn.Sequential(nn.Conv2d(in_channels=num_channels, out_channels=d, kernel_size=5, stride=1, padding=2),\n                                        nn.PReLU())\n\n        self.layers = []\n        self.layers.append(nn.Sequential(nn.Conv2d(in_channels=d, out_channels=s, kernel_size=1, stride=1, padding=0),\n                                         nn.PReLU()))\n        for _ in range(m):\n            self.layers.append(nn.Conv2d(in_channels=s, out_channels=s, kernel_size=3, stride=1, padding=1))\n        self.layers.append(nn.PReLU())\n        self.layers.append(nn.Sequential(nn.Conv2d(in_channels=s, out_channels=d, kernel_size=1, stride=1, padding=0),\n                                         nn.PReLU()))\n\n        self.mid_part = torch.nn.Sequential(*self.layers)\n\n        # Deconvolution\n        self.last_part = nn.ConvTranspose2d(in_channels=d, out_channels=num_channels, kernel_size=9, stride=upscale_factor, padding=3, output_padding=1)\n\n    def forward(self, x):\n        out = self.first_part(x)\n        out = self.mid_part(out)\n        out = self.last_part(out)\n        return out\n\n    def weight_init(self, mean=0.0, std=0.02):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                m.weight.data.normal_(mean, std)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            if isinstance(m, nn.ConvTranspose2d):\n                m.weight.data.normal_(0.0, 0.0001)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n'"
FSRCNN/solver.py,10,"b'from __future__ import print_function\nfrom math import log10\n\nimport torch\nimport torch.backends.cudnn as cudnn\nfrom FSRCNN.model import Net\nfrom progress_bar import progress_bar\n\n\nclass FSRCNNTrainer(object):\n    def __init__(self, config, training_loader, testing_loader):\n        super(FSRCNNTrainer, self).__init__()\n        self.CUDA = torch.cuda.is_available()\n        self.device = torch.device(\'cuda\' if self.CUDA else \'cpu\')\n        self.model = None\n        self.lr = config.lr\n        self.nEpochs = config.nEpochs\n        self.criterion = None\n        self.optimizer = None\n        self.scheduler = None\n        self.seed = config.seed\n        self.upscale_factor = config.upscale_factor\n        self.training_loader = training_loader\n        self.testing_loader = testing_loader\n\n    def build_model(self):\n        self.model = Net(num_channels=1, upscale_factor=self.upscale_factor).to(self.device)\n        self.model.weight_init(mean=0.0, std=0.2)\n        self.criterion = torch.nn.MSELoss()\n        torch.manual_seed(self.seed)\n\n        if self.CUDA:\n            torch.cuda.manual_seed(self.seed)\n            cudnn.benchmark = True\n            self.criterion.cuda()\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[50, 75, 100], gamma=0.5)  # lr decay\n\n    def save_model(self):\n        model_out_path = ""model_path.pth""\n        torch.save(self.model, model_out_path)\n        print(""Checkpoint saved to {}"".format(model_out_path))\n\n    def train(self):\n        self.model.train()\n        train_loss = 0\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            data, target = data.to(self.device), target.to(self.device)\n            self.optimizer.zero_grad()\n            loss = self.criterion(self.model(data), target)\n            train_loss += loss.item()\n            loss.backward()\n            self.optimizer.step()\n            progress_bar(batch_num, len(self.training_loader), \'Loss: %.4f\' % (train_loss / (batch_num + 1)))\n\n        print(""    Average Loss: {:.4f}"".format(train_loss / len(self.training_loader)))\n\n    def test(self):\n        self.model.eval()\n        avg_psnr = 0\n\n        with torch.no_grad():\n            for batch_num, (data, target) in enumerate(self.testing_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                prediction = self.model(data)\n                mse = self.criterion(prediction, target)\n                psnr = 10 * log10(1 / mse.item())\n                avg_psnr += psnr\n                progress_bar(batch_num, len(self.testing_loader), \'PSNR: %.4f\' % (avg_psnr / (batch_num + 1)))\n\n        print(""    Average PSNR: {:.4f} dB"".format(avg_psnr / len(self.testing_loader)))\n\n    def run(self):\n        self.build_model()\n        for epoch in range(1, self.nEpochs + 1):\n            print(""\\n===> Epoch {} starts:"".format(epoch))\n            self.train()\n            self.test()\n            self.scheduler.step(epoch)\n            if epoch == self.nEpochs:\n                self.save_model()\n'"
SRCNN/model.py,3,"b'import torch\nimport torch.nn as nn\n\n\nclass Net(torch.nn.Module):\n    def __init__(self, num_channels, base_filter, upscale_factor=2):\n        super(Net, self).__init__()\n\n        self.layers = torch.nn.Sequential(\n            nn.Conv2d(in_channels=num_channels, out_channels=base_filter, kernel_size=9, stride=1, padding=4, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=base_filter, out_channels=base_filter // 2, kernel_size=1, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels=base_filter // 2, out_channels=num_channels * (upscale_factor ** 2), kernel_size=5, stride=1, padding=2, bias=True),\n            nn.PixelShuffle(upscale_factor)\n        )\n\n    def forward(self, x):\n        out = self.layers(x)\n        return out\n\n    def weight_init(self, mean, std):\n        for m in self._modules:\n            normal_init(self._modules[m], mean, std)\n\n\ndef normal_init(m, mean, std):\n    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n        m.weight.data.normal_(mean, std)\n        m.bias.data.zero_()\n'"
SRCNN/solver.py,10,"b'from __future__ import print_function\n\nfrom math import log10\n\nimport torch\nimport torch.backends.cudnn as cudnn\n\nfrom SRCNN.model import Net\nfrom progress_bar import progress_bar\n\n\nclass SRCNNTrainer(object):\n    def __init__(self, config, training_loader, testing_loader):\n        super(SRCNNTrainer, self).__init__()\n        self.CUDA = torch.cuda.is_available()\n        self.device = torch.device(\'cuda\' if self.CUDA else \'cpu\')\n        self.model = None\n        self.lr = config.lr\n        self.nEpochs = config.nEpochs\n        self.criterion = None\n        self.optimizer = None\n        self.scheduler = None\n        self.seed = config.seed\n        self.upscale_factor = config.upscale_factor\n        self.training_loader = training_loader\n        self.testing_loader = testing_loader\n\n    def build_model(self):\n        self.model = Net(num_channels=1, base_filter=64, upscale_factor=self.upscale_factor).to(self.device)\n        self.model.weight_init(mean=0.0, std=0.01)\n        self.criterion = torch.nn.MSELoss()\n        torch.manual_seed(self.seed)\n\n        if self.CUDA:\n            torch.cuda.manual_seed(self.seed)\n            cudnn.benchmark = True\n            self.criterion.cuda()\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[50, 75, 100], gamma=0.5)\n\n    def save_model(self):\n        model_out_path = ""model_path.pth""\n        torch.save(self.model, model_out_path)\n        print(""Checkpoint saved to {}"".format(model_out_path))\n\n    def train(self):\n        self.model.train()\n        train_loss = 0\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            data, target = data.to(self.device), target.to(self.device)\n            self.optimizer.zero_grad()\n            loss = self.criterion(self.model(data), target)\n            train_loss += loss.item()\n            loss.backward()\n            self.optimizer.step()\n            progress_bar(batch_num, len(self.training_loader), \'Loss: %.4f\' % (train_loss / (batch_num + 1)))\n\n        print(""    Average Loss: {:.4f}"".format(train_loss / len(self.training_loader)))\n\n    def test(self):\n        self.model.eval()\n        avg_psnr = 0\n\n        with torch.no_grad():\n            for batch_num, (data, target) in enumerate(self.testing_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                prediction = self.model(data)\n                mse = self.criterion(prediction, target)\n                psnr = 10 * log10(1 / mse.item())\n                avg_psnr += psnr\n                progress_bar(batch_num, len(self.testing_loader), \'PSNR: %.4f\' % (avg_psnr / (batch_num + 1)))\n\n        print(""    Average PSNR: {:.4f} dB"".format(avg_psnr / len(self.testing_loader)))\n\n    def run(self):\n        self.build_model()\n        for epoch in range(1, self.nEpochs + 1):\n            print(""\\n===> Epoch {} starts:"".format(epoch))\n            self.train()\n            self.test()\n            self.scheduler.step(epoch)\n            if epoch == self.nEpochs:\n                self.save_model()\n'"
SRGAN/model.py,3,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef swish(x):\n    return x * F.sigmoid(x)\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, kernel, out_channels, stride):\n        super(ResidualBlock, self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=kernel // 2)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel, stride=stride, padding=kernel // 2)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        y = swish(self.bn1(self.conv1(x)))\n        return self.bn2(self.conv2(y)) + x\n\n\nclass UpsampleBlock(nn.Module):\n    # Implements resize-convolution\n    def __init__(self, in_channels):\n        super(UpsampleBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channels, in_channels * 4, kernel_size=3, stride=1, padding=1)\n        self.shuffler = nn.PixelShuffle(2)\n\n    def forward(self, x):\n        return swish(self.shuffler(self.conv(x)))\n\n\nclass Generator(nn.Module):\n    def __init__(self, n_residual_blocks, upsample_factor, num_channel=1, base_filter=64):\n        super(Generator, self).__init__()\n        self.n_residual_blocks = n_residual_blocks\n        self.upsample_factor = upsample_factor\n\n        self.conv1 = nn.Conv2d(num_channel, base_filter, kernel_size=9, stride=1, padding=4)\n\n        for i in range(self.n_residual_blocks):\n            self.add_module('residual_block' + str(i + 1), ResidualBlock(in_channels=base_filter, out_channels=base_filter, kernel=3, stride=1))\n\n        self.conv2 = nn.Conv2d(base_filter, base_filter, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(base_filter)\n\n        for i in range(self.upsample_factor // 2):\n            self.add_module('upsample' + str(i + 1), UpsampleBlock(base_filter))\n\n        self.conv3 = nn.Conv2d(base_filter, num_channel, kernel_size=9, stride=1, padding=4)\n\n    def forward(self, x):\n        x = swish(self.conv1(x))\n\n        y = x.clone()\n        for i in range(self.n_residual_blocks):\n            y = self.__getattr__('residual_block' + str(i + 1))(y)\n\n        x = self.bn2(self.conv2(y)) + x\n\n        for i in range(self.upsample_factor // 2):\n            x = self.__getattr__('upsample' + str(i + 1))(x)\n\n        return self.conv3(x)\n\n    def weight_init(self, mean=0.0, std=0.02):\n        for m in self._modules:\n            normal_init(self._modules[m], mean, std)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, num_channel=1, base_filter=64):\n        super(Discriminator, self).__init__()\n        self.conv1 = nn.Conv2d(num_channel, base_filter, kernel_size=3, stride=1, padding=1)\n\n        self.conv2 = nn.Conv2d(base_filter, base_filter, kernel_size=3, stride=2, padding=1)\n        self.bn2 = nn.BatchNorm2d(base_filter)\n        self.conv3 = nn.Conv2d(base_filter, base_filter * 2, kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(base_filter * 2)\n        self.conv4 = nn.Conv2d(base_filter * 2, base_filter * 2, kernel_size=3, stride=2, padding=1)\n        self.bn4 = nn.BatchNorm2d(base_filter * 2)\n        self.conv5 = nn.Conv2d(base_filter * 2, base_filter * 4, kernel_size=3, stride=1, padding=1)\n        self.bn5 = nn.BatchNorm2d(base_filter * 4)\n        self.conv6 = nn.Conv2d(base_filter * 4, base_filter * 4, kernel_size=3, stride=2, padding=1)\n        self.bn6 = nn.BatchNorm2d(base_filter * 4)\n        self.conv7 = nn.Conv2d(base_filter * 4, base_filter * 8, kernel_size=3, stride=1, padding=1)\n        self.bn7 = nn.BatchNorm2d(base_filter * 8)\n        self.conv8 = nn.Conv2d(base_filter * 8, base_filter * 8, kernel_size=3, stride=2, padding=1)\n        self.bn8 = nn.BatchNorm2d(base_filter * 8)\n\n        # Replaced original paper FC layers with FCN\n        self.conv9 = nn.Conv2d(base_filter * 8, num_channel, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, x):\n        x = swish(self.conv1(x))\n\n        x = swish(self.bn2(self.conv2(x)))\n        x = swish(self.bn3(self.conv3(x)))\n        x = swish(self.bn4(self.conv4(x)))\n        x = swish(self.bn5(self.conv5(x)))\n        x = swish(self.bn6(self.conv6(x)))\n        x = swish(self.bn7(self.conv7(x)))\n        x = swish(self.bn8(self.conv8(x)))\n\n        x = self.conv9(x)\n        return torch.sigmoid(F.avg_pool2d(x, x.size()[2:])).view(x.size()[0], -1)\n\n    def weight_init(self, mean=0.0, std=0.02):\n        for m in self._modules:\n            normal_init(self._modules[m], mean, std)\n\n\ndef normal_init(m, mean, std):\n    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n        m.weight.data.normal_(mean, std)\n        m.bias.data.zero_()\n"""
SRGAN/solver.py,13,"b'from __future__ import print_function\nfrom math import log10\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torchvision.models.vgg import vgg16\nfrom SRGAN.model import Generator, Discriminator\nfrom progress_bar import progress_bar\n\n\nclass SRGANTrainer(object):\n    def __init__(self, config, training_loader, testing_loader):\n        super(SRGANTrainer, self).__init__()\n        self.GPU_IN_USE = torch.cuda.is_available()\n        self.device = torch.device(\'cuda\' if self.GPU_IN_USE else \'cpu\')\n        self.netG = None\n        self.netD = None\n        self.lr = config.lr\n        self.nEpochs = config.nEpochs\n        self.epoch_pretrain = 10\n        self.criterionG = None\n        self.criterionD = None\n        self.optimizerG = None\n        self.optimizerD = None\n        self.feature_extractor = None\n        self.scheduler = None\n        self.seed = config.seed\n        self.upscale_factor = config.upscale_factor\n        self.num_residuals = 16\n        self.training_loader = training_loader\n        self.testing_loader = testing_loader\n\n    def build_model(self):\n        self.netG = Generator(n_residual_blocks=self.num_residuals, upsample_factor=self.upscale_factor, base_filter=64, num_channel=1).to(self.device)\n        self.netD = Discriminator(base_filter=64, num_channel=1).to(self.device)\n        self.feature_extractor = vgg16(pretrained=True)\n        self.netG.weight_init(mean=0.0, std=0.2)\n        self.netD.weight_init(mean=0.0, std=0.2)\n        self.criterionG = nn.MSELoss()\n        self.criterionD = nn.BCELoss()\n        torch.manual_seed(self.seed)\n\n        if self.GPU_IN_USE:\n            torch.cuda.manual_seed(self.seed)\n            self.feature_extractor.cuda()\n            cudnn.benchmark = True\n            self.criterionG.cuda()\n            self.criterionD.cuda()\n\n        self.optimizerG = optim.Adam(self.netG.parameters(), lr=self.lr, betas=(0.9, 0.999))\n        self.optimizerD = optim.SGD(self.netD.parameters(), lr=self.lr / 100, momentum=0.9, nesterov=True)\n        self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizerG, milestones=[50, 75, 100], gamma=0.5)  # lr decay\n        self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizerD, milestones=[50, 75, 100], gamma=0.5)  # lr decay\n\n    @staticmethod\n    def to_data(x):\n        if torch.cuda.is_available():\n            x = x.cpu()\n        return x.data\n\n    def save(self):\n        g_model_out_path = ""SRGAN_Generator_model_path.pth""\n        d_model_out_path = ""SRGAN_Discriminator_model_path.pth""\n        torch.save(self.netG, g_model_out_path)\n        torch.save(self.netD, d_model_out_path)\n        print(""Checkpoint saved to {}"".format(g_model_out_path))\n        print(""Checkpoint saved to {}"".format(d_model_out_path))\n\n    def pretrain(self):\n        self.netG.train()\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            data, target = data.to(self.device), target.to(self.device)\n            self.netG.zero_grad()\n            loss = self.criterionG(self.netG(data), target)\n            loss.backward()\n            self.optimizerG.step()\n\n    def train(self):\n        # models setup\n        self.netG.train()\n        self.netD.train()\n        g_train_loss = 0\n        d_train_loss = 0\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            # setup noise\n            real_label = torch.ones(data.size(0), data.size(1)).to(self.device)\n            fake_label = torch.zeros(data.size(0), data.size(1)).to(self.device)\n            data, target = data.to(self.device), target.to(self.device)\n\n            # Train Discriminator\n            self.optimizerD.zero_grad()\n            d_real = self.netD(target)\n            d_real_loss = self.criterionD(d_real, real_label)\n\n            d_fake = self.netD(self.netG(data))\n            d_fake_loss = self.criterionD(d_fake, fake_label)\n            d_total = d_real_loss + d_fake_loss\n            d_train_loss += d_total.item()\n            d_total.backward()\n            self.optimizerD.step()\n\n            # Train generator\n            self.optimizerG.zero_grad()\n            g_real = self.netG(data)\n            g_fake = self.netD(g_real)\n            gan_loss = self.criterionD(g_fake, real_label)\n            mse_loss = self.criterionG(g_real, target)\n\n            g_total = mse_loss + 1e-3 * gan_loss\n            g_train_loss += g_total.item()\n            g_total.backward()\n            self.optimizerG.step()\n\n            progress_bar(batch_num, len(self.training_loader), \'G_Loss: %.4f | D_Loss: %.4f\' % (g_train_loss / (batch_num + 1), d_train_loss / (batch_num + 1)))\n\n        print(""    Average G_Loss: {:.4f}"".format(g_train_loss / len(self.training_loader)))\n\n    def test(self):\n        self.netG.eval()\n        avg_psnr = 0\n\n        with torch.no_grad():\n            for batch_num, (data, target) in enumerate(self.testing_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                prediction = self.netG(data)\n                mse = self.criterionG(prediction, target)\n                psnr = 10 * log10(1 / mse.item())\n                avg_psnr += psnr\n                progress_bar(batch_num, len(self.testing_loader), \'PSNR: %.4f\' % (avg_psnr / (batch_num + 1)))\n\n        print(""    Average PSNR: {:.4f} dB"".format(avg_psnr / len(self.testing_loader)))\n\n    def run(self):\n        self.build_model()\n        for epoch in range(1, self.epoch_pretrain + 1):\n            self.pretrain()\n            print(""{}/{} pretrained"".format(epoch, self.epoch_pretrain))\n\n        for epoch in range(1, self.nEpochs + 1):\n            print(""\\n===> Epoch {} starts:"".format(epoch))\n            self.train()\n            self.test()\n            self.scheduler.step(epoch)\n            if epoch == self.nEpochs:\n                self.save()\n'"
SubPixelCNN/model.py,2,"b""import torch.nn as nn\nimport torch.nn.init as init\n\n\nclass Net(nn.Module):\n    def __init__(self, upscale_factor):\n        super(Net, self).__init__()\n\n        self.relu = nn.ReLU()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2)\n        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, kernel_size=3, stride=1, padding=1)\n        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n\n        self._initialize_weights()\n\n    def _initialize_weights(self):\n        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n        init.orthogonal_(self.conv4.weight)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.relu(x)\n        x = self.conv4(x)\n        x = self.pixel_shuffle(x)\n        return x\n"""
SubPixelCNN/solver.py,10,"b'from __future__ import print_function\n\nfrom math import log10\n\nimport torch\nimport torch.backends.cudnn as cudnn\n\nfrom SubPixelCNN.model import Net\nfrom progress_bar import progress_bar\n\n\nclass SubPixelTrainer(object):\n    def __init__(self, config, training_loader, testing_loader):\n        super(SubPixelTrainer, self).__init__()\n        self.CUDA = torch.cuda.is_available()\n        self.device = torch.device(\'cuda\' if self.CUDA else \'cpu\')\n        self.model = None\n        self.lr = config.lr\n        self.nEpochs = config.nEpochs\n        self.criterion = None\n        self.optimizer = None\n        self.scheduler = None\n        self.seed = config.seed\n        self.upscale_factor = config.upscale_factor\n        self.training_loader = training_loader\n        self.testing_loader = testing_loader\n\n    def build_model(self):\n        self.model = Net(upscale_factor=self.upscale_factor).to(self.device)\n        self.criterion = torch.nn.MSELoss()\n        torch.manual_seed(self.seed)\n\n        if self.CUDA:\n            torch.cuda.manual_seed(self.seed)\n            cudnn.benchmark = True\n            self.criterion.cuda()\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[50, 75, 100], gamma=0.5)  # lr decay\n\n    def save(self):\n        model_out_path = ""model_path.pth""\n        torch.save(self.model, model_out_path)\n        print(""Checkpoint saved to {}"".format(model_out_path))\n\n    def train(self):\n        self.model.train()\n        train_loss = 0\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            data, target = data.to(self.device), target.to(self.device)\n            self.optimizer.zero_grad()\n            loss = self.criterion(self.model(data), target)\n            train_loss += loss.item()\n            loss.backward()\n            self.optimizer.step()\n            progress_bar(batch_num, len(self.training_loader), \'Loss: %.4f\' % (train_loss / (batch_num + 1)))\n\n        print(""    Average Loss: {:.4f}"".format(train_loss / len(self.training_loader)))\n\n    def test(self):\n        self.model.eval()\n        avg_psnr = 0\n\n        with torch.no_grad():\n            for batch_num, (data, target) in enumerate(self.testing_loader):\n                data, target = data.to(self.device), target.to(self.device)\n                prediction = self.model(data)\n                mse = self.criterion(prediction, target)\n                psnr = 10 * log10(1 / mse.item())\n                avg_psnr += psnr\n                progress_bar(batch_num, len(self.testing_loader), \'PSNR: %.4f\' % (avg_psnr / (batch_num + 1)))\n\n        print(""    Average PSNR: {:.4f} dB"".format(avg_psnr / len(self.testing_loader)))\n\n    def run(self):\n        self.build_model()\n        for epoch in range(1, self.nEpochs + 1):\n            print(""\\n===> Epoch {} starts:"".format(epoch))\n            self.train()\n            self.test()\n            self.scheduler.step(epoch)\n            if epoch == self.nEpochs:\n                self.save()\n'"
VDSR/model.py,2,"b""import torch\nimport torch.nn as nn\n\n\nclass Net(nn.Module):\n    def __init__(self, num_channels, base_channels, num_residuals):\n        super(Net, self).__init__()\n\n        self.input_conv = nn.Sequential(nn.Conv2d(num_channels, base_channels, kernel_size=3, stride=1, padding=1, bias=False), nn.ReLU(inplace=True))\n        self.residual_layers = nn.Sequential(*[nn.Sequential(nn.Conv2d(base_channels, base_channels, kernel_size=3, stride=1, padding=1, bias=False), nn.ReLU(inplace=True)) for _ in range(num_residuals)])\n        self.output_conv = nn.Conv2d(base_channels, num_channels, kernel_size=3, stride=1, padding=1, bias=False)\n\n    def weight_init(self):\n        for m in self._modules:\n            weights_init_kaiming(m)\n\n    def forward(self, x):\n        residual = x\n        x = self.input_conv(x)\n        x = self.residual_layers(x)\n        x = self.output_conv(x)\n        x = torch.add(x, residual)\n        return x\n\n\ndef weights_init_kaiming(m):\n    class_name = m.__class__.__name__\n    if class_name.find('Linear') != -1:\n        nn.init.kaiming_normal_(m.weight)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif class_name.find('Conv2d') != -1:\n        nn.init.kaiming_normal_(m.weight)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif class_name.find('ConvTranspose2d') != -1:\n        nn.init.kaiming_normal_(m.weight)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif class_name.find('Norm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        if m.bias is not None:\n            m.bias.data.zero_()\n"""
VDSR/solver.py,11,"b'from __future__ import print_function\n\nfrom math import log10\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\nfrom VDSR.model import Net\nfrom progress_bar import progress_bar\n\n\nclass VDSRTrainer(object):\n    def __init__(self, config, training_loader, testing_loader):\n        super(VDSRTrainer, self).__init__()\n        self.CUDA = torch.cuda.is_available()\n        self.device = torch.device(\'cuda\' if self.CUDA else \'cpu\')\n        self.model = None\n        self.lr = config.lr\n        self.nEpochs = config.nEpochs\n        self.criterion = None\n        self.optimizer = None\n        self.scheduler = None\n        self.seed = config.seed\n        self.upscale_factor = config.upscale_factor\n        self.training_loader = training_loader\n        self.testing_loader = testing_loader\n\n    def build_model(self):\n        self.model = Net(num_channels=1, base_channels=64, num_residuals=4).to(self.device)\n        self.model.weight_init()\n        self.criterion = torch.nn.MSELoss()\n        torch.manual_seed(self.seed)\n\n        if self.CUDA:\n            torch.cuda.manual_seed(self.seed)\n            cudnn.benchmark = True\n            self.criterion.cuda()\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=[50, 75, 100], gamma=0.5)\n\n    def img_preprocess(self, data, interpolation=\'bicubic\'):\n        if interpolation == \'bicubic\':\n            interpolation = Image.BICUBIC\n        elif interpolation == \'bilinear\':\n            interpolation = Image.BILINEAR\n        elif interpolation == \'nearest\':\n            interpolation = Image.NEAREST\n\n        size = list(data.shape)\n\n        if len(size) == 4:\n            target_height = int(size[2] * self.upscale_factor)\n            target_width = int(size[3] * self.upscale_factor)\n            out_data = torch.FloatTensor(size[0], size[1], target_height, target_width)\n            for i, img in enumerate(data):\n                transform = transforms.Compose([transforms.ToPILImage(),\n                                                transforms.Resize((target_width, target_height), interpolation=interpolation),\n                                                transforms.ToTensor()])\n\n                out_data[i, :, :, :] = transform(img)\n            return out_data\n        else:\n            target_height = int(size[1] * self.upscale_factor)\n            target_width = int(size[2] * self.upscale_factor)\n            transform = transforms.Compose([transforms.ToPILImage(),\n                                            transforms.Resize((target_width, target_height), interpolation=interpolation),\n                                            transforms.ToTensor()])\n            return transform(data)\n\n    def save(self):\n        model_out_path = ""VDSR_model_path.pth""\n        torch.save(self.model, model_out_path)\n        print(""Checkpoint saved to {}"".format(model_out_path))\n\n    def train(self):\n        self.model.train()\n        train_loss = 0\n\n        for batch_num, (data, target) in enumerate(self.training_loader):\n            data = self.img_preprocess(data)  # resize input image size\n            data, target = data.to(self.device), target.to(self.device)\n            self.optimizer.zero_grad()\n            loss = self.criterion(self.model(data), target)\n            train_loss += loss.item()\n            loss.backward()\n            self.optimizer.step()\n            progress_bar(batch_num, len(self.training_loader), \'Loss: %.4f\' % (train_loss / (batch_num + 1)))\n\n        print(""    Average Loss: {:.4f}"".format(train_loss / len(self.training_loader)))\n\n    def test(self):\n        self.model.eval()\n        avg_psnr = 0\n\n        with torch.no_grad():\n            for batch_num, (data, target) in enumerate(self.testing_loader):\n                data = self.img_preprocess(data)  # resize input image size\n                data, target = data.to(self.device), target.to(self.device)\n                prediction = self.model(data)\n                mse = self.criterion(prediction, target)\n                psnr = 10 * log10(1 / mse.item())\n                avg_psnr += psnr\n                progress_bar(batch_num, len(self.testing_loader), \'PSNR: %.4f\' % (avg_psnr / (batch_num + 1)))\n\n        print(""    Average PSNR: {:.4f} dB"".format(avg_psnr / len(self.testing_loader)))\n\n    def run(self):\n        self.build_model()\n        for epoch in range(1, self.nEpochs + 1):\n            print(""\\n===> Epoch {} starts:"".format(epoch))\n            self.train()\n            self.test()\n            self.scheduler.step(epoch)\n            if epoch == self.nEpochs:\n                self.save()\n'"
dataset/data.py,0,"b'import tarfile\nfrom os import remove\nfrom os.path import exists, join, basename\n\nfrom six.moves import urllib\nfrom torchvision.transforms import Compose, CenterCrop, ToTensor, Resize\n\nfrom .dataset import DatasetFromFolder\n\n\ndef download_bsd300(dest=""./dataset""):\n    output_image_dir = join(dest, ""BSDS300/images"")\n\n    if not exists(output_image_dir):\n        url = ""http://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz""\n        print(""downloading url "", url)\n\n        data = urllib.request.urlopen(url)\n\n        file_path = join(dest, basename(url))\n        with open(file_path, \'wb\') as f:\n            f.write(data.read())\n\n        print(""Extracting data"")\n        with tarfile.open(file_path) as tar:\n            for item in tar:\n                tar.extract(item, dest)\n\n        remove(file_path)\n\n    return output_image_dir\n\n\ndef calculate_valid_crop_size(crop_size, upscale_factor):\n    return crop_size - (crop_size % upscale_factor)\n\n\ndef input_transform(crop_size, upscale_factor):\n    return Compose([\n        CenterCrop(crop_size),\n        Resize(crop_size // upscale_factor),\n        ToTensor(),\n    ])\n\n\ndef target_transform(crop_size):\n    return Compose([\n        CenterCrop(crop_size),\n        ToTensor(),\n    ])\n\n\ndef get_training_set(upscale_factor):\n    root_dir = download_bsd300()\n    train_dir = join(root_dir, ""train"")\n    crop_size = calculate_valid_crop_size(256, upscale_factor)\n\n    return DatasetFromFolder(train_dir,\n                             input_transform=input_transform(crop_size, upscale_factor),\n                             target_transform=target_transform(crop_size))\n\n\ndef get_test_set(upscale_factor):\n    root_dir = download_bsd300()\n    test_dir = join(root_dir, ""test"")\n    crop_size = calculate_valid_crop_size(256, upscale_factor)\n\n    return DatasetFromFolder(test_dir,\n                             input_transform=input_transform(crop_size, upscale_factor),\n                             target_transform=target_transform(crop_size))\n'"
dataset/dataset.py,1,"b'from os import listdir\nfrom os.path import join\n\nimport torch.utils.data as data\nfrom PIL import Image\n\n\ndef is_image_file(filename):\n    return any(filename.endswith(extension) for extension in ["".png"", "".jpg"", "".jpeg""])\n\n\ndef load_img(filepath):\n    img = Image.open(filepath).convert(\'YCbCr\')\n    y, _, _ = img.split()\n    return y\n\n\nclass DatasetFromFolder(data.Dataset):\n    def __init__(self, image_dir, input_transform=None, target_transform=None):\n        super(DatasetFromFolder, self).__init__()\n        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n\n        self.input_transform = input_transform\n        self.target_transform = target_transform\n\n    def __getitem__(self, index):\n        input_image = load_img(self.image_filenames[index])\n        target = input_image.copy()\n        if self.input_transform:\n            input_image = self.input_transform(input_image)\n        if self.target_transform:\n            target = self.target_transform(target)\n\n        return input_image, target\n\n    def __len__(self):\n        return len(self.image_filenames)\n'"
