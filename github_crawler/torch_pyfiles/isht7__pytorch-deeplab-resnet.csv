file_path,api_count,code
convert_deeplab_resnet.py,6,"b'import numpy as np\nimport os\nos.environ[""GLOG_minloglevel""] = ""2""\nimport sys\nsys.path.insert(0,\'/data1/ravikiran/SketchObjPartSegmentation/src/caffe-switch/caffe/python\')\n#sys.path.insert(0,\'/data1/ravikiran/deeplab-public-ver2/python\')\nimport re\nimport caffe\nimport numpy as np\nimport skimage.io\nimport torch\nfrom torch.autograd import Variable\nimport torchvision.models as models\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport deeplab_resnet\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\nimport cv2\nclass CaffeParamProvider():\n    def __init__(self, caffe_net):\n        self.caffe_net = caffe_net\n\n    def conv_kernel(self, name):\n        k = self.caffe_net.params[name][0].data\n        return k\n\n    def conv_biases(self, name):\n        k = self.caffe_net.params[name][1].data\n        return k\n\n    def bn_gamma(self, name):\n        return self.caffe_net.params[name][0].data\n\n    def bn_beta(self, name):\n        return self.caffe_net.params[name][1].data\n\n    def bn_mean(self, name):\n        return (self.caffe_net.params[name][0].data/self.caffe_net.params[name][2].data)\n\n    def bn_variance(self, name):\n        return (self.caffe_net.params[name][1].data/self.caffe_net.params[name][2].data)\n\n    def fc_weights(self, name):\n        w = self.caffe_net.params[name][0].data\n        #w = w.transpose((1, 0))\n        return w\n\n\n    def fc_biases(self, name):\n        b = self.caffe_net.params[name][1].data\n        return b\n\n\ndef preprocess(out):\n    #""""""Changes RGB [0,1] valued image to BGR [0,255] with mean subtracted.""""""\n    #out = np.copy(img) * 255.0\n    out = out[:, :, [2, 1, 0]]  # swap channel from RGB to BGR\n    out[0] -= 104.008\n    out[1] -= 116.669\n    out[2] -= 122.675\n    return out\n\n\ndef assert_almost_equal(caffe_tensor, th_tensor):\n    t = th_tensor[0]\n    c = caffe_tensor[0]\n\n    if t.shape != c.shape:\n        print ""t.shape"", t.shape\n        print ""c.shape"", c.shape\n\n    d = np.linalg.norm(t - c)\n    print ""d"", d\n    assert d < 500\n\ndef dist_(caffe_tensor, th_tensor):\n    t = th_tensor[0]\n    c = caffe_tensor[0]\n\n    if t.shape != c.shape:\n        print ""t.shape"", t.shape\n        print ""c.shape"", c.shape\n\n    d = np.linalg.norm(t - c)\n    print ""d"", d\n\n\n\n# returns image of shape [321, 321, 3]\n# [height, width, depth]\ndef load_image(path, size=321):\n    img = cv2.imread(path)\n    resized_img = cv2.resize(img,(size,size)).astype(float)\n    return resized_img\n\n\ndef load_caffe(img_p):\n    caffe.set_mode_cpu()\n    #caffe.set_device(0)\n\n    prototxt = ""data/test.prototxt"" \n    caffemodel = ""data/train_iter_20000.caffemodel"" \n    net = caffe.Net(prototxt,caffemodel,  caffe.TEST)\n\n    net.blobs[\'data\'].data[0] = img_p.transpose((2, 0, 1))\n    assert net.blobs[\'data\'].data[0].shape == (3, 321, 321)\n    net.forward()\n\n    return net\n\n\n\ndef parse_pth_varnames(p, pth_varname, num_layers):\n    # this function has been modified to fix #4 \n\n    post = \'\'\n    EXP = \'voc12\'\n    if (\'weight\' in pth_varname and \'conv2d_list\' in pth_varname):\n#        #print (\'res%d%s_branch%d%s\'+post) % x\n        if len(post)!=0:\n            post = post[1:]+\'_\' \n        y = (EXP,int(pth_varname[25]))\n        return p.conv_kernel((\'fc1_%s_\'+post+ \'c%d\') % y)\n\n    if (\'bias\' in pth_varname and \'conv2d_list\' in pth_varname):\n#        #print (\'res%d%s_branch%d%s\'+post) % x\n         if len(post)!=0:\n            post = post[1:]+\'_\'\n         y = (EXP,int(pth_varname[25]))\n         return p.conv_biases((\'fc1_%s_\'+post+\'c%d\') % y)\n\n\n    if pth_varname == \'Scale.conv1.weight\':\n        return p.conv_kernel(\'conv1\'+post)\n\n    elif pth_varname == \'Scale.bn1.weight\':\n        return p.bn_gamma(\'scale_conv1\'+post)\n\n    elif pth_varname == \'Scale.bn1.bias\':\n        return p.bn_beta(\'scale_conv1\'+post)\n\n    elif pth_varname == \'Scale.bn1.running_mean\':\n        return p.bn_mean(\'bn_conv1\'+post)\n\n    elif pth_varname == \'Scale.bn1.running_var\':\n        return p.bn_variance(\'bn_conv1\'+post)\n\n    elif pth_varname == \'fc.weight\':\n        return p.fc_weights(\'fc1000\')\n\n    elif pth_varname == \'fc.bias\':\n        return p.fc_biases(\'fc1000\')\n\n    re1 = \'Scale.layer(\\d+).(\\d+).(downsample|conv1|bn1|conv2|bn2|conv3|bn3)\'\n    #re1 = \'scale(\\d+)/block(\\d+)/(shortcut|a|b|c|A|B)\'\n    m = re.search(re1, pth_varname)\n\n    def letter(i):\n        return chr(ord(\'a\') + i - 1)\n\n    scale_num = int(m.group(1)) + 1\n\n    block_num = int(m.group(2)) + 1\n\n\n\n    if scale_num == 2:\n        # scale 2 uses block letters\n        block_str = letter(block_num)\n    elif scale_num == 3 or scale_num == 4:\n        # scale 3 uses numbered blocks \n        # scale 4 uses numbered blocks\n        if num_layers == 50:\n            block_str = letter(block_num)\n        else:\n            if block_num == 1:\n                block_str = \'a\'\n            else:\n                block_str = \'b%d\' % (block_num - 1)\n    elif scale_num == 5:\n        # scale 5 uses block letters\n        block_str = letter(block_num)\n    else:\n        raise ValueError(""unexpected scale_num %d"" % scale_num)\n\n    branch = m.group(3)\n    if branch == ""downsample"":\n        branch_num = 1\n        conv_letter = \'\'\n    else:\n        branch_num = 2\n        conv_letter = letter(int(branch[-1]))\n\n    x = (scale_num, block_str, branch_num, conv_letter)\n\n    if (\'weight\' in pth_varname and \'conv\' in pth_varname) or \'downsample.0.weight\' in pth_varname:\n        return p.conv_kernel((\'res%d%s_branch%d%s\'+post) % x)\n\n    if (\'weight\' in pth_varname and \'bn\' in pth_varname) or \'downsample.1.weight\' in pth_varname:\n        return p.bn_gamma((\'scale%d%s_branch%d%s\'+post) % x)\n\n    if (\'bias\' in pth_varname and \'bn\' in pth_varname) or \'downsample.1.bias\' in pth_varname:\n        return p.bn_beta((\'scale%d%s_branch%d%s\'+post) % x)\n\n    if (\'running_mean\' in pth_varname and \'bn\' in pth_varname) or \'downsample.1.running_mean\' in pth_varname:\n        return p.bn_mean((\'bn%d%s_branch%d%s\'+post) % x)\n\n    if (\'running_var\' in pth_varname and \'bn\' in pth_varname) or \'downsample.1.running_var\' in pth_varname:\n        return p.bn_variance((\'bn%d%s_branch%d%s\'+post) % x)\n\n    raise ValueError(\'unhandled var \' + pth_varname)\n\n\ndef checkpoint_fn(layers):\n    return \'resnet%d.pth\' % layers\n\ndef convert(img_p, layers):\n    caffe_model = load_caffe(img_p)\n\n    param_provider = CaffeParamProvider(caffe_model)\n    model = deeplab_resnet.Res_Deeplab(21) \n    old_dict = model.state_dict()\n    new_state_dict = OrderedDict()\n    keys = model.state_dict().keys()\n\n    for var_name in keys[:]:\n        data = parse_pth_varnames(param_provider, var_name, layers)\n        new_state_dict[var_name] = torch.from_numpy(data).float()\n    \n    model.load_state_dict(new_state_dict)\n\n    \n    o = []\n    def hook(module, input, output):\n        #print module\n        o.append(input[0].data.numpy())\n    \n    model.Scale.conv1.register_forward_hook(hook)   #0, data\n    model.Scale.bn1.register_forward_hook(hook)     #1 conv1 out\n    model.Scale.relu.register_forward_hook(hook)  #2 batch norm out\n    model.Scale.maxpool.register_forward_hook(hook)    #3 bn1, relu out\n    model.Scale.layer1._modules[\'0\'].conv1.register_forward_hook(hook)   #4, pool1 out \n    model.Scale.layer1._modules[\'1\'].conv1.register_forward_hook(hook) #5, res2a out\n    model.Scale.layer5.conv2d_list._modules[\'0\'].register_forward_hook(hook) #6, res5c out\n\n    model.eval()\n    output = model(Variable(torch.from_numpy(img_p[np.newaxis, :].transpose(0,3,1,2)).float(),volatile=True))  \n    \n    interp = nn.UpsamplingBilinear2d(size=(321, 321))\n    output_temp = interp(output[3]).cpu().data[0].numpy()\n    output_temp = output_temp.transpose(1,2,0)\n    output_temp = np.argmax(output_temp,axis = 2)\n    #plt.imshow(output_temp)\n    #plt.show()\n    dist_(caffe_model.blobs[\'data\'].data,o[0])\n    dist_(caffe_model.blobs[\'conv1\'].data,o[3])\n    dist_(caffe_model.blobs[\'pool1\'].data,o[4])\n    dist_(caffe_model.blobs[\'res2a\'].data,o[5])\n    dist_(caffe_model.blobs[\'res5c\'].data,o[6])\n    dist_(caffe_model.blobs[\'fc1_voc12\'].data,output[0].data.numpy())\n    dist_(caffe_model.blobs[\'fc1_voc12_res075_interp\'].data,output[1].data.numpy())\n    dist_(caffe_model.blobs[\'fc1_voc12_res05\'].data,output[2].data.numpy())\n    dist_(caffe_model.blobs[\'fc_fusion\'].data,output[3].data.numpy())\n\n    print \'input image shape\',img_p[np.newaxis, :].transpose(0,3,1,2).shape\n    print \'output shapes -\'\n    for a in output:\n\tprint \ta.data.numpy().shape\n\n    torch.save(model.state_dict(),\'data/MS_DeepLab_resnet_trained_VOC.pth\')\n\n\ndef main():\n    img = load_image(""data/cat.jpg"")\n    #img = load_image(""data/2007_000033.jpg"")\n    img_p = preprocess(img)\n\n    print ""CONVERTING Multi-scale DeepLab_resnet""\n    convert(img_p, layers = 101)\n\n\nif __name__ == \'__main__\':\n    main()\n\n'"
deeplab_resnet.py,4,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torch\nimport numpy as np\naffine_par = True\n\n\ndef outS(i):\n    i = int(i)\n    i = (i+1)/2\n    i = int(np.ceil((i+1)/2.0))\n    i = (i+1)/2\n    return i\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes, affine = affine_par)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes, affine = affine_par)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1,  dilation_ = 1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n        self.bn1 = nn.BatchNorm2d(planes,affine = affine_par)\n\tfor i in self.bn1.parameters():\n            i.requires_grad = False\n        padding = 1\n        if dilation_ == 2:\n\t    padding = 2\n        elif dilation_ == 4:\n\t    padding = 4\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, # change\n                               padding=padding, bias=False, dilation = dilation_)\n        self.bn2 = nn.BatchNorm2d(planes,affine = affine_par)\n        for i in self.bn2.parameters():\n            i.requires_grad = False\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4, affine = affine_par)\n        for i in self.bn3.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Classifier_Module(nn.Module):\n\n    def __init__(self,dilation_series,padding_series,NoLabels):\n        super(Classifier_Module, self).__init__()\n\tself.conv2d_list = nn.ModuleList()\n\tfor dilation,padding in zip(dilation_series,padding_series):\n\t    self.conv2d_list.append(nn.Conv2d(2048,NoLabels,kernel_size=3,stride=1, padding =padding, dilation = dilation,bias = True))\n\n        for m in self.conv2d_list:\n            m.weight.data.normal_(0, 0.01)\n\n\n    def forward(self, x):\n\tout = self.conv2d_list[0](x)\n\tfor i in range(len(self.conv2d_list)-1):\n\t    out += self.conv2d_list[i+1](x)\n        return out\n\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers,NoLabels):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64,affine = affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation__ = 2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation__ = 4)\n\tself.layer5 = self._make_pred_layer(Classifier_Module, [6,12,18,24],[6,12,18,24],NoLabels)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, 0.01)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        #        for i in m.parameters():\n        #            i.requires_grad = False\n\n    def _make_layer(self, block, planes, blocks, stride=1,dilation__ = 1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion or dilation__ == 2 or dilation__ == 4:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion,affine = affine_par),\n            )\n        for i in downsample._modules[\'1\'].parameters():\n            i.requires_grad = False\n        layers = []\n        layers.append(block(self.inplanes, planes, stride,dilation_=dilation__, downsample = downsample ))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes,dilation_=dilation__))\n\n        return nn.Sequential(*layers)\n    def _make_pred_layer(self,block, dilation_series, padding_series,NoLabels):\n\treturn block(dilation_series,padding_series,NoLabels)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\tx = self.layer5(x)\n\n        return x\n\nclass MS_Deeplab(nn.Module):\n    def __init__(self,block,NoLabels):\n\tsuper(MS_Deeplab,self).__init__()\n\tself.Scale = ResNet(block,[3, 4, 23, 3],NoLabels)   #changed to fix #4 \n\n    def forward(self,x):\n        input_size = x.size()[2]\n\tself.interp1 = nn.UpsamplingBilinear2d(size = (  int(input_size*0.75)+1,  int(input_size*0.75)+1  ))\n        self.interp2 = nn.UpsamplingBilinear2d(size = (  int(input_size*0.5)+1,   int(input_size*0.5)+1   ))\n        self.interp3 = nn.UpsamplingBilinear2d(size = (  outS(input_size),   outS(input_size)   ))\n        out = []\n        x2 = self.interp1(x)\n        x3 = self.interp2(x)\n\tout.append(self.Scale(x))\t# for original scale\n\tout.append(self.interp3(self.Scale(x2)))\t# for 0.75x scale\n\tout.append(self.Scale(x3))\t# for 0.5x scale\n\n\n        x2Out_interp = out[1]\n        x3Out_interp = self.interp3(out[2])\n        temp1 = torch.max(out[0],x2Out_interp)\n        out.append(torch.max(temp1,x3Out_interp))\n\treturn out\n\ndef Res_Deeplab(NoLabels=21):\n    model = MS_Deeplab(Bottleneck,NoLabels)\n    return model\n\n'"
evalpyt.py,6,"b'import scipy\nfrom scipy import ndimage\nimport cv2\nimport numpy as np\nimport sys\nsys.path.insert(0,\'/data1/ravikiran/SketchObjPartSegmentation/src/caffe-switch/caffe/python\')\n#import caffe\nimport torch\nfrom torch.autograd import Variable\nimport torchvision.models as models\nimport torch.nn.functional as F\nimport deeplab_resnet \nfrom collections import OrderedDict\nimport os\nfrom os import walk\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\nfrom docopt import docopt\n\ndocstr = """"""Evaluate ResNet-DeepLab trained on scenes (VOC 2012),a total of 21 labels including background\n\nUsage: \n    evalpyt.py [options]\n\nOptions:\n    -h, --help                  Print this message\n    --visualize                 view outputs of each sketch\n    --snapPrefix=<str>          Snapshot [default: VOC12_scenes_]\n    --testGTpath=<str>          Ground truth path prefix [default: data/gt/]\n    --testIMpath=<str>          Sketch images path prefix [default: data/img/]\n    --NoLabels=<int>            The number of different labels in training data, VOC has 21 labels, including background [default: 21]\n    --gpu0=<int>                GPU number [default: 0]\n""""""\n\nargs = docopt(docstr, version=\'v0.1\')\nprint args\n\ndef get_iou(pred,gt):\n    if pred.shape!= gt.shape:\n        print \'pred shape\',pred.shape, \'gt shape\', gt.shape\n    assert(pred.shape == gt.shape)    \n    gt = gt.astype(np.float32)\n    pred = pred.astype(np.float32)\n\n    max_label = int(args[\'--NoLabels\'])-1  # labels from 0,1, ... 20(for VOC)  \n    count = np.zeros((max_label+1,))\n    for j in range(max_label+1):\n        x = np.where(pred==j)\n        p_idx_j = set(zip(x[0].tolist(),x[1].tolist()))\n        x = np.where(gt==j)\n        GT_idx_j = set(zip(x[0].tolist(),x[1].tolist()))\n        #pdb.set_trace()     \n        n_jj = set.intersection(p_idx_j,GT_idx_j)\n        u_jj = set.union(p_idx_j,GT_idx_j)\n    \n        \n        if len(GT_idx_j)!=0:\n            count[j] = float(len(n_jj))/float(len(u_jj))\n\n    result_class = count\n    Aiou = np.sum(result_class[:])/float(len(np.unique(gt))) \n    \n    return Aiou\n\n\n\ngpu0 = int(args[\'--gpu0\'])\nim_path = args[\'--testIMpath\']\nmodel = deeplab_resnet.Res_Deeplab(int(args[\'--NoLabels\']))\nmodel.eval()\ncounter = 0\nmodel.cuda(gpu0)\nsnapPrefix = args[\'--snapPrefix\'] \ngt_path = args[\'--testGTpath\']\nimg_list = open(\'data/list/val.txt\').readlines()\n\nfor iter in range(1,21):   #TODO set the (different iteration)models that you want to evaluate on. Models are saved during training after every 1000 iters by default.\n    saved_state_dict = torch.load(os.path.join(\'data/snapshots/\',snapPrefix+str(iter)+\'000.pth\'))\n    if counter==0:\n\tprint snapPrefix\n    counter+=1\n    model.load_state_dict(saved_state_dict)\n\n    pytorch_list = [];\n    for i in img_list:\n        img = np.zeros((513,513,3));\n\n        img_temp = cv2.imread(os.path.join(im_path,i[:-1]+\'.jpg\')).astype(float)\n        img_original = img_temp\n        img_temp[:,:,0] = img_temp[:,:,0] - 104.008\n        img_temp[:,:,1] = img_temp[:,:,1] - 116.669\n        img_temp[:,:,2] = img_temp[:,:,2] - 122.675\n        img[:img_temp.shape[0],:img_temp.shape[1],:] = img_temp\n        gt = cv2.imread(os.path.join(gt_path,i[:-1]+\'.png\'),0)\n        gt[gt==255] = 0\n        with torch.no_grad():\n            output = model(Variable(torch.from_numpy(img[np.newaxis, :].transpose(0,3,1,2)).float(),volatile = True).cuda(gpu0))\n            interp = nn.UpsamplingBilinear2d(size=(513, 513))\n            output = interp(output[3]).cpu().data[0].numpy()\n        output = output[:,:img_temp.shape[0],:img_temp.shape[1]]\n        \n        output = output.transpose(1,2,0)\n        output = np.argmax(output,axis = 2)\n        if args[\'--visualize\']:\n            plt.subplot(3, 1, 1)\n            plt.imshow(img_original)\n            plt.subplot(3, 1, 2)\n            plt.imshow(gt)\n            plt.subplot(3, 1, 3)\n            plt.imshow(output)\n            plt.show()\n\n        iou_pytorch = get_iou(output,gt)       \n        pytorch_list.append(iou_pytorch)\n\n    print \'pytorch\',iter, np.sum(np.asarray(pytorch_list))/len(pytorch_list)\n'"
evalpyt2.py,6,"b'import scipy\nfrom scipy import ndimage\nimport cv2\nimport numpy as np\nimport sys\n#sys.path.insert(0,\'/data1/ravikiran/SketchObjPartSegmentation/src/caffe-switch/caffe/python\')\n#import caffe\nimport torch\nfrom torch.autograd import Variable\nimport torchvision.models as models\nimport torch.nn.functional as F\nimport deeplab_resnet \nfrom collections import OrderedDict\nimport os\nfrom os import walk\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\nfrom docopt import docopt\n\ndocstr = """"""Evaluate ResNet-DeepLab trained on scenes (VOC 2012),a total of 21 labels including background\n\nUsage: \n    evalpyt.py [options]\n\nOptions:\n    -h, --help                  Print this message\n    --visualize                 view outputs of each sketch\n    --snapPrefix=<str>          Snapshot [default: VOC12_scenes_]\n    --testGTpath=<str>          Ground truth path prefix [default: data/gt/]\n    --testIMpath=<str>          Sketch images path prefix [default: data/img/]\n    --NoLabels=<int>            The number of different labels in training data, VOC has 21 labels, including background [default: 21]\n    --gpu0=<int>                GPU number [default: 0]\n""""""\n\nargs = docopt(docstr, version=\'v0.1\')\nprint args\n\nmax_label = int(args[\'--NoLabels\'])-1 # labels from 0,1, ... 20(for VOC) \ndef fast_hist(a, b, n):\n    k = (a >= 0) & (a < n)\n    return np.bincount(n * a[k].astype(int) + b[k], minlength=n**2).reshape(n, n)\n\ndef get_iou(pred,gt):\n    if pred.shape!= gt.shape:\n        print \'pred shape\',pred.shape, \'gt shape\', gt.shape\n    assert(pred.shape == gt.shape)    \n    gt = gt.astype(np.float32)\n    pred = pred.astype(np.float32)\n\n    count = np.zeros((max_label+1,))\n    for j in range(max_label+1):\n        x = np.where(pred==j)\n        p_idx_j = set(zip(x[0].tolist(),x[1].tolist()))\n        x = np.where(gt==j)\n        GT_idx_j = set(zip(x[0].tolist(),x[1].tolist()))\n        #pdb.set_trace()     \n        n_jj = set.intersection(p_idx_j,GT_idx_j)\n        u_jj = set.union(p_idx_j,GT_idx_j)\n    \n        \n        if len(GT_idx_j)!=0:\n            count[j] = float(len(n_jj))/float(len(u_jj))\n\n    result_class = count\n    Aiou = np.sum(result_class[:])/float(len(np.unique(gt))) \n    \n    return Aiou\n\n\n\ngpu0 = int(args[\'--gpu0\'])\nim_path = args[\'--testIMpath\']\nmodel = deeplab_resnet.Res_Deeplab(int(args[\'--NoLabels\']))\nmodel.eval()\ncounter = 0\nmodel.cuda(gpu0)\nsnapPrefix = args[\'--snapPrefix\'] \ngt_path = args[\'--testGTpath\']\nimg_list = open(\'data/list/val.txt\').readlines()\n\nfor iter in range(1,21):   #TODO set the (different iteration)models that you want to evaluate on. Models are saved during training after each 1000 iters by default.\n    saved_state_dict = torch.load(os.path.join(\'data/snapshots/\',snapPrefix+str(iter)+\'000.pth\'))\n    if counter==0:\n\tprint snapPrefix\n    counter+=1\n    model.load_state_dict(saved_state_dict)\n\n    hist = np.zeros((max_label+1, max_label+1))\n    pytorch_list = [];\n    for i in img_list:\n        img = np.zeros((513,513,3));\n\n        img_temp = cv2.imread(os.path.join(im_path,i[:-1]+\'.jpg\')).astype(float)\n        img_original = img_temp\n        img_temp[:,:,0] = img_temp[:,:,0] - 104.008\n        img_temp[:,:,1] = img_temp[:,:,1] - 116.669\n        img_temp[:,:,2] = img_temp[:,:,2] - 122.675\n        img[:img_temp.shape[0],:img_temp.shape[1],:] = img_temp\n        gt = cv2.imread(os.path.join(gt_path,i[:-1]+\'.png\'),0)\n        #gt[gt==255] = 0\n        with torch.no_grad():\n            output = model(Variable(torch.from_numpy(img[np.newaxis, :].transpose(0,3,1,2)).float(),volatile = True).cuda(gpu0))\n            interp = nn.UpsamplingBilinear2d(size=(513, 513))\n            output = interp(output[3]).cpu().data[0].numpy()\n        output = output[:,:img_temp.shape[0],:img_temp.shape[1]]\n        \n        output = output.transpose(1,2,0)\n        output = np.argmax(output,axis = 2)\n        if args[\'--visualize\']:\n            plt.subplot(3, 1, 1)\n            plt.imshow(img_original)\n            plt.subplot(3, 1, 2)\n            plt.imshow(gt)\n            plt.subplot(3, 1, 3)\n            plt.imshow(output)\n            plt.show()\n\n        iou_pytorch = get_iou(output,gt)       \n        pytorch_list.append(iou_pytorch)\n        hist += fast_hist(gt.flatten(),output.flatten(),max_label+1)\n    miou = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n    print \'pytorch\',iter,""Mean iou = "",np.sum(miou)/len(miou)\n'"
init_net_surgery.py,5,"b'import numpy as np\nimport os\nos.environ[""GLOG_minloglevel""] = ""2""\nimport sys\nsys.path.insert(0,\'/data1/ravikiran/SketchObjPartSegmentation/src/caffe-switch/caffe/python\')\nimport re\nimport caffe\nimport numpy as np\nimport skimage.io\nimport torch\nimport cv2\nfrom torch.autograd import Variable\nimport torchvision.models as models\nimport torch.nn.functional as F\nimport deeplab_resnet\nfrom collections import OrderedDict\n\nclass CaffeParamProvider():\n    def __init__(self, caffe_net):\n        self.caffe_net = caffe_net\n\n    def conv_kernel(self, name):\n        k = self.caffe_net.params[name][0].data\n        return k\n\n    def conv_biases(self, name):\n        k = self.caffe_net.params[name][1].data\n        return k\n\n    def bn_gamma(self, name):\n        return self.caffe_net.params[name][0].data\n\n    def bn_beta(self, name):\n        return self.caffe_net.params[name][1].data\n\n    def bn_mean(self, name):\n        return (self.caffe_net.params[name][0].data/self.caffe_net.params[name][2].data)\n\n    def bn_variance(self, name):\n        return (self.caffe_net.params[name][1].data/self.caffe_net.params[name][2].data)\n\n    def fc_weights(self, name):\n        w = self.caffe_net.params[name][0].data\n        #w = w.transpose((1, 0))\n        return w\n\n\n    def fc_biases(self, name):\n        b = self.caffe_net.params[name][1].data\n        return b\n\n\ndef preprocess(out):\n    """"""Changes RGB [0,1] valued image to BGR [0,255] with mean subtracted.""""""\n    #out = np.copy(img) * 255.0\n    out = out[:, :, [2, 1, 0]]  # swap channel from RGB to BGR\n    out[0] -= 104.008\n    out[1] -= 116.669\n    out[2] -= 122.675\n    return out\n\n\ndef assert_almost_equal(caffe_tensor, th_tensor):\n    t = th_tensor[0]\n    c = caffe_tensor[0]\n\n    if t.shape != c.shape:\n        print ""t.shape"", t.shape\n        print ""c.shape"", c.shape\n\n    d = np.linalg.norm(t - c)\n    print ""d"", d\n    assert d < 500\n\ndef dist_(caffe_tensor, th_tensor):\n    t = th_tensor[0]\n    c = caffe_tensor[0]\n\n    if t.shape != c.shape:\n        print ""t.shape"", t.shape\n        print ""c.shape"", c.shape\n\n    d = np.linalg.norm(t - c)\n    print ""d"", d\n\n\n\n# returns image of shape [321, 321, 3]\n# [height, width, depth]\ndef load_image(path, size=321):\n    img = cv2.imread(path)\n    resized_img = cv2.resize(img,(size,size)).astype(float)\n    return resized_img\n\n\ndef load_caffe(img_p, ):\n    caffe.set_mode_cpu()\n    #caffe.set_device(0)\n\n    prototxt = ""data/test_Scale1.prototxt"" \n    caffemodel = ""data/init.caffemodel"" \n    net = caffe.Net(prototxt,caffemodel,  caffe.TEST)\n\n    net.blobs[\'data\'].data[0] = img_p.transpose((2, 0, 1))\n    assert net.blobs[\'data\'].data[0].shape == (3, 321, 321)\n    net.forward()\n\n    return net\n\n\n\ndef parse_pth_varnames(p, pth_varname, num_layers):\n    # this function has been modified to fix #4\n\n    post = \'\'\n    EXP = \'voc12\'\n    #    Scale3.layer5.conv2d_list.2.bias\n    if (\'weight\' in pth_varname and \'conv2d_list\' in pth_varname):\n#        #print (\'res%d%s_branch%d%s\'+post) % x\n        if len(post)!=0:\n            post = post[1:]+\'_\' \n        y = (EXP,int(pth_varname[25]))\n        return p.conv_kernel((\'fc1_%s_\'+post+ \'c%d\') % y)\n\n    if (\'bias\' in pth_varname and \'conv2d_list\' in pth_varname):\n#        #print (\'res%d%s_branch%d%s\'+post) % x\n         if len(post)!=0:\n            post = post[1:]+\'_\'\n         y = (EXP,int(pth_varname[25]))\n         return p.conv_biases((\'fc1_%s_\'+post+\'c%d\') % y)\n\n\n    if pth_varname == \'Scale.conv1.weight\':\n        return p.conv_kernel(\'conv1\'+post)\n\n    elif pth_varname == \'Scale.bn1.weight\':\n        return p.bn_gamma(\'scale_conv1\'+post)\n\n    elif pth_varname == \'Scale.bn1.bias\':\n        return p.bn_beta(\'scale_conv1\'+post)\n\n    elif pth_varname == \'Scale.bn1.running_mean\':\n        return p.bn_mean(\'bn_conv1\'+post)\n\n    elif pth_varname == \'Scale.bn1.running_var\':\n        return p.bn_variance(\'bn_conv1\'+post)\n\n    elif pth_varname == \'fc.weight\':\n        return p.fc_weights(\'fc1000\')\n\n    elif pth_varname == \'fc.bias\':\n        return p.fc_biases(\'fc1000\')\n\n    re1 = \'Scale.layer(\\d+).(\\d+).(downsample|conv1|bn1|conv2|bn2|conv3|bn3)\' #changed to handle issue #4\n    m = re.search(re1, pth_varname)\n\n    def letter(i):\n        return chr(ord(\'a\') + i - 1)\n\n    scale_num = int(m.group(1)) + 1\n\n    block_num = int(m.group(2)) + 1\n\n\n\n    if scale_num == 2:\n        # scale 2 uses block letters\n        block_str = letter(block_num)\n    elif scale_num == 3 or scale_num == 4:\n        # scale 3 uses numbered blocks \n        # scale 4 uses numbered blocks\n        if num_layers == 50:\n            block_str = letter(block_num)\n        else:\n            if block_num == 1:\n                block_str = \'a\'\n            else:\n                block_str = \'b%d\' % (block_num - 1)\n    elif scale_num == 5:\n        # scale 5 uses block letters\n        block_str = letter(block_num)\n    else:\n        raise ValueError(""unexpected scale_num %d"" % scale_num)\n\n    branch = m.group(3)\n    if branch == ""downsample"":\n        branch_num = 1\n        conv_letter = \'\'\n    else:\n        branch_num = 2\n        conv_letter = letter(int(branch[-1]))\n\n    x = (scale_num, block_str, branch_num, conv_letter)\n\n    if (\'weight\' in pth_varname and \'conv\' in pth_varname) or \'downsample.0.weight\' in pth_varname:\n        return p.conv_kernel((\'res%d%s_branch%d%s\'+post) % x)\n\n    if (\'weight\' in pth_varname and \'bn\' in pth_varname) or \'downsample.1.weight\' in pth_varname:\n        return p.bn_gamma((\'scale%d%s_branch%d%s\'+post) % x)\n\n    if (\'bias\' in pth_varname and \'bn\' in pth_varname) or \'downsample.1.bias\' in pth_varname:\n        return p.bn_beta((\'scale%d%s_branch%d%s\'+post) % x)\n\n    if (\'running_mean\' in pth_varname and \'bn\' in pth_varname) or \'downsample.1.running_mean\' in pth_varname:\n        return p.bn_mean((\'bn%d%s_branch%d%s\'+post) % x)\n\n    if (\'running_var\' in pth_varname and \'bn\' in pth_varname) or \'downsample.1.running_var\' in pth_varname:\n        return p.bn_variance((\'bn%d%s_branch%d%s\'+post) % x)\n\n    raise ValueError(\'unhandled var \' + pth_varname)\n\ndef convert(img_p, layers):\n    caffe_model = load_caffe(img_p)\n\n    param_provider = CaffeParamProvider(caffe_model)\n    model = deeplab_resnet.Res_Deeplab(21) \n    old_dict = model.state_dict()\n    new_state_dict = OrderedDict()\n    keys = model.state_dict().keys()\n    for var_name in keys[:]:\n        data = parse_pth_varnames(param_provider, var_name, layers)\n        new_state_dict[var_name] = torch.from_numpy(data).float()\n    \n    model.load_state_dict(new_state_dict)\n\n    \n    o = []\n    def hook(module, input, output):\n        #print module\n        o.append(input[0].data.numpy())\n    \n    model.Scale.conv1.register_forward_hook(hook)   #0, data\n    model.Scale.bn1.register_forward_hook(hook)     #1 conv1 out\n    model.Scale.relu.register_forward_hook(hook)  #2 batch norm out\n    model.Scale.maxpool.register_forward_hook(hook)    #3 bn1, relu out\n    model.Scale.layer1._modules[\'0\'].conv1.register_forward_hook(hook)   #4, pool1 out \n    model.Scale.layer1._modules[\'1\'].conv1.register_forward_hook(hook) #5, res2a out\n    model.Scale.layer5.conv2d_list._modules[\'0\'].register_forward_hook(hook) #6, res5c out\n\n    model.eval()\n    output = model(Variable(torch.from_numpy(img_p[np.newaxis, :].transpose(0,3,1,2)).float(),volatile=True))  \n    \n\n    dist_(caffe_model.blobs[\'data\'].data,o[0])\n    dist_(caffe_model.blobs[\'conv1\'].data,o[3])\n    dist_(caffe_model.blobs[\'pool1\'].data,o[4])\n    dist_(caffe_model.blobs[\'res2a\'].data,o[5])\n    dist_(caffe_model.blobs[\'res5c\'].data,o[6])\n    dist_(caffe_model.blobs[\'fc1_voc12\'].data,output[3].data.numpy())\n\n    print \'input image shape\',img_p[np.newaxis, :].transpose(0,3,1,2).shape\n    print \'output shapes -\'\n    for a in output:\n\tprint \ta.data.numpy().shape\n\n    torch.save(model.state_dict(),\'data/MS_DeepLab_resnet_pretrained_COCO_init.pth\')\n\n\ndef main():\n    img = load_image(""data/cat.jpg"")\n    img_p = preprocess(img)\n\n    print ""CONVERTING Multi-scale DeepLab_resnet COCO init""\n    convert(img_p, layers = 101)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n\n\n\n'"
train.py,9,"b'import torch\nimport torch.nn as nn\nimport numpy as np\nimport pickle\nimport deeplab_resnet \nimport cv2\nfrom torch.autograd import Variable\nimport torch.optim as optim\nimport scipy.misc\nimport torch.backends.cudnn as cudnn\nimport sys\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import *\nimport random\nfrom docopt import docopt\nimport timeit\nstart = timeit.timeit()\ndocstr = """"""Train ResNet-DeepLab on VOC12 (scenes) in pytorch using MSCOCO pretrained initialization \n\nUsage: \n    train.py [options]\n\nOptions:\n    -h, --help                  Print this message\n    --GTpath=<str>              Ground truth path prefix [default: data/gt/]\n    --IMpath=<str>              Sketch images path prefix [default: data/img/]\n    --NoLabels=<int>            The number of different labels in training data, VOC has 21 labels, including background [default: 21]\n    --LISTpath=<str>            Input image number list file [default: data/list/train_aug.txt]\n    --lr=<float>                Learning Rate [default: 0.00025]\n    -i, --iterSize=<int>        Num iters to accumulate gradients over [default: 10]\n    --wtDecay=<float>          Weight decay during training [default: 0.0005]\n    --gpu0=<int>                GPU number [default: 0]\n    --maxIter=<int>             Maximum number of iterations [default: 20000]\n""""""\n\n#    -b, --batchSize=<int>       num sample per batch [default: 1] currently only batch size of 1 is implemented, arbitrary batch size to be implemented soon\nargs = docopt(docstr, version=\'v0.1\')\nprint(args)\n\ncudnn.enabled = False\ngpu0 = int(args[\'--gpu0\'])\n\n\ndef outS(i):\n    """"""Given shape of input image as i,i,3 in deeplab-resnet model, this function\n    returns j such that the shape of output blob of is j,j,21 (21 in case of VOC)""""""\n    j = int(i)\n    j = (j+1)/2\n    j = int(np.ceil((j+1)/2.0))\n    j = (j+1)/2\n    return j\n\ndef read_file(path_to_file):\n    with open(path_to_file) as f:\n        img_list = []\n        for line in f:\n            img_list.append(line[:-1])\n    return img_list\n\ndef chunker(seq, size):\n return (seq[pos:pos+size] for pos in xrange(0,len(seq), size))\n\ndef resize_label_batch(label, size):\n    label_resized = np.zeros((size,size,1,label.shape[3]))\n    interp = nn.UpsamplingBilinear2d(size=(size, size))\n    labelVar = Variable(torch.from_numpy(label.transpose(3, 2, 0, 1)))\n    label_resized[:, :, :, :] = interp(labelVar).data.numpy().transpose(2, 3, 1, 0)\n\n    return label_resized\n\ndef flip(I,flip_p):\n    if flip_p>0.5:\n        return np.fliplr(I)\n    else:\n        return I\n\ndef scale_im(img_temp,scale):\n    new_dims = (  int(img_temp.shape[0]*scale),  int(img_temp.shape[1]*scale)   )\n    return cv2.resize(img_temp,new_dims).astype(float)\n\ndef scale_gt(img_temp,scale):\n    new_dims = (  int(img_temp.shape[0]*scale),  int(img_temp.shape[1]*scale)   )\n    return cv2.resize(img_temp,new_dims,interpolation = cv2.INTER_NEAREST).astype(float)\n   \ndef get_data_from_chunk_v2(chunk):\n    gt_path =  args[\'--GTpath\']\n    img_path = args[\'--IMpath\']\n\n    scale = random.uniform(0.5, 1.3) #random.uniform(0.5,1.5) does not fit in a Titan X with the present version of pytorch, so we random scaling in the range (0.5,1.3), different than caffe implementation in that caffe used only 4 fixed scales. Refer to read me\n    dim = int(scale*321)\n    images = np.zeros((dim,dim,3,len(chunk)))\n    gt = np.zeros((dim,dim,1,len(chunk)))\n    for i,piece in enumerate(chunk):\n        flip_p = random.uniform(0, 1)\n        img_temp = cv2.imread(os.path.join(img_path,piece+\'.jpg\')).astype(float)\n        img_temp = cv2.resize(img_temp,(321,321)).astype(float)\n        img_temp = scale_im(img_temp,scale)\n        img_temp[:,:,0] = img_temp[:,:,0] - 104.008\n        img_temp[:,:,1] = img_temp[:,:,1] - 116.669\n        img_temp[:,:,2] = img_temp[:,:,2] - 122.675\n        img_temp = flip(img_temp,flip_p)\n        images[:,:,:,i] = img_temp\n\n        gt_temp = cv2.imread(os.path.join(gt_path,piece+\'.png\'))[:,:,0]\n        gt_temp[gt_temp == 255] = 0\n        gt_temp = cv2.resize(gt_temp,(321,321) , interpolation = cv2.INTER_NEAREST)\n        gt_temp = scale_gt(gt_temp,scale)\n        gt_temp = flip(gt_temp,flip_p)\n        gt[:,:,0,i] = gt_temp\n        a = outS(321*scale)#41\n        b = outS((321*0.5)*scale+1)#21\n    labels = [resize_label_batch(gt,i) for i in [a,a,b,a]]\n    images = images.transpose((3,2,0,1))\n    images = torch.from_numpy(images).float()\n    return images, labels\n\n\n\ndef loss_calc(out, label,gpu0):\n    """"""\n    This function returns cross entropy loss for semantic segmentation\n    """"""\n    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n    label = label[:,:,0,:].transpose(2,0,1)\n    label = torch.from_numpy(label).long()\n    label = Variable(label).cuda(gpu0)\n    m = nn.LogSoftmax()\n    criterion = nn.NLLLoss2d()\n    out = m(out)\n    \n    return criterion(out,label)\n\n\ndef lr_poly(base_lr, iter,max_iter,power):\n    return base_lr*((1-float(iter)/max_iter)**(power))\n\n\ndef get_1x_lr_params_NOscale(model):\n    """"""\n    This generator returns all the parameters of the net except for \n    the last classification layer. Note that for each batchnorm layer, \n    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return \n    any batchnorm parameter\n    """"""\n    b = []\n\n    b.append(model.Scale.conv1)\n    b.append(model.Scale.bn1)\n    b.append(model.Scale.layer1)\n    b.append(model.Scale.layer2)\n    b.append(model.Scale.layer3)\n    b.append(model.Scale.layer4)\n\n    \n    for i in range(len(b)):\n        for j in b[i].modules():\n            jj = 0\n            for k in j.parameters():\n                jj+=1\n                if k.requires_grad:\n                    yield k\n\ndef get_10x_lr_params(model):\n    """"""\n    This generator returns all the parameters for the last layer of the net,\n    which does the classification of pixel into classes\n    """"""\n\n    b = []\n    b.append(model.Scale.layer5.parameters())\n\n    for j in range(len(b)):\n        for i in b[j]:\n            yield i\n\nif not os.path.exists(\'data/snapshots\'):\n    os.makedirs(\'data/snapshots\')\n\n\nmodel = deeplab_resnet.Res_Deeplab(int(args[\'--NoLabels\']))\n\nsaved_state_dict = torch.load(\'data/MS_DeepLab_resnet_pretrained_COCO_init.pth\')\nif int(args[\'--NoLabels\'])!=21:\n    for i in saved_state_dict:\n        #Scale.layer5.conv2d_list.3.weight\n        i_parts = i.split(\'.\')\n        if i_parts[1]==\'layer5\':\n            saved_state_dict[i] = model.state_dict()[i]\n\nmodel.load_state_dict(saved_state_dict)\n\nmax_iter = int(args[\'--maxIter\']) \nbatch_size = 1\nweight_decay = float(args[\'--wtDecay\'])\nbase_lr = float(args[\'--lr\'])\n\nmodel.float()\nmodel.eval() # use_global_stats = True\n\nimg_list = read_file(args[\'--LISTpath\'])\n\ndata_list = []\nfor i in range(10):  # make list for 10 epocs, though we will only use the first max_iter*batch_size entries of this list\n    np.random.shuffle(img_list)\n    data_list.extend(img_list)\n\nmodel.cuda(gpu0)\ncriterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\noptimizer = optim.SGD([{\'params\': get_1x_lr_params_NOscale(model), \'lr\': base_lr }, {\'params\': get_10x_lr_params(model), \'lr\': 10*base_lr} ], lr = base_lr, momentum = 0.9,weight_decay = weight_decay)\n\noptimizer.zero_grad()\ndata_gen = chunker(data_list, batch_size)\n\nfor iter in range(max_iter+1):\n    chunk = data_gen.next()\n\n    images, label = get_data_from_chunk_v2(chunk)\n    images = Variable(images).cuda(gpu0)\n\n    out = model(images)\n    loss = loss_calc(out[0], label[0],gpu0)\n    iter_size = int(args[\'--iterSize\']) \n    for i in range(len(out)-1):\n        loss = loss + loss_calc(out[i+1],label[i+1],gpu0)\n    loss = loss/iter_size \n    loss.backward()\n\n    if iter %1 == 0:\n        print \'iter = \',iter, \'of\',max_iter,\'completed, loss = \', iter_size*(loss.data.cpu().numpy())\n\n    if iter % iter_size  == 0:\n        optimizer.step()\n        lr_ = lr_poly(base_lr,iter,max_iter,0.9)\n        print \'(poly lr policy) learning rate\',lr_\n        optimizer = optim.SGD([{\'params\': get_1x_lr_params_NOscale(model), \'lr\': lr_ }, {\'params\': get_10x_lr_params(model), \'lr\': 10*lr_} ], lr = lr_, momentum = 0.9,weight_decay = weight_decay)\n        optimizer.zero_grad()\n\n    if iter % 1000 == 0 and iter!=0:\n        print \'taking snapshot ...\'\n        torch.save(model.state_dict(),\'data/snapshots/VOC12_scenes_\'+str(iter)+\'.pth\')\nend = timeit.timeit()\nprint \'time taken \', end-start\n'"
data/create_h5.py,0,"b'""""""\nThis file is used to create the hdf5 file (cat.h5) which is used by convert_deeplab_resnet.py and init_net_surgery.py\n""""""\nimport cv2\nimport h5py, os\nimport numpy as np\ndef preprocess(out):\n    #""""""Changes RGB [0,1] valued image to BGR [0,255] with mean subtracted.""""""\n    #out = np.copy(img) * 255.0\n    out = out[:, :, [2, 1, 0]]  # swap channel from RGB to BGR\n    out[0] -= 104.008\n    out[1] -= 116.669\n    out[2] -= 122.675\n    return out\n\ndef load_image(path, size=321):\n    img = cv2.imread(path)\n    resized_img = cv2.resize(img,(321,321)).astype(float)\n    return resized_img\n\n\nimg = load_image(""cat.jpg"")\nprint img.shape\nimg = preprocess(img)\nprint img.shape\n\ngts = np.zeros((1, 1, 321, 321)) #garbage value as this is irrelavent for conversion to .pth files\n\n\ncomp_kwargs = {\'compression\': \'gzip\', \'compression_opts\': 1}\nwith h5py.File(\'cat.h5\', \'w\') as f:\n    f.create_dataset(\'data\', data=img[np.newaxis,:].transpose(0,3,1,2), **comp_kwargs)\n    f.create_dataset(\'label\', data=gts, **comp_kwargs)\n'"
