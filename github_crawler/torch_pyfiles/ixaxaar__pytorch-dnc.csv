file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n""""""A setuptools based setup module.\nSee:\nhttps://packaging.python.org/en/latest/distributing.html\nhttps://github.com/pypa/sampleproject\n""""""\n\n# Always prefer setuptools over distutils\nfrom setuptools import setup, find_packages\n# To use a consistent encoding\nfrom codecs import open\nfrom os import path\n\nhere = path.abspath(path.dirname(__file__))\n\n# Get the long description from the README file\nwith open(path.join(here, \'README.rst\'), encoding=\'utf-8\') as f:\n    long_description = f.read()\n\nsetup(\n    name=\'dnc\',\n\n    version=\'1.0.3\',\n    description=\'Differentiable Neural Computer, for Pytorch\',\n    long_description=long_description,\n\n    # The project\'s main homepage.\n    url=\'https://github.com/pypa/dnc\',\n\n    # Author details\n    author=\'Russi Chatterjee\',\n    author_email=\'root@ixaxaar.in\',\n\n    # Choose your license\n    license=\'MIT\',\n\n    # See https://pypi.python.org/pypi?%3Aaction=list_classifiers\n    classifiers=[\n        \'Development Status :: 3 - Alpha\',\n\n        \'Intended Audience :: Science/Research\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n\n        \'License :: OSI Approved :: MIT License\',\n\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.3\',\n        \'Programming Language :: Python :: 3.4\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n    ],\n\n    keywords=\'differentiable neural computer dnc memory network\',\n\n    packages=find_packages(exclude=[\'contrib\', \'docs\', \'tests\', \'tasks\', \'scripts\']),\n\n    install_requires=[\'torch\', \'numpy\', \'flann\'],\n\n    extras_require={\n        \'dev\': [\'check-manifest\'],\n        \'test\': [\'coverage\'],\n    },\n\n    python_requires=\'>=3\',\n)\n'"
dnc/__init__.py,0,b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nfrom .dnc import DNC\nfrom .sdnc import SDNC\nfrom .sam import SAM\nfrom .memory import Memory\nfrom .sparse_memory import SparseMemory\nfrom .sparse_temporal_memory import SparseTemporalMemory\n'
dnc/dnc.py,6,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport numpy as np\n\nfrom torch.nn.utils.rnn import pad_packed_sequence as pad\nfrom torch.nn.utils.rnn import pack_padded_sequence as pack\nfrom torch.nn.utils.rnn import PackedSequence\n\nfrom .util import *\nfrom .memory import *\n\nfrom torch.nn.init import orthogonal_, xavier_uniform_\n\n\nclass DNC(nn.Module):\n\n  def __init__(\n      self,\n      input_size,\n      hidden_size,\n      rnn_type=\'lstm\',\n      num_layers=1,\n      num_hidden_layers=2,\n      bias=True,\n      batch_first=True,\n      dropout=0,\n      bidirectional=False,\n      nr_cells=5,\n      read_heads=2,\n      cell_size=10,\n      nonlinearity=\'tanh\',\n      gpu_id=-1,\n      independent_linears=False,\n      share_memory=True,\n      debug=False,\n      clip=20\n  ):\n    super(DNC, self).__init__()\n    # todo: separate weights and RNNs for the interface and output vectors\n\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.rnn_type = rnn_type\n    self.num_layers = num_layers\n    self.num_hidden_layers = num_hidden_layers\n    self.bias = bias\n    self.batch_first = batch_first\n    self.dropout = dropout\n    self.bidirectional = bidirectional\n    self.nr_cells = nr_cells\n    self.read_heads = read_heads\n    self.cell_size = cell_size\n    self.nonlinearity = nonlinearity\n    self.gpu_id = gpu_id\n    self.independent_linears = independent_linears\n    self.share_memory = share_memory\n    self.debug = debug\n    self.clip = clip\n\n    self.w = self.cell_size\n    self.r = self.read_heads\n\n    self.read_vectors_size = self.r * self.w\n    self.output_size = self.hidden_size\n\n    self.nn_input_size = self.input_size + self.read_vectors_size\n    self.nn_output_size = self.output_size + self.read_vectors_size\n\n    self.rnns = []\n    self.memories = []\n\n    for layer in range(self.num_layers):\n      if self.rnn_type.lower() == \'rnn\':\n        self.rnns.append(nn.RNN((self.nn_input_size if layer == 0 else self.nn_output_size), self.output_size,\n                                bias=self.bias, nonlinearity=self.nonlinearity, batch_first=True, dropout=self.dropout, num_layers=self.num_hidden_layers))\n      elif self.rnn_type.lower() == \'gru\':\n        self.rnns.append(nn.GRU((self.nn_input_size if layer == 0 else self.nn_output_size),\n                                self.output_size, bias=self.bias, batch_first=True, dropout=self.dropout, num_layers=self.num_hidden_layers))\n      if self.rnn_type.lower() == \'lstm\':\n        self.rnns.append(nn.LSTM((self.nn_input_size if layer == 0 else self.nn_output_size),\n                                 self.output_size, bias=self.bias, batch_first=True, dropout=self.dropout, num_layers=self.num_hidden_layers))\n      setattr(self, self.rnn_type.lower() + \'_layer_\' + str(layer), self.rnns[layer])\n\n      # memories for each layer\n      if not self.share_memory:\n        self.memories.append(\n            Memory(\n                input_size=self.output_size,\n                mem_size=self.nr_cells,\n                cell_size=self.w,\n                read_heads=self.r,\n                gpu_id=self.gpu_id,\n                independent_linears=self.independent_linears\n            )\n        )\n        setattr(self, \'rnn_layer_memory_\' + str(layer), self.memories[layer])\n\n    # only one memory shared by all layers\n    if self.share_memory:\n      self.memories.append(\n          Memory(\n              input_size=self.output_size,\n              mem_size=self.nr_cells,\n              cell_size=self.w,\n              read_heads=self.r,\n              gpu_id=self.gpu_id,\n              independent_linears=self.independent_linears\n          )\n      )\n      setattr(self, \'rnn_layer_memory_shared\', self.memories[0])\n\n    # final output layer\n    self.output = nn.Linear(self.nn_output_size, self.input_size)\n    orthogonal_(self.output.weight)\n\n    if self.gpu_id != -1:\n      [x.cuda(self.gpu_id) for x in self.rnns]\n      [x.cuda(self.gpu_id) for x in self.memories]\n      self.output.cuda()\n\n  def _init_hidden(self, hx, batch_size, reset_experience):\n    # create empty hidden states if not provided\n    if hx is None:\n      hx = (None, None, None)\n    (chx, mhx, last_read) = hx\n\n    # initialize hidden state of the controller RNN\n    if chx is None:\n      h = cuda(T.zeros(self.num_hidden_layers, batch_size, self.output_size), gpu_id=self.gpu_id)\n      xavier_uniform_(h)\n\n      chx = [ (h, h) if self.rnn_type.lower() == \'lstm\' else h for x in range(self.num_layers)]\n\n    # Last read vectors\n    if last_read is None:\n      last_read = cuda(T.zeros(batch_size, self.w * self.r), gpu_id=self.gpu_id)\n\n    # memory states\n    if mhx is None:\n      if self.share_memory:\n        mhx = self.memories[0].reset(batch_size, erase=reset_experience)\n      else:\n        mhx = [m.reset(batch_size, erase=reset_experience) for m in self.memories]\n    else:\n      if self.share_memory:\n        mhx = self.memories[0].reset(batch_size, mhx, erase=reset_experience)\n      else:\n        mhx = [m.reset(batch_size, h, erase=reset_experience) for m, h in zip(self.memories, mhx)]\n\n    return chx, mhx, last_read\n\n  def _debug(self, mhx, debug_obj):\n    if not debug_obj:\n      debug_obj = {\n          \'memory\': [],\n          \'link_matrix\': [],\n          \'precedence\': [],\n          \'read_weights\': [],\n          \'write_weights\': [],\n          \'usage_vector\': [],\n      }\n\n    debug_obj[\'memory\'].append(mhx[\'memory\'][0].data.cpu().numpy())\n    debug_obj[\'link_matrix\'].append(mhx[\'link_matrix\'][0][0].data.cpu().numpy())\n    debug_obj[\'precedence\'].append(mhx[\'precedence\'][0].data.cpu().numpy())\n    debug_obj[\'read_weights\'].append(mhx[\'read_weights\'][0].data.cpu().numpy())\n    debug_obj[\'write_weights\'].append(mhx[\'write_weights\'][0].data.cpu().numpy())\n    debug_obj[\'usage_vector\'].append(mhx[\'usage_vector\'][0].unsqueeze(0).data.cpu().numpy())\n    return debug_obj\n\n  def _layer_forward(self, input, layer, hx=(None, None), pass_through_memory=True):\n    (chx, mhx) = hx\n\n    # pass through the controller layer\n    input, chx = self.rnns[layer](input.unsqueeze(1), chx)\n    input = input.squeeze(1)\n\n    # clip the controller output\n    if self.clip != 0:\n      output = T.clamp(input, -self.clip, self.clip)\n    else:\n      output = input\n\n    # the interface vector\n    \xce\xbe = output\n\n    # pass through memory\n    if pass_through_memory:\n      if self.share_memory:\n        read_vecs, mhx = self.memories[0](\xce\xbe, mhx)\n      else:\n        read_vecs, mhx = self.memories[layer](\xce\xbe, mhx)\n      # the read vectors\n      read_vectors = read_vecs.view(-1, self.w * self.r)\n    else:\n      read_vectors = None\n\n    return output, (chx, mhx, read_vectors)\n\n  def forward(self, input, hx=(None, None, None), reset_experience=False, pass_through_memory=True):\n    # handle packed data\n    is_packed = type(input) is PackedSequence\n    if is_packed:\n      input, lengths = pad(input)\n      max_length = lengths[0]\n    else:\n      max_length = input.size(1) if self.batch_first else input.size(0)\n      lengths = [input.size(1)] * max_length if self.batch_first else [input.size(0)] * max_length\n\n    batch_size = input.size(0) if self.batch_first else input.size(1)\n\n    if not self.batch_first:\n      input = input.transpose(0, 1)\n    # make the data time-first\n\n    controller_hidden, mem_hidden, last_read = self._init_hidden(hx, batch_size, reset_experience)\n\n    # concat input with last read (or padding) vectors\n    inputs = [T.cat([input[:, x, :], last_read], 1) for x in range(max_length)]\n\n    # batched forward pass per element / word / etc\n    if self.debug:\n      viz = None\n\n    outs = [None] * max_length\n    read_vectors = None\n\n    # pass through time\n    for time in range(max_length):\n      # pass thorugh layers\n      for layer in range(self.num_layers):\n        # this layer\'s hidden states\n        chx = controller_hidden[layer]\n        m = mem_hidden if self.share_memory else mem_hidden[layer]\n        # pass through controller\n        outs[time], (chx, m, read_vectors) = \\\n          self._layer_forward(inputs[time], layer, (chx, m), pass_through_memory)\n\n        # debug memory\n        if self.debug:\n          viz = self._debug(m, viz)\n\n        # store the memory back (per layer or shared)\n        if self.share_memory:\n          mem_hidden = m\n        else:\n          mem_hidden[layer] = m\n        controller_hidden[layer] = chx\n\n        if read_vectors is not None:\n          # the controller output + read vectors go into next layer\n          outs[time] = T.cat([outs[time], read_vectors], 1)\n        else:\n          outs[time] = T.cat([outs[time], last_read], 1)\n        inputs[time] = outs[time]\n\n    if self.debug:\n      viz = {k: np.array(v) for k, v in viz.items()}\n      viz = {k: v.reshape(v.shape[0], v.shape[1] * v.shape[2]) for k, v in viz.items()}\n\n    # pass through final output layer\n    inputs = [self.output(i) for i in inputs]\n    outputs = T.stack(inputs, 1 if self.batch_first else 0)\n\n    if is_packed:\n      outputs = pack(output, lengths)\n\n    if self.debug:\n      return outputs, (controller_hidden, mem_hidden, read_vectors), viz\n    else:\n      return outputs, (controller_hidden, mem_hidden, read_vectors)\n\n  def __repr__(self):\n    s = ""\\n----------------------------------------\\n""\n    s += \'{name}({input_size}, {hidden_size}\'\n    if self.rnn_type != \'lstm\':\n      s += \', rnn_type={rnn_type}\'\n    if self.num_layers != 1:\n      s += \', num_layers={num_layers}\'\n    if self.num_hidden_layers != 2:\n      s += \', num_hidden_layers={num_hidden_layers}\'\n    if self.bias != True:\n      s += \', bias={bias}\'\n    if self.batch_first != True:\n      s += \', batch_first={batch_first}\'\n    if self.dropout != 0:\n      s += \', dropout={dropout}\'\n    if self.bidirectional != False:\n      s += \', bidirectional={bidirectional}\'\n    if self.nr_cells != 5:\n      s += \', nr_cells={nr_cells}\'\n    if self.read_heads != 2:\n      s += \', read_heads={read_heads}\'\n    if self.cell_size != 10:\n      s += \', cell_size={cell_size}\'\n    if self.nonlinearity != \'tanh\':\n      s += \', nonlinearity={nonlinearity}\'\n    if self.gpu_id != -1:\n      s += \', gpu_id={gpu_id}\'\n    if self.independent_linears != False:\n      s += \', independent_linears={independent_linears}\'\n    if self.share_memory != True:\n      s += \', share_memory={share_memory}\'\n    if self.debug != False:\n      s += \', debug={debug}\'\n    if self.clip != 20:\n      s += \', clip={clip}\'\n\n    s += "")\\n"" + super(DNC, self).__repr__() + \\\n      ""\\n----------------------------------------\\n""\n    return s.format(name=self.__class__.__name__, **self.__dict__)\n\n\n\n'"
dnc/faiss_index.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport faiss\n\nfrom faiss import cast_integer_to_float_ptr as cast_float\nfrom faiss import cast_integer_to_int_ptr as cast_int\nfrom faiss import cast_integer_to_long_ptr as cast_long\n\nfrom .util import *\n\n\nclass FAISSIndex(object):\n\n  def __init__(self, cell_size=20, nr_cells=1024, K=4, num_lists=32, probes=32, res=None, train=None, gpu_id=-1):\n    super(FAISSIndex, self).__init__()\n    self.cell_size = cell_size\n    self.nr_cells = nr_cells\n    self.probes = probes\n    self.K = K\n    self.num_lists = num_lists\n    self.gpu_id = gpu_id\n\n    # BEWARE: if this variable gets deallocated, FAISS crashes\n    self.res = res if res else faiss.StandardGpuResources()\n    self.res.setTempMemoryFraction(0.01)\n    if self.gpu_id != -1:\n      self.res.initializeForDevice(self.gpu_id)\n\n    nr_samples = self.nr_cells * 100 * self.cell_size\n    train = train if train is not None else T.randn(self.nr_cells * 100, self.cell_size)\n\n    self.index = faiss.GpuIndexIVFFlat(self.res, self.cell_size, self.num_lists, faiss.METRIC_L2)\n    self.index.setNumProbes(self.probes)\n    self.train(train)\n\n  def cuda(self, gpu_id):\n    self.gpu_id = gpu_id\n\n  def train(self, train):\n    train = ensure_gpu(train, -1)\n    T.cuda.synchronize()\n    self.index.train_c(self.nr_cells, cast_float(ptr(train)))\n    T.cuda.synchronize()\n\n  def reset(self):\n    T.cuda.synchronize()\n    self.index.reset()\n    T.cuda.synchronize()\n\n  def add(self, other, positions=None, last=None):\n    other = ensure_gpu(other, self.gpu_id)\n\n    T.cuda.synchronize()\n    if positions is not None:\n      positions = ensure_gpu(positions, self.gpu_id)\n      assert positions.size(0) == other.size(0), ""Mismatch in number of positions and vectors""\n      self.index.add_with_ids_c(other.size(0), cast_float(ptr(other)), cast_long(ptr(positions + 1)))\n    else:\n      other = other[:last, :] if last is not None else other\n      self.index.add_c(other.size(0), cast_float(ptr(other)))\n    T.cuda.synchronize()\n\n  def search(self, query, k=None):\n    query = ensure_gpu(query, self.gpu_id)\n\n    k = k if k else self.K\n    (b,n) = query.size()\n\n    distances = T.FloatTensor(b, k)\n    labels = T.LongTensor(b, k)\n\n    if self.gpu_id != -1: distances = distances.cuda(self.gpu_id)\n    if self.gpu_id != -1: labels = labels.cuda(self.gpu_id)\n\n    T.cuda.synchronize()\n    self.index.search_c(\n      b,\n      cast_float(ptr(query)),\n      k,\n      cast_float(ptr(distances)),\n      cast_long(ptr(labels))\n    )\n    T.cuda.synchronize()\n    return (distances, (labels-1))\n\n'"
dnc/flann_index.py,2,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport numpy as np\n\nfrom pyflann import *\n\nfrom .util import *\n\nclass FLANNIndex(object):\n\n  def __init__(self, cell_size=20, nr_cells=1024, K=4, num_kdtrees=32, probes=32, gpu_id=-1):\n    super(FLANNIndex, self).__init__()\n    self.cell_size = cell_size\n    self.nr_cells = nr_cells\n    self.probes = probes\n    self.K = K\n    self.num_kdtrees = num_kdtrees\n    self.gpu_id = gpu_id\n\n    self.index = FLANN()\n\n  def add(self, other, positions=None, last=-1):\n    if isinstance(other, var):\n      other = other[:last, :].data.cpu().numpy()\n    elif isinstance(other, T.Tensor):\n      other = other[:last, :].cpu().numpy()\n\n    self.index.build_index(other, algorithm='kdtree', trees=self.num_kdtrees, checks=self.probes)\n\n  def search(self, query, k=None):\n    if isinstance(query, var):\n      query = query.data.cpu().numpy()\n    elif isinstance(query, T.Tensor):\n      query = query.cpu().numpy()\n\n    l, d = self.index.nn_index(query, num_neighbors=self.K if k is None else k)\n\n    distances = T.from_numpy(d).float()\n    labels = T.from_numpy(l).long()\n\n    if self.gpu_id != -1: distances = distances.cuda(self.gpu_id)\n    if self.gpu_id != -1: labels = labels.cuda(self.gpu_id)\n\n    return (distances, labels)\n\n\n  def reset(self):\n    self.index.delete_index()\n\n"""
dnc/memory.py,4,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nimport numpy as np\n\nfrom .util import *\n\n\nclass Memory(nn.Module):\n\n  def __init__(self, input_size, mem_size=512, cell_size=32, read_heads=4, gpu_id=-1, independent_linears=True):\n    super(Memory, self).__init__()\n\n    self.mem_size = mem_size\n    self.cell_size = cell_size\n    self.read_heads = read_heads\n    self.gpu_id = gpu_id\n    self.input_size = input_size\n    self.independent_linears = independent_linears\n\n    m = self.mem_size\n    w = self.cell_size\n    r = self.read_heads\n\n    if self.independent_linears:\n      self.read_keys_transform = nn.Linear(self.input_size, w * r)\n      self.read_strengths_transform = nn.Linear(self.input_size, r)\n      self.write_key_transform = nn.Linear(self.input_size, w)\n      self.write_strength_transform = nn.Linear(self.input_size, 1)\n      self.erase_vector_transform = nn.Linear(self.input_size, w)\n      self.write_vector_transform = nn.Linear(self.input_size, w)\n      self.free_gates_transform = nn.Linear(self.input_size, r)\n      self.allocation_gate_transform = nn.Linear(self.input_size, 1)\n      self.write_gate_transform = nn.Linear(self.input_size, 1)\n      self.read_modes_transform = nn.Linear(self.input_size, 3 * r)\n    else:\n      self.interface_size = (w * r) + (3 * w) + (5 * r) + 3\n      self.interface_weights = nn.Linear(self.input_size, self.interface_size)\n\n    self.I = cuda(1 - T.eye(m).unsqueeze(0), gpu_id=self.gpu_id)  # (1 * n * n)\n\n  def reset(self, batch_size=1, hidden=None, erase=True):\n    m = self.mem_size\n    w = self.cell_size\n    r = self.read_heads\n    b = batch_size\n\n    if hidden is None:\n      return {\n          'memory': cuda(T.zeros(b, m, w).fill_(0), gpu_id=self.gpu_id),\n          'link_matrix': cuda(T.zeros(b, 1, m, m), gpu_id=self.gpu_id),\n          'precedence': cuda(T.zeros(b, 1, m), gpu_id=self.gpu_id),\n          'read_weights': cuda(T.zeros(b, r, m).fill_(0), gpu_id=self.gpu_id),\n          'write_weights': cuda(T.zeros(b, 1, m).fill_(0), gpu_id=self.gpu_id),\n          'usage_vector': cuda(T.zeros(b, m), gpu_id=self.gpu_id)\n      }\n    else:\n      hidden['memory'] = hidden['memory'].clone()\n      hidden['link_matrix'] = hidden['link_matrix'].clone()\n      hidden['precedence'] = hidden['precedence'].clone()\n      hidden['read_weights'] = hidden['read_weights'].clone()\n      hidden['write_weights'] = hidden['write_weights'].clone()\n      hidden['usage_vector'] = hidden['usage_vector'].clone()\n\n      if erase:\n        hidden['memory'].data.fill_(0)\n        hidden['link_matrix'].data.zero_()\n        hidden['precedence'].data.zero_()\n        hidden['read_weights'].data.fill_(0)\n        hidden['write_weights'].data.fill_(0)\n        hidden['usage_vector'].data.zero_()\n    return hidden\n\n  def get_usage_vector(self, usage, free_gates, read_weights, write_weights):\n    # write_weights = write_weights.detach()  # detach from the computation graph\n    usage = usage + (1 - usage) * (1 - T.prod(1 - write_weights, 1))\n    \xcf\x88 = T.prod(1 - free_gates.unsqueeze(2) * read_weights, 1)\n    return usage * \xcf\x88\n\n  def allocate(self, usage, write_gate):\n    # ensure values are not too small prior to cumprod.\n    usage = \xce\xb4 + (1 - \xce\xb4) * usage\n    batch_size = usage.size(0)\n    # free list\n    sorted_usage, \xcf\x86 = T.topk(usage, self.mem_size, dim=1, largest=False)\n\n    # cumprod with exclusive=True\n    # https://discuss.pytorch.org/t/cumprod-exclusive-true-equivalences/2614/8\n    v = var(sorted_usage.data.new(batch_size, 1).fill_(1))\n    cat_sorted_usage = T.cat((v, sorted_usage), 1)\n    prod_sorted_usage = T.cumprod(cat_sorted_usage, 1)[:, :-1]\n\n    sorted_allocation_weights = (1 - sorted_usage) * prod_sorted_usage.squeeze()\n\n    # construct the reverse sorting index https://stackoverflow.com/questions/2483696/undo-or-reverse-argsort-python\n    _, \xcf\x86_rev = T.topk(\xcf\x86, k=self.mem_size, dim=1, largest=False)\n    allocation_weights = sorted_allocation_weights.gather(1, \xcf\x86_rev.long())\n\n    return allocation_weights.unsqueeze(1), usage\n\n  def write_weighting(self, memory, write_content_weights, allocation_weights, write_gate, allocation_gate):\n    ag = allocation_gate.unsqueeze(-1)\n    wg = write_gate.unsqueeze(-1)\n\n    return wg * (ag * allocation_weights + (1 - ag) * write_content_weights)\n\n  def get_link_matrix(self, link_matrix, write_weights, precedence):\n    precedence = precedence.unsqueeze(2)\n    write_weights_i = write_weights.unsqueeze(3)\n    write_weights_j = write_weights.unsqueeze(2)\n\n    prev_scale = 1 - write_weights_i - write_weights_j\n    new_link_matrix = write_weights_i * precedence\n\n    link_matrix = prev_scale * link_matrix + new_link_matrix\n    # trick to delete diag elems\n    return self.I.expand_as(link_matrix) * link_matrix\n\n  def update_precedence(self, precedence, write_weights):\n    return (1 - T.sum(write_weights, 2, keepdim=True)) * precedence + write_weights\n\n  def write(self, write_key, write_vector, erase_vector, free_gates, read_strengths, write_strength, write_gate, allocation_gate, hidden):\n    # get current usage\n    hidden['usage_vector'] = self.get_usage_vector(\n        hidden['usage_vector'],\n        free_gates,\n        hidden['read_weights'],\n        hidden['write_weights']\n    )\n\n    # lookup memory with write_key and write_strength\n    write_content_weights = self.content_weightings(hidden['memory'], write_key, write_strength)\n\n    # get memory allocation\n    alloc, _ = self.allocate(\n        hidden['usage_vector'],\n        allocation_gate * write_gate\n    )\n\n    # get write weightings\n    hidden['write_weights'] = self.write_weighting(\n        hidden['memory'],\n        write_content_weights,\n        alloc,\n        write_gate,\n        allocation_gate\n    )\n\n    weighted_resets = hidden['write_weights'].unsqueeze(3) * erase_vector.unsqueeze(2)\n    reset_gate = T.prod(1 - weighted_resets, 1)\n    # Update memory\n    hidden['memory'] = hidden['memory'] * reset_gate\n\n    hidden['memory'] = hidden['memory'] + \\\n        T.bmm(hidden['write_weights'].transpose(1, 2), write_vector)\n\n    # update link_matrix\n    hidden['link_matrix'] = self.get_link_matrix(\n        hidden['link_matrix'],\n        hidden['write_weights'],\n        hidden['precedence']\n    )\n    hidden['precedence'] = self.update_precedence(hidden['precedence'], hidden['write_weights'])\n\n    return hidden\n\n  def content_weightings(self, memory, keys, strengths):\n    d = \xce\xb8(memory, keys)\n    return \xcf\x83(d * strengths.unsqueeze(2), 2)\n\n  def directional_weightings(self, link_matrix, read_weights):\n    rw = read_weights.unsqueeze(1)\n\n    f = T.matmul(link_matrix, rw.transpose(2, 3)).transpose(2, 3)\n    b = T.matmul(rw, link_matrix)\n    return f.transpose(1, 2), b.transpose(1, 2)\n\n  def read_weightings(self, memory, content_weights, link_matrix, read_modes, read_weights):\n    forward_weight, backward_weight = self.directional_weightings(link_matrix, read_weights)\n\n    content_mode = read_modes[:, :, 2].contiguous().unsqueeze(2) * content_weights\n    backward_mode = T.sum(read_modes[:, :, 0:1].contiguous().unsqueeze(3) * backward_weight, 2)\n    forward_mode = T.sum(read_modes[:, :, 1:2].contiguous().unsqueeze(3) * forward_weight, 2)\n\n    return backward_mode + content_mode + forward_mode\n\n  def read_vectors(self, memory, read_weights):\n    return T.bmm(read_weights, memory)\n\n  def read(self, read_keys, read_strengths, read_modes, hidden):\n    content_weights = self.content_weightings(hidden['memory'], read_keys, read_strengths)\n\n    hidden['read_weights'] = self.read_weightings(\n        hidden['memory'],\n        content_weights,\n        hidden['link_matrix'],\n        read_modes,\n        hidden['read_weights']\n    )\n    read_vectors = self.read_vectors(hidden['memory'], hidden['read_weights'])\n    return read_vectors, hidden\n\n  def forward(self, \xce\xbe, hidden):\n\n    # \xce\xbe = \xce\xbe.detach()\n    m = self.mem_size\n    w = self.cell_size\n    r = self.read_heads\n    b = \xce\xbe.size()[0]\n\n    if self.independent_linears:\n      # r read keys (b * r * w)\n      read_keys = T.tanh(self.read_keys_transform(\xce\xbe).view(b, r, w))\n      # r read strengths (b * r)\n      read_strengths = F.softplus(self.read_strengths_transform(\xce\xbe).view(b, r))\n      # write key (b * 1 * w)\n      write_key = T.tanh(self.write_key_transform(\xce\xbe).view(b, 1, w))\n      # write strength (b * 1)\n      write_strength = F.softplus(self.write_strength_transform(\xce\xbe).view(b, 1))\n      # erase vector (b * 1 * w)\n      erase_vector = T.sigmoid(self.erase_vector_transform(\xce\xbe).view(b, 1, w))\n      # write vector (b * 1 * w)\n      write_vector = T.tanh(self.write_vector_transform(\xce\xbe).view(b, 1, w))\n      # r free gates (b * r)\n      free_gates = T.sigmoid(self.free_gates_transform(\xce\xbe).view(b, r))\n      # allocation gate (b * 1)\n      allocation_gate = T.sigmoid(self.allocation_gate_transform(\xce\xbe).view(b, 1))\n      # write gate (b * 1)\n      write_gate = T.sigmoid(self.write_gate_transform(\xce\xbe).view(b, 1))\n      # read modes (b * r * 3)\n      read_modes = \xcf\x83(self.read_modes_transform(\xce\xbe).view(b, r, 3), -1)\n    else:\n      \xce\xbe = self.interface_weights(\xce\xbe)\n      # r read keys (b * w * r)\n      read_keys = T.tanh(\xce\xbe[:, :r * w].contiguous().view(b, r, w))\n      # r read strengths (b * r)\n      read_strengths = F.softplus(\xce\xbe[:, r * w:r * w + r].contiguous().view(b, r))\n      # write key (b * w * 1)\n      write_key = T.tanh(\xce\xbe[:, r * w + r:r * w + r + w].contiguous().view(b, 1, w))\n      # write strength (b * 1)\n      write_strength = F.softplus(\xce\xbe[:, r * w + r + w].contiguous().view(b, 1))\n      # erase vector (b * w)\n      erase_vector = T.sigmoid(\xce\xbe[:, r * w + r + w + 1: r * w + r + 2 * w + 1].contiguous().view(b, 1, w))\n      # write vector (b * w)\n      write_vector = T.tanh(\xce\xbe[:, r * w + r + 2 * w + 1: r * w + r + 3 * w + 1].contiguous().view(b, 1, w))\n      # r free gates (b * r)\n      free_gates = T.sigmoid(\xce\xbe[:, r * w + r + 3 * w + 1: r * w + 2 * r + 3 * w + 1].contiguous().view(b, r))\n      # allocation gate (b * 1)\n      allocation_gate = T.sigmoid(\xce\xbe[:, r * w + 2 * r + 3 * w + 1].contiguous().unsqueeze(1).view(b, 1))\n      # write gate (b * 1)\n      write_gate = T.sigmoid(\xce\xbe[:, r * w + 2 * r + 3 * w + 2].contiguous()).unsqueeze(1).view(b, 1)\n      # read modes (b * 3*r)\n      read_modes = \xcf\x83(\xce\xbe[:, r * w + 2 * r + 3 * w + 3: r * w + 5 * r + 3 * w + 3].contiguous().view(b, r, 3), -1)\n\n    hidden = self.write(write_key, write_vector, erase_vector, free_gates,\n                        read_strengths, write_strength, write_gate, allocation_gate, hidden)\n    return self.read(read_keys, read_strengths, read_modes, hidden)\n"""
dnc/sam.py,6,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport numpy as np\n\nfrom torch.nn.utils.rnn import pad_packed_sequence as pad\nfrom torch.nn.utils.rnn import pack_padded_sequence as pack\nfrom torch.nn.utils.rnn import PackedSequence\nfrom torch.nn.init import orthogonal_, xavier_uniform_\n\nfrom .util import *\nfrom .sparse_memory import SparseMemory\n\nfrom .dnc import DNC\n\n\nclass SAM(DNC):\n\n  def __init__(\n      self,\n      input_size,\n      hidden_size,\n      rnn_type='lstm',\n      num_layers=1,\n      num_hidden_layers=2,\n      bias=True,\n      batch_first=True,\n      dropout=0,\n      bidirectional=False,\n      nr_cells=5000,\n      sparse_reads=4,\n      read_heads=4,\n      cell_size=10,\n      nonlinearity='tanh',\n      gpu_id=-1,\n      independent_linears=False,\n      share_memory=True,\n      debug=False,\n      clip=20\n  ):\n\n    super(SAM, self).__init__(\n        input_size=input_size,\n        hidden_size=hidden_size,\n        rnn_type=rnn_type,\n        num_layers=num_layers,\n        num_hidden_layers=num_hidden_layers,\n        bias=bias,\n        batch_first=batch_first,\n        dropout=dropout,\n        bidirectional=bidirectional,\n        nr_cells=nr_cells,\n        read_heads=read_heads,\n        cell_size=cell_size,\n        nonlinearity=nonlinearity,\n        gpu_id=gpu_id,\n        independent_linears=independent_linears,\n        share_memory=share_memory,\n        debug=debug,\n        clip=clip\n    )\n    self.sparse_reads = sparse_reads\n\n    # override SDNC memories with SAM\n    self.memories = []\n\n    for layer in range(self.num_layers):\n      # memories for each layer\n      if not self.share_memory:\n        self.memories.append(\n            SparseMemory(\n                input_size=self.output_size,\n                mem_size=self.nr_cells,\n                cell_size=self.w,\n                sparse_reads=self.sparse_reads,\n                read_heads=self.read_heads,\n                gpu_id=self.gpu_id,\n                mem_gpu_id=self.gpu_id,\n                independent_linears=self.independent_linears\n            )\n        )\n        setattr(self, 'rnn_layer_memory_' + str(layer), self.memories[layer])\n\n    # only one memory shared by all layers\n    if self.share_memory:\n      self.memories.append(\n          SparseMemory(\n              input_size=self.output_size,\n              mem_size=self.nr_cells,\n              cell_size=self.w,\n              sparse_reads=self.sparse_reads,\n              read_heads=self.read_heads,\n              gpu_id=self.gpu_id,\n              mem_gpu_id=self.gpu_id,\n              independent_linears=self.independent_linears\n          )\n      )\n      setattr(self, 'rnn_layer_memory_shared', self.memories[0])\n\n  def _debug(self, mhx, debug_obj):\n    if not debug_obj:\n      debug_obj = {\n          'memory': [],\n          'visible_memory': [],\n          'read_weights': [],\n          'write_weights': [],\n          'read_vectors': [],\n          'least_used_mem': [],\n          'usage': [],\n          'read_positions': []\n      }\n\n    debug_obj['memory'].append(mhx['memory'][0].data.cpu().numpy())\n    debug_obj['visible_memory'].append(mhx['visible_memory'][0].data.cpu().numpy())\n    debug_obj['read_weights'].append(mhx['read_weights'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['write_weights'].append(mhx['write_weights'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['read_vectors'].append(mhx['read_vectors'][0].data.cpu().numpy())\n    debug_obj['least_used_mem'].append(mhx['least_used_mem'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['usage'].append(mhx['usage'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['read_positions'].append(mhx['read_positions'][0].unsqueeze(0).data.cpu().numpy())\n\n    return debug_obj\n"""
dnc/sdnc.py,6,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport numpy as np\n\nfrom torch.nn.utils.rnn import pad_packed_sequence as pad\nfrom torch.nn.utils.rnn import pack_padded_sequence as pack\nfrom torch.nn.utils.rnn import PackedSequence\nfrom torch.nn.init import orthogonal_, xavier_uniform_\n\nfrom .util import *\nfrom .sparse_temporal_memory import SparseTemporalMemory\nfrom .dnc import DNC\n\n\nclass SDNC(DNC):\n\n  def __init__(\n      self,\n      input_size,\n      hidden_size,\n      rnn_type='lstm',\n      num_layers=1,\n      num_hidden_layers=2,\n      bias=True,\n      batch_first=True,\n      dropout=0,\n      bidirectional=False,\n      nr_cells=5000,\n      sparse_reads=4,\n      temporal_reads=4,\n      read_heads=4,\n      cell_size=10,\n      nonlinearity='tanh',\n      gpu_id=-1,\n      independent_linears=False,\n      share_memory=True,\n      debug=False,\n      clip=20\n  ):\n    super(SDNC, self).__init__(\n        input_size=input_size,\n        hidden_size=hidden_size,\n        rnn_type=rnn_type,\n        num_layers=num_layers,\n        num_hidden_layers=num_hidden_layers,\n        bias=bias,\n        batch_first=batch_first,\n        dropout=dropout,\n        bidirectional=bidirectional,\n        nr_cells=nr_cells,\n        read_heads=read_heads,\n        cell_size=cell_size,\n        nonlinearity=nonlinearity,\n        gpu_id=gpu_id,\n        independent_linears=independent_linears,\n        share_memory=share_memory,\n        debug=debug,\n        clip=clip\n    )\n\n    self.sparse_reads = sparse_reads\n    self.temporal_reads = temporal_reads\n\n    self.memories = []\n\n    for layer in range(self.num_layers):\n      # memories for each layer\n      if not self.share_memory:\n        self.memories.append(\n            SparseTemporalMemory(\n                input_size=self.output_size,\n                mem_size=self.nr_cells,\n                cell_size=self.w,\n                sparse_reads=self.sparse_reads,\n                read_heads=self.read_heads,\n                temporal_reads=self.temporal_reads,\n                gpu_id=self.gpu_id,\n                mem_gpu_id=self.gpu_id,\n                independent_linears=self.independent_linears\n            )\n        )\n        setattr(self, 'rnn_layer_memory_' + str(layer), self.memories[layer])\n\n    # only one memory shared by all layers\n    if self.share_memory:\n      self.memories.append(\n          SparseTemporalMemory(\n              input_size=self.output_size,\n              mem_size=self.nr_cells,\n              cell_size=self.w,\n              sparse_reads=self.sparse_reads,\n              read_heads=self.read_heads,\n              temporal_reads=self.temporal_reads,\n              gpu_id=self.gpu_id,\n              mem_gpu_id=self.gpu_id,\n              independent_linears=self.independent_linears\n          )\n      )\n      setattr(self, 'rnn_layer_memory_shared', self.memories[0])\n\n  def _debug(self, mhx, debug_obj):\n    if not debug_obj:\n      debug_obj = {\n          'memory': [],\n          'visible_memory': [],\n          'link_matrix': [],\n          'rev_link_matrix': [],\n          'precedence': [],\n          'read_weights': [],\n          'write_weights': [],\n          'read_vectors': [],\n          'least_used_mem': [],\n          'usage': [],\n          'read_positions': []\n      }\n\n    debug_obj['memory'].append(mhx['memory'][0].data.cpu().numpy())\n    debug_obj['visible_memory'].append(mhx['visible_memory'][0].data.cpu().numpy())\n    debug_obj['link_matrix'].append(mhx['link_matrix'][0].data.cpu().numpy())\n    debug_obj['rev_link_matrix'].append(mhx['rev_link_matrix'][0].data.cpu().numpy())\n    debug_obj['precedence'].append(mhx['precedence'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['read_weights'].append(mhx['read_weights'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['write_weights'].append(mhx['write_weights'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['read_vectors'].append(mhx['read_vectors'][0].data.cpu().numpy())\n    debug_obj['least_used_mem'].append(mhx['least_used_mem'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['usage'].append(mhx['usage'][0].unsqueeze(0).data.cpu().numpy())\n    debug_obj['read_positions'].append(mhx['read_positions'][0].unsqueeze(0).data.cpu().numpy())\n\n    return debug_obj\n\n"""
dnc/sparse_memory.py,3,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nimport numpy as np\nimport math\n\nfrom .util import *\nimport time\n\n\nclass SparseMemory(nn.Module):\n\n  def __init__(\n      self,\n      input_size,\n      mem_size=512,\n      cell_size=32,\n      independent_linears=True,\n      read_heads=4,\n      sparse_reads=4,\n      num_lists=None,\n      index_checks=32,\n      gpu_id=-1,\n      mem_gpu_id=-1\n  ):\n    super(SparseMemory, self).__init__()\n\n    self.mem_size = mem_size\n    self.cell_size = cell_size\n    self.gpu_id = gpu_id\n    self.mem_gpu_id = mem_gpu_id\n    self.input_size = input_size\n    self.independent_linears = independent_linears\n    self.K = sparse_reads if self.mem_size > sparse_reads else self.mem_size\n    self.read_heads = read_heads\n    self.num_lists = num_lists if num_lists is not None else int(self.mem_size / 100)\n    self.index_checks = index_checks\n\n    m = self.mem_size\n    w = self.cell_size\n    r = self.read_heads\n    # The visible memory size: (K * R read heads, forward and backward\n    # temporal reads of size KL and least used memory cell)\n    self.c = (r * self.K) + 1\n\n    if self.independent_linears:\n      if self.gpu_id != -1:\n        self.read_query_transform = nn.Linear(self.input_size, w * r).cuda()\n        self.write_vector_transform = nn.Linear(self.input_size, w).cuda()\n        self.interpolation_gate_transform = nn.Linear(self.input_size, self.c).cuda()\n        self.write_gate_transform = nn.Linear(self.input_size, 1).cuda()\n      else:\n        self.read_query_transform = nn.Linear(self.input_size, w * r)\n        self.write_vector_transform = nn.Linear(self.input_size, w)\n        self.interpolation_gate_transform = nn.Linear(self.input_size, self.c)\n        self.write_gate_transform = nn.Linear(self.input_size, 1)\n      T.nn.init.orthogonal_(self.read_query_transform.weight)\n      T.nn.init.orthogonal_(self.write_vector_transform.weight)\n      T.nn.init.orthogonal_(self.interpolation_gate_transform.weight)\n      T.nn.init.orthogonal_(self.write_gate_transform.weight)\n    else:\n      self.interface_size = (r * w) + w + self.c + 1\n      if self.gpu_id != -1:\n        self.interface_weights = nn.Linear(self.input_size, self.interface_size).cuda()\n      else:\n        self.interface_weights = nn.Linear(self.input_size, self.interface_size)\n      T.nn.init.orthogonal_(self.interface_weights.weight)\n\n    self.I = cuda(1 - T.eye(self.c).unsqueeze(0), gpu_id=self.gpu_id)  # (1 * n * n)\n    self.\xce\xb4 = 0.005  # minimum usage\n    self.timestep = 0\n    self.mem_limit_reached = False\n    if self.gpu_id != -1:\n      self.cuda()\n\n  def rebuild_indexes(self, hidden, erase=False):\n    b = hidden[\'memory\'].size(0)\n\n    # if indexes already exist, we reset them\n    if \'indexes\' in hidden:\n      [x.reset() for x in hidden[\'indexes\']]\n    else:\n      # create new indexes, try to use FAISS, fall back to FLANN\n      try:\n        from .faiss_index import FAISSIndex\n        hidden[\'indexes\'] = \\\n            [FAISSIndex(cell_size=self.cell_size,\n                        nr_cells=self.mem_size, K=self.K, num_lists=self.num_lists,\n                        probes=self.index_checks, gpu_id=self.mem_gpu_id) for x in range(b)]\n      except Exception as e:\n        print(""\\nFalling back to FLANN (CPU). \\nFor using faster, GPU based indexes, install FAISS: `conda install faiss-gpu -c pytorch`"")\n        from .flann_index import FLANNIndex\n        hidden[\'indexes\'] = \\\n            [FLANNIndex(cell_size=self.cell_size,\n                        nr_cells=self.mem_size, K=self.K, num_kdtrees=self.num_lists,\n                        probes=self.index_checks, gpu_id=self.mem_gpu_id) for x in range(b)]\n\n    # add existing memory into indexes\n    pos = hidden[\'read_positions\'].squeeze().data.cpu().numpy()\n    if not erase:\n      for n, i in enumerate(hidden[\'indexes\']):\n        i.reset()\n        i.add(hidden[\'memory\'][n], last=pos[n][-1])\n    else:\n      self.timestep = 0\n      self.mem_limit_reached = False\n\n    return hidden\n\n  def reset(self, batch_size=1, hidden=None, erase=True):\n    m = self.mem_size\n    w = self.cell_size\n    b = batch_size\n    r = self.read_heads\n    c = self.c\n\n    if hidden is None:\n      hidden = {\n          # warning can be a huge chunk of contiguous memory\n          \'memory\': cuda(T.zeros(b, m, w).fill_(\xce\xb4), gpu_id=self.mem_gpu_id),\n          \'visible_memory\': cuda(T.zeros(b, c, w).fill_(\xce\xb4), gpu_id=self.mem_gpu_id),\n          \'read_weights\': cuda(T.zeros(b, m).fill_(\xce\xb4), gpu_id=self.gpu_id),\n          \'write_weights\': cuda(T.zeros(b, m).fill_(\xce\xb4), gpu_id=self.gpu_id),\n          \'read_vectors\': cuda(T.zeros(b, r, w).fill_(\xce\xb4), gpu_id=self.gpu_id),\n          \'least_used_mem\': cuda(T.zeros(b, 1).fill_(c + 1), gpu_id=self.gpu_id).long(),\n          \'usage\': cuda(T.zeros(b, m), gpu_id=self.gpu_id),\n          \'read_positions\': cuda(T.arange(0, c).expand(b, c), gpu_id=self.gpu_id).long()\n      }\n      hidden = self.rebuild_indexes(hidden, erase=True)\n    else:\n      hidden[\'memory\'] = hidden[\'memory\'].clone()\n      hidden[\'visible_memory\'] = hidden[\'visible_memory\'].clone()\n      hidden[\'read_weights\'] = hidden[\'read_weights\'].clone()\n      hidden[\'write_weights\'] = hidden[\'write_weights\'].clone()\n      hidden[\'read_vectors\'] = hidden[\'read_vectors\'].clone()\n      hidden[\'least_used_mem\'] = hidden[\'least_used_mem\'].clone()\n      hidden[\'usage\'] = hidden[\'usage\'].clone()\n      hidden[\'read_positions\'] = hidden[\'read_positions\'].clone()\n      hidden = self.rebuild_indexes(hidden, erase)\n\n      if erase:\n        hidden[\'memory\'].data.fill_(\xce\xb4)\n        hidden[\'visible_memory\'].data.fill_(\xce\xb4)\n        hidden[\'read_weights\'].data.fill_(\xce\xb4)\n        hidden[\'write_weights\'].data.fill_(\xce\xb4)\n        hidden[\'read_vectors\'].data.fill_(\xce\xb4)\n        hidden[\'least_used_mem\'].data.fill_(c + 1)\n        hidden[\'usage\'].data.fill_(0)\n        hidden[\'read_positions\'] = cuda(\n            T.arange(0, c).expand(b, c), gpu_id=self.gpu_id).long()\n\n    return hidden\n\n  def write_into_sparse_memory(self, hidden):\n    visible_memory = hidden[\'visible_memory\']\n    positions = hidden[\'read_positions\']\n\n    (b, m, w) = hidden[\'memory\'].size()\n    # update memory\n    hidden[\'memory\'].scatter_(1, positions.unsqueeze(2).expand(b, self.c, w), visible_memory)\n\n    # non-differentiable operations\n    pos = positions.data.cpu().numpy()\n    for batch in range(b):\n      # update indexes\n      hidden[\'indexes\'][batch].reset()\n      hidden[\'indexes\'][batch].add(hidden[\'memory\'][batch], last=(pos[batch][-1] if not self.mem_limit_reached else None))\n\n    mem_limit_reached = hidden[\'least_used_mem\'][0].data.cpu().numpy()[0] >= self.mem_size - 1\n    self.mem_limit_reached = mem_limit_reached or self.mem_limit_reached\n\n    return hidden\n\n  def write(self, interpolation_gate, write_vector, write_gate, hidden):\n\n    read_weights = hidden[\'read_weights\'].gather(1, hidden[\'read_positions\'])\n    # encourage read and write in the first timestep\n    if self.timestep == 1: read_weights =  read_weights + 1\n    write_weights = hidden[\'write_weights\'].gather(1, hidden[\'read_positions\'])\n\n    hidden[\'usage\'], I = self.update_usage(\n        hidden[\'read_positions\'],\n        read_weights,\n        write_weights,\n        hidden[\'usage\']\n    )\n\n    # either we write to previous read locations\n    x = interpolation_gate * read_weights\n    # or to a new location\n    y = (1 - interpolation_gate) * I\n    write_weights = write_gate * (x + y)\n\n    # store the write weights\n    hidden[\'write_weights\'].scatter_(1, hidden[\'read_positions\'], write_weights)\n\n    # erase matrix\n    erase_matrix = I.unsqueeze(2).expand(hidden[\'visible_memory\'].size())\n\n    # write into memory\n    hidden[\'visible_memory\'] = hidden[\'visible_memory\'] * \\\n        (1 - erase_matrix) + T.bmm(write_weights.unsqueeze(2), write_vector)\n    hidden = self.write_into_sparse_memory(hidden)\n\n    # update least used memory cell\n    hidden[\'least_used_mem\'] = T.topk(hidden[\'usage\'], 1, dim=-1, largest=False)[1]\n\n    return hidden\n\n  def update_usage(self, read_positions, read_weights, write_weights, usage):\n    (b, _) = read_positions.size()\n    # usage is timesteps since a non-negligible memory access\n    u = (read_weights + write_weights > self.\xce\xb4).float()\n\n    # usage before write\n    relevant_usages = usage.gather(1, read_positions)\n\n    # indicator of words with minimal memory usage\n    minusage = T.min(relevant_usages, -1, keepdim=True)[0]\n    minusage = minusage.expand(relevant_usages.size())\n    I = (relevant_usages == minusage).float()\n\n    # usage after write\n    relevant_usages = (self.timestep - relevant_usages) * u + relevant_usages * (1 - u)\n\n    usage.scatter_(1, read_positions, relevant_usages)\n\n    return usage, I\n\n  def read_from_sparse_memory(self, memory, indexes, keys, least_used_mem, usage):\n    b = keys.size(0)\n    read_positions = []\n\n    # we search for k cells per read head\n    for batch in range(b):\n      distances, positions = indexes[batch].search(keys[batch])\n      read_positions.append(positions)\n    read_positions = T.stack(read_positions, 0)\n\n    # add least used mem to read positions\n    # TODO: explore possibility of reading co-locations or ranges and such\n    (b, r, k) = read_positions.size()\n    read_positions = var(read_positions).squeeze(1).view(b, -1)\n\n    # no gradient here\n    # temporal reads\n    (b, m, w) = memory.size()\n    # get the top KL entries\n    max_length = int(least_used_mem[0, 0].data.cpu().numpy()) if not self.mem_limit_reached else (m-1)\n\n    # differentiable ops\n    # append forward and backward read positions, might lead to duplicates\n    read_positions = T.cat([read_positions, least_used_mem], 1)\n    read_positions = T.clamp(read_positions, 0, max_length)\n\n    visible_memory = memory.gather(1, read_positions.unsqueeze(2).expand(b, self.c, w))\n\n    read_weights = \xcf\x83(\xce\xb8(visible_memory, keys), 2)\n    read_vectors = T.bmm(read_weights, visible_memory)\n    read_weights = T.prod(read_weights, 1)\n\n    return read_vectors, read_positions, read_weights, visible_memory\n\n  def read(self, read_query, hidden):\n    # sparse read\n    read_vectors, positions, read_weights, visible_memory = \\\n        self.read_from_sparse_memory(\n            hidden[\'memory\'],\n            hidden[\'indexes\'],\n            read_query,\n            hidden[\'least_used_mem\'],\n            hidden[\'usage\']\n        )\n\n    hidden[\'read_positions\'] = positions\n    hidden[\'read_weights\'] = hidden[\'read_weights\'].scatter_(1, positions, read_weights)\n    hidden[\'read_vectors\'] = read_vectors\n    hidden[\'visible_memory\'] = visible_memory\n\n    return hidden[\'read_vectors\'], hidden\n\n  def forward(self, \xce\xbe, hidden):\n    t = time.time()\n\n    # \xce\xbe = \xce\xbe.detach()\n    m = self.mem_size\n    w = self.cell_size\n    r = self.read_heads\n    c = self.c\n    b = \xce\xbe.size()[0]\n\n    if self.independent_linears:\n      # r read keys (b * r * w)\n      read_query = self.read_query_transform(\xce\xbe).view(b, r, w)\n      # write key (b * 1 * w)\n      write_vector = self.write_vector_transform(\xce\xbe).view(b, 1, w)\n      # write vector (b * 1 * r)\n      interpolation_gate = T.sigmoid(self.interpolation_gate_transform(\xce\xbe)).view(b, c)\n      # write gate (b * 1)\n      write_gate = T.sigmoid(self.write_gate_transform(\xce\xbe).view(b, 1))\n    else:\n      \xce\xbe = self.interface_weights(\xce\xbe)\n      # r read keys (b * r * w)\n      read_query = \xce\xbe[:, :r * w].contiguous().view(b, r, w)\n      # write key (b * 1 * w)\n      write_vector = \xce\xbe[:, r * w: r * w + w].contiguous().view(b, 1, w)\n      # write vector (b * 1 * r)\n      interpolation_gate = T.sigmoid(\xce\xbe[:, r * w + w: r * w + w + c]).contiguous().view(b, c)\n      # write gate (b * 1)\n      write_gate = T.sigmoid(\xce\xbe[:, -1].contiguous()).unsqueeze(1).view(b, 1)\n\n    self.timestep += 1\n    hidden = self.write(interpolation_gate, write_vector, write_gate, hidden)\n    return self.read(read_query, hidden)\n'"
dnc/sparse_temporal_memory.py,3,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nimport numpy as np\nimport math\n\nfrom .util import *\nimport time\n\n\nclass SparseTemporalMemory(nn.Module):\n\n  def __init__(\n      self,\n      input_size,\n      mem_size=512,\n      cell_size=32,\n      independent_linears=True,\n      read_heads=4,\n      sparse_reads=4,\n      temporal_reads=4,\n      num_lists=None,\n      index_checks=32,\n      gpu_id=-1,\n      mem_gpu_id=-1\n  ):\n    super(SparseTemporalMemory, self).__init__()\n\n    self.mem_size = mem_size\n    self.cell_size = cell_size\n    self.gpu_id = gpu_id\n    self.mem_gpu_id = mem_gpu_id\n    self.input_size = input_size\n    self.independent_linears = independent_linears\n    self.K = sparse_reads if self.mem_size > sparse_reads else self.mem_size\n    self.KL = temporal_reads if self.mem_size > temporal_reads else self.mem_size\n    self.read_heads = read_heads\n    self.num_lists = num_lists if num_lists is not None else int(self.mem_size / 100)\n    self.index_checks = index_checks\n\n    m = self.mem_size\n    w = self.cell_size\n    r = self.read_heads\n    # The visible memory size: (K * R read heads, forward and backward\n    # temporal reads of size KL and least used memory cell)\n    self.c = (r * self.K) + (self.KL * 2) + 1\n\n    if self.independent_linears:\n      self.read_query_transform = nn.Linear(self.input_size, w * r)\n      self.write_vector_transform = nn.Linear(self.input_size, w)\n      self.interpolation_gate_transform = nn.Linear(self.input_size, self.c)\n      self.write_gate_transform = nn.Linear(self.input_size, 1)\n      T.nn.init.orthogonal_(self.read_query_transform.weight)\n      T.nn.init.orthogonal_(self.write_vector_transform.weight)\n      T.nn.init.orthogonal_(self.interpolation_gate_transform.weight)\n      T.nn.init.orthogonal_(self.write_gate_transform.weight)\n    else:\n      self.interface_size = (r * w) + w + self.c + 1\n      self.interface_weights = nn.Linear(self.input_size, self.interface_size)\n      T.nn.init.orthogonal_(self.interface_weights.weight)\n\n    self.I = cuda(1 - T.eye(self.c).unsqueeze(0), gpu_id=self.gpu_id)  # (1 * n * n)\n    self.\xce\xb4 = 0.005  # minimum usage\n    self.timestep = 0\n    self.mem_limit_reached = False\n\n  def rebuild_indexes(self, hidden, erase=False):\n    b = hidden[\'memory\'].size(0)\n\n    # if indexes already exist, we reset them\n    if \'indexes\' in hidden:\n      [x.reset() for x in hidden[\'indexes\']]\n    else:\n      # create new indexes\n      try:\n        from .faiss_index import FAISSIndex\n        hidden[\'indexes\'] = \\\n            [FAISSIndex(cell_size=self.cell_size,\n                        nr_cells=self.mem_size, K=self.K, num_lists=self.num_lists,\n                        probes=self.index_checks, gpu_id=self.mem_gpu_id) for x in range(b)]\n      except Exception as e:\n        print(""\\nFalling back to FLANN (CPU). \\nFor using faster, GPU based indexes, install FAISS: `conda install faiss-gpu -c pytorch`"")\n        from .flann_index import FLANNIndex\n        hidden[\'indexes\'] = \\\n            [FLANNIndex(cell_size=self.cell_size,\n                        nr_cells=self.mem_size, K=self.K, num_kdtrees=self.num_lists,\n                        probes=self.index_checks, gpu_id=self.mem_gpu_id) for x in range(b)]\n\n    # add existing memory into indexes\n    pos = hidden[\'read_positions\'].squeeze().data.cpu().numpy()\n    if not erase:\n      for n, i in enumerate(hidden[\'indexes\']):\n        i.reset()\n        i.add(hidden[\'memory\'][n], last=pos[n][-1])\n    else:\n      self.timestep = 0\n      self.mem_limit_reached = False\n\n    return hidden\n\n  def reset(self, batch_size=1, hidden=None, erase=True):\n    m = self.mem_size\n    w = self.cell_size\n    b = batch_size\n    r = self.read_heads\n    c = self.c\n\n    if hidden is None:\n      hidden = {\n          # warning can be a huge chunk of contiguous memory\n          \'memory\': cuda(T.zeros(b, m, w).fill_(\xce\xb4), gpu_id=self.mem_gpu_id),\n          \'visible_memory\': cuda(T.zeros(b, c, w).fill_(\xce\xb4), gpu_id=self.mem_gpu_id),\n          \'link_matrix\': cuda(T.zeros(b, m, self.KL * 2), gpu_id=self.gpu_id),\n          \'rev_link_matrix\': cuda(T.zeros(b, m, self.KL * 2), gpu_id=self.gpu_id),\n          \'precedence\': cuda(T.zeros(b, self.KL * 2).fill_(\xce\xb4), gpu_id=self.gpu_id),\n          \'read_weights\': cuda(T.zeros(b, m).fill_(\xce\xb4), gpu_id=self.gpu_id),\n          \'write_weights\': cuda(T.zeros(b, m).fill_(\xce\xb4), gpu_id=self.gpu_id),\n          \'read_vectors\': cuda(T.zeros(b, r, w).fill_(\xce\xb4), gpu_id=self.gpu_id),\n          \'least_used_mem\': cuda(T.zeros(b, 1).fill_(c + 1), gpu_id=self.gpu_id).long(),\n          \'usage\': cuda(T.zeros(b, m), gpu_id=self.gpu_id),\n          \'read_positions\': cuda(T.arange(0, c).expand(b, c), gpu_id=self.gpu_id).long()\n      }\n      hidden = self.rebuild_indexes(hidden, erase=True)\n    else:\n      hidden[\'memory\'] = hidden[\'memory\'].clone()\n      hidden[\'visible_memory\'] = hidden[\'visible_memory\'].clone()\n      hidden[\'link_matrix\'] = hidden[\'link_matrix\'].clone()\n      hidden[\'rev_link_matrix\'] = hidden[\'link_matrix\'].clone()\n      hidden[\'precedence\'] = hidden[\'precedence\'].clone()\n      hidden[\'read_weights\'] = hidden[\'read_weights\'].clone()\n      hidden[\'write_weights\'] = hidden[\'write_weights\'].clone()\n      hidden[\'read_vectors\'] = hidden[\'read_vectors\'].clone()\n      hidden[\'least_used_mem\'] = hidden[\'least_used_mem\'].clone()\n      hidden[\'usage\'] = hidden[\'usage\'].clone()\n      hidden[\'read_positions\'] = hidden[\'read_positions\'].clone()\n      hidden = self.rebuild_indexes(hidden, erase)\n\n      if erase:\n        hidden[\'memory\'].data.fill_(\xce\xb4)\n        hidden[\'visible_memory\'].data.fill_(\xce\xb4)\n        hidden[\'link_matrix\'].data.zero_()\n        hidden[\'rev_link_matrix\'].data.zero_()\n        hidden[\'precedence\'].data.zero_()\n        hidden[\'read_weights\'].data.fill_(\xce\xb4)\n        hidden[\'write_weights\'].data.fill_(\xce\xb4)\n        hidden[\'read_vectors\'].data.fill_(\xce\xb4)\n        hidden[\'least_used_mem\'].data.fill_(c + 1 + self.timestep)\n        hidden[\'usage\'].data.fill_(0)\n        hidden[\'read_positions\'] = cuda(\n            T.arange(self.timestep, c + self.timestep).expand(b, c), gpu_id=self.gpu_id).long()\n\n    return hidden\n\n  def write_into_sparse_memory(self, hidden):\n    visible_memory = hidden[\'visible_memory\']\n    positions = hidden[\'read_positions\']\n\n    (b, m, w) = hidden[\'memory\'].size()\n    # update memory\n    hidden[\'memory\'].scatter_(1, positions.unsqueeze(2).expand(b, self.c, w), visible_memory)\n\n    # non-differentiable operations\n    pos = positions.data.cpu().numpy()\n    for batch in range(b):\n      # update indexes\n      hidden[\'indexes\'][batch].reset()\n      hidden[\'indexes\'][batch].add(hidden[\'memory\'][batch], last=(pos[batch][-1] if not self.mem_limit_reached else None))\n\n    mem_limit_reached = hidden[\'least_used_mem\'][0].data.cpu().numpy()[0] >= self.mem_size - 1\n    self.mem_limit_reached = mem_limit_reached or self.mem_limit_reached\n\n    return hidden\n\n  def update_link_matrices(self, link_matrix, rev_link_matrix, write_weights, precedence, temporal_read_positions):\n    write_weights_i = write_weights.unsqueeze(2)\n    precedence_j = precedence.unsqueeze(1)\n\n    (b, m, k) = link_matrix.size()\n    I = cuda(T.eye(m, k).unsqueeze(0).expand((b, m, k)), gpu_id=self.gpu_id)\n\n    # since only KL*2 entries are kept non-zero sparse, create the dense version from the sparse one\n    precedence_dense = cuda(T.zeros(b, m), gpu_id=self.gpu_id)\n    precedence_dense.scatter_(1, temporal_read_positions, precedence)\n    precedence_dense_i = precedence_dense.unsqueeze(2)\n\n    temporal_write_weights_j = write_weights.gather(1, temporal_read_positions).unsqueeze(1)\n\n    link_matrix = (1 - write_weights_i) * link_matrix + write_weights_i * precedence_j\n\n    rev_link_matrix = (1 - temporal_write_weights_j) * rev_link_matrix + \\\n        (temporal_write_weights_j * precedence_dense_i)\n\n    return link_matrix * I, rev_link_matrix * I\n\n  def update_precedence(self, precedence, write_weights):\n    return (1 - T.sum(write_weights, dim=-1, keepdim=True)) * precedence + write_weights\n\n  def write(self, interpolation_gate, write_vector, write_gate, hidden):\n\n    read_weights = hidden[\'read_weights\'].gather(1, hidden[\'read_positions\'])\n    # encourage read and write in the first timestep\n    if self.timestep == 1: read_weights =  read_weights + 1\n    write_weights = hidden[\'write_weights\'].gather(1, hidden[\'read_positions\'])\n\n    hidden[\'usage\'], I = self.update_usage(\n        hidden[\'read_positions\'],\n        read_weights,\n        write_weights,\n        hidden[\'usage\']\n    )\n\n    # either we write to previous read locations\n    x = interpolation_gate * read_weights\n    # or to a new location\n    y = (1 - interpolation_gate) * I\n    write_weights = write_gate * (x + y)\n\n    # store the write weights\n    hidden[\'write_weights\'].scatter_(1, hidden[\'read_positions\'], write_weights)\n\n    # erase matrix\n    erase_matrix = I.unsqueeze(2).expand(hidden[\'visible_memory\'].size())\n\n    # write into memory\n    hidden[\'visible_memory\'] = hidden[\'visible_memory\'] * \\\n        (1 - erase_matrix) + T.bmm(write_weights.unsqueeze(2), write_vector)\n    hidden = self.write_into_sparse_memory(hidden)\n\n    # update link_matrix and precedence\n    (b, c) = write_weights.size()\n\n    # update link matrix\n    temporal_read_positions = hidden[\'read_positions\'][:, self.read_heads * self.K + 1:]\n    hidden[\'link_matrix\'], hidden[\'rev_link_matrix\'] = \\\n        self.update_link_matrices(\n        hidden[\'link_matrix\'],\n        hidden[\'rev_link_matrix\'],\n        hidden[\'write_weights\'],\n        hidden[\'precedence\'],\n        temporal_read_positions\n    )\n\n    # update precedence vector\n    read_weights = hidden[\'read_weights\'].gather(1, temporal_read_positions)\n    hidden[\'precedence\'] = self.update_precedence(hidden[\'precedence\'], read_weights)\n\n    # update least used memory cell\n    hidden[\'least_used_mem\'] = T.topk(hidden[\'usage\'], 1, dim=-1, largest=False)[1]\n\n    return hidden\n\n  def update_usage(self, read_positions, read_weights, write_weights, usage):\n    (b, _) = read_positions.size()\n    # usage is timesteps since a non-negligible memory access\n    u = (read_weights + write_weights > self.\xce\xb4).float()\n\n    # usage before write\n    relevant_usages = usage.gather(1, read_positions)\n\n    # indicator of words with minimal memory usage\n    minusage = T.min(relevant_usages, -1, keepdim=True)[0]\n    minusage = minusage.expand(relevant_usages.size())\n    I = (relevant_usages == minusage).float()\n\n    # usage after write\n    relevant_usages = (self.timestep - relevant_usages) * u + relevant_usages * (1 - u)\n\n    usage.scatter_(1, read_positions, relevant_usages)\n\n    return usage, I\n\n  def directional_weightings(self, link_matrix, rev_link_matrix, temporal_read_weights):\n    f = T.bmm(link_matrix, temporal_read_weights.unsqueeze(2)).squeeze(2)\n    b = T.bmm(rev_link_matrix, temporal_read_weights.unsqueeze(2)).squeeze(2)\n    return f, b\n\n  def read_from_sparse_memory(self, memory, indexes, keys, least_used_mem, usage, forward, backward, prev_read_positions):\n    b = keys.size(0)\n    read_positions = []\n\n    # we search for k cells per read head\n    for batch in range(b):\n      distances, positions = indexes[batch].search(keys[batch])\n      read_positions.append(positions)\n    read_positions = T.stack(read_positions, 0)\n\n    # add least used mem to read positions\n    # TODO: explore possibility of reading co-locations or ranges and such\n    (b, r, k) = read_positions.size()\n    read_positions = var(read_positions).squeeze(1).view(b, -1)\n\n    # no gradient here\n    # temporal reads\n    (b, m, w) = memory.size()\n    # get the top KL entries\n    max_length = int(least_used_mem[0, 0].data.cpu().numpy()) if not self.mem_limit_reached else (m-1)\n\n    _, fp = T.topk(forward, self.KL, largest=True)\n    _, bp = T.topk(backward, self.KL, largest=True)\n\n    # differentiable ops\n    # append forward and backward read positions, might lead to duplicates\n    read_positions = T.cat([read_positions, fp, bp], 1)\n    read_positions = T.cat([read_positions, least_used_mem], 1)\n    read_positions = T.clamp(read_positions, 0, max_length)\n\n    visible_memory = memory.gather(1, read_positions.unsqueeze(2).expand(b, self.c, w))\n\n    read_weights = \xcf\x83(\xce\xb8(visible_memory, keys), 2)\n    read_vectors = T.bmm(read_weights, visible_memory)\n    read_weights = T.prod(read_weights, 1)\n\n    return read_vectors, read_positions, read_weights, visible_memory\n\n  def read(self, read_query, hidden):\n    # get forward and backward weights\n    temporal_read_positions = hidden[\'read_positions\'][:, self.read_heads * self.K + 1:]\n    read_weights = hidden[\'read_weights\'].gather(1, temporal_read_positions)\n    forward, backward = self.directional_weightings(hidden[\'link_matrix\'], hidden[\'rev_link_matrix\'], read_weights)\n\n    # sparse read\n    read_vectors, positions, read_weights, visible_memory = \\\n        self.read_from_sparse_memory(\n            hidden[\'memory\'],\n            hidden[\'indexes\'],\n            read_query,\n            hidden[\'least_used_mem\'],\n            hidden[\'usage\'],\n            forward, backward,\n            hidden[\'read_positions\']\n        )\n\n    hidden[\'read_positions\'] = positions\n    hidden[\'read_weights\'] = hidden[\'read_weights\'].scatter_(1, positions, read_weights)\n    hidden[\'read_vectors\'] = read_vectors\n    hidden[\'visible_memory\'] = visible_memory\n\n    return hidden[\'read_vectors\'], hidden\n\n  def forward(self, \xce\xbe, hidden):\n    t = time.time()\n\n    # \xce\xbe = \xce\xbe.detach()\n    m = self.mem_size\n    w = self.cell_size\n    r = self.read_heads\n    c = self.c\n    b = \xce\xbe.size()[0]\n\n    if self.independent_linears:\n      # r read keys (b * r * w)\n      read_query = self.read_query_transform(\xce\xbe).view(b, r, w)\n      # write key (b * 1 * w)\n      write_vector = self.write_vector_transform(\xce\xbe).view(b, 1, w)\n      # write vector (b * 1 * r)\n      interpolation_gate = T.sigmoid(self.interpolation_gate_transform(\xce\xbe)).view(b, c)\n      # write gate (b * 1)\n      write_gate = T.sigmoid(self.write_gate_transform(\xce\xbe).view(b, 1))\n    else:\n      \xce\xbe = self.interface_weights(\xce\xbe)\n      # r read keys (b * r * w)\n      read_query = \xce\xbe[:, :r * w].contiguous().view(b, r, w)\n      # write key (b * 1 * w)\n      write_vector = \xce\xbe[:, r * w: r * w + w].contiguous().view(b, 1, w)\n      # write vector (b * 1 * r)\n      interpolation_gate = T.sigmoid(\xce\xbe[:, r * w + w: r * w + w + c]).contiguous().view(b, c)\n      # write gate (b * 1)\n      write_gate = T.sigmoid(\xce\xbe[:, -1].contiguous()).unsqueeze(1).view(b, 1)\n\n    self.timestep += 1\n    hidden = self.write(interpolation_gate, write_vector, write_gate, hidden)\n    return self.read(read_query, hidden)\n'"
dnc/util.py,3,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nimport torch.nn.functional as F\nimport numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport re\nimport string\n\n\ndef recursiveTrace(obj):\n  print(type(obj))\n  if hasattr(obj, \'grad_fn\'):\n    print(obj.grad_fn)\n    recursiveTrace(obj.grad_fn)\n  elif hasattr(obj, \'saved_variables\'):\n    print(obj.requires_grad, len(obj.saved_tensors), len(obj.saved_variables))\n    [print(v) for v in obj.saved_variables]\n    [recursiveTrace(v.grad_fn) for v in obj.saved_variables]\n\n\ndef cuda(x, grad=False, gpu_id=-1):\n  x = x.float() if T.is_tensor(x) else x\n  if gpu_id == -1:\n    t = T.FloatTensor(x)\n    t.requires_grad=grad\n    return t\n  else:\n    t = T.FloatTensor(x.pin_memory()).cuda(gpu_id)\n    t.requires_grad=grad\n    return t\n\n\ndef cudavec(x, grad=False, gpu_id=-1):\n  if gpu_id == -1:\n    t = T.Tensor(T.from_numpy(x))\n    t.requires_grad = grad\n    return t\n  else:\n    t = T.Tensor(T.from_numpy(x).pin_memory()).cuda(gpu_id)\n    t.requires_grad = grad\n    return t\n\n\ndef cudalong(x, grad=False, gpu_id=-1):\n  if gpu_id == -1:\n    t = T.LongTensor(T.from_numpy(x.astype(np.long)))\n    t.requires_grad = grad\n    return t\n  else:\n    t = T.LongTensor(T.from_numpy(x.astype(np.long)).pin_memory()).cuda(gpu_id)\n    t.requires_grad = grad\n    return t\n\n\ndef \xce\xb8(a, b, dimA=2, dimB=2, normBy=2):\n  """"""Batchwise Cosine distance\n\n  Cosine distance\n\n  Arguments:\n      a {Tensor} -- A 3D Tensor (b * m * w)\n      b {Tensor} -- A 3D Tensor (b * r * w)\n\n  Keyword Arguments:\n      dimA {number} -- exponent value of the norm for `a` (default: {2})\n      dimB {number} -- exponent value of the norm for `b` (default: {1})\n\n  Returns:\n      Tensor -- Batchwise cosine distance (b * r * m)\n  """"""\n  a_norm = T.norm(a, normBy, dimA, keepdim=True).expand_as(a) + \xce\xb4\n  b_norm = T.norm(b, normBy, dimB, keepdim=True).expand_as(b) + \xce\xb4\n\n  x = T.bmm(a, b.transpose(1, 2)).transpose(1, 2) / (\n      T.bmm(a_norm, b_norm.transpose(1, 2)).transpose(1, 2) + \xce\xb4)\n  # apply_dict(locals())\n  return x\n\n\ndef \xcf\x83(input, axis=1):\n  """"""Softmax on an axis\n\n  Softmax on an axis\n\n  Arguments:\n      input {Tensor} -- input Tensor\n\n  Keyword Arguments:\n      axis {number} -- axis on which to take softmax on (default: {1})\n\n  Returns:\n      Tensor -- Softmax output Tensor\n  """"""\n  input_size = input.size()\n\n  trans_input = input.transpose(axis, len(input_size) - 1)\n  trans_size = trans_input.size()\n\n  input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n  soft_max_2d = F.softmax(input_2d, -1)\n  soft_max_nd = soft_max_2d.view(*trans_size)\n  return soft_max_nd.transpose(axis, len(input_size) - 1)\n\n\xce\xb4 = 1e-6\n\n\ndef register_nan_checks(model):\n  def check_grad(module, grad_input, grad_output):\n    # print(module) you can add this to see that the hook is called\n    # print(\'hook called for \' + str(type(module)))\n    if any(np.all(np.isnan(gi.data.cpu().numpy())) for gi in grad_input if gi is not None):\n      print(\'NaN gradient in grad_input \' + type(module).__name__)\n\n  model.apply(lambda module: module.register_backward_hook(check_grad))\n\n\ndef apply_dict(dic):\n  for k, v in dic.items():\n    apply_var(v, k)\n    if isinstance(v, nn.Module):\n      key_list = [a for a in dir(v) if not a.startswith(\'__\')]\n      for key in key_list:\n        apply_var(getattr(v, key), key)\n      for pk, pv in v._parameters.items():\n        apply_var(pv, pk)\n\n\ndef apply_var(v, k):\n  if isinstance(v, Variable) and v.requires_grad:\n    v.register_hook(check_nan_gradient(k))\n\n\ndef check_nan_gradient(name=\'\'):\n  def f(tensor):\n    if np.isnan(T.mean(tensor).data.cpu().numpy()):\n      print(\'\\nnan gradient of {} :\'.format(name))\n      # print(tensor)\n      # assert 0, \'nan gradient\'\n      return tensor\n  return f\n\ndef ptr(tensor):\n  if T.is_tensor(tensor):\n    return tensor.storage().data_ptr()\n  elif hasattr(tensor, \'data\'):\n    return tensor.clone().data.storage().data_ptr()\n  else:\n    return tensor\n\n# TODO: EWW change this shit\ndef ensure_gpu(tensor, gpu_id):\n  if ""cuda"" in str(type(tensor)) and gpu_id != -1:\n    return tensor.cuda(gpu_id)\n  elif ""cuda"" in str(type(tensor)):\n    return tensor.cpu()\n  elif ""Tensor"" in str(type(tensor)) and gpu_id != -1:\n    return tensor.cuda(gpu_id)\n  elif ""Tensor"" in str(type(tensor)):\n    return tensor\n  elif type(tensor) is np.ndarray:\n    return cudavec(tensor, gpu_id=gpu_id).data\n  else:\n    return tensor\n\n\ndef print_gradient(x, name):\n  s = ""Gradient of "" + name + "" ----------------------------------""\n  x.register_hook(lambda y: print(s, y.squeeze()))\n'"
tasks/__init__.py,0,b''
tasks/adding_task.py,4,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport warnings\nwarnings.filterwarnings(\'ignore\')\n\nimport numpy as np\nimport getopt\nimport sys\nimport os\nimport math\nimport time\nimport argparse\nfrom visdom import Visdom\n\nsys.path.insert(0, os.path.join(\'..\', \'..\'))\n\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.nn.utils import clip_grad_norm_\n\nfrom dnc.dnc import DNC\nfrom dnc.sdnc import SDNC\nfrom dnc.sam import SAM\nfrom dnc.util import *\n\nparser = argparse.ArgumentParser(description=\'PyTorch Differentiable Neural Computer\')\nparser.add_argument(\'-input_size\', type=int, default=6, help=\'dimension of input feature\')\nparser.add_argument(\'-rnn_type\', type=str, default=\'lstm\', help=\'type of recurrent cells to use for the controller\')\nparser.add_argument(\'-nhid\', type=int, default=64, help=\'number of hidden units of the inner nn\')\nparser.add_argument(\'-dropout\', type=float, default=0, help=\'controller dropout\')\nparser.add_argument(\'-memory_type\', type=str, default=\'dnc\', help=\'dense or sparse memory: dnc | sdnc | sam\')\n\nparser.add_argument(\'-nlayer\', type=int, default=1, help=\'number of layers\')\nparser.add_argument(\'-nhlayer\', type=int, default=2, help=\'number of hidden layers\')\nparser.add_argument(\'-lr\', type=float, default=1e-4, help=\'initial learning rate\')\nparser.add_argument(\'-optim\', type=str, default=\'adam\', help=\'learning rule, supports adam|rmsprop\')\nparser.add_argument(\'-clip\', type=float, default=50, help=\'gradient clipping\')\n\nparser.add_argument(\'-batch_size\', type=int, default=100, metavar=\'N\', help=\'batch size\')\nparser.add_argument(\'-mem_size\', type=int, default=20, help=\'memory dimension\')\nparser.add_argument(\'-mem_slot\', type=int, default=16, help=\'number of memory slots\')\nparser.add_argument(\'-read_heads\', type=int, default=4, help=\'number of read heads\')\nparser.add_argument(\'-sparse_reads\', type=int, default=10, help=\'number of sparse reads per read head\')\nparser.add_argument(\'-temporal_reads\', type=int, default=2, help=\'number of temporal reads\')\n\nparser.add_argument(\'-sequence_max_length\', type=int, default=1000, metavar=\'N\', help=\'sequence_max_length\')\nparser.add_argument(\'-cuda\', type=int, default=-1, help=\'Cuda GPU ID, -1 for CPU\')\n\nparser.add_argument(\'-iterations\', type=int, default=2000, metavar=\'N\', help=\'total number of iteration\')\nparser.add_argument(\'-summarize_freq\', type=int, default=100, metavar=\'N\', help=\'summarize frequency\')\nparser.add_argument(\'-check_freq\', type=int, default=100, metavar=\'N\', help=\'check point frequency\')\nparser.add_argument(\'-visdom\', action=\'store_true\', help=\'plot memory content on visdom per -summarize_freq steps\')\n\nargs = parser.parse_args()\nprint(args)\n\nviz = Visdom()\n# assert viz.check_connection()\n\nif args.cuda != -1:\n  print(\'Using CUDA.\')\n  T.manual_seed(1111)\nelse:\n  print(\'Using CPU.\')\n\ndef llprint(message):\n  sys.stdout.write(message)\n  sys.stdout.flush()\n\n\ndef onehot(x, n):\n  ret = np.zeros(n).astype(np.float32)\n  ret[x] = 1.0\n  return ret\n\n\ndef generate_data(length, size):\n\n  content = np.random.randint(0, size - 1, length)\n\n  seqlen = length + 1\n  x_seq_list = [float(\'nan\')] * seqlen\n  sums = 0.0\n  sums_text = """"\n  for i in range(seqlen):\n    if (i < length):\n      x_seq_list[i] = onehot(content[i], size)\n      sums += content[i]\n      sums_text += str(content[i]) + "" + ""\n    else:\n      x_seq_list[i] = onehot(size - 1, size)\n\n  x_seq_list = np.array(x_seq_list)\n  x_seq_list = x_seq_list.reshape((1,) + x_seq_list.shape)\n  sums = np.array(sums)\n  sums = sums.reshape(1, 1, 1)\n\n  return cudavec(x_seq_list.astype(np.float32), gpu_id=args.cuda).float(), \\\n          cudavec(sums.astype(np.float32), gpu_id=args.cuda).float(), \\\n          sums_text\n\n\ndef cross_entropy(prediction, target):\n  return (prediction - target) ** 2\n\n\nif __name__ == \'__main__\':\n\n  dirname = os.path.dirname(__file__)\n  ckpts_dir = os.path.join(dirname, \'checkpoints\')\n\n  input_size = args.input_size\n  memory_type = args.memory_type\n  lr = args.lr\n  clip = args.clip\n  batch_size = args.batch_size\n  sequence_max_length = args.sequence_max_length\n  cuda = args.cuda\n  iterations = args.iterations\n  summarize_freq = args.summarize_freq\n  check_freq = args.check_freq\n  visdom = args.visdom\n\n  from_checkpoint = None\n\n  if args.memory_type == \'dnc\':\n    rnn = DNC(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=args.mem_slot,\n        cell_size=args.mem_size,\n        read_heads=args.read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=True\n    )\n  elif args.memory_type == \'sdnc\':\n    rnn = SDNC(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=args.mem_slot,\n        cell_size=args.mem_size,\n        sparse_reads=args.sparse_reads,\n        temporal_reads=args.temporal_reads,\n        read_heads=args.read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=False\n    )\n  elif args.memory_type == \'sam\':\n    rnn = SAM(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=args.mem_slot,\n        cell_size=args.mem_size,\n        sparse_reads=args.sparse_reads,\n        read_heads=args.read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=False\n    )\n  else:\n    raise Exception(\'Not recognized type of memory\')\n\n  if args.cuda != -1:\n    rnn = rnn.cuda(args.cuda)\n\n  print(rnn)\n\n  last_save_losses = []\n\n  if args.optim == \'adam\':\n    optimizer = optim.Adam(rnn.parameters(), lr=args.lr, eps=1e-9, betas=[0.9, 0.98])  # 0.0001\n  elif args.optim == \'adamax\':\n    optimizer = optim.Adamax(rnn.parameters(), lr=args.lr, eps=1e-9, betas=[0.9, 0.98])  # 0.0001\n  elif args.optim == \'rmsprop\':\n    optimizer = optim.RMSprop(rnn.parameters(), lr=args.lr, momentum=0.9, eps=1e-10)  # 0.0001\n  elif args.optim == \'sgd\':\n    optimizer = optim.SGD(rnn.parameters(), lr=args.lr)  # 0.01\n  elif args.optim == \'adagrad\':\n    optimizer = optim.Adagrad(rnn.parameters(), lr=args.lr)\n  elif args.optim == \'adadelta\':\n    optimizer = optim.Adadelta(rnn.parameters(), lr=args.lr)\n\n  last_100_losses = []\n\n  (chx, mhx, rv) = (None, None, None)\n  for epoch in range(iterations + 1):\n    llprint(""\\rIteration {ep}/{tot}"".format(ep=epoch, tot=iterations))\n    optimizer.zero_grad()\n    # We use for training just (sequence_max_length / 10) examples\n    random_length = np.random.randint(2, (sequence_max_length) + 1)\n    input_data, target_output, sums_text = generate_data(random_length, input_size)\n\n    if rnn.debug:\n      output, (chx, mhx, rv), v = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n    else:\n      output, (chx, mhx, rv) = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n\n    output = output.sum(dim=2, keepdim=True).sum(dim=1, keepdim=True)\n    loss = cross_entropy(output, target_output)\n\n    loss.backward()\n\n    T.nn.utils.clip_grad_norm_(rnn.parameters(), args.clip)\n    optimizer.step()\n    loss_value = loss.item()\n\n    # detach memory from graph\n    mhx = { k : (v.detach() if isinstance(v, var) else v) for k, v in mhx.items() }\n\n    summarize = (epoch % summarize_freq == 0)\n    take_checkpoint = (epoch != 0) and (epoch % iterations == 0)\n\n    last_100_losses.append(loss_value)\n\n    if summarize:\n      llprint(""\\rIteration %d/%d"" % (epoch, iterations))\n      llprint(""\\nAvg. Logistic Loss: %.4f\\n"" % (np.mean(last_100_losses)))\n      output = output.data.cpu().numpy()\n      print(""Real value: "", \' = \' + str(int(target_output[0])))\n      print(""Predicted:  "", \' = \' + str(int(output // 1)) + "" ["" + str(output) + ""]"")\n      last_100_losses = []\n\n    if take_checkpoint:\n      llprint(""\\nSaving Checkpoint ... ""),\n      check_ptr = os.path.join(ckpts_dir, \'step_{}.pth\'.format(epoch))\n      cur_weights = rnn.state_dict()\n      T.save(cur_weights, check_ptr)\n      llprint(""Done!\\n"")\n\n  llprint(""\\nTesting generalization...\\n"")\n\n  rnn.eval()\n\n  for i in range(int((iterations + 1) / 10)):\n    llprint(""\\nIteration %d/%d"" % (i, iterations))\n    # We test now the learned generalization using sequence_max_length examples\n    random_length = np.random.randint(2, int(sequence_max_length) * 10 + 1)\n    input_data, target_output, sums_text = generate_data(random_length, input_size)\n\n    if rnn.debug:\n      output, (chx, mhx, rv), v = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n    else:\n      output, (chx, mhx, rv) = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n\n    output = output.sum(dim=2, keepdim=True).sum(dim=1, keepdim=True)\n    output = output.data.cpu().numpy()\n    print(""\\nReal value: "", \' = \' + str(int(target_output[0])))\n    print(""Predicted:  "", \' = \' + str(int(output // 1)) + "" ["" + str(output) + ""]"")\n'"
tasks/argmax_task.py,4,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport warnings\nwarnings.filterwarnings(\'ignore\')\n\nimport numpy as np\nimport getopt\nimport sys\nimport os\nimport math\nimport time\nimport argparse\nfrom visdom import Visdom\n\nsys.path.insert(0, os.path.join(\'..\', \'..\'))\n\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.nn.utils import clip_grad_norm_\n\nfrom dnc.dnc import DNC\nfrom dnc.sdnc import SDNC\nfrom dnc.sam import SAM\nfrom dnc.util import *\n\nparser = argparse.ArgumentParser(description=\'PyTorch Differentiable Neural Computer\')\nparser.add_argument(\'-input_size\', type=int, default=6, help=\'dimension of input feature\')\nparser.add_argument(\'-rnn_type\', type=str, default=\'lstm\', help=\'type of recurrent cells to use for the controller\')\nparser.add_argument(\'-nhid\', type=int, default=100, help=\'number of hidden units of the inner nn\')\nparser.add_argument(\'-dropout\', type=float, default=0, help=\'controller dropout\')\nparser.add_argument(\'-memory_type\', type=str, default=\'dnc\', help=\'dense or sparse memory: dnc | sdnc | sam\')\n\nparser.add_argument(\'-nlayer\', type=int, default=1, help=\'number of layers\')\nparser.add_argument(\'-nhlayer\', type=int, default=2, help=\'number of hidden layers\')\nparser.add_argument(\'-lr\', type=float, default=1e-4, help=\'initial learning rate\')\nparser.add_argument(\'-optim\', type=str, default=\'adam\', help=\'learning rule, supports adam|rmsprop\')\nparser.add_argument(\'-clip\', type=float, default=50, help=\'gradient clipping\')\n\nparser.add_argument(\'-batch_size\', type=int, default=100, metavar=\'N\', help=\'batch size\')\nparser.add_argument(\'-mem_size\', type=int, default=20, help=\'memory dimension\')\nparser.add_argument(\'-mem_slot\', type=int, default=16, help=\'number of memory slots\')\nparser.add_argument(\'-read_heads\', type=int, default=4, help=\'number of read heads\')\nparser.add_argument(\'-sparse_reads\', type=int, default=10, help=\'number of sparse reads per read head\')\nparser.add_argument(\'-temporal_reads\', type=int, default=2, help=\'number of temporal reads\')\n\nparser.add_argument(\'-sequence_max_length\', type=int, default=4, metavar=\'N\', help=\'sequence_max_length\')\nparser.add_argument(\'-cuda\', type=int, default=-1, help=\'Cuda GPU ID, -1 for CPU\')\n\nparser.add_argument(\'-iterations\', type=int, default=2000, metavar=\'N\', help=\'total number of iteration\')\nparser.add_argument(\'-summarize_freq\', type=int, default=100, metavar=\'N\', help=\'summarize frequency\')\nparser.add_argument(\'-check_freq\', type=int, default=100, metavar=\'N\', help=\'check point frequency\')\nparser.add_argument(\'-visdom\', action=\'store_true\', help=\'plot memory content on visdom per -summarize_freq steps\')\n\nargs = parser.parse_args()\nprint(args)\n\nviz = Visdom()\n# assert viz.check_connection()\n\nif args.cuda != -1:\n  print(\'Using CUDA.\')\n  T.manual_seed(1111)\nelse:\n  print(\'Using CPU.\')\n\ndef llprint(message):\n  sys.stdout.write(message)\n  sys.stdout.flush()\n\n\ndef onehot(x, n):\n  ret = np.zeros(n).astype(np.float32)\n  ret[x] = 1.0\n  return ret\n\n\ndef generate_data(length, size):\n\n  content = np.random.randint(0, size - 1, length)\n\n  seqlen = length + 1\n  x_seq_list = [float(\'nan\')] * seqlen\n  max_value = 0\n  max_ind = 0\n  for i in range(seqlen):\n      if (i < length):\n          x_seq_list[i] = onehot(content[i], size)\n          if (max_value <= content[i]):\n              max_value = content[i]\n              max_ind = i\n      else:\n          x_seq_list[i] = onehot(size - 1, size)\n\n  x_seq_list = np.array(x_seq_list)\n  x_seq_list = x_seq_list.reshape((1,) + x_seq_list.shape)\n  x_seq_list = np.reshape(x_seq_list, (1, -1, size))\n\n  target_output = np.zeros((1, 1, seqlen), dtype=np.float32)\n  target_output[:, -1, -1] = max_ind\n  target_output = np.reshape(target_output, (1, -1, 1))\n\n  weights_vec = np.zeros((1, 1, seqlen), dtype=np.float32)\n  weights_vec[:, -1, -1] = 1.0\n  weights_vec = np.reshape(weights_vec, (1, -1, 1))\n\n  return cudavec(x_seq_list, gpu_id=args.cuda).float(), \\\n    cudavec(target_output, gpu_id=args.cuda).float(), \\\n    cudavec(weights_vec, gpu_id=args.cuda)\n\n\nif __name__ == \'__main__\':\n\n  dirname = os.path.dirname(__file__)\n  ckpts_dir = os.path.join(dirname, \'checkpoints\')\n\n  input_size = args.input_size\n  memory_type = args.memory_type\n  lr = args.lr\n  clip = args.clip\n  batch_size = args.batch_size\n  sequence_max_length = args.sequence_max_length\n  cuda = args.cuda\n  iterations = args.iterations\n  summarize_freq = args.summarize_freq\n  check_freq = args.check_freq\n  visdom = args.visdom\n\n  from_checkpoint = None\n\n  if args.memory_type == \'dnc\':\n    rnn = DNC(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=args.mem_slot,\n        cell_size=args.mem_size,\n        read_heads=args.read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=False\n    )\n  elif args.memory_type == \'sdnc\':\n    rnn = SDNC(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=args.mem_slot,\n        cell_size=args.mem_size,\n        sparse_reads=args.sparse_reads,\n        temporal_reads=args.temporal_reads,\n        read_heads=args.read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=False\n    )\n  elif args.memory_type == \'sam\':\n    rnn = SAM(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=args.mem_slot,\n        cell_size=args.mem_size,\n        sparse_reads=args.sparse_reads,\n        read_heads=args.read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=False\n    )\n  else:\n    raise Exception(\'Not recognized type of memory\')\n\n  if args.cuda != -1:\n    rnn = rnn.cuda(args.cuda)\n\n  print(rnn)\n\n  last_save_losses = []\n\n  if args.optim == \'adam\':\n    optimizer = optim.Adam(rnn.parameters(), lr=args.lr, eps=1e-9, betas=[0.9, 0.98])  # 0.0001\n  elif args.optim == \'adamax\':\n    optimizer = optim.Adamax(rnn.parameters(), lr=args.lr, eps=1e-9, betas=[0.9, 0.98])  # 0.0001\n  elif args.optim == \'rmsprop\':\n    optimizer = optim.RMSprop(rnn.parameters(), lr=args.lr, momentum=0.9, eps=1e-10)  # 0.0001\n  elif args.optim == \'sgd\':\n    optimizer = optim.SGD(rnn.parameters(), lr=args.lr)  # 0.01\n  elif args.optim == \'adagrad\':\n    optimizer = optim.Adagrad(rnn.parameters(), lr=args.lr)\n  elif args.optim == \'adadelta\':\n    optimizer = optim.Adadelta(rnn.parameters(), lr=args.lr)\n\n  last_100_losses = []\n\n  (chx, mhx, rv) = (None, None, None)\n  for epoch in range(iterations + 1):\n    llprint(""\\rIteration {ep}/{tot}"".format(ep=epoch, tot=iterations))\n    optimizer.zero_grad()\n\n    # We use for training just (sequence_max_length / 10) examples\n    random_length = np.random.randint(2, (sequence_max_length) + 1)\n    input_data, target_output, loss_weights = generate_data(random_length, input_size)\n\n    if rnn.debug:\n      output, (chx, mhx, rv), v = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n    else:\n      output, (chx, mhx, rv) = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n\n    loss = T.mean(((loss_weights * output).sum(-1, keepdim=True) - target_output) ** 2)\n\n    loss.backward()\n\n    T.nn.utils.clip_grad_norm_(rnn.parameters(), args.clip)\n    optimizer.step()\n    loss_value = loss.item()\n\n    # detach memory from graph\n    mhx = { k : (v.detach() if isinstance(v, var) else v) for k, v in mhx.items() }\n\n    summarize = (epoch % summarize_freq == 0)\n    take_checkpoint = (epoch != 0) and (epoch % iterations == 0)\n\n    last_100_losses.append(loss_value)\n\n    try:\n      if summarize:\n        output = (loss_weights * output).sum().data.cpu().numpy()[0]\n        target_output = target_output.sum().data.cpu().numpy()\n\n        llprint(""\\rIteration %d/%d"" % (epoch, iterations))\n        llprint(""\\nAvg. Logistic Loss: %.4f\\n"" % (np.mean(last_100_losses)))\n        print(target_output)\n        print(""Real value: "", \' = \' + str(int(target_output[0])))\n        print(""Predicted:  "", \' = \' + str(int(output // 1)) + "" ["" + str(output) + ""]"")\n        last_100_losses = []\n\n      if take_checkpoint:\n        llprint(""\\nSaving Checkpoint ... ""),\n        check_ptr = os.path.join(ckpts_dir, \'step_{}.pth\'.format(epoch))\n        cur_weights = rnn.state_dict()\n        T.save(cur_weights, check_ptr)\n        llprint(""Done!\\n"")\n    except Exception as e:\n      pass\n\n  llprint(""\\nTesting generalization...\\n"")\n\n  rnn.eval()\n\n  for i in range(int((iterations + 1) / 10)):\n    llprint(""\\nIteration %d/%d"" % (i, iterations))\n    # We test now the learned generalization using sequence_max_length examples\n    random_length = np.random.randint(2, sequence_max_length * 2 + 1)\n    input_data, target_output, loss_weights = generate_data(random_length, input_size)\n\n    if rnn.debug:\n      output, (chx, mhx, rv), v = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n    else:\n      output, (chx, mhx, rv) = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n\n    output = output[:, -1, :].sum().data.cpu().numpy()[0]\n    target_output = target_output.sum().data.cpu().numpy()\n\n    try:\n      print(""\\nReal value: "", \' = \' + str(int(target_output[0])))\n      print(""Predicted:  "", \' = \' + str(int(output // 1)) + "" ["" + str(output) + ""]"")\n    except Exception as e:\n      pass\n'"
tasks/copy_task.py,4,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport warnings\nwarnings.filterwarnings(\'ignore\')\n\nimport numpy as np\nimport getopt\nimport sys\nimport os\nimport math\nimport time\nimport argparse\nfrom visdom import Visdom\n\nsys.path.insert(0, os.path.join(\'..\', \'..\'))\n\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.nn.utils import clip_grad_norm_\n\nfrom dnc.dnc import DNC\nfrom dnc.sdnc import SDNC\nfrom dnc.sam import SAM\nfrom dnc.util import *\n\nparser = argparse.ArgumentParser(description=\'PyTorch Differentiable Neural Computer\')\nparser.add_argument(\'-input_size\', type=int, default=6, help=\'dimension of input feature\')\nparser.add_argument(\'-rnn_type\', type=str, default=\'lstm\', help=\'type of recurrent cells to use for the controller\')\nparser.add_argument(\'-nhid\', type=int, default=64, help=\'number of hidden units of the inner nn\')\nparser.add_argument(\'-dropout\', type=float, default=0, help=\'controller dropout\')\nparser.add_argument(\'-memory_type\', type=str, default=\'dnc\', help=\'dense or sparse memory: dnc | sdnc | sam\')\n\nparser.add_argument(\'-nlayer\', type=int, default=1, help=\'number of layers\')\nparser.add_argument(\'-nhlayer\', type=int, default=2, help=\'number of hidden layers\')\nparser.add_argument(\'-lr\', type=float, default=1e-4, help=\'initial learning rate\')\nparser.add_argument(\'-optim\', type=str, default=\'adam\', help=\'learning rule, supports adam|rmsprop\')\nparser.add_argument(\'-clip\', type=float, default=50, help=\'gradient clipping\')\n\nparser.add_argument(\'-batch_size\', type=int, default=100, metavar=\'N\', help=\'batch size\')\nparser.add_argument(\'-mem_size\', type=int, default=20, help=\'memory dimension\')\nparser.add_argument(\'-mem_slot\', type=int, default=16, help=\'number of memory slots\')\nparser.add_argument(\'-read_heads\', type=int, default=4, help=\'number of read heads\')\nparser.add_argument(\'-sparse_reads\', type=int, default=10, help=\'number of sparse reads per read head\')\nparser.add_argument(\'-temporal_reads\', type=int, default=2, help=\'number of temporal reads\')\n\nparser.add_argument(\'-sequence_max_length\', type=int, default=4, metavar=\'N\', help=\'sequence_max_length\')\nparser.add_argument(\'-curriculum_increment\', type=int, default=0, metavar=\'N\', help=\'sequence_max_length incrementor per 1K iterations\')\nparser.add_argument(\'-curriculum_freq\', type=int, default=1000, metavar=\'N\', help=\'sequence_max_length incrementor per 1K iterations\')\nparser.add_argument(\'-cuda\', type=int, default=-1, help=\'Cuda GPU ID, -1 for CPU\')\n\nparser.add_argument(\'-iterations\', type=int, default=100000, metavar=\'N\', help=\'total number of iteration\')\nparser.add_argument(\'-summarize_freq\', type=int, default=100, metavar=\'N\', help=\'summarize frequency\')\nparser.add_argument(\'-check_freq\', type=int, default=100, metavar=\'N\', help=\'check point frequency\')\nparser.add_argument(\'-visdom\', action=\'store_true\', help=\'plot memory content on visdom per -summarize_freq steps\')\n\nargs = parser.parse_args()\nprint(args)\n\nviz = Visdom()\n# assert viz.check_connection()\n\nif args.cuda != -1:\n  print(\'Using CUDA.\')\n  T.manual_seed(1111)\nelse:\n  print(\'Using CPU.\')\n\n\ndef llprint(message):\n  sys.stdout.write(message)\n  sys.stdout.flush()\n\n\ndef generate_data(batch_size, length, size, cuda=-1):\n\n  input_data = np.zeros((batch_size, 2 * length + 1, size), dtype=np.float32)\n  target_output = np.zeros((batch_size, 2 * length + 1, size), dtype=np.float32)\n\n  sequence = np.random.binomial(1, 0.5, (batch_size, length, size - 1))\n\n  input_data[:, :length, :size - 1] = sequence\n  input_data[:, length, -1] = 1  # the end symbol\n  target_output[:, length + 1:, :size - 1] = sequence\n\n  input_data = T.from_numpy(input_data)\n  target_output = T.from_numpy(target_output)\n  if cuda != -1:\n    input_data = input_data.cuda()\n    target_output = target_output.cuda()\n\n  return var(input_data), var(target_output)\n\n\ndef criterion(predictions, targets):\n  return T.mean(\n      -1 * F.logsigmoid(predictions) * (targets) - T.log(1 - F.sigmoid(predictions) + 1e-9) * (1 - targets)\n  )\n\nif __name__ == \'__main__\':\n\n  dirname = os.path.dirname(__file__)\n  ckpts_dir = os.path.join(dirname, \'checkpoints\')\n  if not os.path.isdir(ckpts_dir):\n    os.mkdir(ckpts_dir)\n\n  batch_size = args.batch_size\n  sequence_max_length = args.sequence_max_length\n  iterations = args.iterations\n  summarize_freq = args.summarize_freq\n  check_freq = args.check_freq\n\n  # input_size = output_size = args.input_size\n  mem_slot = args.mem_slot\n  mem_size = args.mem_size\n  read_heads = args.read_heads\n\n  if args.memory_type == \'dnc\':\n    rnn = DNC(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=mem_slot,\n        cell_size=mem_size,\n        read_heads=read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=True\n    )\n  elif args.memory_type == \'sdnc\':\n    rnn = SDNC(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=mem_slot,\n        cell_size=mem_size,\n        sparse_reads=args.sparse_reads,\n        temporal_reads=args.temporal_reads,\n        read_heads=args.read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=False\n    )\n  elif args.memory_type == \'sam\':\n    rnn = SAM(\n        input_size=args.input_size,\n        hidden_size=args.nhid,\n        rnn_type=args.rnn_type,\n        num_layers=args.nlayer,\n        num_hidden_layers=args.nhlayer,\n        dropout=args.dropout,\n        nr_cells=mem_slot,\n        cell_size=mem_size,\n        sparse_reads=args.sparse_reads,\n        read_heads=args.read_heads,\n        gpu_id=args.cuda,\n        debug=args.visdom,\n        batch_first=True,\n        independent_linears=False\n    )\n  else:\n    raise Exception(\'Not recognized type of memory\')\n\n  print(rnn)\n  # register_nan_checks(rnn)\n\n  if args.cuda != -1:\n    rnn = rnn.cuda(args.cuda)\n\n  last_save_losses = []\n\n  if args.optim == \'adam\':\n    optimizer = optim.Adam(rnn.parameters(), lr=args.lr, eps=1e-9, betas=[0.9, 0.98]) # 0.0001\n  elif args.optim == \'adamax\':\n    optimizer = optim.Adamax(rnn.parameters(), lr=args.lr, eps=1e-9, betas=[0.9, 0.98]) # 0.0001\n  elif args.optim == \'rmsprop\':\n    optimizer = optim.RMSprop(rnn.parameters(), lr=args.lr, momentum=0.9, eps=1e-10) # 0.0001\n  elif args.optim == \'sgd\':\n    optimizer = optim.SGD(rnn.parameters(), lr=args.lr) # 0.01\n  elif args.optim == \'adagrad\':\n    optimizer = optim.Adagrad(rnn.parameters(), lr=args.lr)\n  elif args.optim == \'adadelta\':\n    optimizer = optim.Adadelta(rnn.parameters(), lr=args.lr)\n\n\n  (chx, mhx, rv) = (None, None, None)\n  for epoch in range(iterations + 1):\n    llprint(""\\rIteration {ep}/{tot}"".format(ep=epoch, tot=iterations))\n    optimizer.zero_grad()\n\n    random_length = np.random.randint(1, sequence_max_length + 1)\n\n    input_data, target_output = generate_data(batch_size, random_length, args.input_size, args.cuda)\n\n    if rnn.debug:\n      output, (chx, mhx, rv), v = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n    else:\n      output, (chx, mhx, rv) = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n\n    loss = criterion((output), target_output)\n\n    loss.backward()\n\n    T.nn.utils.clip_grad_norm_(rnn.parameters(), args.clip)\n    optimizer.step()\n    loss_value = loss.item()\n\n    summarize = (epoch % summarize_freq == 0)\n    take_checkpoint = (epoch != 0) and (epoch % check_freq == 0)\n    increment_curriculum = (epoch != 0) and (epoch % args.curriculum_freq == 0)\n\n    # detach memory from graph\n    mhx = { k : (v.detach() if isinstance(v, var) else v) for k, v in mhx.items() }\n\n    last_save_losses.append(loss_value)\n\n    if summarize:\n      loss = np.mean(last_save_losses)\n      # print(input_data)\n      # print(""1111111111111111111111111111111111111111111111"")\n      # print(target_output)\n      # print(\'2222222222222222222222222222222222222222222222\')\n      # print(F.relu6(output))\n      llprint(""\\n\\tAvg. Logistic Loss: %.4f\\n"" % (loss))\n      if np.isnan(loss):\n        raise Exception(\'nan Loss\')\n\n    if summarize and rnn.debug:\n      loss = np.mean(last_save_losses)\n      # print(input_data)\n      # print(""1111111111111111111111111111111111111111111111"")\n      # print(target_output)\n      # print(\'2222222222222222222222222222222222222222222222\')\n      # print(F.relu6(output))\n      last_save_losses = []\n\n      if args.memory_type == \'dnc\':\n        viz.heatmap(\n            v[\'memory\'],\n            opts=dict(\n                xtickstep=10,\n                ytickstep=2,\n                title=\'Memory, t: \' + str(epoch) + \', loss: \' + str(loss),\n                ylabel=\'layer * time\',\n                xlabel=\'mem_slot * mem_size\'\n            )\n        )\n\n      if args.memory_type == \'dnc\':\n        viz.heatmap(\n            v[\'link_matrix\'][-1].reshape(args.mem_slot, args.mem_slot),\n            opts=dict(\n                xtickstep=10,\n                ytickstep=2,\n                title=\'Link Matrix, t: \' + str(epoch) + \', loss: \' + str(loss),\n                ylabel=\'mem_slot\',\n                xlabel=\'mem_slot\'\n            )\n        )\n      elif args.memory_type == \'sdnc\':\n        viz.heatmap(\n            v[\'link_matrix\'][-1].reshape(args.mem_slot, -1),\n            opts=dict(\n                xtickstep=10,\n                ytickstep=2,\n                title=\'Link Matrix, t: \' + str(epoch) + \', loss: \' + str(loss),\n                ylabel=\'mem_slot\',\n                xlabel=\'mem_slot\'\n            )\n        )\n\n        viz.heatmap(\n            v[\'rev_link_matrix\'][-1].reshape(args.mem_slot, -1),\n            opts=dict(\n                xtickstep=10,\n                ytickstep=2,\n                title=\'Reverse Link Matrix, t: \' + str(epoch) + \', loss: \' + str(loss),\n                ylabel=\'mem_slot\',\n                xlabel=\'mem_slot\'\n            )\n        )\n\n      elif args.memory_type == \'sdnc\' or args.memory_type == \'dnc\':\n        viz.heatmap(\n            v[\'precedence\'],\n            opts=dict(\n                xtickstep=10,\n                ytickstep=2,\n                title=\'Precedence, t: \' + str(epoch) + \', loss: \' + str(loss),\n                ylabel=\'layer * time\',\n                xlabel=\'mem_slot\'\n            )\n        )\n\n      if args.memory_type == \'sdnc\':\n        viz.heatmap(\n            v[\'read_positions\'],\n            opts=dict(\n                xtickstep=10,\n                ytickstep=2,\n                title=\'Read Positions, t: \' + str(epoch) + \', loss: \' + str(loss),\n                ylabel=\'layer * time\',\n                xlabel=\'mem_slot\'\n            )\n        )\n\n      viz.heatmap(\n          v[\'read_weights\'],\n          opts=dict(\n              xtickstep=10,\n              ytickstep=2,\n              title=\'Read Weights, t: \' + str(epoch) + \', loss: \' + str(loss),\n              ylabel=\'layer * time\',\n              xlabel=\'nr_read_heads * mem_slot\'\n          )\n      )\n\n      viz.heatmap(\n          v[\'write_weights\'],\n          opts=dict(\n              xtickstep=10,\n              ytickstep=2,\n              title=\'Write Weights, t: \' + str(epoch) + \', loss: \' + str(loss),\n              ylabel=\'layer * time\',\n              xlabel=\'mem_slot\'\n          )\n      )\n\n      viz.heatmap(\n          v[\'usage_vector\'] if args.memory_type == \'dnc\' else v[\'usage\'],\n          opts=dict(\n              xtickstep=10,\n              ytickstep=2,\n              title=\'Usage Vector, t: \' + str(epoch) + \', loss: \' + str(loss),\n              ylabel=\'layer * time\',\n              xlabel=\'mem_slot\'\n          )\n      )\n\n    if increment_curriculum:\n      sequence_max_length = sequence_max_length + args.curriculum_increment\n      print(""Increasing max length to "" + str(sequence_max_length))\n\n    if take_checkpoint:\n      llprint(""\\nSaving Checkpoint ... ""),\n      check_ptr = os.path.join(ckpts_dir, \'step_{}.pth\'.format(epoch))\n      cur_weights = rnn.state_dict()\n      T.save(cur_weights, check_ptr)\n      llprint(""Done!\\n"")\n\n  for i in range(int((iterations + 1) / 10)):\n    llprint(""\\nIteration %d/%d"" % (i, iterations))\n    # We test now the learned generalization using sequence_max_length examples\n    random_length = np.random.randint(2, sequence_max_length * 10 + 1)\n    input_data, target_output, loss_weights = generate_data(random_length, input_size)\n\n    if rnn.debug:\n      output, (chx, mhx, rv), v = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n    else:\n      output, (chx, mhx, rv) = rnn(input_data, (None, mhx, None), reset_experience=True, pass_through_memory=True)\n\n    output = output[:, -1, :].sum().data.cpu().numpy()[0]\n    target_output = target_output.sum().data.cpu().numpy()\n\n    try:\n      print(""\\nReal value: "", \' = \' + str(int(target_output[0])))\n      print(""Predicted:  "", \' = \' + str(int(output // 1)) + "" ["" + str(output) + ""]"")\n    except Exception as e:\n      pass\n\n'"
test/test_gru.py,5,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*- \n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nsys.path.insert(0, '.')\n\nimport functools\n\nfrom dnc import DNC\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 1\n  cell_size = 1\n  read_heads = 1\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0].size() == T.Size([10,100])\n  assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 1])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 12\n  cell_size = 17\n  read_heads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[1].size() == T.Size([num_hidden_layers,10,100])\n  assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 51])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 12\n  cell_size = 17\n  read_heads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n\n"""
test/test_indexes.py,5,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nimport functools\nsys.path.insert(0, '.')\n\nfrom pyflann import *\n\nfrom dnc.flann_index import FLANNIndex\n\ndef test_indexes():\n\n  n = 30\n  cell_size=20\n  nr_cells=1024\n  K=10\n  probes=32\n  d = T.ones(n, cell_size)\n  q = T.ones(1, cell_size)\n\n  for gpu_id in (-1, -1):\n    i = FLANNIndex(cell_size=cell_size, nr_cells=nr_cells, K=K, probes=probes, gpu_id=gpu_id)\n    d = d if gpu_id == -1 else d.cuda(gpu_id)\n\n    i.add(d)\n\n    dist, labels = i.search(q*7)\n\n    assert dist.size() == T.Size([1,K])\n    assert labels.size() == T.Size([1, K])\n\n"""
test/test_lstm.py,5,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nimport functools\nsys.path.insert(0, '.')\n\nfrom dnc import DNC\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 1\n  cell_size = 1\n  read_heads = 1\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0][0].size() == T.Size([10,100])\n  assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 1])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 12\n  cell_size = 17\n  read_heads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0][0].size() == T.Size([num_hidden_layers,10,100])\n  assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 51])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 12\n  cell_size = 17\n  read_heads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0][0].size() == T.Size([num_hidden_layers,10,100])\n  assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n"""
test/test_rnn.py,5,"b""#!/usr/bin/env python3\n# -*- coding: utf-8 -*- \n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nsys.path.insert(0, '.')\n\nimport functools\n\nfrom dnc import DNC\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 1\n  cell_size = 1\n  read_heads = 1\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0].size() == T.Size([10,100])\n  assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 1])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 12\n  cell_size = 17\n  read_heads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[1].size() == T.Size([num_hidden_layers,10,100])\n  assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 51])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 12\n  cell_size = 17\n  read_heads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = DNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[1].size() == T.Size([num_hidden_layers,10,100])\n  assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n\n"""
test/test_sam_gru.py,5,"b""# #!/usr/bin/env python3\n# # -*- coding: utf-8 -*-\n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nimport functools\nsys.path.insert(0, '.')\n\nfrom dnc import SAM\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 100\n  cell_size = 10\n  read_heads = 1\n  sparse_reads = 2\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0].size() == T.Size([10,100])\n  # assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 10])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 200\n  cell_size = 17\n  read_heads = 2\n  sparse_reads = 4\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 34])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 5000\n  cell_size = 17\n  sparse_reads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n"""
test/test_sam_lstm.py,5,"b""# #!/usr/bin/env python3\n# # -*- coding: utf-8 -*-\n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nimport functools\nsys.path.insert(0, '.')\n\nfrom dnc import SAM\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 100\n  cell_size = 10\n  read_heads = 1\n  sparse_reads = 2\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0][0].size() == T.Size([10,100])\n  # assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 10])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 200\n  cell_size = 17\n  read_heads = 2\n  sparse_reads = 4\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0][0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 34])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 5000\n  cell_size = 17\n  sparse_reads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0][0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n"""
test/test_sam_rnn.py,5,"b""# #!/usr/bin/env python3\n# # -*- coding: utf-8 -*-\n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nimport functools\nsys.path.insert(0, '.')\n\nfrom dnc import SAM\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 100\n  cell_size = 10\n  read_heads = 1\n  sparse_reads = 2\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0].size() == T.Size([10,100])\n  # assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 10])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 200\n  cell_size = 17\n  read_heads = 2\n  sparse_reads = 4\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 34])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 5000\n  cell_size = 17\n  sparse_reads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SAM(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      sparse_reads=sparse_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n"""
test/test_sdnc_gru.py,5,"b""# #!/usr/bin/env python3\n# # -*- coding: utf-8 -*-\n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nimport functools\nsys.path.insert(0, '.')\n\nfrom dnc import SDNC\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 100\n  cell_size = 10\n  read_heads = 1\n  sparse_reads = 2\n  temporal_reads = 1\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0].size() == T.Size([10,100])\n  # assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 10])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 200\n  cell_size = 17\n  read_heads = 2\n  sparse_reads = 4\n  temporal_reads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 34])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'gru'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 5000\n  cell_size = 17\n  sparse_reads = 3\n  temporal_reads = 4\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n"""
test/test_sdnc_lstm.py,5,"b""# #!/usr/bin/env python3\n# # -*- coding: utf-8 -*-\n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nimport functools\nsys.path.insert(0, '.')\n\nfrom dnc import SDNC\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 100\n  cell_size = 10\n  read_heads = 1\n  sparse_reads = 2\n  temporal_reads = 1\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0][0].size() == T.Size([10,100])\n  # assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 10])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 200\n  cell_size = 17\n  read_heads = 2\n  sparse_reads = 4\n  temporal_reads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0][0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 34])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'lstm'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 5000\n  cell_size = 17\n  sparse_reads = 3\n  temporal_reads = 4\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0][0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n"""
test/test_sdnc_rnn.py,5,"b""# #!/usr/bin/env python3\n# # -*- coding: utf-8 -*-\n\nimport pytest\nimport numpy as np\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport torch.optim as optim\nimport numpy as np\n\nimport sys\nimport os\nimport math\nimport time\nimport functools\nsys.path.insert(0, '.')\n\nfrom dnc import SDNC\nfrom test_utils import generate_data, criterion\n\n\ndef test_rnn_1():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 1\n  num_hidden_layers = 1\n  dropout = 0\n  nr_cells = 100\n  cell_size = 10\n  read_heads = 1\n  sparse_reads = 2\n  temporal_reads = 1\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 10\n  length = 10\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([21, 10, 100])\n  assert chx[0][0].size() == T.Size([10,100])\n  # assert mhx['memory'].size() == T.Size([10,1,1])\n  assert rv.size() == T.Size([10, 10])\n\n\ndef test_rnn_n():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 200\n  cell_size = 17\n  read_heads = 2\n  sparse_reads = 4\n  temporal_reads = 3\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      read_heads=read_heads,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  output, (chx, mhx, rv), v = rnn(input_data, None)\n  output = output.transpose(0, 1)\n\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv.size() == T.Size([10, 34])\n\n\ndef test_rnn_no_memory_pass():\n  T.manual_seed(1111)\n\n  input_size = 100\n  hidden_size = 100\n  rnn_type = 'rnn'\n  num_layers = 3\n  num_hidden_layers = 5\n  dropout = 0.2\n  nr_cells = 5000\n  cell_size = 17\n  sparse_reads = 3\n  temporal_reads = 4\n  gpu_id = -1\n  debug = True\n  lr = 0.001\n  sequence_max_length = 10\n  batch_size = 10\n  cuda = gpu_id\n  clip = 20\n  length = 13\n\n  rnn = SDNC(\n      input_size=input_size,\n      hidden_size=hidden_size,\n      rnn_type=rnn_type,\n      num_layers=num_layers,\n      num_hidden_layers=num_hidden_layers,\n      dropout=dropout,\n      nr_cells=nr_cells,\n      cell_size=cell_size,\n      sparse_reads=sparse_reads,\n      temporal_reads=temporal_reads,\n      gpu_id=gpu_id,\n      debug=debug\n  )\n\n  optimizer = optim.Adam(rnn.parameters(), lr=lr)\n  optimizer.zero_grad()\n\n  input_data, target_output = generate_data(batch_size, length, input_size, cuda)\n  target_output = target_output.transpose(0, 1).contiguous()\n\n  (chx, mhx, rv) = (None, None, None)\n  outputs = []\n  for x in range(6):\n    output, (chx, mhx, rv), v = rnn(input_data, (chx, mhx, rv), pass_through_memory=False)\n    output = output.transpose(0, 1)\n    outputs.append(output)\n\n  output = functools.reduce(lambda x,y: x + y, outputs)\n  loss = criterion((output), target_output)\n  loss.backward()\n\n  T.nn.utils.clip_grad_norm_(rnn.parameters(), clip)\n  optimizer.step()\n\n  assert target_output.size() == T.Size([27, 10, 100])\n  assert chx[0].size() == T.Size([num_hidden_layers,10,100])\n  # assert mhx['memory'].size() == T.Size([10,12,17])\n  assert rv == None\n\n"""
test/test_utils.py,3,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport torch.nn as nn\nimport torch as T\nfrom torch.autograd import Variable as var\nimport torch.nn.functional as F\nimport numpy as np\n\ndef generate_data(batch_size, length, size, cuda=-1):\n\n  input_data = np.zeros((batch_size, 2 * length + 1, size), dtype=np.float32)\n  target_output = np.zeros((batch_size, 2 * length + 1, size), dtype=np.float32)\n\n  sequence = np.random.binomial(1, 0.5, (batch_size, length, size - 1))\n\n  input_data[:, :length, :size - 1] = sequence\n  input_data[:, length, -1] = 1  # the end symbol\n  target_output[:, length + 1:, :size - 1] = sequence\n\n  input_data = T.from_numpy(input_data)\n  target_output = T.from_numpy(target_output)\n  if cuda != -1:\n    input_data = input_data.cuda()\n    target_output = target_output.cuda()\n\n  return var(input_data), var(target_output)\n\ndef criterion(predictions, targets):\n  return T.mean(\n      -1 * F.logsigmoid(predictions) * (targets) - T.log(1 - T.sigmoid(predictions) + 1e-9) * (1 - targets)\n  )\n\n'"
