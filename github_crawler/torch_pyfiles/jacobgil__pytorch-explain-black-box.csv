file_path,api_count,code
explain.py,15,"b'import torch\nfrom torch.autograd import Variable\nfrom torchvision import models\nimport cv2\nimport sys\nimport numpy as np\n\nuse_cuda = torch.cuda.is_available()\nFloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\nLongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\nTensor = FloatTensor\n\ndef tv_norm(input, tv_beta):\n\timg = input[0, 0, :]\n\trow_grad = torch.mean(torch.abs((img[:-1 , :] - img[1 :, :])).pow(tv_beta))\n\tcol_grad = torch.mean(torch.abs((img[: , :-1] - img[: , 1 :])).pow(tv_beta))\n\treturn row_grad + col_grad\n\ndef preprocess_image(img):\n\tmeans=[0.485, 0.456, 0.406]\n\tstds=[0.229, 0.224, 0.225]\n\n\tpreprocessed_img = img.copy()[: , :, ::-1]\n\tfor i in range(3):\n\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n\t\tpreprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n\tpreprocessed_img = \\\n\t\tnp.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n\n\tif use_cuda:\n\t\tpreprocessed_img_tensor = torch.from_numpy(preprocessed_img).cuda()\n\telse:\n\t\tpreprocessed_img_tensor = torch.from_numpy(preprocessed_img)\n\n\tpreprocessed_img_tensor.unsqueeze_(0)\n\treturn Variable(preprocessed_img_tensor, requires_grad = False)\n\ndef save(mask, img, blurred):\n\tmask = mask.cpu().data.numpy()[0]\n\tmask = np.transpose(mask, (1, 2, 0))\n\n\tmask = (mask - np.min(mask)) / np.max(mask)\n\tmask = 1 - mask\n\theatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)\n\t\n\theatmap = np.float32(heatmap) / 255\n\tcam = 1.0*heatmap + np.float32(img)/255\n\tcam = cam / np.max(cam)\n\n\timg = np.float32(img) / 255\n\tperturbated = np.multiply(1 - mask, img) + np.multiply(mask, blurred)\t\n\n\tcv2.imwrite(""perturbated.png"", np.uint8(255*perturbated))\n\tcv2.imwrite(""heatmap.png"", np.uint8(255*heatmap))\n\tcv2.imwrite(""mask.png"", np.uint8(255*mask))\n\tcv2.imwrite(""cam.png"", np.uint8(255*cam))\n\ndef numpy_to_torch(img, requires_grad = True):\n\tif len(img.shape) < 3:\n\t\toutput = np.float32([img])\n\telse:\n\t\toutput = np.transpose(img, (2, 0, 1))\n\n\toutput = torch.from_numpy(output)\n\tif use_cuda:\n\t\toutput = output.cuda()\n\n\toutput.unsqueeze_(0)\n\tv = Variable(output, requires_grad = requires_grad)\n\treturn v\n\ndef load_model():\n\tmodel = models.vgg19(pretrained=True)\n\tmodel.eval()\n\tif use_cuda:\n\t\tmodel.cuda()\n\t\n\tfor p in model.features.parameters():\n\t\tp.requires_grad = False\n \tfor p in model.classifier.parameters():\n            p.requires_grad = False\n\n\treturn model\n\nif __name__ == \'__main__\':\n\t#Hyper parameters. \n\t#TBD: Use argparse\n\ttv_beta = 3\n\tlearning_rate = 0.1\n\tmax_iterations = 500\n\tl1_coeff = 0.01\n\ttv_coeff = 0.2\n\n\tmodel = load_model()\n\toriginal_img = cv2.imread(sys.argv[1], 1)\n\toriginal_img = cv2.resize(original_img, (224, 224))\n\timg = np.float32(original_img) / 255\n\tblurred_img1 = cv2.GaussianBlur(img, (11, 11), 5)\n\tblurred_img2 = np.float32(cv2.medianBlur(original_img, 11))/255\n\tblurred_img_numpy = (blurred_img1 + blurred_img2) / 2\n\tmask_init = np.ones((28, 28), dtype = np.float32)\n\t\n\t# Convert to torch variables\n\timg = preprocess_image(img)\n\tblurred_img = preprocess_image(blurred_img2)\n\tmask = numpy_to_torch(mask_init)\n\n\tif use_cuda:\n\t\tupsample = torch.nn.UpsamplingBilinear2d(size=(224, 224)).cuda()\n\telse:\n\t\tupsample = torch.nn.UpsamplingBilinear2d(size=(224, 224))\n\toptimizer = torch.optim.Adam([mask], lr=learning_rate)\n\n\ttarget = torch.nn.Softmax()(model(img))\n\tcategory = np.argmax(target.cpu().data.numpy())\n\tprint ""Category with highest probability"", category\n\tprint ""Optimizing.. ""\n\n\tfor i in range(max_iterations):\n\t\tupsampled_mask = upsample(mask)\n\t\t# The single channel mask is used with an RGB image, \n\t\t# so the mask is duplicated to have 3 channel,\n\t\tupsampled_mask = \\\n\t\t\tupsampled_mask.expand(1, 3, upsampled_mask.size(2), \\\n\t\t\t\t\t\t\t\t\t\tupsampled_mask.size(3))\n\t\t\n\t\t# Use the mask to perturbated the input image.\n\t\tperturbated_input = img.mul(upsampled_mask) + \\\n\t\t\t\t\t\t\tblurred_img.mul(1-upsampled_mask)\n\t\t\n\t\tnoise = np.zeros((224, 224, 3), dtype = np.float32)\n\t\tcv2.randn(noise, 0, 0.2)\n\t\tnoise = numpy_to_torch(noise)\n\t\tperturbated_input = perturbated_input + noise\n\t\t\n\t\toutputs = torch.nn.Softmax()(model(perturbated_input))\n\t\tloss = l1_coeff*torch.mean(torch.abs(1 - mask)) + \\\n\t\t\t\ttv_coeff*tv_norm(mask, tv_beta) + outputs[0, category]\n\n\t\toptimizer.zero_grad()\n\t\tloss.backward()\n\t\toptimizer.step()\n\n\t\t# Optional: clamping seems to give better results\n\t\tmask.data.clamp_(0, 1)\n\n\tupsampled_mask = upsample(mask)\n\tsave(upsampled_mask, original_img, blurred_img_numpy)\n'"
