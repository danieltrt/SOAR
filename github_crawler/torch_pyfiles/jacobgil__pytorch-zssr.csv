file_path,api_count,code
data.py,2,"b""import PIL\nimport numpy as np\nimport sys\nimport random\nimport torch\nfrom torchvision import transforms\nfrom torchvision.transforms import functional as F\nimport numbers\nimport cv2\nfrom source_target_transforms import *\n\nclass DataSampler:\n    def __init__(self, img, sr_factor, crop_size):\n        self.img = img\n        self.sr_factor = sr_factor\n        self.pairs = self.create_hr_lr_pairs()\n        sizes = np.float32([x[0].size[0]*x[0].size[1] / float(img.size[0]*img.size[1]) \\\n            for x in self.pairs])\n        self.pair_probabilities = sizes / np.sum(sizes)\n\n        self.transform = transforms.Compose([\n            RandomRotationFromSequence([0, 90, 180, 270]),\n            RandomHorizontalFlip(),\n            RandomVerticalFlip(),\n            RandomCrop(crop_size),\n            ToTensor()]) \n\n    def create_hr_lr_pairs(self):\n        smaller_side = min(self.img.size[0 : 2])\n        larger_side = max(self.img.size[0 : 2])\n\n        factors = []\n        for i in range(smaller_side//5, smaller_side+1):\n            downsampled_smaller_side = i\n            zoom = float(downsampled_smaller_side)/smaller_side\n            downsampled_larger_side = round(larger_side*zoom)\n            if downsampled_smaller_side%self.sr_factor==0 and \\\n                downsampled_larger_side%self.sr_factor==0:\n                factors.append(zoom)\n\n        pairs = []\n        for zoom in factors:\n            hr = self.img.resize((int(self.img.size[0]*zoom), \\\n                                int(self.img.size[1]*zoom)), \\\n                resample=PIL.Image.BICUBIC)\n\n            lr = hr.resize((int(hr.size[0]/self.sr_factor), \\\n                int(hr.size[1]/self.sr_factor)),\n                resample=PIL.Image.BICUBIC)\n\n            lr = lr.resize(hr.size, resample=PIL.Image.BICUBIC)\n\n            pairs.append((hr, lr))\n\n        return pairs\n\n    def generate_data(self):\n        while True:\n            hr, lr = random.choices(self.pairs, weights=self.pair_probabilities, k=1)[0]\n            hr_tensor, lr_tensor = self.transform((hr, lr))\n            hr_tensor = torch.unsqueeze(hr_tensor, 0)\n            lr_tensor = torch.unsqueeze(lr_tensor, 0)\n            yield hr_tensor, lr_tensor\n\nif __name__ == '__main__':\n    img = PIL.Image.open(sys.argv[1])\n    sampler = DataSampler(img, 2)\n    for x in sampler.generate_data():\n        hr, lr = x\n        hr = hr.numpy().transpose((1, 2, 0))\n        lr = lr.numpy().transpose((1, 2, 0))"""
net.py,1,"b'import torch\nimport torch.nn as nn\n\nclass ZSSRNet(nn.Module):\n\tdef __init__(self, input_channels=3, kernel_size=3, channels=64):\n\t\t super(ZSSRNet, self).__init__()\n\t\t \n\t\t self.conv0 = nn.Conv2d(input_channels, channels, kernel_size=kernel_size, padding=kernel_size//2, bias=True)\n\t\t self.conv1 = nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2, bias=True)\n\t\t self.conv2 = nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2, bias=True)\n\t\t self.conv3 = nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2, bias=True)\n\t\t self.conv4 = nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2, bias=True)\n\t\t self.conv5 = nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2, bias=True)\n\t\t self.conv6 = nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=kernel_size//2, bias=True)\n\t\t self.conv7 = nn.Conv2d(channels, input_channels, kernel_size=kernel_size, padding=kernel_size//2, bias=True)\n\n\t\t self.relu = nn.ReLU()\n\n\tdef forward(self, x):\n\t\tx = self.relu(self.conv0(x))\n\t\tx = self.relu(self.conv1(x))\n\t\tx = self.relu(self.conv2(x))\n\t\tx = self.relu(self.conv3(x))\n\t\tx = self.relu(self.conv4(x))\n\t\tx = self.relu(self.conv5(x))\n\t\tx = self.relu(self.conv6(x))\n\t\tx = self.conv7(x)\n\n\t\treturn x'"
source_target_transforms.py,1,"b'import numpy as np\nimport PIL\nimport random\nfrom torchvision import transforms\nfrom torchvision.transforms import functional as F\nimport numbers\n\nclass RandomRotationFromSequence(object):\n    """"""Rotate the image by angle.\n    Args:\n        degrees (sequence or float or int): Range of degrees to select from.\n            If degrees is a number instead of sequence like (min, max), the range of degrees\n            will be (-degrees, +degrees).\n        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n            An optional resampling filter.\n            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n            If omitted, or if the image has mode ""1"" or ""P"", it is set to PIL.Image.NEAREST.\n        expand (bool, optional): Optional expansion flag.\n            If true, expands the output to make it large enough to hold the entire rotated image.\n            If false or omitted, make the output image the same size as the input image.\n            Note that the expand flag assumes rotation around the center and no translation.\n        center (2-tuple, optional): Optional center of rotation.\n            Origin is the upper left corner.\n            Default is the center of the image.\n    """"""\n\n    def __init__(self, degrees, resample=False, expand=False, center=None):\n        self.degrees = degrees\n        self.resample = resample\n        self.expand = expand\n        self.center = center\n\n    @staticmethod\n    def get_params(degrees):\n        """"""Get parameters for ``rotate`` for a random rotation.\n        Returns:\n            sequence: params to be passed to ``rotate`` for random rotation.\n        """"""\n        angle = np.random.choice(degrees)\n        return angle\n\n    def __call__(self, data):\n        """"""\n            img (PIL Image): Image to be rotated.\n        Returns:\n            PIL Image: Rotated image.\n        """"""\n        hr, lr = data\n        angle = self.get_params(self.degrees)\n        return F.rotate(hr, angle, self.resample, self.expand, self.center), \\\n                F.rotate(lr, angle, self.resample, self.expand, self.center)\n\nclass RandomHorizontalFlip(object):\n    """"""Horizontally flip the given PIL Image randomly with a probability of 0.5.""""""\n\n    def __call__(self, data):\n        """"""\n        Args:\n            img (PIL Image): Image to be flipped.\n        Returns:\n            PIL Image: Randomly flipped image.\n        """"""\n        hr, lr = data\n        if random.random() < 0.5:\n            return F.hflip(hr), F.hflip(lr)\n        return hr, lr\n\nclass RandomVerticalFlip(object):\n    """"""Vertically flip the given PIL Image randomly with a probability of 0.5.""""""\n\n    def __call__(self, data):\n        """"""\n        Args:\n            img (PIL Image): Image to be flipped.\n        Returns:\n            PIL Image: Randomly flipped image.\n        """"""\n        hr, lr = data\n        if random.random() < 0.5:\n            return F.vflip(hr), F.vflip(lr)\n        return hr, lr\n\nclass RandomCrop(object):\n    """"""Crop the given PIL Image at a random location.\n    Args:\n        size (sequence or int): Desired output size of the crop. If size is an\n            int instead of sequence like (h, w), a square crop (size, size) is\n            made.\n        padding (int or sequence, optional): Optional padding on each border\n            of the image. Default is 0, i.e no padding. If a sequence of length\n            4 is provided, it is used to pad left, top, right, bottom borders\n            respectively.\n    """"""\n\n    def __init__(self, size, padding=0):\n        if isinstance(size, numbers.Number):\n            self.size = (int(size), int(size))\n        else:\n            self.size = size\n        self.padding = padding\n\n    @staticmethod\n    def get_params(data, output_size):\n        """"""Get parameters for ``crop`` for a random crop.\n        Args:\n            img (PIL Image): Image to be cropped.\n            output_size (tuple): Expected output size of the crop.\n        Returns:\n            tuple: params (i, j, h, w) to be passed to ``crop`` for random crop.\n        """"""\n        hr, lr = data\n        w, h = hr.size\n        th, tw = output_size\n        if w == tw or h == th:\n            return 0, 0, h, w\n\n        if w < tw or h < th:\n            th, tw = h//2, w//2\n\n        i = random.randint(0, h - th)\n        j = random.randint(0, w - tw)\n        return i, j, th, tw\n\n    def __call__(self, data):\n        """"""\n        Args:\n            img (PIL Image): Image to be cropped.\n        Returns:\n            PIL Image: Cropped image.\n        """"""\n        hr, lr = data\n        if self.padding > 0:\n            hr = F.pad(hr, self.padding)\n            lr = F.pad(lr, self.padding)\n\n        i, j, h, w = self.get_params(data, self.size)\n        return F.crop(hr, i, j, h, w), F.crop(lr, i, j, h, w)\n\nclass ToTensor(object):\n    """"""Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n    """"""\n\n    def __call__(self, data):\n        """"""\n        Args:\n            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n        Returns:\n            Tensor: Converted image.\n        """"""\n        hr, lr = data\n        return F.to_tensor(hr), F.to_tensor(lr)\n'"
train.py,6,"b'import numpy as np\nfrom net import ZSSRNet\nfrom data import DataSampler\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.nn import init\nimport PIL\nimport sys\nfrom torchvision import transforms\nimport tqdm\nimport argparse\n\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    if classname.find(\'Conv\') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode=\'fan_in\')\n    elif classname.find(\'Linear\') != -1:\n        init.kaiming_normal(m.weight.data, a=0, mode=\'fan_in\')\n    elif classname.find(\'BatchNorm2d\') != -1:\n        init.normal(m.weight.data, 1.0, 0.02)\n        init.constant(m.bias.data, 0.0)\n\n\ndef adjust_learning_rate(optimizer, new_lr):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = new_lr\n\ndef train(model, img, sr_factor, num_batches, learning_rate, crop_size):\n    loss = nn.L1Loss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    sampler = DataSampler(img, sr_factor, crop_size)\n    model.cuda()\n    with tqdm.tqdm(total=num_batches, miniters=1, mininterval=0) as progress:\n        for iter, (hr, lr) in enumerate(sampler.generate_data()):\n            model.zero_grad()\n\n            lr = Variable(lr).cuda()\n            hr = Variable(hr).cuda()\n\n            output = model(lr) + lr\n            error = loss(output, hr)\n\n            cpu_loss = error.data.cpu().numpy()[0]\n\n            progress.set_description(""Iteration: {iter} Loss: {loss}, Learning Rate: {lr}"".format( \\\n                iter=iter, loss=cpu_loss, lr=learning_rate))\n            progress.update()\n\n            if iter > 0 and iter % 10000 == 0:\n                learning_rate = learning_rate / 10\n                adjust_learning_rate(optimizer, new_lr=learning_rate)\n                print(""Learning rate reduced to {lr}"".format(lr=learning_rate) )\n\n            error.backward()\n            optimizer.step()\n\n            if iter > num_batches:\n                print(\'Done training.\')\n                break\n            \n\ndef test(model, img, sr_factor):\n    model.eval()\n\n    img = img.resize((int(img.size[0]*sr_factor), \\\n        int(img.size[1]*sr_factor)), resample=PIL.Image.BICUBIC)\n    img.save(\'low_res.png\')\n\n    img = transforms.ToTensor()(img)\n    img = torch.unsqueeze(img, 0)\n    input = Variable(img.cuda())\n    residual = model(input)\n    output = input + residual\n\n    output = output.cpu().data[0, :, :, :]\n    o = output.numpy()\n    o[np.where(o < 0)] = 0.0\n    o[np.where(o > 1)] = 1.0\n    output = torch.from_numpy(o)\n    output = transforms.ToPILImage()(output) \n    output.save(\'zssr.png\')\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--num_batches\', type=int, default=15000, \\\n        help=\'Number of batches to run\')\n    parser.add_argument(\'--crop\', type=int, default=128, \\\n        help=\'Random crop size\')\n    parser.add_argument(\'--lr\', type=float, default=0.00001, \\\n        help=\'Base learning rate for Adam\')\n    parser.add_argument(\'--factor\', type=int, default=2, \\\n        help=\'Interpolation factor.\')\n    parser.add_argument(\'--img\', type=str, help=\'Path to input img\')\n\n    args = parser.parse_args()\n\n    return args\n\nif __name__ == \'__main__\':\n    args = get_args()\n\n    img = PIL.Image.open(args.img)\n    num_channels = len(np.array(img).shape)\n    if num_channels == 3:\n        model = ZSSRNet(input_channels = 3)\n    elif num_channels == 2:\n        model = ZSSRNet(input_channels = 1)\n    else:\n        print(""Expecting RGB or gray image, instead got"", img.size)\n        sys.exit(1)\n\n    # Weight initialization\n    model.apply(weights_init_kaiming)\n\n    train(model, img, args.factor, args.num_batches, args.lr, args.crop)\n    test(model, img, args.factor)'"
