file_path,api_count,code
__init__.py,0,b''
congan_train.py,21,"b'import os, sys\r\nsys.path.append(os.getcwd())\r\n\r\nimport time\r\nimport functools\r\nimport argparse\r\n\r\nimport numpy as np\r\n#import sklearn.datasets\r\n\r\nimport libs as lib\r\nimport libs.plot\r\nfrom tensorboardX import SummaryWriter\r\n\r\nimport pdb\r\nimport gpustat\r\n\r\nfrom models.conwgan import *\r\n\r\nimport torch\r\nimport torchvision\r\nfrom torch import nn\r\nfrom torch import autograd\r\nfrom torch import optim\r\nfrom torchvision import transforms, datasets\r\nfrom torch.autograd import grad\r\nfrom timeit import default_timer as timer\r\n\r\nimport torch.nn.init as init\r\n\r\nDATA_DIR = \'/datasets/lsun\'\r\nVAL_DIR = \'/datasets/lsun\'\r\n\r\nIMAGE_DATA_SET = \'lsun\' #change this to something else, e.g. \'imagenets\' or \'raw\' if your data is just a folder of raw images. \r\n#If you use lmdb, you\'ll need to write the loader by yourself, see load_data\r\nTRAINING_CLASS = [\'dining_room_train\', \'bridge_train\', \'restaurant_train\', \'tower_train\'] \r\nVAL_CLASS = [\'dining_room_val\', \'bridge_val\', \'restaurant_val\', \'tower_val\'] \r\nNUM_CLASSES = 4\r\n\r\nif len(DATA_DIR) == 0:\r\n    raise Exception(\'Please specify path to data directory in gan_64x64.py!\')\r\n\r\nRESTORE_MODE = False  # if True, it will load saved model from OUT_PATH and continue to train\r\nSTART_ITER = 0 # starting iteration \r\nOUTPUT_PATH = \'/path/to/output/\' # output path where result (.e.g drawing images, cost, chart) will be stored\r\n# MODE = \'wgan-gp\'\r\nDIM = 64 # Model dimensionality\r\nCRITIC_ITERS = 5 # How many iterations to train the critic for\r\nGENER_ITERS = 1\r\nN_GPUS = 1 # Number of GPUs\r\nBATCH_SIZE = 64# Batch size. Must be a multiple of N_GPUS\r\nEND_ITER = 100000 # How many iterations to train for\r\nLAMBDA = 10 # Gradient penalty lambda hyperparameter\r\nOUTPUT_DIM = 64*64*3 # Number of pixels in each iamge\r\nACGAN_SCALE = 1. # How to scale the critic\'s ACGAN loss relative to WGAN loss\r\nACGAN_SCALE_G = 1. # How to scale generator\'s ACGAN loss relative to WGAN loss\r\n\r\ndef showMemoryUsage(device=1):\r\n    gpu_stats = gpustat.GPUStatCollection.new_query()\r\n    item = gpu_stats.jsonify()[""gpus""][device]\r\n    print(\'Used/total: \' + ""{}/{}"".format(item[""memory.used""], item[""memory.total""]))\r\n\r\n\r\ndef weights_init(m):\r\n    if isinstance(m, MyConvo2d): \r\n        if m.conv.weight is not None:\r\n            if m.he_init:\r\n                init.kaiming_uniform_(m.conv.weight)\r\n            else:\r\n                init.xavier_uniform_(m.conv.weight)\r\n        if m.conv.bias is not None:\r\n            init.constant_(m.conv.bias, 0.0)\r\n    if isinstance(m, nn.Linear):\r\n        if m.weight is not None:\r\n            init.xavier_uniform_(m.weight)\r\n        if m.bias is not None:\r\n            init.constant_(m.bias, 0.0)\r\n\r\ndef load_data(path_to_folder, classes):\r\n    data_transform = transforms.Compose([\r\n                 transforms.Scale(64),\r\n                 transforms.CenterCrop(64),\r\n                 transforms.ToTensor(),\r\n                 transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])\r\n                ])\r\n    if IMAGE_DATA_SET == \'lsun\':\r\n        dataset =  datasets.LSUN(path_to_folder, classes=classes, transform=data_transform)\r\n    else:\r\n        dataset = datasets.ImageFolder(root=path_to_folder,transform=data_transform)\r\n    dataset_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=5, drop_last=True, pin_memory=True)\r\n    return dataset_loader\r\n\r\ndef calc_gradient_penalty(netD, real_data, fake_data):\r\n    alpha = torch.rand(BATCH_SIZE, 1)\r\n    alpha = alpha.expand(BATCH_SIZE, int(real_data.nelement()/BATCH_SIZE)).contiguous()\r\n    alpha = alpha.view(BATCH_SIZE, 3, DIM, DIM)\r\n    alpha = alpha.to(device)\r\n\r\n    fake_data = fake_data.view(BATCH_SIZE, 3, DIM, DIM)\r\n    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\r\n\r\n    interpolates = interpolates.to(device)\r\n    interpolates.requires_grad_(True)   \r\n\r\n    disc_interpolates, _ = netD(interpolates)\r\n\r\n    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\r\n                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\r\n                              create_graph=True, retain_graph=True, only_inputs=True)[0]\r\n\r\n    gradients = gradients.view(gradients.size(0), -1)                              \r\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\r\n    return gradient_penalty\r\n\r\ndef generate_image(netG, noise=None):\r\n    if noise is None:\r\n        rand_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\r\n        noise = gen_rand_noise_with_label(rand_label)\r\n    with torch.no_grad():\r\n        noisev = noise\r\n    samples = netG(noisev)\r\n    samples = samples.view(BATCH_SIZE, 3, DIM, DIM)\r\n\r\n    samples = samples * 0.5 + 0.5\r\n\r\n    return samples\r\n\r\ndef gen_rand_noise_with_label(label=None):\r\n    if label is None:\r\n        label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\r\n    #attach label into noise\r\n    noise = np.random.normal(0, 1, (BATCH_SIZE, 128))\r\n    prefix = np.zeros((BATCH_SIZE, NUM_CLASSES))\r\n    prefix[np.arange(BATCH_SIZE), label] = 1\r\n    noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = prefix[np.arange(BATCH_SIZE)]\r\n\r\n    noise = torch.from_numpy(noise).float()\r\n    noise = noise.to(device)\r\n\r\n    return noise\r\n\r\n\r\ncuda_available = torch.cuda.is_available()\r\ndevice = torch.device(""cuda"" if cuda_available else ""cpu"")\r\nfixed_label = []\r\nfor c in range(BATCH_SIZE):\r\n    fixed_label.append(c%NUM_CLASSES)\r\nfixed_noise = gen_rand_noise_with_label(fixed_label)\r\n\r\nif RESTORE_MODE:\r\n    aG = torch.load(OUTPUT_PATH + ""generator.pt"")\r\n    aD = torch.load(OUTPUT_PATH + ""discriminator.pt"")\r\nelse:\r\n    aG = GoodGenerator(64,64*64*3)\r\n    aD = GoodDiscriminator(64, NUM_CLASSES)\r\n    \r\n    aG.apply(weights_init)\r\n    aD.apply(weights_init)\r\n\r\nLR = 1e-4\r\noptimizer_g = torch.optim.Adam(aG.parameters(), lr=LR, betas=(0,0.9))\r\noptimizer_d = torch.optim.Adam(aD.parameters(), lr=LR, betas=(0,0.9))\r\n\r\naux_criterion = nn.CrossEntropyLoss() # nn.NLLLoss()\r\n\r\none = torch.FloatTensor([1])\r\nmone = one * -1\r\naG = aG.to(device)\r\naD = aD.to(device)\r\none = one.to(device)\r\nmone = mone.to(device)\r\n\r\nwriter = SummaryWriter()\r\n#Reference: https://github.com/caogang/wgan-gp/blob/master/gan_cifar10.py\r\ndef train():\r\n    #writer = SummaryWriter()\r\n    dataloader = load_data(DATA_DIR, TRAINING_CLASS)\r\n    dataiter = iter(dataloader)\r\n    for iteration in range(START_ITER, END_ITER):\r\n        start_time = time.time()\r\n        print(""Iter: "" + str(iteration))\r\n        start = timer()\r\n        #---------------------TRAIN G------------------------\r\n        for p in aD.parameters():\r\n            p.requires_grad_(False)  # freeze D\r\n\r\n        gen_cost = None\r\n        for i in range(GENER_ITERS):\r\n            print(""Generator iters: "" + str(i))\r\n            aG.zero_grad()\r\n            f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\r\n            noise = gen_rand_noise_with_label(f_label)\r\n            noise.requires_grad_(True)\r\n            fake_data = aG(noise)\r\n            gen_cost, gen_aux_output = aD(fake_data)\r\n\r\n            aux_label = torch.from_numpy(f_label).long()\r\n            aux_label = aux_label.to(device)\r\n            aux_errG = aux_criterion(gen_aux_output, aux_label).mean()\r\n            gen_cost = -gen_cost.mean()\r\n            g_cost = ACGAN_SCALE_G*aux_errG + gen_cost\r\n            g_cost.backward()\r\n        \r\n        optimizer_g.step()\r\n        end = timer()\r\n        print(f\'---train G elapsed time: {end - start}\')\r\n        #---------------------TRAIN D------------------------\r\n        for p in aD.parameters():  # reset requires_grad\r\n            p.requires_grad_(True)  # they are set to False below in training G\r\n        for i in range(CRITIC_ITERS):\r\n            print(""Critic iter: "" + str(i))\r\n            \r\n            start = timer()\r\n            aD.zero_grad()\r\n\r\n            # gen fake data and load real data\r\n            f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\r\n            noise = gen_rand_noise_with_label(f_label)\r\n            with torch.no_grad():\r\n                noisev = noise  # totally freeze G, training D\r\n            fake_data = aG(noisev).detach()\r\n            end = timer(); print(f\'---gen G elapsed time: {end-start}\')\r\n            start = timer()\r\n            batch = next(dataiter, None)\r\n            if batch is None:\r\n                dataiter = iter(dataloader)\r\n                batch = dataiter.next()\r\n            real_data = batch[0] #batch[1] contains labels\r\n            real_data.requires_grad_(True)\r\n            real_label = batch[1]\r\n            #print(""r_label"" + str(r_label))\r\n            end = timer(); print(f\'---load real imgs elapsed time: {end-start}\')\r\n\r\n            start = timer()\r\n            real_data = real_data.to(device)\r\n            real_label = real_label.to(device)\r\n\r\n            # train with real data\r\n            disc_real, aux_output = aD(real_data)\r\n            aux_errD_real = aux_criterion(aux_output, real_label)\r\n            errD_real = aux_errD_real.mean()\r\n            disc_real = disc_real.mean()\r\n\r\n\r\n            # train with fake data\r\n            disc_fake, aux_output = aD(fake_data)\r\n            #aux_errD_fake = aux_criterion(aux_output, fake_label)\r\n            #errD_fake = aux_errD_fake.mean()\r\n            disc_fake = disc_fake.mean()\r\n\r\n            #showMemoryUsage(0)\r\n            # train with interpolates data\r\n            gradient_penalty = calc_gradient_penalty(aD, real_data, fake_data)\r\n            #showMemoryUsage(0)\r\n\r\n            # final disc cost\r\n            disc_cost = disc_fake - disc_real + gradient_penalty\r\n            disc_acgan = errD_real #+ errD_fake\r\n            (disc_cost + ACGAN_SCALE*disc_acgan).backward()\r\n            w_dist = disc_fake  - disc_real\r\n            optimizer_d.step()\r\n            #------------------VISUALIZATION----------\r\n            if i == CRITIC_ITERS-1:\r\n                writer.add_scalar(\'data/disc_cost\', disc_cost, iteration)\r\n                #writer.add_scalar(\'data/disc_fake\', disc_fake, iteration)\r\n                #writer.add_scalar(\'data/disc_real\', disc_real, iteration)\r\n                writer.add_scalar(\'data/gradient_pen\', gradient_penalty, iteration)\r\n                writer.add_scalar(\'data/ac_disc_cost\', disc_acgan, iteration)\r\n                writer.add_scalar(\'data/ac_gen_cost\', aux_errG, iteration)\r\n                #writer.add_scalar(\'data/d_conv_weight_mean\', [i for i in aD.children()][0].conv.weight.data.clone().mean(), iteration)\r\n                #writer.add_scalar(\'data/d_linear_weight_mean\', [i for i in aD.children()][-1].weight.data.clone().mean(), iteration)\r\n                #writer.add_scalar(\'data/fake_data_mean\', fake_data.mean())\r\n                #writer.add_scalar(\'data/real_data_mean\', real_data.mean())\r\n                #if iteration %200==99:\r\n                #    paramsD = aD.named_parameters()\r\n                #    for name, pD in paramsD:\r\n                #        writer.add_histogram(""D."" + name, pD.clone().data.cpu().numpy(), iteration)\r\n                if iteration %200==199:\r\n                    body_model = [i for i in aD.children()][0]\r\n                    layer1 = body_model.conv\r\n                    xyz = layer1.weight.data.clone()\r\n                    tensor = xyz.cpu()\r\n                    tensors = torchvision.utils.make_grid(tensor, nrow=8,padding=1)\r\n                    writer.add_image(\'D/conv1\', tensors, iteration)\r\n\r\n            end = timer(); print(f\'---train D elapsed time: {end-start}\')\r\n        #---------------VISUALIZATION---------------------\r\n        writer.add_scalar(\'data/gen_cost\', gen_cost, iteration)\r\n        #if iteration %200==199:\r\n        #   paramsG = aG.named_parameters()\r\n        #   for name, pG in paramsG:\r\n        #       writer.add_histogram(\'G.\' + name, pG.clone().data.cpu().numpy(), iteration)\r\n\t#----------------------Generate images-----------------\r\n\r\n        lib.plot.plot(OUTPUT_PATH + \'time\', time.time() - start_time)\r\n        lib.plot.plot(OUTPUT_PATH + \'train_disc_cost\', disc_cost.cpu().data.numpy())\r\n        lib.plot.plot(OUTPUT_PATH + \'train_gen_cost\', gen_cost.cpu().data.numpy())\r\n        lib.plot.plot(OUTPUT_PATH + \'wasserstein_distance\', w_dist.cpu().data.numpy())\r\n        if iteration % 200==199:\r\n            val_loader = load_data(VAL_DIR, VAL_CLASS)\r\n            dev_disc_costs = []\r\n            for _, images in enumerate(val_loader):\r\n                imgs = torch.Tensor(images[0])\r\n               \timgs = imgs.to(device)\r\n                with torch.no_grad():\r\n            \t    imgs_v = imgs\r\n\r\n                D, _ = aD(imgs_v)\r\n                _dev_disc_cost = -D.mean().cpu().data.numpy()\r\n                dev_disc_costs.append(_dev_disc_cost)\r\n            lib.plot.plot(OUTPUT_PATH + \'dev_disc_cost.png\', np.mean(dev_disc_costs))\r\n            lib.plot.flush()\t\r\n            gen_images = generate_image(aG, fixed_noise)\r\n            torchvision.utils.save_image(gen_images, OUTPUT_PATH + \'samples_{}.png\'.format(iteration), nrow=8, padding=2)\r\n            grid_images = torchvision.utils.make_grid(gen_images, nrow=8, padding=2)\r\n            writer.add_image(\'images\', grid_images, iteration)\r\n            #gen_images = generate_image(iteration, aG, persistant_noise)\r\n            #gen_images = torchvision.utils.make_grid(torch.from_numpy(gen_images), nrow=8, padding=1)\r\n            #writer.add_image(\'images\', gen_images, iteration)\r\n\t#----------------------Save model----------------------\r\n            torch.save(aG, OUTPUT_PATH + ""generator.pt"")\r\n            torch.save(aD, OUTPUT_PATH + ""discriminator.pt"")\r\n        lib.plot.tick()\r\n\r\ntrain()\r\n\r\n\r\n'"
train.py,23,"b'import os, sys\r\nsys.path.append(os.getcwd())\r\nimport click\r\nimport time\r\nimport functools\r\nimport pdb\r\n\r\nimport numpy as np\r\nfrom pathlib import Path\r\n\r\nimport torch\r\nimport torchvision\r\nfrom torch import optim\r\nfrom torchvision import transforms\r\n\r\n\r\nfrom models.wgan import *\r\nfrom training_utils import *\r\nimport libs as lib\r\nimport libs.plot\r\nfrom tensorboardX import SummaryWriter\r\n\r\n# to fix png loading\r\nfrom PIL import ImageFile\r\nImageFile.LOAD_TRUNCATED_IMAGES = True\r\n\r\nfrom timeit import default_timer as timer\r\n\r\n\r\n# Some public testing data\r\n# lsun lmdb data set can be download via https://github.com/fyu/lsun\r\n# ImageNet (64x64) at http://image-net.org/small/download.php\r\n\r\n@click.command()\r\n@click.option(\'--train_dir\', default=None, help=\'Data path for training\')\r\n@click.option(\'--validation_dir\', default=None, help=\'Data path for valication\')\r\n@click.option(\'--image_data_type\', default=""image_folder"", type=click.Choice([""lsun"", ""image_folder""]), help=\'If you are using lsun images from lsun lmdb, use lsun. If you use your own data in a folder, then use ""image_folder"". If you use lmdb, you\\\'ll need to write the loader by yourself. Please check load_data function\')\r\n@click.option(\'--output_path\', default=None, help=\'Output path where result (.e.g drawing images, cost, chart) will be stored\')\r\n@click.option(\'--dim\', default=64, help=\'Model dimensionality or image resolution, tested with 64.\')\r\n@click.option(\'--lr\', default=1e-4, help=\'Learning rate\')\r\n@click.option(\'--critic_iters\', default=5, help=\'How many iterations to train the critic/disciminator for\')\r\n@click.option(\'--gen_iters\', default=1, help=\'How many iterations to train the gemerator for\')\r\n@click.option(\'--batch_size\', default=64, help=\'Training batch size. Must be a multiple of number of gpus\')\r\n@click.option(\'--noisy_label_prob\', default=0., help=\'Make the labels the noisy for the discriminator: occasionally flip the labels when training the discriminator\')\r\n@click.option(\'--start_iter\', default=0, help=\'Starting iteration\')\r\n@click.option(\'--end_iter\', default=100000, help=\'Ending iteration\')\r\n@click.option(\'--gp_lambda\', default=10, help=\'Gradient penalty lambda hyperparameter\')\r\n@click.option(\'--num_workers\', default=5, help=\'Number of workers to load data\')\r\n@click.option(\'--saving_step\', default=200, help=\'Save model, sample every this saving step\')\r\n@click.option(\'--training_class\', default=None, help=\'A list of classes, separated by comma "","". IGNORE this if you are NOT training on lsun, or if you want to train on other classes of lsun, then change it accordingly\')\r\n@click.option(\'--val_class\', default=None, help=\'A list of classes, separated by comma "","". IGNORE this if you are NOT training on lsun, or if you want to train on other classes of lsun, then change it accordingly\')\r\n@click.option(\'--restore_mode/--no-restore_mode\', default=False, help=""If True, it will load saved model from OUT_PATH and continue to train"")\r\n\r\n\r\ndef train(train_dir, validation_dir, image_data_type, output_path, dim, lr, critic_iters, gen_iters, batch_size, noisy_label_prob, start_iter, end_iter, gp_lambda, num_workers, saving_step, training_class, val_class, restore_mode):\r\n\r\n    if train_dir is None or len(train_dir) == 0:\r\n        raise Exception(\'Please specify path to data directory in gan.py!\')\r\n\r\n\r\n    output_path = Path(output_path)\r\n    sample_path = output_path / ""samples""\r\n    mkdir_path(sample_path)\r\n    if isinstance(training_class, str):\r\n        training_class = training_class.split("","")\r\n    if isinstance(val_class, str):\r\n        val_class = val_class.split("","")\r\n\r\n    data_transform = transforms.Compose([\r\n        transforms.Resize(dim),\r\n        transforms.RandomCrop(dim),\r\n        # transforms.Lambda(lambda x : x + torch.normal(0, 0.1, (3, dim, dim))),\r\n        transforms.ToTensor(),\r\n        # transforms.Lambda(lambda x : x + torch.randn_like(x)),\r\n        # transforms.Lambda(lambda x : x + torch.normal(0, 0.1, (3, dim, dim))),\r\n        transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])\r\n    ])\r\n\r\n    cuda_available = torch.cuda.is_available()\r\n    device = torch.device(""cuda"" if cuda_available else ""cpu"")\r\n    fixed_noise = gen_rand_noise(batch_size).to(device)\r\n\r\n    if restore_mode:\r\n        aG = GoodGenerator(dim, dim*dim*3)\r\n        aD = GoodDiscriminator(dim)\r\n        # aG = torch.load(str(output_path / ""generator.pt""))\r\n        # aD = torch.load(str(output_path / ""discriminator.pt""))\r\n        g_state_dict = torch.load(str(output_path / ""generator.pt""))\r\n        aG.load_state_dict(remove_module_str_in_state_dict(g_state_dict))\r\n        d_state_dict = torch.load(str(output_path / ""discriminator.pt""))\r\n        aD.load_state_dict(remove_module_str_in_state_dict(d_state_dict))\r\n    else:\r\n        aG = GoodGenerator(dim, dim*dim*3)\r\n        aD = GoodDiscriminator(dim)\r\n        aG.apply(weights_init)\r\n        aD.apply(weights_init)\r\n\r\n    optimizer_g = torch.optim.Adam(aG.parameters(), lr=lr, betas=(0,0.9))\r\n    optimizer_d = torch.optim.Adam(aD.parameters(), lr=lr, betas=(0,0.9))\r\n    one = torch.FloatTensor([1])\r\n    mone = one * -1\r\n    # aG = aG.to(device)\r\n    # aD = aD.to(device)\r\n    aG = torch.nn.DataParallel(aG).to(device)\r\n    aD = torch.nn.DataParallel(aD).to(device)\r\n    one = one.to(device)\r\n    mone = mone.to(device)\r\n\r\n    writer = SummaryWriter()\r\n    #Reference: https://github.com/caogang/wgan-gp/blob/master/gan_cifar10.py\r\n    dataloader = load_data(image_data_type, train_dir, data_transform, batch_size=batch_size, classes=training_class, num_workers=num_workers)\r\n    dataiter = iter(dataloader)\r\n    for iteration in range(start_iter, end_iter):\r\n        start_time = time.time()\r\n        print(""Iter: "" + str(iteration))\r\n        start = timer()\r\n        #---------------------TRAIN G------------------------\r\n        for p in aD.parameters():\r\n            p.requires_grad_(False)  # freeze D\r\n\r\n        gen_cost = None\r\n        for i in range(gen_iters):\r\n            print(""Generator iters: "" + str(i))\r\n            aG.zero_grad()\r\n            noise = gen_rand_noise(batch_size).to(device)\r\n            noise.requires_grad_(True)\r\n            fake_data = aG(noise)\r\n            # fake_data = fake_data.view(batch_size, 3, dim, dim)\r\n            # fake_data += torch.normal(0, 0.1, (batch_size, 3, dim, dim)).to(device)\r\n            gen_cost = aD(fake_data)\r\n            gen_cost = gen_cost.mean()\r\n            gen_cost.backward(mone)\r\n            gen_cost = -gen_cost\r\n        \r\n        optimizer_g.step()\r\n        end = timer()\r\n        print(f\'---train G elapsed time: {end - start}\')\r\n        #---------------------TRAIN D------------------------\r\n        for p in aD.parameters():  # reset requires_grad\r\n            p.requires_grad_(True)  # they are set to False below in training G\r\n        for i in range(critic_iters):\r\n            print(""Critic iter: "" + str(i))\r\n            \r\n            start = timer()\r\n            aD.zero_grad()\r\n\r\n            # gen fake data and load real data\r\n            noise = gen_rand_noise(batch_size).to(device)\r\n            with torch.no_grad():\r\n                noisev = noise  # totally freeze G, training D\r\n            fake_data = aG(noisev).detach()\r\n            # fake_data = fake_data.view(batch_size, 3, dim, dim)\r\n            # fake_data += torch.normal(0, 0.1, (batch_size, 3, dim, dim)).to(device)\r\n            end = timer(); print(f\'---gen G elapsed time: {end-start}\')\r\n            start = timer()\r\n            batch = next(dataiter, None)\r\n            if batch is None:\r\n                dataiter = iter(dataloader)\r\n                batch = dataiter.next()\r\n            batch = batch[0] #batch[1] contains labels\r\n            real_data = batch.to(device) #TODO: modify load_data for each loading\r\n            end = timer(); print(f\'---load real imgs elapsed time: {end-start}\')\r\n            start = timer()\r\n\r\n            is_flipping = False\r\n            if noisy_label_prob > 0 and noisy_label_prob < 1:\r\n                is_flipping = np.random.randint(1//noisy_label_prob, size=1)[0] == 1\r\n\r\n            if not is_flipping:\r\n                # train with real data\r\n                disc_real = aD(real_data)\r\n                disc_real = disc_real.mean()\r\n\r\n                # train with fake data\r\n                disc_fake = aD(fake_data)\r\n                disc_fake = disc_fake.mean()\r\n            else:\r\n                # train with fake data\r\n                disc_real = aD(fake_data)\r\n                disc_real = disc_real.mean()\r\n\r\n                # train with real data\r\n                disc_fake = aD(real_data)\r\n                disc_fake = disc_fake.mean()\r\n\r\n            #showMemoryUsage(0)\r\n            # train with interpolates data\r\n            gradient_penalty = calc_gradient_penalty(aD, real_data, fake_data, batch_size, dim, device, gp_lambda)\r\n            #showMemoryUsage(0)\r\n\r\n            # final disc cost\r\n            disc_cost = disc_fake - disc_real + gradient_penalty\r\n            disc_cost.backward()\r\n            w_dist = disc_fake  - disc_real\r\n            optimizer_d.step()\r\n            #------------------VISUALIZATION----------\r\n            if i == critic_iters-1:\r\n                writer.add_scalar(\'data/disc_cost\', disc_cost, iteration)\r\n                #writer.add_scalar(\'data/disc_fake\', disc_fake, iteration)\r\n                #writer.add_scalar(\'data/disc_real\', disc_real, iteration)\r\n                writer.add_scalar(\'data/gradient_pen\', gradient_penalty, iteration)\r\n\r\n            end = timer(); print(f\'---train D elapsed time: {end-start}\')\r\n        #---------------VISUALIZATION---------------------\r\n        writer.add_scalar(\'data/gen_cost\', gen_cost, iteration)\r\n\r\n        lib.plot.plot(str(output_path / \'time\'), time.time() - start_time)\r\n        lib.plot.plot(str(output_path / \'train_disc_cost\'), disc_cost.cpu().data.numpy())\r\n        lib.plot.plot(str(output_path / \'train_gen_cost\'), gen_cost.cpu().data.numpy())\r\n        lib.plot.plot(str(output_path / \'wasserstein_distance\'), w_dist.cpu().data.numpy())\r\n        if iteration > 0 and iteration % saving_step == 0:\r\n            val_loader = load_data(image_data_type, validation_dir, data_transform, batch_size=batch_size, classes=val_class, num_workers=num_workers)\r\n            dev_disc_costs = []\r\n            for _, images in enumerate(val_loader):\r\n                imgs = torch.Tensor(images[0])\r\n               \timgs = imgs.to(device)\r\n                with torch.no_grad():\r\n            \t    imgs_v = imgs\r\n\r\n                D = aD(imgs_v)\r\n                _dev_disc_cost = -D.mean().cpu().data.numpy()\r\n                dev_disc_costs.append(_dev_disc_cost)\r\n            lib.plot.plot(str(output_path / \'dev_disc_cost.png\'), np.mean(dev_disc_costs))\r\n            lib.plot.flush()\t\r\n            gen_images = generate_image(aG, dim=dim, batch_size=batch_size, noise=fixed_noise)\r\n            torchvision.utils.save_image(gen_images, str(sample_path / \'samples_{}.png\').format(iteration), nrow=8, padding=2)\r\n            grid_images = torchvision.utils.make_grid(gen_images, nrow=8, padding=2)\r\n            writer.add_image(\'images\', grid_images, iteration)\r\n\t#----------------------Save model----------------------\r\n            # torch.save(aG, str(output_path / ""generator.pt""))\r\n            # torch.save(aD, str(output_path / ""discriminator.pt""))\r\n            torch.save(aG.state_dict(), str(output_path / ""generator.pt""))\r\n            torch.save(aD.state_dict(), str(output_path / ""discriminator.pt""))\r\n        lib.plot.tick()\r\n\r\nif __name__ == \'__main__\':\r\n    train()\r\n    '"
training_utils.py,8,"b'from pathlib import Path\nfrom collections import OrderedDict\n\nimport gpustat\nimport torch\nfrom torch import autograd\nimport torch.nn.init as init\nfrom torchvision import transforms, datasets\nfrom torch.autograd import grad\n\nfrom models.wgan import *\n\ndef mkdir_path(path):\n    path.mkdir(parents=True, exist_ok=True)\n\ndef showMemoryUsage(device=1):\n    gpu_stats = gpustat.GPUStatCollection.new_query()\n    item = gpu_stats.jsonify()[""gpus""][device]\n    print(\'Used/total: \' + ""{}/{}"".format(item[""memory.used""], item[""memory.total""]))\n\n\ndef weights_init(m):\n    if isinstance(m, MyConvo2d): \n        if m.conv.weight is not None:\n            if m.he_init:\n                init.kaiming_uniform_(m.conv.weight)\n            else:\n                init.xavier_uniform_(m.conv.weight)\n        if m.conv.bias is not None:\n            init.constant_(m.conv.bias, 0.0)\n    if isinstance(m, nn.Linear):\n        if m.weight is not None:\n            init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            init.constant_(m.bias, 0.0)\n\n\ndef remove_module_str_in_state_dict(state_dict):\n    state_dict_rename = OrderedDict()\n    for k, v in state_dict.items():\n        name = k.replace(""module."", """") # remove `module.`\n        state_dict_rename[name] = v\n    return state_dict_rename\n\ndef load_data(image_data_type, path_to_folder, data_transform, batch_size, classes=None, num_workers=5):\n    # torch issue\n    # https://github.com/pytorch/pytorch/issues/22866\n    torch.set_num_threads(1)\n    if image_data_type == \'lsun\':\n        dataset =  datasets.LSUN(path_to_folder, classes=classes, transform=data_transform)\n    elif image_data_type == ""image_folder"":\n        dataset = datasets.ImageFolder(root=path_to_folder,transform=data_transform)\n    else:\n        raise ValueError(""Invalid image data type"")\n    dataset_loader = torch.utils.data.DataLoader(dataset,batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True, pin_memory=True)\n    return dataset_loader\n\n\ndef generate_image(netG, dim, batch_size, noise=None):\n    if noise is None:\n        noise = gen_rand_noise()\n\n    with torch.no_grad():\n    \tnoisev = noise \n    samples = netG(noisev)\n    samples = samples.view(batch_size, 3, dim, dim)\n    samples = samples * 0.5 + 0.5\n    return samples\n\ndef gen_rand_noise(batch_size, ):\n    noise = torch.randn(batch_size, 128)\n    return noise\n\n\ndef calc_gradient_penalty(netD, real_data, fake_data, batch_size, dim, device, gp_lambda):\n    alpha = torch.rand(batch_size, 1)\n    alpha = alpha.expand(batch_size, int(real_data.nelement()/batch_size)).contiguous()\n    alpha = alpha.view(batch_size, 3, dim, dim)\n    alpha = alpha.to(device)\n    \n    fake_data = fake_data.view(batch_size, 3, dim, dim)\n    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n\n    interpolates = interpolates.to(device)\n    interpolates.requires_grad_(True)\n\n    disc_interpolates = netD(interpolates)\n\n    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n\n    gradients = gradients.view(gradients.size(0), -1)                              \n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * gp_lambda\n    return gradient_penalty\n\n\n\n\n'"
libs/__init__.py,0,b''
libs/plot.py,0,"b'import numpy as np\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\n\nimport collections\nimport time\n#import cPickle as pickle\nimport pickle\n\n_since_beginning = collections.defaultdict(lambda: {})\n_since_last_flush = collections.defaultdict(lambda: {})\n\n_iter = [0]\ndef tick():\n\t_iter[0] += 1\n\ndef plot(name, value):\n\t_since_last_flush[name][_iter[0]] = value\n\ndef flush():\n\tprints = []\n\n\tfor name, vals in _since_last_flush.items():\n\t\tprints.append(""{}\\t{}"".format(name, np.mean(list(vals.values()))))\n\t\t_since_beginning[name].update(vals)\n\n\t\tx_vals = np.sort(list(_since_beginning[name].keys()))\n\t\ty_vals = [_since_beginning[name][x] for x in x_vals]\n\n\t\tplt.clf()\n\t\tplt.plot(x_vals, y_vals)\n\t\tplt.xlabel(\'iteration\')\n\t\tplt.ylabel(name)\n\t\tplt.savefig(name.replace(\' \', \'_\')+\'.jpg\')\n\n\tprint(""iter {}\\t{}"".format(_iter[0], ""\\t"".join(prints)))\n\t_since_last_flush.clear()\n\n\twith open(\'log.pkl\', \'wb\') as f:\n\t\tpickle.dump(dict(_since_beginning), f, pickle.HIGHEST_PROTOCOL)\n'"
models/__init__.py,0,b''
models/conwgan.py,3,"b""from torch import nn\nfrom torch.autograd import grad\nimport torch\nDIM=64\nOUTPUT_DIM=64*64*3\n\nclass MyConvo2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, he_init = True,  stride = 1, bias = True):\n        super(MyConvo2d, self).__init__()\n        self.he_init = he_init\n        self.padding = int((kernel_size - 1)/2)\n        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=self.padding, bias = bias)\n\n    def forward(self, input):\n        output = self.conv(input)\n        return output\n\nclass ConvMeanPool(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, he_init = True):\n        super(ConvMeanPool, self).__init__()\n        self.he_init = he_init\n        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init)\n\n    def forward(self, input):\n        output = self.conv(input)\n        output = (output[:,:,::2,::2] + output[:,:,1::2,::2] + output[:,:,::2,1::2] + output[:,:,1::2,1::2]) / 4\n        return output\n\nclass MeanPoolConv(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, he_init = True):\n        super(MeanPoolConv, self).__init__()\n        self.he_init = he_init\n        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init)\n\n    def forward(self, input):\n        output = input\n        output = (output[:,:,::2,::2] + output[:,:,1::2,::2] + output[:,:,::2,1::2] + output[:,:,1::2,1::2]) / 4\n        output = self.conv(output)\n        return output\n\nclass DepthToSpace(nn.Module):\n    def __init__(self, block_size):\n        super(DepthToSpace, self).__init__()\n        self.block_size = block_size\n        self.block_size_sq = block_size*block_size\n\n    def forward(self, input):\n        output = input.permute(0, 2, 3, 1)\n        (batch_size, input_height, input_width, input_depth) = output.size()\n        output_depth = int(input_depth / self.block_size_sq)\n        output_width = int(input_width * self.block_size)\n        output_height = int(input_height * self.block_size)\n        t_1 = output.reshape(batch_size, input_height, input_width, self.block_size_sq, output_depth)\n        spl = t_1.split(self.block_size, 3)\n        stacks = [t_t.reshape(batch_size,input_height,output_width,output_depth) for t_t in spl]\n        output = torch.stack(stacks,0).transpose(0,1).permute(0,2,1,3,4).reshape(batch_size,output_height,output_width,output_depth)\n        output = output.permute(0, 3, 1, 2)\n        return output\n\n\nclass UpSampleConv(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, he_init = True, bias=True):\n        super(UpSampleConv, self).__init__()\n        self.he_init = he_init\n        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init, bias=bias)\n        self.depth_to_space = DepthToSpace(2)\n\n    def forward(self, input):\n        output = input\n        output = torch.cat((output, output, output, output), 1)\n        output = self.depth_to_space(output)\n        output = self.conv(output)\n        return output\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, resample=None, hw=DIM):\n        super(ResidualBlock, self).__init__()\n\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.kernel_size = kernel_size\n        self.resample = resample\n        self.bn1 = None\n        self.bn2 = None\n        self.relu1 = nn.ReLU()\n        self.relu2 = nn.ReLU()\n        if resample == 'down':\n            self.bn1 = nn.LayerNorm([input_dim, hw, hw])\n            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n        elif resample == 'up':\n            self.bn1 = nn.BatchNorm2d(input_dim)\n            self.bn2 = nn.BatchNorm2d(output_dim)\n        elif resample == None:\n            #TODO: ????\n            self.bn1 = nn.BatchNorm2d(output_dim)\n            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n        else:\n            raise Exception('invalid resample value')\n\n        if resample == 'down':\n            self.conv_shortcut = MeanPoolConv(input_dim, output_dim, kernel_size = 1, he_init = False)\n            self.conv_1 = MyConvo2d(input_dim, input_dim, kernel_size = kernel_size, bias = False)\n            self.conv_2 = ConvMeanPool(input_dim, output_dim, kernel_size = kernel_size)\n        elif resample == 'up':\n            self.conv_shortcut = UpSampleConv(input_dim, output_dim, kernel_size = 1, he_init = False)\n            self.conv_1 = UpSampleConv(input_dim, output_dim, kernel_size = kernel_size, bias = False)\n            self.conv_2 = MyConvo2d(output_dim, output_dim, kernel_size = kernel_size)\n        elif resample == None:\n            self.conv_shortcut = MyConvo2d(input_dim, output_dim, kernel_size = 1, he_init = False)\n            self.conv_1 = MyConvo2d(input_dim, input_dim, kernel_size = kernel_size, bias = False)\n            self.conv_2 = MyConvo2d(input_dim, output_dim, kernel_size = kernel_size)\n        else:\n            raise Exception('invalid resample value')\n\n    def forward(self, input):\n        if self.input_dim == self.output_dim and self.resample == None:\n            shortcut = input\n        else:\n            shortcut = self.conv_shortcut(input)\n\n        output = input\n        output = self.bn1(output)\n        output = self.relu1(output)\n        output = self.conv_1(output)\n        output = self.bn2(output)\n        output = self.relu2(output)\n        output = self.conv_2(output)\n\n        return shortcut + output\n\nclass ReLULayer(nn.Module):\n    def __init__(self, n_in, n_out):\n        super(ReLULayer, self).__init__()\n        self.n_in = n_in\n        self.n_out = n_out\n        self.linear = nn.Linear(n_in, n_out)\n        self.relu = nn.ReLU()\n\n    def forward(self, input):\n        output = self.linear(input)\n        output = self.relu(output)\n        return output\n\nclass FCGenerator(nn.Module):\n    def __init__(self, FC_DIM=512):\n        super(FCGenerator, self).__init__()\n        self.relulayer1 = ReLULayer(128, FC_DIM)\n        self.relulayer2 = ReLULayer(FC_DIM, FC_DIM)\n        self.relulayer3 = ReLULayer(FC_DIM, FC_DIM)\n        self.relulayer4 = ReLULayer(FC_DIM, FC_DIM)\n        self.linear = nn.Linear(FC_DIM, OUTPUT_DIM)\n        self.tanh = nn.Tanh()\n\n    def forward(self, input):\n        output = self.relulayer1(input)\n        output = self.relulayer2(output)\n        output = self.relulayer3(output)\n        output = self.relulayer4(output)\n        output = self.linear(output)\n        output = self.tanh(output)\n        return output\n\nclass GoodGenerator(nn.Module):\n    def __init__(self, dim=DIM,output_dim=OUTPUT_DIM):\n        super(GoodGenerator, self).__init__()\n\n        self.dim = dim\n\n        self.ln1 = nn.Linear(128, 4*4*8*self.dim)\n        self.rb1 = ResidualBlock(8*self.dim, 8*self.dim, 3, resample = 'up')\n        self.rb2 = ResidualBlock(8*self.dim, 4*self.dim, 3, resample = 'up')\n        self.rb3 = ResidualBlock(4*self.dim, 2*self.dim, 3, resample = 'up')\n        self.rb4 = ResidualBlock(2*self.dim, 1*self.dim, 3, resample = 'up')\n        self.bn  = nn.BatchNorm2d(self.dim)\n\n        self.conv1 = MyConvo2d(1*self.dim, 3, 3)\n        self.relu = nn.ReLU()\n        self.tanh = nn.Tanh()\n\n    def forward(self, input):\n        output = self.ln1(input.contiguous())\n        output = output.view(-1, 8*self.dim, 4, 4)\n        output = self.rb1(output)\n        output = self.rb2(output)\n        output = self.rb3(output)\n        output = self.rb4(output)\n\n        output = self.bn(output)\n        output = self.relu(output)\n        output = self.conv1(output)\n        output = self.tanh(output)\n        output = output.view(-1, OUTPUT_DIM)\n        return output\n\nclass GoodDiscriminator(nn.Module):\n    def __init__(self, dim=DIM, num_class=2):\n        super(GoodDiscriminator, self).__init__()\n\n        self.dim = dim\n        self.num_class = num_class\n        self.conv1 = MyConvo2d(3, self.dim, 3, he_init = False)\n        self.rb1 = ResidualBlock(self.dim, 2*self.dim, 3, resample = 'down', hw=DIM)\n        self.rb2 = ResidualBlock(2*self.dim, 4*self.dim, 3, resample = 'down', hw=int(DIM/2))\n        self.rb3 = ResidualBlock(4*self.dim, 8*self.dim, 3, resample = 'down', hw=int(DIM/4))\n        self.rb4 = ResidualBlock(8*self.dim, 8*self.dim, 3, resample = 'down', hw=int(DIM/8))\n        self.ln1 = nn.Linear(4*4*8*self.dim, 1)\n\n        self.ln2 = nn.Linear(4*4*8*self.dim, self.num_class)\n\n    def forward(self, input):\n        output = input.contiguous()\n        output = output.view(-1, 3, DIM, DIM)\n        output = self.conv1(output)\n        output = self.rb1(output)\n        output = self.rb2(output)\n        output = self.rb3(output)\n        output = self.rb4(output)\n        output = output.view(-1, 4*4*8*self.dim)\n        output_wgan = self.ln1(output)\n        output_wgan = output_wgan.view(-1)\n        output_congan = self.ln2(output)\n        return output_wgan, output_congan\n"""
models/wgan.py,3,"b""from torch import nn\nfrom torch.autograd import grad\nimport torch\nimport pdb\n\nclass MyConvo2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, he_init = True,  stride = 1, bias = True):\n        super(MyConvo2d, self).__init__()\n        self.he_init = he_init\n        self.padding = int((kernel_size - 1)/2)\n        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=self.padding, bias = bias)\n\n    def forward(self, input):\n        output = self.conv(input)\n        return output\n\nclass ConvMeanPool(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, he_init = True):\n        super(ConvMeanPool, self).__init__()\n        self.he_init = he_init\n        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init)\n\n    def forward(self, input):\n        output = self.conv(input)\n        output = (output[:,:,::2,::2] + output[:,:,1::2,::2] + output[:,:,::2,1::2] + output[:,:,1::2,1::2]) / 4\n        return output\n\nclass MeanPoolConv(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, he_init = True):\n        super(MeanPoolConv, self).__init__()\n        self.he_init = he_init\n        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init)\n\n    def forward(self, input):\n        output = input\n        output = (output[:,:,::2,::2] + output[:,:,1::2,::2] + output[:,:,::2,1::2] + output[:,:,1::2,1::2]) / 4\n        output = self.conv(output)\n        return output\n\nclass DepthToSpace(nn.Module):\n    def __init__(self, block_size):\n        super(DepthToSpace, self).__init__()\n        self.block_size = block_size\n        self.block_size_sq = block_size*block_size\n\n    def forward(self, input):\n        output = input.permute(0, 2, 3, 1)\n        (batch_size, input_height, input_width, input_depth) = output.size()\n        output_depth = int(input_depth / self.block_size_sq)\n        output_width = int(input_width * self.block_size)\n        output_height = int(input_height * self.block_size)\n        t_1 = output.reshape(batch_size, input_height, input_width, self.block_size_sq, output_depth)\n        spl = t_1.split(self.block_size, 3)\n        stacks = [t_t.reshape(batch_size,input_height,output_width,output_depth) for t_t in spl]\n        output = torch.stack(stacks,0).transpose(0,1).permute(0,2,1,3,4).reshape(batch_size,output_height,output_width,output_depth)\n        output = output.permute(0, 3, 1, 2)\n        return output\n\n\nclass UpSampleConv(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, he_init = True, bias=True):\n        super(UpSampleConv, self).__init__()\n        self.he_init = he_init\n        self.conv = MyConvo2d(input_dim, output_dim, kernel_size, he_init = self.he_init, bias=bias)\n        self.depth_to_space = DepthToSpace(2)\n\n    def forward(self, input):\n        output = input\n        output = torch.cat((output, output, output, output), 1)\n        output = self.depth_to_space(output)\n        output = self.conv(output)\n        return output\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, resample=None, hw=64):\n        super(ResidualBlock, self).__init__()\n\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.kernel_size = kernel_size\n        self.resample = resample\n        self.bn1 = None\n        self.bn2 = None\n        self.relu1 = nn.ReLU()\n        self.relu2 = nn.ReLU()\n        if resample == 'down':\n            self.bn1 = nn.LayerNorm([input_dim, hw, hw])\n            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n        elif resample == 'up':\n            self.bn1 = nn.BatchNorm2d(input_dim)\n            self.bn2 = nn.BatchNorm2d(output_dim)\n        elif resample == None:\n            #TODO: ????\n            self.bn1 = nn.BatchNorm2d(output_dim)\n            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n        else:\n            raise Exception('invalid resample value')\n\n        if resample == 'down':\n            self.conv_shortcut = MeanPoolConv(input_dim, output_dim, kernel_size = 1, he_init = False)\n            self.conv_1 = MyConvo2d(input_dim, input_dim, kernel_size = kernel_size, bias = False)\n            self.conv_2 = ConvMeanPool(input_dim, output_dim, kernel_size = kernel_size)\n        elif resample == 'up':\n            self.conv_shortcut = UpSampleConv(input_dim, output_dim, kernel_size = 1, he_init = False)\n            self.conv_1 = UpSampleConv(input_dim, output_dim, kernel_size = kernel_size, bias = False)\n            self.conv_2 = MyConvo2d(output_dim, output_dim, kernel_size = kernel_size)\n        elif resample == None:\n            self.conv_shortcut = MyConvo2d(input_dim, output_dim, kernel_size = 1, he_init = False)\n            self.conv_1 = MyConvo2d(input_dim, input_dim, kernel_size = kernel_size, bias = False)\n            self.conv_2 = MyConvo2d(input_dim, output_dim, kernel_size = kernel_size)\n        else:\n            raise Exception('invalid resample value')\n\n    def forward(self, input):\n        if self.input_dim == self.output_dim and self.resample == None:\n            shortcut = input\n        else:\n            shortcut = self.conv_shortcut(input)\n\n        output = input\n        output = self.bn1(output)\n        output = self.relu1(output)\n        output = self.conv_1(output)\n        output = self.bn2(output)\n        output = self.relu2(output)\n        output = self.conv_2(output)\n\n        return shortcut + output\n\n\nclass GoodGenerator(nn.Module):\n    def __init__(self, dim=64, output_dim=3*64*64):\n        super(GoodGenerator, self).__init__()\n\n        self.dim = dim\n\n        self.ssize = self.dim // 16\n        self.ln1 = nn.Linear(128, self.ssize*self.ssize*8*self.dim)\n        self.rb1 = ResidualBlock(8*self.dim, 8*self.dim, 3, resample = 'up')\n        self.rb2 = ResidualBlock(8*self.dim, 4*self.dim, 3, resample = 'up')\n        self.rb3 = ResidualBlock(4*self.dim, 2*self.dim, 3, resample = 'up')\n        self.rb4 = ResidualBlock(2*self.dim, 1*self.dim, 3, resample = 'up')\n        self.bn  = nn.BatchNorm2d(self.dim)\n\n        self.conv1 = MyConvo2d(1*self.dim, 3, 3)\n        self.relu = nn.ReLU()\n        self.tanh = nn.Tanh()\n\n    def forward(self, input):\n        output = self.ln1(input.contiguous())\n        output = output.view(-1, 8*self.dim, self.ssize, self.ssize)\n        output = self.rb1(output)\n        output = self.rb2(output)\n        output = self.rb3(output)\n        output = self.rb4(output)\n\n        output = self.bn(output)\n        output = self.relu(output)\n        output = self.conv1(output)\n        output = self.tanh(output)\n        output = output.view(-1, 3 * self.dim * self.dim)\n        return output\n\nclass GoodDiscriminator(nn.Module):\n    def __init__(self, dim=64):\n        super(GoodDiscriminator, self).__init__()\n\n        self.dim = dim\n\n        self.ssize = self.dim // 16\n        self.conv1 = MyConvo2d(3, self.dim, 3, he_init = False)\n        self.rb1 = ResidualBlock(self.dim, 2*self.dim, 3, resample = 'down', hw=self.dim)\n        self.rb2 = ResidualBlock(2*self.dim, 4*self.dim, 3, resample = 'down', hw=int(self.dim/2))\n        self.rb3 = ResidualBlock(4*self.dim, 8*self.dim, 3, resample = 'down', hw=int(self.dim/4))\n        self.rb4 = ResidualBlock(8*self.dim, 8*self.dim, 3, resample = 'down', hw=int(self.dim/8))\n        self.ln1 = nn.Linear(self.ssize*self.ssize*8*self.dim, 1)\n\n    def forward(self, input):\n        output = input.contiguous()\n        output = output.view(-1, 3, self.dim, self.dim)\n        output = self.conv1(output)\n        output = self.rb1(output)\n        output = self.rb2(output)\n        output = self.rb3(output)\n        output = self.rb4(output)\n        output = output.view(-1, self.ssize*self.ssize*8*self.dim)\n        output = self.ln1(output)\n        output = output.view(-1)\n        return output\n"""
