file_path,api_count,code
infer.py,2,"b""import argparse\nimport os\nimport json\n\nfrom model import ShuffleNet\n\nfrom torchvision import transforms\nfrom torch.autograd import Variable\nimport torch\nfrom PIL import Image\nimport numpy as np\n\ndef get_transformer():\n  normalize = transforms.Normalize(\n      mean=[0.485, 0.456, 0.406],\n      std=[0.229, 0.224, 0.225])\n\n  transformer = transforms.Compose([\n      transforms.Resize(128),\n      transforms.ToTensor(),\n      normalize\n  ])\n  return transformer\n\ndef preprocess(image, transformer):\n  x = transformer(image)\n  return Variable(x.unsqueeze(0))\n\ndef infer(args):\n  # make ShuffleNet model\n  print('Creating ShuffleNet model')\n  net = ShuffleNet(num_classes=args.num_classes, in_channels=3)\n  \n  # load trained checkpoint\n  print('Loading checkpoint')\n  checkpoint = torch.load(args.checkpoint, map_location=lambda storage, loc: storage)\n  net.load_state_dict(checkpoint['state_dict'])\n\n  print('Loading index-class map')\n  with open(args.idx_to_class, 'r') as f:\n      mapping = json.load(f)\n\n  # image transformer\n  transformer = get_transformer()\n\n  # make input tensor\n  print('Loading image')\n  image = Image.open(args.image)\n  print('Preprocessing')\n  x = preprocess(image, transformer)\n\n  # predict output\n  print('Inferring on image {}'.format(args.image))\n  net.eval()\n  y = net(x)\n  top_idxs = np.argsort(y.data.cpu().numpy().ravel()).tolist()[-10:][::-1]\n  print('==========================================')\n  for i, idx in enumerate(top_idxs):\n    key = str(idx)\n    class_name = mapping[key][1]\n    print('{}.\\t{}'.format(i+1, class_name))\n  print('==========================================')\n\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser()\n  parser.add_argument('image', type=str, help='Path to image that we want to classify')\n  parser.add_argument('checkpoint', type=str, help='Path to ShuffleNet checkpoint with trained weights')\n  parser.add_argument('idx_to_class', type=str, help='Path to JSON file mapping indexes to class names')\n  parser.add_argument('--num_classes', type=int, help='Number of classes to predict', default=1000)\n  args = parser.parse_args()\n  infer(args)\n"""
model.py,6,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom collections import OrderedDict\nfrom torch.nn import init\n\n\ndef conv3x3(in_channels, out_channels, stride=1, \n            padding=1, bias=True, groups=1):    \n    """"""3x3 convolution with padding\n    """"""\n    return nn.Conv2d(\n        in_channels, \n        out_channels, \n        kernel_size=3, \n        stride=stride,\n        padding=padding,\n        bias=bias,\n        groups=groups)\n\n\ndef conv1x1(in_channels, out_channels, groups=1):\n    """"""1x1 convolution with padding\n    - Normal pointwise convolution When groups == 1\n    - Grouped pointwise convolution when groups > 1\n    """"""\n    return nn.Conv2d(\n        in_channels, \n        out_channels, \n        kernel_size=1, \n        groups=groups,\n        stride=1)\n\n\ndef channel_shuffle(x, groups):\n    batchsize, num_channels, height, width = x.data.size()\n\n    channels_per_group = num_channels // groups\n    \n    # reshape\n    x = x.view(batchsize, groups, \n        channels_per_group, height, width)\n\n    # transpose\n    # - contiguous() required if transpose() is used before view().\n    #   See https://github.com/pytorch/pytorch/issues/764\n    x = torch.transpose(x, 1, 2).contiguous()\n\n    # flatten\n    x = x.view(batchsize, -1, height, width)\n\n    return x\n\n\nclass ShuffleUnit(nn.Module):\n    def __init__(self, in_channels, out_channels, groups=3,\n                 grouped_conv=True, combine=\'add\'):\n        \n        super(ShuffleUnit, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.grouped_conv = grouped_conv\n        self.combine = combine\n        self.groups = groups\n        self.bottleneck_channels = self.out_channels // 4\n\n        # define the type of ShuffleUnit\n        if self.combine == \'add\':\n            # ShuffleUnit Figure 2b\n            self.depthwise_stride = 1\n            self._combine_func = self._add\n        elif self.combine == \'concat\':\n            # ShuffleUnit Figure 2c\n            self.depthwise_stride = 2\n            self._combine_func = self._concat\n            \n            # ensure output of concat has the same channels as \n            # original output channels.\n            self.out_channels -= self.in_channels\n        else:\n            raise ValueError(""Cannot combine tensors with \\""{}\\"""" \\\n                             ""Only \\""add\\"" and \\""concat\\"" are"" \\\n                             ""supported"".format(self.combine))\n\n        # Use a 1x1 grouped or non-grouped convolution to reduce input channels\n        # to bottleneck channels, as in a ResNet bottleneck module.\n        # NOTE: Do not use group convolution for the first conv1x1 in Stage 2.\n        self.first_1x1_groups = self.groups if grouped_conv else 1\n\n        self.g_conv_1x1_compress = self._make_grouped_conv1x1(\n            self.in_channels,\n            self.bottleneck_channels,\n            self.first_1x1_groups,\n            batch_norm=True,\n            relu=True\n            )\n\n        # 3x3 depthwise convolution followed by batch normalization\n        self.depthwise_conv3x3 = conv3x3(\n            self.bottleneck_channels, self.bottleneck_channels,\n            stride=self.depthwise_stride, groups=self.bottleneck_channels)\n        self.bn_after_depthwise = nn.BatchNorm2d(self.bottleneck_channels)\n\n        # Use 1x1 grouped convolution to expand from \n        # bottleneck_channels to out_channels\n        self.g_conv_1x1_expand = self._make_grouped_conv1x1(\n            self.bottleneck_channels,\n            self.out_channels,\n            self.groups,\n            batch_norm=True,\n            relu=False\n            )\n\n\n    @staticmethod\n    def _add(x, out):\n        # residual connection\n        return x + out\n\n\n    @staticmethod\n    def _concat(x, out):\n        # concatenate along channel axis\n        return torch.cat((x, out), 1)\n\n\n    def _make_grouped_conv1x1(self, in_channels, out_channels, groups,\n        batch_norm=True, relu=False):\n\n        modules = OrderedDict()\n\n        conv = conv1x1(in_channels, out_channels, groups=groups)\n        modules[\'conv1x1\'] = conv\n\n        if batch_norm:\n            modules[\'batch_norm\'] = nn.BatchNorm2d(out_channels)\n        if relu:\n            modules[\'relu\'] = nn.ReLU()\n        if len(modules) > 1:\n            return nn.Sequential(modules)\n        else:\n            return conv\n\n\n    def forward(self, x):\n        # save for combining later with output\n        residual = x\n\n        if self.combine == \'concat\':\n            residual = F.avg_pool2d(residual, kernel_size=3, \n                stride=2, padding=1)\n\n        out = self.g_conv_1x1_compress(x)\n        out = channel_shuffle(out, self.groups)\n        out = self.depthwise_conv3x3(out)\n        out = self.bn_after_depthwise(out)\n        out = self.g_conv_1x1_expand(out)\n        \n        out = self._combine_func(residual, out)\n        return F.relu(out)\n\n\nclass ShuffleNet(nn.Module):\n    """"""ShuffleNet implementation.\n    """"""\n\n    def __init__(self, groups=3, in_channels=3, num_classes=1000):\n        """"""ShuffleNet constructor.\n\n        Arguments:\n            groups (int, optional): number of groups to be used in grouped \n                1x1 convolutions in each ShuffleUnit. Default is 3 for best\n                performance according to original paper.\n            in_channels (int, optional): number of channels in the input tensor.\n                Default is 3 for RGB image inputs.\n            num_classes (int, optional): number of classes to predict. Default\n                is 1000 for ImageNet.\n\n        """"""\n        super(ShuffleNet, self).__init__()\n\n        self.groups = groups\n        self.stage_repeats = [3, 7, 3]\n        self.in_channels =  in_channels\n        self.num_classes = num_classes\n\n        # index 0 is invalid and should never be called.\n        # only used for indexing convenience.\n        if groups == 1:\n            self.stage_out_channels = [-1, 24, 144, 288, 567]\n        elif groups == 2:\n            self.stage_out_channels = [-1, 24, 200, 400, 800]\n        elif groups == 3:\n            self.stage_out_channels = [-1, 24, 240, 480, 960]\n        elif groups == 4:\n            self.stage_out_channels = [-1, 24, 272, 544, 1088]\n        elif groups == 8:\n            self.stage_out_channels = [-1, 24, 384, 768, 1536]\n        else:\n            raise ValueError(\n                """"""{} groups is not supported for\n                   1x1 Grouped Convolutions"""""".format(num_groups))\n        \n        # Stage 1 always has 24 output channels\n        self.conv1 = conv3x3(self.in_channels,\n                             self.stage_out_channels[1], # stage 1\n                             stride=2)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Stage 2\n        self.stage2 = self._make_stage(2)\n        # Stage 3\n        self.stage3 = self._make_stage(3)\n        # Stage 4\n        self.stage4 = self._make_stage(4)\n\n        # Global pooling:\n        # Undefined as PyTorch\'s functional API can be used for on-the-fly\n        # shape inference if input size is not ImageNet\'s 224x224\n\n        # Fully-connected classification layer\n        num_inputs = self.stage_out_channels[-1]\n        self.fc = nn.Linear(num_inputs, self.num_classes)\n        self.init_params()\n\n\n    def init_params(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal(m.weight, mode=\'fan_out\')\n                if m.bias is not None:\n                    init.constant(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant(m.weight, 1)\n                init.constant(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant(m.bias, 0)\n\n\n    def _make_stage(self, stage):\n        modules = OrderedDict()\n        stage_name = ""ShuffleUnit_Stage{}"".format(stage)\n        \n        # First ShuffleUnit in the stage\n        # 1. non-grouped 1x1 convolution (i.e. pointwise convolution)\n        #   is used in Stage 2. Group convolutions used everywhere else.\n        grouped_conv = stage > 2\n        \n        # 2. concatenation unit is always used.\n        first_module = ShuffleUnit(\n            self.stage_out_channels[stage-1],\n            self.stage_out_channels[stage],\n            groups=self.groups,\n            grouped_conv=grouped_conv,\n            combine=\'concat\'\n            )\n        modules[stage_name+""_0""] = first_module\n\n        # add more ShuffleUnits depending on pre-defined number of repeats\n        for i in range(self.stage_repeats[stage-2]):\n            name = stage_name + ""_{}"".format(i+1)\n            module = ShuffleUnit(\n                self.stage_out_channels[stage],\n                self.stage_out_channels[stage],\n                groups=self.groups,\n                grouped_conv=True,\n                combine=\'add\'\n                )\n            modules[name] = module\n\n        return nn.Sequential(modules)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool(x)\n\n        x = self.stage2(x)\n        x = self.stage3(x)\n        x = self.stage4(x)\n\n        # global average pooling layer\n        x = F.avg_pool2d(x, x.data.size()[-2:])\n        \n        # flatten for input to fully-connected layer\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return F.log_softmax(x, dim=1)\n\n\nif __name__ == ""__main__"":\n    """"""Testing\n    """"""\n    model = ShuffleNet()\n'"
tests.py,4,"b'import unittest\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport numpy as np\nfrom model import channel_shuffle, ShuffleNet, ShuffleUnit\n\n# helper methods to make torch Variables based on shape\ndef make_variable(shape):\n    return Variable(torch.FloatTensor(np.random.random(shape)))\n\ndef get_input(batchsize=1, num_channels=3, height=224, width=224):\n    shape = (batchsize, num_channels, height, width)\n    return make_variable(shape)\n\nclass TestShuffleUnit(unittest.TestCase):\n\n    def test_stage3_concat(self):\n        groups, in_channels, out_channels = 3, 240, 480\n        x = get_input(num_channels=in_channels, height=28, width=28)\n\n        unit = ShuffleUnit(\n            in_channels,\n            out_channels,\n            groups=groups,\n            grouped_conv=True,\n            combine=\'concat\'\n            )\n        out = unit.forward(x)\n\n        self.assertEqual(0, np.any(out.data.size() != \n            (1, out_channels, 14, 14)))\n        #print(""Passed Stage 3 Concat ShuffleUnit test."")\n\n\n    def test_stage2_add(self):\n        groups, in_channels, out_channels = 3, 240, 240\n        x = get_input(num_channels=in_channels, height=28, width=28)\n        unit = ShuffleUnit(\n            in_channels,\n            out_channels,\n            groups=groups,\n            grouped_conv=True,\n            combine=\'add\'\n            )\n        out = unit.forward(x)\n\n        self.assertEqual(0, np.any(out.data.size() != (1, 240, 28, 28)))\n        #print(""Passed Stage 2 Add ShuffleUnit test."")\n\n\n    def test_stage2_firstShuffleUnit(self):\n        groups = 3\n        in_channels = 24\n        out_channels = 240\n        x = get_input(num_channels=in_channels, height=56, width=56)\n        unit = ShuffleUnit(\n            in_channels,\n            out_channels,\n            groups=groups,\n            grouped_conv=False,\n            combine=\'concat\'\n            )\n\n        out = unit.forward(x)\n        self.assertEqual(0, np.any(out.data.size() != (1, 240, 28, 28)))\n\n\nclass TestChannelShuffle(unittest.TestCase):\n    def test(self):\n        \n        batchsize = 1\n        num_channels = 4\n        height = 2\n        width = 2\n        groups = 2\n        \n        # prepare inputs\n        shape = (batchsize, num_channels, height, width)\n        tensor = torch.FloatTensor(\n            np.arange(np.product(shape)).astype(np.float32).reshape(shape))\n        x = Variable(tensor)\n\n        # run function\n        out = channel_shuffle(x, groups).data.numpy()\n\n        # true answer\n        answer =  np.array([0,   1,\n                            2,   3,\n                            8,   9,\n                           10,  11,\n                            4,   5,\n                            6,   7,\n                           12,  13,\n                           14,  15]).reshape(shape)\n        self.assertEqual(0, np.any(out != answer))\n        #print(""Passed channel shuffle test."")\n\n\nclass TestShuffleNet(unittest.TestCase):\n    def test(self):\n        groups = [1, 2, 3, 4, 8]\n        # ImageNet image input size\n        x = get_input(batchsize=1, num_channels=3, width=224, height=224)\n        num_classes = 1000\n\n        for group in groups:\n            net = ShuffleNet(groups=group, num_classes=num_classes)\n            out = net.forward(x)\n            self.assertEqual(0, np.any(out.data.size() != (1, 1000)))\n\nif __name__ == ""__main__"":\n    unittest.main()'"
