file_path,api_count,code
build_face_dataset.py,0,"b'from __future__ import print_function\nfrom multiprocessing import Pool\nfrom PIL import Image\nimport numpy as np\nimport animeface\nimport sys\nimport os\n\n\n# im from PIL.Image.open, face_pos position object, margin\ndef faceCrop(im,face_pos,m):\n    """"""\n    m is the relative margin added to the face image\n    """"""\n    x,y,w,h = face_pos.x, face_pos.y, face_pos.width, face_pos.height\n    sizeX, sizeY = im.size\n    new_x, new_y = max(0,x-m*w), max(0,y-m*h)\n    new_w = w + 2*m*w if sizeX > (new_x + w + 2*m*w) else sizeX - new_x\n    new_h = h + 2*m*h if sizeY > (new_y + h + 2*m*h) else sizeY - new_y\n    new_x,new_y,new_w,new_h = int(new_x),int(new_y),int(new_w),int(new_h)\n    return im.crop((new_x,new_y,new_x+new_w,new_y+new_h))\n    \ndef min_resize_crop(im, min_side):\n    sizeX,sizeY = im.size\n    if sizeX > sizeY:\n        im = im.resize((min_side*sizeX/sizeY, min_side), Image.ANTIALIAS)\n    else:\n        im = im.resize((min_side, sizeY*min_side/sizeX), Image.ANTIALIAS)\n    return im.crop((0,0,min_side,min_side))\n    #return im\n\ndef load_detect(img_path):\n    """"""Read original image file, return the cropped face image in the size 96x96\n\n    Input: A string indicates the image path\n    Output: Detected face image in the size 96x96\n\n    Note that there might be multiple faces in one image, \n    the output crossponding to the face with highest probability\n    """"""\n    im = Image.open(img_path)\n    faces = animeface.detect(im)\n    prob_list = []\n    len_f = len(faces)\n    if len_f == 0:\n        return 0\n    for i in range(len_f):\n        prob_list.append(faces[i].likelihood)\n    prob_array = np.array(prob_list)\n    idx = np.argmax(prob_array)\n    face_pos = faces[idx].face.pos\n    im = faceCrop(im, face_pos, 0.5)\n    return min_resize_crop(im, 96)\n\ndef process_img(img_path):\n    """"""\n    The face images are stored in {${pwd} + faces} \n    """"""\n    tmp = img_path.split(\'/\')\n    cls_name,img_name = tmp[len(tmp)-2], tmp[len(tmp)-1]\n    new_dir_path = os.path.join(\'faces\',cls_name)\n    try:\n        os.makedirs(new_dir_path)\n    except OSError as err:\n        print(""OS error: {0}"".format(err))\n\n    new_img_path = os.path.join(new_dir_path, img_name)\n    if os.path.exists(new_img_path):\n        return 0\n    im = load_detect(img_path)\n    # no faces in this image\n    if im == 0:\n        return 0\n    im.save(new_img_path, \'JPEG\')\n\ndef try_process_img(img_path):\n    try:\n        process_img(img_path)\n    except:\n        e = sys.exc_info()[0]\n        print(\'Err: %s \\n\' % e)\n\n# multiprocessing version\ndef multi_construct_face_dataset(base_dir):\n    cls_dirs = [f for f in os.listdir(base_dir)]\n    imgs = []\n    for i in xrange(len(cls_dirs)):\n        sub_dir = os.path.join(base_dir, cls_dirs[i])\n        imgs_tmp = [os.path.join(sub_dir,f) for f in os.listdir(sub_dir) if f.endswith((\'.jpg\', \'.png\'))]\n        imgs = imgs + imgs_tmp\n    print(\'There are %d classes, %d images in total. \\n\' % (len(cls_dirs), len(imgs)))\n    pool = Pool(12) # 12 workers\n    pool.map(try_process_img, imgs)\n\n\nbase_dir = \'/home/jielei/gallery-dl/danbooru\'\nmulti_construct_face_dataset(base_dir)'"
main.py,20,"b'from __future__ import print_function\nimport os\nimport time\nimport random\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torch.autograd import Variable\n\n### load project files\nimport models\nfrom models import weights_init\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--dataRoot\', required=True, help=\'path to dataset\')\nparser.add_argument(\'--workers\', type=int, default=2, help=\'number of data loading workers\')\nparser.add_argument(\'--batchSize\', type=int, default=64, help=\'input batch size\')\nparser.add_argument(\'--imageSize\', type=int, default=64, help=\'the height / width of the input image to network\')\nparser.add_argument(\'--nz\', type=int, default=100, help=\'size of the latent z vector\')\nparser.add_argument(\'--ngf\', type=int, default=64)\nparser.add_argument(\'--ndf\', type=int, default=64)\nparser.add_argument(\'--niter\', type=int, default=25, help=\'number of epochs to train for\')\nparser.add_argument(\'--lr\', type=float, default=0.0002, help=\'learning rate, default=0.0002\')\nparser.add_argument(\'--beta1\', type=float, default=0.5, help=\'beta1 for adam. default=0.5\')\nparser.add_argument(\'--cuda\'  , action=\'store_true\', help=\'enables cuda\')\nparser.add_argument(\'--ngpu\'  , type=int, default=1, help=\'number of GPUs to use\')\nparser.add_argument(\'--netG\', default=\'\', help=""path to netG (to continue training)"")\nparser.add_argument(\'--netD\', default=\'\', help=""path to netD (to continue training)"")\nparser.add_argument(\'--outDir\', default=\'.\', help=\'folder to output images and model checkpoints\')\nparser.add_argument(\'--model\', type=int, default=1, help=\'1 for dcgan, 2 for illustrationGAN-like-GAN\')\nparser.add_argument(\'--d_labelSmooth\', type=float, default=0, help=\'for D, use soft label ""1-labelSmooth"" for real samples\')\nparser.add_argument(\'--n_extra_layers_d\', type=int, default=0, help=\'number of extra conv layers in D\')\nparser.add_argument(\'--n_extra_layers_g\', type=int, default=1, help=\'number of extra conv layers in G\')\nparser.add_argument(\'--binary\', action=\'store_true\', help=\'z from bernoulli distribution, with prob=0.5\')\n\n# simply prefer this way\n# arg_list = [\n#     \'--dataRoot\', \'/home/jielei/data/danbooru-faces\',\n#     \'--workers\', \'12\',\n#     \'--batchSize\', \'128\',\n#     \'--imageSize\', \'64\',\n#     \'--nz\', \'100\',\n#     \'--ngf\', \'64\',\n#     \'--ndf\', \'64\',\n#     \'--niter\', \'80\',\n#     \'--lr\', \'0.0002\',\n#     \'--beta1\', \'0.5\',\n#     \'--cuda\', \n#     \'--ngpu\', \'1\',\n#     \'--netG\', \'\',\n#     \'--netD\', \'\',\n#     \'--outDir\', \'./results\',\n#     \'--model\', \'1\',\n#     \'--d_labelSmooth\', \'0.1\', # 0.25 from imporved-GAN paper \n#     \'--n_extra_layers_d\', \'0\',\n#     \'--n_extra_layers_g\', \'1\', # in the sense that generator should be more powerful\n# ]\n\nargs = parser.parse_args()\n# opt = parser.parse_args(arg_list)\nprint(opt)\n\ntry:\n    os.makedirs(opt.outDir)\nexcept OSError:\n    pass\n\nopt.manualSeed = random.randint(1,10000) # fix seed, a scalar\nrandom.seed(opt.manualSeed)\ntorch.manual_seed(opt.manualSeed)\n\ncudnn.benchmark = True\n\nif torch.cuda.is_available() and not opt.cuda:\n    print(""WARNING: You have a CUDA device, so you should probably run with --cuda"")\n    \nnc = 3\nngpu = opt.ngpu\nnz = opt.nz\nngf = opt.ngf\nndf = opt.ndf\nn_extra_d = opt.n_extra_layers_d\nn_extra_g = opt.n_extra_layers_g\n\ndataset = dset.ImageFolder(\n    root=opt.dataRoot,\n    transform=transforms.Compose([\n            transforms.Scale(opt.imageSize),\n            # transforms.CenterCrop(opt.imageSize),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # bring images to (-1,1)\n        ])\n)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n                                         shuffle=True, num_workers=opt.workers)\n\n# load models \nif opt.model == 1:\n    netG = models._netG_1(ngpu, nz, nc, ngf, n_extra_g)\n    netD = models._netD_1(ngpu, nz, nc, ndf, n_extra_d)\nelif opt.model == 2:\n    netG = models._netG_2(ngpu, nz, nc, ngf)\n    netD = models._netD_2(ngpu, nz, nc, ndf)\n\nnetG.apply(weights_init)\nif opt.netG != \'\':\n    netG.load_state_dict(torch.load(opt.netG))\nprint(netG)\n\nnetD.apply(weights_init)\nif opt.netD != \'\':\n    netD.load_state_dict(torch.load(opt.netD))\nprint(netD)\n\ncriterion = nn.BCELoss()\ncriterion_MSE = nn.MSELoss()\n\ninput = torch.FloatTensor(opt.batchSize, 3, opt.imageSize, opt.imageSize)\nnoise = torch.FloatTensor(opt.batchSize, nz, 1, 1)\nif opt.binary:\n    bernoulli_prob = torch.FloatTensor(opt.batchSize, nz, 1, 1).fill_(0.5)\n    fixed_noise = torch.bernoulli(bernoulli_prob)\nelse:\n    fixed_noise = torch.FloatTensor(opt.batchSize, nz, 1, 1).normal_(0, 1)\nlabel = torch.FloatTensor(opt.batchSize)\nreal_label = 1\nfake_label = 0\n\nif opt.cuda:\n    netD.cuda()\n    netG.cuda()\n    criterion.cuda()\n    criterion_MSE.cuda()\n    input, label = input.cuda(), label.cuda()\n    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n    \ninput = Variable(input)\nlabel = Variable(label)\nnoise = Variable(noise)\nfixed_noise = Variable(fixed_noise)\n\n# setup optimizer\noptimizerD = optim.Adam(netD.parameters(), lr = opt.lr, betas = (opt.beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr = opt.lr, betas = (opt.beta1, 0.999))\n\nfor epoch in range(opt.niter):\n    for i, data in enumerate(dataloader, 0):\n        start_iter = time.time()\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        netD.zero_grad()\n        real_cpu, _ = data\n        batch_size = real_cpu.size(0)\n        input.data.resize_(real_cpu.size()).copy_(real_cpu)\n        label.data.resize_(batch_size).fill_(real_label - opt.d_labelSmooth) # use smooth label for discriminator\n\n        output = netD(input)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.data.mean()\n        # train with fake\n        noise.data.resize_(batch_size, nz, 1, 1)\n        if opt.binary:\n            bernoulli_prob.resize_(noise.data.size())\n            noise.data.copy_(2*(torch.bernoulli(bernoulli_prob)-0.5))\n        else:\n            noise.data.normal_(0, 1)\n        fake,z_prediction = netG(noise)\n        label.data.fill_(fake_label)\n        output = netD(fake.detach()) # add "".detach()"" to avoid backprop through G\n        errD_fake = criterion(output, label)\n        errD_fake.backward() # gradients for fake/real will be accumulated\n        D_G_z1 = output.data.mean()\n        errD = errD_real + errD_fake\n        optimizerD.step() # .step() can be called once the gradients are computed\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        label.data.fill_(real_label) # fake labels are real for generator cost\n        output = netD(fake)\n        errG = criterion(output, label)\n        errG.backward(retain_variables=True) # True if backward through the graph for the second time\n        if opt.model == 2: # with z predictor\n            errG_z = criterion_MSE(z_prediction, noise)\n            errG_z.backward()\n        D_G_z2 = output.data.mean()\n        optimizerG.step()\n        \n        end_iter = time.time()\n        print(\'[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f Elapsed %.2f s\'\n              % (epoch, opt.niter, i, len(dataloader),\n                 errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2, end_iter-start_iter))\n        if i % 100 == 0:\n            # the first 64 samples from the mini-batch are saved.\n            vutils.save_image(real_cpu[0:64,:,:,:],\n                    \'%s/real_samples.png\' % opt.outDir, nrow=8)\n            fake,_ = netG(fixed_noise)\n            vutils.save_image(fake.data[0:64,:,:,:],\n                    \'%s/fake_samples_epoch_%03d.png\' % (opt.outDir, epoch), nrow=8)\n    if epoch % 1 == 0:\n        # do checkpointing\n        torch.save(netG.state_dict(), \'%s/netG_epoch_%d.pth\' % (opt.outDir, epoch))\n        torch.save(netD.state_dict(), \'%s/netD_epoch_%d.pth\' % (opt.outDir, epoch))\n'"
models.py,7,"b""import torch\nimport torch.nn as nn\nimport torch.nn.parallel\n\n\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n\n# DCGAN model, fully convolutional architecture\nclass _netG_1(nn.Module):\n    def __init__(self, ngpu, nz, nc , ngf, n_extra_layers_g):\n        super(_netG_1, self).__init__()\n        self.ngpu = ngpu\n        #self.nz = nz\n        #self.nc = nc\n        #self.ngf = ngf\n        main = nn.Sequential(\n            # input is Z, going into a convolution\n            # state size. nz x 1 x 1\n            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ngf) x 32 x 32\n        )\n\n        # Extra layers\n        for t in range(n_extra_layers_g):\n            main.add_module('extra-layers-{0}.{1}.conv'.format(t, ngf),\n                            nn.Conv2d(ngf, ngf, 3, 1, 1, bias=False))\n            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, ngf),\n                            nn.BatchNorm2d(ngf))\n            main.add_module('extra-layers-{0}.{1}.relu'.format(t, ngf),\n                            nn.LeakyReLU(0.2, inplace=True))\n\n        main.add_module('final_layer.deconv', \n        \t             nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False)) # 5,3,1 for 96x96\n        main.add_module('final_layer.tanh', \n        \t             nn.Tanh())\n            # state size. (nc) x 96 x 96\n\n        self.main = main\n\n\n    def forward(self, input):\n        gpu_ids = None\n        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n            gpu_ids = range(self.ngpu)\n        return nn.parallel.data_parallel(self.main, input, gpu_ids), 0\n\nclass _netD_1(nn.Module):\n    def __init__(self, ngpu, nz, nc, ndf,  n_extra_layers_d):\n        super(_netD_1, self).__init__()\n        self.ngpu = ngpu\n        main = nn.Sequential(\n            # input is (nc) x 96 x 96\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), # 5,3,1 for 96x96\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n        )\n\n        # Extra layers\n        for t in range(n_extra_layers_d):\n            main.add_module('extra-layers-{0}.{1}.conv'.format(t, ndf * 8),\n                            nn.Conv2d(ndf * 8, ndf * 8, 3, 1, 1, bias=False))\n            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, ndf * 8),\n                            nn.BatchNorm2d(ndf * 8))\n            main.add_module('extra-layers-{0}.{1}.relu'.format(t, ndf * 8),\n                            nn.LeakyReLU(0.2, inplace=True))\n\n\n        main.add_module('final_layers.conv', nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False))\n        main.add_module('final_layers.sigmoid', nn.Sigmoid())\n        # state size. 1 x 1 x 1\n        self.main = main\n\n    def forward(self, input):\n        gpu_ids = None\n        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n            gpu_ids = range(self.ngpu)\n        output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n        return output.view(-1, 1)\n\n\n\n\nclass _netD_2(nn.Module):\n    def __init__(self, ngpu, nz, nc , ndf):\n        super(_netD_2, self).__init__()\n        self.ngpu = ngpu\n        self.convs = nn.Sequential(\n            # input is (nc) x 96 x 96\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*8) x 4 x 4\n            nn.Conv2d(ndf * 8, 1024, 4, 1, 0, bias=False),\n            nn.LeakyReLU(inplace=True),\n            nn.Dropout(0.5),\n            # state size. 1024 x 1 x 1\n        )\n        self.fcs = nn.Sequential(\n            nn.Linear(1024, 1024),\n            nn.LeakyReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 1),            \n            nn.Sigmoid()\n            )\n    def forward(self, input):\n        gpu_ids = None\n        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n            gpu_ids = range(self.ngpu)\n        output = nn.parallel.data_parallel(self.convs, input, gpu_ids)\n        output = self.fcs(output.view(-1,1024))\n        return output.view(-1, 1)\n\n# with z decoder and fc layers\nclass _netG_2(nn.Module):\n    def __init__(self, ngpu, nz, nc , ngf):\n        super(_netG_2, self).__init__()\n        self.ngpu = ngpu\n        self.nz = nz\n        self.fcs = nn.Sequential(\n            # input is Z, going into a convolution\n            # state size. nz x 1 x 1\n            nn.Linear(nz, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            )\n        \n        self.decode_fcs = nn.Sequential(\n            nn.Linear(1024, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(1024, nz),\n            )\n\n        self.convs = nn.Sequential(\n            # 1024x1x1\n            nn.ConvTranspose2d(1024, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(inplace=True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(inplace=True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(inplace=True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(inplace=True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 96 x 96\n        )\n    def forward(self, input):\n        input = self.fcs(input.view(-1,self.nz))\n        gpu_ids = None\n        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n            gpu_ids = range(self.ngpu)\n        z_prediction = self.decode_fcs(input)\n        input = input.view(-1,1024,1,1)\n        output = nn.parallel.data_parallel(self.convs, input, gpu_ids)\n        return output, z_prediction\n\n\n# DCGAN model with fc layers\nclass _netG_3(nn.Module):\n    def __init__(self, ngpu, nz, nc , ngf):\n        super(_netG_3, self).__init__()\n        self.ngpu = ngpu\n        self.fcs = nn.Sequential(\n            # input is Z, going into a convolution\n            # state size. nz x 1 x 1\n            nn.Linear(nz, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            )\n        self.convs = nn.Sequential(\n            # 1024x1x1\n            nn.ConvTranspose2d(1024, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(inplace=True),\n            # state size. (ngf*8) x 4 x 4\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(inplace=True),\n            # state size. (ngf*4) x 8 x 8\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(inplace=True),\n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(inplace=True),\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 96 x 96\n        )\n    def forward(self, input):\n        input = self.fcs(input.view(-1,nz))\n        gpu_ids = None\n        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n            gpu_ids = range(self.ngpu)\n        input = input.view(-1,1024,1,1)\n        return nn.parallel.data_parallel(self.convs, input, gpu_ids)\n"""
