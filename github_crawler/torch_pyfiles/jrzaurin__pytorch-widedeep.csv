file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python3\n# flake8: noqa\nimport os\nimport setuptools\n\npwd = os.path.dirname(__file__)\n\ndev_status = {\n    ""0.1"": ""Development Status :: 1 - Planning"",  # v0.1 - skeleton\n    ""0.2"": ""Development Status :: 2 - Pre-Alpha"",  # v0.2 - some basic functionality\n    ""0.3"": ""Development Status :: 3 - Alpha"",  # v0.3 - most functionality\n    ""0.4"": ""Development Status :: 4 - Beta"",  # v0.4 - most functionality + doc\n    ""1.0"": ""Development Status :: 5 - Production/Stable"",  # v1.0 - most functionality + doc + test  # noqa\n    ""2.0"": ""Development Status :: 6 - Mature"",  # v2.0 - new functionality?\n}\n\n\nwith open(os.path.join(pwd, ""VERSION"")) as f:\n    version = f.read().strip()\n    assert len(version.split(""."")) == 3, ""bad version spec""\n    majorminor = version.rsplit(""."", 1)[0]\n\n\n# with open(""README.md"", ""r"") as f:\n#     long_description = f.read()\n\nlong_description = """"""\npytorch-widedeep: Modular and flexible package to combine tabular data with text and\nimages using Wide and Deep models in Pytorch\n\nFor an introduction to the package and a quick start, go to:\n\n    https://github.com/jrzaurin/pytorch-widedeep\n\nFor a temporal documentation, go to:\n\n    https://github.com/jrzaurin/pytorch-widedeep/tree/master/docs\n\nYou can find the source code at:\n\n    https://github.com/jrzaurin/pytorch-widedeep/tree/master/pytorch_widedeep\n\n""""""\n\n# main setup kw args\nsetup_kwargs = {\n    ""name"": ""pytorch-widedeep"",\n    ""version"": version,\n    ""description"": ""Combine tabular data with text and images using Wide and Deep models in Pytorch"",\n    # ""long_description_content_type"": \'text/markdown\',\n    ""long_description"": long_description,\n    ""author"": ""Javier Rodriguez Zaurin"",\n    ""author_email"": ""jrzaurin@gmail.com"",\n    ""url"": ""https://github.com/jrzaurin/pytorch-widedeep"",\n    ""license"": ""MIT"",\n    ""install_requires"": [\n        ""pytest"",\n        ""pandas"",\n        ""numpy"",\n        ""scipy"",\n        ""scikit-learn"",\n        ""gensim"",\n        ""spacy"",\n        ""opencv-contrib-python"",\n        ""imutils"",\n        ""tqdm"",\n        ""torch"",\n        ""torchvision"",\n    ],\n    ""classifiers"": [\n        dev_status[majorminor],\n        ""Environment :: Other Environment"",\n        ""Framework :: Jupyter"",\n        ""Intended Audience :: Science/Research"",\n        ""License :: OSI Approved :: MIT License"",\n        ""Natural Language :: English"",\n        ""Operating System :: OS Independent"",\n        ""Programming Language :: Python"",\n        ""Topic :: Scientific/Engineering :: Artificial Intelligence"",\n    ],\n    ""zip_safe"": True,\n    ""packages"": setuptools.find_packages(exclude=[""test_*.py""]),\n}\n\n\nif __name__ == ""__main__"":\n    setuptools.setup(**setup_kwargs)\n'"
examples/adult_script.py,4,"b'import numpy as np\nimport pandas as pd\nimport torch\n\nfrom pytorch_widedeep.preprocessing import WidePreprocessor, DeepPreprocessor\nfrom pytorch_widedeep.models import Wide, DeepDense, WideDeep\nfrom pytorch_widedeep.optim import RAdam\nfrom pytorch_widedeep.initializers import KaimingNormal, XavierNormal\nfrom pytorch_widedeep.callbacks import LRHistory, EarlyStopping, ModelCheckpoint\nfrom pytorch_widedeep.metrics import BinaryAccuracy\n\nuse_cuda = torch.cuda.is_available()\n\nif __name__ == ""__main__"":\n\n    df = pd.read_csv(""data/adult/adult.csv.zip"")\n    df.columns = [c.replace(""-"", ""_"") for c in df.columns]\n    df[""age_buckets""] = pd.cut(\n        df.age, bins=[16, 25, 30, 35, 40, 45, 50, 55, 60, 91], labels=np.arange(9)\n    )\n    df[""income_label""] = (df[""income""].apply(lambda x: "">50K"" in x)).astype(int)\n    df.drop(""income"", axis=1, inplace=True)\n    df.head()\n\n    wide_cols = [\n        ""age_buckets"",\n        ""education"",\n        ""relationship"",\n        ""workclass"",\n        ""occupation"",\n        ""native_country"",\n        ""gender"",\n    ]\n    crossed_cols = [(""education"", ""occupation""), (""native_country"", ""occupation"")]\n    cat_embed_cols = [\n        (""education"", 10),\n        (""relationship"", 8),\n        (""workclass"", 10),\n        (""occupation"", 10),\n        (""native_country"", 10),\n    ]\n    continuous_cols = [""age"", ""hours_per_week""]\n    target = ""income_label""\n    target = df[target].values\n    prepare_wide = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n    X_wide = prepare_wide.fit_transform(df)\n    prepare_deep = DeepPreprocessor(\n        embed_cols=cat_embed_cols, continuous_cols=continuous_cols\n    )\n    X_deep = prepare_deep.fit_transform(df)\n    wide = Wide(wide_dim=X_wide.shape[1], output_dim=1)\n    deepdense = DeepDense(\n        hidden_layers=[64, 32],\n        dropout=[0.2, 0.2],\n        deep_column_idx=prepare_deep.deep_column_idx,\n        embed_input=prepare_deep.embeddings_input,\n        continuous_cols=continuous_cols,\n    )\n    model = WideDeep(wide=wide, deepdense=deepdense)\n\n    wide_opt = torch.optim.Adam(model.wide.parameters())\n    deep_opt = RAdam(model.deepdense.parameters())\n    wide_sch = torch.optim.lr_scheduler.StepLR(wide_opt, step_size=3)\n    deep_sch = torch.optim.lr_scheduler.StepLR(deep_opt, step_size=5)\n\n    optimizers = {""wide"": wide_opt, ""deepdense"": deep_opt}\n    schedulers = {""wide"": wide_sch, ""deepdense"": deep_sch}\n    initializers = {""wide"": KaimingNormal, ""deepdense"": XavierNormal}\n    callbacks = [\n        LRHistory(n_epochs=10),\n        EarlyStopping,\n        ModelCheckpoint(filepath=""model_weights/wd_out""),\n    ]\n    metrics = [BinaryAccuracy]\n\n    model.compile(\n        method=""binary"",\n        optimizers=optimizers,\n        lr_schedulers=schedulers,\n        initializers=initializers,\n        callbacks=callbacks,\n        metrics=metrics,\n    )\n\n    model.fit(\n        X_wide=X_wide,\n        X_deep=X_deep,\n        target=target,\n        n_epochs=10,\n        batch_size=256,\n        val_split=0.2,\n    )\n'"
examples/airbnb_data_preprocessing.py,0,"b'# coding: utf-8\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport os\nimport gender_guesser.detector as gender\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom functools import reduce\nfrom itertools import chain\nfrom collections import Counter\nfrom pathlib import Path\n\nwarnings.filterwarnings(""ignore"")\n\nDATA_PATH = Path(""data/airbnb"")\nfname = ""listings.csv.gz""\nif not os.path.exists(DATA_PATH):\n    os.makedirs(DATA_PATH)\n\ndf_original = pd.read_csv(DATA_PATH / fname)\nprint(df_original.shape)\ndf_original.head()\n\n# this is just subjective. One can choose some other columns\nkeep_cols = [\n    ""id"",\n    ""host_id"",\n    ""description"",\n    ""house_rules"",\n    ""host_name"",\n    ""host_listings_count"",\n    ""host_identity_verified"",\n    ""neighbourhood_cleansed"",\n    ""latitude"",\n    ""longitude"",\n    ""is_location_exact"",\n    ""property_type"",\n    ""room_type"",\n    ""accommodates"",\n    ""bathrooms"",\n    ""bedrooms"",\n    ""beds"",\n    ""amenities"",\n    ""price"",\n    ""security_deposit"",\n    ""cleaning_fee"",\n    ""guests_included"",\n    ""extra_people"",\n    ""minimum_nights"",\n    ""instant_bookable"",\n    ""cancellation_policy"",\n    ""reviews_per_month"",\n]\n\ndf = df_original[keep_cols]\ndf = df[~df.reviews_per_month.isna()]\ndf = df[~df.description.isna()]\ndf = df[~df.host_listings_count.isna()]\nprint(df.shape)\n\n# This is a preprocessing stage before preparing the data to be passed to WideDeep\n# Let\'s go ""column by column""\n\n# house rules\n#\n# I will simply include a binary column with 1/0 if the property has/has not\n# house rules.\ndf[""has_house_rules""] = df[""house_rules""]\ndf.has_house_rules.fillna(0, inplace=True)\ndf[""has_house_rules""][df.has_house_rules != 0] = 1\ndf.drop(""house_rules"", axis=1, inplace=True)\n\n# host_name\n#\n# I will use names to infer gender using `gender_guesser`\n\nhost_name = df.host_name.tolist()\nd = gender.Detector()\nhost_gender = [d.get_gender(n) for n in host_name]\nreplace_dict = {""mostly_male"": ""male"", ""mostly_female"": ""female"", ""andy"": ""unknown""}\nhost_gender = [replace_dict.get(item, item) for item in host_gender]\nCounter(host_gender)\ndf[""host_gender""] = host_gender\ndf.drop(""host_name"", axis=1, inplace=True)\ndf.head()\n\n# property_type, room_type, accommodates, bathrooms, bedrooms, beds and\n# guests_included, host_listings_count, minimum_nights\n#\n# Here some standard pre-processing\ndf.property_type.value_counts()\nreplace_prop_type = [\n    val\n    for val in df.property_type.unique().tolist()\n    if val not in [""Apartment"", ""House""]\n]\nreplace_prop_type = {k: ""other"" for k in replace_prop_type}\ndf.property_type.replace(replace_prop_type, inplace=True)\ndf[""property_type""] = df.property_type.apply(lambda x: ""_"".join(x.split("" "")).lower())\n\ndf.room_type.value_counts()\ndf[""room_type""] = df.room_type.apply(lambda x: ""_"".join(x.split("" "")).lower())\n\ndf[""bathrooms""][(df.bathrooms.isna()) & (df.room_type == ""private_room"")] = 0\ndf[""bathrooms""][(df.bathrooms.isna()) & (df.room_type == ""entire_home/apt"")] = 1\ndf.bedrooms.fillna(1, inplace=True)\ndf.beds.fillna(1, inplace=True)\n\n# Encode some as categorical\ncategorical_cut = [\n    (""accommodates"", 3),\n    (""guests_included"", 3),\n    (""minimum_nights"", 3),\n    (""host_listings_count"", 3),\n    (""bathrooms"", 1.5),\n    (""bedrooms"", 3),\n    (""beds"", 3),\n]\n\nfor col, cut in categorical_cut:\n    new_colname = col + ""_catg""\n    df[new_colname] = df[col].apply(lambda x: cut if x >= cut else x)\n    df[new_colname] = df[new_colname].round().astype(int)\n\n# Amenities\n#\n# I will just add a number of dummy columns with 1/0 if the property has/has\n# not that particular amenity\namenity_repls = (\n    (\'""\', """"),\n    (""{"", """"),\n    (""}"", """"),\n    ("" / "", ""_""),\n    (""/"", ""_""),\n    ("" "", ""_""),\n    (""(s)"", """"),\n)\n\namenities_raw = df.amenities.str.lower().tolist()\namenities = [\n    reduce(lambda a, kv: a.replace(*kv), amenity_repls, s).split("","")\n    for s in amenities_raw\n]\n\nall_amenities = list(chain(*amenities))\nall_amenities_count = Counter(all_amenities)\nall_amenities_count\n\n# having a look to the list we see that one amenity is empty and two are\n# ""translation missing:...""\nkeep_amenities = []\nfor k, v in all_amenities_count.items():\n    if k and ""missing"" not in k:\n        keep_amenities.append(k)\n\nfinal_amenities = [\n    [amenity for amenity in house_amenities if amenity in keep_amenities]\n    for house_amenities in amenities\n]\n\n# some properties have no amenities aparently\nfinal_amenities = [\n    [""no amenities""] if not amenity else amenity for amenity in final_amenities\n]\nfinal_amenities = [\n    [""amenity_"" + amenity for amenity in amenities] for amenities in final_amenities\n]\n\n# let\'s build the dummy df\ndf_list_of_amenities = pd.DataFrame({""groups"": final_amenities}, columns=[""groups""])\ns = df_list_of_amenities[""groups""]\n\nmlb = MultiLabelBinarizer()\n\ndf_amenities = pd.DataFrame(mlb.fit_transform(s), columns=mlb.classes_, index=df.index)\n\ndf.drop(""amenities"", axis=1, inplace=True)\ndf = pd.concat([df, df_amenities], axis=1)\ndf.head()\n\n# Price, security_deposit, cleaning_fee, extra_people\n\nmoney_columns = [""price"", ""security_deposit"", ""cleaning_fee"", ""extra_people""]\ntmp_money_df = df[money_columns].fillna(""$0"")\n\nmoney_repls = ((""$"", """"), ("","", """"))\nfor col in money_columns:\n    val_str = tmp_money_df[col].tolist()\n    val_num = [\n        float(st)\n        for st in [\n            reduce(lambda a, kv: a.replace(*kv), money_repls, s) for s in val_str\n        ]\n    ]\n    tmp_money_df[col] = val_num\n\nhigh_price, high_deposit, high_cleaning_fee, high_extra_people = 1000, 2000, 200, 100\n\nhigh_price_count = (tmp_money_df.price >= high_price).sum()\nhigh_deposit_count = (tmp_money_df.security_deposit >= high_deposit).sum()\nhigh_cleaning_fee_count = (tmp_money_df.cleaning_fee >= high_cleaning_fee).sum()\nhigh_extra_people_count = (tmp_money_df.extra_people >= high_extra_people).sum()\n\nprint(""properties with very high price: {}"".format(high_price_count))\nprint(""properties with very high security deposit: {}"".format(high_deposit_count))\nprint(""properties with very high cleaning fee: {}"".format(high_cleaning_fee_count))\nprint(""properties with very high extra people cost: {}"".format(high_extra_people_count))\n\n# We will now just concat and we will drop high values later one\ndf.drop(money_columns, axis=1, inplace=True)\ndf = pd.concat([df, tmp_money_df], axis=1)\ndf = df[\n    (df.price < high_price)\n    & (df.price != 0)\n    & (df.security_deposit < high_deposit)\n    & (df.cleaning_fee < high_cleaning_fee)\n    & (df.extra_people < high_extra_people)\n]\ndf.head()\nprint(df.shape)\n\n# let\'s make sure there are no nan left\nhas_nan = df.isnull().any(axis=0)\nhas_nan = [df.columns[i] for i in np.where(has_nan)[0]]\nif not has_nan:\n    print(""no NaN, all OK"")\n\n# Computing a proxi for yield\n\n# Yield is defined as price * occupancy rate. Occupancy rate can be calculated\n# by multiplying ((reviews / review rate) * average length of stay), where\n# review rate and average length of stay are normally taken as a factor based\n# in some model.  For example, in the San Francisco model a review rate of 0.5\n# is used to convert reviews to estimated bookings (i.e. we assume that only\n# half of the guests will leave a review). An average length of stay of 3\n# nights  multiplied by the estimated bookings over a period gives the\n# occupancy rate. Therefore, in the expression I have used below, if you want\n# to turn my implementation of \'yield\' into a ""proper"" one under the San\n# Francisco model assumptions simply multiply my yield by 6 (3 * (1/0.5)) or\n# by 72 (3 * 2 * 12) if you prefer per year.\n\ndf[""yield""] = (df[""price""] + df[""cleaning_fee""]) * (df[""reviews_per_month""])\ndf.drop([""price"", ""cleaning_fee"", ""reviews_per_month""], axis=1, inplace=True)\n# we will focus in cases with yield below 600 (we lose ~3% of the data).\n# No real reason for this, simply removing some ""outliers""\ndf = df[df[""yield""] <= 600]\ndf.to_csv(DATA_PATH / ""listings_processed.csv"", index=False)\nprint(""data preprocessed finished. Final shape: {}"".format(df.shape))\n'"
examples/airbnb_script.py,7,"b'import pandas as pd\nimport torch\n\nfrom torchvision.transforms import ToTensor, Normalize\n\nfrom pytorch_widedeep.preprocessing import (\n    WidePreprocessor,\n    DeepPreprocessor,\n    TextPreprocessor,\n    ImagePreprocessor,\n)\nfrom pytorch_widedeep.models import Wide, DeepDense, DeepText, DeepImage, WideDeep\nfrom pytorch_widedeep.initializers import KaimingNormal\nfrom pytorch_widedeep.callbacks import EarlyStopping, ModelCheckpoint\nfrom pytorch_widedeep.optim import RAdam\n\n\nuse_cuda = torch.cuda.is_available()\n\nif __name__ == ""__main__"":\n\n    df = pd.read_csv(""data/airbnb/airbnb_sample.csv"")\n\n    crossed_cols = ([""property_type"", ""room_type""],)\n    already_dummies = [c for c in df.columns if ""amenity"" in c] + [""has_house_rules""]\n    wide_cols = [\n        ""is_location_exact"",\n        ""property_type"",\n        ""room_type"",\n        ""host_gender"",\n        ""instant_bookable"",\n    ] + already_dummies\n    cat_embed_cols = [(c, 16) for c in df.columns if ""catg"" in c] + [\n        (""neighbourhood_cleansed"", 64),\n        (""cancellation_policy"", 16),\n    ]\n    continuous_cols = [""latitude"", ""longitude"", ""security_deposit"", ""extra_people""]\n    already_standard = [""latitude"", ""longitude""]\n    text_col = ""description""\n    word_vectors_path = ""data/glove.6B/glove.6B.100d.txt""\n    img_col = ""id""\n    img_path = ""data/airbnb/property_picture""\n    target = ""yield""\n\n    target = df[target].values\n\n    prepare_wide = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n    X_wide = prepare_wide.fit_transform(df)\n\n    prepare_deep = DeepPreprocessor(\n        embed_cols=cat_embed_cols, continuous_cols=continuous_cols\n    )\n    X_deep = prepare_deep.fit_transform(df)\n\n    text_processor = TextPreprocessor(\n        word_vectors_path=word_vectors_path, text_col=text_col\n    )\n    X_text = text_processor.fit_transform(df)\n\n    image_processor = ImagePreprocessor(img_col=img_col, img_path=img_path)\n    X_images = image_processor.fit_transform(df)\n\n    wide = Wide(wide_dim=X_wide.shape[1], output_dim=1)\n    deepdense = DeepDense(\n        hidden_layers=[64, 32],\n        dropout=[0.2, 0.2],\n        deep_column_idx=prepare_deep.deep_column_idx,\n        embed_input=prepare_deep.embeddings_input,\n        continuous_cols=continuous_cols,\n    )\n    deeptext = DeepText(\n        vocab_size=len(text_processor.vocab.itos),\n        hidden_dim=64,\n        n_layers=3,\n        rnn_dropout=0.5,\n        padding_idx=1,\n        embedding_matrix=text_processor.embedding_matrix,\n    )\n    deepimage = DeepImage(pretrained=True, head_layers=None)\n    model = WideDeep(\n        wide=wide, deepdense=deepdense, deeptext=deeptext, deepimage=deepimage\n    )\n\n    wide_opt = torch.optim.Adam(model.wide.parameters())\n    deep_opt = torch.optim.Adam(model.deepdense.parameters())\n    text_opt = RAdam(model.deeptext.parameters())\n    img_opt = RAdam(model.deepimage.parameters())\n\n    wide_sch = torch.optim.lr_scheduler.StepLR(wide_opt, step_size=5)\n    deep_sch = torch.optim.lr_scheduler.StepLR(deep_opt, step_size=3)\n    text_sch = torch.optim.lr_scheduler.StepLR(text_opt, step_size=5)\n    img_sch = torch.optim.lr_scheduler.StepLR(img_opt, step_size=3)\n\n    optimizers = {\n        ""wide"": wide_opt,\n        ""deepdense"": deep_opt,\n        ""deeptext"": text_opt,\n        ""deepimage"": img_opt,\n    }\n    schedulers = {\n        ""wide"": wide_sch,\n        ""deepdense"": deep_sch,\n        ""deeptext"": text_sch,\n        ""deepimage"": img_sch,\n    }\n    initializers = {\n        ""wide"": KaimingNormal,\n        ""deepdense"": KaimingNormal,\n        ""deeptext"": KaimingNormal,\n        ""deepimage"": KaimingNormal,\n    }\n    mean = [0.406, 0.456, 0.485]  # BGR\n    std = [0.225, 0.224, 0.229]  # BGR\n    transforms = [ToTensor, Normalize(mean=mean, std=std)]\n    callbacks = [EarlyStopping, ModelCheckpoint(filepath=""model_weights/wd_out.pt"")]\n\n    model.compile(\n        method=""regression"",\n        initializers=initializers,\n        optimizers=optimizers,\n        lr_schedulers=schedulers,\n        callbacks=callbacks,\n        transforms=transforms,\n    )\n\n    model.fit(\n        X_wide=X_wide,\n        X_deep=X_deep,\n        X_text=X_text,\n        X_img=X_images,\n        target=target,\n        n_epochs=1,\n        batch_size=32,\n        val_split=0.2,\n    )\n\n    # # With warm_up\n    # child = list(model.deepimage.children())[0]\n    # img_layers = list(child.backbone.children())[4:8] + [list(model.deepimage.children())[1]]\n    # img_layers = img_layers[::-1]\n\n    # model.fit(X_wide=X_wide, X_deep=X_deep, X_text=X_text, X_img=X_images,\n    #     target=target, n_epochs=1, batch_size=32, val_split=0.2, warm_up=True,\n    #     warm_epochs=1, warm_deepimage_gradual=True, warm_deepimage_layers=img_layers,\n    #     warm_deepimage_max_lr=0.01, warm_routine=\'howard\')\n'"
examples/airbnb_script_multiclass.py,1,"b'import numpy as np\nimport pandas as pd\nimport torch\n\nfrom pytorch_widedeep.preprocessing import WidePreprocessor, DeepPreprocessor\nfrom pytorch_widedeep.models import Wide, DeepDense, WideDeep\n\nfrom pytorch_widedeep.metrics import CategoricalAccuracy\n\nuse_cuda = torch.cuda.is_available()\n\nif __name__ == ""__main__"":\n\n    df = pd.read_csv(""data/airbnb/airbnb_sample.csv"")\n\n    crossed_cols = ([""property_type"", ""room_type""],)\n    already_dummies = [c for c in df.columns if ""amenity"" in c] + [""has_house_rules""]\n    wide_cols = [\n        ""is_location_exact"",\n        ""property_type"",\n        ""room_type"",\n        ""host_gender"",\n        ""instant_bookable"",\n    ] + already_dummies\n    cat_embed_cols = [(c, 16) for c in df.columns if ""catg"" in c] + [\n        (""neighbourhood_cleansed"", 64),\n        (""cancellation_policy"", 16),\n    ]\n    continuous_cols = [""latitude"", ""longitude"", ""security_deposit"", ""extra_people""]\n    already_standard = [""latitude"", ""longitude""]\n    df[""yield_cat""] = pd.cut(df[""yield""], bins=[0.2, 65, 163, 600], labels=[0, 1, 2])\n    df.drop(""yield"", axis=1, inplace=True)\n    target = ""yield_cat""\n\n    target = np.array(df[target].values)\n    prepare_wide = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n    X_wide = prepare_wide.fit_transform(df)\n\n    prepare_deep = DeepPreprocessor(\n        embed_cols=cat_embed_cols, continuous_cols=continuous_cols\n    )\n    X_deep = prepare_deep.fit_transform(df)\n    wide = Wide(wide_dim=X_wide.shape[1], output_dim=3)\n    deepdense = DeepDense(\n        hidden_layers=[64, 32],\n        dropout=[0.2, 0.2],\n        deep_column_idx=prepare_deep.deep_column_idx,\n        embed_input=prepare_deep.embeddings_input,\n        continuous_cols=continuous_cols,\n    )\n    model = WideDeep(wide=wide, deepdense=deepdense, output_dim=3)\n    model.compile(method=""multiclass"", metrics=[CategoricalAccuracy])\n\n    model.fit(\n        X_wide=X_wide,\n        X_deep=X_deep,\n        target=target,\n        n_epochs=1,\n        batch_size=32,\n        val_split=0.2,\n    )\n'"
examples/download_images.py,0,"b'import pandas as pd\nimport os\nimport pickle\n\nfrom tqdm import tqdm\nfrom urllib.request import urlretrieve\nfrom pathlib import Path\n\n\ndef download_images(df, out_path, id_col, img_col):\n    download_error = []\n    counter = 0\n    for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n        if counter < 1000:\n            img_path = str(out_path / ""."".join([str(row[id_col]), ""jpg""]))\n            if os.path.isfile(img_path):\n                continue\n            else:\n                try:\n                    urlretrieve(row[img_col], img_path)\n                    counter += 1\n                except:\n                    # print(""Error downloading host image {}"".format(row[id_col]))\n                    download_error.append(row[id_col])\n                    pass\n    pickle.dump(download_error, open(DATA_PATH / (id_col + ""_download_error.p""), ""wb""))\n\n\nif __name__ == ""__main__"":\n\n    DATA_PATH = Path(""data/airbnb"")\n    HOST_PATH = DATA_PATH / ""host_picture""\n    PROP_PATH = DATA_PATH / ""property_picture""\n\n    if not os.path.exists(DATA_PATH):\n        os.makedirs(DATA_PATH)\n    if not os.path.exists(HOST_PATH):\n        os.makedirs(HOST_PATH)\n    if not os.path.exists(PROP_PATH):\n        os.makedirs(PROP_PATH)\n\n    df_original = pd.read_csv(DATA_PATH / ""listings.csv.gz"")[\n        [""id"", ""host_id"", ""picture_url"", ""host_picture_url""]\n    ]\n    df_processed = pd.read_csv(DATA_PATH / ""listings_processed.csv"")[[""id"", ""host_id""]]\n    df = df_processed.merge(df_original, on=[""id"", ""host_id""])\n\n    df_host = df.groupby(""host_id"").first().reset_index()\n    download_images(df_host, HOST_PATH, id_col=""host_id"", img_col=""host_picture_url"")\n    download_images(df, PROP_PATH, id_col=""id"", img_col=""picture_url"")\n'"
pytorch_widedeep/__init__.py,0,b'##################################################\n# Store Library Version\n##################################################\nimport os.path\n\nfrom pytorch_widedeep.version import __version__\n\n##################################################\n# utils module accessible from pytorch-widedeep\n##################################################\nfrom .utils import dense_utils\nfrom .utils import text_utils\nfrom .utils import fastai_transforms\nfrom .utils import image_utils\n'
pytorch_widedeep/callbacks.py,2,"b'""""""\nCode here is mostly based on the code from the torchsample and Keras packages\n\nCREDIT TO THE TORCHSAMPLE AND KERAS TEAMS\n""""""\nimport numpy as np\nimport os\nimport datetime\nimport warnings\nimport torch\n\nfrom copy import deepcopy\nfrom .wdtypes import *\n\n\ndef _get_current_time():\n    return datetime.datetime.now().strftime(""%B %d, %Y - %I:%M%p"")\n\n\nclass CallbackContainer(object):\n    """"""\n    Container holding a list of callbacks.\n    """"""\n\n    def __init__(self, callbacks: Optional[List] = None, queue_length: int = 10):\n        instantiated_callbacks = []\n        if callbacks is not None:\n            for callback in callbacks:\n                if isinstance(callback, type):\n                    instantiated_callbacks.append(callback())\n                else:\n                    instantiated_callbacks.append(callback)\n        self.callbacks = [c for c in instantiated_callbacks]\n        self.queue_length = queue_length\n\n    def set_params(self, params):\n        for callback in self.callbacks:\n            callback.set_params(params)\n\n    def set_model(self, model: Any):\n        self.model = model\n        for callback in self.callbacks:\n            callback.set_model(model)\n\n    def on_epoch_begin(self, epoch: int, logs: Optional[Dict] = None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_begin(epoch, logs)\n\n    def on_epoch_end(self, epoch: int, logs: Optional[Dict] = None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_end(epoch, logs)\n\n    def on_batch_begin(self, batch: int, logs: Optional[Dict] = None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_batch_begin(batch, logs)\n\n    def on_batch_end(self, batch: int, logs: Optional[Dict] = None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_batch_end(batch, logs)\n\n    def on_train_begin(self, logs: Optional[Dict] = None):\n        logs = logs or {}\n        logs[""start_time""] = _get_current_time()\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)\n\n    def on_train_end(self, logs: Optional[Dict] = None):\n        logs = logs or {}\n        # logs[\'final_loss\'] = self.model.history.epoch_losses[-1],\n        # logs[\'best_loss\'] = min(self.model.history.epoch_losses),\n        # logs[\'stop_time\'] = _get_current_time()\n        for callback in self.callbacks:\n            callback.on_train_end(logs)\n\n\nclass Callback(object):\n    """"""\n    Abstract base class used to build new callbacks.\n    """"""\n\n    def __init__(self):\n        pass\n\n    def set_params(self, params):\n        self.params = params\n\n    def set_model(self, model: Any):\n        self.model = model\n\n    def on_epoch_begin(self, epoch: int, logs: Optional[Dict] = None):\n        pass\n\n    def on_epoch_end(self, epoch: int, logs: Optional[Dict] = None):\n        pass\n\n    def on_batch_begin(self, batch: int, logs: Optional[Dict] = None):\n        pass\n\n    def on_batch_end(self, batch: int, logs: Optional[Dict] = None):\n        pass\n\n    def on_train_begin(self, logs: Optional[Dict] = None):\n        pass\n\n    def on_train_end(self, logs: Optional[Dict] = None):\n        pass\n\n\nclass History(Callback):\n    """"""\n    Callback that records events into a `History` object.\n    """"""\n\n    def on_train_begin(self, logs: Optional[Dict] = None):\n        self.epoch: List[int] = []\n        self._history: Dict[str, List[float]] = {}\n\n    def on_epoch_begin(self, epoch: int, logs: Optional[Dict] = None):\n        # avoid mutation during epoch run\n        logs = deepcopy(logs) or {}\n        for k, v in logs.items():\n            self._history.setdefault(k, []).append(v)\n\n    def on_epoch_end(self, epoch: int, logs: Optional[Dict] = None):\n        logs = logs or {}\n        self.epoch.append(epoch)\n        for k, v in logs.items():\n            self._history.setdefault(k, []).append(v)\n\n\nclass LRHistory(Callback):\n    r""""""\n    Save the learning rates during training. Given the fact that non-cyclic\n    learning rates and cyclic learning rates are called at different stages\n    during training, the saving procedure is a bit convoluted.\n    """"""\n\n    def __init__(self, n_epochs):\n        super(LRHistory, self).__init__()\n        self.n_epochs = n_epochs\n\n    def on_epoch_begin(self, epoch: int, logs: Optional[Dict] = None):\n        if epoch == 0 and self.model.lr_scheduler:\n            # If is the first epoch and we use a scheduler, define the\n            # lr_history Dict and save\n            self.model.lr_history = {}\n            if self.model.lr_scheduler.__class__.__name__ == ""MultipleLRScheduler"":\n                # if we use multiple schedulers, we save the learning rate for\n                # each param_group of the optimizer.\n                for model_name, opt in self.model.optimizer._optimizers.items():\n                    if model_name in self.model.lr_scheduler._schedulers:\n                        for group_idx, group in enumerate(opt.param_groups):\n                            self.model.lr_history.setdefault(\n                                (""_"").join([""lr"", model_name, str(group_idx)]), []\n                            ).append(group[""lr""])\n            elif not self.model.cyclic:\n                # if we use one lr_scheduler and is not cyclic, save the\n                # learning rate for each param_group of the optimizer.\n                for group_idx, group in enumerate(self.model.optimizer.param_groups):\n                    self.model.lr_history.setdefault(\n                        (""_"").join([""lr"", str(group_idx)]), []\n                    ).append(group[""lr""])\n\n    def on_batch_end(self, batch: int, logs: Optional[Dict] = None):\n        if self.model.lr_scheduler:\n            if self.model.lr_scheduler.__class__.__name__ == ""MultipleLRScheduler"":\n                # if we use multiple schedulers, we save the learning rate for\n                # each param_group of the optimizer IF IS CYCLIC\n                for model_name, opt in self.model.optimizer._optimizers.items():\n                    if model_name in self.model.lr_scheduler._schedulers:\n                        if (\n                            ""cycl""\n                            in self.model.lr_scheduler._schedulers[\n                                model_name\n                            ].__class__.__name__.lower()\n                        ):\n                            for group_idx, group in enumerate(opt.param_groups):\n                                self.model.lr_history.setdefault(\n                                    (""_"").join([""lr"", model_name, str(group_idx)]), []\n                                ).append(group[""lr""])\n            elif self.model.cyclic:\n                # if we use one lr_scheduler and IS CYCLIC, save the\n                # learning rate for each param_group of the optimizer.\n                for group_idx, group in enumerate(self.model.optimizer.param_groups):\n                    self.model.lr_history.setdefault(\n                        (""_"").join([""lr"", str(group_idx)]), []\n                    ).append(group[""lr""])\n\n    def on_epoch_end(self, epoch: int, logs: Optional[Dict] = None):\n        if epoch != (self.n_epochs - 1) and self.model.lr_scheduler:\n            if self.model.lr_scheduler.__class__.__name__ == ""MultipleLRScheduler"":\n                # if we use multiple schedulers, we save the learning rate for\n                # each param_group of the optimizer IF IS NOT CYCLIC\n                for model_name, opt in self.model.optimizer._optimizers.items():\n                    if model_name in self.model.lr_scheduler._schedulers:\n                        if (\n                            ""cycl""\n                            not in self.model.lr_scheduler._schedulers[\n                                model_name\n                            ].__class__.__name__.lower()\n                        ):\n                            for group_idx, group in enumerate(opt.param_groups):\n                                self.model.lr_history.setdefault(\n                                    (""_"").join([""lr"", model_name, str(group_idx)]), []\n                                ).append(group[""lr""])\n            elif not self.model.cyclic:\n                # if we use one lr_scheduler and IS NOT CYCLIC, save the\n                # learning rate for each param_group of the optimizer.\n                for group_idx, group in enumerate(self.model.optimizer.param_groups):\n                    self.model.lr_history.setdefault(\n                        (""_"").join([""lr"", str(group_idx)]), []\n                    ).append(group[""lr""])\n\n\nclass ModelCheckpoint(Callback):\n    r""""""\n    Save the model after every epoch. This class is almost identical to the\n    corresponding keras class. Therefore, credit to the Keras Team.\n\n    Parameters\n    ----------\n    filepath: Str,\n        Full path to save the output weights. It must contain only the root of\n        the filenames. Epoch number and \'.pt\' extension (for pytorch) will be\n        added.\n        e.g. filepath=""path/to/output_weights/weights_out""\n        And the saved files in that directory will be named\n        weights_out_1.pt\n        weights_out_2.pt\n        ...\n    monitor: Str, default=\'val_loss\'\n        quantity to monitor\n    verbose:Int, default=0,\n    save_best_only: Boolean, default=False,\n        the latest best model according to the quantity monitored will not be\n        overwritten.\n    mode: Str, default=\'auto\',\n        If \'save_best_only=True\', the decision to overwrite the current save\n        file is made based on either the maximization or the minimization of\n        the monitored quantity. For \'val_acc\', this should be \'max\', for\n        \'val_loss\' this should be \'min\', etc. In \'auto\' mode, the direction is\n        automatically inferred from the name of the monitored quantity.\n    period: Int, default=1,\n        Interval (number of epochs) between checkpoints.\n    max_save:Int, default=-1\n        Max number of outputs to save. If -1 will save all outputs\n    """"""\n\n    def __init__(\n        self,\n        filepath: str,\n        monitor: str = ""val_loss"",\n        verbose: int = 0,\n        save_best_only: bool = False,\n        mode: str = ""auto"",\n        period: int = 1,\n        max_save: int = -1,\n    ):\n        super(ModelCheckpoint, self).__init__()\n        self.monitor = monitor\n        self.verbose = verbose\n        self.filepath = filepath\n        self.save_best_only = save_best_only\n        self.period = period\n        self.epochs_since_last_save = 0\n        self.max_save = max_save\n\n        root_dir = (""/"").join(filepath.split(""/"")[:-1])\n        if not os.path.exists(root_dir):\n            os.makedirs(root_dir)\n\n        if self.max_save > 0:\n            self.old_files: List[str] = []\n\n        if mode not in [""auto"", ""min"", ""max""]:\n            warnings.warn(\n                ""ModelCheckpoint mode %s is unknown, ""\n                ""fallback to auto mode."" % (mode),\n                RuntimeWarning,\n            )\n            mode = ""auto""\n        if mode == ""min"":\n            self.monitor_op = np.less\n            self.best = np.Inf\n        elif mode == ""max"":\n            self.monitor_op = np.greater\n            self.best = -np.Inf\n        else:\n            if ""acc"" in self.monitor or self.monitor.startswith(""fmeasure""):\n                self.monitor_op = np.greater\n                self.best = -np.Inf\n            else:\n                self.monitor_op = np.less\n                self.best = np.Inf\n\n    def on_epoch_end(self, epoch: int, logs: Optional[Dict] = None):\n        logs = logs or {}\n        self.epochs_since_last_save += 1\n        if self.epochs_since_last_save >= self.period:\n            self.epochs_since_last_save = 0\n            filepath = ""{}_{}.p"".format(self.filepath, epoch + 1)\n            if self.save_best_only:\n                current = logs.get(self.monitor)\n                if current is None:\n                    warnings.warn(\n                        ""Can save best model only with %s available, ""\n                        ""skipping."" % (self.monitor),\n                        RuntimeWarning,\n                    )\n                else:\n                    if self.monitor_op(current, self.best):\n                        if self.verbose > 0:\n                            print(\n                                ""\\nEpoch %05d: %s improved from %0.5f to %0.5f,""\n                                "" saving model to %s""\n                                % (\n                                    epoch + 1,\n                                    self.monitor,\n                                    self.best,\n                                    current,\n                                    filepath,\n                                )\n                            )\n                        self.best = current\n                        torch.save(self.model.state_dict(), filepath)\n                        if self.max_save > 0:\n                            if len(self.old_files) == self.max_save:\n                                try:\n                                    os.remove(self.old_files[0])\n                                except:\n                                    pass\n                                self.old_files = self.old_files[1:]\n                            self.old_files.append(filepath)\n                    else:\n                        if self.verbose > 0:\n                            print(\n                                ""\\nEpoch %05d: %s did not improve from %0.5f""\n                                % (epoch + 1, self.monitor, self.best)\n                            )\n            else:\n                if self.verbose > 0:\n                    print(""\\nEpoch %05d: saving model to %s"" % (epoch + 1, filepath))\n                torch.save(self.model.state_dict(), filepath)\n                if self.max_save > 0:\n                    if len(self.old_files) == self.max_save:\n                        try:\n                            os.remove(self.old_files[0])\n                        except:\n                            pass\n                        self.old_files = self.old_files[1:]\n                    self.old_files.append(filepath)\n\n\nclass EarlyStopping(Callback):\n    r""""""\n    Stop training when a monitored quantity has stopped improving. This class\n    is almost identical to the corresponding keras class. Therefore, credit to\n    the Keras Team.\n\n    # Arguments\n        monitor: Str, default=\'val_loss\'.\n            Quantity to be monitored.\n        min_delta: Float, default=0.\n            minimum change in the monitored quantity to qualify as an\n            improvement, i.e. an absolute change of less than min_delta, will\n            count as no improvement.\n        patience: Int, default=10.\n            Number of epochs that produced the monitored quantity with no\n            improvement after which training will be stopped.\n        verbose: Int.\n            verbosity mode.\n        mode: Str, default=\'auto\'\n            one of {auto, min, max}. In `min` mode, training will stop when\n            the quantity monitored has stopped decreasing; in `max` mode it\n            will stop when the quantity monitored has stopped increasing; in\n            `auto` mode, the direction is automatically inferred from the name\n            of the monitored quantity.\n        baseline: Float, Optional. default=None.\n            Baseline value for the monitored quantity to reach. Training will\n            stop if the model doesn\'t show improvement over the baseline.\n        restore_best_weights: Boolean, default=None\n            Whether to restore model weights from the epoch with the best\n            value of the monitored quantity. If False, the model weights\n            obtained at the last step of training are used.\n    """"""\n\n    def __init__(\n        self,\n        monitor: str = ""val_loss"",\n        min_delta: float = 0.0,\n        patience: int = 10,\n        verbose: int = 0,\n        mode: str = ""auto"",\n        baseline: Optional[float] = None,\n        restore_best_weights: bool = False,\n    ):\n\n        super(EarlyStopping, self).__init__()\n\n        self.monitor = monitor\n        self.baseline = baseline\n        self.patience = patience\n        self.verbose = verbose\n        self.min_delta = min_delta\n        self.wait = 0\n        self.stopped_epoch = 0\n        self.restore_best_weights = restore_best_weights\n        self.state_dict = None\n\n        if mode not in [""auto"", ""min"", ""max""]:\n            warnings.warn(\n                ""EarlyStopping mode %s is unknown, "" ""fallback to auto mode."" % mode,\n                RuntimeWarning,\n            )\n            mode = ""auto""\n\n        if mode == ""min"":\n            self.monitor_op = np.less\n        elif mode == ""max"":\n            self.monitor_op = np.greater\n        else:\n            if ""acc"" in self.monitor:\n                self.monitor_op = np.greater\n            else:\n                self.monitor_op = np.less\n\n        if self.monitor_op == np.greater:\n            self.min_delta *= 1\n        else:\n            self.min_delta *= -1\n\n    def on_train_begin(self, logs: Optional[Dict] = None):\n        # Allow instances to be re-used\n        self.wait = 0\n        self.stopped_epoch = 0\n        if self.baseline is not None:\n            self.best = self.baseline\n        else:\n            self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n\n    def on_epoch_end(self, epoch: int, logs: Optional[Dict] = None):\n        current = self.get_monitor_value(logs)\n        if current is None:\n            return\n\n        if self.monitor_op(current - self.min_delta, self.best):\n            self.best = current\n            self.wait = 0\n            if self.restore_best_weights:\n                self.state_dict = self.model.state_dict()\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                self.stopped_epoch = epoch\n                self.model.early_stop = True\n                if self.restore_best_weights:\n                    if self.verbose > 0:\n                        print(\n                            ""Restoring model weights from the end of "" ""the best epoch""\n                        )\n                    self.model.load_state_dict(self.state_dict)\n\n    def on_train_end(self, logs: Optional[Dict] = None):\n        if self.stopped_epoch > 0 and self.verbose > 0:\n            print(""Epoch %05d: early stopping"" % (self.stopped_epoch + 1))\n\n    def get_monitor_value(self, logs):\n        monitor_value = logs.get(self.monitor)\n        if monitor_value is None:\n            warnings.warn(\n                ""Early stopping conditioned on metric `%s` ""\n                ""which is not available. Available metrics are: %s""\n                % (self.monitor, "","".join(list(logs.keys()))),\n                RuntimeWarning,\n            )\n        return monitor_value\n'"
pytorch_widedeep/initializers.py,0,"b'import re\nimport warnings\n\nfrom torch import nn\nfrom .wdtypes import *\n\n\nclass Initializer(object):\n    def __call__(self, model: nn.Module):\n        raise NotImplementedError(""Initializer must implement this method"")\n\n\nclass MultipleInitializer(object):\n    def __init__(self, initializers: Dict[str, Initializer], verbose=True):\n\n        self.verbose = verbose\n        instantiated_initializers = {}\n        for model_name, initializer in initializers.items():\n            if isinstance(initializer, type):\n                instantiated_initializers[model_name] = initializer()\n            else:\n                instantiated_initializers[model_name] = initializer\n        self._initializers = instantiated_initializers\n\n    def apply(self, model: nn.Module):\n        for name, child in model.named_children():\n            try:\n                self._initializers[name](child)\n            except:\n                if self.verbose:\n                    warnings.warn(""No initializer found for {}"".format(name))\n\n\nclass Normal(Initializer):\n    def __init__(self, mean=0.0, std=1.0, bias=False, pattern="".""):\n        self.mean = mean\n        self.std = std\n        self.bias = bias\n        self.pattern = pattern\n        super(Normal, self).__init__()\n\n    def __call__(self, submodel: nn.Module):\n        for n, p in submodel.named_parameters():\n            if re.search(self.pattern, n):\n                if self.bias and (""bias"" in n):\n                    nn.init.normal_(p, mean=self.mean, std=self.std)\n                elif ""bias"" in n:\n                    pass\n                elif p.requires_grad:\n                    nn.init.normal_(p, mean=self.mean, std=self.std)\n\n\nclass Uniform(Initializer):\n    def __init__(self, a=0, b=1, bias=False, pattern="".""):\n        self.a = a\n        self.b = b\n        self.bias = bias\n        self.pattern = pattern\n        super(Uniform, self).__init__()\n\n    def __call__(self, submodel: nn.Module):\n        for n, p in submodel.named_parameters():\n            if re.search(self.pattern, n):\n                if self.bias and (""bias"" in n):\n                    nn.init.uniform_(p, a=self.a, b=self.b)\n                elif ""bias"" in n:\n                    pass\n                elif p.requires_grad:\n                    nn.init.uniform_(p, a=self.a, b=self.b)\n\n\nclass ConstantInitializer(Initializer):\n    def __init__(self, value, bias=False, pattern="".""):\n\n        self.bias = bias\n        self.value = value\n        self.pattern = pattern\n        super(ConstantInitializer, self).__init__()\n\n    def __call__(self, submodel: nn.Module):\n        for n, p in submodel.named_parameters():\n            if re.search(self.pattern, n):\n                if self.bias and (""bias"" in n):\n                    nn.init.constant_(p, val=self.value)\n                elif ""bias"" in n:\n                    pass\n                elif p.requires_grad:\n                    nn.init.constant_(p, val=self.value)\n\n\nclass XavierUniform(Initializer):\n    def __init__(self, gain=1, pattern="".""):\n        self.gain = gain\n        self.pattern = pattern\n        super(XavierUniform, self).__init__()\n\n    def __call__(self, submodel: nn.Module):\n        for n, p in submodel.named_parameters():\n            if re.search(self.pattern, n):\n                if ""bias"" in n:\n                    nn.init.constant_(p, val=0)\n                elif p.requires_grad:\n                    try:\n                        nn.init.xavier_uniform_(p, gain=self.gain)\n                    except:\n                        pass\n\n\nclass XavierNormal(Initializer):\n    def __init__(self, gain=1, pattern="".""):\n        self.gain = gain\n        self.pattern = pattern\n        super(XavierNormal, self).__init__()\n\n    def __call__(self, submodel: nn.Module):\n        for n, p in submodel.named_parameters():\n            if re.search(self.pattern, n):\n                if ""bias"" in n:\n                    nn.init.constant_(p, val=0)\n                elif p.requires_grad:\n                    try:\n                        nn.init.xavier_normal_(p, gain=self.gain)\n                    except:\n                        pass\n\n\nclass KaimingUniform(Initializer):\n    def __init__(self, a=0, mode=""fan_in"", nonlinearity=""leaky_relu"", pattern="".""):\n        self.a = a\n        self.mode = mode\n        self.nonlinearity = nonlinearity\n        self.pattern = pattern\n        super(KaimingUniform, self).__init__()\n\n    def __call__(self, submodel: nn.Module):\n        for n, p in submodel.named_parameters():\n            if re.search(self.pattern, n):\n                if ""bias"" in n:\n                    nn.init.constant_(p, val=0)\n                elif p.requires_grad:\n                    try:\n                        nn.init.kaiming_normal_(\n                            p, a=self.a, mode=self.mode, nonlinearity=self.nonlinearity\n                        )\n                    except:\n                        pass\n\n\nclass KaimingNormal(Initializer):\n    def __init__(self, a=0, mode=""fan_in"", nonlinearity=""leaky_relu"", pattern="".""):\n        self.a = a\n        self.mode = mode\n        self.nonlinearity = nonlinearity\n        self.pattern = pattern\n        super(KaimingNormal, self).__init__()\n\n    def __call__(self, submodel: nn.Module):\n        for n, p in submodel.named_parameters():\n            if re.search(self.pattern, n):\n                if ""bias"" in n:\n                    nn.init.constant_(p, val=0)\n                elif p.requires_grad:\n                    try:\n                        nn.init.kaiming_normal_(\n                            p, a=self.a, mode=self.mode, nonlinearity=self.nonlinearity\n                        )\n                    except:\n                        pass\n\n\nclass Orthogonal(Initializer):\n    def __init__(self, gain=1, pattern="".""):\n        self.gain = gain\n        self.pattern = pattern\n        super(Orthogonal, self).__init__()\n\n    def __call__(self, submodel: nn.Module):\n        for n, p in submodel.named_parameters():\n            if re.search(self.pattern, n):\n                if ""bias"" in n:\n                    nn.init.constant_(p, val=0)\n                elif p.requires_grad:\n                    try:\n                        nn.init.orthogonal_(p, gain=self.gain)\n                    except:\n                        pass\n'"
pytorch_widedeep/losses.py,5,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom .wdtypes import *\n\n\nuse_cuda = torch.cuda.is_available()\n\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha: float = 0.25, gamma: float = 1.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def get_weight(self, x: Tensor, t: Tensor) -> Tensor:\n        p = x.sigmoid()\n        pt = p * t + (1 - p) * (1 - t)  # type: ignore\n        w = self.alpha * t + (1 - self.alpha) * (1 - t)  # type: ignore\n        return (w * (1 - pt).pow(self.gamma)).detach()  # type: ignore\n\n    def forward(self, input: Tensor, target: Tensor) -> Tensor:  # type: ignore\n        if input.size(1) == 1:\n            input = torch.cat([1 - input, input], axis=1)  # type: ignore\n            num_class = 2\n        else:\n            num_class = input.size(1)\n        binary_target = torch.eye(num_class)[target.long()]\n        if use_cuda:\n            binary_target = binary_target.cuda()\n        binary_target = binary_target.contiguous()\n        weight = self.get_weight(input, binary_target)\n        return F.binary_cross_entropy_with_logits(\n            input, binary_target, weight, reduction=""mean""\n        )\n'"
pytorch_widedeep/metrics.py,0,"b'import numpy as np\n\nfrom .callbacks import Callback\nfrom .wdtypes import *\n\n\nclass Metric(object):\n    def __init__(self):\n        self._name = """"\n\n    def reset(self):\n        raise NotImplementedError(""Custom Metrics must implement this function"")\n\n    def __call__(self, y_pred: Tensor, y_true: Tensor):\n        raise NotImplementedError(""Custom Metrics must implement this function"")\n\n\nclass MultipleMetrics(object):\n    def __init__(self, metrics: List[Metric], prefix: str = """"):\n\n        instantiated_metrics = []\n        for metric in metrics:\n            if isinstance(metric, type):\n                instantiated_metrics.append(metric())\n            else:\n                instantiated_metrics.append(metric)\n        self._metrics = instantiated_metrics\n        self.prefix = prefix\n\n    def reset(self):\n        for metric in self._metrics:\n            metric.reset()\n\n    def __call__(self, y_pred: Tensor, y_true: Tensor) -> Dict:\n        logs = {}\n        for metric in self._metrics:\n            logs[self.prefix + metric._name] = metric(y_pred, y_true)\n        return logs\n\n\nclass MetricCallback(Callback):\n    def __init__(self, container: MultipleMetrics):\n        self.container = container\n\n    def on_epoch_begin(self, epoch: int, logs: Optional[Dict] = None):\n        self.container.reset()\n\n\nclass CategoricalAccuracy(Metric):\n    def __init__(self, top_k=1):\n        self.top_k = top_k\n        self.correct_count = 0\n        self.total_count = 0\n\n        self._name = ""acc""\n\n    def reset(self):\n        self.correct_count = 0\n        self.total_count = 0\n\n    def __call__(self, y_pred: Tensor, y_true: Tensor) -> np.ndarray:\n        top_k = y_pred.topk(self.top_k, 1)[1]\n        true_k = y_true.view(len(y_true), 1).expand_as(top_k)  # type: ignore\n        self.correct_count += top_k.eq(true_k).float().sum().item()\n        self.total_count += len(y_pred)  # type: ignore\n        accuracy = float(self.correct_count) / float(self.total_count)\n        return np.round(accuracy, 4)\n\n\nclass BinaryAccuracy(Metric):\n    def __init__(self):\n        self.correct_count = 0\n        self.total_count = 0\n\n        self._name = ""acc""\n\n    def reset(self):\n        self.correct_count = 0\n        self.total_count = 0\n\n    def __call__(self, y_pred: Tensor, y_true: Tensor) -> np.ndarray:\n        y_pred_round = y_pred.round()\n        self.correct_count += y_pred_round.eq(y_true.view(-1, 1)).float().sum().item()\n        self.total_count += len(y_pred)  # type: ignore\n        accuracy = float(self.correct_count) / float(self.total_count)\n        return np.round(accuracy, 4)\n'"
pytorch_widedeep/version.py,0,"b'__version__ = ""0.3.7""\n'"
pytorch_widedeep/wdtypes.py,4,"b'import sys\n\nfrom torch.nn import Module\nfrom torch import Tensor\nfrom torchvision.transforms import (\n    CenterCrop,\n    ColorJitter,\n    Compose,\n    FiveCrop,\n    Grayscale,\n    Lambda,\n    LinearTransformation,\n    Normalize,\n    Pad,\n    RandomAffine,\n    RandomApply,\n    RandomChoice,\n    RandomCrop,\n    RandomGrayscale,\n    RandomHorizontalFlip,\n    RandomOrder,\n    RandomResizedCrop,\n    RandomRotation,\n    RandomSizedCrop,\n    RandomVerticalFlip,\n    Resize,\n    Scale,\n    TenCrop,\n    ToPILImage,\n    ToTensor,\n)\nfrom torch.optim.optimizer import Optimizer\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom pathlib import PosixPath\nfrom typing import (\n    List,\n    Any,\n    Union,\n    Dict,\n    Callable,\n    Optional,\n    Tuple,\n    Generator,\n    Collection,\n    Iterable,\n    Match,\n    Iterator,\n)\nfrom scipy.sparse.csr import csr_matrix as sparse_matrix\nfrom types import SimpleNamespace\n\n\nListRules = Collection[Callable[[str], str]]\nTokens = Collection[Collection[str]]\nTransforms = Union[\n    CenterCrop,\n    ColorJitter,\n    Compose,\n    FiveCrop,\n    Grayscale,\n    Lambda,\n    LinearTransformation,\n    Normalize,\n    Pad,\n    RandomAffine,\n    RandomApply,\n    RandomChoice,\n    RandomCrop,\n    RandomGrayscale,\n    RandomHorizontalFlip,\n    RandomOrder,\n    RandomResizedCrop,\n    RandomRotation,\n    RandomSizedCrop,\n    RandomVerticalFlip,\n    Resize,\n    Scale,\n    TenCrop,\n    ToPILImage,\n    ToTensor,\n]\nLRScheduler = _LRScheduler\nModelParams = Generator[Tensor, Tensor, Tensor]\n'"
pytorch_widedeep/models/__init__.py,0,b'from .wide import Wide\nfrom .deep_dense import DeepDense\nfrom .deep_text import DeepText\nfrom .deep_image import DeepImage\n\nfrom .wide_deep import WideDeep\n'
pytorch_widedeep/models/_multiple_lr_scheduler.py,0,"b'from ..wdtypes import *\n\n\nclass MultipleLRScheduler(object):\n    def __init__(self, scheds: Dict[str, LRScheduler]):\n        self._schedulers = scheds\n\n    def step(self):\n        for _, sc in self._schedulers.items():\n            sc.step()\n'"
pytorch_widedeep/models/_multiple_optimizer.py,0,"b'from ..wdtypes import *\n\n\nclass MultipleOptimizer(object):\n    def __init__(self, opts: Dict[str, Optimizer]):\n        self._optimizers = opts\n\n    def zero_grad(self):\n        for _, op in self._optimizers.items():\n            op.zero_grad()\n\n    def step(self):\n        for _, op in self._optimizers.items():\n            op.step()\n'"
pytorch_widedeep/models/_multiple_transforms.py,0,"b'from torchvision.transforms import Compose\n\nfrom ..wdtypes import *\n\n\nclass MultipleTransforms(object):\n    def __init__(self, transforms: List[Transforms]):\n\n        instantiated_transforms = []\n        for transform in transforms:\n            if isinstance(transform, type):\n                instantiated_transforms.append(transform())\n            else:\n                instantiated_transforms.append(transform)\n        self._transforms = instantiated_transforms\n\n    def __call__(self):\n        return Compose(self._transforms)\n'"
pytorch_widedeep/models/_warmup.py,7,"b'import numpy as np\nimport torch\n\nfrom ..metrics import Metric, MultipleMetrics\nfrom ..wdtypes import *\n\nfrom tqdm import trange\nfrom torch import nn\n\nuse_cuda = torch.cuda.is_available()\n\n\nclass WarmUp(object):\n    r""""""\n    \'Warm up\' methods to be applied to the individual models before the joined\n    training. There are 3 warm up routines available:\n    1) Warm up all trainable layers at once\n    2) Gradual warm up inspired by the work of Felbo et al., 2017\n    3) Gradual warm up inspired by the work of Howard & Ruder 2018\n\n    The structure of the code in this class is designed to be instantiated within\n    the class WideDeep. This is not ideal, but represents a compromise towards\n    implementing a \'warm up\' functionality for the current overall structure of\n    the package without having to re-structure most of the existing code.\n\n    Parameters\n    ----------\n    activation_fn: Any\n       any function with the same strucure as \'_activation_fn\' in the main class\n       WideDeep at pytorch_widedeep.models.wide_deep\n    loss_fn: Any\n       any function with the same strucure as \'_loss_fn\' in the main class WideDeep\n       at pytorch_widedeep.models.wide_deep\n    metric: Metric\n       object of class Metric (see Metric in pytorch_widedeep.metrics)\n    method: str\n       one of \'binary\', \'regression\' or \'multiclass\'\n    verbose: Boolean\n    """"""\n\n    def __init__(\n        self,\n        activation_fn: Any,\n        loss_fn: Any,\n        metric: Union[Metric, MultipleMetrics],\n        method: str,\n        verbose: int,\n    ):\n        super(WarmUp, self).__init__()\n        self.activation_fn = activation_fn\n        self.loss_fn = loss_fn\n        self.metric = metric\n        self.method = method\n        self.verbose = verbose\n\n    def warm_all(\n        self,\n        model: nn.Module,\n        model_name: str,\n        loader: DataLoader,\n        n_epochs: int,\n        max_lr: float,\n    ):\n        r""""""\n        Warm up all trainable layers in a model using a one cyclic learning rate\n        with a triangular pattern. This is refereed as Slanted Triangular learing\n        rate in Jeremy Howard & Sebastian Ruder 2018\n        (https://arxiv.org/abs/1801.06146). The cycle is described as follows:\n        1-The learning rate will gradually increase for 10% of the training steps\n            from max_lr/10 to max_lr.\n        2-It will then gradually decrease to max_lr/10 for the remaining 90% of the\n            steps.\n        The optimizer used in the process is AdamW\n\n        Parameters:\n        ----------\n        model: nn.Module\n            nn.Module object containing one the WideDeep model components (wide,\n            deepdense, deeptext or deepimage)\n        model_name: Str\n            string indicating the model name to access the corresponding parameters.\n            One of \'wide\', \'deepdense\', \'deeptext\' or \'deepimage\'\n        loader: DataLoader\n            Pytorch DataLoader containing the data used to warm up\n        n_epochs: Int\n            number of epochs used to warm up the model\n        max_lr: Float\n            maximum learning rate value during the triangular cycle.\n        """"""\n        if self.verbose:\n            print(""Warming up {} for {} epochs"".format(model_name, n_epochs))\n        model.train()\n\n        optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr / 10.0)  # type: ignore\n        step_size_up, step_size_down = self._steps_up_down(len(loader), n_epochs)\n        scheduler = torch.optim.lr_scheduler.CyclicLR(\n            optimizer,\n            base_lr=max_lr / 10.0,\n            max_lr=max_lr,\n            step_size_up=step_size_up,\n            step_size_down=step_size_down,\n            cycle_momentum=False,\n        )\n\n        self._warm(model, model_name, loader, optimizer, scheduler, n_epochs=n_epochs)\n\n    def warm_gradual(\n        self,\n        model: nn.Module,\n        model_name: str,\n        loader: DataLoader,\n        last_layer_max_lr: float,\n        layers: List[nn.Module],\n        routine: str,\n    ):\n        r""""""\n        Warm up certain layers within the model following a gradual warm up routine.\n        The approaches implemented in this method are inspired by the work of Felbo\n        et al., 2017 in their DeepEmoji paper (https://arxiv.org/abs/1708.00524) and\n        Howard & Sebastian Ruder 2018 ULMFit paper\n        (https://arxiv.org/abs/1801.06146).\n\n        A one cycle triangular learning rate is used. In both Felbo\'s and Howard\'s\n        routines a gradually decreasing learning rate is used as we go deeper into\n        the network. The \'closest\' layer to the output neuron(s) will use a maximum\n        learning rate of \'last_layer_max_lr\'. The learning rate will then decrease by a factor\n        of 2.5 per layer\n\n        1) The \'Felbo\' routine:\n           warm up the first layer in \'layers\' for one epoch. Then warm up the next\n           layer in \'layers\' for one epoch freezing the already warmed up layer(s).\n           Repeat untill all individual layers are warmed. Then warm one last epoch\n           with all warmed layers trainable\n        2) The \'Howard\' routine:\n           warm up the first layer in \'layers\' for one epoch. Then warm the next layer\n           in the model for one epoch while keeping the already warmed up layer(s)\n           trainable. Repeat.\n\n        Parameters:\n        ----------\n        model: nn.Module\n           nn.Module object containing one the WideDeep model components (wide,\n           deepdense, deeptext or deepimage)\n        model_name: Str\n           string indicating the model name to access the corresponding parameters.\n           One of \'wide\', \'deepdense\', \'deeptext\' or \'deepimage\'\n        loader: DataLoader\n           Pytorch DataLoader containing the data to warm up with.\n        last_layer_max_lr: Float\n           maximum learning rate value during the triangular cycle for the layer\n           closest to the output neuron(s). Deeper layers in \'model\' will be trained\n           with a gradually descending learning rate. The descending factor is fixed\n           and is 2.5\n        layers: List\n           List of nn.Module objects containing the layers that will be warmed up.\n           This must be in \'WARM-UP ORDER\'.\n        routine: str\n           one of \'howard\' or \'felbo\'\n        """"""\n        model.train()\n        step_size_up, step_size_down = self._steps_up_down(len(loader))\n        original_setup = {}\n        for n, p in model.named_parameters():\n            original_setup[n] = p.requires_grad\n        layers_max_lr = [last_layer_max_lr] + [\n            last_layer_max_lr / (2.5 * n) for n in range(1, len(layers))\n        ]\n\n        for layer in layers:\n            for p in layer.parameters():\n                p.requires_grad = False\n\n        if routine == ""howard"":\n            params: List = []\n            max_lr: List = []\n            base_lr: List = []\n\n        for i, (lr, layer) in enumerate(zip(layers_max_lr, layers)):\n            if self.verbose:\n                print(\n                    ""Warming up {}, layer {} of {}"".format(\n                        model_name, i + 1, len(layers)\n                    )\n                )\n            for p in layer.parameters():\n                p.requires_grad = True\n            if routine == ""felbo"":\n                params, max_lr, base_lr = layer.parameters(), lr, lr / 10.0  # type: ignore\n            elif routine == ""howard"":\n                params += [{""params"": layer.parameters(), ""lr"": lr / 10.0}]\n                max_lr += [lr]\n                base_lr += [lr / 10.0]\n            optimizer = torch.optim.AdamW(params)  # type: ignore\n            scheduler = torch.optim.lr_scheduler.CyclicLR(\n                optimizer,\n                base_lr=base_lr,  # type: ignore\n                max_lr=max_lr,  # type: ignore\n                step_size_up=step_size_up,\n                step_size_down=step_size_down,  # type: ignore\n                cycle_momentum=False,\n            )\n            self._warm(model, model_name, loader, optimizer, scheduler)\n            if routine == ""felbo"":\n                for p in layer.parameters():\n                    p.requires_grad = False\n\n        if routine == ""felbo"":\n            if self.verbose:\n                print(""Warming up one last epoch with all warmed up layers trainable"")\n            for layer in layers:\n                for p in layer.parameters():\n                    p.requires_grad = True\n            params, max_lr, base_lr = [], [], []\n            for lr, layer in zip(layers_max_lr, layers):\n                params += [{""params"": layer.parameters(), ""lr"": lr / 10.0}]\n                max_lr += [lr]\n                base_lr += [lr / 10.0]\n            optimizer = torch.optim.AdamW(params)  # type: ignore\n            scheduler = torch.optim.lr_scheduler.CyclicLR(\n                optimizer,\n                base_lr=base_lr,  # type: ignore\n                max_lr=max_lr,  # type: ignore\n                step_size_up=step_size_up,\n                step_size_down=step_size_down,  # type: ignore\n                cycle_momentum=False,\n            )\n            self._warm(model, model_name, loader, optimizer, scheduler)\n\n        for n, p in model.named_parameters():\n            p.requires_grad = original_setup[n]\n\n    def _warm(\n        self,\n        model: nn.Module,\n        model_name: str,\n        loader: DataLoader,\n        optimizer: Optimizer,\n        scheduler: LRScheduler,\n        n_epochs: int = 1,\n    ):\n        r""""""\n        Standard Pytorch training loop\n        """"""\n        steps = len(loader)\n        for epoch in range(n_epochs):\n            running_loss = 0.0\n            with trange(steps, disable=self.verbose != 1) as t:\n                for batch_idx, (data, target) in zip(t, loader):\n                    t.set_description(""epoch %i"" % (epoch + 1))\n                    X = data[model_name].cuda() if use_cuda else data[model_name]\n                    y = target.float() if self.method != ""multiclass"" else target\n                    y = y.cuda() if use_cuda else y\n\n                    optimizer.zero_grad()\n                    y_pred = self.activation_fn(model(X))\n                    loss = self.loss_fn(y_pred, y)\n                    loss.backward()\n                    optimizer.step()\n                    scheduler.step()  # type: ignore\n\n                    running_loss += loss.item()\n                    avg_loss = running_loss / (batch_idx + 1)\n\n                    if self.metric is not None:\n                        acc = self.metric(y_pred, y)\n                        t.set_postfix(metrics=acc, loss=avg_loss)\n                    else:\n                        t.set_postfix(loss=np.sqrt(avg_loss))\n\n    def _steps_up_down(self, steps: int, n_epochs: int = 1) -> Tuple[int, int]:\n        r""""""\n        Calculate the number of steps up and down during the one cycle warm up for a\n        given number of epochs\n\n        Parameters:\n        ----------\n        steps: Int\n            steps per epoch\n        n_epochs: Int. Default=1\n            number of warm up epochs\n\n        Returns:\n        -------\n        up, down: Tuple, Int\n            number of steps increasing/decreasing the learning rate during the cycle\n        """"""\n        up = round((steps * n_epochs) * 0.1)\n        down = (steps * n_epochs) - up\n        return up, down\n'"
pytorch_widedeep/models/_wd_dataset.py,4,"b'import numpy as np\nimport torch\n\nfrom sklearn.utils import Bunch\nfrom torch.utils.data import Dataset\n\nfrom ..wdtypes import *\n\n\nclass WideDeepDataset(Dataset):\n    r""""""Dataset object to load WideDeep data to the model\n\n    Parameters\n    ----------\n    X_wide: np.ndarray, scipy csr sparse matrix.\n        wide input.Note that if a sparse matrix is passed to the\n        WideDeepDataset class, the loading process will be notably slow since\n        the transformation to a dense matrix is done on an index basis \'on the\n        fly\'. At the moment this is the best option given the current support\n        offered for sparse tensors for pytorch.\n    X_deep: np.ndarray\n        deepdense input\n    X_text: np.ndarray\n        deeptext input\n    X_img: np.ndarray\n        deepimage input\n    target: np.ndarray\n    transforms: MultipleTransforms() object (which is in itself a torchvision\n        Compose). See in models/_multiple_transforms.py\n    """"""\n\n    def __init__(\n        self,\n        X_wide: Union[np.ndarray, sparse_matrix],\n        X_deep: np.ndarray,\n        target: Optional[np.ndarray] = None,\n        X_text: Optional[np.ndarray] = None,\n        X_img: Optional[np.ndarray] = None,\n        transforms: Optional[Any] = None,\n    ):\n\n        self.X_wide = X_wide\n        self.X_deep = X_deep\n        self.X_text = X_text\n        self.X_img = X_img\n        self.transforms = transforms\n        if self.transforms:\n            self.transforms_names = [\n                tr.__class__.__name__ for tr in self.transforms.transforms\n            ]\n        else:\n            self.transforms_names = []\n        self.Y = target\n\n    def __getitem__(self, idx: int):\n        # X_wide and X_deep are assumed to be *always* present\n        if isinstance(self.X_wide, sparse_matrix):\n            X = Bunch(wide=np.array(self.X_wide[idx].todense()).squeeze())\n        else:\n            X = Bunch(wide=self.X_wide[idx])\n        X.deepdense = self.X_deep[idx]\n        if self.X_text is not None:\n            X.deeptext = self.X_text[idx]\n        if self.X_img is not None:\n            # if an image dataset is used, make sure is in the right format to\n            # be ingested by the conv layers\n            xdi = self.X_img[idx]\n            # if int must be uint8\n            if ""int"" in str(xdi.dtype) and ""uint8"" != str(xdi.dtype):\n                xdi = xdi.astype(""uint8"")\n            # if int float must be float32\n            if ""float"" in str(xdi.dtype) and ""float32"" != str(xdi.dtype):\n                xdi = xdi.astype(""float32"")\n            # if there are no transforms, or these do not include ToTensor(),\n            # then we need to  replicate what Tensor() does -> transpose axis\n            # and normalize if necessary\n            if not self.transforms or ""ToTensor"" not in self.transforms_names:\n                xdi = xdi.transpose(2, 0, 1)\n                if ""int"" in str(xdi.dtype):\n                    xdi = (xdi / xdi.max()).astype(""float32"")\n            # if ToTensor() is included, simply apply transforms\n            if ""ToTensor"" in self.transforms_names:\n                xdi = self.transforms(xdi)\n            # else apply transforms on the result of calling torch.tensor on\n            # xdi after all the previous manipulation\n            elif self.transforms:\n                xdi = self.transforms(torch.tensor(xdi))\n            # fill the Bunch\n            X.deepimage = xdi\n        if self.Y is not None:\n            y = self.Y[idx]\n            return X, y\n        else:\n            return X\n\n    def __len__(self):\n        return len(self.X_deep)\n'"
pytorch_widedeep/models/deep_dense.py,3,"b'import numpy as np\nimport torch\n\nfrom torch import nn\nfrom ..wdtypes import *\n\n\ndef dense_layer(inp: int, out: int, p: float = 0.0, bn=False):\n    layers = [nn.Linear(inp, out), nn.LeakyReLU(inplace=True)]\n    if bn:\n        layers.append(nn.BatchNorm1d(out))\n    layers.append(nn.Dropout(p))\n    return nn.Sequential(*layers)\n\n\nclass DeepDense(nn.Module):\n    r""""""Dense branch of the deep side of the model. This class combines embedding\n    representations of the categorical features with numerical (aka\n    continuous) features. These are then passed through a series of dense\n    layers.\n\n    Parameters\n    ----------\n    deep_column_idx: Dict\n        Dict containing the index of the columns that will be passed through\n        the DeepDense model. Required to slice the tensors. e.g. {\'education\':\n        0, \'relationship\': 1, \'workclass\': 2, ...}\n    hidden_layers: List\n        List with the number of neurons per dense layer. e.g: [64,32]\n    batchnorm: Boolean\n        Boolean indicating whether or not to include batch normalizatin in the\n        dense layers\n    dropout: List, Optional\n        List with the dropout between the dense layers. e.g: [0.5,0.5]\n    embeddings_input: List, Optional\n        List of Tuples with the column name, number of unique values and\n        embedding dimension. e.g. [(education, 11, 32), ...]\n    embed_p: float\n        embeddings dropout\n    continuous_cols: List, Optional\n        List with the name of the numeric (aka continuous) columns\n\n    **Either embeddings_input or continuous_cols (or both) should be passed to the\n    model\n\n    Attributes\n    ----------\n    dense: nn.Sequential\n        model of dense layers that will receive the concatenation of the\n        embeddings and the continuous columns\n    embed_layers: nn.ModuleDict\n        ModuleDict with the embedding layers\n    output_dim: Int\n        The output dimension of the model. This is a required attribute\n        neccesary to build the WideDeep class\n\n    Example\n    --------\n    >>> import torch\n    >>> from pytorch_widedeep.models import DeepDense\n    >>> X_deep = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n    >>> colnames = [\'a\', \'b\', \'c\', \'d\', \'e\']\n    >>> embed_input = [(u,i,j) for u,i,j in zip(colnames[:4], [4]*4, [8]*4)]\n    >>> deep_column_idx = {k:v for v,k in enumerate(colnames)}\n    >>> model = DeepDense(hidden_layers=[8,4], deep_column_idx=deep_column_idx, embed_input=embed_input)\n    >>> model(X_deep)\n    tensor([[ 3.4470e-02, -2.0089e-03,  4.7983e-02,  3.3500e-01],\n            [ 1.4329e-02, -1.3800e-03, -3.3617e-04,  4.1046e-01],\n            [-3.3546e-04,  3.2413e-02, -4.1198e-03,  4.8717e-01],\n            [-6.7882e-04,  7.9103e-03, -1.9960e-03,  4.2134e-01],\n            [ 6.7187e-02, -1.2821e-03, -3.0960e-04,  3.6123e-01]],\n           grad_fn=<LeakyReluBackward1>)\n    """"""\n\n    def __init__(\n        self,\n        deep_column_idx: Dict[str, int],\n        hidden_layers: List[int],\n        batchnorm: bool = False,\n        dropout: Optional[List[float]] = None,\n        embed_input: Optional[List[Tuple[str, int, int]]] = None,\n        embed_p: float = 0.0,\n        continuous_cols: Optional[List[str]] = None,\n    ):\n\n        super(DeepDense, self).__init__()\n        self.embed_input = embed_input\n        self.continuous_cols = continuous_cols\n        self.deep_column_idx = deep_column_idx\n\n        # Embeddings\n        if self.embed_input is not None:\n            self.embed_layers = nn.ModuleDict(\n                {\n                    ""emb_layer_"" + col: nn.Embedding(val, dim)\n                    for col, val, dim in self.embed_input\n                }\n            )\n            self.embed_dropout = nn.Dropout(embed_p)\n            emb_inp_dim = np.sum([embed[2] for embed in self.embed_input])\n        else:\n            emb_inp_dim = 0\n\n        # Continuous\n        if self.continuous_cols is not None:\n            cont_inp_dim = len(self.continuous_cols)\n        else:\n            cont_inp_dim = 0\n\n        # Dense Layers\n        input_dim = emb_inp_dim + cont_inp_dim\n        hidden_layers = [input_dim] + hidden_layers\n        if not dropout:\n            dropout = [0.0] * len(hidden_layers)\n        self.dense = nn.Sequential()\n        for i in range(1, len(hidden_layers)):\n            self.dense.add_module(\n                ""dense_layer_{}"".format(i - 1),\n                dense_layer(\n                    hidden_layers[i - 1], hidden_layers[i], dropout[i - 1], batchnorm\n                ),\n            )\n\n        # the output_dim attribute will be used as input_dim when ""merging"" the models\n        self.output_dim = hidden_layers[-1]\n\n    def forward(self, X: Tensor) -> Tensor:  # type: ignore\n        if self.embed_input is not None:\n            x = [\n                self.embed_layers[""emb_layer_"" + col](\n                    X[:, self.deep_column_idx[col]].long()\n                )\n                for col, _, _ in self.embed_input\n            ]\n            x = torch.cat(x, 1)  # type: ignore\n            x = self.embed_dropout(x)  # type: ignore\n        if self.continuous_cols is not None:\n            cont_idx = [self.deep_column_idx[col] for col in self.continuous_cols]\n            x_cont = X[:, cont_idx].float()\n            x = torch.cat([x, x_cont], 1) if self.embed_input is not None else x_cont  # type: ignore\n        return self.dense(x)  # type: ignore\n'"
pytorch_widedeep/models/deep_image.py,1,"b'from ..wdtypes import *\n\nfrom .deep_dense import dense_layer\n\nfrom torch import nn\nfrom torchvision import models\n\n\ndef conv_layer(\n    ni: int,\n    nf: int,\n    ks: int = 3,\n    stride: int = 1,\n    maxpool: bool = True,\n    adaptiveavgpool: bool = False,\n):\n    layer = nn.Sequential(\n        nn.Conv2d(ni, nf, kernel_size=ks, bias=True, stride=stride, padding=ks // 2),\n        nn.BatchNorm2d(nf, momentum=0.01),\n        nn.LeakyReLU(negative_slope=0.1, inplace=True),\n    )\n    if maxpool:\n        layer.add_module(""maxpool"", nn.MaxPool2d(2, 2))\n    if adaptiveavgpool:\n        layer.add_module(""adaptiveavgpool"", nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n    return layer\n\n\nclass DeepImage(nn.Module):\n    r""""""\n    Standard image classifier/regressor using a pretrained network freezing\n    some of the first layers, or all layers. I use Resnets which have 9\n    ""components"" before the last dense layers.\n    The first 4 are: conv->batchnorm->relu->maxpool.\n    After that we have 4 additional \'layers\' (resnet blocks) (so 4+4=8)\n    comprised by a series of convolutions and then the final AdaptiveAvgPool2d\n    (8+1=9). The parameter freeze sets the layers to be frozen. For example,\n    freeze=6 will freeze all but the last 2 Layers and AdaptiveAvgPool2d\n    layer. If freeze=\'all\' it freezes the entire network. In addition, there\n    is the option to add a Fully Connected (FC) set of dense layers (FC-Head,\n    referred as \'imagehead\') on top of the stack of RNNs\n\n    Parameters\n    ----------\n    pretrained: Boolean\n        Indicates whether or not we use a pretrained Resnet network or a\n        series of conv layers (see conv_layer function)\n    resnet: Int\n        The resnet architecture. One of 18, 34 or 50\n    freeze: Int, Str\n        number of layers to freeze. If int must be less than 8. The only\n        string allowed is \'all\' which will freeze the entire network\n    head_layers: List, Optional\n        List with the sizes of the stacked dense layers in the head\n        e.g: [128, 64]\n    head_dropout: List, Optional\n        List with the dropout between the dense layers. e.g: [0.5, 0.5].\n    head_batchnorm: Boolean, Optional\n        Boolean indicating whether or not to include batch normalizatin in the\n        dense layers that form the imagehead\n\n    Attributes\n    ----------\n    backbone: nn.Sequential\n        Sequential stack of CNNs comprising the \'backbone\' of the network\n    imagehead: nn.Sequential\n        Sequential stack of dense layers comprising the FC-Head (aka imagehead)\n    output_dim: Int\n        The output dimension of the model. This is a required attribute\n        neccesary to build the WideDeep class\n\n    Example\n    --------\n    >>> import torch\n    >>> from pytorch_widedeep.models import DeepImage\n    >>> X_img = torch.rand((2,3,224,224))\n    >>> model = DeepImage(head_layers=[512, 64, 8])\n    >>> model(X_img)\n    tensor([[ 7.7234e-02,  8.0923e-02,  2.3077e-01, -5.1122e-03, -4.3018e-03,\n              3.1193e-01,  3.0780e-01,  6.5098e-01],\n            [ 4.6191e-02,  6.7856e-02, -3.0163e-04, -3.7670e-03, -2.1437e-03,\n              1.5416e-01,  3.9227e-01,  5.5048e-01]], grad_fn=<LeakyReluBackward1>)\n    """"""\n\n    def __init__(\n        self,\n        pretrained: bool = True,\n        resnet: int = 18,\n        freeze: Union[str, int] = 6,\n        head_layers: Optional[List[int]] = None,\n        head_dropout: Optional[List[float]] = None,\n        head_batchnorm: Optional[bool] = False,\n    ):\n        super(DeepImage, self).__init__()\n\n        self.head_layers = head_layers\n\n        if pretrained:\n            if resnet == 18:\n                vision_model = models.resnet18(pretrained=True)\n            elif resnet == 34:\n                vision_model = models.resnet34(pretrained=True)\n            elif resnet == 50:\n                vision_model = models.resnet50(pretrained=True)\n\n            backbone_layers = list(vision_model.children())[:-1]\n\n            if isinstance(freeze, str):\n                frozen_layers = []\n                for layer in backbone_layers:\n                    for param in layer.parameters():\n                        param.requires_grad = False\n                    frozen_layers.append(layer)\n                self.backbone = nn.Sequential(*frozen_layers)\n            if isinstance(freeze, int):\n                assert (\n                    freeze < 8\n                ), ""freeze\' must be less than 8 when using resnet architectures""\n                frozen_layers = []\n                trainable_layers = backbone_layers[freeze:]\n                for layer in backbone_layers[:freeze]:\n                    for param in layer.parameters():\n                        param.requires_grad = False\n                    frozen_layers.append(layer)\n\n                backbone_layers = frozen_layers + trainable_layers\n                self.backbone = nn.Sequential(*backbone_layers)\n        else:\n            self.backbone = nn.Sequential(\n                conv_layer(3, 64, 3),\n                conv_layer(64, 128, 1, maxpool=False),\n                conv_layer(128, 256, 1, maxpool=False),\n                conv_layer(256, 512, 1, maxpool=False, adaptiveavgpool=True),\n            )\n\n        # the output_dim attribute will be used as input_dim when ""merging"" the models\n        self.output_dim = 512\n\n        if self.head_layers is not None:\n            assert self.head_layers[0] == self.output_dim, (\n                ""The output dimension from the backbone ({}) is not consistent with ""\n                ""the expected input dimension ({}) of the fc-head"".format(\n                    self.output_dim, self.head_layers[0]\n                )\n            )\n            if not head_dropout:\n                head_dropout = [0.0] * len(head_layers)\n            self.imagehead = nn.Sequential()\n            for i in range(1, len(head_layers)):\n                self.imagehead.add_module(\n                    ""dense_layer_{}"".format(i - 1),\n                    dense_layer(\n                        head_layers[i - 1],\n                        head_layers[i],\n                        head_dropout[i - 1],\n                        head_batchnorm,\n                    ),\n                )\n            self.output_dim = head_layers[-1]\n\n    def forward(self, x: Tensor) -> Tensor:  # type: ignore\n        x = self.backbone(x)\n        x = x.view(x.size(0), -1)\n        if self.head_layers is not None:\n            out = self.imagehead(x)\n            return out\n        else:\n            return x\n'"
pytorch_widedeep/models/deep_text.py,3,"b'import numpy as np\nimport torch\nimport warnings\n\nfrom torch import nn\nfrom ..wdtypes import *\nfrom .deep_dense import dense_layer\n\n\nclass DeepText(nn.Module):\n    r""""""Standard text classifier/regressor comprised by a stack of RNNs (LSTMs).\n    In addition, there is the option to add a Fully Connected (FC) set of dense\n    layers (FC-Head, referred as \'texthead\') on top of the stack of RNNs\n\n    Parameters\n    ----------\n    vocab_size: Int\n        number of words in the vocabulary\n    hidden_dim: Int\n        number of features in the hidden state h of the LSTM\n    n_layers: Int\n        number of recurrent layers\n    rnn_dropout: Int\n        dropout for the dropout layer on the outputs of each LSTM layer except\n        the last layer\n    bidirectional: Boolean\n        indicates whether the staked RNNs are bidirectional\n    padding_idx: Int\n        index of the padding token in the padded-tokenised sequences. default:\n        1. I use the fastai Tokenizer where the token index 0 is reserved for\n        the  unknown word token\n    embed_dim: Int, Optional\n        Dimension of the word embedding matrix\n    embedding_matrix: np.ndarray, Optional\n         Pretrained word embeddings\n    head_layers: List, Optional\n        List with the sizes of the stacked dense layers in the head\n        e.g: [128, 64]\n    head_dropout: List, Optional\n        List with the dropout between the dense layers. e.g: [0.5, 0.5].\n    head_batchnorm: Boolean, Optional\n        Whether or not to include batch normalizatin in the dense layers that\n        form the texthead\n\n    Attributes\n    ----------\n    word_embed: nn.Module\n        word embedding matrix\n    rnn: nn.Module\n        Stack of LSTMs\n    texthead: nn.Sequential, Optional\n        Stack of dense layers\n    output_dim: Int\n        The output dimension of the model. This is a required attribute\n        neccesary to build the WideDeep class\n\n    Example\n    --------\n    >>> import torch\n    >>> from pytorch_widedeep.models import DeepText\n    >>> X_text = torch.cat((torch.zeros([5,1]), torch.empty(5, 4).random_(1,4)), axis=1)\n    >>> model = DeepText(vocab_size=4, hidden_dim=4, n_layers=1, padding_idx=0, embed_dim=4)\n    >>> model(X_text)\n    tensor([[ 0.0315,  0.0393, -0.0618, -0.0561],\n            [-0.0674,  0.0297, -0.1118, -0.0668],\n            [-0.0446,  0.0814, -0.0921, -0.0338],\n            [-0.0844,  0.0681, -0.1016, -0.0464],\n            [-0.0268,  0.0294, -0.0988, -0.0666]], grad_fn=<SelectBackward>)\n    """"""\n\n    def __init__(\n        self,\n        vocab_size: int,\n        hidden_dim: int = 64,\n        n_layers: int = 3,\n        rnn_dropout: float = 0.0,\n        bidirectional: bool = False,\n        padding_idx: int = 1,\n        embed_dim: Optional[int] = None,\n        embedding_matrix: Optional[np.ndarray] = None,\n        head_layers: Optional[List[int]] = None,\n        head_dropout: Optional[List[float]] = None,\n        head_batchnorm: Optional[bool] = False,\n    ):\n        super(DeepText, self).__init__()\n\n        if (\n            embed_dim is not None\n            and embedding_matrix is not None\n            and not embed_dim == embedding_matrix.shape[1]\n        ):\n            warnings.warn(\n                ""the input embedding dimension {} and the dimension of the ""\n                ""pretrained embeddings {} do not match. The pretrained embeddings ""\n                ""dimension ({}) will be used"".format(\n                    embed_dim, embedding_matrix.shape[1], embedding_matrix.shape[1]\n                ),\n                UserWarning,\n            )\n\n        self.bidirectional = bidirectional\n        self.head_layers = head_layers\n\n        # Pre-trained Embeddings\n        if isinstance(embedding_matrix, np.ndarray):\n            assert (\n                embedding_matrix.dtype == ""float32""\n            ), ""\'embedding_matrix\' must be of dtype \'float32\', got dtype \'{}\'"".format(\n                str(embedding_matrix.dtype)\n            )\n            self.word_embed = nn.Embedding(\n                vocab_size, embedding_matrix.shape[1], padding_idx=padding_idx\n            )\n            self.word_embed.weight = nn.Parameter(\n                torch.tensor(embedding_matrix), requires_grad=True\n            )\n            embed_dim = embedding_matrix.shape[1]\n        else:\n            self.word_embed = nn.Embedding(\n                vocab_size, embed_dim, padding_idx=padding_idx\n            )\n\n        # stack of RNNs (LSTMs)\n        self.rnn = nn.LSTM(\n            embed_dim,\n            hidden_dim,\n            num_layers=n_layers,\n            bidirectional=bidirectional,\n            dropout=rnn_dropout,\n            batch_first=True,\n        )\n\n        # the output_dim attribute will be used as input_dim when ""merging"" the models\n        self.output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n\n        if self.head_layers is not None:\n            assert self.head_layers[0] == self.output_dim, (\n                ""The hidden dimension from the stack or RNNs ({}) is not consistent with ""\n                ""the expected input dimension ({}) of the fc-head"".format(\n                    self.output_dim, self.head_layers[0]\n                )\n            )\n            if not head_dropout:\n                head_dropout = [0.0] * len(head_layers)\n            self.texthead = nn.Sequential()\n            for i in range(1, len(head_layers)):\n                self.texthead.add_module(\n                    ""dense_layer_{}"".format(i - 1),\n                    dense_layer(\n                        head_layers[i - 1],\n                        head_layers[i],\n                        head_dropout[i - 1],\n                        head_batchnorm,\n                    ),\n                )\n            self.output_dim = head_layers[-1]\n\n    def forward(self, X: Tensor) -> Tensor:  # type: ignore\n\n        embed = self.word_embed(X.long())\n        o, (h, c) = self.rnn(embed)\n        if self.bidirectional:\n            last_h = torch.cat((h[-2], h[-1]), dim=1)\n        else:\n            last_h = h[-1]\n        if self.head_layers is not None:\n            out = self.texthead(last_h)\n            return out\n        else:\n            return last_h\n'"
pytorch_widedeep/models/wide.py,1,"b'from torch import nn\nfrom ..wdtypes import *\n\n\nclass Wide(nn.Module):\n    r""""""simple linear layer between the one-hot encoded wide input and the output\n    neuron.\n\n    Parameters\n    ----------\n    wide_dim: Int\n        size of the input tensor\n    output_dim: Int\n        size of the ouput tensor\n\n    Attributes\n    ----------\n    wide_linear: nn.Module\n        the linear layer that comprises the wide branch of the model\n\n    Example\n    --------\n    >>> import torch\n    >>> from pytorch_widedeep.models import Wide\n    >>> X = torch.empty(4, 4).random_(2)\n    >>> wide = Wide(wide_dim=X.size(0), output_dim=1)\n    >>> wide(X)\n    tensor([[-0.8841],\n            [-0.8633],\n            [-1.2713],\n            [-0.4762]], grad_fn=<AddmmBackward>)\n    """"""\n\n    def __init__(self, wide_dim: int, output_dim: int = 1):\n        super(Wide, self).__init__()\n        self.wide_linear = nn.Linear(wide_dim, output_dim)\n\n    def forward(self, X: Tensor) -> Tensor:  # type: ignore\n        out = self.wide_linear(X.float())\n        return out\n'"
pytorch_widedeep/models/wide_deep.py,27,"b'import numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom ..wdtypes import *\n\nfrom ..initializers import Initializer, MultipleInitializer\nfrom ..callbacks import Callback, History, CallbackContainer\nfrom ..metrics import Metric, MultipleMetrics, MetricCallback\nfrom ..losses import FocalLoss\n\nfrom ._wd_dataset import WideDeepDataset\nfrom ._multiple_optimizer import MultipleOptimizer\nfrom ._multiple_lr_scheduler import MultipleLRScheduler\nfrom ._multiple_transforms import MultipleTransforms\nfrom ._warmup import WarmUp\nfrom .deep_dense import dense_layer\n\nfrom tqdm import trange\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\n\n\nn_cpus = os.cpu_count()\nuse_cuda = torch.cuda.is_available()\n\n\nclass WideDeep(nn.Module):\n    r"""""" Main collector class to combine all Wide, DeepDense, DeepText and\n    DeepImage models. There are two options to combine these models.\n    1) Directly connecting the output of the models to an ouput neuron(s).\n    2) Adding a FC-Head on top of the deep models. This FC-Head will combine\n    the output form the DeepDense, DeepText and DeepImage and will be then\n    connected to the output neuron(s)\n\n    Parameters\n    ----------\n    wide: nn.Module\n        Wide model. I recommend using the Wide class in this package. However,\n        can a custom model as long as is  consistent with the required\n        architecture.\n    deepdense: nn.Module\n        \'Deep dense\' model consisting in a series of categorical features\n        represented by embeddings combined with numerical (aka continuous)\n        features. I recommend using the DeepDense class in this package.\n        However, a custom model as long as is  consistent with the required\n        architecture.\n    deeptext: nn.Module, Optional\n        \'Deep text\' model for the text input. Must be an object of class\n        DeepText or a custom model as long as is consistent with the required\n        architecture.\n    deepimage: nn.Module, Optional\n        \'Deep Image\' model for the images input. Must be an object of class\n        DeepImage or a custom model as long as is consistent with the required\n        architecture.\n    deephead: nn.Module, Optional\n        Dense model consisting in a stack of dense layers. The FC-Head\n    head_layers: List, Optional\n        Sizes of the stacked dense layers in the fc-head e.g: [128, 64]\n    head_dropout: List, Optional\n        Dropout between the dense layers. e.g: [0.5, 0.5]\n    head_batchnorm: Boolean, Optional\n        Specifies if batch normalizatin should be included in the dense layers\n        that form the texthead\n    output_dim: Int\n        Size of the final layer. 1 for regression and binary classification or\n        \'n_class\' for multiclass classification\n\n    ** While I recommend using the Wide and DeepDense classes within this\n    package when building the corresponding model components, it is very likely\n    that the user will want to use custom text and image models. That is perfectly\n    possible. Simply, build them and pass them as the corresponding parameters.\n    Note that the custom models MUST return a last layer of activations (i.e. not\n    the final prediction) so that  these activations are collected by WideDeep and\n    combined accordingly. In  addition, the models MUST also contain an attribute\n    \'output_dim\' with the size of these last layers of activations.\n\n    Example\n    --------\n    >>> import torch\n    >>> from pytorch_widedeep.models import Wide, DeepDense, DeepText, DeepImage, WideDeep\n    >>>\n    >>> X_wide = torch.empty(5, 5).random_(2)\n    >>> wide = Wide(wide_dim=X_wide.size(0), output_dim=1)\n    >>>\n    >>> X_deep = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n    >>> colnames = [\'a\', \'b\', \'c\', \'d\', \'e\']\n    >>> embed_input = [(u,i,j) for u,i,j in zip(colnames[:4], [4]*4, [8]*4)]\n    >>> deep_column_idx = {k:v for v,k in enumerate(colnames)}\n    >>> deepdense = DeepDense(hidden_layers=[8,4], deep_column_idx=deep_column_idx, embed_input=embed_input)\n    >>>\n    >>> X_text = torch.cat((torch.zeros([5,1]), torch.empty(5, 4).random_(1,4)), axis=1)\n    >>> deeptext = DeepText(vocab_size=4, hidden_dim=4, n_layers=1, padding_idx=0, embed_dim=4)\n    >>>\n    >>> X_img = torch.rand((5,3,224,224))\n    >>> deepimage = DeepImage(head_layers=[512, 64, 8])\n    >>>\n    >>> model = WideDeep(wide=wide, deepdense=deepdense, deeptext=deeptext, deepimage=deepimage, output_dim=1)\n    >>> input_dict = {\'wide\':X_wide, \'deepdense\':X_deep, \'deeptext\':X_text, \'deepimage\':X_img}\n    >>> model(X=input_dict)\n    tensor([[-0.3779],\n            [-0.5247],\n            [-0.2773],\n            [-0.2888],\n            [-0.2010]], grad_fn=<AddBackward0>)\n    """"""\n\n    def __init__(\n        self,\n        wide: nn.Module,\n        deepdense: nn.Module,\n        output_dim: int = 1,\n        deeptext: Optional[nn.Module] = None,\n        deepimage: Optional[nn.Module] = None,\n        deephead: Optional[nn.Module] = None,\n        head_layers: Optional[List[int]] = None,\n        head_dropout: Optional[List] = None,\n        head_batchnorm: Optional[bool] = None,\n    ):\n\n        super(WideDeep, self).__init__()\n\n        # The main 5 components of the wide and deep assemble\n        self.wide = wide\n        self.deepdense = deepdense\n        self.deeptext = deeptext\n        self.deepimage = deepimage\n        self.deephead = deephead\n\n        if self.deephead is None:\n            if head_layers is not None:\n                input_dim: int = self.deepdense.output_dim  # type:ignore\n                if self.deeptext is not None:\n                    input_dim += self.deeptext.output_dim\n                if self.deepimage is not None:\n                    input_dim += self.deepimage.output_dim\n                head_layers = [input_dim] + head_layers\n                if not head_dropout:\n                    head_dropout = [0.0] * (len(head_layers) - 1)\n                self.deephead = nn.Sequential()\n                for i in range(1, len(head_layers)):\n                    self.deephead.add_module(\n                        ""head_layer_{}"".format(i - 1),\n                        dense_layer(\n                            head_layers[i - 1],\n                            head_layers[i],\n                            head_dropout[i - 1],\n                            head_batchnorm,\n                        ),\n                    )\n                self.deephead.add_module(\n                    ""head_out"", nn.Linear(head_layers[-1], output_dim)\n                )\n            else:\n                self.deepdense = nn.Sequential(\n                    self.deepdense, nn.Linear(self.deepdense.output_dim, output_dim)  # type: ignore\n                )\n                if self.deeptext is not None:\n                    self.deeptext = nn.Sequential(\n                        self.deeptext, nn.Linear(self.deeptext.output_dim, output_dim)  # type: ignore\n                    )\n                if self.deepimage is not None:\n                    self.deepimage = nn.Sequential(\n                        self.deepimage, nn.Linear(self.deepimage.output_dim, output_dim)  # type: ignore\n                    )\n\n    def forward(self, X: Dict[str, Tensor]) -> Tensor:  # type: ignore\n        r""""""\n        Parameters\n        ----------\n        X: List\n            List of Dict where the keys are the model names (\'wide\',\n            \'deepdense\', \'deeptext\' and \'deepimage\') and the values are the\n            corresponding Tensors\n        """"""\n        # Wide output: direct connection to the output neuron(s)\n        out = self.wide(X[""wide""])\n\n        # Deep output: either connected directly to the output neuron(s) or\n        # passed through a head first\n        if self.deephead:\n            deepside = self.deepdense(X[""deepdense""])\n            if self.deeptext is not None:\n                deepside = torch.cat([deepside, self.deeptext(X[""deeptext""])], axis=1)  # type: ignore\n            if self.deepimage is not None:\n                deepside = torch.cat([deepside, self.deepimage(X[""deepimage""])], axis=1)  # type: ignore\n            deepside_out = self.deephead(deepside)\n            return out.add_(deepside_out)\n        else:\n            out.add_(self.deepdense(X[""deepdense""]))\n            if self.deeptext is not None:\n                out.add_(self.deeptext(X[""deeptext""]))\n            if self.deepimage is not None:\n                out.add_(self.deepimage(X[""deepimage""]))\n            return out\n\n    def compile(\n        self,\n        method: str,\n        optimizers: Optional[Union[Optimizer, Dict[str, Optimizer]]] = None,\n        lr_schedulers: Optional[Union[LRScheduler, Dict[str, LRScheduler]]] = None,\n        initializers: Optional[Dict[str, Initializer]] = None,\n        transforms: Optional[List[Transforms]] = None,\n        callbacks: Optional[List[Callback]] = None,\n        metrics: Optional[List[Metric]] = None,\n        class_weight: Optional[Union[float, List[float], Tuple[float]]] = None,\n        with_focal_loss: bool = False,\n        alpha: float = 0.25,\n        gamma: float = 2,\n        verbose: int = 1,\n        seed: int = 1,\n    ):\n        r""""""\n        Function to set a number of attributes that will be used during the\n        training process.\n\n        Parameters\n        ----------\n        method: Str\n            One of (\'regression\', \'binary\' or \'multiclass\')\n        optimizers: Optimizer, Dict. Optional, Default=AdamW\n            Either an optimizers object (e.g. torch.optim.Adam()) or a\n            dictionary where there keys are the model\'s children (i.e. \'wide\',\n            \'deepdense\', \'deeptext\', \'deepimage\' and/or \'deephead\')  and the\n            values are the corresponding optimizers. If multiple optimizers\n            are used the  dictionary MUST contain an optimizer per child.\n        lr_schedulers: LRScheduler, Dict. Optional. Default=None\n            Either a LRScheduler object (e.g\n            torch.optim.lr_scheduler.StepLR(opt, step_size=5)) or dictionary\n            where there keys are the model\'s children (i.e. \'wide\', \'deepdense\',\n            \'deeptext\', \'deepimage\' and/or \'deephead\') and the values are the\n            corresponding learning rate schedulers.\n        initializers: Dict, Optional. Default=None\n            Dict where there keys are the model\'s children (i.e. \'wide\',\n            \'deepdense\', \'deeptext\', \'deepimage\' and/or \'deephead\') and the\n            values are the corresponding initializers.\n        transforms: List, Optional. Default=None\n            List with torchvision.transforms to be applied to the image\n            component of the model (i.e. \'deepimage\')\n        callbacks: List, Optional. Default=None\n            Callbacks available are: ModelCheckpoint, EarlyStopping, and\n            LRHistory. The History callback is used by default.\n        metrics: List, Optional. Default=None\n            Metrics available are: BinaryAccuracy and CategoricalAccuracy\n        class_weight: List, Tuple, Float. Optional. Default=None\n            Can be one of: float indicating the weight of the minority class\n            in binary classification problems (e.g. 9.) or a list or tuple\n            with weights for the different classes in multiclass\n            classification problems  (e.g. [1., 2., 3.]). The weights do not\n            neccesarily need to be normalised. If your loss function uses\n            reduction=\'mean\', the loss will be normalized by the sum of the\n            corresponding weights for each element. If you are using\n            reduction=\'none\', you would have to take care of the normalization\n            yourself. See here:\n            https://discuss.pytorch.org/t/passing-the-weights-to-crossentropyloss-correctly/14731/10\n        with_focal_loss: Boolean, Optional. Default=False\n            Use the Focal Loss. https://arxiv.org/pdf/1708.02002.pdf\n        alpha, gamma: Float. Default=0.25, 2\n            Focal Loss parameters. See: https://arxiv.org/pdf/1708.02002.pdf\n        verbose: Int\n            Setting it to 0 will print nothing during training.\n        seed: Int, Default=1\n            Random seed to be used throughout all the methods\n\n        Attributes\n        ----------\n        Attributes that are not direct assignations of parameters\n\n        self.cyclic: Boolean\n            Indicates if any of the lr_schedulers is cyclic (i.e. CyclicLR or\n            OneCycleLR)\n\n        Example\n        --------\n        Assuming you have already built the model components (wide, deepdense, etc...)\n\n        >>> from pytorch_widedeep.models import WideDeep\n        >>> from pytorch_widedeep.initializers import *\n        >>> from pytorch_widedeep.callbacks import *\n        >>> from pytorch_widedeep.optim import RAdam\n        >>> model = WideDeep(wide=wide, deepdense=deepdense, deeptext=deeptext, deepimage=deepimage)\n        >>> wide_opt = torch.optim.Adam(model.wide.parameters())\n        >>> deep_opt = torch.optim.Adam(model.deepdense.parameters())\n        >>> text_opt = RAdam(model.deeptext.parameters())\n        >>> img_opt  = RAdam(model.deepimage.parameters())\n        >>> wide_sch = torch.optim.lr_scheduler.StepLR(wide_opt, step_size=5)\n        >>> deep_sch = torch.optim.lr_scheduler.StepLR(deep_opt, step_size=3)\n        >>> text_sch = torch.optim.lr_scheduler.StepLR(text_opt, step_size=5)\n        >>> img_sch  = torch.optim.lr_scheduler.StepLR(img_opt, step_size=3)\n        >>> optimizers = {\'wide\': wide_opt, \'deepdense\':deep_opt, \'deeptext\':text_opt, \'deepimage\': img_opt}\n        >>> schedulers = {\'wide\': wide_sch, \'deepdense\':deep_sch, \'deeptext\':text_sch, \'deepimage\': img_sch}\n        >>> initializers = {\'wide\': Uniform, \'deepdense\':Normal, \'deeptext\':KaimingNormal,\n        >>> ... \'deepimage\':KaimingUniform}\n        >>> transforms = [ToTensor, Normalize(mean=mean, std=std)]\n        >>> callbacks = [LRHistory, EarlyStopping, ModelCheckpoint(filepath=\'model_weights/wd_out.pt\')]\n        >>> model.compile(method=\'regression\', initializers=initializers, optimizers=optimizers,\n        >>> ... lr_schedulers=schedulers, callbacks=callbacks, transforms=transforms)\n        """"""\n        self.verbose = verbose\n        self.seed = seed\n        self.early_stop = False\n        self.method = method\n        self.with_focal_loss = with_focal_loss\n        if self.with_focal_loss:\n            self.alpha, self.gamma = alpha, gamma\n\n        if isinstance(class_weight, float):\n            self.class_weight = torch.tensor([1.0 - class_weight, class_weight])\n        elif isinstance(class_weight, (tuple, list)):\n            self.class_weight = torch.tensor(class_weight)\n        else:\n            self.class_weight = None\n\n        if initializers is not None:\n            self.initializer = MultipleInitializer(initializers, verbose=self.verbose)\n            self.initializer.apply(self)\n\n        if optimizers is not None:\n            if isinstance(optimizers, Optimizer):\n                self.optimizer: Union[Optimizer, MultipleOptimizer] = optimizers\n            elif len(optimizers) > 1:\n                opt_names = list(optimizers.keys())\n                mod_names = [n for n, c in self.named_children()]\n                for mn in mod_names:\n                    assert mn in opt_names, ""No optimizer found for {}"".format(mn)\n                self.optimizer = MultipleOptimizer(optimizers)\n        else:\n            self.optimizer = torch.optim.AdamW(self.parameters())  # type: ignore\n\n        if lr_schedulers is not None:\n            if isinstance(lr_schedulers, LRScheduler):\n                self.lr_scheduler: Union[\n                    LRScheduler, MultipleLRScheduler\n                ] = lr_schedulers\n                self.cyclic = ""cycl"" in self.lr_scheduler.__class__.__name__.lower()\n            elif len(lr_schedulers) > 1:\n                self.lr_scheduler = MultipleLRScheduler(lr_schedulers)\n                scheduler_names = [\n                    sc.__class__.__name__.lower()\n                    for _, sc in self.lr_scheduler._schedulers.items()\n                ]\n                self.cyclic = any([""cycl"" in sn for sn in scheduler_names])\n        else:\n            self.lr_scheduler, self.cyclic = None, False\n\n        if transforms is not None:\n            self.transforms: MultipleTransforms = MultipleTransforms(transforms)()\n        else:\n            self.transforms = None\n\n        self.history = History()\n        self.callbacks: List = [self.history]\n        if callbacks is not None:\n            for callback in callbacks:\n                if isinstance(callback, type):\n                    callback = callback()\n                self.callbacks.append(callback)\n\n        if metrics is not None:\n            self.metric = MultipleMetrics(metrics)\n            self.callbacks += [MetricCallback(self.metric)]\n        else:\n            self.metric = None\n\n        self.callback_container = CallbackContainer(self.callbacks)\n        self.callback_container.set_model(self)\n\n        if use_cuda:\n            self.cuda()\n\n    def fit(\n        self,\n        X_wide: Optional[np.ndarray] = None,\n        X_deep: Optional[np.ndarray] = None,\n        X_text: Optional[np.ndarray] = None,\n        X_img: Optional[np.ndarray] = None,\n        X_train: Optional[Dict[str, np.ndarray]] = None,\n        X_val: Optional[Dict[str, np.ndarray]] = None,\n        val_split: Optional[float] = None,\n        target: Optional[np.ndarray] = None,\n        n_epochs: int = 1,\n        validation_freq: int = 1,\n        batch_size: int = 32,\n        patience: int = 10,\n        warm_up: bool = False,\n        warm_epochs: int = 4,\n        warm_max_lr: float = 0.01,\n        warm_deeptext_gradual: bool = False,\n        warm_deeptext_max_lr: float = 0.01,\n        warm_deeptext_layers: Optional[List[nn.Module]] = None,\n        warm_deepimage_gradual: bool = False,\n        warm_deepimage_max_lr: float = 0.01,\n        warm_deepimage_layers: Optional[List[nn.Module]] = None,\n        warm_routine: str = ""howard"",\n    ):\n        r""""""\n        fit method that must run after calling \'compile\'\n\n        Parameters\n        ----------\n        X_wide: np.ndarray, Optional. Default=None\n            One hot encoded wide input.\n        X_deep: np.ndarray, Optional. Default=None\n            Input for the deepdense model\n        X_text: np.ndarray, Optional. Default=None\n            Input for the deeptext model\n        X_img : np.ndarray, Optional. Default=None\n            Input for the deepimage model\n        X_train: Dict, Optional. Default=None\n            Training dataset for the different model branches.  Keys are\n            \'X_wide\', \'X_deep\', \'X_text\', \'X_img\' and \'target\' the values are\n            the corresponding matrices e.g X_train = {\'X_wide\': X_wide,\n            \'X_wide\': X_wide, \'X_text\': X_text, \'X_img\': X_img}\n        X_val: Dict, Optional. Default=None\n            Validation dataset for the different model branches.  Keys are\n            \'X_wide\', \'X_deep\', \'X_text\', \'X_img\' and \'target\' the values are\n            the corresponding matrices e.g X_val = {\'X_wide\': X_wide,\n            \'X_wide\': X_wide, \'X_text\': X_text, \'X_img\': X_img}\n        val_split: Float, Optional. Default=None\n            train/val split\n        target: np.ndarray, Optional. Default=None\n            target values\n        n_epochs: Int, Default=1\n        validation_freq: Int, Default=1\n        batch_size: Int, Default=32\n        patience: Int, Default=10\n            Number of epochs without improving the target metric before we\n            stop the fit\n        warm_up: Boolean, Default=False\n            warm_up model components individually before the joined traininga\n        warm_epochs: Int, Default=4\n            Number of warm up epochs for those model componenst that will not\n            be gradually warmed up\n        warm_max_lr: Float, Default=0.01\n            Maximum learning rate during the Triangular Learning rate cycle\n            for those model componenst that will not be gradually warmed up\n        warm_deeptext_gradual: Boolean, Default=False\n            Boolean indicating if the deeptext component will be warmed\n            up gradually\n        warm_deeptext_max_lr: Float, Default=0.01\n            Maximum learning rate during the Triangular Learning rate cycle\n            for the deeptext component\n        warm_deeptext_layers: Optional, List, Default=None\n            List of nn.Modules that will be warmed up gradually. These have to\n            be in \'warm-up-order\': the layers or blocks close to the output\n            neuron(s) first\n        warm_deepimage_gradual: Boolean, Default=False\n            Boolean indicating if the deepimage component will be warmed\n            up gradually\n        warm_deepimage_max_lr: Float, Default=0.01\n            Maximum learning rate during the Triangular Learning rate cycle\n            for the deepimage component\n        warm_deepimage_layers: Optional, List, Default=None\n            List of nn.Modules that will be warmed up gradually. These have to\n            be in \'warm-up-order\': the layers or blocks close to the output\n            neuron(s) first\n        warm_routine: Str, Default=\'felbo\'\n            Warm up routine. On of \'felbo\' or \'howard\'. See the WarmUp class\n            documentation for details\n\n        **WideDeep assumes that X_wide, X_deep and target ALWAYS exist, while\n        X_text and X_img are optional\n        **Either X_train or X_wide, X_deep and target must be passed to the\n        fit method\n\n        Example\n        --------\n        Assuming you have already built and compiled the model\n\n        Ex 1. using train input arrays directly and no validation\n        >>> model.fit(X_wide=X_wide, X_deep=X_deep, target=target, n_epochs=10, batch_size=256)\n\n        Ex 2: using train input arrays directly and validation with val_split\n        >>> model.fit(X_wide=X_wide, X_deep=X_deep, target=target, n_epochs=10, batch_size=256, val_split=0.2)\n\n        Ex 3: using train dict and val_split\n        >>> X_train = {\'X_wide\': X_wide, \'X_deep\': X_deep, \'target\': y}\n        >>> model.fit(X_train, n_epochs=10, batch_size=256, val_split=0.2)\n\n        Ex 4: validation using training and validation dicts\n        >>> X_train = {\'X_wide\': X_wide_tr, \'X_deep\': X_deep_tr, \'target\': y_tr}\n        >>> X_val = {\'X_wide\': X_wide_val, \'X_deep\': X_deep_val, \'target\': y_val}\n        >>> model.fit(X_train=X_train, X_val=X_val n_epochs=10, batch_size=256)\n        """"""\n\n        if X_train is None and (X_wide is None or X_deep is None or target is None):\n            raise ValueError(\n                ""Training data is missing. Either a dictionary (X_train) with ""\n                ""the training dataset or at least 3 arrays (X_wide, X_deep, ""\n                ""target) must be passed to the fit method""\n            )\n\n        self.batch_size = batch_size\n        train_set, eval_set = self._train_val_split(\n            X_wide, X_deep, X_text, X_img, X_train, X_val, val_split, target\n        )\n        train_loader = DataLoader(\n            dataset=train_set, batch_size=batch_size, num_workers=n_cpus\n        )\n        if warm_up:\n            # warm up...\n            self._warm_up(\n                train_loader,\n                warm_epochs,\n                warm_max_lr,\n                warm_deeptext_gradual,\n                warm_deeptext_layers,\n                warm_deeptext_max_lr,\n                warm_deepimage_gradual,\n                warm_deepimage_layers,\n                warm_deepimage_max_lr,\n                warm_routine,\n            )\n        train_steps = len(train_loader)\n        self.callback_container.on_train_begin(\n            {""batch_size"": batch_size, ""train_steps"": train_steps, ""n_epochs"": n_epochs}\n        )\n        if self.verbose:\n            print(""Training"")\n        for epoch in range(n_epochs):\n            # train step...\n            epoch_logs: Dict[str, float] = {}\n            self.callback_container.on_epoch_begin(epoch, logs=epoch_logs)\n            self.train_running_loss = 0.0\n            with trange(train_steps, disable=self.verbose != 1) as t:\n                for batch_idx, (data, target) in zip(t, train_loader):\n                    t.set_description(""epoch %i"" % (epoch + 1))\n                    acc, train_loss = self._training_step(data, target, batch_idx)\n                    if acc is not None:\n                        t.set_postfix(metrics=acc, loss=train_loss)\n                    else:\n                        t.set_postfix(loss=np.sqrt(train_loss))\n                    if self.lr_scheduler:\n                        self._lr_scheduler_step(step_location=""on_batch_end"")\n                    self.callback_container.on_batch_end(batch=batch_idx)\n            epoch_logs[""train_loss""] = train_loss\n            if acc is not None:\n                epoch_logs[""train_acc""] = acc[""acc""]\n            # eval step...\n            if epoch % validation_freq == (validation_freq - 1):\n                if eval_set is not None:\n                    eval_loader = DataLoader(\n                        dataset=eval_set,\n                        batch_size=batch_size,\n                        num_workers=n_cpus,\n                        shuffle=False,\n                    )\n                    eval_steps = len(eval_loader)\n                    self.valid_running_loss = 0.0\n                    with trange(eval_steps, disable=self.verbose != 1) as v:\n                        for i, (data, target) in zip(v, eval_loader):\n                            v.set_description(""valid"")\n                            acc, val_loss = self._validation_step(data, target, i)\n                            if acc is not None:\n                                v.set_postfix(metrics=acc, loss=val_loss)\n                            else:\n                                v.set_postfix(loss=np.sqrt(val_loss))\n                    epoch_logs[""val_loss""] = val_loss\n                    if acc is not None:\n                        epoch_logs[""val_acc""] = acc[""acc""]\n            if self.lr_scheduler:\n                self._lr_scheduler_step(step_location=""on_epoch_end"")\n            # \xc2\xa0log and check if early_stop...\n            self.callback_container.on_epoch_end(epoch, epoch_logs)\n            if self.early_stop:\n                self.callback_container.on_train_end(epoch_logs)\n                break\n            self.callback_container.on_train_end(epoch_logs)\n        self.train()\n\n    def predict(\n        self,\n        X_wide: np.ndarray,\n        X_deep: np.ndarray,\n        X_text: Optional[np.ndarray] = None,\n        X_img: Optional[np.ndarray] = None,\n        X_test: Optional[Dict[str, np.ndarray]] = None,\n    ) -> np.ndarray:\n        r""""""\n        fit method that must run after calling \'compile\'\n\n        Parameters\n        ----------\n        X_wide: np.ndarray, Optional. Default=None\n            One hot encoded wide input.\n        X_deep: np.ndarray, Optional. Default=None\n            Input for the deepdense model\n        X_text: np.ndarray, Optional. Default=None\n            Input for the deeptext model\n        X_img : np.ndarray, Optional. Default=None\n            Input for the deepimage model\n        X_test: Dict, Optional. Default=None\n            Testing dataset for the different model branches.  Keys are\n            \'X_wide\', \'X_deep\', \'X_text\', \'X_img\' and \'target\' the values are\n            the corresponding matrices e.g X_train = {\'X_wide\': X_wide,\n            \'X_wide\': X_wide, \'X_text\': X_text, \'X_img\': X_img}\n\n        **WideDeep assumes that X_wide, X_deep and target ALWAYS exist, while\n        X_text and X_img are optional\n\n        Returns\n        -------\n        preds: np.array with the predicted target for the test dataset.\n        """"""\n        preds_l = self._predict(X_wide, X_deep, X_text, X_img, X_test)\n        if self.method == ""regression"":\n            return np.vstack(preds_l).squeeze(1)\n        if self.method == ""binary"":\n            preds = np.vstack(preds_l).squeeze(1)\n            return (preds > 0.5).astype(""int"")\n        if self.method == ""multiclass"":\n            preds = np.vstack(preds_l)\n            return np.argmax(preds, 1)\n\n    def predict_proba(\n        self,\n        X_wide: np.ndarray,\n        X_deep: np.ndarray,\n        X_text: Optional[np.ndarray] = None,\n        X_img: Optional[np.ndarray] = None,\n        X_test: Optional[Dict[str, np.ndarray]] = None,\n    ) -> np.ndarray:\n        r""""""\n        Returns\n        -------\n        preds: np.ndarray\n            Predicted probabilities of target for the test dataset for  binary\n            and multiclass methods\n        """"""\n        preds_l = self._predict(X_wide, X_deep, X_text, X_img, X_test)\n        if self.method == ""binary"":\n            preds = np.vstack(preds_l).squeeze(1)\n            probs = np.zeros([preds.shape[0], 2])\n            probs[:, 0] = 1 - preds\n            probs[:, 1] = preds\n            return probs\n        if self.method == ""multiclass"":\n            return np.vstack(preds_l)\n\n    def get_embeddings(\n        self, col_name: str, cat_encoding_dict: Dict[str, Dict[str, int]]\n    ) -> Dict[str, np.ndarray]:\n        r""""""\n        Get the learned embeddings for the categorical features passed through deepdense.\n\n        Parameters\n        ----------\n        col_name: str,\n            Column name of the feature we want to get the embeddings for\n        cat_encoding_dict: Dict\n            Categorical encodings. The function is designed to take the\n            \'encoding_dict\' attribute from the DeepPreprocessor class. Any\n            Dict with the same structure can be used\n\n        Returns\n        -------\n        cat_embed_dict: Dict\n            Categorical levels of the col_name feature and the corresponding\n            embeddings\n\n        Example:\n        -------\n        Assuming we have already train the model:\n\n        >>> model.get_embeddings(col_name=\'education\', cat_encoding_dict=deep_preprocessor.encoding_dict)\n        {\'11th\': array([-0.42739448, -0.22282735,  0.36969638,  0.4445322 ,  0.2562272 ,\n        0.11572784, -0.01648579,  0.09027119,  0.0457597 , -0.28337458], dtype=float32),\n         \'HS-grad\': array([-0.10600474, -0.48775527,  0.3444158 ,  0.13818645, -0.16547225,\n        0.27409762, -0.05006042, -0.0668492 , -0.11047247,  0.3280354 ], dtype=float32),\n        ...\n        }\n\n        where:\n\n        >>> deep_preprocessor.encoding_dict[\'education\']\n        {\'11th\': 0, \'HS-grad\': 1, \'Assoc-acdm\': 2, \'Some-college\': 3, \'10th\': 4, \'Prof-school\': 5,\n        \'7th-8th\': 6, \'Bachelors\': 7, \'Masters\': 8, \'Doctorate\': 9, \'5th-6th\': 10, \'Assoc-voc\': 11,\n        \'9th\': 12, \'12th\': 13, \'1st-4th\': 14, \'Preschool\': 15}\n        """"""\n        for n, p in self.named_parameters():\n            if ""embed_layers"" in n and col_name in n:\n                embed_mtx = p.cpu().data.numpy()\n        encoding_dict = cat_encoding_dict[col_name]\n        inv_encoding_dict = {v: k for k, v in encoding_dict.items()}\n        cat_embed_dict = {}\n        for idx, value in inv_encoding_dict.items():\n            cat_embed_dict[value] = embed_mtx[idx]\n        return cat_embed_dict\n\n    def _activation_fn(self, inp: Tensor) -> Tensor:\n        if self.method == ""binary"":\n            return torch.sigmoid(inp)\n        else:\n            # F.cross_entropy will apply logSoftmax to the preds in the case\n            # of \'multiclass\'\n            return inp\n\n    def _loss_fn(self, y_pred: Tensor, y_true: Tensor) -> Tensor:  # type: ignore\n        if self.with_focal_loss:\n            return FocalLoss(self.alpha, self.gamma)(y_pred, y_true)\n        if self.method == ""regression"":\n            return F.mse_loss(y_pred, y_true.view(-1, 1))\n        if self.method == ""binary"":\n            return F.binary_cross_entropy(\n                y_pred, y_true.view(-1, 1), weight=self.class_weight\n            )\n        if self.method == ""multiclass"":\n            return F.cross_entropy(y_pred, y_true, weight=self.class_weight)\n\n    def _train_val_split(\n        self,\n        X_wide: Optional[np.ndarray] = None,\n        X_deep: Optional[np.ndarray] = None,\n        X_text: Optional[np.ndarray] = None,\n        X_img: Optional[np.ndarray] = None,\n        X_train: Optional[Dict[str, np.ndarray]] = None,\n        X_val: Optional[Dict[str, np.ndarray]] = None,\n        val_split: Optional[float] = None,\n        target: Optional[np.ndarray] = None,\n    ):\n        r""""""\n        If a validation set (X_val) is passed to the fit method, or val_split\n        is specified, the train/val split will happen internally. A number of\n        options are allowed in terms of data inputs. For parameter\n        information, please, see the .fit() method documentation\n\n        Returns\n        -------\n        train_set: WideDeepDataset\n            WideDeepDataset object that will be loaded through\n            torch.utils.data.DataLoader\n        eval_set : WideDeepDataset\n            WideDeepDataset object that will be loaded through\n            torch.utils.data.DataLoader\n        """"""\n        # \xc2\xa0Without validation\n        if X_val is None and val_split is None:\n            # if a train dictionary is passed, check if text and image datasets\n            # are present and instantiate the WideDeepDataset class\n            if X_train is not None:\n                X_wide, X_deep, target = (\n                    X_train[""X_wide""],\n                    X_train[""X_deep""],\n                    X_train[""target""],\n                )\n                if ""X_text"" in X_train.keys():\n                    X_text = X_train[""X_text""]\n                if ""X_img"" in X_train.keys():\n                    X_img = X_train[""X_img""]\n            X_train = {""X_wide"": X_wide, ""X_deep"": X_deep, ""target"": target}\n            try:\n                X_train.update({""X_text"": X_text})\n            except:\n                pass\n            try:\n                X_train.update({""X_img"": X_img})\n            except:\n                pass\n            train_set = WideDeepDataset(**X_train, transforms=self.transforms)  # type: ignore\n            eval_set = None\n        # \xc2\xa0With validation\n        else:\n            if X_val is not None:\n                # if a validation dictionary is passed, then if not train\n                # dictionary is passed we build it with the input arrays\n                # (either the dictionary or the arrays must be passed)\n                if X_train is None:\n                    X_train = {""X_wide"": X_wide, ""X_deep"": X_deep, ""target"": target}\n                    if X_text is not None:\n                        X_train.update({""X_text"": X_text})\n                    if X_img is not None:\n                        X_train.update({""X_img"": X_img})\n            else:\n                # if a train dictionary is passed, check if text and image\n                # datasets are present. The train/val split using val_split\n                if X_train is not None:\n                    X_wide, X_deep, target = (\n                        X_train[""X_wide""],\n                        X_train[""X_deep""],\n                        X_train[""target""],\n                    )\n                    if ""X_text"" in X_train.keys():\n                        X_text = X_train[""X_text""]\n                    if ""X_img"" in X_train.keys():\n                        X_img = X_train[""X_img""]\n                (\n                    X_tr_wide,\n                    X_val_wide,\n                    X_tr_deep,\n                    X_val_deep,\n                    y_tr,\n                    y_val,\n                ) = train_test_split(\n                    X_wide,\n                    X_deep,\n                    target,\n                    test_size=val_split,\n                    random_state=self.seed,\n                    stratify=target if self.method != ""regression"" else None,\n                )\n                X_train = {""X_wide"": X_tr_wide, ""X_deep"": X_tr_deep, ""target"": y_tr}\n                X_val = {""X_wide"": X_val_wide, ""X_deep"": X_val_deep, ""target"": y_val}\n                try:\n                    X_tr_text, X_val_text = train_test_split(\n                        X_text,\n                        test_size=val_split,\n                        random_state=self.seed,\n                        stratify=target if self.method != ""regression"" else None,\n                    )\n                    X_train.update({""X_text"": X_tr_text}), X_val.update(\n                        {""X_text"": X_val_text}\n                    )\n                except:\n                    pass\n                try:\n                    X_tr_img, X_val_img = train_test_split(\n                        X_img,\n                        test_size=val_split,\n                        random_state=self.seed,\n                        stratify=target if self.method != ""regression"" else None,\n                    )\n                    X_train.update({""X_img"": X_tr_img}), X_val.update(\n                        {""X_img"": X_val_img}\n                    )\n                except:\n                    pass\n            # At this point the X_train and X_val dictionaries have been built\n            train_set = WideDeepDataset(**X_train, transforms=self.transforms)  # type: ignore\n            eval_set = WideDeepDataset(**X_val, transforms=self.transforms)  # type: ignore\n        return train_set, eval_set\n\n    def _warm_up(\n        self,\n        loader: DataLoader,\n        n_epochs: int,\n        max_lr: float,\n        deeptext_gradual: bool,\n        deeptext_layers: List[nn.Module],\n        deeptext_max_lr: float,\n        deepimage_gradual: bool,\n        deepimage_layers: List[nn.Module],\n        deepimage_max_lr: float,\n        routine: str = ""felbo"",\n    ):\n        r""""""\n        Simple wrappup to individually warm up model components\n        """"""\n        if self.deephead is not None:\n            raise ValueError(\n                ""Currently warming up is only supported without a fully connected \'DeepHead\'""\n            )\n        # This is not the most elegant solution, but is a soluton ""in-between""\n        # a non elegant one and re-factoring the whole code\n        warmer = WarmUp(\n            self._activation_fn, self._loss_fn, self.metric, self.method, self.verbose\n        )\n        warmer.warm_all(self.wide, ""wide"", loader, n_epochs, max_lr)\n        warmer.warm_all(self.deepdense, ""deepdense"", loader, n_epochs, max_lr)\n        if self.deeptext:\n            if deeptext_gradual:\n                warmer.warm_gradual(\n                    self.deeptext,\n                    ""deeptext"",\n                    loader,\n                    deeptext_max_lr,\n                    deeptext_layers,\n                    routine,\n                )\n            else:\n                warmer.warm_all(self.deeptext, ""deeptext"", loader, n_epochs, max_lr)\n        if self.deepimage:\n            if deepimage_gradual:\n                warmer.warm_gradual(\n                    self.deepimage,\n                    ""deepimage"",\n                    loader,\n                    deepimage_max_lr,\n                    deepimage_layers,\n                    routine,\n                )\n            else:\n                warmer.warm_all(self.deepimage, ""deepimage"", loader, n_epochs, max_lr)\n\n    def _lr_scheduler_step(self, step_location: str):\n        r""""""\n        Function to execute the learning rate schedulers steps.\n        If the lr_scheduler is Cyclic (i.e. CyclicLR or OneCycleLR), the step\n        must happen after training each bach durig training. On the other\n        hand, if the  scheduler is not Cyclic, is expected to be called after\n        validation.\n\n        Parameters\n        ----------\n        step_location: Str\n            Indicates where to run the lr_scheduler step\n        """"""\n        if (\n            self.lr_scheduler.__class__.__name__ == ""MultipleLRScheduler""\n            and self.cyclic\n        ):\n            if step_location == ""on_batch_end"":\n                for model_name, scheduler in self.lr_scheduler._schedulers.items():  # type: ignore\n                    if ""cycl"" in scheduler.__class__.__name__.lower():\n                        scheduler.step()  # type: ignore\n            elif step_location == ""on_epoch_end"":\n                for scheduler_name, scheduler in self.lr_scheduler._schedulers.items():  # type: ignore\n                    if ""cycl"" not in scheduler.__class__.__name__.lower():\n                        scheduler.step()  # type: ignore\n        elif self.cyclic:\n            if step_location == ""on_batch_end"":\n                self.lr_scheduler.step()  # type: ignore\n            else:\n                pass\n        elif self.lr_scheduler.__class__.__name__ == ""MultipleLRScheduler"":\n            if step_location == ""on_epoch_end"":\n                self.lr_scheduler.step()  # type: ignore\n            else:\n                pass\n        elif step_location == ""on_epoch_end"":\n            self.lr_scheduler.step()  # type: ignore\n        else:\n            pass\n\n    def _training_step(self, data: Dict[str, Tensor], target: Tensor, batch_idx: int):\n        self.train()\n        X = {k: v.cuda() for k, v in data.items()} if use_cuda else data\n        y = target.float() if self.method != ""multiclass"" else target\n        y = y.cuda() if use_cuda else y\n\n        self.optimizer.zero_grad()\n        y_pred = self._activation_fn(self.forward(X))\n        loss = self._loss_fn(y_pred, y)\n        loss.backward()\n        self.optimizer.step()\n\n        self.train_running_loss += loss.item()\n        avg_loss = self.train_running_loss / (batch_idx + 1)\n\n        if self.metric is not None:\n            acc = self.metric(y_pred, y)\n            return acc, avg_loss\n        else:\n            return None, avg_loss\n\n    def _validation_step(self, data: Dict[str, Tensor], target: Tensor, batch_idx: int):\n\n        self.eval()\n        with torch.no_grad():\n            X = {k: v.cuda() for k, v in data.items()} if use_cuda else data\n            y = target.float() if self.method != ""multiclass"" else target\n            y = y.cuda() if use_cuda else y\n\n            y_pred = self._activation_fn(self.forward(X))\n            loss = self._loss_fn(y_pred, y)\n            self.valid_running_loss += loss.item()\n            avg_loss = self.valid_running_loss / (batch_idx + 1)\n\n        if self.metric is not None:\n            acc = self.metric(y_pred, y)\n            return acc, avg_loss\n        else:\n            return None, avg_loss\n\n    def _predict(\n        self,\n        X_wide: np.ndarray,\n        X_deep: np.ndarray,\n        X_text: Optional[np.ndarray] = None,\n        X_img: Optional[np.ndarray] = None,\n        X_test: Optional[Dict[str, np.ndarray]] = None,\n    ) -> List:\n        r""""""\n        Hidden method to avoid code repetition in predict and predict_proba.\n        For parameter information, please, see the .predict() method\n        documentation\n        """"""\n        if X_test is not None:\n            test_set = WideDeepDataset(**X_test)\n        else:\n            load_dict = {""X_wide"": X_wide, ""X_deep"": X_deep}\n            if X_text is not None:\n                load_dict.update({""X_text"": X_text})\n            if X_img is not None:\n                load_dict.update({""X_img"": X_img})\n            test_set = WideDeepDataset(**load_dict)\n\n        test_loader = DataLoader(\n            dataset=test_set,\n            batch_size=self.batch_size,\n            num_workers=n_cpus,\n            shuffle=False,\n        )\n        test_steps = (len(test_loader.dataset) // test_loader.batch_size) + 1\n\n        self.eval()\n        preds_l = []\n        with torch.no_grad():\n            with trange(test_steps, disable=self.verbose != 1) as t:\n                for i, data in zip(t, test_loader):\n                    t.set_description(""predict"")\n                    X = {k: v.cuda() for k, v in data.items()} if use_cuda else data\n                    preds = self._activation_fn(self.forward(X))\n                    if self.method == ""multiclass"":\n                        preds = F.softmax(preds, dim=1)\n                    preds = preds.cpu().data.numpy()\n                    preds_l.append(preds)\n        self.train()\n        return preds_l\n'"
pytorch_widedeep/optim/__init__.py,0,b'from .radam import RAdam\n'
pytorch_widedeep/optim/radam.py,7,"b'import math\nimport torch\nfrom torch.optim.optimizer import Optimizer\n\n\nclass RAdam(Optimizer):\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n        self.buffer = [[None, None, None] for ind in range(10)]\n        super(RAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(RAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group[""params""]:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError(""RAdam does not support sparse gradients"")\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state[""step""] = 0\n                    state[""exp_avg""] = torch.zeros_like(p_data_fp32)\n                    state[""exp_avg_sq""] = torch.zeros_like(p_data_fp32)\n                else:\n                    state[""exp_avg""] = state[""exp_avg""].type_as(p_data_fp32)\n                    state[""exp_avg_sq""] = state[""exp_avg_sq""].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state[""exp_avg""], state[""exp_avg_sq""]\n                beta1, beta2 = group[""betas""]\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                state[""step""] += 1\n                buffered = self.buffer[int(state[""step""] % 10)]\n                if state[""step""] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state[""step""]\n                    beta2_t = beta2 ** state[""step""]\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state[""step""] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n\n                    # more conservative since it\'s an approximated value\n                    if N_sma >= 5:\n                        step_size = math.sqrt(\n                            (1 - beta2_t)\n                            * (N_sma - 4)\n                            / (N_sma_max - 4)\n                            * (N_sma - 2)\n                            / N_sma\n                            * N_sma_max\n                            / (N_sma_max - 2)\n                        ) / (1 - beta1 ** state[""step""])\n                    else:\n                        step_size = 1.0 / (1 - beta1 ** state[""step""])\n                    buffered[2] = step_size\n\n                if group[""weight_decay""] != 0:\n                    p_data_fp32.add_(-group[""weight_decay""] * group[""lr""], p_data_fp32)\n\n                # more conservative since it\'s an approximated value\n                if N_sma >= 5:\n                    denom = exp_avg_sq.sqrt().add_(group[""eps""])\n                    p_data_fp32.addcdiv_(-step_size * group[""lr""], exp_avg, denom)\n                else:\n                    p_data_fp32.add_(-step_size * group[""lr""], exp_avg)\n\n                p.data.copy_(p_data_fp32)\n\n        return loss\n\n\nclass PlainRAdam(Optimizer):\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n\n        super(PlainRAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(PlainRAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group[""params""]:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError(""RAdam does not support sparse gradients"")\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state[""step""] = 0\n                    state[""exp_avg""] = torch.zeros_like(p_data_fp32)\n                    state[""exp_avg_sq""] = torch.zeros_like(p_data_fp32)\n                else:\n                    state[""exp_avg""] = state[""exp_avg""].type_as(p_data_fp32)\n                    state[""exp_avg_sq""] = state[""exp_avg_sq""].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state[""exp_avg""], state[""exp_avg_sq""]\n                beta1, beta2 = group[""betas""]\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                state[""step""] += 1\n                beta2_t = beta2 ** state[""step""]\n                N_sma_max = 2 / (1 - beta2) - 1\n                N_sma = N_sma_max - 2 * state[""step""] * beta2_t / (1 - beta2_t)\n\n                if group[""weight_decay""] != 0:\n                    p_data_fp32.add_(-group[""weight_decay""] * group[""lr""], p_data_fp32)\n\n                # more conservative since it\'s an approximated value\n                if N_sma >= 5:\n                    step_size = (\n                        group[""lr""]\n                        * math.sqrt(\n                            (1 - beta2_t)\n                            * (N_sma - 4)\n                            / (N_sma_max - 4)\n                            * (N_sma - 2)\n                            / N_sma\n                            * N_sma_max\n                            / (N_sma_max - 2)\n                        )\n                        / (1 - beta1 ** state[""step""])\n                    )\n                    denom = exp_avg_sq.sqrt().add_(group[""eps""])\n                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n                else:\n                    step_size = group[""lr""] / (1 - beta1 ** state[""step""])\n                    p_data_fp32.add_(-step_size, exp_avg)\n\n                p.data.copy_(p_data_fp32)\n\n        return loss\n\n\nclass AdamW(Optimizer):\n    def __init__(\n        self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup=0\n    ):\n        if not 0.0 <= lr:\n            raise ValueError(""Invalid learning rate: {}"".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(""Invalid epsilon value: {}"".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 0: {}"".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(""Invalid beta parameter at index 1: {}"".format(betas[1]))\n\n        defaults = dict(\n            lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, warmup=warmup\n        )\n        super(AdamW, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(AdamW, self).__setstate__(state)\n\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group[""params""]:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError(\n                        ""Adam does not support sparse gradients, please consider SparseAdam instead""\n                    )\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state[""step""] = 0\n                    state[""exp_avg""] = torch.zeros_like(p_data_fp32)\n                    state[""exp_avg_sq""] = torch.zeros_like(p_data_fp32)\n                else:\n                    state[""exp_avg""] = state[""exp_avg""].type_as(p_data_fp32)\n                    state[""exp_avg_sq""] = state[""exp_avg_sq""].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state[""exp_avg""], state[""exp_avg_sq""]\n                beta1, beta2 = group[""betas""]\n\n                state[""step""] += 1\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                denom = exp_avg_sq.sqrt().add_(group[""eps""])\n                bias_correction1 = 1 - beta1 ** state[""step""]\n                bias_correction2 = 1 - beta2 ** state[""step""]\n\n                if group[""warmup""] > state[""step""]:\n                    scheduled_lr = 1e-8 + state[""step""] * group[""lr""] / group[""warmup""]\n                else:\n                    scheduled_lr = group[""lr""]\n\n                step_size = (\n                    scheduled_lr * math.sqrt(bias_correction2) / bias_correction1\n                )\n\n                if group[""weight_decay""] != 0:\n                    p_data_fp32.add_(-group[""weight_decay""] * scheduled_lr, p_data_fp32)\n\n                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n\n                p.data.copy_(p_data_fp32)\n\n        return loss\n'"
pytorch_widedeep/preprocessing/__init__.py,0,b'from ._preprocessors import WidePreprocessor\nfrom ._preprocessors import DeepPreprocessor\nfrom ._preprocessors import TextPreprocessor\nfrom ._preprocessors import ImagePreprocessor\n'
pytorch_widedeep/preprocessing/_preprocessors.py,0,"b'import numpy as np\nimport pandas as pd\nimport warnings\nimport cv2\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.exceptions import NotFittedError\nfrom tqdm import tqdm\n\nfrom ..wdtypes import *\nfrom ..utils.fastai_transforms import Vocab\nfrom ..utils.dense_utils import label_encoder\nfrom ..utils.text_utils import get_texts, pad_sequences, build_embeddings_matrix\nfrom ..utils.image_utils import AspectAwarePreprocessor, SimplePreprocessor\n\n\nclass BasePreprocessor(object):\n    def fit(self, df: pd.DataFrame):\n        raise NotImplementedError(""Preprocessor must implement this method"")\n\n    def transform(self, df: pd.DataFrame):\n        raise NotImplementedError(""Preprocessor must implement this method"")\n\n    def fit_transform(self, df: pd.DataFrame):\n        raise NotImplementedError(""Preprocessor must implement this method"")\n\n\nclass WidePreprocessor(BasePreprocessor):\n    r""""""Preprocessor to prepare the wide input dataset\n\n    Parameters\n    ----------\n    wide_cols: List\n        List with the name of the columns that will be one-hot encoded and\n        pass through the Wide model\n    crossed_cols: List\n        List of Tuples with the name of the columns that will be ""crossed""\n        and then one-hot encoded. e.g. ([\'education\', \'occupation\'], ...)\n    already_dummies: List\n        List of columns that are already dummies/one-hot encoded\n\n    Attributes\n    ----------\n    one_hot_enc: sklearn\'s OneHotEncoder\n    wide_crossed_cols: List\n        List with the names of all columns that will be one-hot encoded\n\n    Example\n    --------\n    Assuming we have a dataset loaded in memory as a pd.DataFrame\n\n    >>> wide_cols = [\'age_buckets\', \'education\', \'relationship\',\'workclass\',\'occupation\',\n    ... \'native_country\',\'gender\']\n    >>> crossed_cols = [(\'education\', \'occupation\'), (\'native_country\', \'occupation\')]\n    >>> wide_preprocessor = WidePreprocessor(wide_cols=wide_cols, crossed_cols=crossed_cols)\n    >>> X_wide = wide_preprocessor.fit_transform(df)\n\n    From there on, for new data (loaded as a dataframe)\n    >>> new_X_wide = wide_preprocessor.transform(new_df)\n    """"""\n\n    def __init__(\n        self,\n        wide_cols: List[str],\n        crossed_cols=None,\n        already_dummies: Optional[List[str]] = None,\n        sparse=False,\n        handle_unknown=""ignore"",\n    ):\n        super(WidePreprocessor, self).__init__()\n        self.wide_cols = wide_cols\n        self.crossed_cols = crossed_cols\n        self.already_dummies = already_dummies\n        self.one_hot_enc = OneHotEncoder(sparse=sparse, handle_unknown=handle_unknown)\n\n    def _cross_cols(self, df: pd.DataFrame):\n        crossed_colnames = []\n        for cols in self.crossed_cols:\n            cols = list(cols)\n            for c in cols:\n                df[c] = df[c].astype(""str"")\n            colname = ""_"".join(cols)\n            df[colname] = df[cols].apply(lambda x: ""-"".join(x), axis=1)\n            crossed_colnames.append(colname)\n        return df, crossed_colnames\n\n    def fit(self, df: pd.DataFrame) -> BasePreprocessor:\n        df_wide = df.copy()[self.wide_cols]\n        if self.crossed_cols is not None:\n            df_wide, crossed_colnames = self._cross_cols(df_wide)\n            self.wide_crossed_cols = self.wide_cols + crossed_colnames\n        else:\n            self.wide_crossed_cols = self.wide_cols\n\n        if self.already_dummies:\n            dummy_cols = [\n                c for c in self.wide_crossed_cols if c not in self.already_dummies\n            ]\n            self.one_hot_enc.fit(df_wide[dummy_cols])\n        else:\n            self.one_hot_enc.fit(df_wide[self.wide_crossed_cols])\n        return self\n\n    def transform(self, df: pd.DataFrame) -> Union[sparse_matrix, np.ndarray]:\n        try:\n            self.one_hot_enc.categories_\n        except:\n            raise NotFittedError(\n                ""This WidePreprocessor instance is not fitted yet. ""\n                ""Call \'fit\' with appropriate arguments before using this estimator.""\n            )\n        df_wide = df.copy()[self.wide_cols]\n        if self.crossed_cols is not None:\n            df_wide, _ = self._cross_cols(df_wide)\n        if self.already_dummies:\n            X_oh_1 = df_wide[self.already_dummies].values\n            dummy_cols = [\n                c for c in self.wide_crossed_cols if c not in self.already_dummies\n            ]\n            X_oh_2 = self.one_hot_enc.transform(df_wide[dummy_cols])\n            return np.hstack((X_oh_1, X_oh_2))\n        else:\n            return self.one_hot_enc.transform(df_wide[self.wide_crossed_cols])\n\n    def fit_transform(self, df: pd.DataFrame) -> Union[sparse_matrix, np.ndarray]:\n        return self.fit(df).transform(df)\n\n\nclass DeepPreprocessor(BasePreprocessor):\n    r""""""Preprocessor to prepare the deepdense input dataset\n\n    Parameters\n    ----------\n    embed_cols: List\n        List containing the name of the columns that will be represented with\n        embeddings or a Tuple with the name and the embedding dimension. e.g.:\n         [(\'education\',32), (\'relationship\',16)\n    continuous_cols: List\n        List with the name of the so called continuous cols\n    scale: Bool\n        Bool indicating whether or not to scale/Standarise continuous cols.\n        Should ""almost always"" be True.\n    default_embed_dim: Int, default=8\n        Dimension for the embeddings used in the Deep-Dense model\n    already_standard: List, Optional,\n        List with the name of the continuous cols that do not need to be\n        Standarised.\n\n    Attributes\n    ----------\n    encoding_dict: Dict\n        Dict with the categorical encoding\n    embed_cols: List\n        List with the columns that will be represented with embeddings\n    embed_dim: Dict\n        Dict where keys are the embed cols and values are the embed dimensions\n    standardize_cols: List\n        List of the columns that will be standarized\n    deep_column_idx: Dict\n        Dict where keys are column names and values are column indexes. This\n        will be neccesary to slice tensors\n    scaler: sklearn\'s StandardScaler\n\n    Example\n    --------\n    Assuming we have a dataset loaded in memory as a pd.DataFrame\n\n    >>> cat_embed_cols = [(\'education\',10), (\'relationship\',8), (\'workclass\',10),\n    ... (\'occupation\',10),(\'native_country\',10)]\n    >>> continuous_cols = [""age"",""hours_per_week""]\n    >>> deep_preprocessor = DeepPreprocessor(embed_cols=cat_embed_cols, continuous_cols=continuous_cols)\n    >>> X_deep = deep_preprocessor.fit_transform(df)\n\n    From there on, for new data (loaded as a dataframe)\n    >>> new_X_deep = deep_preprocessor.transform(new_df)\n    """"""\n\n    def __init__(\n        self,\n        embed_cols: List[Union[str, Tuple[str, int]]] = None,\n        continuous_cols: List[str] = None,\n        scale: bool = True,\n        default_embed_dim: int = 8,\n        already_standard: Optional[List[str]] = None,\n    ):\n        super(DeepPreprocessor, self).__init__()\n\n        self.embed_cols = embed_cols\n        self.continuous_cols = continuous_cols\n        self.already_standard = already_standard\n        self.scale = scale\n        self.default_embed_dim = default_embed_dim\n\n        assert (self.embed_cols is not None) or (\n            self.continuous_cols is not None\n        ), ""\'embed_cols\' and \'continuous_cols\' are \'None\'. Please, define at least one of the two.""\n\n    def _prepare_embed(self, df: pd.DataFrame) -> pd.DataFrame:\n        if isinstance(self.embed_cols[0], tuple):\n            self.embed_dim = dict(self.embed_cols)  # type: ignore\n            embed_colname = [emb[0] for emb in self.embed_cols]\n        else:\n            self.embed_dim = {e: self.default_embed_dim for e in self.embed_cols}  # type: ignore\n            embed_colname = self.embed_cols  # type: ignore\n        return df.copy()[embed_colname]\n\n    def _prepare_continuous(self, df: pd.DataFrame) -> pd.DataFrame:\n        if self.scale:\n            if self.already_standard is not None:\n                self.standardize_cols = [\n                    c for c in self.continuous_cols if c not in self.already_standard\n                ]\n            else:\n                self.standardize_cols = self.continuous_cols\n        return df.copy()[self.continuous_cols]\n\n    def fit(self, df: pd.DataFrame) -> BasePreprocessor:\n        if self.embed_cols is not None:\n            df_emb = self._prepare_embed(df)\n            _, self.encoding_dict = label_encoder(df_emb, cols=df_emb.columns.tolist())\n            self.embeddings_input: List = []\n            for k, v in self.encoding_dict.items():\n                self.embeddings_input.append((k, len(v), self.embed_dim[k]))\n        if self.continuous_cols is not None:\n            df_cont = self._prepare_continuous(df)\n            if self.scale:\n                df_std = df_cont[self.standardize_cols]\n                self.scaler = StandardScaler().fit(df_std.values)\n            else:\n                warnings.warn(""Continuous columns will not be normalised"")\n        return self\n\n    def transform(self, df: pd.DataFrame) -> np.ndarray:\n        if self.embed_cols is not None:\n            df_emb = self._prepare_embed(df)\n            df_emb, _ = label_encoder(\n                df_emb, cols=df_emb.columns.tolist(), val_to_idx=self.encoding_dict\n            )\n        if self.continuous_cols is not None:\n            df_cont = self._prepare_continuous(df)\n            if self.scale:\n                try:\n                    self.scaler.mean_\n                except:\n                    raise NotFittedError(\n                        ""This DeepPreprocessor instance is not fitted yet. ""\n                        ""Call \'fit\' with appropriate arguments before using this estimator.""\n                    )\n                df_std = df_cont[self.standardize_cols]\n                df_cont[self.standardize_cols] = self.scaler.transform(df_std.values)\n        try:\n            df_deep = pd.concat([df_emb, df_cont], axis=1)\n        except:\n            try:\n                df_deep = df_emb.copy()\n            except:\n                df_deep = df_cont.copy()\n        self.deep_column_idx = {k: v for v, k in enumerate(df_deep.columns)}\n        return df_deep.values\n\n    def fit_transform(self, df: pd.DataFrame) -> np.ndarray:\n        return self.fit(df).transform(df)\n\n\nclass TextPreprocessor(BasePreprocessor):\n    r""""""Preprocessor to prepare the deepdense input dataset\n\n    Parameters\n    ----------\n    text_col: str\n        column in the input pd.DataFrame containing the texts\n    max_vocab: Int, default=30000\n        Maximum number of token in the vocabulary\n    min_freq: Int, default=5\n        Minimum frequency for a token to be part of the vocabulary\n    maxlen: Int, default=80\n        Maximum length of the tokenized sequences\n    word_vectors_path: Optional, str\n        Path to the pretrained word vectors\n    verbose: Int, Default 1\n        Enable verbose output.\n\n    Attributes\n    ----------\n    vocab: fastai Vocab object. See https://docs.fast.ai/text.transform.html#Vocab\n        Vocab object containing the information of the vocabulary\n    tokens: List\n        List with Lists of str containing the tokenized texts\n    embedding_matrix: np.ndarray\n        Array with the pretrained embeddings\n\n    Example\n    --------\n    Assuming we have a dataset loaded in memory as a pd.DataFrame\n\n    >>> text_preprocessor = TextPreprocessor()\n    >>> X_text = text_preprocessor.fit_transform(df, text_col)\n\n    from there on\n\n    From there on, for new data (loaded as a dataframe)\n    >>> new_X_text = text_preprocessor.transform(new_df)\n    """"""\n\n    def __init__(\n        self,\n        text_col: str,\n        max_vocab: int = 30000,\n        min_freq: int = 5,\n        maxlen: int = 80,\n        word_vectors_path: Optional[str] = None,\n        verbose: int = 1,\n    ):\n        super(TextPreprocessor, self).__init__()\n        self.text_col = text_col\n        self.max_vocab = max_vocab\n        self.min_freq = min_freq\n        self.maxlen = maxlen\n        self.word_vectors_path = word_vectors_path\n        self.verbose = verbose\n\n    def fit(self, df: pd.DataFrame) -> BasePreprocessor:\n        texts = df[self.text_col].tolist()\n        tokens = get_texts(texts)\n        self.vocab = Vocab.create(\n            tokens, max_vocab=self.max_vocab, min_freq=self.min_freq\n        )\n        return self\n\n    def transform(self, df: pd.DataFrame) -> np.ndarray:\n        try:\n            self.vocab\n        except:\n            raise NotFittedError(\n                ""This TextPreprocessor instance is not fitted yet. ""\n                ""Call \'fit\' with appropriate arguments before using this estimator.""\n            )\n        texts = df[self.text_col].tolist()\n        self.tokens = get_texts(texts)\n        sequences = [self.vocab.numericalize(t) for t in self.tokens]\n        padded_seq = np.array([pad_sequences(s, maxlen=self.maxlen) for s in sequences])\n        if self.verbose:\n            print(""The vocabulary contains {} tokens"".format(len(self.vocab.stoi)))\n        if self.word_vectors_path is not None:\n            self.embedding_matrix = build_embeddings_matrix(\n                self.vocab, self.word_vectors_path, self.min_freq\n            )\n        return padded_seq\n\n    def fit_transform(self, df: pd.DataFrame) -> np.ndarray:\n        return self.fit(df).transform(df)\n\n\nclass ImagePreprocessor(BasePreprocessor):\n    r""""""Preprocessor to prepare the deepdense input dataset\n\n    Parameters\n    ----------\n    img_col: str\n        name of the column with the images filenames\n    img_path: str\n        path to the dicrectory where the images are stored\n    width: Int, default=224\n        width of the resulting processed image. 224 because the default\n        architecture used by WideDeep is ResNet\n    height: Int, default=224\n        width of the resulting processed image. 224 because the default\n        architecture used by WideDeep is ResNet\n    verbose: Int, Default 1\n        Enable verbose output.\n\n    Attributes\n    ----------\n    aap: Class, AspectAwarePreprocessor()\n        Preprocessing tool taken from Adrian Rosebrock\'s book ""Deep Learning\n        for Computer Vision"".\n    spp: Class, SimplePreprocessor()\n        Preprocessing tool taken from Adrian Rosebrock\'s book ""Deep Learning\n        for Computer Vision"".\n    normalise_metrics: Dict\n        Dict containing the normalisation metrics of the image dataset, i.e.\n        mean and std for the R, G and B channels\n\n    Example\n    --------\n    Assuming we have a dataset loaded in memory as a pd.DataFrame\n\n    >>> image_preprocessor = ImagePreprocessor()\n    >>> img_path = \'path/to/my_images\'\n    >>> X_images = image_preprocessor.fit_transform(df, img_col, img_path)\n\n    from there on\n\n    From there on, for new data (loaded as a dataframe)\n    >>> next_X_images = image_preprocessor.transform(new_df)\n    """"""\n\n    def __init__(\n        self,\n        img_col: str,\n        img_path: str,\n        width: int = 224,\n        height: int = 224,\n        verbose: int = 1,\n    ):\n        super(ImagePreprocessor, self).__init__()\n        self.img_col = img_col\n        self.img_path = img_path\n        self.width = width\n        self.height = height\n        self.verbose = verbose\n\n    def fit(self, df: pd.DataFrame) -> BasePreprocessor:\n        self.aap = AspectAwarePreprocessor(self.width, self.height)\n        self.spp = SimplePreprocessor(self.width, self.height)\n        return self\n\n    def transform(self, df: pd.DataFrame) -> np.ndarray:\n        try:\n            self.aap\n        except:\n            raise NotFittedError(\n                ""This ImagePreprocessor instance is not fitted yet. ""\n                ""Call \'fit\' with appropriate arguments before using this estimator.""\n            )\n        image_list = df[self.img_col].tolist()\n        if self.verbose:\n            print(""Reading Images from {}"".format(self.img_path))\n        imgs = [cv2.imread(""/"".join([self.img_path, img])) for img in image_list]\n\n        # finding images with different height and width\n        aspect = [(im.shape[0], im.shape[1]) for im in imgs]\n        aspect_r = [a[0] / a[1] for a in aspect]\n        diff_idx = [i for i, r in enumerate(aspect_r) if r != 1.0]\n\n        if self.verbose:\n            print(""Resizing"")\n        resized_imgs = []\n        for i, img in tqdm(enumerate(imgs), total=len(imgs), disable=self.verbose != 1):\n            if i in diff_idx:\n                resized_imgs.append(self.aap.preprocess(img))\n            else:\n                resized_imgs.append(self.spp.preprocess(img))\n\n        if self.verbose:\n            print(""Computing normalisation metrics"")\n        mean_R, mean_G, mean_B = [], [], []\n        std_R, std_G, std_B = [], [], []\n        for rsz_img in resized_imgs:\n            (mean_b, mean_g, mean_r), (std_b, std_g, std_r) = cv2.meanStdDev(rsz_img)\n            mean_R.append(mean_r)\n            mean_G.append(mean_g)\n            mean_B.append(mean_b)\n            std_R.append(std_r)\n            std_G.append(std_g)\n            std_B.append(std_b)\n        self.normalise_metrics = dict(\n            mean={\n                ""R"": np.mean(mean_R) / 255.0,\n                ""G"": np.mean(mean_G) / 255.0,\n                ""B"": np.mean(mean_B) / 255.0,\n            },\n            std={\n                ""R"": np.mean(std_R) / 255.0,\n                ""G"": np.mean(std_G) / 255.0,\n                ""B"": np.mean(std_B) / 255.0,\n            },\n        )\n        return np.asarray(resized_imgs)\n\n    def fit_transform(self, df: pd.DataFrame) -> np.ndarray:\n        return self.fit(df).transform(df)\n'"
pytorch_widedeep/utils/__init__.py,0,b'from .dense_utils import *\nfrom .text_utils import *\nfrom .fastai_transforms import *\nfrom .image_utils import *\n'
pytorch_widedeep/utils/dense_utils.py,0,"b'import pandas as pd\n\nfrom ..wdtypes import *\n\n\npd.options.mode.chained_assignment = None\n\n\n__all__ = [""label_encoder""]\n\n\ndef label_encoder(\n    df_inp: pd.DataFrame,\n    cols: Optional[List[str]] = None,\n    val_to_idx: Optional[Dict[str, Dict[str, int]]] = None,\n):\n    r""""""\n    Label-encode some features of a given dataset.\n\n    Parameters:\n    -----------\n    df_inp: pd.Dataframe\n        input dataframe\n    cols: List, Optional\n        columns to be label-encoded\n    val_to_idx: Dict, Optional\n        dictionary with the encodings\n\n    Returns:\n    --------\n    df: pd.Dataframe\n        df with Label-encoded features.\n    val_to_idx: Dict\n        Dictionary with the encoding information\n    """"""\n\n    df = df_inp.copy()\n    if cols is None:\n        cols = list(df.select_dtypes(include=[""object""]).columns)\n\n    if not val_to_idx:\n        val_types = dict()\n        for c in cols:  # type: ignore\n            val_types[c] = df[c].unique()\n        val_to_idx = dict()\n        for k, v in val_types.items():\n            val_to_idx[k] = {o: i for i, o in enumerate(val_types[k])}\n\n    for k, v in val_to_idx.items():\n        df[k] = df[k].apply(lambda x: v[x])\n\n    return df, val_to_idx\n'"
pytorch_widedeep/utils/fastai_transforms.py,0,"b'""""""\nNLP data processing; tokenizes text and creates vocab indexes\n\nI have directly COPIED AND PASTE OF THE TRANSFORMS.PY FASTAI LIBRARY.  I only\nneed the Tokenizer and the Vocab classes which are both in this module. This\nway I avoid the numerous fastai dependencies.\n\nCredit for the code here to Jeremy Howard and the fastai team\n""""""\n\nfrom ..wdtypes import *\n\nimport os\nimport re\nimport html\nimport spacy\n\nfrom concurrent.futures.process import ProcessPoolExecutor\nfrom collections import Counter, defaultdict\nfrom spacy.symbols import ORTH\n\n\ndef partition(a: Collection, sz: int) -> List[Collection]:\n    ""Split iterables `a` in equal parts of size `sz`""\n    return [a[i : i + sz] for i in range(0, len(a), sz)]  # type: ignore\n\n\ndef partition_by_cores(a: Collection, n_cpus: int) -> List[Collection]:\n    ""Split data in `a` equally among `n_cpus` cores""\n    return partition(a, len(a) // n_cpus + 1)\n\n\ndef ifnone(a: Any, b: Any) -> Any:\n    ""`a` if `a` is not None, otherwise `b`.""\n    return b if a is None else a\n\n\ndef num_cpus() -> Optional[int]:\n    ""Get number of cpus""\n    try:\n        return len(os.sched_getaffinity(0))\n    except AttributeError:\n        return os.cpu_count()\n\n\n_default_cpus = min(16, num_cpus())\ndefaults = SimpleNamespace(\n    cpus=_default_cpus, cmap=""viridis"", return_fig=False, silent=False\n)\n\n__all__ = [\n    ""BaseTokenizer"",\n    ""SpacyTokenizer"",\n    ""Tokenizer"",\n    ""Vocab"",\n    ""fix_html"",\n    ""replace_all_caps"",\n    ""replace_rep"",\n    ""replace_wrep"",\n    ""rm_useless_spaces"",\n    ""spec_add_spaces"",\n    ""BOS"",\n    ""EOS"",\n    ""FLD"",\n    ""UNK"",\n    ""PAD"",\n    ""TK_MAJ"",\n    ""TK_UP"",\n    ""TK_REP"",\n    ""TK_REP"",\n    ""TK_WREP"",\n    ""deal_caps"",\n]\n\nBOS, EOS, FLD, UNK, PAD = ""xxbos"", ""xxeos"", ""xxfld"", ""xxunk"", ""xxpad""\nTK_MAJ, TK_UP, TK_REP, TK_WREP = ""xxmaj"", ""xxup"", ""xxrep"", ""xxwrep""\ndefaults.text_spec_tok = [UNK, PAD, BOS, EOS, FLD, TK_MAJ, TK_UP, TK_REP, TK_WREP]\n\n\nclass BaseTokenizer:\n    ""Basic class for a tokenizer function.""\n\n    def __init__(self, lang: str):\n        self.lang = lang\n\n    def tokenizer(self, t: str) -> List[str]:\n        return t.split("" "")\n\n    def add_special_cases(self, toks: Collection[str]):\n        pass\n\n\nclass SpacyTokenizer(BaseTokenizer):\n    ""Wrapper around a spacy tokenizer to make it a `BaseTokenizer`.""\n\n    def __init__(self, lang: str):\n        self.tok = spacy.blank(lang, disable=[""parser"", ""tagger"", ""ner""])\n\n    def tokenizer(self, t: str) -> List[str]:\n        return [t.text for t in self.tok.tokenizer(t)]\n\n    def add_special_cases(self, toks: Collection[str]):\n        for w in toks:\n            self.tok.tokenizer.add_special_case(w, [{ORTH: w}])\n\n\ndef spec_add_spaces(t: str) -> str:\n    ""Add spaces around / and # in `t`. \\n""\n    return re.sub(r""([/#\\n])"", r"" \\1 "", t)\n\n\ndef rm_useless_spaces(t: str) -> str:\n    ""Remove multiple spaces in `t`.""\n    return re.sub("" {2,}"", "" "", t)\n\n\ndef replace_rep(t: str) -> str:\n    ""Replace repetitions at the character level in `t`.""\n\n    def _replace_rep(m: Match[str]) -> str:\n        c, cc = m.groups()\n        return f"" {TK_REP} {len(cc)+1} {c} ""\n\n    re_rep = re.compile(r""(\\S)(\\1{3,})"")\n    return re_rep.sub(_replace_rep, t)\n\n\ndef replace_wrep(t: str) -> str:\n    ""Replace word repetitions in `t`.""\n\n    def _replace_wrep(m: Match[str]) -> str:\n        c, cc = m.groups()\n        return f"" {TK_WREP} {len(cc.split())+1} {c} ""\n\n    re_wrep = re.compile(r""(\\b\\w+\\W+)(\\1{3,})"")\n    return re_wrep.sub(_replace_wrep, t)\n\n\ndef fix_html(x: str) -> str:\n    ""List of replacements from html strings in `x`.""\n    re1 = re.compile(r""  +"")\n    x = (\n        x.replace(""#39;"", ""\'"")\n        .replace(""amp;"", ""&"")\n        .replace(""#146;"", ""\'"")\n        .replace(""nbsp;"", "" "")\n        .replace(""#36;"", ""$"")\n        .replace(""\\\\n"", ""\\n"")\n        .replace(""quot;"", ""\'"")\n        .replace(""<br />"", ""\\n"")\n        .replace(\'\\\\""\', \'""\')\n        .replace(""<unk>"", UNK)\n        .replace("" @.@ "", ""."")\n        .replace("" @-@ "", ""-"")\n        .replace("" @,@ "", "","")\n        .replace(""\\\\"", "" \\\\ "")\n    )\n    return re1.sub("" "", html.unescape(x))\n\n\ndef replace_all_caps(x: Collection[str]) -> Collection[str]:\n    ""Replace tokens in ALL CAPS in `x` by their lower version and add `TK_UP` before.""\n    res = []\n    for t in x:\n        if t.isupper() and len(t) > 1:\n            res.append(TK_UP)\n            res.append(t.lower())\n        else:\n            res.append(t)\n    return res\n\n\ndef deal_caps(x: Collection[str]) -> Collection[str]:\n    ""Replace all Capitalized tokens in `x` by their lower version and add `TK_MAJ` before.""\n    res = []\n    for t in x:\n        if t == """":\n            continue\n        if t[0].isupper() and len(t) > 1 and t[1:].islower():\n            res.append(TK_MAJ)\n        res.append(t.lower())\n    return res\n\n\ndefaults.text_pre_rules = [\n    fix_html,\n    replace_rep,\n    replace_wrep,\n    spec_add_spaces,\n    rm_useless_spaces,\n]\ndefaults.text_post_rules = [replace_all_caps, deal_caps]\n\n\nclass Tokenizer:\n    ""Put together rules and a tokenizer function to tokenize text with multiprocessing.""\n\n    def __init__(\n        self,\n        tok_func: Callable = SpacyTokenizer,\n        lang: str = ""en"",\n        pre_rules: ListRules = None,\n        post_rules: ListRules = None,\n        special_cases: Collection[str] = None,\n        n_cpus: int = None,\n    ):\n        self.tok_func, self.lang, self.special_cases = tok_func, lang, special_cases\n        self.pre_rules = ifnone(pre_rules, defaults.text_pre_rules)\n        self.post_rules = ifnone(post_rules, defaults.text_post_rules)\n        self.special_cases = (\n            special_cases if special_cases is not None else defaults.text_spec_tok\n        )\n        self.n_cpus = ifnone(n_cpus, defaults.cpus)\n\n    def __repr__(self) -> str:\n        res = f""Tokenizer {self.tok_func.__name__} in {self.lang} with the following rules:\\n""\n        for rule in self.pre_rules:\n            res += f"" - {rule.__name__}\\n""\n        for rule in self.post_rules:\n            res += f"" - {rule.__name__}\\n""\n        return res\n\n    def process_text(self, t: str, tok: BaseTokenizer) -> List[str]:\n        ""Process one text `t` with tokenizer `tok`.""\n        for rule in self.pre_rules:\n            t = rule(t)\n        toks = tok.tokenizer(t)\n        for rule in self.post_rules:\n            toks = rule(toks)\n        return toks\n\n    def _process_all_1(self, texts: Collection[str]) -> List[List[str]]:\n        ""Process a list of `texts` in one process.""\n        tok = self.tok_func(self.lang)\n        if self.special_cases:\n            tok.add_special_cases(self.special_cases)\n        return [self.process_text(str(t), tok) for t in texts]\n\n    def process_all(self, texts: Collection[str]) -> List[List[str]]:\n        ""Process a list of `texts`.""\n        if self.n_cpus <= 1:\n            return self._process_all_1(texts)\n        with ProcessPoolExecutor(self.n_cpus) as e:\n            return sum(\n                e.map(self._process_all_1, partition_by_cores(texts, self.n_cpus)), []\n            )\n\n\nclass Vocab:\n    ""Contain the correspondence between numbers and tokens and numericalize.""\n\n    def __init__(self, itos: Collection[str]):\n        self.itos = itos\n        self.stoi = defaultdict(int, {v: k for k, v in enumerate(self.itos)})\n\n    def numericalize(self, t: Collection[str]) -> List[int]:\n        ""Convert a list of tokens `t` to their ids.""\n        return [self.stoi[w] for w in t]\n\n    def textify(self, nums: Collection[int], sep="" "") -> List[str]:\n        ""Convert a list of `nums` to their tokens.""\n        return sep.join([self.itos[i] for i in nums]) if sep is not None else [self.itos[i] for i in nums]  # type: ignore\n\n    def __getstate__(self):\n        return {""itos"": self.itos}\n\n    def __setstate__(self, state: dict):\n        self.itos = state[""itos""]\n        self.stoi = defaultdict(int, {v: k for k, v in enumerate(self.itos)})\n\n    def save(self, path):\n        ""Save `self.itos` in `path`""\n        pickle.dump(self.itos, open(path, ""wb""))\n\n    @classmethod\n    def create(cls, tokens: Tokens, max_vocab: int, min_freq: int) -> ""Vocab"":\n        ""Create a vocabulary from a set of `tokens`.""\n        freq = Counter(p for o in tokens for p in o)\n        itos = [o for o, c in freq.most_common(max_vocab) if c >= min_freq]\n        for o in reversed(defaults.text_spec_tok):\n            if o in itos:\n                itos.remove(o)\n            itos.insert(0, o)\n        itos = itos[:max_vocab]\n        if (\n            len(itos) < max_vocab\n        ):  # Make sure vocab size is a multiple of 8 for fast mixed precision training\n            while len(itos) % 8 != 0:\n                itos.append(""xxfake"")\n        return cls(itos)\n\n    @classmethod\n    def load(cls, path):\n        ""Load the `Vocab` contained in `path`""\n        itos = pickle.load(open(path, ""rb""))\n        return cls(itos)\n'"
pytorch_widedeep/utils/image_utils.py,0,"b'""""""\nAspectAwarePreprocessor and SimplePreprocessor are directly taked from the\ngreat series of Books ""Deep Learning for Computer Vision"" by Adrian\n(https://www.pyimagesearch.com/author/adrian/). Check here\nhttps://www.pyimagesearch.com/\n\nCredit for the code here to ADRIAN ROSEBROCK\n""""""\n\nimport numpy as np\nimport imutils\nimport cv2\n\n\n__all__ = [""AspectAwarePreprocessor"", ""SimplePreprocessor""]\n\n\nclass AspectAwarePreprocessor:\n    def __init__(self, width: int, height: int, inter=cv2.INTER_AREA):\n        self.width = width\n        self.height = height\n        self.inter = inter\n\n    def preprocess(self, image: np.ndarray) -> np.ndarray:\n        (h, w) = image.shape[:2]\n        dW = 0\n        dH = 0\n\n        if w < h:\n            image = imutils.resize(image, width=self.width, inter=self.inter)\n            dH = int((image.shape[0] - self.height) / 2.0)\n        else:\n            image = imutils.resize(image, height=self.height, inter=self.inter)\n            dW = int((image.shape[1] - self.width) / 2.0)\n\n        (h, w) = image.shape[:2]\n        image = image[dH : h - dH, dW : w - dW]\n\n        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)\n\n\nclass SimplePreprocessor:\n    def __init__(self, width: int, height: int, inter=cv2.INTER_AREA):\n        self.width = width\n        self.height = height\n        self.inter = inter\n\n    def preprocess(self, image: np.ndarray) -> np.ndarray:\n        return cv2.resize(image, (self.width, self.height), interpolation=self.inter)\n'"
pytorch_widedeep/utils/text_utils.py,0,"b'import numpy as np\nimport os\n\nfrom ..wdtypes import *\nfrom .fastai_transforms import Tokenizer, Vocab\nfrom gensim.utils import tokenize\n\n\n__all__ = [""simple_preprocess"", ""get_texts"", ""pad_sequences"", ""build_embeddings_matrix""]\n\n\ndef simple_preprocess(\n    doc: str,\n    lower: bool = False,\n    deacc: bool = False,\n    min_len: int = 2,\n    max_len: int = 15,\n) -> List[str]:\n    r""""""\n    Gensim\'s simple_preprocess adding a \'lower\' param to indicate wether or not to\n    lower case all the token in the texts\n\n    For more informations see: https://radimrehurek.com/gensim/utils.html\n    """"""\n    tokens = [\n        token\n        for token in tokenize(doc, lower=False, deacc=deacc, errors=""ignore"")\n        if min_len <= len(token) <= max_len and not token.startswith(""_"")\n    ]\n    return tokens\n\n\ndef get_texts(texts: List[str]) -> List[List[str]]:\n    r""""""\n    Uses fastai\'s Tokenizer because it does a series of very convenients things\n    during the tokenization process\n\n    See here: https://docs.fast.ai/text.transform.html#Tokenizer\n    """"""\n    processed_textx = ["" "".join(simple_preprocess(t)) for t in texts]\n    tok = Tokenizer().process_all(processed_textx)\n    return tok\n\n\ndef pad_sequences(\n    seq: List[int], maxlen: int, pad_first: bool = True, pad_idx: int = 1\n) -> List[List[int]]:\n    r""""""\n    Given a List of tokenized and \'numericalised\' sequences it will return padded sequences\n    according to the input parameters maxlen, pad_first and pad_idx\n\n    Parameters\n    ----------\n    seq: List\n        List of int tokens\n    maxlen: Int\n        Maximum length of the padded sequences\n    pad_first: Boolean. Default=True\n        Indicates whether the padding index will be added at the beginning or the\n        end of the sequences\n    pad_idx: Int. Default=1\n        padding index. Fastai\'s Tokenizer leaves 0 for the \'unknown\' token.\n\n    Returns:\n    res: List\n       Padded sequences\n    """"""\n    if len(seq) >= maxlen:\n        res = np.array(seq[-maxlen:]).astype(""int32"")\n        return res\n    else:\n        res = np.zeros(maxlen, dtype=""int32"") + pad_idx\n        if pad_first:\n            res[-len(seq) :] = seq\n        else:\n            res[: len(seq) :] = seq\n        return res\n\n\ndef build_embeddings_matrix(\n    vocab: Vocab, word_vectors_path: str, min_freq: int, verbose: int = 1\n) -> np.ndarray:\n    r""""""\n    Build the embedding matrix using pretrained word vectors\n\n    Parameters\n    ----------\n    vocab: Fastai\'s Vocab object\n        see: https://docs.fast.ai/text.transform.html#Vocab\n    word_vectors_path:str\n        path to the pretrained word embeddings\n    min_freq: Int\n        minimum frequency required for a word to be in the vocabulary\n    verbose: Int. Default=1\n\n    Returns\n    -------\n    embedding_matrix: np.ndarray\n        pretrained word embeddings. If a word in our vocabulary is not among the\n        pretrained embeddings it will be assigned the mean pretrained\n        word-embeddings vector\n    """"""\n    if not os.path.isfile(word_vectors_path):\n        raise FileNotFoundError(""{} not found"".format(word_vectors_path))\n    if verbose:\n        print(""Indexing word vectors..."")\n\n    embeddings_index = {}\n    f = open(word_vectors_path)\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype=""float32"")\n        embeddings_index[word] = coefs\n    f.close()\n\n    if verbose:\n        print(""Loaded {} word vectors"".format(len(embeddings_index)))\n        print(""Preparing embeddings matrix..."")\n\n    mean_word_vector = np.mean(list(embeddings_index.values()), axis=0)\n    embedding_dim = len(list(embeddings_index.values())[0])\n    num_words = len(vocab.itos)\n    embedding_matrix = np.zeros((num_words, embedding_dim))\n    found_words = 0\n    for i, word in enumerate(vocab.itos):\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n            found_words += 1\n        else:\n            embedding_matrix[i] = mean_word_vector\n\n    if verbose:\n        print(\n            ""{} words in the vocabulary had {} vectors and appear more than {} times"".format(\n                found_words, word_vectors_path, min_freq\n            )\n        )\n\n    return embedding_matrix.astype(""float32"")\n'"
tests/test_data_utils/test_du_deep_dense.py,0,"b'import numpy as np\nimport pandas as pd\nimport pytest\n\nfrom pytorch_widedeep.utils.dense_utils import label_encoder\nfrom pytorch_widedeep.preprocessing import DeepPreprocessor\n\n\ndef create_test_dataset(input_type, input_type_2=None):\n    df = pd.DataFrame()\n    col1 = list(np.random.choice(input_type, 3))\n    if input_type_2 is not None:\n        col2 = list(np.random.choice(input_type_2, 3))\n    else:\n        col2 = list(np.random.choice(input_type, 3))\n    df[""col1""], df[""col2""] = col1, col2\n    return df\n\n\nsome_letters = [""a"", ""b"", ""c"", ""d"", ""e""]\nsome_numbers = [1, 2, 3, 4, 5]\n\ndf_letters = create_test_dataset(some_letters)\ndf_numbers = create_test_dataset(some_numbers)\n\n\n###############################################################################\n# Simple test of functionality: testing the label_encoder function\n###############################################################################\ndf_letters_le, letters_enconding_dict = label_encoder(df_letters, [""col1"", ""col2""])\ndf_numbers_le, numbers_enconding_dict = label_encoder(df_numbers, [""col1"", ""col2""])\n\n\n@pytest.mark.parametrize(\n    ""input_df, encoding_dict, output_df"",\n    [\n        (df_letters, letters_enconding_dict, df_letters_le),\n        (df_numbers, numbers_enconding_dict, df_numbers_le),\n    ],\n)\ndef test_label_encoder(input_df, encoding_dict, output_df):\n    tmp_df = input_df.copy()\n    for c in input_df.columns:\n        tmp_df[c] = tmp_df[c].map(encoding_dict[c])\n    assert tmp_df.equals(output_df)\n\n\n################################################################################\n# Same as before but testing functioning when passed a custom encoding dict\n###############################################################################\nencoding_dict_1 = {\n    c: {k: v for v, k in enumerate(sorted(df_letters[c].unique()))}\n    for c in df_letters.columns\n}\nencoding_dict_2 = {\n    c: {k: v for v, k in enumerate(sorted(df_numbers[c].unique()))}\n    for c in df_numbers.columns\n}\n\ndf_letters_le, letters_enconding_dict = label_encoder(\n    df_letters, cols=[""col1"", ""col2""], val_to_idx=encoding_dict_1\n)\ndf_numbers_le, numbers_enconding_dict = label_encoder(\n    df_numbers, cols=[""col1"", ""col2""], val_to_idx=encoding_dict_2\n)\n\n\n@pytest.mark.parametrize(\n    ""input_df, encoding_dict, output_df"",\n    [\n        (df_letters, encoding_dict_1, df_letters_le),\n        (df_numbers, encoding_dict_2, df_numbers_le),\n    ],\n)\ndef test_label_encoder_with_custom_encoder(input_df, encoding_dict, output_df):\n    tmp_df = input_df.copy()\n    for c in input_df.columns:\n        tmp_df[c] = tmp_df[c].map(encoding_dict[c])\n    assert tmp_df.equals(output_df)\n\n\n################################################################################\n# Test the DeepPreprocessor: only categorical columns to be represented with\n# embeddings\n###############################################################################\ncat_embed_cols = [(""col1"", 5), (""col2"", 5)]\n\npreprocessor1 = DeepPreprocessor(cat_embed_cols)\nX_letters = preprocessor1.fit_transform(df_letters)\nembed_input_letters = preprocessor1.embeddings_input\ndecoding_dict_letters = {\n    c: {k: v for v, k in preprocessor1.encoding_dict[c].items()}\n    for c in preprocessor1.encoding_dict.keys()\n}\n\npreprocessor2 = DeepPreprocessor(cat_embed_cols)\nX_numbers = preprocessor2.fit_transform(df_numbers)\nembed_input_numbers = preprocessor2.embeddings_input\ndecoding_dict_numbers = {\n    c: {k: v for v, k in preprocessor2.encoding_dict[c].items()}\n    for c in preprocessor2.encoding_dict.keys()\n}\n\n\nerrors = []\n\n\n@pytest.mark.parametrize(\n    ""input_df, X_deep, embed_input, decoding_dict, error_list"",\n    [\n        (df_letters, X_letters, embed_input_letters, decoding_dict_letters, errors),\n        (df_numbers, X_numbers, embed_input_numbers, decoding_dict_numbers, errors),\n    ],\n)\ndef test_prepare_deep_without_continous_columns(\n    input_df, X_deep, embed_input, decoding_dict, error_list\n):\n    for i, c in enumerate(input_df.columns):\n        if (\n            input_df[c].nunique() != embed_input[i][1]\n            or cat_embed_cols[i][1] != embed_input[i][2]\n        ):\n            error_list.append(\n                ""error: the setup output does not match the intended input""\n            )\n\n    tmp_df = pd.DataFrame({""col1"": X_deep[:, 0], ""col2"": X_deep[:, 1]})\n    for c in input_df.columns:\n        tmp_df[c] = tmp_df[c].map(decoding_dict[c])\n\n    if not tmp_df.equals(input_df):\n        error_list.append(""error: the decoding does not match the encoding"")\n\n    assert not error_list, ""errors occured:\\n{}"".format(""\\n"".join(error_list))\n\n\n################################################################################\n# Test the DeepPreprocessor: only continouos columns\n###############################################################################\ndef test_prepare_deep_without_embedding_columns():\n\n    errors = []\n    df_randint = pd.DataFrame(np.random.choice(np.arange(100), (100, 2)))\n    df_randint.columns = [""col1"", ""col2""]\n    preprocessor3 = DeepPreprocessor(continuous_cols=[""col1"", ""col2""])\n\n    try:\n        X_randint = preprocessor3.fit_transform(df_randint)\n    except:\n        errors.append(""Fundamental Error"")\n\n    out_booleans = []\n\n    means, stds = np.mean(X_randint, axis=0), np.std(X_randint, axis=0)\n    for mean, std in zip(means, stds):\n        out_booleans.append(np.isclose(mean, 0.0))\n        out_booleans.append(np.isclose(std, 1.0))\n\n    if not np.all(out_booleans):\n        errors.append(""There is something going on with the scaler"")\n\n    assert not errors, ""errors occured:\\n{}"".format(""\\n"".join(errors))\n'"
tests/test_data_utils/test_du_deep_image.py,0,"b'import numpy as np\nimport pandas as pd\nimport os\n\nfrom pytorch_widedeep.preprocessing import ImagePreprocessor\n\n\nfull_path = os.path.realpath(__file__)\npath = os.path.split(full_path)[0]\ndf = pd.DataFrame({""galaxies"": [""galaxy1.png"", ""galaxy2.png""]})\nimg_col = ""galaxies""\nimd_dir = os.path.join(path, ""images"")\nprocessor = ImagePreprocessor(img_col=img_col, img_path=imd_dir)\nX_imgs = processor.fit_transform(df)\n\n\n###############################################################################\n# There is not much to test here, since I only resize.\n###############################################################################\ndef test_sizes():\n    img_width = X_imgs.shape[1]\n    img_height = X_imgs.shape[2]\n    assert np.all((img_width == processor.width, img_height == processor.height))\n'"
tests/test_data_utils/test_du_deep_text.py,0,"b'import numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom pytorch_widedeep.preprocessing import TextPreprocessor\n\ntexts = np.random.choice(fetch_20newsgroups().data, 10)\ndf = pd.DataFrame({""texts"": texts})\nprocessor = TextPreprocessor(min_freq=0, text_col=""texts"")\nX_text = processor.fit_transform(df)\n\n\n###############################################################################\n# There is not much to test here. I will simply test that the tokenization and\n# and padding processes went well\n###############################################################################\ndef test_text_processor():\n    idx = int(np.random.choice(np.arange(10), 1))\n\n    original_tokens = processor.tokens[idx]\n    if len(original_tokens) > processor.maxlen:\n        original_tokens = original_tokens[-processor.maxlen :]\n\n    padded_sequence = X_text[idx]\n\n    recovered_tokens = []\n    for t in padded_sequence:\n        if processor.vocab.itos[t] != ""xxpad"":\n            recovered_tokens.append(processor.vocab.itos[t])\n\n    assert np.all([org == recv for org, recv in zip(original_tokens, recovered_tokens)])\n'"
tests/test_data_utils/test_du_wide.py,0,"b'import numpy as np\nimport pandas as pd\nimport pytest\n\nfrom pytorch_widedeep.preprocessing import WidePreprocessor\n\n\ndef create_test_dataset(input_type, with_crossed=True):\n    df = pd.DataFrame()\n    col1 = list(np.random.choice(input_type, 3))\n    col2 = list(np.random.choice(input_type, 3))\n    df[""col1""], df[""col2""] = col1, col2\n    if with_crossed:\n        crossed = [""_"".join([str(c1), str(c2)]) for c1, c2 in zip(col1, col2)]\n        nuniques = df.col1.nunique() + df.col2.nunique() + len(np.unique(crossed))\n    else:\n        nuniques = df.col1.nunique() + df.col2.nunique()\n    return df, nuniques\n\n\nsome_letters = [""a"", ""b"", ""c"", ""d"", ""e""]\nsome_numbers = [1, 2, 3, 4, 5]\n\nwide_cols = [""col1"", ""col2""]\ncross_cols = [(""col1"", ""col2"")]\n\n\n###############################################################################\n# Simple test of functionality making sure the shape match\n###############################################################################\ndf_letters, unique_letters = create_test_dataset(some_letters)\ndf_numbers, unique_numbers = create_test_dataset(some_numbers)\npreprocessor1 = WidePreprocessor(wide_cols, cross_cols)\n\n\n@pytest.mark.parametrize(\n    ""input_df, expected_shape"",\n    [(df_letters, unique_letters), (df_numbers, unique_numbers)],\n)\ndef test_preprocessor1(input_df, expected_shape):\n    wide_mtx = preprocessor1.fit_transform(input_df)\n    assert wide_mtx.shape[1] == expected_shape\n\n\n###############################################################################\n# Same test as before but checking that all works when no passing crossed cols\n###############################################################################\ndf_letters_wo_crossed, unique_letters_wo_crossed = create_test_dataset(\n    some_letters, with_crossed=False\n)\ndf_numbers_wo_crossed, unique_numbers_wo_crossed = create_test_dataset(\n    some_numbers, with_crossed=False\n)\npreprocessor2 = WidePreprocessor(wide_cols)\n\n\n@pytest.mark.parametrize(\n    ""input_df, expected_shape"",\n    [\n        (df_letters_wo_crossed, unique_letters_wo_crossed),\n        (df_numbers_wo_crossed, unique_numbers_wo_crossed),\n    ],\n)\ndef test_prepare_wide_wo_crossed(input_df, expected_shape):\n    wide_mtx = preprocessor2.fit_transform(input_df)\n    assert wide_mtx.shape[1] == expected_shape\n'"
tests/test_model_components/test_mc_deep_dense.py,1,"b'import string\nimport numpy as np\nimport torch\n\nfrom pytorch_widedeep.models import DeepDense\n\n\ncolnames = list(string.ascii_lowercase)[:10]\nembed_cols = [np.random.choice(np.arange(5), 10) for _ in range(5)]\ncont_cols = [np.random.rand(10) for _ in range(5)]\n\nX_deep = torch.from_numpy(np.vstack(embed_cols + cont_cols).transpose())\nX_deep_emb = X_deep[:, :5]\nX_deep_cont = X_deep[:, 5:]\n\n\n###############################################################################\n# Embeddings and NO continuous_cols\n###############################################################################\nembed_input = [(u, i, j) for u, i, j in zip(colnames[:5], [5] * 5, [16] * 5)]\nmodel1 = DeepDense(\n    hidden_layers=[32, 16],\n    dropout=[0.5, 0.2],\n    deep_column_idx={k: v for v, k in enumerate(colnames[:5])},\n    embed_input=embed_input,\n)\n\n\ndef test_deep_dense_embed():\n    out = model1(X_deep_emb)\n    assert out.size(0) == 10 and out.size(1) == 16\n\n\n###############################################################################\n# Continous cols but NO embeddings\n###############################################################################\ncontinuous_cols = colnames[-5:]\nmodel2 = DeepDense(\n    hidden_layers=[32, 16],\n    dropout=[0.5, 0.2],\n    deep_column_idx={k: v for v, k in enumerate(colnames[5:])},\n    continuous_cols=continuous_cols,\n)\n\n\ndef test_deep_dense_cont():\n    out = model2(X_deep_cont)\n    assert out.size(0) == 10 and out.size(1) == 16\n\n\n###############################################################################\n# Continous Cols and Embeddings\n###############################################################################\nmodel3 = DeepDense(\n    hidden_layers=[32, 16],\n    dropout=[0.5, 0.2],\n    deep_column_idx={k: v for v, k in enumerate(colnames)},\n    embed_input=embed_input,\n    continuous_cols=continuous_cols,\n)\n\n\ndef test_deep_dense():\n    out = model3(X_deep)\n    assert out.size(0) == 10 and out.size(1) == 16\n'"
tests/test_model_components/test_mc_deep_image.py,1,"b'import numpy as np\nimport torch\n\nfrom pytorch_widedeep.models import DeepImage\n\nX_images = (torch.from_numpy(np.random.rand(10, 3, 224, 224))).float()\n\n\n###############################################################################\n# Simply testing that it runs with the defaults\n###############################################################################\nmodel1 = DeepImage()\n\n\ndef test_deep_image_1():\n    out = model1(X_images)\n    assert out.size(0) == 10 and out.size(1) == 512\n\n\n###############################################################################\n# Testing with custome backbone\n###############################################################################\nmodel2 = DeepImage(pretrained=False)\n\n\ndef test_deep_image_custom_backbone():\n    out = model2(X_images)\n    assert out.size(0) == 10 and out.size(1) == 512\n\n\n###############################################################################\n# Testing with freeze=\'all\'\n###############################################################################\nmodel3 = DeepImage(freeze=""all"")\n\n\ndef test_deep_image_freeze_all():\n    out = model3(X_images)\n    assert out.size(0) == 10 and out.size(1) == 512\n\n\n###############################################################################\n# Testing with freeze=int\n###############################################################################\nmodel4 = DeepImage(freeze=5)\n\n\ndef test_deep_image_freeze_int():\n    out = model4(X_images)\n    assert out.size(0) == 10 and out.size(1) == 512\n\n\n###############################################################################\n# Testing with resnet 34\n###############################################################################\nmodel5 = DeepImage(resnet=34)\n\n\ndef test_deep_image_resnet_34():\n    out = model5(X_images)\n    assert out.size(0) == 10 and out.size(1) == 512\n\n\n###############################################################################\n# Testing the head\n###############################################################################\nmodel6 = DeepImage(head_layers=[512, 256, 128], head_dropout=[0.0, 0.0])\n\n\ndef test_deep_image_2():\n    out = model6(X_images)\n    assert out.size(0) == 10 and out.size(1) == 128\n'"
tests/test_model_components/test_mc_deep_text.py,3,"b'import numpy as np\nimport torch\nimport pytest\n\nfrom pytorch_widedeep.models import DeepText\n\npadded_sequences = np.random.choice(np.arange(1, 100), (100, 48))\npadded_sequences = np.hstack(\n    (np.repeat(np.array([[0, 0]]), 100, axis=0), padded_sequences)\n)\npretrained_embeddings = np.random.rand(1000, 64).astype(""float32"")\nvocab_size = 1000\n\n\n###############################################################################\n# Without Pretrained Embeddings\n###############################################################################\nmodel1 = DeepText(vocab_size=vocab_size, embed_dim=32, padding_idx=0)\n\n\ndef test_deep_test():\n    out = model1(torch.from_numpy(padded_sequences))\n    assert out.size(0) == 100 and out.size(1) == 64\n\n\n###############################################################################\n# With Pretrained Embeddings\n###############################################################################\nmodel2 = DeepText(\n    vocab_size=vocab_size, embedding_matrix=pretrained_embeddings, padding_idx=0\n)\n\n\ndef test_deep_test_pretrained():\n    out = model2(torch.from_numpy(padded_sequences))\n    assert out.size(0) == 100 and out.size(1) == 64\n\n\n###############################################################################\n# Make sure it throws a warning\n###############################################################################\ndef test_catch_warning():\n    with pytest.warns(UserWarning):\n        model3 = DeepText(\n            vocab_size=vocab_size,\n            embed_dim=32,\n            embedding_matrix=pretrained_embeddings,\n            padding_idx=0,\n        )\n    out = model3(torch.from_numpy(padded_sequences))\n    assert out.size(0) == 100 and out.size(1) == 64\n'"
tests/test_model_components/test_mc_wide.py,1,"b'import torch\n\nfrom pytorch_widedeep.models import Wide\n\ninp = torch.rand(10, 10)\nmodel = Wide(10, 1)\n\n\n###############################################################################\n# Simply testing that it runs\n###############################################################################\ndef test_wide():\n    out = model(inp)\n    assert out.size(0) == 10 and out.size(1) == 1\n'"
tests/test_model_functioning/test_callbacks.py,4,"b'import numpy as np\nimport os\nimport string\nimport torch\nimport pytest\n\nfrom torch.optim.lr_scheduler import StepLR, CyclicLR\nfrom itertools import chain\n\nfrom pytorch_widedeep.models import Wide, DeepDense, WideDeep\nfrom pytorch_widedeep.callbacks import ModelCheckpoint, EarlyStopping, LRHistory\nfrom pytorch_widedeep.optim import RAdam\n\n\n# Wide array\nX_wide = np.random.choice(2, (100, 100), p=[0.8, 0.2])\n\n# Deep Array\ncolnames = list(string.ascii_lowercase)[:10]\nembed_cols = [np.random.choice(np.arange(5), 100) for _ in range(5)]\nembed_input = [(u, i, j) for u, i, j in zip(colnames[:5], [5] * 5, [16] * 5)]\ncont_cols = [np.random.rand(100) for _ in range(5)]\ndeep_column_idx = {k: v for v, k in enumerate(colnames)}\nX_deep = np.vstack(embed_cols + cont_cols).transpose()\n\n# \xc2\xa0Text Array\npadded_sequences = np.random.choice(np.arange(1, 100), (100, 48))\nvocab_size = 1000\nX_text = np.hstack((np.repeat(np.array([[0, 0]]), 100, axis=0), padded_sequences))\n\n# target\ntarget = np.random.choice(2, 100)\n\n\n###############################################################################\n# Test that history saves the information adequately\n###############################################################################\nwide = Wide(100, 1)\ndeepdense = DeepDense(\n    hidden_layers=[32, 16],\n    dropout=[0.5, 0.5],\n    deep_column_idx=deep_column_idx,\n    embed_input=embed_input,\n    continuous_cols=colnames[-5:],\n)\nmodel = WideDeep(wide=wide, deepdense=deepdense)\n\nwide_opt_1 = torch.optim.Adam(model.wide.parameters())\ndeep_opt_1 = torch.optim.Adam(model.deepdense.parameters())\nwide_sch_1 = StepLR(wide_opt_1, step_size=4)\ndeep_sch_1 = CyclicLR(\n    deep_opt_1, base_lr=0.001, max_lr=0.01, step_size_up=10, cycle_momentum=False\n)\noptimizers_1 = {""wide"": wide_opt_1, ""deepdense"": deep_opt_1}\nlr_schedulers_1 = {""wide"": wide_sch_1, ""deepdense"": deep_sch_1}\n\nwide_opt_2 = torch.optim.Adam(model.wide.parameters())\ndeep_opt_2 = RAdam(model.deepdense.parameters())\nwide_sch_2 = StepLR(wide_opt_2, step_size=4)\ndeep_sch_2 = StepLR(deep_opt_2, step_size=4)\noptimizers_2 = {""wide"": wide_opt_2, ""deepdense"": deep_opt_2}\nlr_schedulers_2 = {""wide"": wide_sch_2, ""deepdense"": deep_sch_2}\n\n\n@pytest.mark.parametrize(\n    ""optimizers, schedulers, len_loss_output, len_lr_output"",\n    [(optimizers_1, lr_schedulers_1, 5, 21), (optimizers_2, lr_schedulers_2, 5, 5)],\n)\ndef test_history_callback(optimizers, schedulers, len_loss_output, len_lr_output):\n    model.compile(\n        method=""binary"",\n        optimizers=optimizers,\n        lr_schedulers=schedulers,\n        callbacks=[LRHistory(n_epochs=5)],\n        verbose=0,\n    )\n    model.fit(X_wide=X_wide, X_deep=X_deep, X_text=X_text, target=target, n_epochs=5)\n    out = []\n    out.append(len(model.history._history[""train_loss""]) == len_loss_output)\n    try:\n        lr_list = list(chain.from_iterable(model.lr_history[""lr_deepdense_0""]))\n    except TypeError:\n        lr_list = model.lr_history[""lr_deepdense_0""]\n    out.append(len(lr_list) == len_lr_output)\n    assert all(out)\n\n\n###############################################################################\n# Test that EarlyStopping stops as expected\n###############################################################################\ndef test_early_stop():\n    wide = Wide(100, 1)\n    deepdense = DeepDense(\n        hidden_layers=[32, 16],\n        dropout=[0.5, 0.5],\n        deep_column_idx=deep_column_idx,\n        embed_input=embed_input,\n        continuous_cols=colnames[-5:],\n    )\n    model = WideDeep(wide=wide, deepdense=deepdense)\n    model.compile(\n        method=""binary"",\n        callbacks=[\n            EarlyStopping(\n                min_delta=0.1, patience=3, restore_best_weights=True, verbose=1\n            )\n        ],\n        verbose=1,\n    )\n    model.fit(X_wide=X_wide, X_deep=X_deep, target=target, val_split=0.2, n_epochs=5)\n    # length of history = patience+1\n    assert len(model.history._history[""train_loss""]) == 3 + 1\n\n\n###############################################################################\n# Test that ModelCheckpoint behaves as expected\n###############################################################################\n@pytest.mark.parametrize(\n    ""save_best_only, max_save, n_files"", [(True, 2, 2), (False, 2, 2), (False, 0, 5)]\n)\ndef test_model_checkpoint(save_best_only, max_save, n_files):\n    wide = Wide(100, 1)\n    deepdense = DeepDense(\n        hidden_layers=[32, 16],\n        dropout=[0.5, 0.5],\n        deep_column_idx=deep_column_idx,\n        embed_input=embed_input,\n        continuous_cols=colnames[-5:],\n    )\n    model = WideDeep(wide=wide, deepdense=deepdense)\n    model.compile(\n        method=""binary"",\n        callbacks=[\n            ModelCheckpoint(\n                ""weights/test_weights"", save_best_only=save_best_only, max_save=max_save\n            )\n        ],\n        verbose=0,\n    )\n    model.fit(X_wide=X_wide, X_deep=X_deep, target=target, n_epochs=5, val_split=0.2)\n    n_saved = len(os.listdir(""weights/""))\n    for f in os.listdir(""weights/""):\n        os.remove(""weights/"" + f)\n    assert n_saved <= n_files\n'"
tests/test_model_functioning/test_data_inputs.py,0,"b'import numpy as np\nimport string\nimport pytest\n\nfrom torchvision.transforms import ToTensor, Normalize\nfrom sklearn.model_selection import train_test_split\nfrom pytorch_widedeep.models import Wide, DeepDense, DeepText, DeepImage, WideDeep\n\n# Wide array\nX_wide = np.random.choice(2, (100, 100), p=[0.8, 0.2])\n\n# Deep Array\ncolnames = list(string.ascii_lowercase)[:10]\nembed_cols = [np.random.choice(np.arange(5), 100) for _ in range(5)]\nembed_input = [(u, i, j) for u, i, j in zip(colnames[:5], [5] * 5, [16] * 5)]\ncont_cols = [np.random.rand(100) for _ in range(5)]\nX_deep = np.vstack(embed_cols + cont_cols).transpose()\n\n# \xc2\xa0Text Array\npadded_sequences = np.random.choice(np.arange(1, 100), (100, 48))\nX_text = np.hstack((np.repeat(np.array([[0, 0]]), 100, axis=0), padded_sequences))\nvocab_size = 1000\n\n# \xc2\xa0Image Array\nX_img = np.random.choice(256, (100, 224, 224, 3))\nX_img_norm = X_img / 255.0\n\n# Target\ntarget = np.random.choice(2, 100)\n\n# train/validation split\n(\n    X_wide_tr,\n    X_wide_val,\n    X_deep_tr,\n    X_deep_val,\n    X_text_tr,\n    X_text_val,\n    X_img_tr,\n    X_img_val,\n    y_train,\n    y_val,\n) = train_test_split(X_wide, X_deep, X_text, X_img, target)\n\n# build model components\nwide = Wide(100, 1)\ndeepdense = DeepDense(\n    hidden_layers=[32, 16],\n    dropout=[0.5, 0.5],\n    deep_column_idx={k: v for v, k in enumerate(colnames)},\n    embed_input=embed_input,\n    continuous_cols=colnames[-5:],\n)\ndeeptext = DeepText(vocab_size=vocab_size, embed_dim=32, padding_idx=0)\ndeepimage = DeepImage(pretrained=True)\n\n# transforms\nmean = [0.406, 0.456, 0.485]  # BGR\nstd = [0.225, 0.224, 0.229]  # BGR\ntransforms1 = [ToTensor, Normalize(mean=mean, std=std)]\ntransforms2 = [Normalize(mean=mean, std=std)]\n\n\n##############################################################################\n# Test many possible scenarios of data inputs I can think off. Surely users\n# will input something unexpected\n##############################################################################\n@pytest.mark.parametrize(\n    ""X_wide, X_deep, X_text, X_img, X_train, X_val, target, val_split, transforms, nepoch, null"",\n    [\n        (X_wide, X_deep, X_text, X_img, None, None, target, None, transforms1, 0, None),\n        (X_wide, X_deep, X_text, X_img, None, None, target, None, transforms2, 0, None),\n        (X_wide, X_deep, X_text, X_img, None, None, target, None, None, 0, None),\n        (\n            X_wide,\n            X_deep,\n            X_text,\n            X_img_norm,\n            None,\n            None,\n            target,\n            None,\n            transforms2,\n            0,\n            None,\n        ),\n        (\n            X_wide,\n            X_deep,\n            X_text,\n            X_img_norm,\n            None,\n            None,\n            target,\n            None,\n            transforms1,\n            0,\n            None,\n        ),\n        (X_wide, X_deep, X_text, X_img_norm, None, None, target, None, None, 0, None),\n        (X_wide, X_deep, X_text, X_img, None, None, target, 0.2, None, 0, None),\n        (\n            None,\n            None,\n            None,\n            None,\n            {\n                ""X_wide"": X_wide,\n                ""X_deep"": X_deep,\n                ""X_text"": X_text,\n                ""X_img"": X_img,\n                ""target"": target,\n            },\n            None,\n            None,\n            None,\n            None,\n            0,\n            None,\n        ),\n        (\n            None,\n            None,\n            None,\n            None,\n            {\n                ""X_wide"": X_wide,\n                ""X_deep"": X_deep,\n                ""X_text"": X_text,\n                ""X_img"": X_img,\n                ""target"": target,\n            },\n            None,\n            None,\n            None,\n            transforms1,\n            0,\n            None,\n        ),\n        (\n            None,\n            None,\n            None,\n            None,\n            {\n                ""X_wide"": X_wide,\n                ""X_deep"": X_deep,\n                ""X_text"": X_text,\n                ""X_img"": X_img,\n                ""target"": target,\n            },\n            None,\n            None,\n            0.2,\n            None,\n            0,\n            None,\n        ),\n        (\n            None,\n            None,\n            None,\n            None,\n            {\n                ""X_wide"": X_wide,\n                ""X_deep"": X_deep,\n                ""X_text"": X_text,\n                ""X_img"": X_img,\n                ""target"": target,\n            },\n            None,\n            None,\n            0.2,\n            transforms2,\n            0,\n            None,\n        ),\n        (\n            None,\n            None,\n            None,\n            None,\n            {\n                ""X_wide"": X_wide_tr,\n                ""X_deep"": X_deep_tr,\n                ""X_text"": X_text_tr,\n                ""X_img"": X_img_tr,\n                ""target"": y_train,\n            },\n            {\n                ""X_wide"": X_wide_val,\n                ""X_deep"": X_deep_val,\n                ""X_text"": X_text_val,\n                ""X_img"": X_img_val,\n                ""target"": y_val,\n            },\n            None,\n            None,\n            None,\n            0,\n            None,\n        ),\n        (\n            None,\n            None,\n            None,\n            None,\n            {\n                ""X_wide"": X_wide_tr,\n                ""X_deep"": X_deep_tr,\n                ""X_text"": X_text_tr,\n                ""X_img"": X_img_tr,\n                ""target"": y_train,\n            },\n            {\n                ""X_wide"": X_wide_val,\n                ""X_deep"": X_deep_val,\n                ""X_text"": X_text_val,\n                ""X_img"": X_img_val,\n                ""target"": y_val,\n            },\n            None,\n            None,\n            transforms1,\n            0,\n            None,\n        ),\n    ],\n)\ndef test_widedeep_inputs(\n    X_wide,\n    X_deep,\n    X_text,\n    X_img,\n    X_train,\n    X_val,\n    target,\n    val_split,\n    transforms,\n    nepoch,\n    null,\n):\n    model = WideDeep(\n        wide=wide, deepdense=deepdense, deeptext=deeptext, deepimage=deepimage\n    )\n    model.compile(method=""binary"", transforms=transforms, verbose=0)\n    model.fit(\n        X_wide=X_wide,\n        X_deep=X_deep,\n        X_text=X_text,\n        X_img=X_img,\n        X_train=X_train,\n        X_val=X_val,\n        target=target,\n        val_split=val_split,\n        batch_size=16,\n    )\n    assert (\n        model.history.epoch[0] == nepoch\n        and model.history._history[""train_loss""] is not null\n    )\n'"
tests/test_model_functioning/test_fit_methods.py,0,"b'import numpy as np\nimport string\nimport pytest\n\nfrom pytorch_widedeep.models import Wide, DeepDense, WideDeep\n\n# Wide array\nX_wide = np.random.choice(2, (100, 100), p=[0.8, 0.2])\n\n# Deep Array\ncolnames = list(string.ascii_lowercase)[:10]\nembed_cols = [np.random.choice(np.arange(5), 100) for _ in range(5)]\nembed_input = [(u, i, j) for u, i, j in zip(colnames[:5], [5] * 5, [16] * 5)]\ncont_cols = [np.random.rand(100) for _ in range(5)]\ndeep_column_idx = {k: v for v, k in enumerate(colnames)}\nX_deep = np.vstack(embed_cols + cont_cols).transpose()\n\n# Target\ntarget_regres = np.random.random(100)\ntarget_binary = np.random.choice(2, 100)\ntarget_multic = np.random.choice(3, 100)\n\n# Test dictionary\nX_test = {""X_wide"": X_wide, ""X_deep"": X_deep}\n\n\n##############################################################################\n# Test that the three possible methods (regression, binary and mutliclass)\n# work well\n##############################################################################\n@pytest.mark.parametrize(\n    ""X_wide, X_deep, target, method, X_wide_test, X_deep_test, X_test, output_dim, probs_dim"",\n    [\n        (X_wide, X_deep, target_regres, ""regression"", X_wide, X_deep, None, 1, None),\n        (X_wide, X_deep, target_binary, ""binary"", X_wide, X_deep, None, 1, 2),\n        (X_wide, X_deep, target_multic, ""multiclass"", X_wide, X_deep, None, 3, 3),\n        (X_wide, X_deep, target_regres, ""regression"", None, None, X_test, 1, None),\n        (X_wide, X_deep, target_binary, ""binary"", None, None, X_test, 1, 2),\n        (X_wide, X_deep, target_multic, ""multiclass"", None, None, X_test, 3, 3),\n    ],\n)\ndef test_fit_methods(\n    X_wide,\n    X_deep,\n    target,\n    method,\n    X_wide_test,\n    X_deep_test,\n    X_test,\n    output_dim,\n    probs_dim,\n):\n    wide = Wide(100, output_dim)\n    deepdense = DeepDense(\n        hidden_layers=[32, 16],\n        dropout=[0.5, 0.5],\n        deep_column_idx=deep_column_idx,\n        embed_input=embed_input,\n        continuous_cols=colnames[-5:],\n    )\n    model = WideDeep(wide=wide, deepdense=deepdense, output_dim=output_dim)\n    model.compile(method=method, verbose=0)\n    model.fit(X_wide=X_wide, X_deep=X_deep, target=target)\n    preds = model.predict(X_wide=X_wide, X_deep=X_deep, X_test=X_test)\n    if method == ""binary"":\n        pass\n    else:\n        probs = model.predict_proba(X_wide=X_wide, X_deep=X_deep, X_test=X_test)\n    assert preds.shape[0] == 100, probs.shape[1] == probs_dim\n'"
tests/test_model_functioning/test_focal_loss.py,0,"b'import numpy as np\nimport string\nimport pytest\n\nfrom pytorch_widedeep.models import Wide, DeepDense, WideDeep\n\n# Wide array\nX_wide = np.random.choice(2, (100, 100), p=[0.8, 0.2])\n\n# Deep Array\ncolnames = list(string.ascii_lowercase)[:10]\nembed_cols = [np.random.choice(np.arange(5), 100) for _ in range(5)]\nembed_input = [(u, i, j) for u, i, j in zip(colnames[:5], [5] * 5, [16] * 5)]\ncont_cols = [np.random.rand(100) for _ in range(5)]\ndeep_column_idx = {k: v for v, k in enumerate(colnames)}\nX_deep = np.vstack(embed_cols + cont_cols).transpose()\n\n# Target\ntarget_binary = np.random.choice(2, 100)\ntarget_multic = np.random.choice(3, 100)\n\n\n##############################################################################\n# Test that the model runs with the focal loss\n##############################################################################\n@pytest.mark.parametrize(\n    ""X_wide, X_deep, target, method, output_dim, probs_dim"",\n    [\n        (X_wide, X_deep, target_binary, ""binary"", 1, 2),\n        (X_wide, X_deep, target_multic, ""multiclass"", 3, 3),\n    ],\n)\ndef test_focal_loss(X_wide, X_deep, target, method, output_dim, probs_dim):\n    wide = Wide(100, output_dim)\n    deepdense = DeepDense(\n        hidden_layers=[32, 16],\n        dropout=[0.5, 0.5],\n        deep_column_idx=deep_column_idx,\n        embed_input=embed_input,\n        continuous_cols=colnames[-5:],\n    )\n    model = WideDeep(wide=wide, deepdense=deepdense, output_dim=output_dim)\n    model.compile(method=method, verbose=0, with_focal_loss=True)\n    model.fit(X_wide=X_wide, X_deep=X_deep, target=target)\n    probs = model.predict_proba(X_wide=X_wide, X_deep=X_deep)\n    assert probs.shape[1] == probs_dim\n'"
tests/test_model_functioning/test_initializers.py,2,"b'import numpy as np\nimport string\nimport torch\n\nfrom pytorch_widedeep.models import Wide, DeepDense, DeepText, DeepImage, WideDeep\nfrom pytorch_widedeep.initializers import (\n    XavierNormal,\n    XavierUniform,\n    KaimingNormal,\n    KaimingUniform,\n)\nfrom copy import deepcopy as c\n\n# Wide array\nX_wide = np.random.choice(2, (100, 100), p=[0.8, 0.2])\n\n# Deep Array\ncolnames = list(string.ascii_lowercase)[:10]\nembed_cols = [np.random.choice(np.arange(5), 100) for _ in range(5)]\nembed_input = [(u, i, j) for u, i, j in zip(colnames[:5], [5] * 5, [16] * 5)]\ncont_cols = [np.random.rand(100) for _ in range(5)]\ndeep_column_idx = {k: v for v, k in enumerate(colnames)}\nX_deep = np.vstack(embed_cols + cont_cols).transpose()\n\n# \xc2\xa0Text Array\npadded_sequences = np.random.choice(np.arange(1, 100), (100, 48))\nvocab_size = 1000\nX_text = np.hstack((np.repeat(np.array([[0, 0]]), 100, axis=0), padded_sequences))\n\n# \xc2\xa0Image Array\nX_img = np.random.choice(256, (100, 224, 224, 3))\n\n\n###############################################################################\n# Simply Testing that ""something happens (i.e. in!=out)"" since the stochastic\n# Nature of the most initializers does not allow for more\n###############################################################################\ninitializers_1 = {\n    ""wide"": XavierNormal,\n    ""deepdense"": XavierUniform,\n    ""deeptext"": KaimingNormal,\n    ""deepimage"": KaimingUniform,\n}\ntest_layers_1 = [\n    ""wide.wlinear.weight"",\n    ""deepdense.dense.dense_layer_1.0.weight"",\n    ""deeptext.rnn.weight_hh_l1"",\n    ""deepimage.dilinear.0.weight"",\n]\n\n\ndef test_initializers_1():\n\n    wide = Wide(100, 1)\n    deepdense = DeepDense(\n        hidden_layers=[32, 16],\n        dropout=[0.5, 0.5],\n        deep_column_idx=deep_column_idx,\n        embed_input=embed_input,\n        continuous_cols=colnames[-5:],\n    )\n    deeptext = DeepText(vocab_size=vocab_size, embed_dim=32, padding_idx=0)\n    deepimage = DeepImage(pretrained=True)\n    model = WideDeep(\n        wide=wide,\n        deepdense=deepdense,\n        deeptext=deeptext,\n        deepimage=deepimage,\n        output_dim=1,\n    )\n    cmodel = c(model)\n\n    org_weights = []\n    for n, p in cmodel.named_parameters():\n        if n in test_layers_1:\n            org_weights.append(p)\n\n    model.compile(method=""binary"", verbose=0, initializers=initializers_1)\n    init_weights = []\n    for n, p in model.named_parameters():\n        if n in test_layers_1:\n            init_weights.append(p)\n\n    res = all(\n        [\n            torch.all((1 - (a == b).int()).bool())\n            for a, b in zip(org_weights, init_weights)\n        ]\n    )\n    assert res\n\n\n###############################################################################\n# Make Sure that the ""patterns"" parameter works\n###############################################################################\ninitializers_2 = {\n    ""wide"": XavierNormal,\n    ""deepdense"": XavierUniform,\n    ""deeptext"": KaimingNormal(pattern=r""^(?!.*word_embed).*$""),\n}\n\n\ndef test_initializers_with_pattern():\n\n    wide = Wide(100, 1)\n    deepdense = DeepDense(\n        hidden_layers=[32, 16],\n        dropout=[0.5, 0.5],\n        deep_column_idx=deep_column_idx,\n        embed_input=embed_input,\n        continuous_cols=colnames[-5:],\n    )\n    deeptext = DeepText(vocab_size=vocab_size, embed_dim=32, padding_idx=0)\n    model = WideDeep(wide=wide, deepdense=deepdense, deeptext=deeptext, output_dim=1)\n    cmodel = c(model)\n    org_word_embed = []\n    for n, p in cmodel.named_parameters():\n        if ""word_embed"" in n:\n            org_word_embed.append(p)\n    model.compile(method=""binary"", verbose=0, initializers=initializers_2)\n    init_word_embed = []\n    for n, p in model.named_parameters():\n        if ""word_embed"" in n:\n            init_word_embed.append(p)\n\n    assert torch.all(org_word_embed[0] == init_word_embed[0].cpu())\n'"
tests/test_model_functioning/test_metrics.py,3,"b'import numpy as np\nimport torch\nimport pytest\n\nfrom copy import deepcopy\nfrom pytorch_widedeep.metrics import BinaryAccuracy, CategoricalAccuracy\n\n\ny_true = torch.from_numpy(np.random.choice(2, 100)).float()\ny_pred = deepcopy(y_true.view(-1, 1)).float()\n\n\ndef test_binary_accuracy():\n    metric = BinaryAccuracy()\n    acc = metric(y_pred, y_true)\n    assert acc == 1.0\n\n\n@pytest.mark.parametrize(""top_k, expected_acc"", [(1, 0.33), (2, 0.66)])\ndef test_categorical_accuracy(top_k, expected_acc):\n    y_true = torch.from_numpy(np.random.choice(3, 100))\n    y_pred = torch.from_numpy(np.random.rand(100, 3))\n    metric = CategoricalAccuracy(top_k=top_k)\n    acc = metric(y_pred, y_true)\n    assert np.isclose(acc, expected_acc, atol=0.3)\n'"
tests/test_warm_up/test_warm_up_routines.py,9,"b'import pytest\nimport numpy as np\nimport string\nimport torch\nimport torch.nn.functional as F\n\nfrom torch import nn\nfrom sklearn.utils import Bunch\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom pytorch_widedeep.models import Wide, DeepDense\nfrom pytorch_widedeep.models.deep_image import conv_layer\nfrom pytorch_widedeep.metrics import BinaryAccuracy\nfrom pytorch_widedeep.models._warmup import WarmUp\n\nuse_cuda = torch.cuda.is_available()\n\n\n# Define a series of simple models to quickly test the WarmUp class\nclass TestDeepText(nn.Module):\n    def __init__(self):\n        super(TestDeepText, self).__init__()\n        self.word_embed = nn.Embedding(5, 16, padding_idx=0)\n        self.rnn = nn.LSTM(16, 8, batch_first=True)\n        self.linear = nn.Linear(8, 1)\n\n    def forward(self, X):\n        embed = self.word_embed(X.long())\n        o, (h, c) = self.rnn(embed)\n        return self.linear(h).view(-1, 1)\n\n\nclass TestDeepImage(nn.Module):\n    def __init__(self):\n        super(TestDeepImage, self).__init__()\n\n        self.conv_block = nn.Sequential(\n            conv_layer(3, 64, 3),\n            conv_layer(64, 128, 1, maxpool=False, adaptiveavgpool=True),\n        )\n        self.linear = nn.Linear(128, 1)\n\n    def forward(self, X):\n        x = self.conv_block(X)\n        x = x.view(x.size(0), -1)\n        return self.linear(x)\n\n\n# \xc2\xa0Define a simple WideDeep Dataset\nclass WDset(Dataset):\n    def __init__(self, X_wide, X_deep, X_text, X_img, target):\n\n        self.X_wide = X_wide\n        self.X_deep = X_deep\n        self.X_text = X_text\n        self.X_img = X_img\n        self.Y = target\n\n    def __getitem__(self, idx: int):\n\n        X = Bunch(wide=self.X_wide[idx])\n        X.deepdense = self.X_deep[idx]\n        X.deeptext = self.X_text[idx]\n        X.deepimage = self.X_img[idx]\n        y = self.Y[idx]\n        return X, y\n\n    def __len__(self):\n        return len(self.X_deep)\n\n\n# Remember that the WarmUp class will be instantiated inside the WideDeep and\n# will take, among others, the activation_fn and the loss_fn of that class as\n# parameters. Therefore, we define equivalent classes to replicate the\n# scenario\ndef activ_fn(inp):\n    return torch.sigmoid(inp)\n\n\ndef loss_fn(y_pred, y_true):\n    return F.binary_cross_entropy(y_pred, y_true.view(-1, 1))\n\n\n# \xc2\xa0Define the data components:\n\n# target\ntarget = torch.empty(100, 1).random_(0, 2)\n\n# wide\nX_wide = torch.empty(100, 10).random_(0, 2)\n\n# deep\ncolnames = list(string.ascii_lowercase)[:10]\nembed_cols = [np.random.choice(np.arange(5), 100) for _ in range(5)]\ncont_cols = [np.random.rand(100) for _ in range(5)]\nembed_input = [(u, i, j) for u, i, j in zip(colnames[:5], [5] * 5, [16] * 5)]\ndeep_column_idx = {k: v for v, k in enumerate(colnames[:10])}\ncontinuous_cols = colnames[-5:]\nX_deep = torch.from_numpy(np.vstack(embed_cols + cont_cols).transpose())\n\n# text\nX_text = torch.cat((torch.zeros([100, 1]), torch.empty(100, 4).random_(1, 4)), axis=1)\n\n# image\nX_image = torch.rand(100, 3, 28, 28)\n\n# Define the model components\n\n# wide\nwide = Wide(10, 1)\nif use_cuda:\n    wide.cuda()\n\n# deep\ndeepdense = DeepDense(\n    hidden_layers=[16, 8],\n    dropout=[0.5, 0.2],\n    deep_column_idx=deep_column_idx,\n    embed_input=embed_input,\n    continuous_cols=continuous_cols,\n)\ndeepdense = nn.Sequential(deepdense, nn.Linear(8, 1))\nif use_cuda:\n    deepdense.cuda()\n\n# text\ndeeptext = TestDeepText()\nif use_cuda:\n    deeptext.cuda()\n\n# image\ndeepimage = TestDeepImage()\nif use_cuda:\n    deepimage.cuda()\n\n# Define the loader\nwdset = WDset(X_wide, X_deep, X_text, X_image, target)\nwdloader = DataLoader(wdset, batch_size=10, shuffle=True)\n\n# Instantiate the WarmUp class\nwarmer = WarmUp(activ_fn, loss_fn, BinaryAccuracy(), ""binary"", False)\n\n# List the layers for the warm_gradual method\ntext_layers = [c for c in list(deeptext.children())[1:]][::-1]\nimage_layers = [c for c in list(deepimage.children())][::-1]\n\n\n###############################################################################\n# \xc2\xa0Simply test that warm_all runs\n###############################################################################\n@pytest.mark.parametrize(\n    ""model, modelname, loader, n_epochs, max_lr"",\n    [\n        (wide, ""wide"", wdloader, 1, 0.01),\n        (deepdense, ""deepdense"", wdloader, 1, 0.01),\n        (deeptext, ""deeptext"", wdloader, 1, 0.01),\n        (deepimage, ""deepimage"", wdloader, 1, 0.01),\n    ],\n)\ndef test_warm_all(model, modelname, loader, n_epochs, max_lr):\n    has_run = True\n    try:\n        warmer.warm_all(model, modelname, loader, n_epochs, max_lr)\n    except:\n        has_run = False\n    assert has_run\n\n\n###############################################################################\n# \xc2\xa0Simply test that warm_gradual runs\n###############################################################################\n@pytest.mark.parametrize(\n    ""model, modelname, loader, max_lr, layers, routine"",\n    [\n        (deeptext, ""deeptext"", wdloader, 0.01, text_layers, ""felbo""),\n        (deeptext, ""deeptext"", wdloader, 0.01, text_layers, ""howard""),\n        (deepimage, ""deepimage"", wdloader, 0.01, image_layers, ""felbo""),\n        (deepimage, ""deepimage"", wdloader, 0.01, image_layers, ""howard""),\n    ],\n)\ndef test_warm_gradual(model, modelname, loader, max_lr, layers, routine):\n    has_run = True\n    try:\n        warmer.warm_gradual(model, modelname, loader, max_lr, layers, routine)\n    except:\n        has_run = False\n    assert has_run\n'"
