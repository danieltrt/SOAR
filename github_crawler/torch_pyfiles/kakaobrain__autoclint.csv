file_path,api_count,code
model.py,28,"b""# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport os\nimport threading\nimport random\n\nimport tensorflow as tf\nimport torch\nimport torchvision as tv\nimport numpy as np\n\nimport skeleton\nfrom architectures.resnet import ResNet18\nfrom skeleton.projects import LogicModel, get_logger\nfrom skeleton.projects.others import NBAC, AUC\n\n\ntorch.backends.cudnn.benchmark = True\nthreads = [\n    threading.Thread(target=lambda: torch.cuda.synchronize()),\n    threading.Thread(target=lambda: tf.Session())\n]\n[t.start() for t in threads]\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nLOGGER = get_logger(__name__)\n\n\ndef set_random_seed_all(seed, deterministic=False):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    tf.random.set_random_seed(seed)\n    if deterministic:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\n\nclass Model(LogicModel):\n    def __init__(self, metadata):\n        # set_random_seed_all(0xC0FFEE)\n        super(Model, self).__init__(metadata)\n        self.use_test_time_augmentation = False\n        self.update_transforms = False\n\n    def build(self):\n        base_dir = os.path.dirname(os.path.abspath(__file__))\n        in_channels = self.info['dataset']['shape'][-1]\n        num_class = self.info['dataset']['num_class']\n        # torch.cuda.synchronize()\n\n        LOGGER.info('[init] session')\n        [t.join() for t in threads]\n\n        self.device = torch.device('cuda', 0)\n        self.session = tf.Session()\n\n        LOGGER.info('[init] Model')\n        Network = ResNet18  # ResNet18  # BasicNet, SENet18, ResNet18\n        self.model = Network(in_channels, num_class)\n        self.model_pred = Network(in_channels, num_class).eval()\n        # torch.cuda.synchronize()\n\n        LOGGER.info('[init] weight initialize')\n        if Network in [ResNet18]:\n            model_path = os.path.join(base_dir, 'models')\n            LOGGER.info('model path: %s', model_path)\n\n            self.model.init(model_dir=model_path, gain=1.0)\n        else:\n            self.model.init(gain=1.0)\n        # torch.cuda.synchronize()\n\n        LOGGER.info('[init] copy to device')\n        self.model = self.model.to(device=self.device, non_blocking=True) #.half()\n        self.model_pred = self.model_pred.to(device=self.device, non_blocking=True) #.half()\n        self.is_half = self.model._half\n        # torch.cuda.synchronize()\n\n        LOGGER.info('[init] done.')\n\n    def update_model(self):\n        num_class = self.info['dataset']['num_class']\n\n        epsilon = min(0.1, max(0.001, 0.001 * pow(num_class / 10, 2)))\n        if self.is_multiclass():\n            self.model.loss_fn = torch.nn.BCEWithLogitsLoss(reduction='none')\n            # self.model.loss_fn = skeleton.nn.BinaryCrossEntropyLabelSmooth(num_class, epsilon=epsilon, reduction='none')\n            self.tau = 8.0\n            LOGGER.info('[update_model] %s (tau:%f, epsilon:%f)', self.model.loss_fn.__class__.__name__, self.tau, epsilon)\n        else:\n            self.model.loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n            # self.model.loss_fn = skeleton.nn.CrossEntropyLabelSmooth(num_class, epsilon=epsilon)\n            self.tau = 8.0\n            LOGGER.info('[update_model] %s (tau:%f, epsilon:%f)', self.model.loss_fn.__class__.__name__, self.tau, epsilon)\n        self.model_pred.loss_fn = self.model.loss_fn\n\n        if self.is_video():\n            # not use fast auto aug\n            self.hyper_params['conditions']['use_fast_auto_aug'] = False\n            times = self.hyper_params['dataset']['input'][0]\n            self.model.set_video(times=times)\n            self.model_pred.set_video(times=times)\n\n        self.init_opt()\n        LOGGER.info('[update] done.')\n\n    def init_opt(self):\n        steps_per_epoch = self.hyper_params['dataset']['steps_per_epoch']\n        batch_size = self.hyper_params['dataset']['batch_size']\n\n        params = [p for p in self.model.parameters() if p.requires_grad]\n        params_fc = [p for n, p in self.model.named_parameters() if p.requires_grad and 'fc' == n[:2] or 'conv1d' == n[:6]]\n\n        init_lr = self.hyper_params['optimizer']['lr']\n        warmup_multiplier = 2.0\n        lr_multiplier = max(0.5, batch_size / 32)\n        scheduler_lr = skeleton.optim.get_change_scale(\n            skeleton.optim.gradual_warm_up(\n                skeleton.optim.get_reduce_on_plateau_scheduler(\n                    init_lr * lr_multiplier / warmup_multiplier,\n                    patience=10, factor=.5, metric_name='train_loss'\n                ),\n                warm_up_epoch=5,\n                multiplier=warmup_multiplier\n            ),\n            init_scale=1.0\n        )\n        self.optimizer_fc = skeleton.optim.ScheduledOptimizer(\n            params_fc,\n            torch.optim.SGD,\n            # skeleton.optim.SGDW,\n            steps_per_epoch=steps_per_epoch,\n            clip_grad_max_norm=None,\n            lr=scheduler_lr,\n            momentum=0.9,\n            weight_decay=0.00025,\n            nesterov=True\n        )\n        self.optimizer = skeleton.optim.ScheduledOptimizer(\n            params,\n            torch.optim.SGD,\n            # skeleton.optim.SGDW,\n            steps_per_epoch=steps_per_epoch,\n            clip_grad_max_norm=None,\n            lr=scheduler_lr,\n            momentum=0.9,\n            weight_decay=0.00025,\n            nesterov=True\n        )\n        LOGGER.info('[optimizer] %s (batch_size:%d)', self.optimizer._optimizer.__class__.__name__, batch_size)\n\n    def adapt(self, remaining_time_budget=None):\n        epoch = self.info['loop']['epoch']\n        input_shape = self.hyper_params['dataset']['input']\n        height, width = input_shape[:2]\n        batch_size = self.hyper_params['dataset']['batch_size']\n\n        train_score = np.average([c['train']['score'] for c in self.checkpoints[-5:]])\n        valid_score = np.average([c['valid']['score'] for c in self.checkpoints[-5:]])\n        LOGGER.info('[adapt] [%04d/%04d] train:%.3f valid:%.3f',\n                    epoch, self.hyper_params['dataset']['max_epoch'],\n                    train_score, valid_score)\n\n        self.use_test_time_augmentation = self.info['loop']['test'] > 1\n\n        if self.hyper_params['conditions']['use_fast_auto_aug']:\n            self.hyper_params['conditions']['use_fast_auto_aug'] = valid_score < 0.995\n\n        # Adapt Apply Fast auto aug\n        if self.hyper_params['conditions']['use_fast_auto_aug'] and \\\n                (train_score > 0.995 or self.info['terminate']) and \\\n                remaining_time_budget > 120 and \\\n                valid_score > 0.01 and \\\n                self.dataloaders['valid'] is not None and \\\n                not self.update_transforms:\n            LOGGER.info('[adapt] search fast auto aug policy')\n            self.update_transforms = True\n            self.info['terminate'] = True\n\n            original_valid_policy = self.dataloaders['valid'].dataset.transform.transforms\n            policy = skeleton.data.augmentations.autoaug_policy()\n\n            num_policy_search = 100\n            num_sub_policy = 3\n            num_select_policy = 5\n            searched_policy = []\n            for policy_search in range(num_policy_search):\n                selected_idx = np.random.choice(list(range(len(policy))), num_sub_policy)\n                selected_policy = [policy[i] for i in selected_idx]\n\n                self.dataloaders['valid'].dataset.transform.transforms = original_valid_policy + [\n                    lambda t: t.cpu().float() if isinstance(t, torch.Tensor) else torch.Tensor(t),\n                    tv.transforms.ToPILImage(),\n                    skeleton.data.augmentations.Augmentation(\n                        selected_policy\n                    ),\n                    tv.transforms.ToTensor(),\n                    lambda t: t.to(device=self.device) #.half()\n                ]\n\n                metrics = []\n                for policy_eval in range(num_sub_policy * 2):\n                    valid_dataloader = self.build_or_get_dataloader('valid', self.datasets['valid'], self.datasets['num_valids'])\n                    # original_valid_batch_size = valid_dataloader.batch_sampler.batch_size\n                    # valid_dataloader.batch_sampler.batch_size = batch_size\n\n                    valid_metrics = self.epoch_valid(self.info['loop']['epoch'], valid_dataloader, reduction='max')\n\n                    # valid_dataloader.batch_sampler.batch_size = original_valid_batch_size\n                    metrics.append(valid_metrics)\n                loss = np.max([m['loss'] for m in metrics])\n                score = np.max([m['score'] for m in metrics])\n                LOGGER.info('[adapt] [FAA] [%02d/%02d] score: %f, loss: %f, selected_policy: %s',\n                            policy_search, num_policy_search, score, loss, selected_policy)\n\n                searched_policy.append({\n                    'loss': loss,\n                    'score': score,\n                    'policy': selected_policy\n                })\n\n            flatten = lambda l: [item for sublist in l for item in sublist]\n\n            # filtered valid score\n            searched_policy = [p for p in searched_policy if p['score'] > valid_score]\n\n            if len(searched_policy) > 0:\n                policy_sorted_index = np.argsort([p['score'] for p in searched_policy])[::-1][:num_select_policy]\n                # policy_sorted_index = np.argsort([p['loss'] for p in searched_policy])[:num_select_policy]\n                policy = flatten([searched_policy[idx]['policy'] for idx in policy_sorted_index])\n                policy = skeleton.data.augmentations.remove_duplicates(policy)\n\n                LOGGER.info('[adapt] [FAA] scores: %s', [searched_policy[idx]['score'] for idx in policy_sorted_index])\n\n                original_train_policy = self.dataloaders['train'].dataset.transform.transforms\n                self.dataloaders['train'].dataset.transform.transforms = original_train_policy + [\n                    lambda t: t.cpu().float() if isinstance(t, torch.Tensor) else torch.Tensor(t),\n                    tv.transforms.ToPILImage(),\n                    skeleton.data.augmentations.Augmentation(\n                        policy\n                    ),\n                    tv.transforms.ToTensor(),\n                    lambda t: t.to(device=self.device) #.half()\n                ]\n\n            self.dataloaders['valid'].dataset.transform.transforms = original_valid_policy\n\n            # reset optimizer pararms\n            # self.model.init()\n            self.hyper_params['optimizer']['lr'] /= 2.0\n            self.init_opt()\n            self.hyper_params['conditions']['max_inner_loop_ratio'] *= 3\n            self.hyper_params['conditions']['threshold_valid_score_diff'] = 0.00001\n            self.hyper_params['conditions']['min_lr'] = 1e-8\n\n    def activation(self, logits):\n        if self.is_multiclass():\n            logits = torch.sigmoid(logits)\n            prediction = (logits > 0.5).to(logits.dtype)\n        else:\n            logits = torch.softmax(logits, dim=-1)\n            _, k = logits.max(-1)\n            prediction = torch.zeros(logits.shape, dtype=logits.dtype, device=logits.device).scatter_(-1, k.view(-1, 1), 1.0)\n        return logits, prediction\n\n    def epoch_train(self, epoch, train, model=None, optimizer=None):\n        model = model if model is not None else self.model\n        if epoch < 0:\n            optimizer = optimizer if optimizer is not None else self.optimizer_fc\n        else:\n            optimizer = optimizer if optimizer is not None else self.optimizer\n        #optimizer = optimizer if optimizer is not None else self.optimizer\n\n        # batch_size = self.hyper_params['dataset']['batch_size']\n        model.train()\n        model.zero_grad()\n\n        num_steps = len(train)\n        metrics = []\n        for step, (examples, labels) in enumerate(train):\n            if examples.shape[0] == 1:\n                examples = examples[0]\n                labels = labels[0]\n            original_labels = labels\n            if not self.is_multiclass():\n                labels = labels.argmax(dim=-1)\n\n            skeleton.nn.MoveToHook.to((examples, labels), self.device, self.is_half)\n            logits, loss = model(examples, labels, tau=self.tau, reduction='avg')\n            loss = loss.sum()\n            loss.backward()\n\n            max_epoch = self.hyper_params['dataset']['max_epoch']\n            optimizer.update(maximum_epoch=max_epoch)\n            optimizer.step()\n            model.zero_grad()\n\n            logits, prediction = self.activation(logits.float())\n            tpr, tnr, nbac = NBAC(prediction, original_labels.float())\n            auc = AUC(logits, original_labels.float())\n\n            score = auc if self.hyper_params['conditions']['score_type'] == 'auc' else float(nbac.detach().float())\n            metrics.append({\n                'loss': loss.detach().float().cpu(),\n                'score': score,\n            })\n\n            LOGGER.debug(\n                '[train] [%02d] [%03d/%03d] loss:%.6f AUC:%.3f NBAC:%.3f tpr:%.3f tnr:%.3f, lr:%.8f',\n                epoch, step, num_steps, loss, auc, nbac, tpr, tnr,\n                optimizer.get_learning_rate()\n            )\n\n        train_loss = np.average([m['loss'] for m in metrics])\n        train_score = np.average([m['score'] for m in metrics])\n        optimizer.update(train_loss=train_loss)\n\n        return {\n            'loss': train_loss,\n            'score': train_score,\n        }\n\n    def epoch_valid(self, epoch, valid, reduction='avg'):\n        test_time_augmentation = False\n        self.model.eval()\n        num_steps = len(valid)\n        metrics = []\n        tau = self.tau\n\n        with torch.no_grad():\n            for step, (examples, labels) in enumerate(valid):\n                original_labels = labels\n                if not self.is_multiclass():\n                    labels = labels.argmax(dim=-1)\n\n                batch_size = examples.size(0)\n\n                # Test-Time Augment flip\n                if self.use_test_time_augmentation and test_time_augmentation:\n                    examples = torch.cat([examples, torch.flip(examples, dims=[-1])], dim=0)\n                    labels = torch.cat([labels, labels], dim=0)\n\n                # skeleton.nn.MoveToHook.to((examples, labels), self.device, self.is_half)\n                logits, loss = self.model(examples, labels, tau=tau, reduction=reduction)\n\n                # avergae\n                if self.use_test_time_augmentation and test_time_augmentation:\n                    logits1, logits2 = torch.split(logits, batch_size, dim=0)\n                    logits = (logits1 + logits2) / 2.0\n\n                logits, prediction = self.activation(logits.float())\n                tpr, tnr, nbac = NBAC(prediction, original_labels.float())\n                if reduction == 'avg':\n                    auc = AUC(logits, original_labels.float())\n                else:\n                    auc = max([AUC(logits[i:i+16], original_labels[i:i+16].float()) for i in range(int(len(logits)) // 16)])\n\n                score = auc if self.hyper_params['conditions']['score_type'] == 'auc' else float(nbac.detach().float())\n                metrics.append({\n                    'loss': loss.detach().float().cpu(),\n                    'score': score,\n                })\n\n                LOGGER.debug(\n                    '[valid] [%02d] [%03d/%03d] loss:%.6f AUC:%.3f NBAC:%.3f tpr:%.3f tnr:%.3f, lr:%.8f',\n                    epoch, step, num_steps, loss, auc, nbac, tpr, tnr,\n                    self.optimizer.get_learning_rate()\n                )\n            if reduction == 'avg':\n                valid_loss = np.average([m['loss'] for m in metrics])\n                valid_score = np.average([m['score'] for m in metrics])\n            elif reduction in ['min', 'max']:\n                valid_loss = np.min([m['loss'] for m in metrics])\n                valid_score = np.max([m['score'] for m in metrics])\n            else:\n                raise Exception('not support reduction method: %s' % reduction)\n        self.optimizer.update(valid_loss=np.average(valid_loss))\n\n        return {\n            'loss': valid_loss,\n            'score': valid_score,\n        }\n\n    def skip_valid(self, epoch):\n        LOGGER.debug('[valid] skip')\n        return {\n            'loss': 99.9,\n            'score': epoch * 1e-4,\n        }\n\n    def prediction(self, dataloader, model=None, test_time_augmentation=True, detach=True, num_step=None):\n        tau = self.tau\n        if model is None:\n            model = self.model_pred\n\n            best_idx = np.argmax(np.array([c['valid']['score'] for c in self.checkpoints]))\n            best_loss = self.checkpoints[best_idx]['valid']['loss']\n            best_score = self.checkpoints[best_idx]['valid']['score']\n\n            states = self.checkpoints[best_idx]['model']\n            model.load_state_dict(states)\n            LOGGER.info('best checkpoints at %d/%d (valid loss:%f score:%f) tau:%f',\n                        best_idx + 1, len(self.checkpoints), best_loss, best_score, tau)\n\n        num_step = len(dataloader) if num_step is None else num_step\n\n        model.eval()\n        with torch.no_grad():\n            predictions = []\n            for step, (examples, labels) in zip(range(num_step), dataloader):\n                batch_size = examples.size(0)\n\n                # Test-Time Augment flip\n                if self.use_test_time_augmentation and test_time_augmentation:\n                    examples = torch.cat([examples, torch.flip(examples, dims=[-1])], dim=0)\n\n                # skeleton.nn.MoveToHook.to((examples, labels), self.device, self.is_half)\n                logits = model(examples, tau=tau)\n\n                # avergae\n                if self.use_test_time_augmentation and test_time_augmentation:\n                    logits1, logits2 = torch.split(logits, batch_size, dim=0)\n                    logits = (logits1 + logits2) / 2.0\n\n                logits, prediction = self.activation(logits)\n\n                if detach:\n                    predictions.append(logits.detach().float().cpu().numpy())\n                else:\n                    predictions.append(logits)\n\n            if detach:\n                predictions = np.concatenate(predictions, axis=0).astype(np.float)\n            else:\n                predictions = torch.cat(predictions, dim=0)\n        return predictions\n"""
architectures/__init__.py,0,b''
architectures/resnet.py,40,"b""import logging\nimport sys\nfrom collections import OrderedDict\n\nimport torch\nimport torchvision.models as models\nfrom torch.utils import model_zoo\nfrom torchvision.models.resnet import BasicBlock, model_urls, Bottleneck\n\nimport skeleton\n\nformatter = logging.Formatter(fmt='[%(asctime)s %(levelname)s %(filename)s] %(message)s')\n\nhandler = logging.StreamHandler(sys.stdout)\nhandler.setFormatter(formatter)\n\nLOGGER = logging.getLogger(__name__)\nLOGGER.setLevel(logging.INFO)\nLOGGER.addHandler(handler)\n\n\nclass ResNet18(models.ResNet):\n    Block = BasicBlock\n\n    def __init__(self, in_channels, num_classes=10, **kwargs):\n        Block = BasicBlock\n        super(ResNet18, self).__init__(Block, [2, 2, 2, 2], num_classes=num_classes, **kwargs)    # resnet18\n\n        if in_channels == 3:\n            self.stem = torch.nn.Sequential(\n                # skeleton.nn.Permute(0, 3, 1, 2),\n                skeleton.nn.Normalize(0.5, 0.25, inplace=False),\n            )\n        elif in_channels == 1:\n            self.stem = torch.nn.Sequential(\n                # skeleton.nn.Permute(0, 3, 1, 2),\n                skeleton.nn.Normalize(0.5, 0.25, inplace=False),\n                skeleton.nn.CopyChannels(3),\n            )\n        else:\n            self.stem = torch.nn.Sequential(\n                # skeleton.nn.Permute(0, 3, 1, 2),\n                skeleton.nn.Normalize(0.5, 0.25, inplace=False),\n                torch.nn.Conv2d(in_channels, 3, kernel_size=3, stride=1, padding=1, bias=False),\n                torch.nn.BatchNorm2d(3),\n            )\n\n        self.last_channels = 512 * Block.expansion\n        self.conv1d = torch.nn.Sequential(\n            skeleton.nn.Split(OrderedDict([\n                ('skip', torch.nn.Sequential(\n                    # torch.nn.AvgPool1d(3, stride=2, padding=1)\n                )),\n                ('deep', torch.nn.Sequential(\n                    # torch.nn.Conv1d(self.last_channels, self.last_channels // 4,\n                    #                 kernel_size=1, stride=1, padding=0, bias=False),\n                    # torch.nn.BatchNorm1d(self.last_channels // 4),\n                    # torch.nn.ReLU(inplace=True),\n                    # torch.nn.Conv1d(self.last_channels // 4, self.last_channels // 4,\n                    #                 kernel_size=5, stride=1, padding=2, groups=self.last_channels // 4, bias=False),\n                    # torch.nn.BatchNorm1d(self.last_channels // 4),\n                    # torch.nn.ReLU(inplace=True),\n                    # torch.nn.Conv1d(self.last_channels // 4, self.last_channels,\n                    #                 kernel_size=1, stride=1, padding=0, bias=False),\n                    # torch.nn.BatchNorm1d(self.last_channels),\n\n                    torch.nn.Conv1d(self.last_channels, self.last_channels,\n                                    kernel_size=5, stride=1, padding=2, bias=False),\n                    torch.nn.BatchNorm1d(self.last_channels),\n                    torch.nn.ReLU(inplace=True),\n                ))\n            ])),\n            skeleton.nn.MergeSum(),\n\n            # torch.nn.Conv1d(self.last_channels, self.last_channels,\n            #                 kernel_size=5, stride=1, padding=2, bias=False),\n            # torch.nn.BatchNorm1d(self.last_channels),\n            # torch.nn.ReLU(inplace=True),\n\n            torch.nn.AdaptiveAvgPool1d(1)\n        )\n\n        # self.self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.pool = torch.nn.AdaptiveAvgPool2d((1, 1))\n        # self.pool = torch.nn.AdaptiveMaxPool2d((1, 1))\n        self.fc = torch.nn.Linear(self.last_channels, num_classes, bias=False)\n        self._half = False\n        self._class_normalize = True\n        self._is_video = False\n\n    def set_video(self, is_video=True, times=False):\n        self._is_video = is_video\n        if is_video:\n            self.conv1d_prev = torch.nn.Sequential(\n                skeleton.nn.SplitTime(times),\n                skeleton.nn.Permute(0, 2, 1, 3, 4),\n            )\n\n            self.conv1d_post = torch.nn.Sequential(\n            )\n\n    def is_video(self):\n        return self._is_video\n\n    def init(self, model_dir=None, gain=1.):\n        self.model_dir = model_dir if model_dir is not None else self.model_dir\n        sd = model_zoo.load_url(model_urls['resnet18'], model_dir=self.model_dir)\n        # sd = model_zoo.load_url(model_urls['resnet34'], model_dir='./models/')\n        del sd['fc.weight']\n        del sd['fc.bias']\n        self.load_state_dict(sd, strict=False)\n\n        # for idx in range(len(self.stem)):\n        #     m = self.stem[idx]\n        #     if hasattr(m, 'weight') and not isinstance(m, torch.nn.BatchNorm2d):\n        #         # torch.nn.init.kaiming_normal_(self.stem.weight, mode='fan_in', nonlinearity='linear')\n        #         torch.nn.init.xavier_normal_(m.weight, gain=gain)\n        #         LOGGER.debug('initialize stem weight')\n        #\n        # for idx in range(len(self.conv1d)):\n        #     m = self.conv1d[idx]\n        #     if hasattr(m, 'weight') and not isinstance(m, torch.nn.BatchNorm1d):\n        #         # torch.nn.init.kaiming_normal_(self.stem.weight, mode='fan_in', nonlinearity='linear')\n        #         torch.nn.init.xavier_normal_(m.weight, gain=gain)\n        #         LOGGER.debug('initialize conv1d weight')\n\n        # torch.nn.init.kaiming_uniform_(self.fc.weight, mode='fan_in', nonlinearity='sigmoid')\n        torch.nn.init.xavier_uniform_(self.fc.weight, gain=gain)\n        LOGGER.debug('initialize classifier weight')\n\n    def forward_origin(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.pool(x)\n\n        if self.is_video():\n            x = self.conv1d_prev(x)\n            x = x.view(x.size(0), x.size(1), -1)\n            x = self.conv1d(x)\n            x = self.conv1d_post(x)\n\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n    def forward(self, inputs, targets=None, tau=8.0, reduction='avg'):  # pylint: disable=arguments-differ\n        dims = len(inputs.shape)\n\n        if self.is_video() and dims == 5:\n            batch, times, channels, height, width = inputs.shape\n            inputs = inputs.view(batch*times, channels, height, width)\n\n        inputs = self.stem(inputs)\n        logits = self.forward_origin(inputs)\n        logits /= tau\n\n        if targets is None:\n            return logits\n        if targets.device != logits.device:\n            targets = targets.to(device=logits.device)\n\n        loss = self.loss_fn(input=logits, target=targets)\n\n        if self._class_normalize and isinstance(self.loss_fn, (torch.nn.BCEWithLogitsLoss, skeleton.nn.BinaryCrossEntropyLabelSmooth)):\n            pos = (targets == 1).to(logits.dtype)\n            neg = (targets < 1).to(logits.dtype)\n            npos = pos.sum()\n            nneg = neg.sum()\n\n            positive_ratio = max(0.1, min(0.9, (npos) / (npos + nneg)))\n            negative_ratio = max(0.1, min(0.9, (nneg) / (npos + nneg)))\n            LOGGER.debug('[BCEWithLogitsLoss] positive_ratio:%f, negative_ratio:%f',\n                         positive_ratio, negative_ratio)\n\n            normalized_loss =  (loss * pos) / positive_ratio\n            normalized_loss += (loss * neg) / negative_ratio\n\n            loss = normalized_loss\n\n        if reduction == 'avg':\n            loss = loss.mean()\n        elif reduction == 'max':\n            loss = loss.max()\n        elif reduction == 'min':\n            loss = loss.min()\n        return logits, loss\n\n    def half(self):\n        # super(BasicNet, self).half()\n        for module in self.modules():\n            if len([c for c in module.children()]) > 0:\n                continue\n\n            if not isinstance(module, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d)):\n                module.half()\n            else:\n                module.float()\n        self._half = True\n        return self\n"""
skeleton/__init__.py,0,b'# -*- coding: utf-8 -*-\n# pylint: disable=wildcard-import\nfrom __future__ import absolute_import\n\nfrom . import nn\nfrom . import optim\nfrom . import utils\n\nfrom . import data'
skeleton/data/__init__.py,0,"b'# -*- coding: utf-8 -*-\n# pylint: disable=wildcard-import\nfrom __future__ import absolute_import\n\nfrom .dataset import TFDataset, TransformDataset, prefetch_dataset\nfrom .dataloader import FixedSizeDataLoader, InfiniteSampler, PrefetchDataLoader\nfrom .transforms import *\nfrom .stratified_sampler import StratifiedSampler\nfrom . import augmentations\n'"
skeleton/data/augmentations.py,0,"b'# code in this file is adpated from rpmcruz/autoaugment\n# https://github.com/rpmcruz/autoaugment/blob/master/transformations.py\nimport random\n\nimport PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\nimport numpy as np\n\nrandom_mirror = True\n\n\ndef ShearX(img, v):  # [-0.3, 0.3]\n    assert -0.3 <= v <= 0.3\n    if random_mirror and random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n\n\ndef ShearY(img, v):  # [-0.3, 0.3]\n    assert -0.3 <= v <= 0.3\n    if random_mirror and random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n\n\ndef TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert -0.45 <= v <= 0.45\n    if random_mirror and random.random() > 0.5:\n        v = -v\n    v = v * img.size[0]\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\n\ndef TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert -0.45 <= v <= 0.45\n    if random_mirror and random.random() > 0.5:\n        v = -v\n    v = v * img.size[1]\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\n\ndef TranslateXAbs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert 0 <= v <= 10\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n\n\ndef TranslateYAbs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n    assert 0 <= v <= 10\n    if random.random() > 0.5:\n        v = -v\n    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n\n\ndef Rotate(img, v):  # [-30, 30]\n    assert -30 <= v <= 30\n    if random_mirror and random.random() > 0.5:\n        v = -v\n    return img.rotate(v)\n\n\ndef AutoContrast(img, _):\n    return PIL.ImageOps.autocontrast(img)\n\n\ndef Invert(img, _):\n    return PIL.ImageOps.invert(img)\n\n\ndef Equalize(img, _):\n    return PIL.ImageOps.equalize(img)\n\n\ndef Flip(img, _):  # not from the paper\n    return PIL.ImageOps.mirror(img)\n\n\ndef Solarize(img, v):  # [0, 256]\n    assert 0 <= v <= 256\n    return PIL.ImageOps.solarize(img, v)\n\n\ndef Posterize(img, v):  # [4, 8]\n    assert 4 <= v <= 8\n    v = int(v)\n    return PIL.ImageOps.posterize(img, v)\n\n\ndef Posterize2(img, v):  # [0, 4]\n    assert 0 <= v <= 4\n    v = int(v)\n    return PIL.ImageOps.posterize(img, v)\n\n\ndef Contrast(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Contrast(img).enhance(v)\n\n\ndef Color(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Color(img).enhance(v)\n\n\ndef Brightness(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Brightness(img).enhance(v)\n\n\ndef Sharpness(img, v):  # [0.1,1.9]\n    assert 0.1 <= v <= 1.9\n    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n\n\ndef Cutout(img, v):  # [0, 60] => percentage: [0, 0.2]\n    assert 0.0 <= v <= 0.2\n    if v <= 0.:\n        return img\n\n    v = v * img.size[0]\n\n    return CutoutAbs(img, v)\n\n    # x0 = np.random.uniform(w - v)\n    # y0 = np.random.uniform(h - v)\n    # xy = (x0, y0, x0 + v, y0 + v)\n    # color = (127, 127, 127)\n    # img = img.copy()\n    # PIL.ImageDraw.Draw(img).rectangle(xy, color)\n    # return img\n\n\ndef CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n    # assert 0 <= v <= 20\n    if v < 0:\n        return img\n    w, h = img.size\n    x0 = np.random.uniform(w)\n    y0 = np.random.uniform(h)\n\n    x0 = int(max(0, x0 - v / 2.))\n    y0 = int(max(0, y0 - v / 2.))\n    x1 = min(w, x0 + v)\n    y1 = min(h, y0 + v)\n\n    xy = (x0, y0, x1, y1)\n    color = (125, 123, 114)\n    # color = (0, 0, 0)\n    img = img.copy()\n    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n    return img\n\n\ndef SamplePairing(imgs):  # [0, 0.4]\n    def f(img1, v):\n        i = np.random.choice(len(imgs))\n        img2 = PIL.Image.fromarray(imgs[i])\n        return PIL.Image.blend(img1, img2, v)\n\n    return f\n\n\ndef augment_list(for_autoaug=True):  # 16 operations and their ranges\n    l = [\n        (ShearX, -0.3, 0.3),  # 0\n        (ShearY, -0.3, 0.3),  # 1\n        (TranslateX, -0.45, 0.45),  # 2\n        (TranslateY, -0.45, 0.45),  # 3\n        (Rotate, -30, 30),  # 4\n        (AutoContrast, 0, 1),  # 5\n        (Invert, 0, 1),  # 6\n        (Equalize, 0, 1),  # 7\n        (Solarize, 0, 256),  # 8\n        (Posterize, 4, 8),  # 9\n        (Contrast, 0.1, 1.9),  # 10\n        (Color, 0.1, 1.9),  # 11\n        (Brightness, 0.1, 1.9),  # 12\n        (Sharpness, 0.1, 1.9),  # 13\n        (Cutout, 0, 0.2),  # 14\n        # (SamplePairing(imgs), 0, 0.4),  # 15\n    ]\n    if for_autoaug:\n        l += [\n            (CutoutAbs, 0, 20),  # compatible with auto-augment\n            (Posterize2, 0, 4),  # 9\n            (TranslateXAbs, 0, 10),  # 9\n            (TranslateYAbs, 0, 10),  # 9\n        ]\n    return l\n\n\naugment_dict = {fn.__name__: (fn, v1, v2) for fn, v1, v2 in augment_list()}\n\n\ndef get_augment(name):\n    return augment_dict[name]\n\n\ndef apply_augment(img, name, level):\n    augment_fn, low, high = get_augment(name)\n    return augment_fn(img.copy(), level * (high - low) + low)\n\n\nclass Augmentation(object):\n    def __init__(self, policies):\n        self.policies = policies\n\n    def __call__(self, img):\n        for _ in range(1):\n            policy = random.choice(self.policies)\n            for name, pr, level in policy:\n                if random.random() > pr:\n                    continue\n                img = apply_augment(img, name, level)\n        return img\n\n\n# policy from https://github.com/kakaobrain/fast-autoaugment/blob/master/FastAutoAugment/archive.py\nfrom collections import defaultdict\n\nPARAMETER_MAX = 10\n\n\ndef remove_duplicates(policies):\n    s = set()\n    new_policies = []\n    for ops in policies:\n        key = []\n        for op in ops:\n            key.append(op[0])\n        key = \'_\'.join(key)\n        if key in s:\n            continue\n        else:\n            s.add(key)\n            new_policies.append(ops)\n\n    return new_policies\n\n\ndef float_parameter(level, maxval):\n    return float(level) * maxval / PARAMETER_MAX\n\n\ndef int_parameter(level, maxval):\n    return int(float_parameter(level, maxval))\n\n\ndef autoaug2arsaug(f):\n    def autoaug():\n        mapper = defaultdict(lambda: lambda x: x)\n        mapper.update({\n            \'ShearX\': lambda x: float_parameter(x, 0.3),\n            \'ShearY\': lambda x: float_parameter(x, 0.3),\n            \'TranslateX\': lambda x: int_parameter(x, 10),\n            \'TranslateY\': lambda x: int_parameter(x, 10),\n            \'Rotate\': lambda x: int_parameter(x, 30),\n            \'Solarize\': lambda x: 256 - int_parameter(x, 256),\n            \'Posterize2\': lambda x: 4 - int_parameter(x, 4),\n            \'Contrast\': lambda x: float_parameter(x, 1.8) + .1,\n            \'Color\': lambda x: float_parameter(x, 1.8) + .1,\n            \'Brightness\': lambda x: float_parameter(x, 1.8) + .1,\n            \'Sharpness\': lambda x: float_parameter(x, 1.8) + .1,\n            \'CutoutAbs\': lambda x: int_parameter(x, 20)\n        })\n\n        def low_high(name, prev_value):\n            _, low, high = get_augment(name)\n            return float(prev_value - low) / (high - low)\n\n        policies = f()\n        new_policies = []\n        for policy in policies:\n            new_policies.append([(name, pr, low_high(name, mapper[name](level))) for name, pr, level in policy])\n        return new_policies\n\n    return autoaug\n\n\n@autoaug2arsaug\ndef autoaug_policy():\n    """"""AutoAugment policies found on Cifar.""""""\n    exp0_0 = [\n        [(\'Invert\', 0.1, 7), (\'Contrast\', 0.2, 6)],\n        [(\'Rotate\', 0.7, 2), (\'TranslateXAbs\', 0.3, 9)],\n        [(\'Sharpness\', 0.8, 1), (\'Sharpness\', 0.9, 3)],\n        [(\'ShearY\', 0.5, 8), (\'TranslateYAbs\', 0.7, 9)],\n        [(\'AutoContrast\', 0.5, 8), (\'Equalize\', 0.9, 2)]]\n    exp0_1 = [\n        [(\'Solarize\', 0.4, 5), (\'AutoContrast\', 0.9, 3)],\n        [(\'TranslateYAbs\', 0.9, 9), (\'TranslateYAbs\', 0.7, 9)],\n        [(\'AutoContrast\', 0.9, 2), (\'Solarize\', 0.8, 3)],\n        [(\'Equalize\', 0.8, 8), (\'Invert\', 0.1, 3)],\n        [(\'TranslateYAbs\', 0.7, 9), (\'AutoContrast\', 0.9, 1)]]\n    exp0_2 = [\n        [(\'Solarize\', 0.4, 5), (\'AutoContrast\', 0.0, 2)],\n        [(\'TranslateYAbs\', 0.7, 9), (\'TranslateYAbs\', 0.7, 9)],\n        [(\'AutoContrast\', 0.9, 0), (\'Solarize\', 0.4, 3)],\n        [(\'Equalize\', 0.7, 5), (\'Invert\', 0.1, 3)],\n        [(\'TranslateYAbs\', 0.7, 9), (\'TranslateYAbs\', 0.7, 9)]]\n    exp0_3 = [\n        [(\'Solarize\', 0.4, 5), (\'AutoContrast\', 0.9, 1)],\n        [(\'TranslateYAbs\', 0.8, 9), (\'TranslateYAbs\', 0.9, 9)],\n        [(\'AutoContrast\', 0.8, 0), (\'TranslateYAbs\', 0.7, 9)],\n        [(\'TranslateYAbs\', 0.2, 7), (\'Color\', 0.9, 6)],\n        [(\'Equalize\', 0.7, 6), (\'Color\', 0.4, 9)]]\n    exp1_0 = [\n        [(\'ShearY\', 0.2, 7), (\'Posterize2\', 0.3, 7)],\n        [(\'Color\', 0.4, 3), (\'Brightness\', 0.6, 7)],\n        [(\'Sharpness\', 0.3, 9), (\'Brightness\', 0.7, 9)],\n        [(\'Equalize\', 0.6, 5), (\'Equalize\', 0.5, 1)],\n        [(\'Contrast\', 0.6, 7), (\'Sharpness\', 0.6, 5)]]\n    exp1_1 = [\n        [(\'Brightness\', 0.3, 7), (\'AutoContrast\', 0.5, 8)],\n        [(\'AutoContrast\', 0.9, 4), (\'AutoContrast\', 0.5, 6)],\n        [(\'Solarize\', 0.3, 5), (\'Equalize\', 0.6, 5)],\n        [(\'TranslateYAbs\', 0.2, 4), (\'Sharpness\', 0.3, 3)],\n        [(\'Brightness\', 0.0, 8), (\'Color\', 0.8, 8)]]\n    exp1_2 = [\n        [(\'Solarize\', 0.2, 6), (\'Color\', 0.8, 6)],\n        [(\'Solarize\', 0.2, 6), (\'AutoContrast\', 0.8, 1)],\n        [(\'Solarize\', 0.4, 1), (\'Equalize\', 0.6, 5)],\n        [(\'Brightness\', 0.0, 0), (\'Solarize\', 0.5, 2)],\n        [(\'AutoContrast\', 0.9, 5), (\'Brightness\', 0.5, 3)]]\n    exp1_3 = [\n        [(\'Contrast\', 0.7, 5), (\'Brightness\', 0.0, 2)],\n        [(\'Solarize\', 0.2, 8), (\'Solarize\', 0.1, 5)],\n        [(\'Contrast\', 0.5, 1), (\'TranslateYAbs\', 0.2, 9)],\n        [(\'AutoContrast\', 0.6, 5), (\'TranslateYAbs\', 0.0, 9)],\n        [(\'AutoContrast\', 0.9, 4), (\'Equalize\', 0.8, 4)]]\n    exp1_4 = [\n        [(\'Brightness\', 0.0, 7), (\'Equalize\', 0.4, 7)],\n        [(\'Solarize\', 0.2, 5), (\'Equalize\', 0.7, 5)],\n        [(\'Equalize\', 0.6, 8), (\'Color\', 0.6, 2)],\n        [(\'Color\', 0.3, 7), (\'Color\', 0.2, 4)],\n        [(\'AutoContrast\', 0.5, 2), (\'Solarize\', 0.7, 2)]]\n    exp1_5 = [\n        [(\'AutoContrast\', 0.2, 0), (\'Equalize\', 0.1, 0)],\n        [(\'ShearY\', 0.6, 5), (\'Equalize\', 0.6, 5)],\n        [(\'Brightness\', 0.9, 3), (\'AutoContrast\', 0.4, 1)],\n        [(\'Equalize\', 0.8, 8), (\'Equalize\', 0.7, 7)],\n        [(\'Equalize\', 0.7, 7), (\'Solarize\', 0.5, 0)]]\n    exp1_6 = [\n        [(\'Equalize\', 0.8, 4), (\'TranslateYAbs\', 0.8, 9)],\n        [(\'TranslateYAbs\', 0.8, 9), (\'TranslateYAbs\', 0.6, 9)],\n        [(\'TranslateYAbs\', 0.9, 0), (\'TranslateYAbs\', 0.5, 9)],\n        [(\'AutoContrast\', 0.5, 3), (\'Solarize\', 0.3, 4)],\n        [(\'Solarize\', 0.5, 3), (\'Equalize\', 0.4, 4)]]\n    exp2_0 = [\n        [(\'Color\', 0.7, 7), (\'TranslateXAbs\', 0.5, 8)],\n        [(\'Equalize\', 0.3, 7), (\'AutoContrast\', 0.4, 8)],\n        [(\'TranslateYAbs\', 0.4, 3), (\'Sharpness\', 0.2, 6)],\n        [(\'Brightness\', 0.9, 6), (\'Color\', 0.2, 8)],\n        [(\'Solarize\', 0.5, 2), (\'Invert\', 0.0, 3)]]\n    exp2_1 = [\n        [(\'AutoContrast\', 0.1, 5), (\'Brightness\', 0.0, 0)],\n        # [(\'CutoutAbs\', 0.2, 4), (\'Equalize\', 0.1, 1)],\n        [(\'Equalize\', 0.7, 7), (\'AutoContrast\', 0.6, 4)],\n        [(\'Color\', 0.1, 8), (\'ShearY\', 0.2, 3)],\n        [(\'ShearY\', 0.4, 2), (\'Rotate\', 0.7, 0)]]\n    exp2_2 = [\n        [(\'ShearY\', 0.1, 3), (\'AutoContrast\', 0.9, 5)],\n        # [(\'TranslateYAbs\', 0.3, 6), (\'CutoutAbs\', 0.3, 3)],\n        [(\'Equalize\', 0.5, 0), (\'Solarize\', 0.6, 6)],\n        [(\'AutoContrast\', 0.3, 5), (\'Rotate\', 0.2, 7)],\n        [(\'Equalize\', 0.8, 2), (\'Invert\', 0.4, 0)]]\n    exp2_3 = [\n        [(\'Equalize\', 0.9, 5), (\'Color\', 0.7, 0)],\n        [(\'Equalize\', 0.1, 1), (\'ShearY\', 0.1, 3)],\n        [(\'AutoContrast\', 0.7, 3), (\'Equalize\', 0.7, 0)],\n        [(\'Brightness\', 0.5, 1), (\'Contrast\', 0.1, 7)],\n        [(\'Contrast\', 0.1, 4), (\'Solarize\', 0.6, 5)]]\n    exp2_4 = [\n        [(\'Solarize\', 0.2, 3), (\'ShearX\', 0.0, 0)],\n        [(\'TranslateXAbs\', 0.3, 0), (\'TranslateXAbs\', 0.6, 0)],\n        [(\'Equalize\', 0.5, 9), (\'TranslateYAbs\', 0.6, 7)],\n        [(\'ShearX\', 0.1, 0), (\'Sharpness\', 0.5, 1)],\n        [(\'Equalize\', 0.8, 6), (\'Invert\', 0.3, 6)]]\n    exp2_5 = [\n        # [(\'AutoContrast\', 0.3, 9), (\'CutoutAbs\', 0.5, 3)],\n        [(\'ShearX\', 0.4, 4), (\'AutoContrast\', 0.9, 2)],\n        [(\'ShearX\', 0.0, 3), (\'Posterize2\', 0.0, 3)],\n        [(\'Solarize\', 0.4, 3), (\'Color\', 0.2, 4)],\n        [(\'Equalize\', 0.1, 4), (\'Equalize\', 0.7, 6)]]\n    exp2_6 = [\n        [(\'Equalize\', 0.3, 8), (\'AutoContrast\', 0.4, 3)],\n        [(\'Solarize\', 0.6, 4), (\'AutoContrast\', 0.7, 6)],\n        [(\'AutoContrast\', 0.2, 9), (\'Brightness\', 0.4, 8)],\n        [(\'Equalize\', 0.1, 0), (\'Equalize\', 0.0, 6)],\n        [(\'Equalize\', 0.8, 4), (\'Equalize\', 0.0, 4)]]\n    exp2_7 = [\n        [(\'Equalize\', 0.5, 5), (\'AutoContrast\', 0.1, 2)],\n        [(\'Solarize\', 0.5, 5), (\'AutoContrast\', 0.9, 5)],\n        [(\'AutoContrast\', 0.6, 1), (\'AutoContrast\', 0.7, 8)],\n        [(\'Equalize\', 0.2, 0), (\'AutoContrast\', 0.1, 2)],\n        [(\'Equalize\', 0.6, 9), (\'Equalize\', 0.4, 4)]]\n    exp0s = exp0_0 + exp0_1 + exp0_2 + exp0_3\n    exp1s = exp1_0 + exp1_1 + exp1_2 + exp1_3 + exp1_4 + exp1_5 + exp1_6\n    exp2s = exp2_0 + exp2_1 + exp2_2 + exp2_3 + exp2_4 + exp2_5 + exp2_6 + exp2_7\n\n    return exp0s + exp1s + exp2s\n'"
skeleton/data/dataloader.py,8,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport logging\n\nimport torch\n\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass FixedSizeDataLoader:\n    def __init__(self, dataset, steps, batch_size=1, shuffle=False, num_workers=0, pin_memory=False, drop_last=False,\n                 sampler=None):\n        sampler = InfiniteSampler(dataset, shuffle) if sampler is None else sampler\n        self.batch_size = batch_size\n        batch_size = 1 if batch_size is None else batch_size\n\n        self.steps = steps\n        self.dataset = dataset\n        self.dataloader = torch.utils.data.DataLoader(\n            self.dataset,\n            batch_size=batch_size,\n            sampler=sampler,\n            num_workers=num_workers,\n            pin_memory=pin_memory,\n            drop_last=drop_last\n        )\n\n    def __len__(self):\n        return self.steps\n\n    def __iter__(self):\n        if self.steps is not None:\n            for _, data in zip(range(self.steps), self.dataloader):\n                yield ([t[0] for t in data] if self.batch_size is None else data)\n        else:\n            for data in self.dataloader:\n                yield ([t[0] for t in data] if self.batch_size is None else data)\n\n\nclass InfiniteSampler(torch.utils.data.sampler.Sampler):\n    def __init__(self, data_source, shuffle=False):\n        self.data_source = data_source\n        self.shuffle = shuffle\n\n    def __iter__(self):\n        n = len(self.data_source)\n        while True:\n            index_list = torch.randperm(n).tolist() if self.shuffle else list(range(n))\n            for idx in index_list:\n                yield idx\n\n    def __len__(self):\n        return len(self.data_source)\n\n\nclass PrefetchDataLoader:\n    def __init__(self, dataloader, device, half=False):\n        self.loader = dataloader\n        self.iter = None\n        self.device = device\n        self.dtype = torch.float16 if half else torch.float32\n        self.stream = torch.cuda.Stream()\n        self.next_data = None\n\n    def __len__(self):\n        return len(self.loader)\n\n    def async_prefech(self):\n        try:\n            self.next_data = next(self.iter)\n        except StopIteration:\n            self.next_data = None\n            return\n\n        with torch.cuda.stream(self.stream):\n            if isinstance(self.next_data, torch.Tensor):\n                self.next_data = self.next_data.to(dtype=self.dtype, device=self.device, non_blocking=True)\n            elif isinstance(self.next_data, (list, tuple)):\n                self.next_data = [\n                    t.to(dtype=self.dtype, device=self.device, non_blocking=True) if t.is_floating_point() else t.to(device=self.device, non_blocking=True) for t in self.next_data\n                ]\n\n    def __iter__(self):\n        self.iter = iter(self.loader)\n        self.async_prefech()\n        while self.next_data is not None:\n            torch.cuda.current_stream().wait_stream(self.stream)\n            data = self.next_data\n            self.async_prefech()\n            yield data\n'"
skeleton/data/dataset.py,7,"b""# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport logging\n\nimport torch\nfrom torch.utils.data import Dataset\nimport numpy as np\nimport tensorflow as tf\nfrom ..nn.modules.hooks import MoveToHook\n\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass TFDataset(Dataset):\n    def __init__(self, session, dataset, num_samples):\n        super(TFDataset, self).__init__()\n        self.session = session\n        self.dataset = dataset\n        self.num_samples = num_samples\n        self.next_element = None\n\n        self.reset()\n\n    def reset(self):\n        dataset = self.dataset\n        iterator = dataset.make_one_shot_iterator()\n        self.next_element = iterator.get_next()\n        return self\n\n    def __len__(self):\n        return self.num_samples\n\n    def __getitem__(self, index):\n        session = self.session if self.session is not None else tf.Session()\n        try:\n            example, label = session.run(self.next_element)\n        except tf.errors.OutOfRangeError:\n            self.reset()\n            raise StopIteration\n\n        return example, label\n\n    def scan(self, samples=1000000, with_tensors=False, is_batch=False, device=None, half=False):\n        shapes, counts, tensors = [], [], []\n        labels = []\n        min_list, max_list = [], []\n        for i in range(min(self.num_samples, samples)):\n            try:\n                example, label = self.__getitem__(i)\n            except tf.errors.OutOfRangeError:\n                break\n            except StopIteration:\n                break\n\n            shape = example.shape\n            count = np.sum(label, axis=None if not is_batch else -1)\n            labels.append(label)\n            # index = np.argmax(label, axis=None if not is_batch else -1)\n\n            shapes.append(shape)\n            counts.append(count)\n            min_list.append(np.min(example))\n            max_list.append(np.max(example))\n\n            if with_tensors:\n                example = torch.Tensor(example)\n                label = torch.Tensor(label)\n\n                example.data = example.data.to(device=device)\n                if half and example.is_floating_point():\n                    example.data = example.data.half()\n\n                label.data = label.data.to(device=device)\n                if half and label.is_floating_point():\n                    label.data = label.data.half()\n\n                tensors.append([example, label])\n\n        shapes = np.array(shapes)\n        counts = np.array(counts) if not is_batch else np.concatenate(counts)\n\n        labels = np.array(labels) if not is_batch else np.concatenate(labels)\n        labels = np.sum(labels, axis=0)\n        zero_count = sum(labels == 0)\n\n        info = {\n            'count': len(counts),\n            'is_multiclass': counts.max() > 1.0,\n            'is_video': int(np.median(shapes, axis=0)[0]) > 1,\n            'example': {\n                'shape': [int(v) for v in np.median(shapes, axis=0)],  # time, channels, height, width\n                'shape_avg': [int(v) for v in np.average(shapes, axis=0)],  # time, channels, height, width\n                'value': {'min': min(min_list), 'max': max(max_list)}\n            },\n            'label': {\n                'min': counts.min(),\n                'max': counts.max(),\n                'average': counts.mean(),\n                'median': np.median(counts),\n                'zero_count': zero_count,\n            },\n            # 'indexs': {\n            #     'min': indexs.min(),\n            #     'max': indexs.max(),\n            #     'average': indexs.mean(),\n            #     'median': np.median(indexs),\n            # }\n        }\n\n        if with_tensors:\n            return info, tensors\n        return info\n\n\nclass TransformDataset(Dataset):\n    def __init__(self, dataset, transform=None, index=None):\n        self.dataset = dataset\n        self.transform = transform\n        self.index = index\n\n    def __getitem__(self, index):\n        tensors = self.dataset[index]\n        tensors = list(tensors)\n\n        if self.transform is not None:\n            if self.index is None:\n                tensors = self.transform(*tensors)\n            else:\n                tensors[self.index] = self.transform(tensors[self.index])\n\n        return tuple(tensors)\n\n    def __len__(self):\n        return len(self.dataset)\n\n\ndef prefetch_dataset(dataset, num_workers=4, batch_size=32, device=None, half=False):\n    if isinstance(dataset, list) and isinstance(dataset[0], torch.Tensor):\n        tensors = dataset\n    else:\n        dataloader = torch.utils.data.DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=False, drop_last=False,\n            num_workers=num_workers, pin_memory=False\n        )\n        tensors = [t for t in dataloader]\n        tensors = [torch.cat(t, dim=0) for t in zip(*tensors)]\n\n    if device is not None:\n        tensors = [t.to(device=device) for t in tensors]\n    if half:\n        tensors = [t.half() if  t.is_floating_point() else t for t in tensors]\n\n    return torch.utils.data.TensorDataset(*tensors)\n"""
skeleton/data/stratified_sampler.py,1,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport logging\n\nimport os\nimport random\nfrom abc import ABC\nfrom collections import defaultdict\n\nfrom torch.utils.data import Sampler\n\n\nclass StratifiedSampler(Sampler, ABC):\n    def __init__(self, labels):\n        self.idx_by_lb = defaultdict(list)\n        for idx, lb in enumerate(labels):\n            self.idx_by_lb[lb].append(idx)\n\n        self.size = len(labels)\n\n    def __len__(self):\n        return self.size\n\n    def __iter__(self):\n        while True:\n            songs_list = []\n            artists_list = []\n            for lb, v in self.idx_by_lb.items():\n                for idx in v:\n                    songs_list.append(idx)\n                    artists_list.append(lb)\n\n            shuffled = spotifyShuffle(songs_list, artists_list)\n            for idx in shuffled:\n                yield idx\n\n\ndef fisherYatesShuffle(arr):\n    """"""\n    https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle\n    for i from n\xe2\x88\x921 downto 1 do\n     j \xe2\x86\x90 random integer such that 0 \xe2\x89\xa4 j \xe2\x89\xa4 i\n     exchange a[j] and a[i]\n    """"""\n    for i in range(len(arr)-1, 0, -1):\n        j = random.randint(0, i)\n        arr[i], arr[j] = arr[j], arr[i]\n    return arr\n\n\ndef spotifyShuffle(songs_list, artists_list):\n    artist2songs = defaultdict(list)\n    for artist, song in zip(artists_list, songs_list):\n        artist2songs[artist].append(song)\n    songList = []\n    songsLocs = []\n    for artist, songs in artist2songs.items():\n        songs = fisherYatesShuffle(songs)\n        songList += songs\n        songsLocs += get_locs(len(songs))\n    return [songList[idx] for idx in argsort(songsLocs)]\n\n\ndef argsort(seq):\n    return [i for i, j in sorted(enumerate(seq), key=lambda x:x[1])]\n\n\ndef get_locs(n):\n    percent = 1. / n\n    locs = [percent * random.random()]\n    last = locs[0]\n    for i in range(n - 1):\n        value = last + percent * random.uniform(0.8, 1.2)  # 25% : 20~30% = 1 : 0.8x~1.2x\n        locs.append(value)\n        last = value\n    return locs\n'"
skeleton/data/transforms.py,3,"b""# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport os\nimport logging\nimport hashlib\nimport random\n\nimport numpy as np\nimport torch\n\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass Identity:\n    def __call__(self, image):\n        return image\n\n\nclass Normalize:\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, image):\n        return (image - self.mean) / self.std\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\n\nclass RandomFlip:\n    def __init__(self, p=0.5, dims=[-1]):\n        self.p = p\n        self.dims = dims\n\n    def __call__(self, tensor):\n        if random.random() < self.p:\n            tensor = torch.flip(tensor, dims=self.dims)\n        return tensor\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(p={})'.format(self.p)\n\n\nclass Crop:\n    def __init__(self, height, width):\n        self.height = height\n        self.width = width\n\n    def __call__(self, image):\n        h, w = image.shape[-2:]\n\n        y = np.random.randint(h - self.height)\n        x = np.random.randint(w - self.width)\n\n        return image[:, y:y+self.height, x:x+self.width]\n\n\nclass Cutout:\n    def __init__(self, height, width):\n        self.height = height\n        self.width = width\n        LOGGER.debug('[%s] height:%d, width:%d', self.__class__.__name__, self.height, self.width)\n\n    def __call__(self, image):\n        if self.height > 0 or self.width > 0:\n            if isinstance(image, torch.Tensor):\n                mask = torch.ones_like(image)\n            elif isinstance(image, np.ndarray):\n                mask = np.ones_like(image)\n            else:\n                raise NotImplementedError('support only tensor or numpy array')\n\n            h, w = image.shape[-2:]\n\n            y = np.random.randint(h)\n            x = np.random.randint(w)\n\n            y1 = np.clip(y - self.height // 2, 0, h)\n            y2 = np.clip(y + self.height // 2, 0, h)\n            x1 = np.clip(x - self.width // 2, 0, w)\n            x2 = np.clip(x + self.width // 2, 0, w)\n\n            if len(mask.shape) == 3:\n                mask[:, y1: y2, x1: x2] = 0.\n            else:\n                mask[:, :, y1: y2, x1: x2] = 0.\n            image *= mask\n        return image\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(height={0}, width={1})'.format(self.height, self.width)\n\n\nclass RandomHorizontalFlip:\n    def __init__(self, p=0.5):\n        self.p = p\n\n    def __call__(self, img):\n        if random.random() < self.p:\n            img = np.flip(img, axis=-1).copy()\n        return img\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(p={})'.format(self.p)\n\n\nclass Writer:\n    def __init__(self, path, format='jpg'):\n        self.path = path\n        self.format = format\n        os.makedirs(self.path, exist_ok=True)\n\n    def __call__(self, image):\n        filename = hashlib.md5(image.tobytes()).hexdigest()\n        path = self.path + '/' + filename + '.' + self.format\n        image.save(path)\n        return image\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(path={0}, format={1})'.format(self.path, self.format)\n"""
skeleton/nn/__init__.py,0,b'# -*- coding: utf-8 -*-\n# pylint: disable=wildcard-import\nfrom __future__ import absolute_import\n\nfrom .modules import *\n'
skeleton/optim/__init__.py,0,b'# -*- coding: utf-8 -*-\n# pylint: disable=wildcard-import\nfrom __future__ import absolute_import\n\nfrom .optimizers import *\nfrom .scheduler import *\nfrom .sgdw import SGDW\n'
skeleton/optim/optimizers.py,1,"b""# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport logging\n\nimport torch\n\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass ScheduledOptimizer:\n    def __init__(self, parameters, optimizer, steps_per_epoch=1, clip_grad_max_norm=None, tag=None, **opt_params):\n        self.epoch = 0.0\n        self.tag = tag\n        self._parameters = parameters\n        self.steps_per_epoch = steps_per_epoch\n        self.clip_grad_max_norm = clip_grad_max_norm\n        self._opt_params = opt_params\n\n        self._optimizer = optimizer(parameters, **self.update_params(0))\n\n    def update_params(self, epoch=None, **kwargs):\n        return {\n            k: v(self.epoch if epoch is None else epoch, **kwargs) if callable(v) else v\n            for k, v in self._opt_params.items()\n        }\n\n    def update(self, epoch=None, **kwargs):\n        opt_pararms = self.update_params(epoch, **kwargs)\n        self._optimizer.param_groups[0].update(**opt_pararms)\n\n        for key, value in opt_pararms.items():\n            tag = self.tag if self.tag is not None else 'train'\n            if not isinstance(value, (float, int)):\n                # LOGGER.warning('CANNOT SUPPORT type(%s) at ([%s] %s %s)', type(value), tag, key, str(value))\n                continue\n        # LOGGER.debug('update optimizer params:%s', self.opt_params)\n        return self\n\n    def step(self, epoch=None):\n        self.epoch = self.epoch + (1.0 / self.steps_per_epoch) if epoch is None else epoch\n        # self.update(self.epoch)\n        if self.clip_grad_max_norm is not None and self.clip_grad_max_norm > 0.0:\n            torch.nn.utils.clip_grad_norm_(self._parameters, self.clip_grad_max_norm, norm_type=1)\n        self._optimizer.step()\n\n    def state_dict(self):\n        state_dict = self._optimizer.state_dict()\n        state_dict.update({'epoch': self.epoch})\n        return state_dict\n\n    def load_state_dict(self, state_dict):\n        self.epoch = state_dict.pop('epoch')\n        return self._optimizer.load_state_dict(state_dict)\n\n    def zero_grad(self):\n        return self._optimizer.zero_grad()\n\n    def get_learning_rate(self):\n        return self._optimizer.param_groups[0]['lr']\n\n    def __getattr__(self, item):\n        return getattr(self._optimizer, item)\n"""
skeleton/optim/scheduler.py,0,"b""# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport math\nimport logging\n\n\nLOGGER = logging.getLogger(__name__)\n\n\ndef gradual_warm_up(scheduler, warm_up_epoch, multiplier):\n    def schedule(e, **kwargs):\n        lr = scheduler(e, **kwargs)\n        lr = lr * ((multiplier - 1.0) * min(e, warm_up_epoch) / warm_up_epoch + 1)\n        return lr\n    return schedule\n\n\ndef get_discrete_epoch(scheduler):\n    def schedule(e, **kwargs):\n        return scheduler(int(e), **kwargs)\n    return schedule\n\n\ndef get_change_scale(scheduler, init_scale=1.0):\n    def schedule(e, scale=None, **kwargs):\n        lr = scheduler(e, **kwargs)\n        return lr * (scale if scale is not None else init_scale)\n    return schedule\n\n\ndef get_step_scheduler(init_lr, step_size, gamma=0.1):\n    def schedule(e, **kwargs):\n        lr = init_lr * gamma ** (e // step_size)\n        return lr\n    return schedule\n\n\ndef get_cosine_scheduler(init_lr, maximum_epoch, eta_min=0):\n    def schedule(e, **kwargs):\n        maximum = kwargs['maximum_epoch'] if 'maximum_epoch' in kwargs else maximum_epoch\n        lr = eta_min + (init_lr - eta_min) * (1 + math.cos(math.pi * e / maximum)) / 2\n        return lr\n    return schedule\n\n\nclass PlateauScheduler:\n    def __init__(self, init_lr, factor=0.1, patience=10, threshold=1e-4):\n        self.init_lr = init_lr\n        self.factor = factor\n        self.patience = patience\n        self.threshold = threshold\n\n        self.curr_lr = init_lr\n        self.best_loss = 10000\n        self.prev_epoch = 0\n        self.num_bad_epochs = 0\n\n    def __call__(self, epoch, loss=None, **kwargs):\n        if loss is None:\n            loss = self.best_loss\n\n        if self.best_loss - self.threshold > loss:\n            self.num_bad_epochs = 0\n            self.best_loss = loss\n        else:\n            self.num_bad_epochs += epoch - self.prev_epoch\n\n        if self.num_bad_epochs >= self.patience:\n            self.num_bad_epochs = 0\n            self.curr_lr *= self.factor\n\n        self.prev_epoch = epoch\n        return self.curr_lr\n\n\ndef get_reduce_on_plateau_scheduler(init_lr, factor=0.1, patience=10, threshold=1e-4, min_lr=0, metric_name='metric'):\n    class Schedule:\n        def __init__(self):\n            self.num_bad_epochs = 0\n            self.lr = init_lr\n            self.best = None\n            self.metric_name = metric_name\n\n        def __call__(self, e, **kwargs):\n            if self.metric_name not in kwargs:\n                return self.lr\n            metric = kwargs[self.metric_name]\n\n            LOGGER.debug(\n                '[%s] lr:%f best:%f curr:%f num_bad_epoch:%d>%d',\n                'get_reduce_on_plateau',\n                self.lr,\n                self.best if self.best is not None else -1,\n                metric,\n                self.num_bad_epochs,\n                patience\n            )\n\n            if self.best is None or self.best > metric:\n                self.best = metric - threshold\n                self.num_bad_epochs = 0\n            else:\n                self.num_bad_epochs += 1\n\n            if self.num_bad_epochs > patience:\n                self.num_bad_epochs = 0\n                lr = max(min_lr, self.lr * factor)\n                LOGGER.debug('[%s] reduce lr %f -> %f', 'get_reduce_on_plateau', self.lr, lr)\n                self.lr = lr\n            return self.lr\n    return Schedule()\n"""
skeleton/optim/sgdw.py,2,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\n\nimport torch\n\n\nclass SGDW(torch.optim.SGD):\n    """"""\n    Decoupled Weight Decay Regularization\n    reference: https://arxiv.org/abs/1711.05101\n    """"""\n    def step(self, closure=None):\n        """"""Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        """"""\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            weight_decay = group[\'weight_decay\']\n            momentum = group[\'momentum\']\n            dampening = group[\'dampening\']\n            nesterov = group[\'nesterov\']\n\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                d_p = p.grad.data\n                if momentum != 0:\n                    param_state = self.state[p]\n                    if \'momentum_buffer\' not in param_state:\n                        buf = param_state[\'momentum_buffer\'] = torch.zeros_like(p.data)\n                        buf.mul_(momentum).add_(d_p)\n                    else:\n                        buf = param_state[\'momentum_buffer\']\n                        buf.mul_(momentum).add_(1 - dampening, d_p)\n                    if nesterov:\n                        d_p = d_p.add(momentum, buf)\n                    else:\n                        d_p = buf\n\n                # decoupled weight decay\n                if weight_decay != 0:\n                    d_p.add_(weight_decay, p.data)\n\n                p.data.add_(-group[\'lr\'], d_p)\n\n        return loss\n'"
skeleton/projects/__init__.py,0,b'# -*- coding: utf-8 -*-\n# pylint: disable=wildcard-import\nfrom __future__ import absolute_import\n\nfrom .api import *\nfrom .others import *\nfrom .logic import *'
skeleton/projects/logic.py,2,"b""# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport random\n\nimport tensorflow as tf\nimport torchvision as tv\nimport torch\nimport numpy as np\n\nfrom .api import Model\nfrom .others import *\nimport skeleton\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n\nLOGGER = get_logger(__name__)\n\n\nclass LogicModel(Model):\n    def __init__(self, metadata, session=None):\n        super(LogicModel, self).__init__(metadata)\n        LOGGER.info('--------- Model.metadata ----------')\n        LOGGER.info('path: %s', self.metadata.get_dataset_name())\n        LOGGER.info('shape:  %s', self.metadata.get_tensor_size(0))\n        LOGGER.info('size: %s', self.metadata.size())\n        LOGGER.info('num_class:  %s', self.metadata.get_output_size())\n\n        test_metadata_filename = self.metadata.get_dataset_name().replace('train', 'test') + '/metadata.textproto'\n        self.num_test = [int(line.split(':')[1]) for line in open(test_metadata_filename, 'r').readlines()[:3] if 'sample_count' in line][0]\n        LOGGER.info('num_test:  %d', self.num_test)\n\n        self.timers = {\n            'train': skeleton.utils.Timer(),\n            'test': skeleton.utils.Timer()\n        }\n        self.info = {\n            'dataset': {\n                'path': self.metadata.get_dataset_name(),\n                'shape': self.metadata.get_tensor_size(0),\n                'size': self.metadata.size(),\n                'num_class': self.metadata.get_output_size()\n            },\n            'loop': {\n                'epoch': 0,\n                'test': 0,\n                'best_score': 0.0\n            },\n            'condition': {\n                'first': {\n                    'train': True,\n                    'valid': True,\n                    'test': True\n                }\n            },\n            'terminate': False\n        }\n\n        # TODO: adaptive logic for hyper parameter\n        self.hyper_params = {\n            'optimizer': {\n                'lr': 0.025,\n            },\n            'dataset': {\n                'train_info_sample': 256,\n                'cv_valid_ratio': 0.1,\n                'max_valid_count': 256,\n\n                'max_size': 64,\n                'base': 16,  # input size should be multipliers of 16\n                'max_times': 8,\n\n                'enough_count': {\n                    'image': 10000,\n                    'video': 1000\n                },\n\n                'batch_size': 32,\n                'steps_per_epoch': 30,\n                'max_epoch': 1000,  # initial value\n                'batch_size_test': 256,\n            },\n            'checkpoints': {\n                'keep': 50\n            },\n            'conditions': {\n                'score_type': 'auc',\n                'early_epoch': 1,\n                'skip_valid_score_threshold': 0.90,  # if bigger then 1.0 is not use\n                'skip_valid_after_test': min(10, max(3, int(self.info['dataset']['size'] // 1000))),\n                'test_after_at_least_seconds': 1,\n                'test_after_at_least_seconds_max': 90,\n                'test_after_at_least_seconds_step': 2,\n\n                'threshold_valid_score_diff': 0.001,\n                'threshold_valid_best_score': 0.997,\n                'max_inner_loop_ratio': 0.2,\n                'min_lr': 1e-6,\n                'use_fast_auto_aug': True\n            }\n        }\n        self.checkpoints = []\n        LOGGER.info('[init] build')\n\n        self.build()\n        LOGGER.info('[init] session')\n\n        self.dataloaders = {\n            'train': None,\n            'valid': None,\n            'test': None\n        }\n        self.is_skip_valid = True\n        LOGGER.info('[init] done')\n\n    def __repr__(self):\n        return '\\n---------[{0}]---------\\ninfo:{1}\\nparams:{2}\\n---------- ---------'.format(\n            self.__class__.__name__,\n            self.info, self.hyper_params\n        )\n\n    def build(self):\n        raise NotImplementedError\n\n    def update_model(self):\n        # call after to scan train sample\n        pass\n\n    def epoch_train(self, epoch, train):\n        raise NotImplementedError\n\n    def epoch_valid(self, epoch, valid):\n        raise NotImplementedError\n\n    def skip_valid(self, epoch):\n        raise NotImplementedError\n\n    def prediction(self, dataloader):\n        raise NotImplementedError\n\n    def adapt(self):\n        raise NotImplementedError\n\n    def is_multiclass(self):\n        return self.info['dataset']['sample']['is_multiclass']\n\n    def is_video(self):\n        return self.info['dataset']['sample']['is_video']\n\n    def build_or_get_train_dataloader(self, dataset):\n        if not self.info['condition']['first']['train']:\n            return self.build_or_get_dataloader('train')\n\n        num_images = self.info['dataset']['size']\n\n        # split train/valid\n        num_valids = int(min(num_images * self.hyper_params['dataset']['cv_valid_ratio'], self.hyper_params['dataset']['max_valid_count']))\n        num_trains = num_images - num_valids\n        LOGGER.info('[cv_fold] num_trains:%d num_valids:%d', num_trains, num_valids)\n\n        LOGGER.info('[%s] scan before', 'sample')\n        num_samples = self.hyper_params['dataset']['train_info_sample']\n        sample = dataset.take(num_samples).prefetch(buffer_size=num_samples)\n        train = skeleton.data.TFDataset(self.session, sample, num_samples)\n        self.info['dataset']['sample'] = train.scan(samples=num_samples)\n        del train\n        del sample\n        LOGGER.info('[%s] scan after', 'sample')\n\n        # input_shape = [min(s, self.hyper_params['dataset']['max_size']) for s in self.info['dataset']['shape']]\n        times, height, width, channels = self.info['dataset']['sample']['example']['shape']\n        values = self.info['dataset']['sample']['example']['value']\n        aspect_ratio = width / height\n\n        # fit image area to 64x64\n        if aspect_ratio > 2 or 1. / aspect_ratio > 2:\n            self.hyper_params['dataset']['max_size'] *= 2\n        size = [min(s, self.hyper_params['dataset']['max_size']) for s in [height, width]]\n\n        # keep aspect ratio\n        if aspect_ratio > 1:\n            size[0] = size[1] / aspect_ratio\n        else:\n            size[1] = size[0] * aspect_ratio\n\n        # too small image use original image\n        if width <= 32 and height <= 32:\n            input_shape = [times, height, width, channels]\n        else:\n            fit_size_fn = lambda x: int(x / self.hyper_params['dataset']['base'] + 0.8) * self.hyper_params['dataset']['base']\n            size = list(map(fit_size_fn, size))\n            min_times = min(times, self.hyper_params['dataset']['max_times'])\n            input_shape = [fit_size_fn(min_times) if min_times > self.hyper_params['dataset']['base'] else min_times] + size + [channels]\n\n        if self.is_video():\n            self.hyper_params['dataset']['batch_size'] = int(self.hyper_params['dataset']['batch_size'] // 2)\n            # self.hyper_params['dataset']['batch_size_test'] = int(self.hyper_params['dataset']['batch_size_test'] // 2)\n        LOGGER.info('[input_shape] origin:%s aspect_ratio:%f target:%s', [times, height, width, channels], aspect_ratio, input_shape)\n\n        self.hyper_params['dataset']['input'] = input_shape\n\n        num_class = self.info['dataset']['num_class']\n        batch_size = self.hyper_params['dataset']['batch_size']\n        if num_class > batch_size / 2 and not self.is_video():\n            self.hyper_params['dataset']['batch_size'] = batch_size * 2\n        batch_size = self.hyper_params['dataset']['batch_size']\n\n        preprocessor1 = get_tf_resize(input_shape[1], input_shape[2], times=input_shape[0], min_value=values['min'], max_value=values['max'])\n\n        dataset = dataset.map(\n            lambda *x: (preprocessor1(x[0]), x[1]),\n            num_parallel_calls=tf.data.experimental.AUTOTUNE\n        )\n        # dataset = dataset.prefetch(buffer_size=batch_size * 3)\n        # dataset = dataset.shuffle(buffer_size=num_valids * 4, reshuffle_each_iteration=False)\n\n        must_shuffle = self.info['dataset']['sample']['label']['zero_count'] / self.info['dataset']['num_class'] >= 0.5\n        enough_count = self.hyper_params['dataset']['enough_count']['video'] if self.is_video() else self.hyper_params['dataset']['enough_count']['image']\n        if must_shuffle or num_images < enough_count:\n            dataset = dataset.shuffle(buffer_size=min(enough_count, num_images), reshuffle_each_iteration=False)\n            LOGGER.info('[dataset] shuffle before split train/valid')\n\n        train = dataset.skip(num_valids)\n        valid = dataset.take(num_valids)\n        self.datasets = {\n            'train': train,\n            'valid': valid,\n            'num_trains': num_trains,\n            'num_valids': num_valids\n        }\n        return self.build_or_get_dataloader('train', self.datasets['train'], num_trains)\n\n    def build_or_get_dataloader(self, mode, dataset=None, num_items=0):\n        if mode in self.dataloaders and self.dataloaders[mode] is not None:\n            return self.dataloaders[mode]\n\n        enough_count = self.hyper_params['dataset']['enough_count']['video'] if self.is_video() else self.hyper_params['dataset']['enough_count']['image']\n\n        LOGGER.debug('[dataloader] %s build start', mode)\n        values = self.info['dataset']['sample']['example']['value']\n        if mode == 'train':\n            batch_size = self.hyper_params['dataset']['batch_size']\n            # input_shape = self.hyper_params['dataset']['input']\n            preprocessor = get_tf_to_tensor(is_random_flip=True)\n            # dataset = dataset.prefetch(buffer_size=batch_size * 3)\n\n            if num_items < enough_count:\n                dataset = dataset.cache()\n\n            # dataset = dataset.apply(\n            #     tf.data.experimental.shuffle_and_repeat(buffer_size=min(enough_count, num_items))\n            # )\n            dataset = dataset.repeat()\n            dataset = dataset.map(\n                lambda *x: (preprocessor(x[0]), x[1]),\n                num_parallel_calls=tf.data.experimental.AUTOTUNE\n            )\n            dataset = dataset.prefetch(buffer_size=batch_size * 8)\n\n            dataset = skeleton.data.TFDataset(self.session, dataset, num_items)\n\n            transform = tv.transforms.Compose([\n                # skeleton.data.Cutout(int(input_shape[1] // 4), int(input_shape[2] // 4))\n            ])\n            dataset = skeleton.data.TransformDataset(dataset, transform, index=0)\n\n            self.dataloaders['train'] = skeleton.data.FixedSizeDataLoader(\n                dataset,\n                steps=self.hyper_params['dataset']['steps_per_epoch'],\n                batch_size=batch_size,\n                shuffle=False, drop_last=True, num_workers=0, pin_memory=False\n            )\n        elif mode in ['valid', 'test']:\n            batch_size = self.hyper_params['dataset']['batch_size_test']\n            input_shape = self.hyper_params['dataset']['input']\n\n            preprocessor2 = get_tf_to_tensor(is_random_flip=False)\n            if mode == 'valid':\n                preprocessor = preprocessor2\n            else:\n                preprocessor1 = get_tf_resize(input_shape[1], input_shape[2], times=input_shape[0], min_value=values['min'], max_value=values['max'])\n                preprocessor = lambda *tensor: preprocessor2(preprocessor1(*tensor))\n\n            # batch_size = 500\n            tf_dataset = dataset.apply(\n                tf.data.experimental.map_and_batch(\n                    map_func=lambda *x: (preprocessor(x[0]), x[1]),\n                    batch_size=batch_size,\n                    drop_remainder=False,\n                    num_parallel_calls=tf.data.experimental.AUTOTUNE\n                )\n            ).prefetch(buffer_size=8)\n\n            dataset = skeleton.data.TFDataset(self.session, tf_dataset, num_items)\n\n            LOGGER.info('[%s] scan before', mode)\n            self.info['dataset'][mode], tensors = dataset.scan(\n                with_tensors=True, is_batch=True,\n                device=self.device, half=self.is_half\n            )\n            tensors = [torch.cat(t, dim=0) for t in zip(*tensors)]\n            LOGGER.info('[%s] scan after', mode)\n\n            del tf_dataset\n            del dataset\n            dataset = skeleton.data.prefetch_dataset(tensors)\n\n            if 'valid' == mode:\n                transform = tv.transforms.Compose([\n                ])\n                dataset = skeleton.data.TransformDataset(dataset, transform, index=0)\n\n            self.dataloaders[mode] = torch.utils.data.DataLoader(\n                dataset,\n                batch_size=self.hyper_params['dataset']['batch_size_test'],\n                shuffle=False, drop_last=False, num_workers=0, pin_memory=False\n            )\n\n            self.info['condition']['first'][mode] = False\n\n        LOGGER.debug('[dataloader] %s build end', mode)\n        return self.dataloaders[mode]\n\n    def update_condition(self, metrics=None):\n        self.info['condition']['first']['train'] = False\n        self.info['loop']['epoch'] += 1\n\n        metrics.update({'epoch': self.info['loop']['epoch']})\n        self.checkpoints.append(metrics)\n\n        indices = np.argsort(np.array([v['valid']['score'] for v in self.checkpoints] if len(self.checkpoints) > 0 else [0]))\n        indices = sorted(indices[::-1][:self.hyper_params['checkpoints']['keep']])\n        self.checkpoints = [self.checkpoints[i] for i in indices]\n\n    def break_train_loop_condition(self, remaining_time_budget=None, inner_epoch=1):\n        consume = inner_epoch * self.timers['train'].step_time\n\n        best_idx = np.argmax(np.array([c['valid']['score'] for c in self.checkpoints]))\n        best_epoch = self.checkpoints[best_idx]['epoch']\n        best_loss = self.checkpoints[best_idx]['valid']['loss']\n        best_score = self.checkpoints[best_idx]['valid']['score']\n        lr = self.optimizer.get_learning_rate()\n        LOGGER.debug('[CONDITION] best (epoch:%04d loss:%.2f score:%.2f) lr:%.8f time delta:%.2f',\n                     best_epoch, best_loss, best_score, lr, consume)\n\n        if self.info['loop']['epoch'] <= self.hyper_params['conditions']['early_epoch']:\n            LOGGER.info('[BREAK] early %d epoch', self.hyper_params['conditions']['early_epoch'])\n            return True\n\n        if best_score > self.hyper_params['conditions']['threshold_valid_best_score']:\n            LOGGER.info('[BREAK] achieve best score %f', best_score)\n            return True\n\n        if consume > self.hyper_params['conditions']['test_after_at_least_seconds'] and \\\n            self.checkpoints[best_idx]['epoch'] > self.info['loop']['epoch'] - inner_epoch and \\\n            best_score > self.info['loop']['best_score'] * 1.001:\n            # increase hyper param\n            self.hyper_params['conditions']['test_after_at_least_seconds'] = min(\n                self.hyper_params['conditions']['test_after_at_least_seconds_max'],\n                self.hyper_params['conditions']['test_after_at_least_seconds'] + self.hyper_params['conditions']['test_after_at_least_seconds_step']\n            )\n\n            self.info['loop']['best_score'] = best_score\n            LOGGER.info('[BREAK] found best model (score:%f)', best_score)\n            return True\n\n        if lr < self.hyper_params['conditions']['min_lr']:\n            LOGGER.info('[BREAK] too small lr (lr:%f < %f)', lr, self.hyper_params['conditions']['min_lr'])\n            return True\n\n        early_term_budget = 3 * 60\n        expected_more_time = (self.timers['test'].step_time + (self.timers['train'].step_time * 2)) * 1.5\n        if remaining_time_budget is not None and \\\n            remaining_time_budget - early_term_budget < expected_more_time:\n            LOGGER.info('[BREAK] not enough time to train (remain:%f need:%f)', remaining_time_budget, expected_more_time)\n            return True\n\n        if self.info['loop']['epoch'] >= 20 and \\\n            inner_epoch > self.hyper_params['dataset']['max_epoch'] * self.hyper_params['conditions']['max_inner_loop_ratio']:\n            LOGGER.info('[BREAK] cannot found best model in too many epoch')\n            return True\n\n        return False\n\n    def terminate_train_loop_condition(self, remaining_time_budget=None, inner_epoch=0):\n        early_term_budget = 3 * 60\n        expected_more_time = (self.timers['test'].step_time + (self.timers['train'].step_time * 2)) * 1.5\n        if remaining_time_budget is not None and \\\n            remaining_time_budget - early_term_budget < expected_more_time:\n            LOGGER.info('[TERMINATE] not enough time to train (remain:%f need:%f)', remaining_time_budget, expected_more_time)\n            self.info['terminate'] = True\n            self.done_training = True\n            return True\n\n        best_idx = np.argmax(np.array([c['valid']['score'] for c in self.checkpoints]))\n        best_score = self.checkpoints[best_idx]['valid']['score']\n        if best_score > self.hyper_params['conditions']['threshold_valid_best_score']:\n            LOGGER.info('[TERMINATE] achieve best score %f', best_score)\n            done = True if self.info['terminate'] else False\n            self.info['terminate'] = True\n            self.done_training = done if self.is_video() else True\n            return True\n\n        scores = [c['valid']['score'] for c in self.checkpoints]\n        diff = (max(scores) - min(scores)) * (1 - max(scores))\n        threshold = self.hyper_params['conditions']['threshold_valid_score_diff']\n        if 1e-8 < diff and diff < threshold and \\\n            self.info['loop']['epoch'] >= 20:\n            LOGGER.info('[TERMINATE] too small score change (diff:%f < %f)', diff, threshold)\n            done = True if self.info['terminate'] else False\n            self.info['terminate'] = True\n            self.done_training = done\n            return True\n\n        if self.optimizer.get_learning_rate() < self.hyper_params['conditions']['min_lr']:\n            LOGGER.info('[TERMINATE] lr=%f', self.optimizer.get_learning_rate())\n            done = True if self.info['terminate'] else False\n            self.info['terminate'] = True\n            self.done_training = done\n            return True\n\n        if self.info['loop']['epoch'] >= 20 and \\\n            inner_epoch > self.hyper_params['dataset']['max_epoch'] * self.hyper_params['conditions']['max_inner_loop_ratio']:\n            LOGGER.info('[TERMINATE] cannot found best model in too many epoch')\n            done = True if self.info['terminate'] else False\n            self.info['terminate'] = True\n            self.done_training = done\n            return True\n\n        return False\n\n    def get_total_time(self):\n        return sum([self.timers[key].total_time for key in self.timers.keys()])\n\n    def train(self, dataset, remaining_time_budget=None):\n        LOGGER.debug(self)\n        LOGGER.debug('[train] [%02d] budget:%f', self.info['loop']['epoch'], remaining_time_budget)\n        self.timers['train']('outer_start', exclude_total=True, reset_step=True)\n\n        train_dataloader = self.build_or_get_train_dataloader(dataset)\n        if self.info['condition']['first']['train']:\n            self.update_model()\n            LOGGER.info(self)\n        self.timers['train']('build_dataset')\n\n        inner_epoch = 0\n        while True:\n            inner_epoch += 1\n            remaining_time_budget -= self.timers['train'].step_time\n\n            self.timers['train']('start', reset_step=True)\n            train_metrics = self.epoch_train(self.info['loop']['epoch'], train_dataloader)\n            self.timers['train']('train')\n\n            train_score = np.min([c['train']['score'] for c in self.checkpoints[-20:] + [{'train': train_metrics}]])\n            if train_score > self.hyper_params['conditions']['skip_valid_score_threshold'] or \\\n                self.info['loop']['test'] >= self.hyper_params['conditions']['skip_valid_after_test']:\n                is_first = self.info['condition']['first']['valid']\n                valid_dataloader = self.build_or_get_dataloader('valid', self.datasets['valid'], self.datasets['num_valids'])\n                self.timers['train']('valid_dataset', exclude_step=is_first)\n\n                valid_metrics = self.epoch_valid(self.info['loop']['epoch'], valid_dataloader)\n                self.is_skip_valid = False\n            else:\n                valid_metrics = self.skip_valid(self.info['loop']['epoch'])\n                self.is_skip_valid = True\n            self.timers['train']('valid')\n\n            metrics = {\n                'epoch': self.info['loop']['epoch'],\n                'model': self.model.state_dict().copy(),\n                'train': train_metrics,\n                'valid': valid_metrics,\n            }\n\n            self.update_condition(metrics)\n            self.timers['train']('adapt', exclude_step=True)\n\n            LOGGER.info(\n                '[train] [%02d] time(budge:%.2f, total:%.2f, step:%.2f) loss:(train:%.3f, valid:%.3f) score:(train:%.3f valid:%.3f) lr:%f',\n                self.info['loop']['epoch'], remaining_time_budget, self.get_total_time(), self.timers['train'].step_time,\n                metrics['train']['loss'], metrics['valid']['loss'], metrics['train']['score'], metrics['valid']['score'],\n                self.optimizer.get_learning_rate()\n            )\n            LOGGER.debug('[train] [%02d] Timer:%s', self.info['loop']['epoch'], self.timers['train'])\n\n            self.hyper_params['dataset']['max_epoch'] = self.info['loop']['epoch'] + remaining_time_budget // self.timers['train'].step_time\n            LOGGER.info('[ESTIMATE] max_epoch: %d', self.hyper_params['dataset']['max_epoch'])\n\n            if self.break_train_loop_condition(remaining_time_budget, inner_epoch):\n                break\n\n            self.timers['train']('end')\n\n        # if 'test' in self.dataloaders and self.dataloaders['test'] is not None and \\\n        #     not is_skip_valid:\n        #     self.prediction(self.dataloaders['test'])\n        #     for step in range(3):\n        #         test_metric = self.epoch_train(self.info['loop']['epoch'], self.dataloaders['test'])\n        #         LOGGER.info(\n        #             '[train] [%02d] [%02d/%02d] [finetune] loss:%.3f score:%.3f',\n        #             self.info['loop']['epoch'], step, 3, test_metric['loss'], test_metric['score'],\n        #         )\n        # self.timers['train']('finetune')\n\n        remaining_time_budget -= self.timers['train'].step_time\n        self.terminate_train_loop_condition(remaining_time_budget, inner_epoch)\n\n        if not self.done_training:\n            self.adapt(remaining_time_budget)\n\n        self.timers['train']('outer_end')\n        LOGGER.info(\n            '[train] [%02d] time(budge:%.2f, total:%.2f, step:%.2f) loss:(train:%.3f, valid:%.3f) score:(train:%.3f valid:%.3f) lr:%f',\n            self.info['loop']['epoch'], remaining_time_budget, self.get_total_time(), self.timers['train'].step_time,\n            metrics['train']['loss'], metrics['valid']['loss'], metrics['train']['score'], metrics['valid']['score'],\n            self.optimizer.get_learning_rate()\n        )\n        # LOGGER.info('[train] [%02d] Timer:%s', self.info['loop']['epoch'], self.timers['train'])\n\n    def test(self, dataset, remaining_time_budget=None):\n        self.timers['test']('start', exclude_total=True, reset_step=True)\n        is_first = self.info['condition']['first']['test']\n        self.info['loop']['test'] += 1\n\n        dataloader = self.build_or_get_dataloader('test', dataset, self.num_test)\n        self.timers['test']('build_dataset', reset_step=is_first)\n\n        rv = self.prediction(dataloader)\n        self.timers['test']('end')\n\n        LOGGER.info(\n            '[test ] [%02d] test:%02d time(budge:%.2f, total:%.2f, step:%.2f)',\n            self.info['loop']['epoch'], self.info['loop']['test'], remaining_time_budget, self.get_total_time(), self.timers['test'].step_time,\n        )\n        # LOGGER.debug('[test ] [%02d] Timer:%s', self.info['loop']['epoch'], self.timers['test'])\n        return rv\n"""
skeleton/projects/others.py,0,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport sys\nimport os\nimport logging\nfrom functools import reduce\n\nimport tensorflow as tf\nimport torchvision as tv\nimport numpy as np\n\n\ndef get_logger(name, stream=sys.stderr):\n    formatter = logging.Formatter(fmt=\'[%(asctime)s %(levelname)s %(filename)s] %(message)s\')\n\n    handler = logging.StreamHandler(stream)\n    handler.setFormatter(formatter)\n\n    logger = logging.getLogger(name)\n    level = logging.INFO if os.environ.get(\'LOG_LEVEL\', \'INFO\') == \'INFO\' else logging.DEBUG\n    logger.setLevel(level)\n    logger.addHandler(handler)\n    return logger\n\n\nLOGGER = get_logger(__name__)\n\n\ndef get_tf_resize(height, width, times=1, min_value=0.0, max_value=1.0):\n    def preprocessor(tensor):\n        in_times, in_height, in_width, in_channels = tensor.get_shape()\n        LOGGER.info(\'[get_tf_resize] shape:%s\', (in_times, in_height, in_width, in_channels))\n\n        if width == in_width and height == in_height:\n            LOGGER.info(\'[get_tf_resize] do not resize (%dx%d)\', width, height)\n        else:\n            tensor = tf.image.resize_images(tensor, (height, width), method=tf.image.ResizeMethod.BICUBIC)\n\n        if times != in_times or times > 1:\n            # resize time axis using NN (to select frame \\wo interpolate)\n            tensor = tf.reshape(tensor, [-1, height * width, in_channels])\n            tensor = tf.image.resize_images(tensor, (times,  height * width), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n            tensor = tf.reshape(tensor, [times, height, width, in_channels])\n\n            # sampling at center of time axis\n            # tensor = tensor[int(times // 2)] # single image\n            # delta = int(times // 2)\n            # tensor = tensor[delta:delta+times]\n\n        if times == 1:\n            tensor = tensor[int(times // 2)]\n\n        delta = max_value - min_value\n        if delta < 0.9 or delta > 1.1 or min_value < -0.1 or min_value > 0.1:\n            LOGGER.info(\'[get_tf_resize] min-max normalize(min:%f, max:%f)\', min_value, max_value)\n            tensor = (tensor - min_value) / delta\n\n        # tensor = (tensor - 0.5) / 0.25\n        return tensor\n    return preprocessor\n\n\ndef get_tf_to_tensor(is_random_flip=True):\n    def preprocessor(tensor):\n        if is_random_flip:\n            tensor = tf.image.random_flip_left_right(tensor)\n        dims = len(tensor.shape)\n        # LOGGER.info(\'[get_tf_to_tensor] dims:%s\', dims)\n        if dims == 3:\n            # height, width, channels -> channels, height, width\n            tensor = tf.transpose(tensor, perm=[2, 0, 1])\n        elif dims == 4:\n            # time, height, width, channels -> time, channels, height, width\n            tensor = tf.transpose(tensor, perm=[0, 3, 1, 2])\n        return tensor\n    return preprocessor\n\n\ndef NBAC(logits, labels):\n    if logits.device != labels.device:\n        labels = labels.to(device=logits.device)\n\n    positive_mask = labels > 0\n    negative_mask = labels < 1\n\n    tpr = (logits * labels).sum() / positive_mask.sum()\n    tnr = ((1-logits) * (1-labels)).sum() / negative_mask.sum()\n    return tpr, tnr, (tpr + tnr - 1)\n\n\ndef tiedrank(a):\n    \'\'\' Return the ranks (with base 1) of a list resolving ties by averaging.\n     This works for numpy arrays.\'\'\'\n    m = len(a)\n    # Sort a in ascending order (sa=sorted vals, i=indices)\n    i = a.argsort()\n    sa = a[i]\n    # Find unique values\n    uval = np.unique(a)\n    # Test whether there are ties\n    R = np.arange(m, dtype=float) + 1  # Ranks with base 1\n    if len(uval) != m:\n        # Average the ranks for the ties\n        oldval = sa[0]\n        newval = sa[0]\n        k0 = 0\n        for k in range(1, m):\n            newval = sa[k]\n            if newval == oldval:\n                # moving average\n                R[k0:k + 1] = R[k - 1] * (k - k0) / (k - k0 + 1) + R[k] / (k - k0 + 1)\n            else:\n                k0 = k;\n                oldval = newval\n    # Invert the index\n    S = np.empty(m)\n    S[i] = R\n    return S\n\n\ndef mvmean(R, axis=0):\n    \'\'\' Moving average to avoid rounding errors. A bit slow, but...\n    Computes the mean along the given axis, except if this is a vector, in which case the mean is returned.\n    Does NOT flatten.\'\'\'\n    if len(R.shape) == 0: return R\n    average = lambda x: reduce(lambda i, j: (0, (j[0] / (j[0] + 1.)) * i[1] + (1. / (j[0] + 1)) * j[1]), enumerate(x))[\n        1]\n    R = np.array(R)\n    if len(R.shape) == 1: return average(R)\n    if axis == 1:\n        return np.array(map(average, R))\n    else:\n        return np.array(map(average, R.transpose()))\n\n\ndef get_valid_columns(solution):\n    """"""Get a list of column indices for which the column has more than one class.\n    This is necessary when computing BAC or AUC which involves true positive and\n    true negative in the denominator. When some class is missing, these scores\n    don\'t make sense (or you have to add an epsilon to remedy the situation).\n\n    Args:\n    solution: array, a matrix of binary entries, of shape\n      (num_examples, num_features)\n    Returns:\n    valid_columns: a list of indices for which the column has more than one\n      class.\n    """"""\n    num_examples = solution.shape[0]\n    col_sum = np.sum(solution, axis=0)\n    valid_columns = np.where(1 - np.isclose(col_sum, 0) -\n                               np.isclose(col_sum, num_examples))[0]\n    return valid_columns\n\n\ndef AUC(logits, labels):\n    logits = logits.detach().float().cpu().numpy()\n    labels = labels.detach().float().cpu().numpy()\n\n    valid_columns = get_valid_columns(labels)\n\n    logits = logits[:, valid_columns].copy()\n    labels = labels[:, valid_columns].copy()\n\n    label_num = labels.shape[1]\n    if label_num == 0:\n        return 0.0\n\n    auc = np.empty(label_num)\n    for k in range(label_num):\n        r_ = tiedrank(logits[:, k])\n        s_ = labels[:, k]\n\n        npos = sum(s_ == 1)\n        nneg = sum(s_ < 1)\n        auc[k] = (sum(r_[s_ == 1]) - npos * (npos + 1) / 2) / (nneg * npos)\n\n    return 2 * mvmean(auc) - 1\n'"
skeleton/utils/__init__.py,0,b'# -*- coding: utf-8 -*-\n# pylint: disable=wildcard-import\nfrom __future__ import absolute_import\n\nfrom .timer import Timer'
skeleton/utils/timer.py,0,"b""# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nimport time\nfrom collections import OrderedDict\nimport logging\n\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass Timer:\n    def __init__(self):\n        self.times = [time.time()]\n        self.accumulation = OrderedDict({})\n        self.total_time = 0.0\n        self.step_time = 0.0\n\n    def __call__(self, name, exclude_total=False, exclude_step=False, reset_step=False):\n        self.times.append(time.time())\n        delta = self.times[-1] - self.times[-2]\n\n        if name not in self.accumulation:\n            self.accumulation[name] = 0.0\n        self.accumulation[name] += delta\n\n        if not exclude_total:\n            self.total_time += delta\n\n        if reset_step:\n            self.step_time = 0.0\n        elif not exclude_step:\n            self.step_time += delta\n\n        return delta\n\n    def __repr__(self):\n        results = []\n        for key, value in self.accumulation.items():\n            results.append('{0}={1:.3f}'.format(key, value))\n        return self.__class__.__name__ + '(total={0}, step={1}, {2})'.format(\n            self.total_time, self.step_time, ', '.join(results)\n        )\n"""
skeleton/nn/modules/__init__.py,0,b'# -*- coding: utf-8 -*-\n# pylint: disable=wildcard-import\nfrom __future__ import absolute_import\n\nfrom .profile import Profile\nfrom .hooks import MoveToHook\nfrom .wrappers import *\nfrom .loss import *\n'
skeleton/nn/modules/hooks.py,1,"b'# -*- coding: utf-8 -*-\n# pylint: disable=arguments-differ, abstract-method\nfrom __future__ import absolute_import\nimport logging\n\nimport torch\nfrom torch import nn\n\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass MoveToHook(nn.Module):\n    @staticmethod\n    def to(tensors, device, half=False):\n        for t in tensors:\n            if isinstance(t, (tuple, list)):\n                MoveToHook.to(t, device, half)\n            if not isinstance(t, torch.Tensor):\n                continue\n            t.data = t.data.to(device=device)\n            if half:\n                if t.is_floating_point():\n                    t.data = t.data.half()\n\n    @staticmethod\n    def get_forward_pre_hook(device, half=False):\n        def hook(module, inputs):\n            _ = module\n            MoveToHook.to(inputs, device, half)\n        return hook\n\n'"
skeleton/nn/modules/loss.py,4,"b""# -*- coding: utf-8 -*-\n# pylint: disable=arguments-differ, abstract-method\nfrom __future__ import absolute_import\nimport logging\n\nimport torch\n\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass CrossEntropyLabelSmooth(torch.nn.Module):\n    def __init__(self, num_classes, epsilon=0.1, sparse_target=True, reduction='avg'):\n        super(CrossEntropyLabelSmooth, self).__init__()\n        self.num_classes = num_classes\n        self.epsilon = epsilon\n        self.sparse_target = sparse_target\n        self.logsoftmax = torch.nn.LogSoftmax(dim=1)\n        self.reduction = reduction\n\n    def forward(self, input, target):  # pylint: disable=redefined-builtin\n        log_probs = self.logsoftmax(input)\n        if self.sparse_target:\n            targets = torch.zeros_like(log_probs).scatter_(1, target.unsqueeze(1), 1)\n        else:\n            targets = target\n        targets = (1 - self.epsilon) * targets + (self.epsilon / self.num_classes)\n        loss = (-targets * log_probs)\n        if self.reduction == 'avg':\n            loss = loss.mean(0).sum()\n        elif self.reduction == 'sum':\n            loss = loss.sum()\n\n        return loss\n\n\nclass BinaryCrossEntropyLabelSmooth(torch.nn.BCEWithLogitsLoss):\n    def __init__(self, num_classes, epsilon=0.1, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None):\n        super(BinaryCrossEntropyLabelSmooth, self).__init__(weight, size_average, reduce, reduction, pos_weight)\n        self.num_classes = num_classes\n        self.epsilon = epsilon\n\n    def forward(self, input, target):  # pylint: disable=redefined-builtin\n        target = (1 - self.epsilon) * target + self.epsilon\n        return super(BinaryCrossEntropyLabelSmooth, self).forward(input, target)\n"""
skeleton/nn/modules/profile.py,19,"b""# -*- coding: utf-8 -*-\n# pylint: disable=arguments-differ, abstract-method\nfrom __future__ import absolute_import\nimport logging\n\nimport numpy as np\nimport torch\nfrom torch import nn\n\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass Profile:\n    def __init__(self, module):\n        self.module = module\n\n    def params(self, name_filter=lambda name: True):\n        return np.sum(params.numel() for name, params in self.module.named_parameters() if name_filter(name))\n\n    def flops(self, *inputs, name_filter=lambda name: 'skeleton' not in name and 'loss' not in name):\n        operation_flops = []\n\n        def get_hook(name):\n            def counting(module, inp, outp):\n                class_name = module.__class__.__name__\n\n                flops = 0\n                module_type = type(module)\n                if not name_filter(str(module_type)):\n                    pass\n                elif module_type in COUNT_FN_MAP:\n                    fn = COUNT_FN_MAP[module_type]\n                    flops = fn(module, inp, outp) if fn is not None else 0\n                else:\n                    LOGGER.warning('Not implemented for %s', module_type)\n\n                data = {\n                    'name': name,\n                    'class_name': class_name,\n                    'flops': flops,\n                }\n                operation_flops.append(data)\n            return counting\n\n        handles = []\n        for name, module in self.module.named_modules():\n            if len(list(module.children())) > 0:  # pylint: disable=len-as-condition\n                continue\n            handle = module.register_forward_hook(get_hook(name))\n            handles.append(handle)\n\n        _ = self.module(*inputs)\n\n        # remove hook\n        _ = [h.remove() for h in handles]\n\n        return np.sum([data['flops'] for data in operation_flops if name_filter(data['name'])])\n\n\n# base code from https://github.com/Lyken17/pytorch-OpCounter/blob/master/thop/count_hooks.py\nCOUNT_OP_MULTIPLY_ADD = 1\n\n\ndef count_conv2d(m, x, y):\n    # TODO: add support for pad and dilation\n    x = x[0]\n\n    cin = m.in_channels\n    cout = m.out_channels\n    kh, kw = m.kernel_size\n    batch_size = x.size()[0]\n\n    out_w = y.size(2) // m.stride[0]\n    out_h = y.size(3) // m.stride[1]\n\n    # ops per output element\n    # kernel_mul = kh * kw * cin\n    # kernel_add = kh * kw * cin - 1\n    kernel_ops = COUNT_OP_MULTIPLY_ADD * kh * kw * cin // m.groups\n    bias_ops = 1 if m.bias is not None else 0\n    ops_per_element = kernel_ops + bias_ops\n\n    # total ops\n    # num_out_elements = y.numel()\n    output_elements = batch_size * out_w * out_h * cout\n    total_ops = output_elements * ops_per_element\n\n    # in case same conv is used multiple times\n    return int(total_ops)\n\n\ndef count_bn2d(m, x, y):\n    x = x[0]\n\n    nelements = x.numel()\n    total_sub = nelements\n    total_div = nelements\n    total_ops = total_sub + total_div\n\n    return int(total_ops)\n\n\ndef count_relu(m, x, y):\n    x = x[0]\n\n    nelements = x.numel()\n    total_ops = nelements\n\n    return int(total_ops)\n\n\ndef count_softmax(m, x, y):\n    x = x[0]\n\n    batch_size, nfeatures = x.size()\n\n    total_exp = nfeatures\n    total_add = nfeatures - 1\n    total_div = nfeatures\n    total_ops = batch_size * (total_exp + total_add + total_div)\n\n    return int(total_ops)\n\n\ndef count_maxpool(m, x, y):\n    kernel_ops = torch.prod(torch.Tensor([m.kernel_size])) - 1\n    num_elements = y.numel()\n    total_ops = kernel_ops * num_elements\n\n    return int(total_ops)\n\n\ndef count_avgpool(m, x, y):\n    total_add = torch.prod(torch.Tensor([m.kernel_size])) - 1\n    total_div = 1\n    kernel_ops = total_add + total_div\n    num_elements = y.numel()\n    total_ops = kernel_ops * num_elements\n\n    return int(total_ops)\n\n\ndef count_global_avgpool(m, x, y):\n    x = x[0]\n\n    w, h = x.size(2), x.size(1)\n    total_add = w * h - 1\n    total_div = 1\n    kernel_ops = total_add + total_div\n    num_elements = y.numel()\n    total_ops = kernel_ops * num_elements\n\n    return int(total_ops)\n\n\ndef count_linear(m, x, y):\n    # per output element\n    total_mul = m.in_features\n    total_add = m.in_features - 1\n    num_elements = y.numel()\n    total_ops = (total_mul + total_add) * num_elements\n\n    return int(total_ops)\n\n\nCOUNT_FN_MAP = {\n    torch.nn.Conv2d: count_conv2d,\n    torch.nn.BatchNorm2d: count_bn2d,\n    torch.nn.ReLU: count_relu,\n    torch.nn.ReLU6: count_relu,\n    torch.nn.LeakyReLU: count_relu,\n    torch.nn.MaxPool1d: count_maxpool,\n    torch.nn.MaxPool2d: count_maxpool,\n    torch.nn.MaxPool3d: count_maxpool,\n    torch.nn.AvgPool1d: count_avgpool,\n    torch.nn.AvgPool2d: count_avgpool,\n    torch.nn.AvgPool3d: count_avgpool,\n    torch.nn.AdaptiveAvgPool1d: count_global_avgpool,\n    torch.nn.AdaptiveAvgPool2d: count_global_avgpool,\n    torch.nn.AdaptiveAvgPool3d: count_global_avgpool,\n    torch.nn.Linear: count_linear,\n    torch.nn.Dropout: None,\n    # torch.nn.Identity: None,\n}\n"""
skeleton/nn/modules/wrappers.py,28,"b""# -*- coding: utf-8 -*-\n# pylint: disable=arguments-differ\nfrom __future__ import absolute_import\nimport logging\nfrom functools import wraps\nfrom collections import OrderedDict\n\nimport torch\nimport numpy as np\n\nLOGGER = logging.getLogger(__name__)\n\n\nclass ToDevice(torch.nn.Module):\n    def __init__(self):\n        super(ToDevice, self).__init__()\n        self.register_buffer('buf', torch.zeros(1, dtype=torch.float32))\n\n    def forward(self, *xs):\n        if len(xs) == 1 and isinstance(xs[0], (tuple, list)):\n            xs = xs[0]\n\n        device = self.buf.device\n        out = []\n        for x in xs:\n            if x is not None and x.device != device:\n                out.append(x.to(device=device))\n            else:\n                out.append(x)\n        return out[0] if len(xs) == 1 else tuple(out)\n\n\nclass CopyChannels(torch.nn.Module):\n    def __init__(self, multiple=3, dim=1):\n        super(CopyChannels, self).__init__()\n        self.multiple = multiple\n        self.dim = dim\n\n    def forward(self, x):\n        return torch.cat([x for _ in range(self.multiple)], dim=self.dim)\n\n\nclass Normalize(torch.nn.Module):\n    def __init__(self, mean, std, inplace=False):\n        super(Normalize, self).__init__()\n        self.register_buffer('mean', torch.tensor([mean], dtype=torch.float32)[None, :, None, None])\n        self.register_buffer('std', torch.tensor([std], dtype=torch.float32)[None, :, None, None])\n        self.inplace = inplace\n\n    def forward(self, x):\n        if not self.inplace:\n            x = x.clone()\n\n        x.sub_(self.mean).div_(self.std)\n        return x\n\n\nclass Reshape(torch.nn.Module):\n    def __init__(self, *shape):\n        super(Reshape, self).__init__()\n        self.shape = shape\n\n    def forward(self, x):\n        return x.view(*self.shape)\n\n\nclass Flatten(torch.nn.Module):\n    def __init__(self):\n        super(Flatten, self).__init__()\n\n    def forward(self, x):\n        batch = x.shape[0]\n        return x.view([batch, -1])\n\n\nclass SplitTime(torch.nn.Module):\n    def __init__(self, times):\n        super(SplitTime, self).__init__()\n        self.times = times\n\n    def forward(self, x):\n        batch, channels, height, width = x.shape\n        return x.view(-1, self.times, channels, height, width)\n\n\nclass Permute(torch.nn.Module):\n    def __init__(self, *dims):\n        super(Permute, self).__init__()\n        self.dims = dims\n\n    def forward(self, x):\n        return x.permute(*self.dims)\n\n\nclass Cutout(torch.nn.Module):\n    def __init__(self, ratio=0.0):\n        super(Cutout, self).__init__()\n        self.ratio = ratio\n\n    def forward(self, input):\n        batch, channel, height, width = input.shape\n        w = int(width * self.ratio)\n        h = int(height * self.ratio)\n\n        if self.training and w > 0 and h > 0:\n            x = np.random.randint(width, size=(batch,))\n            y = np.random.randint(height, size=(batch,))\n\n            x1s = np.clip(x - w // 2, 0, width)\n            x2s = np.clip(x + w // 2, 0, width)\n            y1s = np.clip(y - h // 2, 0, height)\n            y2s = np.clip(y + h // 2, 0, height)\n\n            mask = torch.ones_like(input)\n            for idx, (x1, x2, y1, y2) in enumerate(zip(x1s, x2s, y1s, y2s)):\n                mask[idx, :, y1:y2, x1:x2] = 0.\n\n            input = input * mask\n        return input\n\n\nclass Mul(torch.nn.Module):\n    def __init__(self, weight):\n        super(Mul, self).__init__()\n        self.weight = weight\n\n    def forward(self, x):\n        return x * self.weight\n\n\nclass Flatten(torch.nn.Module):\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n\n\ndef decorator_tuple_to_args(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        args = list(args)\n        if len(args) == 2 and isinstance(args[1], (tuple, list)):\n            args[1:] = list(args[1])\n        return func(*args, **kwargs)\n    return wrapper\n\n\nclass Concat(torch.nn.Module):\n    def __init__(self, dim=1):\n        super(Concat, self).__init__()\n        self.dim = dim\n\n    @decorator_tuple_to_args\n    def forward(self, *xs):\n        return torch.cat(xs, dim=self.dim)\n\n\nclass MergeSum(torch.nn.Module):\n    @decorator_tuple_to_args\n    def forward(self, *xs):\n        return torch.sum(torch.stack(xs), dim=0)\n\n\nclass MergeProd(torch.nn.Module):\n    @decorator_tuple_to_args\n    def forward(self, *xs):\n        # xs = list(xs)\n        # s = xs[0].shape\n        # xs[0] = xs[0].view(s[0], 1, s[1])\n        return xs[0] * xs[1]\n\n\nclass Choice(torch.nn.Module):\n    def __init__(self, idx=0):\n        super(Choice, self).__init__()\n        self.idx = idx\n\n    @decorator_tuple_to_args\n    def forward(self, *xs):\n        return xs[self.idx]\n\n\nclass Toggle(torch.nn.Module):\n    def __init__(self, module):\n        super(Toggle, self).__init__()\n        self.module = module\n        self.on = True\n\n    def forward(self, x):\n        return self.module(x) if self.on else x\n\n\nclass Split(torch.nn.Module):\n    def __init__(self, *modules):\n        super(Split, self).__init__()\n        if len(modules) == 1 and isinstance(modules[0], OrderedDict):\n            for key, module in modules[0].items():\n                self.add_module(key, module)\n        else:\n            for idx, module in enumerate(modules):\n                self.add_module(str(idx), module)\n\n    def forward(self, x):\n        return tuple([m(x) for m in self._modules.values()])\n\n\nclass DropPath(torch.nn.Module):\n    def __init__(self, drop_prob=0.0):\n        super(DropPath, self).__init__()\n        self.drop_prob = drop_prob\n        self._half = False\n\n    def forward(self, x):\n        if self.training and self.drop_prob > 0.:\n            # shape = list(x.shape[:2]) + [1 for _ in x.shape[2:]]\n            shape = list(x.shape[:1]) + [1 for _ in x.shape[1:]]\n            keep_prob = 1. - self.drop_prob\n            mask = torch.cuda.FloatTensor(*shape).bernoulli_(keep_prob)\n            if self._half:\n                mask = mask.half()\n            x.div_(keep_prob)\n            x.mul_(mask)\n        return x\n\n    def half(self):\n        self._half = True\n\n    def float(self):\n        self._half = False\n\n\nclass DelayedPass(torch.nn.Module):\n    def __init__(self):\n        super(DelayedPass, self).__init__()\n        self.register_buffer('keep', None)\n\n    def forward(self, x):\n        rv = self.keep  # pylint: disable=access-member-before-definition\n        self.keep = x\n        return rv\n\n\nclass Reader(torch.nn.Module):\n    def __init__(self, x=None):\n        super(Reader, self).__init__()\n        self.x = x\n\n    def forward(self, x):  # pylint: disable=unused-argument\n        return self.x\n\n\nclass KeepByPass(torch.nn.Module):\n    def __init__(self):\n        super(KeepByPass, self).__init__()\n        self._reader = Reader()\n        self.info = {}\n\n    @property\n    def x(self):\n        return self._reader.x\n\n    def forward(self, x):\n        self._reader.x = x\n        return x\n\n    def reader(self):\n        return self._reader\n"""
skeleton/projects/api/__init__.py,0,b'# -*- coding: utf-8 -*-\n# pylint: disable=wildcard-import\nfrom __future__ import absolute_import\n\nfrom .model import Model\n'
skeleton/projects/api/model.py,0,"b'# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\n\n\nclass Model:\n    def __init__(self, metadata):\n        """"""\n        :param metadata: an AutoDLMetadata object. Its definition can be found in\n            https://github.com/zhengying-liu/autodl_starting_kit_stable/blob/master/AutoDL_ingestion_program/dataset.py#L41\n        """"""\n        self.metadata = metadata\n\n        self.done_training = False\n        # the loop of calling \'train\' and \'test\' will only run if self.done_training = False\n        # otherwinse, the looop will go until the time budge in used up set self.done_training = True\n        # when you think the model is converged or when is not enough time for next round of traning\n\n    def train(self, dataset, remaining_time_budget=None):\n        """"""\n        :param dataset: a `tf.data.Dataset` object. Each of its examples is of the form (example, labels)\n            where `example` is a dense 4-D Tensor of shape  (sequence_size, row_count, col_count, num_channels)\n            and `labels` is a 1-D Tensor of shape (output_dim,)\n            Here `output_dim` represents number of classes of this multilabel classification task.\n        :param remaining_time_budget: a float, time remaining to execute train()\n        :return: None\n        """"""\n        raise NotImplementedError\n\n    def test(self, dataset, remaining_time_budget=None):\n        """"""\n        :param: Same as that of `train` method, except that the labes will be empty (all zeros)\n        :return: predictions: A `numpy.ndarray` matrix of shape (sample_count, output_dim)\n            The values should be binary or in the interval [0,1].\n        """"""\n        raise NotImplementedError\n'"
