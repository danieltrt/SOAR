file_path,api_count,code
model.py,11,"b'import numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.nn.parameter import Parameter\n\n\nclass VIN(nn.Module):\n    def __init__(self, config):\n        super(VIN, self).__init__()\n        self.config = config\n        self.h = nn.Conv2d(\n            in_channels=config.l_i,\n            out_channels=config.l_h,\n            kernel_size=(3, 3),\n            stride=1,\n            padding=1,\n            bias=True)\n        self.r = nn.Conv2d(\n            in_channels=config.l_h,\n            out_channels=1,\n            kernel_size=(1, 1),\n            stride=1,\n            padding=0,\n            bias=False)\n        self.q = nn.Conv2d(\n            in_channels=1,\n            out_channels=config.l_q,\n            kernel_size=(3, 3),\n            stride=1,\n            padding=1,\n            bias=False)\n        self.fc = nn.Linear(in_features=config.l_q, out_features=8, bias=False)\n        self.w = Parameter(\n            torch.zeros(config.l_q, 1, 3, 3), requires_grad=True)\n        self.sm = nn.Softmax(dim=1)\n\n    def forward(self, X, S1, S2, config):\n        h = self.h(X)\n        r = self.r(h)\n        q = self.q(r)\n        v, _ = torch.max(q, dim=1, keepdim=True)\n        for i in range(0, config.k - 1):\n            q = F.conv2d(\n                torch.cat([r, v], 1),\n                torch.cat([self.q.weight, self.w], 1),\n                stride=1,\n                padding=1)\n            v, _ = torch.max(q, dim=1, keepdim=True)\n\n        q = F.conv2d(\n            torch.cat([r, v], 1),\n            torch.cat([self.q.weight, self.w], 1),\n            stride=1,\n            padding=1)\n\n        slice_s1 = S1.long().expand(config.imsize, 1, config.l_q, q.size(0))\n        slice_s1 = slice_s1.permute(3, 2, 1, 0)\n        q_out = q.gather(2, slice_s1).squeeze(2)\n\n        slice_s2 = S2.long().expand(1, config.l_q, q.size(0))\n        slice_s2 = slice_s2.permute(2, 1, 0)\n        q_out = q_out.gather(2, slice_s2).squeeze(2)\n\n        logits = self.fc(q_out)\n        return logits, self.sm(logits)\n'"
test.py,7,"b'import sys\nimport argparse\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport torch\nfrom torch.autograd import Variable\n\nfrom dataset.dataset import *\nfrom utility.utils import *\nfrom model import *\n\nfrom domains.gridworld import *\nfrom generators.obstacle_gen import *\n\n\ndef main(config,\n         n_domains=100,\n         max_obs=30,\n         max_obs_size=None,\n         n_traj=1,\n         n_actions=8):\n    # Correct vs total:\n    correct, total = 0.0, 0.0\n    # Automatic swith of GPU mode if available\n    use_GPU = torch.cuda.is_available()\n    # Instantiate a VIN model\n    vin = VIN(config)\n    # Load model parameters\n    vin.load_state_dict(torch.load(config.weights))\n    # Use GPU if available\n    if use_GPU:\n        vin = vin.cuda()\n\n    for dom in range(n_domains):\n        # Randomly select goal position\n        goal = [\n            np.random.randint(config.imsize),\n            np.random.randint(config.imsize)\n        ]\n        # Generate obstacle map\n        obs = obstacles([config.imsize, config.imsize], goal, max_obs_size)\n        # Add obstacles to map\n        n_obs = obs.add_n_rand_obs(max_obs)\n        # Add border to map\n        border_res = obs.add_border()\n        # Ensure we have valid map\n        if n_obs == 0 or not border_res:\n            continue\n        # Get final map\n        im = obs.get_final()\n\n        # Generate gridworld from obstacle map\n        G = gridworld(im, goal[0], goal[1])\n        # Get value prior\n        value_prior = G.get_reward_prior()\n        # Sample random trajectories to our goal\n        states_xy, states_one_hot = sample_trajectory(G, n_traj)\n\n        for i in range(n_traj):\n            if len(states_xy[i]) > 1:\n\n                # Get number of steps to goal\n                L = len(states_xy[i]) * 2\n                # Allocate space for predicted steps\n                pred_traj = np.zeros((L, 2))\n                # Set starting position\n                pred_traj[0, :] = states_xy[i][0, :]\n\n                for j in range(1, L):\n                    # Transform current state data\n                    state_data = pred_traj[j - 1, :]\n                    state_data = state_data.astype(np.int)\n                    # Transform domain to Networks expected input shape\n                    im_data = G.image.astype(np.int)\n                    im_data = 1 - im_data\n                    im_data = im_data.reshape(1, 1, config.imsize,\n                                              config.imsize)\n                    # Transfrom value prior to Networks expected input shape\n                    value_data = value_prior.astype(np.int)\n                    value_data = value_data.reshape(1, 1, config.imsize,\n                                                    config.imsize)\n                    # Get inputs as expected by network\n                    X_in = torch.from_numpy(\n                        np.append(im_data, value_data, axis=1)).float()\n                    S1_in = torch.from_numpy(state_data[0].reshape(\n                        [1, 1])).float()\n                    S2_in = torch.from_numpy(state_data[1].reshape(\n                        [1, 1])).float()\n                    # Send Tensors to GPU if available\n                    if use_GPU:\n                        X_in = X_in.cuda()\n                        S1_in = S1_in.cuda()\n                        S2_in = S2_in.cuda()\n                    # Wrap to autograd.Variable\n                    X_in, S1_in, S2_in = Variable(X_in), Variable(\n                        S1_in), Variable(S2_in)\n                    # Forward pass in our neural net\n                    _, predictions = vin(X_in, S1_in, S2_in, config)\n                    _, indices = torch.max(predictions.cpu(), 1, keepdim=True)\n                    a = indices.data.numpy()[0][0]\n                    # Transform prediction to indices\n                    s = G.map_ind_to_state(pred_traj[j - 1, 0],\n                                           pred_traj[j - 1, 1])\n                    ns = G.sample_next_state(s, a)\n                    nr, nc = G.get_coords(ns)\n                    pred_traj[j, 0] = nr\n                    pred_traj[j, 1] = nc\n                    if nr == goal[0] and nc == goal[1]:\n                        # We hit goal so fill remaining steps\n                        pred_traj[j + 1:, 0] = nr\n                        pred_traj[j + 1:, 1] = nc\n                        break\n                # Plot optimal and predicted path (also start, end)\n                if pred_traj[-1, 0] == goal[0] and pred_traj[-1, 1] == goal[1]:\n                    correct += 1\n                total += 1\n                if config.plot == True:\n                    visualize(G.image.T, states_xy[i], pred_traj)\n        sys.stdout.write(""\\r"" + str(int(\n            (float(dom) / n_domains) * 100.0)) + ""%"")\n        sys.stdout.flush()\n    sys.stdout.write(""\\n"")\n    print(\'Rollout Accuracy: {:.2f}%\'.format(100 * (correct / total)))\n\n\ndef visualize(dom, states_xy, pred_traj):\n    fig, ax = plt.subplots()\n    implot = plt.imshow(dom, cmap=""Greys_r"")\n    ax.plot(states_xy[:, 0], states_xy[:, 1], c=\'b\', label=\'Optimal Path\')\n    ax.plot(\n        pred_traj[:, 0], pred_traj[:, 1], \'-X\', c=\'r\', label=\'Predicted Path\')\n    ax.plot(states_xy[0, 0], states_xy[0, 1], \'-o\', label=\'Start\')\n    ax.plot(states_xy[-1, 0], states_xy[-1, 1], \'-s\', label=\'Goal\')\n    legend = ax.legend(loc=\'upper right\', shadow=False)\n    for label in legend.get_texts():\n        label.set_fontsize(\'x-small\')  # the legend text size\n    for label in legend.get_lines():\n        label.set_linewidth(0.5)  # the legend line width\n    plt.draw()\n    plt.waitforbuttonpress(0)\n    plt.close(fig)\n\n\nif __name__ == \'__main__\':\n    # Parsing training parameters\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--weights\',\n        type=str,\n        default=\'trained/vin_8x8.pth\',\n        help=\'Path to trained weights\')\n    parser.add_argument(\'--plot\', action=\'store_true\', default=False)\n    parser.add_argument(\'--imsize\', type=int, default=8, help=\'Size of image\')\n    parser.add_argument(\n        \'--k\', type=int, default=10, help=\'Number of Value Iterations\')\n    parser.add_argument(\n        \'--l_i\', type=int, default=2, help=\'Number of channels in input layer\')\n    parser.add_argument(\n        \'--l_h\',\n        type=int,\n        default=150,\n        help=\'Number of channels in first hidden layer\')\n    parser.add_argument(\n        \'--l_q\',\n        type=int,\n        default=10,\n        help=\'Number of channels in q layer (~actions) in VI-module\')\n    config = parser.parse_args()\n    # Compute Paths generated by network and plot\n    main(config)\n'"
train.py,9,"b'import time\nimport argparse\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\nfrom dataset.dataset import *\nfrom utility.utils import *\nfrom model import *\n\n\ndef train(net, trainloader, config, criterion, optimizer):\n    print_header()\n    for epoch in range(config.epochs):  # Loop over dataset multiple times\n        avg_error, avg_loss, num_batches = 0.0, 0.0, 0.0\n        start_time = time.time()\n        for i, data in enumerate(trainloader):  # Loop over batches of data\n            # Get input batch\n            X, S1, S2, labels = data\n            if X.size()[0] != config.batch_size:\n                continue  # Drop those data, if not enough for a batch\n            # Automaticlly select device to make the code device agnostic \n            device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")\n            X = X.to(device)\n            S1 = S1.to(device)\n            S2 = S2.to(device)\n            labels = labels.to(device)\n            net = net.to(device)\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n            # Forward pass\n            outputs, predictions = net(X, S1, S2, config)\n            # Loss\n            loss = criterion(outputs, labels)\n            # Backward pass\n            loss.backward()\n            # Update params\n            optimizer.step()\n            # Calculate Loss and Error\n            loss_batch, error_batch = get_stats(loss, predictions, labels)\n            avg_loss += loss_batch\n            avg_error += error_batch\n            num_batches += 1\n        time_duration = time.time() - start_time\n        # Print epoch logs\n        print_stats(epoch, avg_loss, avg_error, num_batches, time_duration)\n    print(\'\\nFinished training. \\n\')\n\n\ndef test(net, testloader, config):\n    total, correct = 0.0, 0.0\n    for i, data in enumerate(testloader):\n        # Get inputs\n        X, S1, S2, labels = data\n        if X.size()[0] != config.batch_size:\n            continue  # Drop those data, if not enough for a batch\n        # automaticlly select device, device agnostic \n        device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")\n        X = X.to(device)\n        S1 = S1.to(device)\n        S2 = S2.to(device)\n        labels = labels.to(device)\n        net = net.to(device)\n        # Forward pass\n        outputs, predictions = net(X, S1, S2, config)\n        # Select actions with max scores(logits)\n        _, predicted = torch.max(outputs, dim=1, keepdim=True)\n        # Unwrap autograd.Variable to Tensor\n        predicted = predicted.data\n        # Compute test accuracy\n        correct += (torch.eq(torch.squeeze(predicted), labels)).sum()\n        total += labels.size()[0]\n    print(\'Test Accuracy: {:.2f}%\'.format(100 * (correct / total)))\n\n\nif __name__ == \'__main__\':\n    # Parsing training parameters\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \'--datafile\',\n        type=str,\n        default=\'dataset/gridworld_8x8.npz\',\n        help=\'Path to data file\')\n    parser.add_argument(\'--imsize\', type=int, default=8, help=\'Size of image\')\n    parser.add_argument(\n        \'--lr\',\n        type=float,\n        default=0.005,\n        help=\'Learning rate, [0.01, 0.005, 0.002, 0.001]\')\n    parser.add_argument(\n        \'--epochs\', type=int, default=30, help=\'Number of epochs to train\')\n    parser.add_argument(\n        \'--k\', type=int, default=10, help=\'Number of Value Iterations\')\n    parser.add_argument(\n        \'--l_i\', type=int, default=2, help=\'Number of channels in input layer\')\n    parser.add_argument(\n        \'--l_h\',\n        type=int,\n        default=150,\n        help=\'Number of channels in first hidden layer\')\n    parser.add_argument(\n        \'--l_q\',\n        type=int,\n        default=10,\n        help=\'Number of channels in q layer (~actions) in VI-module\')\n    parser.add_argument(\n        \'--batch_size\', type=int, default=128, help=\'Batch size\')\n    config = parser.parse_args()\n    # Get path to save trained model\n    save_path = ""trained/vin_{0}x{0}.pth"".format(config.imsize)\n    # Instantiate a VIN model\n    net = VIN(config)\n    # Loss\n    criterion = nn.CrossEntropyLoss()\n    # Optimizer\n    optimizer = optim.RMSprop(net.parameters(), lr=config.lr, eps=1e-6)\n    # Dataset transformer: torchvision.transforms\n    transform = None\n    # Define Dataset\n    trainset = GridworldData(\n        config.datafile, imsize=config.imsize, train=True, transform=transform)\n    testset = GridworldData(\n        config.datafile,\n        imsize=config.imsize,\n        train=False,\n        transform=transform)\n    # Create Dataloader\n    trainloader = torch.utils.data.DataLoader(\n        trainset, batch_size=config.batch_size, shuffle=True, num_workers=0)\n    testloader = torch.utils.data.DataLoader(\n        testset, batch_size=config.batch_size, shuffle=False, num_workers=0)\n    # Train the model\n    train(net, trainloader, config, criterion, optimizer)\n    # Test accuracy\n    test(net, testloader, config)\n    # Save the trained model parameters\n    torch.save(net.state_dict(), save_path)\n'"
dataset/__init__.py,0,b''
dataset/dataset.py,2,"b'import numpy as np\n\nimport torch\nimport torch.utils.data as data\n\n\nclass GridworldData(data.Dataset):\n    def __init__(self,\n                 file,\n                 imsize,\n                 train=True,\n                 transform=None,\n                 target_transform=None):\n        assert file.endswith(\'.npz\')  # Must be .npz format\n        self.file = file\n        self.imsize = imsize\n        self.transform = transform\n        self.target_transform = target_transform\n        self.train = train  # training set or test set\n\n        self.images, self.S1, self.S2, self.labels =  \\\n                                self._process(file, self.train)\n\n    def __getitem__(self, index):\n        img = self.images[index]\n        s1 = self.S1[index]\n        s2 = self.S2[index]\n        label = self.labels[index]\n        # Apply transform if we have one\n        if self.transform is not None:\n            img = self.transform(img)\n        else:  # Internal default transform: Just to Tensor\n            img = torch.from_numpy(img)\n        # Apply target transform if we have one\n        if self.target_transform is not None:\n            label = self.target_transform(label)\n        return img, int(s1), int(s2), int(label)\n\n    def __len__(self):\n        return self.images.shape[0]\n\n    def _process(self, file, train):\n        """"""Data format: A list, [train data, test data]\n        Each data sample: label, S1, S2, Images, in this order.\n        """"""\n        with np.load(file, mmap_mode=\'r\') as f:\n            if train:\n                images = f[\'arr_0\']\n                S1 = f[\'arr_1\']\n                S2 = f[\'arr_2\']\n                labels = f[\'arr_3\']\n            else:\n                images = f[\'arr_4\']\n                S1 = f[\'arr_5\']\n                S2 = f[\'arr_6\']\n                labels = f[\'arr_7\']\n        # Set proper datatypes\n        images = images.astype(np.float32)\n        S1 = S1.astype(int)  # (S1, S2) location are integers\n        S2 = S2.astype(int)\n        labels = labels.astype(int)  # labels are integers\n        # Print number of samples\n        if train:\n            print(""Number of Train Samples: {0}"".format(images.shape[0]))\n        else:\n            print(""Number of Test Samples: {0}"".format(images.shape[0]))\n        return images, S1, S2, labels\n'"
dataset/make_training_data.py,0,"b'import sys\n\nimport numpy as np\nfrom dataset import *\n\nsys.path.append(\'.\')\nfrom domains.gridworld import *\nfrom generators.obstacle_gen import *\nsys.path.remove(\'.\')\n\n\ndef extract_action(traj):\n    # Given a trajectory, outputs a 1D vector of\n    #  actions corresponding to the trajectory.\n    n_actions = 8\n    action_vecs = np.asarray([[-1., 0.], [1., 0.], [0., 1.], [0., -1.],\n                              [-1., 1.], [-1., -1.], [1., 1.], [1., -1.]])\n    action_vecs[4:] = 1 / np.sqrt(2) * action_vecs[4:]\n    action_vecs = action_vecs.T\n    state_diff = np.diff(traj, axis=0)\n    norm_state_diff = state_diff * np.tile(\n        1 / np.sqrt(np.sum(np.square(state_diff), axis=1)), (2, 1)).T\n    prj_state_diff = np.dot(norm_state_diff, action_vecs)\n    actions_one_hot = np.abs(prj_state_diff - 1) < 0.00001\n    actions = np.dot(actions_one_hot, np.arange(n_actions).T)\n    return actions\n\n\ndef make_data(dom_size, n_domains, max_obs, max_obs_size, n_traj,\n              state_batch_size):\n\n    X_l = []\n    S1_l = []\n    S2_l = []\n    Labels_l = []\n\n    dom = 0.0\n    while dom <= n_domains:\n        goal = [np.random.randint(dom_size[0]), np.random.randint(dom_size[1])]\n        # Generate obstacle map\n        obs = obstacles([dom_size[0], dom_size[1]], goal, max_obs_size)\n        # Add obstacles to map\n        n_obs = obs.add_n_rand_obs(max_obs)\n        # Add border to map\n        border_res = obs.add_border()\n        # Ensure we have valid map\n        if n_obs == 0 or not border_res:\n            continue\n        # Get final map\n        im = obs.get_final()\n        # Generate gridworld from obstacle map\n        G = gridworld(im, goal[0], goal[1])\n        # Get value prior\n        value_prior = G.t_get_reward_prior()\n        # Sample random trajectories to our goal\n        states_xy, states_one_hot = sample_trajectory(G, n_traj)\n        for i in range(n_traj):\n            if len(states_xy[i]) > 1:\n                # Get optimal actions for each state\n                actions = extract_action(states_xy[i])\n                ns = states_xy[i].shape[0] - 1\n                # Invert domain image => 0 = free, 1 = obstacle\n                image = 1 - im\n                # Resize domain and goal images and concate\n                image_data = np.resize(image, (1, 1, dom_size[0], dom_size[1]))\n                value_data = np.resize(value_prior,\n                                       (1, 1, dom_size[0], dom_size[1]))\n                iv_mixed = np.concatenate((image_data, value_data), axis=1)\n                X_current = np.tile(iv_mixed, (ns, 1, 1, 1))\n                # Resize states\n                S1_current = np.expand_dims(states_xy[i][0:ns, 0], axis=1)\n                S2_current = np.expand_dims(states_xy[i][0:ns, 1], axis=1)\n                # Resize labels\n                Labels_current = np.expand_dims(actions, axis=1)\n                # Append to output list\n                X_l.append(X_current)\n                S1_l.append(S1_current)\n                S2_l.append(S2_current)\n                Labels_l.append(Labels_current)\n        dom += 1\n        sys.stdout.write(""\\r"" + str(int((dom / n_domains) * 100)) + ""%"")\n        sys.stdout.flush()\n    sys.stdout.write(""\\n"")\n    # Concat all outputs\n    X_f = np.concatenate(X_l)\n    S1_f = np.concatenate(S1_l)\n    S2_f = np.concatenate(S2_l)\n    Labels_f = np.concatenate(Labels_l)\n    return X_f, S1_f, S2_f, Labels_f\n\n\ndef main(dom_size=[28, 28],\n         n_domains=5000,\n         max_obs=50,\n         max_obs_size=2,\n         n_traj=7,\n         state_batch_size=1):\n    # Get path to save dataset\n    save_path = ""dataset/gridworld_{0}x{1}"".format(dom_size[0], dom_size[1])\n    # Get training data\n    print(""Now making training data..."")\n    X_out_tr, S1_out_tr, S2_out_tr, Labels_out_tr = make_data(\n        dom_size, n_domains, max_obs, max_obs_size, n_traj, state_batch_size)\n    # Get testing data\n    print(""\\nNow making  testing data..."")\n    X_out_ts, S1_out_ts, S2_out_ts, Labels_out_ts = make_data(\n        dom_size, n_domains / 6, max_obs, max_obs_size, n_traj,\n        state_batch_size)\n    # Save dataset\n    np.savez_compressed(save_path, X_out_tr, S1_out_tr, S2_out_tr,\n                        Labels_out_tr, X_out_ts, S1_out_ts, S2_out_ts,\n                        Labels_out_ts)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
domains/__init__.py,0,b''
domains/gridworld.py,0,"b'import numpy as np\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse.csgraph import dijkstra\n\n\nclass gridworld:\n    """"""A class for making gridworlds""""""\n\n    def __init__(self, image, targetx, targety):\n        self.image = image\n        self.n_row = image.shape[0]\n        self.n_col = image.shape[1]\n        self.obstacles = []\n        self.freespace = []\n        self.targetx = targetx\n        self.targety = targety\n        self.G = []\n        self.W = []\n        self.R = []\n        self.P = []\n        self.A = []\n        self.n_states = 0\n        self.n_actions = 0\n        self.state_map_col = []\n        self.state_map_row = []\n        self.set_vals()\n\n    def set_vals(self):\n        # Setup function to initialize all necessary\n        #  data\n        row_obs, col_obs = np.where(self.image == 0)\n        row_free, col_free = np.where(self.image != 0)\n        self.obstacles = [row_obs, col_obs]\n        self.freespace = [row_free, col_free]\n\n        n_states = self.n_row * self.n_col\n        n_actions = 8\n        self.n_states = n_states\n        self.n_actions = n_actions\n\n        p_n = np.zeros((self.n_states, self.n_states))\n        p_s = np.zeros((self.n_states, self.n_states))\n        p_e = np.zeros((self.n_states, self.n_states))\n        p_w = np.zeros((self.n_states, self.n_states))\n        p_ne = np.zeros((self.n_states, self.n_states))\n        p_nw = np.zeros((self.n_states, self.n_states))\n        p_se = np.zeros((self.n_states, self.n_states))\n        p_sw = np.zeros((self.n_states, self.n_states))\n\n        R = -1 * np.ones((self.n_states, self.n_actions))\n        R[:, 4:self.n_actions] = R[:, 4:self.n_actions] * np.sqrt(2)\n        target = np.ravel_multi_index(\n            [self.targetx, self.targety], (self.n_row, self.n_col), order=\'F\')\n        R[target, :] = 0\n\n        for row in range(0, self.n_row):\n            for col in range(0, self.n_col):\n\n                curpos = np.ravel_multi_index(\n                    [row, col], (self.n_row, self.n_col), order=\'F\')\n\n                rows, cols = self.neighbors(row, col)\n\n                neighbor_inds = np.ravel_multi_index(\n                    [rows, cols], (self.n_row, self.n_col), order=\'F\')\n\n                p_n[curpos, neighbor_inds[\n                    0]] = p_n[curpos, neighbor_inds[0]] + 1\n                p_s[curpos, neighbor_inds[\n                    1]] = p_s[curpos, neighbor_inds[1]] + 1\n                p_e[curpos, neighbor_inds[\n                    2]] = p_e[curpos, neighbor_inds[2]] + 1\n                p_w[curpos, neighbor_inds[\n                    3]] = p_w[curpos, neighbor_inds[3]] + 1\n                p_ne[curpos, neighbor_inds[\n                    4]] = p_ne[curpos, neighbor_inds[4]] + 1\n                p_nw[curpos, neighbor_inds[\n                    5]] = p_nw[curpos, neighbor_inds[5]] + 1\n                p_se[curpos, neighbor_inds[\n                    6]] = p_se[curpos, neighbor_inds[6]] + 1\n                p_sw[curpos, neighbor_inds[\n                    7]] = p_sw[curpos, neighbor_inds[7]] + 1\n\n        G = np.logical_or.reduce((p_n, p_s, p_e, p_w, p_ne, p_nw, p_se, p_sw))\n\n        W = np.maximum(\n            np.maximum(\n                np.maximum(\n                    np.maximum(\n                        np.maximum(np.maximum(np.maximum(p_n, p_s), p_e), p_w),\n                        np.sqrt(2) * p_ne),\n                    np.sqrt(2) * p_nw),\n                np.sqrt(2) * p_se),\n            np.sqrt(2) * p_sw)\n\n        non_obstacles = np.ravel_multi_index(\n            [self.freespace[0], self.freespace[1]], (self.n_row, self.n_col),\n            order=\'F\')\n\n        non_obstacles = np.sort(non_obstacles)\n        p_n = p_n[non_obstacles, :]\n        p_n = np.expand_dims(p_n[:, non_obstacles], axis=2)\n        p_s = p_s[non_obstacles, :]\n        p_s = np.expand_dims(p_s[:, non_obstacles], axis=2)\n        p_e = p_e[non_obstacles, :]\n        p_e = np.expand_dims(p_e[:, non_obstacles], axis=2)\n        p_w = p_w[non_obstacles, :]\n        p_w = np.expand_dims(p_w[:, non_obstacles], axis=2)\n        p_ne = p_ne[non_obstacles, :]\n        p_ne = np.expand_dims(p_ne[:, non_obstacles], axis=2)\n        p_nw = p_nw[non_obstacles, :]\n        p_nw = np.expand_dims(p_nw[:, non_obstacles], axis=2)\n        p_se = p_se[non_obstacles, :]\n        p_se = np.expand_dims(p_se[:, non_obstacles], axis=2)\n        p_sw = p_sw[non_obstacles, :]\n        p_sw = np.expand_dims(p_sw[:, non_obstacles], axis=2)\n        G = G[non_obstacles, :]\n        G = G[:, non_obstacles]\n        W = W[non_obstacles, :]\n        W = W[:, non_obstacles]\n        R = R[non_obstacles, :]\n\n        P = np.concatenate(\n            (p_n, p_s, p_e, p_w, p_ne, p_nw, p_se, p_sw), axis=2)\n\n        self.G = G\n        self.W = W\n        self.P = P\n        self.R = R\n        state_map_col, state_map_row = np.meshgrid(\n            np.arange(0, self.n_col), np.arange(0, self.n_row))\n        self.state_map_col = state_map_col.flatten(\'F\')[non_obstacles]\n        self.state_map_row = state_map_row.flatten(\'F\')[non_obstacles]\n\n    def get_graph(self):\n        # Returns graph\n        G = self.G\n        W = self.W[self.W != 0]\n        return G, W\n\n    def get_graph_inv(self):\n        # Returns transpose of graph\n        G = self.G.T\n        W = self.W.T\n        return G, W\n\n    def val_2_image(self, val):\n        # Zeros for obstacles, val for free space\n        im = np.zeros((self.n_row, self.n_col))\n        im[self.freespace[0], self.freespace[1]] = val\n        return im\n\n    def get_value_prior(self):\n        # Returns value prior for gridworld\n        s_map_col, s_map_row = np.meshgrid(\n            np.arange(0, self.n_col), np.arange(0, self.n_row))\n        im = np.sqrt(\n            np.square(s_map_col - self.targety) +\n            np.square(s_map_row - self.targetx))\n        return im\n\n    def get_reward_prior(self):\n        # Returns reward prior for gridworld\n        im = -1 * np.ones((self.n_row, self.n_col))\n        im[self.targetx, self.targety] = 10\n        return im\n\n    def t_get_reward_prior(self):\n        # Returns reward prior as needed for\n        #  dataset generation\n        im = np.zeros((self.n_row, self.n_col))\n        im[self.targetx, self.targety] = 10\n        return im\n\n    def get_state_image(self, row, col):\n        # Zeros everywhere except [row,col]\n        im = np.zeros((self.n_row, self.n_col))\n        im[row, col] = 1\n        return im\n\n    def map_ind_to_state(self, row, col):\n        # Takes [row, col] and maps to a state\n        rw = np.where(self.state_map_row == row)\n        cl = np.where(self.state_map_col == col)\n        return np.intersect1d(rw, cl)[0]\n\n    def get_coords(self, states):\n        # Given a state or states, returns\n        #  [row,col] pairs for the state(s)\n        non_obstacles = np.ravel_multi_index(\n            [self.freespace[0], self.freespace[1]], (self.n_row, self.n_col),\n            order=\'F\')\n        non_obstacles = np.sort(non_obstacles)\n        states = states.astype(int)\n        r, c = np.unravel_index(\n            non_obstacles[states], (self.n_col, self.n_row), order=\'F\')\n        return r, c\n\n    def rand_choose(self, in_vec):\n        # Samples\n        if len(in_vec.shape) > 1:\n            if in_vec.shape[1] == 1:\n                in_vec = in_vec.T\n        temp = np.hstack((np.zeros((1)), np.cumsum(in_vec))).astype(\'int\')\n        q = np.random.rand()\n        x = np.where(q > temp[0:-1])\n        y = np.where(q < temp[1:])\n        return np.intersect1d(x, y)[0]\n\n    def next_state_prob(self, s, a):\n        # Gets next state probability for\n        #  a given action (a)\n        if hasattr(a, ""__iter__""):\n            p = np.squeeze(self.P[s, :, a])\n        else:\n            p = np.squeeze(self.P[s, :, a]).T\n        return p\n\n    def sample_next_state(self, s, a):\n        # Gets the next state given the\n        #  current state (s) and an\n        #  action (a)\n        vec = self.next_state_prob(s, a)\n        result = self.rand_choose(vec)\n        return result\n\n    def get_size(self):\n        # Returns domain size\n        return self.n_row, self.n_col\n\n    def north(self, row, col):\n        # Returns new [row,col]\n        #  if we take the action\n        new_row = np.max([row - 1, 0])\n        new_col = col\n        if self.image[new_row, new_col] == 0:\n            new_row = row\n            new_col = col\n        return new_row, new_col\n\n    def northeast(self, row, col):\n        # Returns new [row,col]\n        #  if we take the action\n        new_row = np.max([row - 1, 0])\n        new_col = np.min([col + 1, self.n_col - 1])\n        if self.image[new_row, new_col] == 0:\n            new_row = row\n            new_col = col\n        return new_row, new_col\n\n    def northwest(self, row, col):\n        # Returns new [row,col]\n        #  if we take the action\n        new_row = np.max([row - 1, 0])\n        new_col = np.max([col - 1, 0])\n        if self.image[new_row, new_col] == 0:\n            new_row = row\n            new_col = col\n        return new_row, new_col\n\n    def south(self, row, col):\n        # Returns new [row,col]\n        #  if we take the action\n        new_row = np.min([row + 1, self.n_row - 1])\n        new_col = col\n        if self.image[new_row, new_col] == 0:\n            new_row = row\n            new_col = col\n        return new_row, new_col\n\n    def southeast(self, row, col):\n        # Returns new [row,col]\n        #  if we take the action\n        new_row = np.min([row + 1, self.n_row - 1])\n        new_col = np.min([col + 1, self.n_col - 1])\n        if self.image[new_row, new_col] == 0:\n            new_row = row\n            new_col = col\n        return new_row, new_col\n\n    def southwest(self, row, col):\n        # Returns new [row,col]\n        #  if we take the action\n        new_row = np.min([row + 1, self.n_row - 1])\n        new_col = np.max([col - 1, 0])\n        if self.image[new_row, new_col] == 0:\n            new_row = row\n            new_col = col\n        return new_row, new_col\n\n    def east(self, row, col):\n        # Returns new [row,col]\n        #  if we take the action\n        new_row = row\n        new_col = np.min([col + 1, self.n_col - 1])\n        if self.image[new_row, new_col] == 0:\n            new_row = row\n            new_col = col\n        return new_row, new_col\n\n    def west(self, row, col):\n        # Returns new [row,col]\n        #  if we take the action\n        new_row = row\n        new_col = np.max([col - 1, 0])\n        if self.image[new_row, new_col] == 0:\n            new_row = row\n            new_col = col\n        return new_row, new_col\n\n    def neighbors(self, row, col):\n        # Get valid neighbors in all valid directions\n        rows, cols = self.north(row, col)\n        new_row, new_col = self.south(row, col)\n        rows, cols = np.append(rows, new_row), np.append(cols, new_col)\n        new_row, new_col = self.east(row, col)\n        rows, cols = np.append(rows, new_row), np.append(cols, new_col)\n        new_row, new_col = self.west(row, col)\n        rows, cols = np.append(rows, new_row), np.append(cols, new_col)\n        new_row, new_col = self.northeast(row, col)\n        rows, cols = np.append(rows, new_row), np.append(cols, new_col)\n        new_row, new_col = self.northwest(row, col)\n        rows, cols = np.append(rows, new_row), np.append(cols, new_col)\n        new_row, new_col = self.southeast(row, col)\n        rows, cols = np.append(rows, new_row), np.append(cols, new_col)\n        new_row, new_col = self.southwest(row, col)\n        rows, cols = np.append(rows, new_row), np.append(cols, new_col)\n        return rows, cols\n\n\ndef trace_path(pred, source, target):\n    # traces back shortest path from\n    #  source to target given pred\n    #  (a predicessor list)\n    max_len = 1000\n    path = np.zeros((max_len, 1))\n    i = max_len - 1\n    path[i] = target\n    while path[i] != source and i > 0:\n        try:\n            path[i - 1] = pred[int(path[i])]\n            i -= 1\n        except Exception as e:\n            return []\n    if i >= 0:\n        path = path[i:]\n    else:\n        path = None\n    return path\n\n\ndef sample_trajectory(M, n_states):\n    # Samples trajectories from random nodes\n    #  in our domain (M)\n    G, W = M.get_graph_inv()\n    N = G.shape[0]\n    if N >= n_states:\n        rand_ind = np.random.permutation(N)\n    else:\n        rand_ind = np.tile(np.random.permutation(N), (1, 10))\n    init_states = rand_ind[0:n_states].flatten()\n    goal_s = M.map_ind_to_state(M.targetx, M.targety)\n    states = []\n    states_xy = []\n    states_one_hot = []\n    # Get optimal path from graph\n    g_dense = W\n    g_masked = np.ma.masked_values(g_dense, 0)\n    g_sparse = csr_matrix(g_dense)\n    d, pred = dijkstra(g_sparse, indices=goal_s, return_predecessors=True)\n    for i in range(n_states):\n        path = trace_path(pred, goal_s, init_states[i])\n        path = np.flip(path, 0)\n        states.append(path)\n    for state in states:\n        L = len(state)\n        r, c = M.get_coords(state)\n        row_m = np.zeros((L, M.n_row))\n        col_m = np.zeros((L, M.n_col))\n        for i in range(L):\n            row_m[i, r[i]] = 1\n            col_m[i, c[i]] = 1\n        states_one_hot.append(np.hstack((row_m, col_m)))\n        states_xy.append(np.hstack((r, c)))\n    return states_xy, states_one_hot\n'"
generators/__init__.py,0,b''
generators/obstacle_gen.py,0,"b'import numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass obstacles:\n    """"""A class for generating obstacles in a domain""""""\n\n    def __init__(self,\n                 domsize=None,\n                 mask=None,\n                 size_max=None,\n                 dom=None,\n                 obs_types=None,\n                 num_types=None):\n        self.domsize = domsize or []\n        self.mask = mask or []\n        self.dom = dom or np.zeros(self.domsize)\n        self.obs_types = obs_types or [""circ"", ""rect""]\n        self.num_types = num_types or len(self.obs_types)\n        self.size_max = size_max or np.max(self.domsize) / 4\n\n    def check_mask(self, dom=None):\n        # Ensure goal is in free space\n        if dom is not None:\n            return np.any(dom[self.mask[0], self.mask[1]])\n        else:\n            return np.any(self.dom[self.mask[0], self.mask[1]])\n\n    def insert_rect(self, x, y, height, width):\n        # Insert a rectangular obstacle into map\n        im_try = np.copy(self.dom)\n        im_try[x:x + height, y:y + width] = 1\n        return im_try\n\n    def add_rand_obs(self, obj_type):\n        # Add random (valid) obstacle to map\n        if obj_type == ""circ"":\n            print(""circ is not yet implemented... sorry"")\n        elif obj_type == ""rect"":\n            rand_height = int(np.ceil(np.random.rand() * self.size_max))\n            rand_width = int(np.ceil(np.random.rand() * self.size_max))\n            randx = int(np.ceil(np.random.rand() * (self.domsize[1] - 1)))\n            randy = int(np.ceil(np.random.rand() * (self.domsize[1] - 1)))\n            im_try = self.insert_rect(randx, randy, rand_height, rand_width)\n        if self.check_mask(im_try):\n            return False\n        else:\n            self.dom = im_try\n            return True\n\n    def add_n_rand_obs(self, n):\n        # Add random (valid) obstacles to map\n        count = 0\n        for i in range(n):\n            obj_type = ""rect""\n            if self.add_rand_obs(obj_type):\n                count += 1\n        return count\n\n    def add_border(self):\n        # Make full outer border an obstacle\n        im_try = np.copy(self.dom)\n        im_try[0:self.domsize[0], 0] = 1\n        im_try[0, 0:self.domsize[1]] = 1\n        im_try[0:self.domsize[0], self.domsize[1] - 1] = 1\n        im_try[self.domsize[0] - 1, 0:self.domsize[1]] = 1\n        if self.check_mask(im_try):\n            return False\n        else:\n            self.dom = im_try\n            return True\n\n    def get_final(self):\n        # Process obstacle map for domain\n        im = np.copy(self.dom)\n        im = np.max(im) - im\n        im = im / np.max(im)\n        return im\n\n    def show(self):\n        # Utility function to view obstacle map\n        plt.imshow(self.get_final(), cmap=\'Greys\')\n        plt.show()\n\n    def _print(self):\n        # Utility function to view obstacle map\n        #  information\n        print(""domsize: "", self.domsize)\n        print(""mask: "", self.mask)\n        print(""dom: "", self.dom)\n        print(""obs_types: "", self.obs_types)\n        print(""num_types: "", self.num_types)\n        print(""size_max: "", self.size_max)\n'"
utility/__init__.py,0,b''
utility/utils.py,0,"b'import numpy as np\nimport torch\n\n\ndef fmt_row(width, row):\n    out = "" | "".join(fmt_item(x, width) for x in row)\n    return out\n\n\ndef fmt_item(x, l):\n    if isinstance(x, np.ndarray):\n        assert x.ndim == 0\n        x = x.item()\n    if isinstance(x, float): rep = ""%g"" % x\n    else: rep = str(x)\n    return "" "" * (l - len(rep)) + rep\n\n\ndef get_stats(loss, predictions, labels):\n    cp = np.argmax(predictions.cpu().data.numpy(), 1)\n    error = np.mean(cp != labels.cpu().data.numpy())\n    return loss.item(), error\n\n\ndef print_stats(epoch, avg_loss, avg_error, num_batches, time_duration):\n    print(\n        fmt_row(10, [\n            epoch + 1, avg_loss / num_batches, avg_error / num_batches,\n            time_duration\n        ]))\n\n\ndef print_header():\n    print(fmt_row(10, [""Epoch"", ""Train Loss"", ""Train Error"", ""Epoch Time""]))\n'"
