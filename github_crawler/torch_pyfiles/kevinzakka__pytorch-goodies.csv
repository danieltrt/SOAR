file_path,api_count,code
losses.py,23,"b'""""""Common image segmentation losses.\n""""""\n\nimport torch\n\nfrom torch.nn import functional as F\n\n\ndef bce_loss(true, logits, pos_weight=None):\n    """"""Computes the weighted binary cross-entropy loss.\n\n    Args:\n        true: a tensor of shape [B, 1, H, W].\n        logits: a tensor of shape [B, 1, H, W]. Corresponds to\n            the raw output or logits of the model.\n        pos_weight: a scalar representing the weight attributed\n            to the positive class. This is especially useful for\n            an imbalanced dataset.\n\n    Returns:\n        bce_loss: the weighted binary cross-entropy loss.\n    """"""\n    bce_loss = F.binary_cross_entropy_with_logits(\n        logits.float(),\n        true.float(),\n        pos_weight=pos_weight,\n    )\n    return bce_loss\n\n\ndef ce_loss(true, logits, weights, ignore=255):\n    """"""Computes the weighted multi-class cross-entropy loss.\n\n    Args:\n        true: a tensor of shape [B, 1, H, W].\n        logits: a tensor of shape [B, C, H, W]. Corresponds to\n            the raw output or logits of the model.\n        weight: a tensor of shape [C,]. The weights attributed\n            to each class.\n        ignore: the class index to ignore.\n\n    Returns:\n        ce_loss: the weighted multi-class cross-entropy loss.\n    """"""\n    ce_loss = F.cross_entropy(\n        logits.float(),\n        true.long(),\n        ignore_index=ignore,\n        weight=weights,\n    )\n    return ce_loss\n\n\ndef dice_loss(true, logits, eps=1e-7):\n    """"""Computes the S\xc3\xb8rensen\xe2\x80\x93Dice loss.\n\n    Note that PyTorch optimizers minimize a loss. In this\n    case, we would like to maximize the dice loss so we\n    return the negated dice loss.\n\n    Args:\n        true: a tensor of shape [B, 1, H, W].\n        logits: a tensor of shape [B, C, H, W]. Corresponds to\n            the raw output or logits of the model.\n        eps: added to the denominator for numerical stability.\n\n    Returns:\n        dice_loss: the S\xc3\xb8rensen\xe2\x80\x93Dice loss.\n    """"""\n    num_classes = logits.shape[1]\n    if num_classes == 1:\n        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n        pos_prob = torch.sigmoid(logits)\n        neg_prob = 1 - pos_prob\n        probas = torch.cat([pos_prob, neg_prob], dim=1)\n    else:\n        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        probas = F.softmax(logits, dim=1)\n    true_1_hot = true_1_hot.type(logits.type())\n    dims = (0,) + tuple(range(2, true.ndimension()))\n    intersection = torch.sum(probas * true_1_hot, dims)\n    cardinality = torch.sum(probas + true_1_hot, dims)\n    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n    return (1 - dice_loss)\n\n\ndef jaccard_loss(true, logits, eps=1e-7):\n    """"""Computes the Jaccard loss, a.k.a the IoU loss.\n\n    Note that PyTorch optimizers minimize a loss. In this\n    case, we would like to maximize the jaccard loss so we\n    return the negated jaccard loss.\n\n    Args:\n        true: a tensor of shape [B, H, W] or [B, 1, H, W].\n        logits: a tensor of shape [B, C, H, W]. Corresponds to\n            the raw output or logits of the model.\n        eps: added to the denominator for numerical stability.\n\n    Returns:\n        jacc_loss: the Jaccard loss.\n    """"""\n    num_classes = logits.shape[1]\n    if num_classes == 1:\n        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n        pos_prob = torch.sigmoid(logits)\n        neg_prob = 1 - pos_prob\n        probas = torch.cat([pos_prob, neg_prob], dim=1)\n    else:\n        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        probas = F.softmax(logits, dim=1)\n    true_1_hot = true_1_hot.type(logits.type())\n    dims = (0,) + tuple(range(2, true.ndimension()))\n    intersection = torch.sum(probas * true_1_hot, dims)\n    cardinality = torch.sum(probas + true_1_hot, dims)\n    union = cardinality - intersection\n    jacc_loss = (intersection / (union + eps)).mean()\n    return (1 - jacc_loss)\n\n\ndef tversky_loss(true, logits, alpha, beta, eps=1e-7):\n    """"""Computes the Tversky loss [1].\n\n    Args:\n        true: a tensor of shape [B, H, W] or [B, 1, H, W].\n        logits: a tensor of shape [B, C, H, W]. Corresponds to\n            the raw output or logits of the model.\n        alpha: controls the penalty for false positives.\n        beta: controls the penalty for false negatives.\n        eps: added to the denominator for numerical stability.\n\n    Returns:\n        tversky_loss: the Tversky loss.\n\n    Notes:\n        alpha = beta = 0.5 => dice coeff\n        alpha = beta = 1 => tanimoto coeff\n        alpha + beta = 1 => F beta coeff\n\n    References:\n        [1]: https://arxiv.org/abs/1706.05721\n    """"""\n    num_classes = logits.shape[1]\n    if num_classes == 1:\n        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n        pos_prob = torch.sigmoid(logits)\n        neg_prob = 1 - pos_prob\n        probas = torch.cat([pos_prob, neg_prob], dim=1)\n    else:\n        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n        probas = F.softmax(logits, dim=1)\n    true_1_hot = true_1_hot.type(logits.type())\n    dims = (0,) + tuple(range(2, true.ndimension()))\n    intersection = torch.sum(probas * true_1_hot, dims)\n    fps = torch.sum(probas * (1 - true_1_hot), dims)\n    fns = torch.sum((1 - probas) * true_1_hot, dims)\n    num = intersection\n    denom = intersection + (alpha * fps) + (beta * fns)\n    tversky_loss = (num / (denom + eps)).mean()\n    return (1 - tversky_loss)\n\n\ndef ce_dice(true, pred, log=False, w1=1, w2=1):\n    pass\n\n\ndef ce_jaccard(true, pred, log=False, w1=1, w2=1):\n    pass\n\n\ndef focal_loss(true, pred):\n    pass\n'"
metrics.py,6,"b'""""""Common image segmentation metrics.\n""""""\n\nimport torch\n\nfrom utils import nanmean\n\n\nEPS = 1e-10\n\n\ndef _fast_hist(true, pred, num_classes):\n    mask = (true >= 0) & (true < num_classes)\n    hist = torch.bincount(\n        num_classes * true[mask] + pred[mask],\n        minlength=num_classes ** 2,\n    ).reshape(num_classes, num_classes).float()\n    return hist\n\n\ndef overall_pixel_accuracy(hist):\n    """"""Computes the total pixel accuracy.\n\n    The overall pixel accuracy provides an intuitive\n    approximation for the qualitative perception of the\n    label when it is viewed in its overall shape but not\n    its details.\n\n    Args:\n        hist: confusion matrix.\n\n    Returns:\n        overall_acc: the overall pixel accuracy.\n    """"""\n    correct = torch.diag(hist).sum()\n    total = hist.sum()\n    overall_acc = correct / (total + EPS)\n    return overall_acc\n\n\ndef per_class_pixel_accuracy(hist):\n    """"""Computes the average per-class pixel accuracy.\n\n    The per-class pixel accuracy is a more fine-grained\n    version of the overall pixel accuracy. A model could\n    score a relatively high overall pixel accuracy by\n    correctly predicting the dominant labels or areas\n    in the image whilst incorrectly predicting the\n    possibly more important/rare labels. Such a model\n    will score a low per-class pixel accuracy.\n\n    Args:\n        hist: confusion matrix.\n\n    Returns:\n        avg_per_class_acc: the average per-class pixel accuracy.\n    """"""\n    correct_per_class = torch.diag(hist)\n    total_per_class = hist.sum(dim=1)\n    per_class_acc = correct_per_class / (total_per_class + EPS)\n    avg_per_class_acc = nanmean(per_class_acc)\n    return avg_per_class_acc\n\n\ndef jaccard_index(hist):\n    """"""Computes the Jaccard index, a.k.a the Intersection over Union (IoU).\n\n    Args:\n        hist: confusion matrix.\n\n    Returns:\n        avg_jacc: the average per-class jaccard index.\n    """"""\n    A_inter_B = torch.diag(hist)\n    A = hist.sum(dim=1)\n    B = hist.sum(dim=0)\n    jaccard = A_inter_B / (A + B - A_inter_B + EPS)\n    avg_jacc = nanmean(jaccard)\n    return avg_jacc\n\n\ndef dice_coefficient(hist):\n    """"""Computes the S\xc3\xb8rensen\xe2\x80\x93Dice coefficient, a.k.a the F1 score.\n\n    Args:\n        hist: confusion matrix.\n\n    Returns:\n        avg_dice: the average per-class dice coefficient.\n    """"""\n    A_inter_B = torch.diag(hist)\n    A = hist.sum(dim=1)\n    B = hist.sum(dim=0)\n    dice = (2 * A_inter_B) / (A + B + EPS)\n    avg_dice = nanmean(dice)\n    return avg_dice\n\n\ndef eval_metrics(true, pred, num_classes):\n    """"""Computes various segmentation metrics on 2D feature maps.\n\n    Args:\n        true: a tensor of shape [B, H, W] or [B, 1, H, W].\n        pred: a tensor of shape [B, H, W] or [B, 1, H, W].\n        num_classes: the number of classes to segment. This number\n            should be less than the ID of the ignored class.\n\n    Returns:\n        overall_acc: the overall pixel accuracy.\n        avg_per_class_acc: the average per-class pixel accuracy.\n        avg_jacc: the jaccard index.\n        avg_dice: the dice coefficient.\n    """"""\n    hist = torch.zeros((num_classes, num_classes))\n    for t, p in zip(true, pred):\n        hist += _fast_hist(t.flatten(), p.flatten(), num_classes)\n    overall_acc = overall_pixel_accuracy(hist)\n    avg_per_class_acc = per_class_pixel_accuracy(hist)\n    avg_jacc = jaccard_index(hist)\n    avg_dice = dice_coefficient(hist)\n    return overall_acc, avg_per_class_acc, avg_jacc, avg_dice\n\n\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n'"
utils.py,1,"b'import torch\n\n\ndef nanmean(x):\n    """"""Computes the arithmetic mean ignoring any NaNs.""""""\n    return torch.mean(x[x == x])\n'"
models/__init__.py,0,b'from .mnist import MnistConvNet\n'
models/base.py,1,"b'import torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\n\nclass BaseModel(nn.Module):\n    """"""An abstract class representing a model architecture.\n\n    Any model definition should subclass `BaseModel`.\n    """"""\n    def __init__(self):\n        super().__init__()\n\n    @property\n    def num_params(self):\n        return sum(param.numel() for param in self.parameters())\n\n    def forward(self, x):\n        raise NotImplementedError\n'"
models/mnist.py,1,"b'""""""\nFrom https://github.com/pytorch/examples/blob/master/mnist/main.py\n""""""\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nfrom .base import BaseModel\n\n\nclass MnistConvNet(BaseModel):\n    def __init__(self):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n'"
