file_path,api_count,code
setup.py,0,"b'import os\nimport re\nfrom setuptools import setup, find_packages\n\nhere = os.path.dirname(os.path.realpath(__file__))\nwith open(os.path.join(here, \'README.rst\')) as f:\n    readme = f.read()\nwith open(os.path.join(here, \'torchcrf\', \'__init__.py\')) as f:\n    version = re.search(r\'__version__ = ([""\\\'])([^""\\\']*)\\1\', f.read())[2]\n\nsetup(\n    name=\'pytorch-crf\',\n    version=version,\n    description=\'Conditional random field in PyTorch\',\n    long_description=readme,\n    url=\'https://github.com/kmkurn/pytorch-crf\',\n    author=\'Kemal Kurniawan\',\n    author_email=\'kemal@kkurniawan.com\',\n    license=\'MIT\',\n    classifiers=[\n        \'Development Status :: 4 - Beta\',\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Science/Research\',\n        \'License :: OSI Approved :: MIT License\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n    ],\n    keywords=\'torch\',\n    packages=find_packages(),\n    python_requires=\'>=3.6, <4\')\n'"
docs/conf.py,1,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'..\'))\n\nfrom pathlib import Path\nimport re\n\nhere = Path(__file__).resolve().parent\n__version__ = re.search(\n    r\'__version__ = ([""\\\'])([^""\\\']*)\\1\',\n    (here.parent / \'torchcrf\' / \'__init__.py\').read_text(),\n)[2]\n\n# -- Project information -----------------------------------------------------\n\nproject = \'pytorch-crf\'\ncopyright = \'2019, Kemal Kurniawan\'\nauthor = \'Kemal Kurniawan\'\n\n# The short X.Y version\nversion = \'.\'.join(__version__.split(\'.\')[:-1])\n# The full version, including alpha/beta/rc tags\nrelease = __version__\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.autodoc\',\n    \'sphinx.ext.doctest\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx_autodoc_typehints\',\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = None\n\n# The default role.\ndefault_role = \'py:obj\'\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\n#html_theme = \'alabaster\'\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# The default sidebars (for documents that don\'t match any pattern) are\n# defined by theme itself.  Builtin themes are using these templates by\n# default: ``[\'localtoc.html\', \'relations.html\', \'sourcelink.html\',\n# \'searchbox.html\']``.\n#\n# html_sidebars = {}\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'pytorch-crfdoc\'\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'pytorch-crf.tex\', \'pytorch-crf Documentation\', \'Kemal Kurniawan\', \'manual\'),\n]\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, \'pytorch-crf\', \'pytorch-crf Documentation\', [author], 1)]\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc, \'pytorch-crf\', \'pytorch-crf Documentation\', author, \'pytorch-crf\',\n        \'One line description of project.\', \'Miscellaneous\'),\n]\n\n# -- Options for Epub output -------------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = \'\'\n\n# A unique identification for the text.\n#\n# epub_uid = \'\'\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\'search.html\']\n\n# -- Extension configuration -------------------------------------------------\n\n# Mock torch package\nautodoc_mock_imports = [\'torch\']\n\n# -- Options for intersphinx extension ---------------------------------------\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\n    \'https://docs.python.org/3.6/\': None,\n    \'https://pytorch.org/docs/stable/\': None,\n}\n'"
tests/test_crf.py,29,"b""import itertools\nimport math\nimport random\n\nfrom pytest import approx\nimport pytest\nimport torch\nimport torch.nn as nn\n\nfrom torchcrf import CRF\n\nRANDOM_SEED = 1478754\n\nrandom.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\n\n\ndef compute_score(crf, emission, tag):\n    # emission: (seq_length, num_tags)\n    assert emission.dim() == 2\n    assert emission.size(0) == len(tag)\n    assert emission.size(1) == crf.num_tags\n    assert all(0 <= t < crf.num_tags for t in tag)\n\n    # Add transitions score\n    score = crf.start_transitions[tag[0]] + crf.end_transitions[tag[-1]]\n    for cur_tag, next_tag in zip(tag, tag[1:]):\n        score += crf.transitions[cur_tag, next_tag]\n\n    # Add emission score\n    for emit, t in zip(emission, tag):\n        score += emit[t]\n\n    return score\n\n\ndef make_crf(num_tags=5, batch_first=False):\n    return CRF(num_tags, batch_first=batch_first)\n\n\ndef make_emissions(crf, seq_length=3, batch_size=2):\n    em = torch.randn(seq_length, batch_size, crf.num_tags)\n    if crf.batch_first:\n        em = em.transpose(0, 1)\n    return em\n\n\ndef make_tags(crf, seq_length=3, batch_size=2):\n    # shape: (seq_length, batch_size)\n    ts = torch.tensor([[random.randrange(crf.num_tags)\n                        for b in range(batch_size)]\n                       for _ in range(seq_length)],\n                      dtype=torch.long)\n    if crf.batch_first:\n        ts = ts.transpose(0, 1)\n    return ts\n\n\nclass TestInit:\n    def test_minimal(self):\n        num_tags = 10\n        crf = CRF(num_tags)\n\n        assert crf.num_tags == num_tags\n        assert not crf.batch_first\n        assert isinstance(crf.start_transitions, nn.Parameter)\n        assert crf.start_transitions.shape == (num_tags, )\n        assert isinstance(crf.end_transitions, nn.Parameter)\n        assert crf.end_transitions.shape == (num_tags, )\n        assert isinstance(crf.transitions, nn.Parameter)\n        assert crf.transitions.shape == (num_tags, num_tags)\n        assert repr(crf) == f'CRF(num_tags={num_tags})'\n\n    def test_full(self):\n        crf = CRF(10, batch_first=True)\n        assert crf.batch_first\n\n    def test_nonpositive_num_tags(self):\n        with pytest.raises(ValueError) as excinfo:\n            CRF(0)\n        assert 'invalid number of tags: 0' in str(excinfo.value)\n\n\nclass TestForward:\n    def test_works_with_mask(self):\n        crf = make_crf()\n        seq_length, batch_size = 3, 2\n\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf, seq_length, batch_size)\n        # shape: (seq_length, batch_size)\n        tags = make_tags(crf, seq_length, batch_size)\n        # mask should have size of (seq_length, batch_size)\n        mask = torch.tensor([[1, 1, 1], [1, 1, 0]], dtype=torch.uint8).transpose(0, 1)\n\n        # shape: ()\n        llh = crf(emissions, tags, mask=mask)\n\n        # shape: (batch_size, seq_length, num_tags)\n        emissions = emissions.transpose(0, 1)\n        # shape: (batch_size, seq_length)\n        tags = tags.transpose(0, 1)\n        # shape: (batch_size, seq_length)\n        mask = mask.transpose(0, 1)\n\n        # Compute log likelihood manually\n        manual_llh = 0.\n        for emission, tag, mask_ in zip(emissions, tags, mask):\n            seq_len = mask_.sum()\n            emission, tag = emission[:seq_len], tag[:seq_len]\n            numerator = compute_score(crf, emission, tag)\n            all_scores = [\n                compute_score(crf, emission, t)\n                for t in itertools.product(range(crf.num_tags), repeat=seq_len)\n            ]\n            denominator = math.log(sum(math.exp(s) for s in all_scores))\n            manual_llh += numerator - denominator\n\n        assert llh.item() == approx(manual_llh)\n        llh.backward()  # ensure gradients can be computed\n\n    def test_works_without_mask(self):\n        crf = make_crf()\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf)\n        # shape: (seq_length, batch_size)\n        tags = make_tags(crf)\n\n        llh_no_mask = crf(emissions, tags)\n        # No mask means the mask is all ones\n        llh_mask = crf(emissions, tags, mask=torch.ones_like(tags).byte())\n\n        assert llh_no_mask.item() == approx(llh_mask.item())\n\n    def test_batched_loss(self):\n        crf = make_crf()\n        batch_size = 10\n\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf, batch_size=batch_size)\n        # shape: (seq_length, batch_size)\n        tags = make_tags(crf, batch_size=batch_size)\n\n        llh = crf(emissions, tags)\n        assert torch.is_tensor(llh)\n        assert llh.shape == ()\n\n        total_llh = 0.\n        for i in range(batch_size):\n            # shape: (seq_length, 1, num_tags)\n            emissions_ = emissions[:, i, :].unsqueeze(1)\n            # shape: (seq_length, 1)\n            tags_ = tags[:, i].unsqueeze(1)\n            # shape: ()\n            total_llh += crf(emissions_, tags_)\n\n        assert llh.item() == approx(total_llh.item())\n\n    def test_reduction_none(self):\n        crf = make_crf()\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf)\n        # shape: (seq_length, batch_size)\n        tags = make_tags(crf)\n\n        seq_length, batch_size = tags.shape\n\n        llh = crf(emissions, tags, reduction='none')\n\n        assert torch.is_tensor(llh)\n        assert llh.shape == (batch_size, )\n\n        # shape: (batch_size, seq_length, num_tags)\n        emissions = emissions.transpose(0, 1)\n        # shape: (batch_size, seq_length)\n        tags = tags.transpose(0, 1)\n\n        # Compute log likelihood manually\n        manual_llh = []\n        for emission, tag in zip(emissions, tags):\n            numerator = compute_score(crf, emission, tag)\n            all_scores = [\n                compute_score(crf, emission, t)\n                for t in itertools.product(range(crf.num_tags), repeat=seq_length)\n            ]\n            denominator = math.log(sum(math.exp(s) for s in all_scores))\n            manual_llh.append(numerator - denominator)\n\n        for llh_, manual_llh_ in zip(llh, manual_llh):\n            assert llh_.item() == approx(manual_llh_)\n\n    def test_reduction_mean(self):\n        crf = make_crf()\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf)\n        # shape: (seq_length, batch_size)\n        tags = make_tags(crf)\n\n        seq_length, batch_size = tags.shape\n\n        llh = crf(emissions, tags, reduction='mean')\n\n        assert torch.is_tensor(llh)\n        assert llh.shape == ()\n\n        # shape: (batch_size, seq_length, num_tags)\n        emissions = emissions.transpose(0, 1)\n        # shape: (batch_size, seq_length)\n        tags = tags.transpose(0, 1)\n\n        # Compute log likelihood manually\n        manual_llh = 0\n        for emission, tag in zip(emissions, tags):\n            numerator = compute_score(crf, emission, tag)\n            all_scores = [\n                compute_score(crf, emission, t)\n                for t in itertools.product(range(crf.num_tags), repeat=seq_length)\n            ]\n            denominator = math.log(sum(math.exp(s) for s in all_scores))\n            manual_llh += numerator - denominator\n\n        assert llh.item() == approx(manual_llh / batch_size)\n\n    def test_reduction_token_mean(self):\n        crf = make_crf()\n        seq_length, batch_size = 3, 2\n\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf, seq_length, batch_size)\n        # shape: (seq_length, batch_size)\n        tags = make_tags(crf, seq_length, batch_size)\n        # mask should have size of (seq_length, batch_size)\n        mask = torch.tensor([[1, 1, 1], [1, 1, 0]], dtype=torch.uint8).transpose(0, 1)\n\n        llh = crf(emissions, tags, mask=mask, reduction='token_mean')\n\n        assert torch.is_tensor(llh)\n        assert llh.shape == ()\n\n        # shape: (batch_size, seq_length, num_tags)\n        emissions = emissions.transpose(0, 1)\n        # shape: (batch_size, seq_length)\n        tags = tags.transpose(0, 1)\n        # shape: (batch_size, seq_length)\n        mask = mask.transpose(0, 1)\n\n        # Compute log likelihood manually\n        manual_llh, n_tokens = 0, 0\n        for emission, tag, mask_ in zip(emissions, tags, mask):\n            seq_len = mask_.sum()\n            emission, tag = emission[:seq_len], tag[:seq_len]\n            numerator = compute_score(crf, emission, tag)\n            all_scores = [\n                compute_score(crf, emission, t)\n                for t in itertools.product(range(crf.num_tags), repeat=seq_len)\n            ]\n            denominator = math.log(sum(math.exp(s) for s in all_scores))\n            manual_llh += numerator - denominator\n            n_tokens += seq_len\n\n        assert llh.item() == approx(manual_llh / n_tokens)\n\n    def test_batch_first(self):\n        crf = make_crf()\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf)\n        # shape: (seq_length, batch_size)\n        tags = make_tags(crf)\n        llh = crf(emissions, tags)\n\n        crf_bf = make_crf(batch_first=True)\n        # Copy parameter values from non-batch-first CRF; requires_grad must be False\n        # to avoid runtime error of in-place operation on a leaf variable\n        crf_bf.start_transitions.requires_grad_(False).copy_(crf.start_transitions)\n        crf_bf.end_transitions.requires_grad_(False).copy_(crf.end_transitions)\n        crf_bf.transitions.requires_grad_(False).copy_(crf.transitions)\n\n        # shape: (batch_size, seq_length, num_tags)\n        emissions = emissions.transpose(0, 1)\n        # shape: (batch_size, seq_length)\n        tags = tags.transpose(0, 1)\n        llh_bf = crf_bf(emissions, tags)\n\n        assert llh.item() == approx(llh_bf.item())\n\n    def test_emissions_has_bad_number_of_dimension(self):\n        emissions = torch.randn(1, 2)\n        tags = torch.empty(2, 2, dtype=torch.long)\n        crf = make_crf()\n\n        with pytest.raises(ValueError) as excinfo:\n            crf(emissions, tags)\n        assert 'emissions must have dimension of 3, got 2' in str(excinfo.value)\n\n    def test_emissions_and_tags_size_mismatch(self):\n        emissions = torch.randn(1, 2, 3)\n        tags = torch.empty(2, 2, dtype=torch.long)\n        crf = make_crf(3)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf(emissions, tags)\n        assert (\n            'the first two dimensions of emissions and tags must match, '\n            'got (1, 2) and (2, 2)') in str(excinfo.value)\n\n    def test_emissions_last_dimension_not_equal_to_number_of_tags(self):\n        emissions = torch.randn(1, 2, 3)\n        tags = torch.empty(1, 2, dtype=torch.long)\n        crf = make_crf(10)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf(emissions, tags)\n        assert 'expected last dimension of emissions is 10, got 3' in str(excinfo.value)\n\n    def test_first_timestep_mask_is_not_all_on(self):\n        emissions = torch.randn(3, 2, 4)\n        tags = torch.empty(3, 2, dtype=torch.long)\n        mask = torch.tensor([[1, 1, 1], [0, 0, 0]], dtype=torch.uint8).transpose(0, 1)\n        crf = make_crf(4)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf(emissions, tags, mask=mask)\n        assert 'mask of the first timestep must all be on' in str(excinfo.value)\n\n        emissions = emissions.transpose(0, 1)\n        tags = tags.transpose(0, 1)\n        mask = mask.transpose(0, 1)\n        crf = make_crf(4, batch_first=True)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf(emissions, tags, mask=mask)\n        assert 'mask of the first timestep must all be on' in str(excinfo.value)\n\n    def test_invalid_reduction(self):\n        crf = make_crf()\n        emissions = make_emissions(crf)\n        tags = make_tags(crf)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf(emissions, tags, reduction='foo')\n        assert 'invalid reduction: foo' in str(excinfo.value)\n\n\nclass TestDecode:\n    def test_works_with_mask(self):\n        crf = make_crf()\n        seq_length, batch_size = 3, 2\n\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf, seq_length, batch_size)\n        # mask should be (seq_length, batch_size)\n        mask = torch.tensor([[1, 1, 1], [1, 1, 0]], dtype=torch.uint8).transpose(0, 1)\n\n        best_tags = crf.decode(emissions, mask=mask)\n\n        # shape: (batch_size, seq_length, num_tags)\n        emissions = emissions.transpose(0, 1)\n        # shape: (batch_size, seq_length)\n        mask = mask.transpose(0, 1)\n\n        # Compute best tag manually\n        for emission, best_tag, mask_ in zip(emissions, best_tags, mask):\n            seq_len = mask_.sum()\n            assert len(best_tag) == seq_len\n            assert all(isinstance(t, int) for t in best_tag)\n            emission = emission[:seq_len]\n            manual_best_tag = max(\n                itertools.product(range(crf.num_tags), repeat=seq_len),\n                key=lambda t: compute_score(crf, emission, t))\n            assert tuple(best_tag) == manual_best_tag\n\n    def test_works_without_mask(self):\n        crf = make_crf()\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf)\n\n        best_tags_no_mask = crf.decode(emissions)\n        # No mask means mask is all ones\n        best_tags_mask = crf.decode(\n            emissions, mask=emissions.new_ones(emissions.shape[:2]).byte())\n\n        assert best_tags_no_mask == best_tags_mask\n\n    def test_batched_decode(self):\n        crf = make_crf()\n        batch_size, seq_length = 2, 3\n\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf, seq_length, batch_size)\n        # shape: (seq_length, batch_size)\n        mask = torch.tensor([[1, 1, 1], [1, 1, 0]], dtype=torch.uint8).transpose(0, 1)\n\n        batched = crf.decode(emissions, mask=mask)\n\n        non_batched = []\n        for i in range(batch_size):\n            # shape: (seq_length, 1, num_tags)\n            emissions_ = emissions[:, i, :].unsqueeze(1)\n            # shape: (seq_length, 1)\n            mask_ = mask[:, i].unsqueeze(1)\n\n            result = crf.decode(emissions_, mask=mask_)\n            assert len(result) == 1\n            non_batched.append(result[0])\n\n        assert non_batched == batched\n\n    def test_batch_first(self):\n        crf = make_crf()\n        # shape: (seq_length, batch_size, num_tags)\n        emissions = make_emissions(crf)\n        best_tags = crf.decode(emissions)\n\n        crf_bf = make_crf(batch_first=True)\n        # Copy parameter values from non-batch-first CRF; requires_grad must be False\n        # to avoid runtime error of in-place operation on a leaf variable\n        crf_bf.start_transitions.requires_grad_(False).copy_(crf.start_transitions)\n        crf_bf.end_transitions.requires_grad_(False).copy_(crf.end_transitions)\n        crf_bf.transitions.requires_grad_(False).copy_(crf.transitions)\n\n        # shape: (batch_size, seq_length, num_tags)\n        emissions = emissions.transpose(0, 1)\n        best_tags_bf = crf_bf.decode(emissions)\n\n        assert best_tags == best_tags_bf\n\n    def test_emissions_has_bad_number_of_dimension(self):\n        emissions = torch.randn(1, 2)\n        crf = make_crf()\n\n        with pytest.raises(ValueError) as excinfo:\n            crf.decode(emissions)\n        assert 'emissions must have dimension of 3, got 2' in str(excinfo.value)\n\n    def test_emissions_last_dimension_not_equal_to_number_of_tags(self):\n        emissions = torch.randn(1, 2, 3)\n        crf = make_crf(10)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf.decode(emissions)\n        assert 'expected last dimension of emissions is 10, got 3' in str(excinfo.value)\n\n    def test_emissions_and_mask_size_mismatch(self):\n        emissions = torch.randn(1, 2, 3)\n        mask = torch.tensor([[1, 1], [1, 0]], dtype=torch.uint8)\n        crf = make_crf(3)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf.decode(emissions, mask=mask)\n        assert (\n            'the first two dimensions of emissions and mask must match, '\n            'got (1, 2) and (2, 2)') in str(excinfo.value)\n\n    def test_first_timestep_mask_is_not_all_on(self):\n        emissions = torch.randn(3, 2, 4)\n        mask = torch.tensor([[1, 1, 1], [0, 0, 0]], dtype=torch.uint8).transpose(0, 1)\n        crf = make_crf(4)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf.decode(emissions, mask=mask)\n        assert 'mask of the first timestep must all be on' in str(excinfo.value)\n\n        emissions = emissions.transpose(0, 1)\n        mask = mask.transpose(0, 1)\n        crf = make_crf(4, batch_first=True)\n\n        with pytest.raises(ValueError) as excinfo:\n            crf.decode(emissions, mask=mask)\n        assert 'mask of the first timestep must all be on' in str(excinfo.value)\n"""
torchcrf/__init__.py,36,"b'__version__ = \'0.7.2\'\n\nfrom typing import List, Optional\n\nimport torch\nimport torch.nn as nn\n\n\nclass CRF(nn.Module):\n    """"""Conditional random field.\n\n    This module implements a conditional random field [LMP01]_. The forward computation\n    of this class computes the log likelihood of the given sequence of tags and\n    emission score tensor. This class also has `~CRF.decode` method which finds\n    the best tag sequence given an emission score tensor using `Viterbi algorithm`_.\n\n    Args:\n        num_tags: Number of tags.\n        batch_first: Whether the first dimension corresponds to the size of a minibatch.\n\n    Attributes:\n        start_transitions (`~torch.nn.Parameter`): Start transition score tensor of size\n            ``(num_tags,)``.\n        end_transitions (`~torch.nn.Parameter`): End transition score tensor of size\n            ``(num_tags,)``.\n        transitions (`~torch.nn.Parameter`): Transition score tensor of size\n            ``(num_tags, num_tags)``.\n\n\n    .. [LMP01] Lafferty, J., McCallum, A., Pereira, F. (2001).\n       ""Conditional random fields: Probabilistic models for segmenting and\n       labeling sequence data"". *Proc. 18th International Conf. on Machine\n       Learning*. Morgan Kaufmann. pp. 282\xe2\x80\x93289.\n\n    .. _Viterbi algorithm: https://en.wikipedia.org/wiki/Viterbi_algorithm\n    """"""\n\n    def __init__(self, num_tags: int, batch_first: bool = False) -> None:\n        if num_tags <= 0:\n            raise ValueError(f\'invalid number of tags: {num_tags}\')\n        super().__init__()\n        self.num_tags = num_tags\n        self.batch_first = batch_first\n        self.start_transitions = nn.Parameter(torch.empty(num_tags))\n        self.end_transitions = nn.Parameter(torch.empty(num_tags))\n        self.transitions = nn.Parameter(torch.empty(num_tags, num_tags))\n\n        self.reset_parameters()\n\n    def reset_parameters(self) -> None:\n        """"""Initialize the transition parameters.\n\n        The parameters will be initialized randomly from a uniform distribution\n        between -0.1 and 0.1.\n        """"""\n        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n        nn.init.uniform_(self.transitions, -0.1, 0.1)\n\n    def __repr__(self) -> str:\n        return f\'{self.__class__.__name__}(num_tags={self.num_tags})\'\n\n    def forward(\n            self,\n            emissions: torch.Tensor,\n            tags: torch.LongTensor,\n            mask: Optional[torch.ByteTensor] = None,\n            reduction: str = \'sum\',\n    ) -> torch.Tensor:\n        """"""Compute the conditional log likelihood of a sequence of tags given emission scores.\n\n        Args:\n            emissions (`~torch.Tensor`): Emission score tensor of size\n                ``(seq_length, batch_size, num_tags)`` if ``batch_first`` is ``False``,\n                ``(batch_size, seq_length, num_tags)`` otherwise.\n            tags (`~torch.LongTensor`): Sequence of tags tensor of size\n                ``(seq_length, batch_size)`` if ``batch_first`` is ``False``,\n                ``(batch_size, seq_length)`` otherwise.\n            mask (`~torch.ByteTensor`): Mask tensor of size ``(seq_length, batch_size)``\n                if ``batch_first`` is ``False``, ``(batch_size, seq_length)`` otherwise.\n            reduction: Specifies  the reduction to apply to the output:\n                ``none|sum|mean|token_mean``. ``none``: no reduction will be applied.\n                ``sum``: the output will be summed over batches. ``mean``: the output will be\n                averaged over batches. ``token_mean``: the output will be averaged over tokens.\n\n        Returns:\n            `~torch.Tensor`: The log likelihood. This will have size ``(batch_size,)`` if\n            reduction is ``none``, ``()`` otherwise.\n        """"""\n        self._validate(emissions, tags=tags, mask=mask)\n        if reduction not in (\'none\', \'sum\', \'mean\', \'token_mean\'):\n            raise ValueError(f\'invalid reduction: {reduction}\')\n        if mask is None:\n            mask = torch.ones_like(tags, dtype=torch.uint8)\n\n        if self.batch_first:\n            emissions = emissions.transpose(0, 1)\n            tags = tags.transpose(0, 1)\n            mask = mask.transpose(0, 1)\n\n        # shape: (batch_size,)\n        numerator = self._compute_score(emissions, tags, mask)\n        # shape: (batch_size,)\n        denominator = self._compute_normalizer(emissions, mask)\n        # shape: (batch_size,)\n        llh = numerator - denominator\n\n        if reduction == \'none\':\n            return llh\n        if reduction == \'sum\':\n            return llh.sum()\n        if reduction == \'mean\':\n            return llh.mean()\n        assert reduction == \'token_mean\'\n        return llh.sum() / mask.type_as(emissions).sum()\n\n    def decode(self, emissions: torch.Tensor,\n               mask: Optional[torch.ByteTensor] = None) -> List[List[int]]:\n        """"""Find the most likely tag sequence using Viterbi algorithm.\n\n        Args:\n            emissions (`~torch.Tensor`): Emission score tensor of size\n                ``(seq_length, batch_size, num_tags)`` if ``batch_first`` is ``False``,\n                ``(batch_size, seq_length, num_tags)`` otherwise.\n            mask (`~torch.ByteTensor`): Mask tensor of size ``(seq_length, batch_size)``\n                if ``batch_first`` is ``False``, ``(batch_size, seq_length)`` otherwise.\n\n        Returns:\n            List of list containing the best tag sequence for each batch.\n        """"""\n        self._validate(emissions, mask=mask)\n        if mask is None:\n            mask = emissions.new_ones(emissions.shape[:2], dtype=torch.uint8)\n\n        if self.batch_first:\n            emissions = emissions.transpose(0, 1)\n            mask = mask.transpose(0, 1)\n\n        return self._viterbi_decode(emissions, mask)\n\n    def _validate(\n            self,\n            emissions: torch.Tensor,\n            tags: Optional[torch.LongTensor] = None,\n            mask: Optional[torch.ByteTensor] = None) -> None:\n        if emissions.dim() != 3:\n            raise ValueError(f\'emissions must have dimension of 3, got {emissions.dim()}\')\n        if emissions.size(2) != self.num_tags:\n            raise ValueError(\n                f\'expected last dimension of emissions is {self.num_tags}, \'\n                f\'got {emissions.size(2)}\')\n\n        if tags is not None:\n            if emissions.shape[:2] != tags.shape:\n                raise ValueError(\n                    \'the first two dimensions of emissions and tags must match, \'\n                    f\'got {tuple(emissions.shape[:2])} and {tuple(tags.shape)}\')\n\n        if mask is not None:\n            if emissions.shape[:2] != mask.shape:\n                raise ValueError(\n                    \'the first two dimensions of emissions and mask must match, \'\n                    f\'got {tuple(emissions.shape[:2])} and {tuple(mask.shape)}\')\n            no_empty_seq = not self.batch_first and mask[0].all()\n            no_empty_seq_bf = self.batch_first and mask[:, 0].all()\n            if not no_empty_seq and not no_empty_seq_bf:\n                raise ValueError(\'mask of the first timestep must all be on\')\n\n    def _compute_score(\n            self, emissions: torch.Tensor, tags: torch.LongTensor,\n            mask: torch.ByteTensor) -> torch.Tensor:\n        # emissions: (seq_length, batch_size, num_tags)\n        # tags: (seq_length, batch_size)\n        # mask: (seq_length, batch_size)\n        assert emissions.dim() == 3 and tags.dim() == 2\n        assert emissions.shape[:2] == tags.shape\n        assert emissions.size(2) == self.num_tags\n        assert mask.shape == tags.shape\n        assert mask[0].all()\n\n        seq_length, batch_size = tags.shape\n        mask = mask.type_as(emissions)\n\n        # Start transition score and first emission\n        # shape: (batch_size,)\n        score = self.start_transitions[tags[0]]\n        score += emissions[0, torch.arange(batch_size), tags[0]]\n\n        for i in range(1, seq_length):\n            # Transition score to next tag, only added if next timestep is valid (mask == 1)\n            # shape: (batch_size,)\n            score += self.transitions[tags[i - 1], tags[i]] * mask[i]\n\n            # Emission score for next tag, only added if next timestep is valid (mask == 1)\n            # shape: (batch_size,)\n            score += emissions[i, torch.arange(batch_size), tags[i]] * mask[i]\n\n        # End transition score\n        # shape: (batch_size,)\n        seq_ends = mask.long().sum(dim=0) - 1\n        # shape: (batch_size,)\n        last_tags = tags[seq_ends, torch.arange(batch_size)]\n        # shape: (batch_size,)\n        score += self.end_transitions[last_tags]\n\n        return score\n\n    def _compute_normalizer(\n            self, emissions: torch.Tensor, mask: torch.ByteTensor) -> torch.Tensor:\n        # emissions: (seq_length, batch_size, num_tags)\n        # mask: (seq_length, batch_size)\n        assert emissions.dim() == 3 and mask.dim() == 2\n        assert emissions.shape[:2] == mask.shape\n        assert emissions.size(2) == self.num_tags\n        assert mask[0].all()\n\n        seq_length = emissions.size(0)\n\n        # Start transition score and first emission; score has size of\n        # (batch_size, num_tags) where for each batch, the j-th column stores\n        # the score that the first timestep has tag j\n        # shape: (batch_size, num_tags)\n        score = self.start_transitions + emissions[0]\n\n        for i in range(1, seq_length):\n            # Broadcast score for every possible next tag\n            # shape: (batch_size, num_tags, 1)\n            broadcast_score = score.unsqueeze(2)\n\n            # Broadcast emission score for every possible current tag\n            # shape: (batch_size, 1, num_tags)\n            broadcast_emissions = emissions[i].unsqueeze(1)\n\n            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n            # for each sample, entry at row i and column j stores the sum of scores of all\n            # possible tag sequences so far that end with transitioning from tag i to tag j\n            # and emitting\n            # shape: (batch_size, num_tags, num_tags)\n            next_score = broadcast_score + self.transitions + broadcast_emissions\n\n            # Sum over all possible current tags, but we\'re in score space, so a sum\n            # becomes a log-sum-exp: for each sample, entry i stores the sum of scores of\n            # all possible tag sequences so far, that end in tag i\n            # shape: (batch_size, num_tags)\n            next_score = torch.logsumexp(next_score, dim=1)\n\n            # Set score to the next score if this timestep is valid (mask == 1)\n            # shape: (batch_size, num_tags)\n            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n\n        # End transition score\n        # shape: (batch_size, num_tags)\n        score += self.end_transitions\n\n        # Sum (log-sum-exp) over all possible tags\n        # shape: (batch_size,)\n        return torch.logsumexp(score, dim=1)\n\n    def _viterbi_decode(self, emissions: torch.FloatTensor,\n                        mask: torch.ByteTensor) -> List[List[int]]:\n        # emissions: (seq_length, batch_size, num_tags)\n        # mask: (seq_length, batch_size)\n        assert emissions.dim() == 3 and mask.dim() == 2\n        assert emissions.shape[:2] == mask.shape\n        assert emissions.size(2) == self.num_tags\n        assert mask[0].all()\n\n        seq_length, batch_size = mask.shape\n\n        # Start transition and first emission\n        # shape: (batch_size, num_tags)\n        score = self.start_transitions + emissions[0]\n        history = []\n\n        # score is a tensor of size (batch_size, num_tags) where for every batch,\n        # value at column j stores the score of the best tag sequence so far that ends\n        # with tag j\n        # history saves where the best tags candidate transitioned from; this is used\n        # when we trace back the best tag sequence\n\n        # Viterbi algorithm recursive case: we compute the score of the best tag sequence\n        # for every possible next tag\n        for i in range(1, seq_length):\n            # Broadcast viterbi score for every possible next tag\n            # shape: (batch_size, num_tags, 1)\n            broadcast_score = score.unsqueeze(2)\n\n            # Broadcast emission score for every possible current tag\n            # shape: (batch_size, 1, num_tags)\n            broadcast_emission = emissions[i].unsqueeze(1)\n\n            # Compute the score tensor of size (batch_size, num_tags, num_tags) where\n            # for each sample, entry at row i and column j stores the score of the best\n            # tag sequence so far that ends with transitioning from tag i to tag j and emitting\n            # shape: (batch_size, num_tags, num_tags)\n            next_score = broadcast_score + self.transitions + broadcast_emission\n\n            # Find the maximum score over all possible current tag\n            # shape: (batch_size, num_tags)\n            next_score, indices = next_score.max(dim=1)\n\n            # Set score to the next score if this timestep is valid (mask == 1)\n            # and save the index that produces the next score\n            # shape: (batch_size, num_tags)\n            score = torch.where(mask[i].unsqueeze(1), next_score, score)\n            history.append(indices)\n\n        # End transition score\n        # shape: (batch_size, num_tags)\n        score += self.end_transitions\n\n        # Now, compute the best path for each sample\n\n        # shape: (batch_size,)\n        seq_ends = mask.long().sum(dim=0) - 1\n        best_tags_list = []\n\n        for idx in range(batch_size):\n            # Find the tag which maximizes the score at the last timestep; this is our best tag\n            # for the last timestep\n            _, best_last_tag = score[idx].max(dim=0)\n            best_tags = [best_last_tag.item()]\n\n            # We trace back where the best last tag comes from, append that to our best tag\n            # sequence, and trace it back again, and so on\n            for hist in reversed(history[:seq_ends[idx]]):\n                best_last_tag = hist[idx][best_tags[-1]]\n                best_tags.append(best_last_tag.item())\n\n            # Reverse the order because we start from the last timestep\n            best_tags.reverse()\n            best_tags_list.append(best_tags)\n\n        return best_tags_list\n'"
