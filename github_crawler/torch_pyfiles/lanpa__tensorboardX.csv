file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport subprocess\nimport os\nfrom setuptools import setup, find_packages\nfrom setuptools.command.develop import develop\nfrom setuptools.command.install import install\n\n# Dynamically compile protos\ndef compileProtoBuf():\n    res = subprocess.call([\'bash\', \'./compile.sh\'])\n    assert res == 0, \'cannot compile protobuf\'\n\nclass PostDevelopCommand(develop):\n    """"""Post-installation for development mode.""""""\n    def run(self):\n        compileProtoBuf()\n        develop.run(self)\n\n\nclass PostInstallCommand(install):\n    """"""Post-installation for installation mode.""""""\n    def run(self):\n        compileProtoBuf()\n        import os\n        os.system(""pip install protobuf numpy six"")\n        install.run(self)\n\nwith open(\'HISTORY.rst\') as history_file:\n    history = history_file.read()\n\npreparing_PyPI_package = False\nversion_git = version = \'2.0\'\n\nif not preparing_PyPI_package:\n    if os.path.exists(\'.git\'):\n        sha = subprocess.check_output([\'git\', \'rev-parse\', \'HEAD\']).decode(\'ascii\').strip()\n        version_git = version_git + \'+\' + sha[:7]\n\n    with open(\'tensorboardX/__init__.py\', \'a\') as f:\n        f.write(\'\\n__version__ = ""{}""\\n\'.format(version_git))\n\nrequirements = [\n    \'numpy\',\n    \'protobuf >= 3.8.0\',\n    \'six\',\n]\n\ntest_requirements = [\n    \'pytest\',\n    \'matplotlib\',\n    \'crc32c\',\n]\n\nsetup(\n    name=\'tensorboardX\',\n    version=version_git,\n    description=\'TensorBoardX lets you watch Tensors Flow without Tensorflow\',\n    long_description=history,\n    author=\'Tzu-Wei Huang\',\n    author_email=\'huang.dexter@gmail.com\',\n    url=\'https://github.com/lanpa/tensorboardX\',\n    packages=[\'tensorboardX\'],\n    include_package_data=True,\n    install_requires=requirements,\n    license=\'MIT license\',\n    zip_safe=False,\n    classifiers=[\n        \'Development Status :: 2 - Pre-Alpha\',\n        \'Intended Audience :: Developers\',\n        \'License :: OSI Approved :: MIT License\',\n        \'Natural Language :: English\',\n        \'Programming Language :: Python :: 2\',\n        \'Programming Language :: Python :: 2.7\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.4\',\n        \'Programming Language :: Python :: 3.5\',\n        \'Programming Language :: Python :: 3.6\',\n    ],\n    cmdclass={\n        \'develop\': PostDevelopCommand,\n        \'install\': PostInstallCommand,\n    },\n    test_suite=\'tests\',\n    tests_require=test_requirements\n)\n\n\n# checklist: update History.rst readme.md\n# change preparing_PyPI_package to True, and update version_git to new version\n# remove __version__ = ""1.old"" in __init__.py, update the version number\n# python setup.py sdist bdist_wheel --universal\n# check the generated tar.gz file\n# git add [files]\n# git commit -m \'prepare for release\'\n# add tag\n# twine upload dist/*\n# push commit'"
docs/conf.py,1,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# tensorboardX documentation build configuration file, created by\n# sphinx-quickstart on Wed Aug  9 01:38:01 2017.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n# sys.path.insert(0, os.path.abspath(\'.\'))\nsys.path.append(os.path.join(os.path.dirname(__file__), \'..\'))\n#import tensorboard #uncomment to shadow pip installation\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\'sphinx.ext.autodoc\',\n    \'sphinx.ext.mathjax\',\n    \'sphinx.ext.intersphinx\',\n    \'sphinx.ext.napoleon\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.githubpages\']\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = \'.rst\'\n\n# The master toctree document.\nmaster_doc = \'index\'\n\n# General information about the project.\nproject = \'tensorboardX\'\ncopyright = \'2017, tensorboardX Contributors\'\nauthor = \'tensorboardX Contributors\'\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = \'\'\n# The full version, including alpha/beta/rc tags.\nrelease = \'\'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \'sphinx\'\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\n# html_static_path = [\'_static\']\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \'tensorboardXdoc\'\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \'tensorboardX.tex\', \'tensorboardX Documentation\',\n     \'tensorboardX Contributors\', \'manual\'),\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (master_doc, \'tensorboardX\', \'tensorboardX Documentation\',\n     [author], 1)\n]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (master_doc, \'tensorboardX\', \'tensorboardX Documentation\',\n     author, \'tensorboardX\', \'One line description of project.\',\n     \'Miscellaneous\'),\n]\n\n\n\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\n    \'python\':(\'https://docs.python.org/3\', None),\n    \'numpy\': (\'http://docs.scipy.org/doc/numpy/\', None),\n    \'torch\': (\'http://pytorch.org/docs/master\', None),\n    \'matplotlib\': (\'http://matplotlib.sourceforge.net/\', None),\n    }\n'"
examples/__init__.py,0,b''
examples/create_wit_samples.py,0,"b'\n""""""\nhttps://archive.ics.uci.edu/ml/datasets/Heart+Disease\n1. #3 (age)\n2. #4 (sex)\n3. #9 (cp)\n4. #10 (trestbps)\n5. #12 (chol)\n6. #16 (fbs)\n7. #19 (restecg)\n8. #32 (thalach)\n9. #38 (exang)\n10. #40 (oldpeak)\n11. #41 (slope)\n12. #44 (ca)\n13. #51 (thal)\n14. #58 (num) (the predicted attribute)\n\nex: [\'62\', \'0\', \'1\', \'140\', \'0\', \'?\', \'0\', \'143\', \'0\', \'0\', \'?\', \'?\', \'3\', \'2\']\n\nHere I only choose feature 1~8 for example.\n\n""""""\n\n\nwith open(""processed.cleveland.data"") as f:\n    lines = f.readlines()\n\ncolumns = [""age"", ""sex"", ""cp"", ""trestbps"", ""chol"", ""fbs"", ""restecg"", ""thalach"", ""target""]\nfeatures_targets = []\ntargets = []\nfor line in lines:\n    x = line.strip().split(\',\')\n    y = x[-1]\n    if \'?\' in x[:8]:  # skip missing data\n        continue\n    ft = [float(i) for i in x[:8]+[y]]\n    # print(ft)\n    features_targets.append(ft)\n\n\n""""""\n  The first line of the CSV file must contain column names.\n  Each line after that contains one example from the dataset,\n  with values for each of the columns defined on the first line.\n  The pipe character (""|"") deliminates separate feature values\n  in a list of feature values for a given feature.\n""""""\n\nwith open(""test.csv"", \'w\') as f:\n    f.write(\',\'.join(columns) + \'\\n\')\n    for feature in features_targets:\n        feature = [str(i) for i in feature]\n        f.write(\',\'.join(feature) + \'\\n\')\n\n# launch tensorboard and fill [git/]tensorboardX/examples/test.csv in the WIT page and see the data distribution.\n\nexit()\n\n\n# For interactive inference, you may need the data in tfrecord format.\n\nimport tensorflow as tf\n\n\ndef to_examples(features_targets, columns=None):\n    examples = []\n    for row in features_targets:\n        example = tf.train.Example()\n        for i, col in enumerate(columns):\n            example.features.feature[col].float_list.value.append(row[i])\n            # example.features.feature[col].bytes_list.value.append(row[col].encode(\'utf-8\'))\n        examples.append(example)\n    return examples\n\nwriter = tf.io.TFRecordWriter(\'test.tfrecord\')\nfor example in to_examples(features_targets, columns):\n    writer.write(example.SerializeToString())\nwriter.close()\n\n\n# fill [git/]tensorboardX/examples/test.tfrecord in the WIT page and see the data distribution.\n'"
examples/demo.py,9,"b'import torch\nimport torchvision.utils as vutils\nimport numpy as np\nimport torchvision.models as models\nfrom torchvision import datasets\nfrom tensorboardX import SummaryWriter\nimport datetime\n\nresnet18 = models.resnet18(False)\nwriter = SummaryWriter()\nsample_rate = 44100\nfreqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]\n\ntrue_positive_counts = [75, 64, 21, 5, 0]\nfalse_positive_counts = [150, 105, 18, 0, 0]\ntrue_negative_counts = [0, 45, 132, 150, 150]\nfalse_negative_counts = [0, 11, 54, 70, 75]\nprecision = [0.3333333, 0.3786982, 0.5384616, 1.0, 0.0]\nrecall = [1.0, 0.8533334, 0.28, 0.0666667, 0.0]\n\n\nfor n_iter in range(100):\n    s1 = torch.rand(1)  # value to keep\n    s2 = torch.rand(1)\n    # data grouping by `slash`\n    writer.add_scalar(\'data/scalar_systemtime\', s1[0], n_iter, summary_description=""# markdown is supported!"")\n    # data grouping by `slash`\n    writer.add_scalar(\'data/scalar_customtime\', s1[0], n_iter, walltime=n_iter, display_name=""dudubird"")\n    writer.add_scalars(\'data/scalar_group\', {""xsinx"": n_iter * np.sin(n_iter),\n                                             ""xcosx"": n_iter * np.cos(n_iter),\n                                             ""arctanx"": np.arctan(n_iter)}, n_iter)\n    x = torch.rand(32, 3, 64, 64)  # output from network\n    if n_iter % 10 == 0:\n        x = vutils.make_grid(x, normalize=True, scale_each=True)\n        writer.add_image(\'Image\', x, n_iter)  # Tensor\n        writer.add_image_with_boxes(\'imagebox_label\', torch.ones(3, 240, 240) * 0.5,\n             torch.Tensor([[10, 10, 100, 100], [101, 101, 200, 200]]),\n             n_iter, \n             labels=[\'abcde\' + str(n_iter), \'fgh\' + str(n_iter)])\n        x = torch.zeros(sample_rate * 2)\n        for i in range(x.size(0)):\n            # sound amplitude should in [-1, 1]\n            x[i] = np.cos(freqs[n_iter // 10] * np.pi *\n                          float(i) / float(sample_rate))\n        writer.add_audio(\'myAudio\', x, n_iter)\n        writer.add_text(\'Text\', \'text logged at step:\' + str(n_iter), n_iter)\n        writer.add_text(\'markdown Text\', \'\'\'a|b\\n-|-\\nc|d\'\'\', n_iter)\n        for name, param in resnet18.named_parameters():\n            if \'bn\' not in name:\n                writer.add_histogram(name, param, n_iter)\n        writer.add_pr_curve(\'xoxo\', np.random.randint(2, size=100), np.random.rand(\n            100), n_iter)  # needs tensorboard 0.4RC or later\n        writer.add_pr_curve_raw(\'prcurve with raw data\', true_positive_counts,\n                                false_positive_counts,\n                                true_negative_counts,\n                                false_negative_counts,\n                                precision,\n                                recall, n_iter)\n# export scalar data to JSON for external processing\nwriter.export_scalars_to_json(""./all_scalars.json"")\n\ndataset = datasets.MNIST(\'mnist\', train=False, download=True)\nimages = dataset.test_data[:100].float()\nlabel = dataset.test_labels[:100]\nfeatures = images.view(100, 784)\nwriter.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))\nwriter.add_embedding(features, global_step=1, tag=\'noMetadata\')\ndataset = datasets.MNIST(\'mnist\', train=True, download=True)\nimages_train = dataset.train_data[:100].float()\nlabels_train = dataset.train_labels[:100]\nfeatures_train = images_train.view(100, 784)\n\nall_features = torch.cat((features, features_train))\nall_labels = torch.cat((label, labels_train))\nall_images = torch.cat((images, images_train))\ndataset_label = [\'test\'] * 100 + [\'train\'] * 100\nall_labels = list(zip(all_labels, dataset_label))\n\nwriter.add_embedding(all_features, metadata=all_labels, label_img=all_images.unsqueeze(1),\n                     metadata_header=[\'digit\', \'dataset\'], global_step=2)\n\n# VIDEO\nvid_images = dataset.train_data[:16 * 48]\nvid = vid_images.view(16, 48, 1, 28, 28)  # BxTxCxHxW\n\nwriter.add_video(\'video\', vid_tensor=vid)\nwriter.add_video(\'video_1_fps\', vid_tensor=vid, fps=1)\n\nwriter.close()\n'"
examples/demo_beholder.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \'License\');\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \'AS IS\' BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n""""""Simple MNIST classifier to demonstrate features of Beholder.\n\nBased on tensorflow/examples/tutorials/mnist/mnist_with_summaries.py.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorboardX.beholder as beholder_lib\nimport time\n\nfrom collections import namedtuple\n\n\nLOG_DIRECTORY = \'/tmp/beholder-demo\'\ntensor_and_name = namedtuple(\'tensor_and_name\', \'tensor, name\')\n\n\ndef beholder_pytorch():\n    for i in range(1000):\n        fake_param = [tensor_and_name(np.random.randn(128, 768, 3), \'test\' + str(i))\n                      for i in range(5)]\n        arrays = [tensor_and_name(np.random.randn(128, 768, 3), \'test\' + str(i))\n                  for i in range(5)]\n        beholder = beholder_lib.Beholder(logdir=LOG_DIRECTORY)\n        beholder.update(\n            trainable=fake_param,\n            arrays=arrays,\n            frame=np.random.randn(128, 128),\n        )\n        time.sleep(0.1)\n        print(i)\n\n\nif __name__ == \'__main__\':\n    import os\n    if not os.path.exists(LOG_DIRECTORY):\n        os.makedirs(LOG_DIRECTORY)\n    print(LOG_DIRECTORY)\n    beholder_pytorch()\n'"
examples/demo_caffe2.py,0,"b'try:\n    import caffe2.python.predictor.predictor_exporter as pe\nexcept ImportError:\n    print(\'Please check that Caffe2 is installed correctly to run this demo.\')\nimport numpy as np\nimport os\nimport shutil\n\nfrom caffe2.python import core, model_helper, workspace, brew\nfrom tensorboardX import TorchVis\n\n""""""\nThis is a demo showcasing specific functionality for Caffe2. Shown here are\n    add_scalar (with both raw numerical data and Caffe2 blob names)\n    add_scalars (with both raw numerical data and Caffe2 blob names)\n    add_graph (visualizing a Caffe2 model as a graph)\n\nNOTE: lmdb must be installed and enabled with -DUSE_LMDB=ON for this demo to work.\n""""""\n\n# If you would like to see some really detailed initializations,\n# you can change --caffe2_log_level=0 to --caffe2_log_level=-1\ncore.GlobalInit([\'caffe2\', \'--caffe2_log_level=0\'])\nprint(""Necessities imported!"")\n\n\n# This section preps your image and test set in a lmdb database\ndef DownloadResource(url, path):\n    \'\'\'Downloads resources from s3 by url and unzips them to the provided path\'\'\'\n    import requests\n    from six import BytesIO\n    import zipfile\n    print(""Downloading... {} to {}"".format(url, path))\n    r = requests.get(url, stream=True)\n    z = zipfile.ZipFile(BytesIO(r.content))\n    z.extractall(path)\n    print(""Completed download and extraction."")\n\n\ncurrent_folder = os.path.join(os.path.expanduser(\'~\'), \'caffe2_notebooks\')\ndata_folder = os.path.join(current_folder, \'tutorial_data\', \'mnist\')\nroot_folder = os.path.join(current_folder, \'tutorial_files\', \'tutorial_mnist\')\ndb_missing = False\n\nif not os.path.exists(data_folder):\n    os.makedirs(data_folder)\n    print(""Your data folder was not found!! This was generated: {}"".format(data_folder))\n\n# Look for existing database: lmdb\nif os.path.exists(os.path.join(data_folder, ""mnist-train-nchw-lmdb"")):\n    print(""lmdb train db found!"")\nelse:\n    db_missing = True\n\nif os.path.exists(os.path.join(data_folder, ""mnist-test-nchw-lmdb"")):\n    print(""lmdb test db found!"")\nelse:\n    db_missing = True\n\n# attempt the download of the db if either was missing\nif db_missing:\n    print(""one or both of the MNIST lmbd dbs not found!!"")\n    db_url = ""http://download.caffe2.ai/databases/mnist-lmdb.zip""\n    try:\n        DownloadResource(db_url, data_folder)\n    except Exception as ex:\n        print(\n            ""Failed to download dataset. Please download it manually from {}"".format(db_url))\n        print(""Unzip it and place the two database folders here: {}"".format(data_folder))\n        raise ex\n\nif os.path.exists(root_folder):\n    print(""Looks like you ran this before, so we need to cleanup those old files..."")\n    shutil.rmtree(root_folder)\n\nos.makedirs(root_folder)\nworkspace.ResetWorkspace(root_folder)\n\nprint(""training data folder:"" + data_folder)\nprint(""workspace root folder:"" + root_folder)\n\n# END DATA PREPARATION #\n\n# Create TorchVis in preparation for writing. Default format is \'tensorboard\'\ntv = TorchVis()\n\n\ndef AddInput(model, batch_size, db, db_type):\n    # load the data\n    data_uint8, label = model.TensorProtosDBInput(\n        [], [""data_uint8"", ""label""], batch_size=batch_size,\n        db=db, db_type=db_type)\n    # cast the data to float\n    data = model.Cast(data_uint8, ""data"", to=core.DataType.FLOAT)\n    # scale data from [0,255] down to [0,1]\n    data = model.Scale(data, data, scale=float(1. / 256))\n    # don\'t need the gradient for the backward pass\n    data = model.StopGradient(data, data)\n    return data, label\n\n\ndef AddLeNetModel(model, data):\n    \'\'\'\n    This part is the standard LeNet model: from data to the softmax prediction.\n\n    For each convolutional layer we specify dim_in - number of input channels\n    and dim_out - number or output channels. Also each Conv and MaxPool layer changes the\n    image size. For example, kernel of size 5 reduces each side of an image by 4.\n\n    While when we have kernel and stride sizes equal 2 in a MaxPool layer, it divides\n    each side in half.\n    \'\'\'\n    # Image size: 28 x 28 -> 24 x 24\n    conv1 = brew.conv(model, data, \'conv1\', dim_in=1, dim_out=20, kernel=5)\n    # Image size: 24 x 24 -> 12 x 12\n    pool1 = brew.max_pool(model, conv1, \'pool1\', kernel=2, stride=2)\n    # Image size: 12 x 12 -> 8 x 8\n    conv2 = brew.conv(model, pool1, \'conv2\', dim_in=20, dim_out=100, kernel=5)\n    # Image size: 8 x 8 -> 4 x 4\n    pool2 = brew.max_pool(model, conv2, \'pool2\', kernel=2, stride=2)\n    # 50 * 4 * 4 stands for dim_out from previous layer multiplied by the\n    # image size\n    fc3 = brew.fc(model, pool2, \'fc3\', dim_in=100 * 4 * 4, dim_out=500)\n    relu = brew.relu(model, fc3, fc3)\n    pred = brew.fc(model, relu, \'pred\', 500, 10)\n    softmax = brew.softmax(model, pred, \'softmax\')\n    return softmax\n\n\ndef AddAccuracy(model, softmax, label):\n    """"""Adds an accuracy op to the model""""""\n    accuracy = brew.accuracy(model, [softmax, label], ""accuracy"")\n    return accuracy\n\n\ndef AddTrainingOperators(model, softmax, label):\n    """"""Adds training operators to the model.""""""\n    xent = model.LabelCrossEntropy([softmax, label], \'xent\')\n    # compute the expected loss\n    loss = model.AveragedLoss(xent, ""loss"")\n    # track the accuracy of the model\n    AddAccuracy(model, softmax, label)\n    # use the average loss we just computed to add gradient operators to the\n    # model\n    model.AddGradientOperators([loss])\n    # do a simple stochastic gradient descent\n    ITER = brew.iter(model, ""iter"")\n    # set the learning rate schedule\n    LR = model.LearningRate(\n        ITER, ""LR"", base_lr=-0.1, policy=""step"", stepsize=1, gamma=0.999)\n    # ONE is a constant value that is used in the gradient update. We only need\n    # to create it once, so it is explicitly placed in param_init_net.\n    ONE = model.param_init_net.ConstantFill([], ""ONE"", shape=[1], value=1.0)\n    # Now, for each parameter, we do the gradient updates.\n    for param in model.params:\n        # Note how we get the gradient of each parameter - ModelHelper keeps\n        # track of that.\n        param_grad = model.param_to_grad[param]\n        # The update is a simple weighted sum: param = param + param_grad * LR\n        model.WeightedSum([param, ONE, param_grad, LR], param)\n\n\ndef AddBookkeepingOperators(model):\n    """"""This adds a few bookkeeping operators that we can inspect later.\n\n    These operators do not affect the training procedure: they only collect\n    statistics and prints them to file or to logs.\n    """"""\n    # Print basically prints out the content of the blob. to_file=1 routes the\n    # printed output to a file. The file is going to be stored under\n    #     root_folder/[blob name]\n    model.Print(\'accuracy\', [], to_file=1)\n    model.Print(\'loss\', [], to_file=1)\n    # Summarizes the parameters. Different from Print, Summarize gives some\n    # statistics of the parameter, such as mean, std, min and max.\n    for param in model.params:\n        model.Summarize(param, [], to_file=1)\n        model.Summarize(model.param_to_grad[param], [], to_file=1)\n    # Now, if we really want to be verbose, we can summarize EVERY blob\n    # that the model produces; it is probably not a good idea, because that\n    # is going to take time - summarization do not come for free. For this\n    # demo, we will only show how to summarize the parameters and their\n    # gradients.\n\n\narg_scope = {""order"": ""NCHW""}\ntrain_model = model_helper.ModelHelper(name=""mnist_train"", arg_scope=arg_scope)\ndata, label = AddInput(\n    train_model, batch_size=64,\n    db=os.path.join(data_folder, \'mnist-train-nchw-lmdb\'),\n    db_type=\'lmdb\')\nsoftmax = AddLeNetModel(train_model, data)\nAddTrainingOperators(train_model, softmax, label)\nAddBookkeepingOperators(train_model)\n\n# Visualize the Caffe2 model in Tensorboard\ntv.add_graph(train_model, data)\n\n# Testing model. We will set the batch size to 100, so that the testing\n# pass is 100 iterations (10,000 images in total).\n# For the testing model, we need the data input part, the main LeNetModel\n# part, and an accuracy part. Note that init_params is set False because\n# we will be using the parameters obtained from the train model.\ntest_model = model_helper.ModelHelper(\n    name=""mnist_test"", arg_scope=arg_scope, init_params=False)\ndata, label = AddInput(\n    test_model, batch_size=100,\n    db=os.path.join(data_folder, \'mnist-test-nchw-lmdb\'),\n    db_type=\'lmdb\')\nsoftmax = AddLeNetModel(test_model, data)\nAddAccuracy(test_model, softmax, label)\n\n# Deployment model. We simply need the main LeNetModel part.\ndeploy_model = model_helper.ModelHelper(\n    name=""mnist_deploy"", arg_scope=arg_scope, init_params=False)\nAddLeNetModel(deploy_model, ""data"")\n# You may wonder what happens with the param_init_net part of the deploy_model.\n# No, we will not use them, since during deployment time we will not randomly\n# initialize the parameters, but load the parameters from the db.\n\nwith open(os.path.join(root_folder, ""train_net.pbtxt""), \'w\') as fid:\n    fid.write(str(train_model.net.Proto()))\nwith open(os.path.join(root_folder, ""train_init_net.pbtxt""), \'w\') as fid:\n    fid.write(str(train_model.param_init_net.Proto()))\nwith open(os.path.join(root_folder, ""test_net.pbtxt""), \'w\') as fid:\n    fid.write(str(test_model.net.Proto()))\nwith open(os.path.join(root_folder, ""test_init_net.pbtxt""), \'w\') as fid:\n    fid.write(str(test_model.param_init_net.Proto()))\nwith open(os.path.join(root_folder, ""deploy_net.pbtxt""), \'w\') as fid:\n    fid.write(str(deploy_model.net.Proto()))\nprint(""Protocol buffers files have been created in your root folder: "" + root_folder)\n\n# The parameter initialization network only needs to be run once.\nworkspace.RunNetOnce(train_model.param_init_net)\n# creating the network\nworkspace.CreateNet(train_model.net, overwrite=True)\n# set the number of iterations and track the accuracy & loss\ntotal_iters = 200\naccuracy = np.zeros(total_iters)\nloss = np.zeros(total_iters)\n# Now, we will manually run the network for 200 iterations.\nfor i in range(total_iters):\n    workspace.RunNet(train_model.net)\n    accuracy[i] = workspace.FetchBlob(\'accuracy\')\n    loss[i] = workspace.FetchBlob(\'loss\')\n    scalar_dict_raw = {\'accuracy\': accuracy[i], \'loss\': loss[i]}\n    scalar_dict_blobname = {\'accuracy\': \'accuracy\', \'loss\': \'loss\'}\n    # Can pass raw numerical data\n    tv.add_scalars(\'training_raw\', scalar_dict_raw, i)\n    # Can also pass blobname corresponding to data, for fetching\n    tv.add_scalars(\'training_blobname\', scalar_dict_blobname, i)\n\ndata = workspace.FetchBlob(\'data\')\nsoftmax = workspace.FetchBlob(\'softmax\')\n\n# Convolutions for this mini-batch\nconv = workspace.FetchBlob(\'conv1\')\nshape = list(conv.shape)\nshape[1] = 1\n# We can look into any channel. This of it as a feature model learned\nconv = conv[:, 15, :, :].reshape(shape)\n\n# run a test pass on the test net\nworkspace.RunNetOnce(test_model.param_init_net)\nworkspace.CreateNet(test_model.net, overwrite=True)\ntest_accuracy = np.zeros(100)\nfor i in range(100):\n    workspace.RunNet(test_model.net.Proto().name)\n    test_accuracy[i] = workspace.FetchBlob(\'accuracy\')\n    tv.add_scalar(\'test_accuracy_raw\', test_accuracy[i], i)\n    tv.add_scalar(\'test_accuracy_blobname\', \'accuracy\', i)\n# After the execution is done, let\'s plot the values.\nprint(\'test_accuracy: %f\' % test_accuracy.mean())\n'"
examples/demo_custom_scalars.py,0,"b""from numpy.random import rand\nfrom tensorboardX import SummaryWriter\nimport time\n\n\nwith SummaryWriter() as writer:\n    for n_iter in range(100):\n        writer.add_scalar('twse/0050', rand(), n_iter)\n        writer.add_scalar('twse/2330', rand(), n_iter)\n        t = rand()\n        writer.add_scalar('dow/aaa', t, n_iter)\n        writer.add_scalar('dow/bbb', t - 1, n_iter)\n        writer.add_scalar('dow/ccc', t + 1, n_iter)\n        writer.add_scalar('nasdaq/aaa', rand(), n_iter)\n        writer.add_scalar('nasdaq/bbb', rand(), n_iter)\n        writer.add_scalar('nasdaq/ccc', rand(), n_iter)\n\n    layout = {'Taiwan': {'twse': ['Multiline', ['twse/0050', 'twse/2330']]},\n              'USA': {'dow': ['Margin', ['dow/aaa', 'dow/bbb', 'dow/ccc']],\n                      'nasdaq': ['Margin', ['nasdaq/aaa', 'nasdaq/bbb', 'nasdaq/ccc']]}}\n    writer.add_custom_scalars(layout)\n#    writer.add_custom_scalars(layout) second call has no effect\n\ntime.sleep(1)\n\nwith SummaryWriter() as writer:\n    for n_iter in range(100):\n        writer.add_scalar('twse/0050', rand(), n_iter)\n        writer.add_scalar('twse/2330', rand(), n_iter)\n\n    writer.add_custom_scalars_multilinechart(['twse/0050', 'twse/2330'])\n\ntime.sleep(1)\n\nwith SummaryWriter() as writer:\n    for n_iter in range(100):\n        t = rand()\n        writer.add_scalar('dow/aaa', t, n_iter)\n        writer.add_scalar('dow/bbb', t - 1, n_iter)\n        writer.add_scalar('dow/ccc', t + 1, n_iter)\n\n    writer.add_custom_scalars_marginchart(['dow/aaa', 'dow/bbb', 'dow/ccc'])\n"""
examples/demo_embedding.py,10,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\nfrom torch.autograd.variable import Variable\nfrom tensorboardX import SummaryWriter\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# EMBEDDING VISUALIZATION FOR A TWO-CLASSES PROBLEM\n\n# just a bunch of layers\n\n\nclass M(nn.Module):\n    def __init__(self):\n        super(M, self).__init__()\n        self.cn1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3)\n        self.cn2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3)\n        self.fc1 = nn.Linear(in_features=128, out_features=2)\n\n    def forward(self, i):\n        i = self.cn1(i)\n        i = F.relu(i)\n        i = F.max_pool2d(i, 2)\n        i = self.cn2(i)\n        i = F.relu(i)\n        i = F.max_pool2d(i, 2)\n        i = i.view(len(i), -1)\n        i = self.fc1(i)\n        i = F.log_softmax(i, dim=1)\n        return i\n\n# get some random data around value\n\n\ndef get_data(value, shape):\n    data = torch.ones(shape) * value\n    # add some noise\n    data += torch.randn(shape)**2\n    return data\n\n\n# dataset\n# cat some data with different values\ndata = torch.cat(\n    (get_data(\n        0, (100, 1, 14, 14)), get_data(\n            0.5, (100, 1, 14, 14))), 0)\n# labels\nlabels = torch.cat((torch.zeros(100), torch.ones(100)), 0)\n# generator\ngen = DataLoader(TensorDataset(data, labels), batch_size=25, shuffle=True)\n# network\nm = M()\n#loss and optim\nloss = nn.NLLLoss()\noptimizer = torch.optim.Adam(params=m.parameters())\n# settings for train and log\nnum_epochs = 20\nembedding_log = 5\nwriter = SummaryWriter(comment=\'mnist_embedding_training\')\n\n#writer = SummaryWriter(""gs://your-bucket/embedding-test"")\n#writer = SummaryWriter(""s3://your-bucket/embedding-test"")\n\n# TRAIN\nfor epoch in range(num_epochs):\n    for j, sample in enumerate(gen):\n        n_iter = (epoch * len(gen)) + j\n        # reset grad\n        m.zero_grad()\n        optimizer.zero_grad()\n        # get batch data\n        data_batch = Variable(sample[0], requires_grad=True).float()\n        label_batch = Variable(sample[1], requires_grad=False).long()\n        # FORWARD\n        out = m(data_batch)\n        loss_value = loss(out, label_batch)\n        # BACKWARD\n        loss_value.backward()\n        optimizer.step()\n        # LOGGING\n        writer.add_scalar(\'loss\', loss_value.data.item(), n_iter)\n\n        if j % embedding_log == 0:\n            print(""loss_value:{}"".format(loss_value.data.item()))\n            # we need 3 dimension for tensor to visualize it!\n            out = torch.cat((out.data, torch.ones(len(out), 1)), 1)\n            writer.add_embedding(\n                out,\n                metadata=label_batch.data,\n                label_img=data_batch.data,\n                global_step=n_iter)\n\nwriter.close()\n\n# tensorboard --logdir runs\n# you should now see a dropdown list with all the timestep,\n# last timestep should have a visible separation between the two classes\n'"
examples/demo_global_writer.py,0,b'# This program show that you can use summary writer globally\n# So that you can use the writer like the python.logging module\n\n# This file triggers global_1 and global_2 to do their job.\nimport global_1\nimport time\ntime.sleep(2)\nimport global_2\n\n'
examples/demo_graph.py,21,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.autograd import Variable\nfrom tensorboardX import SummaryWriter\n\ndummy_input = (torch.zeros(1, 3),)\n\n\nclass LinearInLinear(nn.Module):\n    def __init__(self):\n        super(LinearInLinear, self).__init__()\n        self.l = nn.Linear(3, 5)\n\n    def forward(self, x):\n        return self.l(x)\n\nwith SummaryWriter(comment=\'LinearInLinear\') as w:\n    w.add_graph(LinearInLinear(), dummy_input, True)\n\n\nclass MultipleInput(nn.Module):\n    def __init__(self):\n        super(MultipleInput, self).__init__()\n        self.Linear_1 = nn.Linear(3, 5)\n\n\n    def forward(self, x, y):\n        return self.Linear_1(x+y)\n\nwith SummaryWriter(comment=\'MultipleInput\') as w:\n    w.add_graph(MultipleInput(), (torch.zeros(1, 3), torch.zeros(1, 3)), True)\n\nclass MultipleOutput(nn.Module):\n    def __init__(self):\n        super(MultipleOutput, self).__init__()\n        self.Linear_1 = nn.Linear(3, 5)\n        self.Linear_2 = nn.Linear(3, 7)\n\n    def forward(self, x):\n        return self.Linear_1(x), self.Linear_2(x)\n\nwith SummaryWriter(comment=\'MultipleOutput\') as w:\n    w.add_graph(MultipleOutput(), dummy_input, True)\n\n\nclass MultipleOutput_shared(nn.Module):\n    def __init__(self):\n        super(MultipleOutput_shared, self).__init__()\n        self.Linear_1 = nn.Linear(3, 5)\n\n    def forward(self, x):\n        return self.Linear_1(x), self.Linear_1(x)\n\nwith SummaryWriter(comment=\'MultipleOutput_shared\') as w:\n    w.add_graph(MultipleOutput_shared(), dummy_input, True)\n\n\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n\n    def forward(self, x):\n        return x * 2\n\n\nmodel = SimpleModel()\ndummy_input = (torch.zeros(1, 2, 3),)\n\nwith SummaryWriter(comment=\'constantModel\') as w:\n    w.add_graph(model, dummy_input, True)\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        # self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = F.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out += residual\n        out = F.relu(out)\n        return out\n\n\ndummy_input = torch.rand(1, 3, 224, 224)\n\nwith SummaryWriter(comment=\'basicblock\') as w:\n    model = BasicBlock(3, 3)\n    w.add_graph(model, (dummy_input, ), verbose=True)\n\n\n\n\nclass Net1(nn.Module):\n    def __init__(self):\n        super(Net1, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n        self.bn = nn.BatchNorm2d(20)\n\n    def forward(self, x):\n        x = F.max_pool2d(self.conv1(x), 2)\n        x = F.relu(x) + F.relu(-x)\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = self.bn(x)\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        x = F.softmax(x, dim=1)\n        return x\n\n\nclass Net2(nn.Module):\n    def __init__(self):\n        super(Net2, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        x = F.log_softmax(x, dim=1)\n        return x\n\n\ndummy_input = Variable(torch.rand(13, 1, 28, 28))\n\nmodel = Net1()\nwith SummaryWriter(comment=\'Net1\') as w:\n    w.add_graph(model, (dummy_input, ))\n\nmodel = Net2()\nwith SummaryWriter(comment=\'Net2\') as w:\n    w.add_graph(model, (dummy_input, ))\n\n\nclass SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        self.cnn1 = Net1()\n\n    def forward_once(self, x):\n        output = self.cnn1(x)\n        return output\n\n    def forward(self, input1, input2):\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        return output1, output2\n\nmodel = SiameseNetwork()\nwith SummaryWriter(comment=\'SiameseNetwork\') as w:\n    w.add_graph(model, (dummy_input, dummy_input))\n\n\ndummy_input = torch.Tensor(1, 3, 224, 224)\n\nwith SummaryWriter(comment=\'alexnet\') as w:\n    model = torchvision.models.alexnet()\n    w.add_graph(model, (dummy_input, ))\n\nwith SummaryWriter(comment=\'vgg19\') as w:\n    model = torchvision.models.vgg19()\n    w.add_graph(model, (dummy_input, ))\n\nwith SummaryWriter(comment=\'densenet121\') as w:\n    model = torchvision.models.densenet121()\n    w.add_graph(model, (dummy_input, ))\n\nwith SummaryWriter(comment=\'resnet18\') as w:\n    model = torchvision.models.resnet18()\n    w.add_graph(model, (dummy_input, ))\n\n\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.i2h = nn.Linear(\n            n_categories +\n            input_size +\n            hidden_size,\n            hidden_size)\n        self.i2o = nn.Linear(\n            n_categories +\n            input_size +\n            hidden_size,\n            output_size)\n        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n        self.dropout = nn.Dropout(0.1)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, category, input, hidden):\n        input_combined = torch.cat((category, input, hidden), 1)\n        hidden = self.i2h(input_combined)\n        output = self.i2o(input_combined)\n        output_combined = torch.cat((hidden, output), 1)\n        output = self.o2o(output_combined)\n        output = self.dropout(output)\n        output = self.softmax(output)\n        return output, hidden, input\n\n    def initHidden(self):\n        return torch.zeros(1, self.hidden_size)\n\n\nn_letters = 100\nn_hidden = 128\nn_categories = 10\nrnn = RNN(n_letters, n_hidden, n_categories)\ncat = torch.Tensor(1, n_categories)\ndummy_input = torch.Tensor(1, n_letters)\nhidden = torch.Tensor(1, n_hidden)\n\n\nout, hidden, input = rnn(cat, dummy_input, hidden)\nwith SummaryWriter(comment=\'RNN\') as w:\n    w.add_graph(rnn, (cat, dummy_input, hidden), verbose=False)\n\n\n\nlstm = torch.nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\ninputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n\n# initialize the hidden state.\nhidden = (torch.randn(1, 1, 3),\n          torch.randn(1, 1, 3))\nfor i in inputs:\n    out, hidden = lstm(i.view(1, 1, -1), hidden)\n\nwith SummaryWriter(comment=\'lstm\') as w:\n    w.add_graph(lstm, (torch.randn(1, 3).view(1, 1, -1), hidden), verbose=True)\n\n\nimport pytest\nprint(\'expect error here:\')\nwith pytest.raises(Exception) as e_info:\n    dummy_input = torch.rand(1, 1, 224, 224)\n    with SummaryWriter(comment=\'basicblock_error\') as w:\n        w.add_graph(model, (dummy_input, ))  # error\n'"
examples/demo_hogwild.py,9,"b'from __future__ import print_function\nimport argparse\nimport os\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.multiprocessing as mp\nfrom torchvision import datasets, transforms\nfrom tensorboardX import GlobalSummaryWriter\n\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=1000, metavar=\'N\',\n                    help=\'input batch size for testing (default: 1000)\')\nparser.add_argument(\'--epochs\', type=int, default=2, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.5, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nparser.add_argument(\'--num-processes\', type=int, default=2, metavar=\'N\',\n                    help=\'how many training processes to use (default: 2)\')\nparser.add_argument(\'--cuda\', action=\'store_true\', default=False,\n                    help=\'enables CUDA training\')\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n\ndef train(rank, args, model, device, dataloader_kwargs):\n    torch.manual_seed(args.seed + rank)\n\n    train_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\'../data\', train=True, download=True,\n                    transform=transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Normalize((0.1307,), (0.3081,))\n                    ])),\n        batch_size=args.batch_size, shuffle=True, num_workers=1,\n        **dataloader_kwargs)\n\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n    for epoch in range(1, args.epochs + 1):\n        train_epoch(epoch, args, model, device, train_loader, optimizer)\n\ndef train_epoch(epoch, args, model, device, data_loader, optimizer):\n    model.train()\n    pid = os.getpid()\n    for batch_idx, (data, target) in enumerate(data_loader):\n        optimizer.zero_grad()\n        output = model(data.to(device))\n        loss = F.nll_loss(output, target.to(device))\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            writer.add_scalar(""Loss"", loss)\n            print(\'{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                pid, epoch, batch_idx * len(data), len(data_loader.dataset),\n                100. * batch_idx / len(data_loader), loss.item()))\n\nwriter = GlobalSummaryWriter()\n\nif __name__ == \'__main__\':\n    args = parser.parse_args()\n\n    use_cuda = args.cuda and torch.cuda.is_available()\n    device = torch.device(""cuda"" if use_cuda else ""cpu"")\n    dataloader_kwargs = {\'pin_memory\': True} if use_cuda else {}\n\n    torch.manual_seed(args.seed)\n    # mp.set_start_method(\'spawn\')\n\n    model = Net().to(device)\n    model.share_memory() # gradients are allocated lazily, so they are not shared here\n    processes = []\n    for rank in range(args.num_processes):\n        p = mp.Process(target=train, args=(rank, args, model, device, dataloader_kwargs))\n        # We first train the model across `num_processes` processes\n        p.start()\n        processes.append(p)\n    for p in processes:\n        p.join()\n\n'"
examples/demo_hparams.py,0,"b'from tensorboardX import SummaryWriter\nimport time\nimport random\n\n\nhparam = {\'lr\': [0.1, 0.01, 0.001],\n          \'bsize\': [1, 2, 4],\n          \'n_hidden\': [100, 200],\n          \'bn\': [True, False]}\n\nmetrics = {\'accuracy\', \'loss\'}\n\ndef train(lr, bsize, n_hidden):\n    x = random.random()\n    return x, x*5\n\ni = 0\nwith SummaryWriter() as w:\n    for lr in hparam[\'lr\']:\n        for bsize in hparam[\'bsize\']:\n            for n_hidden in hparam[\'n_hidden\']:\n                for bn in hparam[\'bn\']:\n                    accu, loss = train(lr, bsize, n_hidden)\n                    i = i + 1\n                    w.add_hparams({\'lr\': lr, \'bsize\': bsize, \'n_hidden\': n_hidden, \'bn\': bn},\n                                    {\'accuracy\': accu, \'loss\': loss}, name=""trial""+str(i))\n\n'"
examples/demo_matplotlib.py,0,"b""import matplotlib.pyplot as plt\nplt.switch_backend('agg')\n\nfig = plt.figure()\n\nc1 = plt.Circle((0.2, 0.5), 0.2, color='r')\nc2 = plt.Circle((0.8, 0.5), 0.2, color='r')\n\nax = plt.gca()\nax.add_patch(c1)\nax.add_patch(c2)\nplt.axis('scaled')\n\n\nfrom tensorboardX import SummaryWriter\nwriter = SummaryWriter()\nwriter.add_figure('matplotlib', fig)\nwriter.close()\n"""
examples/demo_multiple_embedding.py,0,"b'import math\nimport numpy as np\nfrom tensorboardX import SummaryWriter\n\n\ndef main():\n    degrees = np.linspace(0, 3600 * math.pi / 180.0, 3600)\n    degrees = degrees.reshape(3600, 1)\n    labels = [""%d"" % (i) for i in range(0, 3600)]\n\n    with SummaryWriter() as writer:\n        # Maybe make a bunch of data that\'s always shifted in some\n        # way, and that will be hard for PCA to turn into a sphere?\n\n        for epoch in range(0, 16):\n            shift = epoch * 2 * math.pi / 16.0\n            mat = np.concatenate([\n                np.sin(shift + degrees * 2 * math.pi / 180.0),\n                np.sin(shift + degrees * 3 * math.pi / 180.0),\n                np.sin(shift + degrees * 5 * math.pi / 180.0),\n                np.sin(shift + degrees * 7 * math.pi / 180.0),\n                np.sin(shift + degrees * 11 * math.pi / 180.0)\n            ], axis=1)\n            writer.add_embedding(\n                mat=mat,\n                metadata=labels,\n                tag=""sin"",\n                global_step=epoch)\n\n            mat = np.concatenate([\n                np.cos(shift + degrees * 2 * math.pi / 180.0),\n                np.cos(shift + degrees * 3 * math.pi / 180.0),\n                np.cos(shift + degrees * 5 * math.pi / 180.0),\n                np.cos(shift + degrees * 7 * math.pi / 180.0),\n                np.cos(shift + degrees * 11 * math.pi / 180.0)\n            ], axis=1)\n            writer.add_embedding(\n                mat=mat,\n                metadata=labels,\n                tag=""cos"",\n                global_step=epoch)\n\n            mat = np.concatenate([\n                np.tan(shift + degrees * 2 * math.pi / 180.0),\n                np.tan(shift + degrees * 3 * math.pi / 180.0),\n                np.tan(shift + degrees * 5 * math.pi / 180.0),\n                np.tan(shift + degrees * 7 * math.pi / 180.0),\n                np.tan(shift + degrees * 11 * math.pi / 180.0)\n            ], axis=1)\n            writer.add_embedding(\n                mat=mat,\n                metadata=labels,\n                tag=""tan"",\n                global_step=epoch)\n\n\nif __name__ == ""__main__"":\n    main()\n\n# tensorboard --logdir runs\n# Under ""Projection, you should see\n#  48 tensor found named\n#     cos:cos-00000 to cos:cos-00016\n#     sin:sin-00000 to sin:sin-00016\n#     tan:tan-00000 to tan:tan-00016\n'"
examples/demo_multiprocessing.py,0,"b""from tensorboardX import GlobalSummaryWriter\nimport multiprocessing as mp\nimport time\nimport os\nimport psutil\nimport torch\nimport numpy as np\n\nw = GlobalSummaryWriter()\n\n\ndef train3():\n    for i in range(100):\n        w.add_scalar('many_write_in_func', np.random.randn())\n        time.sleep(0.01*np.random.randint(0, 10))\n\ndef train2(x):\n    np.random.seed(x)\n    w.add_scalar('few_write_per_func/1', np.random.randn())\n    time.sleep(0.05*np.random.randint(0, 10))\n    w.add_scalar('few_write_per_func/2', np.random.randn())\n\ndef train(x):\n\n    w.add_scalar('poolmap/1', x*np.random.randn())\n    time.sleep(0.05*np.random.randint(0, 10))\n    w.add_scalar('poolmap/2', x*np.random.randn())\n\n\n\nif __name__ == '__main__':\n\n    with mp.Pool() as pool:\n        pool.map(train, range(100))\n\n\n    processes = []\n    for i in range(4):\n        p0 = mp.Process(target=train2, args=(i,))\n        p1 = mp.Process(target=train3)\n        processes.append(p0)\n        processes.append(p1)\n        p0.start()\n        p1.start()\n\n    for p in processes:\n        p.join()\n\n    w.close()"""
examples/demo_nvidia_smi.py,1,"b'""""""\nwrite gpu and (gpu) memory usage of nvidia cards as scalar\n""""""\nfrom tensorboardX import SummaryWriter\nimport time\nimport torch\ntry:\n    import nvidia_smi\n    nvidia_smi.nvmlInit()\n    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)  # gpu0\nexcept ImportError:\n    print(\'This demo needs nvidia-ml-py or nvidia-ml-py3\')\n    exit()\n\n\nwith SummaryWriter() as writer:\n    x = []\n    for n_iter in range(50):\n        x.append(torch.Tensor(1000, 1000).cuda())\n        res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n        writer.add_scalar(\'nv/gpu\', res.gpu, n_iter)\n        res = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n        writer.add_scalar(\'nv/gpu_mem\', res.used, n_iter)\n        time.sleep(0.1)\n'"
examples/demo_onnx.py,0,"b""from tensorboardX import SummaryWriter\n\nimport subprocess\nzoo_address = 'https://onnxzoo.blob.core.windows.net/models/opset_8/mnist/mnist.tar.gz'\n\nres = subprocess.call(['wget', '-nc', zoo_address])\nassert res == 0, 'cannot download example onnx model from the zoo'\nres = subprocess.call(['tar', 'xf', 'mnist.tar.gz', '-C', 'examples/', 'mnist/model.onnx'])\n\n\n\nwith SummaryWriter() as w:\n    w.add_onnx_graph('examples/mnist/model.onnx')\n    # w.add_onnx_graph('/Users/dexter/Downloads/resnet50/model.onnx')\n"""
examples/demo_openvino.py,0,"b""from tensorboardX import SummaryWriter\nwith SummaryWriter() as w:\n    # https://download.01.org/opencv/2019/open_model_zoo/R3/20190905_163000_models_bin/mobilenetv2-int8-sparse-v1-tf-0001/FP32/mobilenetv2-int8-sparse-v1-tf-0001.xml\n    w.add_openvino_graph('examples/mobilenetv2.xml')\n\n"""
examples/demo_purge.py,0,"b""from time import sleep\nfrom tensorboardX import SummaryWriter\n\nwith SummaryWriter(logdir='runs/purge') as w:\n    for i in range(100):\n        w.add_scalar('purgetest', i, i)\n\nsleep(1.0)\n\nwith SummaryWriter(logdir='runs/purge', purge_step=42) as w:\n    # event 42~99 are removed (inclusively)\n    for i in range(42, 100):\n        w.add_scalar('purgetest', 42, i)\n"""
examples/global_1.py,0,"b""# called by demo_global_writer\n\nfrom tensorboardX import GlobalSummaryWriter\n\nwriter = GlobalSummaryWriter.getSummaryWriter()\n\nwriter.add_text('my_log', 'greeting from global1')\n\nfor i in range(100):\n    writer.add_scalar('global1', i)\n\nfor i in range(100):\n    writer.add_scalar('common', i)"""
examples/global_2.py,0,"b""# called by demo_global_writer\n\nfrom tensorboardX import GlobalSummaryWriter\n\nwriter = GlobalSummaryWriter.getSummaryWriter()\n\nwriter.add_text('my_log', 'greeting from global2')\n\nfor i in range(100):\n    writer.add_scalar('global2', i)\n\nfor i in range(100):\n    writer.add_scalar('common', i)"""
tensorboardX/__init__.py,0,"b'""""""A module for visualization with tensorboard\n""""""\n\nfrom .record_writer import RecordWriter\nfrom .torchvis import TorchVis\nfrom .writer import FileWriter, SummaryWriter\nfrom .global_writer import GlobalSummaryWriter\n__version__ = ""2.0""  # will be overwritten if run setup.py\n'"
tensorboardX/caffe2_graph.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport copy\nimport logging\nimport os\nimport re\nimport six\n\nfrom builtins import bytes\nfrom caffe2.proto import caffe2_pb2\nfrom caffe2.python import core, workspace\n\nfrom .proto.graph_pb2 import GraphDef\nfrom .proto.node_def_pb2 import NodeDef\nfrom .proto.tensor_shape_pb2 import TensorShapeProto\n\n\ndef _make_unique_name(seen, name, min_version=0):\n    \'\'\'\n    Make the name unique by appending a unique number to the name. Used for SSA.\n\n    Args:\n        seen (set): Set of names that have already been used (with respect to\n            some context).\n        name (string): The name to make unique\n        min_version (number): Starting index. Is incremented continually until\n            it can make the resulting name unique relative to \'seen\'.\n\n    Returns:\n        x (string): A version of name that is not in seen.\n    \'\'\'\n    assert name is not None\n    i = min_version\n    x = \'%s_%d\' % (name, i) if i else name\n    while x in seen:\n        i += 1\n        x = \'%s_%d\' % (name, i)\n    seen.add(x)\n    return x\n\n\ndef _rename_tensorflow_style(shapes, blob_name_tracker, ops):\n    \'\'\'\n    Convert some of the common names in Caffe2 to tensorflow.\n    NOTE: The common names in both Caffe2 and Tensorflow are currently\n        hardcoded, if either side changes at some point, then this code should\n        change as well.\n\n    Args:\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n        blob_name_tracker: Dictionary of all unique blob names (with respect to\n            some context).\n        ops: List of Caffe2 operators\n\n    Returns:\n        None. The _rename_all() call modifies blob_name_tracker and ops in-place.\n    \'\'\'\n    WEIGHT = re.compile(r""(_w)$"")\n    WEIGHT_ = re.compile(r""(_w_)"")\n    BN = re.compile(r""(_bn)$"")\n    BN_ = re.compile(r""(_bn_)"")\n    BIAS = re.compile(r""(_b)$"")\n    BIAS_ = re.compile(r""(_b_)"")\n    SCALE = re.compile(r""(_s)$"")\n    SCALE_ = re.compile(r""(_s_)"")\n    SUM = re.compile(r""(_sum)$"")\n    SUM_ = re.compile(r""(_sum_)"")\n    BRANCH = re.compile(r""(_branch)"")\n\n    def f(name):\n        inter_name = WEIGHT_.sub(\'/weight_\', WEIGHT.sub(\'/weight\', name))\n        inter_name = BN_.sub(\'/batchnorm_\', BN.sub(\'/batchnorm\', inter_name))\n        inter_name = BIAS_.sub(\'/bias_\', BIAS.sub(\'/bias\', inter_name))\n        inter_name = SCALE_.sub(\'/scale_\', SCALE.sub(\'/scale\', inter_name))\n        inter_name = SUM_.sub(\'/sum_\', SUM.sub(\'/sum\', inter_name))\n        new_name = BRANCH.sub(\'/branch\', inter_name)\n        return new_name\n    _rename_all(shapes, blob_name_tracker, ops, f)\n\n\ndef _convert_to_ssa(shapes, blob_name_tracker, ops):\n    \'\'\'\n    Convert an operator graph to SSA (i.e. out-of-place).\n    i.e. blobs will be renamed so that each blob is produced only once.\n\n    Args:\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n        blob_name_tracker: Dictionary of all unique blob names (with respect to\n            some context).\n        ops: List of Caffe2 operators\n\n    Returns:\n        None. Modifies blob_name_tracker and ops in-place.\n    \'\'\'\n    ir = core.IR(ops)\n    seen = set()\n    versioned = {}\n    new_shapes = {}\n    new_blob_name_tracker = {}\n\n    def ssa_name(name, versions):\n        assert name in versions\n        version = versions[name]\n        if (name, version) in versioned:\n            return versioned[(name, version)]\n        # Always setting name2 = `{name}_{version}` would work, but we also try\n        # to avoid a trailing `_0`, so we have to be careful not to introduce\n        # name collisions, such as (foo_1, 0) = foo_1 = (foo, 1).\n        # Note: operator names (if any) will be handled later.\n        new_name = _make_unique_name(seen, name, min_version=version)\n        versioned[(name, version)] = new_name\n        # Transfer shape.\n        if name in shapes:\n            new_shapes[new_name] = shapes[name]\n        if blob_name_tracker and name in blob_name_tracker:\n            new_blob_name_tracker[new_name] = blob_name_tracker[name]\n        return new_name\n\n    for (op, ssa) in zip(ops, ir.ssa):\n        assert op is ssa.op\n        inputs = list(op.input)\n        outputs = list(op.output)\n        del op.input[:]\n        del op.output[:]\n        op.input.extend(ssa_name(name, ssa.in_versions) for name in inputs)\n        op.output.extend(ssa_name(name, ssa.out_versions) for name in outputs)\n\n    shapes.clear()\n    shapes.update(new_shapes)\n    if blob_name_tracker:\n        blob_name_tracker.clear()\n        blob_name_tracker.update(new_blob_name_tracker)\n\n\ndef _get_blob_names(ops):\n    \'\'\'\n    Get all the operator input and output blobs and perform dedup on their names.\n\n    Args:\n        ops: List of Caffe2 operators to extract inputs and outputs from\n\n    Returns:\n        set containing distinct inputs and outputs from \'ops\'\n    \'\'\'\n    names = set()\n    for op in ops:\n        names.update(op.input)\n        names.update(op.output)\n    return {name: name for name in names}\n\n\ndef _remap_keys(old_dict, rename_fn):\n    \'\'\'\n    Rename keys of \'old_dict\' according to \'rename_fn\'.\n\n    Args:\n        old_dict: Dictionary (i.e. containing blob_name -> blob_name\n            relationships.)\n        remap_fn: Function string -> string for renaming.\n\n    Returns:\n        None. Modifies old_dict in-place.\n    \'\'\'\n    new_dict = {rename_fn(key): value for key,\n                value in six.iteritems(old_dict)}\n    old_dict.clear()\n    old_dict.update(new_dict)\n\n\ndef _rename_all(shapes, blob_name_tracker, ops, rename_fn):\n    \'\'\'\n    Rename all the names in the operators.\n\n    Args:\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n        blob_name_tracker: Dictionary of all unique blob names (with respect to\n            some context).\n        ops: List of Caffe2 operators\n        rename_fn: Function string -> string that specifies how to rename\n\n    Returns:\n        None. Modifies shapes, blob_name_tracker and ops in-place using the\n            specified \'rename_fn\'.\n    \'\'\'\n    seen = set()\n    renamed = {}\n\n    def g(name):\n        """""" Collision-free version of f.\n        """"""\n        if name is None:\n            return None\n        if name in renamed:\n            return renamed[name]\n        new_name = _make_unique_name(seen, rename_fn(name))\n        renamed[name] = new_name\n        return new_name\n\n    for op in ops:\n        inputs = list(op.input)\n        outputs = list(op.output)\n        del op.input[:]\n        del op.output[:]\n        op.input.extend(g(name) for name in inputs)\n        op.output.extend(g(name) for name in outputs)\n\n    _remap_keys(shapes, g)\n    if blob_name_tracker:\n        _remap_keys(blob_name_tracker, g)\n    # Rename all operator names (if any) independently so that the\n    # unique-fication happens only once in _fill_missing_operator_names().\n    seen.clear()\n    renamed.clear()\n    for op in ops:\n        op.name = g(op.name)\n\n\ndef _add_gradient_scope(shapes, blob_name_tracker, ops):\n    """"""\n    For all operators or blobs with name containing ""_grad"", add a\n    ""GRADIENTS/"" scope.\n    Note: breaks graph execution since the blob -> gradient mapping is\n    hardcoded.\n\n    Args:\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n        blob_name_tracker: Dictionary of all unique blob names (with respect to\n            some context).\n        ops: List of Caffe2 operators\n\n    Returns:\n        None. Modifies shapes, blob_name_tracker and ops in-place by renaming.\n    """"""\n    def f(name):\n        if \'_grad\' in name:\n            return \'GRADIENTS/{}\'.format(name)\n        else:\n            return name\n    _rename_all(shapes, blob_name_tracker, ops, f)\n\n\ndef _replace_colons(shapes, blob_name_tracker, ops, repl):\n    \'\'\'\n    `:i` has a special meaning in Tensorflow. This function replaces all colons\n    with $ to avoid any possible conflicts.\n\n    Args:\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n        blob_name_tracker: Dictionary of all unique blob names (with respect to\n            some context).\n        ops: List of Caffe2 operators\n        repl: String representing the text to replace \':\' with. Usually this is\n            \'$\'.\n\n    Returns:\n        None. Modifies blob_name_tracker in-place.\n\n    \'\'\'\n    def f(name):\n        return name.replace(\':\', repl)\n    _rename_all(shapes, blob_name_tracker, ops, f)\n\n\ndef _fill_missing_operator_names(ops):\n    \'\'\'\n    Give missing operators a name.\n    We expect C2 operators to be generally unnamed. This gives them a scope\n    (inferred from their outputs) and a name after their type. Duplicates will\n    be postfixed by an index.\n\n    Args:\n        ops: List of Caffe2 operators to assign names to.\n\n    Returns:\n        None: Modifies \'ops\' in-place.\n    \'\'\'\n    seen = set()\n    for op in ops:\n        # Make sure operator names don\'t collide with blobs.\n        seen.update(op.input)\n        seen.update(op.output)\n    for op in ops:\n        if op.name:\n            name = op.name\n        elif op.output or op.input:\n            name_list = [os.path.dirname(name)\n                         for name in op.output or op.input]\n            scope = os.path.commonprefix(name_list)\n            name = os.path.join(scope, op.type)\n        else:\n            name = op.type\n        assert(name)\n        op.name = _make_unique_name(seen, name)\n\n\ndef _tf_device(device_option):\n    \'\'\'\n    Handle the devices.\n\n    Args:\n        device_option (caffe2_pb2.DeviceOption): DeviceOption protobuf,\n            associated to an operator, that contains information such as\n            device_type (optional), cuda_gpu_id (optional), node_name (optional,\n            tells which node the operator should execute on). See caffe2.proto\n            in caffe2/proto for the full list.\n\n    Returns:\n        Formatted string representing device information contained in\n            device_option.\n    \'\'\'\n    if not device_option.HasField(""device_type""):\n        return """"\n    if device_option.device_type == caffe2_pb2.CPU or device_option.device_type == caffe2_pb2.MKLDNN:\n        return ""/cpu:*""\n    if device_option.device_type == caffe2_pb2.CUDA:\n        return ""/gpu:{}"".format(device_option.device_id)\n    raise Exception(""Unhandled device"", device_option)\n\n\ndef _add_tf_shape(attr_dict, ints):\n    \'\'\'\n    Converts a list of ints to a TensorShapeProto representing the dimensions of\n    a blob/object.\n\n    Args:\n        attr_dict: Dictionary to update (usually attributes of a Node)\n        ints: List of integers representing dimensions of some object.\n\n    Returns:\n        None. Modifies attr_dict in-place.\n    \'\'\'\n    shape_proto = TensorShapeProto()\n    for i in ints:\n        dim = TensorShapeProto.Dim()\n        dim.size = i\n        shape_proto.dim.extend([dim])\n    attr_dict[\'_output_shapes\'].list.shape.extend([shape_proto])\n\n\ndef _set_tf_attr(attr_dict, arg):\n    \'\'\'\n    Add attributes to a node. Key is the arg.name, and values can be shape,\n        floats, strings, ints or an empty list.\n\n    Args:\n        attr_dict: Dictionary to update (usually attributes of a Node)\n        arg: Object with name and data fields.\n\n    Returns:\n        None. Modifies attr_dict in-place.\n    \'\'\'\n    k = arg.name\n    if k == \'shape\' and arg.ints:\n        _add_tf_shape(attr_dict, arg.ints)\n        return\n    # Float\n    if arg.HasField(""f""):\n        attr_dict[k].f = arg.f\n        return\n    # Integer\n    if arg.HasField(""i""):\n        attr_dict[k].i = arg.i\n        return\n    # String\n    if arg.HasField(""s""):\n        attr_dict[k].s = (\n            arg.s if isinstance(arg.s, bytes) else str(arg.s).encode(\'utf-8\')\n        )\n        return\n    if arg.floats:\n        attr_dict[k].list.f.extend(arg.floats)\n        return\n    if arg.ints:\n        attr_dict[k].list.i.extend(arg.ints)\n        return\n    if arg.strings:\n        attr_dict[k].list.s.extend(\n            s if isinstance(s, bytes) else str(s).encode(\'utf-8\')\n            for s in arg.strings\n        )\n        return\n    # The value is an empty list.\n    attr_dict[k].list.s.extend([])\n\n\ndef _operator_to_node(shapes, op):\n    \'\'\'\n    Converts an operator to a node in a TF graph.\n\n    Args:\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n        op: The Caffe2 operator to convert to a TF graph node.\n\n    Returns:\n        n: The TF graph node created from op.\n    \'\'\'\n    assert op.name, op\n    n = NodeDef()\n    n.name = op.name\n    n.input.extend(op.input)\n    n.op = op.type\n    n.device = _tf_device(op.device_option)\n    if shapes:\n        # Add shapes in order.\n        for output in op.output:\n            if output not in shapes:\n                break\n            _add_tf_shape(n.attr, shapes[output])\n    for arg in op.arg:\n        _set_tf_attr(n.attr, arg)\n    return n\n\n\ndef _operator_to_node_simp(op, inter_blobs, seen):\n    \'\'\'\n    Convert the operators to nodes.\n\n    Args:\n        op: Caffe2 operator to convert to node\n        inter_blobs: Set of intermediate blobs\n        seen: Names that have already been used and are not unique\n\n    Returns:\n        nodes: Nodes representing \'op\' and the outputs of \'op\'\n    \'\'\'\n    assert op\n    nodes = []\n    outputs = [o for o in op.output if o not in inter_blobs]\n    seen.update(outputs)\n    len_outputs = len(outputs)\n    if len_outputs == 1:\n        n = NodeDef()\n        n.name = outputs[0]\n        # Here we are sure the name is unique.\n        n.input.extend(op.input)\n        n.op = op.type\n        n.device = _tf_device(op.device_option)\n        for arg in op.arg:\n            _set_tf_attr(n.attr, arg)\n        nodes.append(n)\n    elif len_outputs > 1:\n        # Create a name that is likely unique\n        if op.name:\n            name = op.name\n        else:\n            name_list = [name for name in outputs]\n            scope = os.path.commonprefix(name_list)\n            name = os.path.join(scope, op.type)\n        assert(name)\n        op.name = _make_unique_name(seen, name)\n        device = _tf_device(op.device_option)\n\n        # Create additional output nodes\n        for output in outputs:\n            n = NodeDef()\n            n.name = output\n            n.input.extend([op.name])\n            n.op = \'Blob\'\n            n.device = device\n            nodes.append(n)\n\n        # Node for the current op\n        n = NodeDef()\n        n.name = op.name\n        n.input.extend(op.input)\n        n.op = op.type\n        n.device = device\n        for arg in op.arg:\n            _set_tf_attr(n.attr, arg)\n        nodes.append(n)\n\n    return nodes\n\n\ndef _blob_to_node(producing_ops, shapes, name):\n    \'\'\'\n    Converts a blob (operator input or output) to a node in a TF graph.\n\n    Args:\n        producing_ops: Dictionary of blob name to list of\n            (producing_op, blob_index within producing_op.output) mapping.\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n        name: String representing the name of this blob.\n\n    Returns:\n        n: The TF graph node created from this blob.\n    \'\'\'\n    assert name\n    n = NodeDef()\n    n.name = name\n    # Get all ops that have the blob corresponding to \'name\' as one of their\n    # outputs. See _operators_to_graph_def.\n    produced_by = producing_ops.get(name, [])\n    if len(produced_by) > 0:\n        n.op = \'Blob\'\n    else:\n        # This blob is not produced but is instead a TF Placeholder where a\n        # value is passed in.\n        n.op = \'Placeholder\'\n    n.input.extend(\'%s:%d\' % (p_op.name, i) for p_op, i in produced_by)\n    if produced_by:\n        device = produced_by[0][0].device_option\n        if (all(producer[0].device_option == device for producer in produced_by)):\n            n.device = _tf_device(device)\n    if shapes and name in shapes:\n        _add_tf_shape(n.attr, shapes[name])\n    return n\n\n\ndef _clear_debug_info(ops, perform_clear):\n    \'\'\'\n    Removes debug information from operators, they are copious.\n\n    Args:\n        ops: List of Caffe2 operators\n        perform_clear: Boolean passed from _operators_to_graph_def specifying\n            whether to remove the debug information. This boolean is passed into\n            this function to reduce the complexity of _operators_to_graph_def.\n\n    Returns:\n        None. Modifies the list of Caffe2 operators in-place and removes the\n        \'debug_info\' field.\n\n    \'\'\'\n    if not perform_clear:\n        return\n\n    for op in ops:\n        if op.HasField(\'debug_info\'):\n            op.ClearField(\'debug_info\')\n\n\ndef _check_if_forward(blob):\n    \'\'\'\n    Blobs with names containing \'_m\' or \'grad\' are part of the backward pass.\n        This function references facebookresearch/Detectron/detectron/utils/net.py.\n\n    Args:\n        blob: The blob to inspect\n\n    Returns:\n        Boolean representing whether this blob is part of the forward pass\n    \'\'\'\n    #\n    return (blob.find(\'__m\') < 0 or blob.find(\'grad\') < 0)\n\n\ndef _check_if_cpu(blob):\n    \'\'\'\n    Check if the blob\'s name starts with \'_gpu\'.\n\n    Args:\n        blob: The blob to inspect\n\n    Returns:\n        Boolean representing whether this blob is associated with a gpu\n    \'\'\'\n    return not blob.startswith(\'_gpu\')\n\n\ndef _compute_in_out(ops):\n    \'\'\'\n    Find the input, intermediate and output nodes of a set of operators.\n\n    Args:\n        ops: List of Caffe2 operators to look through\n\n    Returns:\n        input_blobs: The input nodes of the set of operators\n        inter_blobs: The intermediate nodes of the set of operators\n        output_blobs: The output nodes of the set of operators\n    \'\'\'\n    in_blobs = set()\n    out_blobs = set()\n\n    for op in ops:\n        for input_blob in op.input:\n            in_blobs.add(input_blob)\n        for output_blob in op.output:\n            out_blobs.add(output_blob)\n\n    input_blobs = list(in_blobs.difference(out_blobs))\n    output_blobs = list(out_blobs.difference(in_blobs))\n    inter_blobs = {b for b in output_blobs if b.startswith(\'_\')}\n    output_blobs = [b for b in output_blobs if b not in inter_blobs]\n\n    return input_blobs, inter_blobs, output_blobs\n\n\ndef _filter_ops(ops, filter_fn, perform_filter):\n    \'\'\'\n    Filter unwanted operators based on criteria in \'filter_fn\'.\n\n    Args:\n        ops: List of Caffe2 operators to filter\n        filter_fn: Criteria function for whether inputs/outputs in an operator\n            should be filtered.\n        perform_filter: Boolean passed from _operators_to_graph_def specifying\n            whether to filter operators\n\n    Returns:\n        new_ops: Subset of ops containing a subset of their inputs and outputs.\n    \'\'\'\n    if not perform_filter:\n        return ops\n\n    new_ops = []\n    for op in ops:\n        inputs = list(op.input)\n        outputs = list(op.output)\n        del op.input[:]\n        del op.output[:]\n        new_inputs = [i for i in inputs if filter_fn(i)]\n        new_outputs = [o for o in outputs if filter_fn(o)]\n\n        # Only add the op if output is not empty\n        if new_outputs:\n            op.input.extend(new_inputs)\n            op.output.extend(new_outputs)\n            new_ops.append(op)\n\n    return new_ops\n\n\ndef _operators_to_graph_def(\n    shapes,\n    ops,\n    colon_replacement=\'$\',\n    with_ssa=True,\n    with_gradient_scope=True,\n    blob_name_tracker=None,\n    show_simplified=False,\n    custom_rename=None\n):\n    \'\'\'\n    Main function to convert set of operators to a graph.\n\n    Args:\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n        ops: List of Caffe2 operators, representing some computation graph\n        ### **kwargs (model_to_graph_def, nets_to_graph_def, protos_to_graph_def) ###\n        colon_replacement: Symbol to replace \':\' with. \':i\' in TF has a special\n            meaning, so we need to replace it with a non-conflicting symbol.\n        with_ssa: Boolean\n        with_gradient_scope: Boolean\n        blob_name_tracker: Dictionary tracking names of blobs (inputs/outputs\n            from operators)\n        show_simplified: Whether to show a simplified version of the model graph\n            Sets all of the following values:\n                clear_debug_info: Boolean representing whether to silence debug\n                    info (which can be very verbose)\n                show_forward_only: Boolean representing whether to only show\n                    blobs involved in the forward pass\n                show_cpu_only: Boolean representing whether to only show blobs\n                    that are not associated with a gpu\n                use_tensorflow_naming: Boolean representing whether to convert\n                    some common Caffe2 naming conventions to their Tensorflow\n                    counterparts\n        custom_rename: Function string -> string that defines a custom\n            renaming function to use.\n\n    Returns:\n        current_graph: GraphDef representing the computation graph formed by the\n            set of operators.\n    \'\'\'\n    if blob_name_tracker is not None:\n        blob_name_tracker.clear()\n    else:\n        blob_name_tracker = {}\n\n    blob_name_tracker.update(_get_blob_names(ops))\n\n    _clear_debug_info(ops, show_simplified)  # clear_debug_info\n    ops = _filter_ops(ops, _check_if_forward,\n                      show_simplified)  # show_forward_only\n    ops = _filter_ops(ops, _check_if_cpu, show_simplified)  # show_cpu_only\n    if custom_rename:\n        _rename_all(shapes, blob_name_tracker, ops, custom_rename)\n    if colon_replacement:\n        _replace_colons(shapes, blob_name_tracker, ops, colon_replacement)\n    if with_ssa:\n        _convert_to_ssa(shapes, blob_name_tracker, ops)\n    if with_gradient_scope:\n        _add_gradient_scope(shapes, blob_name_tracker, ops)\n    _fill_missing_operator_names(ops)\n    if show_simplified:  # use_tensorflow_naming\n        _rename_tensorflow_style(shapes, blob_name_tracker, ops)\n    producing_ops = {}\n    blobs = []\n    input_blobs, inter_blobs, _ = _compute_in_out(ops)\n    current_graph = GraphDef()\n    seen = set(input_blobs)\n    for op in ops:\n        nodes_from_op = _operator_to_node_simp(op, inter_blobs, seen) if \\\n            show_simplified else \\\n            [_operator_to_node(shapes, op)]  # .extend() expects an iterable\n        current_graph.node.extend(nodes_from_op)\n        for input_blob in op.input:\n            blobs.append(input_blob)\n        for i, output_blob in enumerate(op.output):\n            blobs.append(output_blob)\n            producing_ops.setdefault(output_blob, []).append((op, i))\n\n    if show_simplified:\n        # Show a cleaner, easier-to-interpret version of the model graph\n        blobs = input_blobs\n\n    for blob in blobs:\n        current_graph.node.extend([_blob_to_node(producing_ops, {}, blob)])\n\n    return current_graph\n\n\ndef _propagate_device_option(net_def):\n    \'\'\'\n    Propagate the device options from net to operators.\n\n    Args:\n        net_def: A caffe2_pb2.NetDef representing a computation graph. The graph\n            consists of Caffe2 operators.\n\n    Returns:\n        None. Iterates through all ops contained within the net. For each op,\n            modifies the op device_option in-place to be the net device_option\n            if the op has no pre-existing device_option, and leaves the op as-is\n            if it already has a device_option.\n    \'\'\'\n    if not net_def.HasField(""device_option""):\n        return\n    for op in net_def.op:\n        if not op.HasField(""device_option""):\n            op.device_option.CopyFrom(net_def.device_option)\n\n\ndef _try_get_shapes(nets):\n    \'\'\'\n    Get missing shapes for all blobs contained in the nets.\n\n    Args:\n        nets: List of core.Net to extract blob shape information from.\n\n    Returns:\n        Dictionary containing blob name to shape/dimensions mapping. The net\n            is a computation graph that is composed of operators, and the\n            operators have input and output blobs, each with their own dims.\n    \'\'\'\n    try:\n        # Note: this will inspect the workspace for better or worse.\n        # We don\'t care about the types, only the shapes\n        shapes, _ = workspace.InferShapesAndTypes(nets)\n        return shapes\n    except Exception as e:\n        logging.warning(\'Failed to compute shapes: %s\', e)\n        return {}\n\n\ndef model_to_graph_def(model, **kwargs):\n    \'\'\'\n    Convert a Caffe2 model to a Tensorflow graph. This function extracts\n    \'param_init_net\' and \'net\' from the model and passes it to nets_to_graph()\n    for further processing.\n\n    Args:\n        model (cnn.CNNModelHelper, model_helper.ModelHelper): The model to\n            extract the nets (instances of core.Net) from.\n\n    Returns:\n        Call to nets_to_graph_def() with extracted \'param_init_net\', \'net\' and\n            **kwargs. See _operators_to_graph_def for detailed **kwargs.\n    \'\'\'\n    nets = [model.param_init_net, model.net]\n    return nets_to_graph_def(nets, **kwargs)\n\n\ndef nets_to_graph_def(nets, shapes=None, **kwargs):\n    \'\'\'\n    Convert a set of Caffe2 nets to a Tensorflow graph.\n\n    Args:\n        nets: List of core.Nets. core.Net is a wrapper around a NetDef protobuf.\n            The corresponding protobuf can be extracted using .Proto().\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n\n    Returns:\n        Call to protos_to_graph_def() with the extracted NetDef protobufs and\n            **kwargs. See _operators_to_graph_def for detailed **kwargs.\n    \'\'\'\n    # if shapes is None:\n    #     shapes = _try_get_shapes(nets)\n    # _try_get_shapes(nets) depends on workspace.InferShapesAndTypes(nets),\n    # which is currently broken (segfault). We omit the shapes for now.\n    shapes = {}\n    nets = [copy.deepcopy(net.Proto()) for net in nets]\n    shapes = copy.deepcopy(shapes)\n    return protos_to_graph_def(nets, shapes, **kwargs)\n\n\ndef protos_to_graph_def(net_defs, shapes=None, **kwargs):\n    \'\'\'\n    Convert a set of Caffe2 net definitions to a Tensorflow graph.\n\n    Args:\n        net_defs: List of caffe2_pb2.NetDef protobufs representing computation\n            graphs.\n        shapes: Dictionary mapping blob names to their shapes/dimensions.\n\n    Returns:\n        Call to _operators_to_graph_def() with the extracted operators from the\n            NetDefs and **kwargs. See _operators_to_graph_def for detailed\n            **kwargs.\n    \'\'\'\n    for net in net_defs:\n        _propagate_device_option(net)\n    shapes = copy.deepcopy(shapes or {})\n    ops = [op for net_def in net_defs for op in net_def.op]\n    return _operators_to_graph_def(shapes, ops, **kwargs)\n'"
tensorboardX/crc32c.py,0,"b'# https://www.ietf.org/rfc/rfc3309.txt\nimport array\nimport os\n\ntry:\n    if os.environ.get(\'CRC32C_SW_MODE\', None) is None:\n        os.environ[\'CRC32C_SW_MODE\'] = \'auto\'\n    from crc32c import crc32 as _crc32c_native\nexcept ImportError:\n    _crc32c_native = None\n\n\nCRC_TABLE = (\n    0x00000000, 0xf26b8303, 0xe13b70f7, 0x1350f3f4,\n    0xc79a971f, 0x35f1141c, 0x26a1e7e8, 0xd4ca64eb,\n    0x8ad958cf, 0x78b2dbcc, 0x6be22838, 0x9989ab3b,\n    0x4d43cfd0, 0xbf284cd3, 0xac78bf27, 0x5e133c24,\n    0x105ec76f, 0xe235446c, 0xf165b798, 0x030e349b,\n    0xd7c45070, 0x25afd373, 0x36ff2087, 0xc494a384,\n    0x9a879fa0, 0x68ec1ca3, 0x7bbcef57, 0x89d76c54,\n    0x5d1d08bf, 0xaf768bbc, 0xbc267848, 0x4e4dfb4b,\n    0x20bd8ede, 0xd2d60ddd, 0xc186fe29, 0x33ed7d2a,\n    0xe72719c1, 0x154c9ac2, 0x061c6936, 0xf477ea35,\n    0xaa64d611, 0x580f5512, 0x4b5fa6e6, 0xb93425e5,\n    0x6dfe410e, 0x9f95c20d, 0x8cc531f9, 0x7eaeb2fa,\n    0x30e349b1, 0xc288cab2, 0xd1d83946, 0x23b3ba45,\n    0xf779deae, 0x05125dad, 0x1642ae59, 0xe4292d5a,\n    0xba3a117e, 0x4851927d, 0x5b016189, 0xa96ae28a,\n    0x7da08661, 0x8fcb0562, 0x9c9bf696, 0x6ef07595,\n    0x417b1dbc, 0xb3109ebf, 0xa0406d4b, 0x522bee48,\n    0x86e18aa3, 0x748a09a0, 0x67dafa54, 0x95b17957,\n    0xcba24573, 0x39c9c670, 0x2a993584, 0xd8f2b687,\n    0x0c38d26c, 0xfe53516f, 0xed03a29b, 0x1f682198,\n    0x5125dad3, 0xa34e59d0, 0xb01eaa24, 0x42752927,\n    0x96bf4dcc, 0x64d4cecf, 0x77843d3b, 0x85efbe38,\n    0xdbfc821c, 0x2997011f, 0x3ac7f2eb, 0xc8ac71e8,\n    0x1c661503, 0xee0d9600, 0xfd5d65f4, 0x0f36e6f7,\n    0x61c69362, 0x93ad1061, 0x80fde395, 0x72966096,\n    0xa65c047d, 0x5437877e, 0x4767748a, 0xb50cf789,\n    0xeb1fcbad, 0x197448ae, 0x0a24bb5a, 0xf84f3859,\n    0x2c855cb2, 0xdeeedfb1, 0xcdbe2c45, 0x3fd5af46,\n    0x7198540d, 0x83f3d70e, 0x90a324fa, 0x62c8a7f9,\n    0xb602c312, 0x44694011, 0x5739b3e5, 0xa55230e6,\n    0xfb410cc2, 0x092a8fc1, 0x1a7a7c35, 0xe811ff36,\n    0x3cdb9bdd, 0xceb018de, 0xdde0eb2a, 0x2f8b6829,\n    0x82f63b78, 0x709db87b, 0x63cd4b8f, 0x91a6c88c,\n    0x456cac67, 0xb7072f64, 0xa457dc90, 0x563c5f93,\n    0x082f63b7, 0xfa44e0b4, 0xe9141340, 0x1b7f9043,\n    0xcfb5f4a8, 0x3dde77ab, 0x2e8e845f, 0xdce5075c,\n    0x92a8fc17, 0x60c37f14, 0x73938ce0, 0x81f80fe3,\n    0x55326b08, 0xa759e80b, 0xb4091bff, 0x466298fc,\n    0x1871a4d8, 0xea1a27db, 0xf94ad42f, 0x0b21572c,\n    0xdfeb33c7, 0x2d80b0c4, 0x3ed04330, 0xccbbc033,\n    0xa24bb5a6, 0x502036a5, 0x4370c551, 0xb11b4652,\n    0x65d122b9, 0x97baa1ba, 0x84ea524e, 0x7681d14d,\n    0x2892ed69, 0xdaf96e6a, 0xc9a99d9e, 0x3bc21e9d,\n    0xef087a76, 0x1d63f975, 0x0e330a81, 0xfc588982,\n    0xb21572c9, 0x407ef1ca, 0x532e023e, 0xa145813d,\n    0x758fe5d6, 0x87e466d5, 0x94b49521, 0x66df1622,\n    0x38cc2a06, 0xcaa7a905, 0xd9f75af1, 0x2b9cd9f2,\n    0xff56bd19, 0x0d3d3e1a, 0x1e6dcdee, 0xec064eed,\n    0xc38d26c4, 0x31e6a5c7, 0x22b65633, 0xd0ddd530,\n    0x0417b1db, 0xf67c32d8, 0xe52cc12c, 0x1747422f,\n    0x49547e0b, 0xbb3ffd08, 0xa86f0efc, 0x5a048dff,\n    0x8ecee914, 0x7ca56a17, 0x6ff599e3, 0x9d9e1ae0,\n    0xd3d3e1ab, 0x21b862a8, 0x32e8915c, 0xc083125f,\n    0x144976b4, 0xe622f5b7, 0xf5720643, 0x07198540,\n    0x590ab964, 0xab613a67, 0xb831c993, 0x4a5a4a90,\n    0x9e902e7b, 0x6cfbad78, 0x7fab5e8c, 0x8dc0dd8f,\n    0xe330a81a, 0x115b2b19, 0x020bd8ed, 0xf0605bee,\n    0x24aa3f05, 0xd6c1bc06, 0xc5914ff2, 0x37faccf1,\n    0x69e9f0d5, 0x9b8273d6, 0x88d28022, 0x7ab90321,\n    0xae7367ca, 0x5c18e4c9, 0x4f48173d, 0xbd23943e,\n    0xf36e6f75, 0x0105ec76, 0x12551f82, 0xe03e9c81,\n    0x34f4f86a, 0xc69f7b69, 0xd5cf889d, 0x27a40b9e,\n    0x79b737ba, 0x8bdcb4b9, 0x988c474d, 0x6ae7c44e,\n    0xbe2da0a5, 0x4c4623a6, 0x5f16d052, 0xad7d5351,\n)\n\nCRC_INIT = 0\n\n_MASK = 0xFFFFFFFF\n\n\ndef crc_update(crc, data):\n    """"""Update CRC-32C checksum with data.\n\n    Args:\n      crc: 32-bit checksum to update as long.\n      data: byte array, string or iterable over bytes.\n\n    Returns:\n      32-bit updated CRC-32C as long.\n    """"""\n\n    if type(data) != array.array or data.itemsize != 1:\n        buf = array.array(""B"", data)\n    else:\n        buf = data\n\n    crc ^= _MASK\n    for b in buf:\n        table_index = (crc ^ b) & 0xff\n        crc = (CRC_TABLE[table_index] ^ (crc >> 8)) & _MASK\n    return crc ^ _MASK\n\n\ndef crc_finalize(crc):\n    """"""Finalize CRC-32C checksum.\n\n    This function should be called as last step of crc calculation.\n\n    Args:\n      crc: 32-bit checksum as long.\n\n    Returns:\n      finalized 32-bit checksum as long\n    """"""\n    return crc & _MASK\n\n\ndef _crc32c(data):\n    """"""Compute CRC-32C checksum of the data.\n\n    Args:\n      data: byte array, string or iterable over bytes.\n\n    Returns:\n      32-bit CRC-32C checksum of data as long.\n    """"""\n    return crc_finalize(crc_update(CRC_INIT, data))\n\n\ncrc32c = _crc32c if _crc32c_native is None else _crc32c_native\n'"
tensorboardX/embedding.py,0,"b'import os\nimport sys\n\n# Maximum sprite size allowed by TB frontend,\n# see https://github.com/lanpa/tensorboardX/issues/516\nTB_MAX_SPRITE_SIZE = 8192\n\n\ndef maybe_upload_file(local_path):\n    \'\'\'Upload a file to remote cloud storage\n    if the path starts with gs:// or s3://\n    \'\'\'\n    if local_path.startswith((\'s3://\', \'gs://\')):\n        prefix = local_path.split(\':\')[0]\n        remote_bucket_path = local_path[len(""s3://""):]  # same length\n        bp = remote_bucket_path.split(""/"")\n        bucket = bp[0]\n        path = remote_bucket_path[1 + len(bucket):]\n\n        # s3://example/file becomes s3:/example/file in Linux\n        local_path = prefix + \':/\' + remote_bucket_path\n        if prefix == \'s3\':\n            import boto3\n            s3 = boto3.client(\'s3\', endpoint_url=os.environ.get(\'S3_ENDPOINT\'))\n            s3.upload_file(local_path, bucket, path)\n\n        elif prefix == \'gs\':\n            from google.cloud import storage\n            client = storage.Client()\n\n            Hbucket = storage.Bucket(client, bucket)\n            blob = storage.Blob(path, Hbucket)\n            blob.upload_from_filename(local_path)\n\n\ndef make_tsv(metadata, save_path, metadata_header=None):\n    if not metadata_header:\n        metadata = [str(x) for x in metadata]\n    else:\n        assert len(metadata_header) == len(metadata[0]), \\\n            \'len of header must be equal to the number of columns in metadata\'\n        metadata = [\'\\t\'.join(str(e) for e in l)\n                    for l in [metadata_header] + metadata]\n\n    named_path = os.path.join(save_path, \'metadata.tsv\')\n\n    if sys.version_info[0] == 3:\n        with open(named_path, \'w\', encoding=\'utf8\') as f:\n            for x in metadata:\n                f.write(x + \'\\n\')\n    else:\n        with open(named_path, \'wb\') as f:\n            for x in metadata:\n                f.write((x + \'\\n\').encode(\'utf-8\'))\n    maybe_upload_file(named_path)\n\n\n# https://github.com/tensorflow/tensorboard/issues/44 image label will be squared\ndef make_sprite(label_img, save_path):\n    import math\n    import numpy as np\n    from .x2num import make_np\n    from .utils import make_grid\n    from PIL import Image\n    # this ensures the sprite image has correct dimension as described in\n    # https://www.tensorflow.org/get_started/embedding_viz\n    # There are some constraints for the sprite image:\n    # 1. The sprite image should be square.\n    # 2. Each image patch in the sprite image should be square.\n    # 2. The content is row major order, so we can padding the image on the\n    #    bottom, but not on the right, otherwise, TB will treat some padded location\n    #    as images to be shown.\n    # args: label_img: tensor in NCHW\n\n    assert label_img.shape[2] == label_img.shape[3], \'Image should be square, see tensorflow/tensorboard#670\'\n    total_pixels = label_img.shape[0] * label_img.shape[2] * label_img.shape[3]\n    pixels_one_side = total_pixels ** 0.5\n    number_of_images_per_row = int(math.ceil(pixels_one_side / label_img.shape[3]))\n    arranged_img_CHW = make_grid(make_np(label_img), ncols=number_of_images_per_row)\n    arranged_img_HWC = arranged_img_CHW.transpose(1, 2, 0)  # chw -> hwc\n\n    sprite_size = arranged_img_CHW.shape[2]\n    assert sprite_size <= TB_MAX_SPRITE_SIZE, \'Sprite too large, see label_img shape limits\'\n    arranged_augment_square_HWC = np.ndarray((sprite_size, sprite_size, 3))\n    arranged_augment_square_HWC[:arranged_img_HWC.shape[0], :, :] = arranged_img_HWC\n    im = Image.fromarray(np.uint8((arranged_augment_square_HWC * 255).clip(0, 255)))\n    named_path = os.path.join(save_path, \'sprite.png\')\n    im.save(named_path)\n    maybe_upload_file(named_path)\n\n\ndef append_pbtxt(metadata, label_img, save_path, subdir, global_step, tag):\n    from posixpath import join\n    named_path = os.path.join(save_path, \'projector_config.pbtxt\')\n    with open(named_path, \'a\') as f:\n        # step = os.path.split(save_path)[-1]\n        f.write(\'embeddings {\\n\')\n        f.write(\'tensor_name: ""{}:{}""\\n\'.format(\n            tag, str(global_step).zfill(5)))\n        f.write(\'tensor_path: ""{}""\\n\'.format(join(subdir, \'tensors.tsv\')))\n        if metadata is not None:\n            f.write(\'metadata_path: ""{}""\\n\'.format(\n                join(subdir, \'metadata.tsv\')))\n        if label_img is not None:\n            f.write(\'sprite {\\n\')\n            f.write(\'image_path: ""{}""\\n\'.format(join(subdir, \'sprite.png\')))\n            f.write(\'single_image_dim: {}\\n\'.format(label_img.shape[3]))\n            f.write(\'single_image_dim: {}\\n\'.format(label_img.shape[2]))\n            f.write(\'}\\n\')\n        f.write(\'}\\n\')\n    maybe_upload_file(named_path)\n\n\ndef make_mat(matlist, save_path):\n    named_path = os.path.join(save_path, \'tensors.tsv\')\n    with open(named_path, \'w\') as f:\n        for x in matlist:\n            x = [str(i.item()) for i in x]\n            f.write(\'\\t\'.join(x) + \'\\n\')\n    maybe_upload_file(named_path)\n'"
tensorboardX/event_file_writer.py,0,"b'# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Writes events to disk in a logdir.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport socket\nimport threading\nimport time\nimport multiprocessing\nimport six\n\nfrom .proto import event_pb2\nfrom .record_writer import RecordWriter, directory_check\n\n\nclass EventsWriter(object):\n    \'\'\'Writes `Event` protocol buffers to an event file.\'\'\'\n\n    def __init__(self, file_prefix, filename_suffix=\'\'):\n        \'\'\'\n        Events files have a name of the form\n        \'/some/file/path/events.out.tfevents.[timestamp].[hostname]\'\n        \'\'\'\n        self._file_name = file_prefix + "".out.tfevents."" + str(time.time())[:10] + ""."" +\\\n            socket.gethostname() + filename_suffix\n        self._num_outstanding_events = 0\n        self._py_recordio_writer = RecordWriter(self._file_name)\n        # Initialize an event instance.\n        self._event = event_pb2.Event()\n        self._event.wall_time = time.time()\n        self._event.file_version = \'brain.Event:2\'\n        self._lock = threading.Lock()\n        self.write_event(self._event)\n\n    def write_event(self, event):\n        \'\'\'Append ""event"" to the file.\'\'\'\n\n        # Check if event is of type event_pb2.Event proto.\n        if not isinstance(event, event_pb2.Event):\n            raise TypeError(""Expected an event_pb2.Event proto, ""\n                            "" but got %s"" % type(event))\n        return self._write_serialized_event(event.SerializeToString())\n\n    def _write_serialized_event(self, event_str):\n        with self._lock:\n            self._num_outstanding_events += 1\n            self._py_recordio_writer.write(event_str)\n\n    def flush(self):\n        \'\'\'Flushes the event file to disk.\'\'\'\n        with self._lock:\n            self._num_outstanding_events = 0\n            self._py_recordio_writer.flush()\n        return True\n\n    def close(self):\n        \'\'\'Call self.flush().\'\'\'\n        return_value = self.flush()\n        with self._lock:\n            self._py_recordio_writer.close()\n        return return_value\n\n\nclass EventFileWriter(object):\n    """"""Writes `Event` protocol buffers to an event file.\n\n    The `EventFileWriter` class creates an event file in the specified directory,\n    and asynchronously writes Event protocol buffers to the file. The Event file\n    is encoded using the tfrecord format, which is similar to RecordIO.\n    """"""\n\n    def __init__(self, logdir, max_queue_size=10, flush_secs=120, filename_suffix=\'\'):\n        """"""Creates a `EventFileWriter` and an event file to write to.\n\n        On construction the summary writer creates a new event file in `logdir`.\n        This event file will contain `Event` protocol buffers, which are written to\n        disk via the add_event method.\n        The other arguments to the constructor control the asynchronous writes to\n        the event file:\n\n        Args:\n          logdir: A string. Directory where event file will be written.\n          max_queue_size: Integer. Size of the queue for pending events and summaries.\n          flush_secs: Number. How often, in seconds, to flush the\n            pending events and summaries to disk.\n        """"""\n        self._logdir = logdir\n        directory_check(self._logdir)\n        self._event_queue = multiprocessing.Queue(max_queue_size)\n        self._ev_writer = EventsWriter(os.path.join(\n            self._logdir, ""events""), filename_suffix)\n        self._flush_secs = flush_secs\n        self._closed = False\n        self._worker = _EventLoggerThread(self._event_queue, self._ev_writer,\n                                          flush_secs)\n\n        self._worker.start()\n\n    def get_logdir(self):\n        """"""Returns the directory where event file will be written.""""""\n        return self._logdir\n\n    def reopen(self):\n        """"""Reopens the EventFileWriter.\n        Can be called after `close()` to add more events in the same directory.\n        The events will go into a new events file and a new write/flush worker\n        is created. Does nothing if the EventFileWriter was not closed.\n        """"""\n        if self._closed:\n            self._closed = False\n            self._worker = _EventLoggerThread(\n                self._event_queue, self._ev_writer, self._flush_secs\n            )\n            self._worker.start()\n\n    def add_event(self, event):\n        """"""Adds an event to the event file.\n\n        Args:\n          event: An `Event` protocol buffer.\n        """"""\n        if not self._closed:\n            self._event_queue.put(event)\n\n    def flush(self):\n        """"""Flushes the event file to disk.\n\n        Call this method to make sure that all pending events have been written to\n        disk.\n        """"""\n        if not self._closed:\n            self._ev_writer.flush()\n\n    def close(self):\n        """"""Performs a final flush of the event file to disk, stops the\n        write/flush worker and closes the file. Call this method when you do not\n        need the summary writer anymore.\n        """"""\n        if not self._closed:\n            self.flush()\n            self._worker.stop()\n            self._ev_writer.close()\n            self._event_queue.close()\n            self._event_queue = None  # this is critical\n            self._worker = None  # this is critical too\n            self._closed = True\n\n\nclass _EventLoggerThread(threading.Thread):\n    """"""Thread that logs events.""""""\n\n    def __init__(self, queue, record_writer, flush_secs):\n        """"""Creates an _EventLoggerThread.\n        Args:\n          queue: A Queue from which to dequeue data.\n          record_writer: An data writer. Used to log brain events for\n           the visualizer.\n          flush_secs: How often, in seconds, to flush the\n            pending file to disk.\n        """"""\n        threading.Thread.__init__(self)\n        self.daemon = True\n        self._queue = queue\n        self._record_writer = record_writer\n        self._flush_secs = flush_secs\n        # The first data will be flushed immediately.\n        self._next_flush_time = 0\n        self._has_pending_data = False\n        self._shutdown_signal = object()\n\n    def stop(self):\n        self._queue.put(self._shutdown_signal)\n        self.join()\n\n    def run(self):\n        # Here wait on the queue until an data appears, or till the next\n        # time to flush the writer, whichever is earlier. If we have an\n        # data, write it. If not, an empty queue exception will be raised\n        # and we can proceed to flush the writer.\n        while True:\n            now = time.time()\n            queue_wait_duration = self._next_flush_time - now\n            data = None\n            try:\n                if queue_wait_duration > 0:\n                    data = self._queue.get(True, queue_wait_duration)\n                else:\n                    data = self._queue.get(False)\n\n                if type(data) == type(self._shutdown_signal):\n                    return\n                self._record_writer.write_event(data)\n                self._has_pending_data = True\n            except six.moves.queue.Empty:\n                pass\n\n            now = time.time()\n            if now > self._next_flush_time:\n                if self._has_pending_data:\n                    # Small optimization - if there are no pending data,\n                    # there\'s no need to flush, since each flush can be\n                    # expensive (e.g. uploading a new file to a server).\n                    self._record_writer.flush()\n                    self._has_pending_data = False\n                # Do it again in flush_secs.\n                self._next_flush_time = now + self._flush_secs\n'"
tensorboardX/global_writer.py,3,"b'from .writer import SummaryWriter\nfrom multiprocessing import Value\nimport multiprocessing as mp\n\nglobal _writer\n_writer = None\n\n\nclass GlobalSummaryWriter(object):\n    """"""A class that implements an event writer that supports concurrent logging and global logging across\n    different modules.\n\n    The GlobalSummaryWriter class provides a set of API to write TensorBoard events from different processes.\n    The writer instance can be accessed from different processes or modules. Also, the instance maintains\n    the ``global_step`` value itself so that the interleaved requests to write an event will not conflict\n    each other. This ensures that the resulting event file is TensorBoard compatible.\n    With GlobalSummaryWriter, you can easily log the metrics of your parallel-trained model.\n    The GlobalSummaryWriter and also be used like the ``logging`` module of Python.\n    See how ``getSummaryWriter`` is used below.\n    """"""\n    def __init__(self, logdir=None, comment=\'\', purge_step=None, max_queue=10,\n                 flush_secs=120, filename_suffix=\'\', write_to_disk=True, log_dir=None,\n                 coalesce_process=True, **kwargs):\n        """"""\n        Initialize a GlobalSummaryWriter. The resulting instance will maintain a monotonically\n        increasing ``global_step`` for the the event to be written. So there is no need to pass\n        the global_step when calling its member functions such as ``add_scalar()``.\n        All arguments for the constructor will be passed to the ordinary ``SummaryWriter.__init__()`` directly.\n\n        Examples::\n\n            import multiprocessing as mp\n            import numpy as np\n            import time\n            from tensorboardX import GlobalSummaryWriter\n            w = GlobalSummaryWriter()\n\n            def train(x):\n                w.add_scalar(\'poolmap/1\', x*np.random.randn())\n                time.sleep(0.05*np.random.randint(0, 10))\n                w.add_scalar(\'poolmap/2\', x*np.random.randn())\n\n            with mp.Pool() as pool:\n                pool.map(train, range(100))\n\n        Expected result:\n\n        .. image:: _static/img/tensorboard/add_scalar_global.png\n           :scale: 50 %\n\n        """"""\n\n        self.smw = SummaryWriter(logdir=logdir, comment=comment, purge_step=purge_step, max_queue=max_queue,\n                                 flush_secs=flush_secs, filename_suffix=filename_suffix, write_to_disk=write_to_disk,\n                                 log_dir=log_dir)\n        self.lock = mp.Lock()\n        self.scalar_tag_to_step = mp.Manager().dict()\n        self.image_tag_to_step = mp.Manager().dict()\n        self.histogram_tag_to_step = mp.Manager().dict()\n        self.text_tag_to_step = mp.Manager().dict()\n        self.audio_tag_to_step = mp.Manager().dict()\n\n    def add_scalar(self, tag, scalar_value, walltime=None):\n        """"""Add scalar data to summary.\n\n        Args:\n            tag (string): Data identifier\n            scalar_value (float): Value to save\n            walltime (float): Optional override default walltime (time.time()) of event\n\n        """"""\n        with self.lock:\n            if tag in self.scalar_tag_to_step:\n                self.scalar_tag_to_step[tag] += 1\n            else:\n                self.scalar_tag_to_step[tag] = 0\n\n            self.smw.add_scalar(tag, scalar_value, self.scalar_tag_to_step[tag], walltime)\n\n    # def add_histogram(self, tag, values, bins=\'tensorflow\', walltime=None, max_bins=None):\n    #     """"""Add histogram to summary.\n\n    #     Args:\n    #         tag (string): Data identifier\n    #         values (torch.Tensor, numpy.array): Values to build histogram\n    #         bins (string): One of {\'tensorflow\',\'auto\', \'fd\', ...}.\n    #           This determines how the bins are made. You can find\n    #           other options in: https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html\n    #         walltime (float): Optional override default walltime (time.time()) of event\n\n    #     """"""\n    #     with self.new_tag_mutex.get_lock():\n    #         if tag in self.histogram_tag_to_step:\n    #             self.histogram_tag_to_step[tag] += 1\n    #         else:\n    #             self.histogram_tag_to_step[tag] = 0\n    #         self.smw.add_histogram(tag,\n    #                                values,\n    #                                self.histogram_tag_to_step[tag],\n    #                                bins=bins,\n    #                                walltime=walltime,\n    #                                max_bins=max_bins)\n\n    def add_image(self, tag, img_tensor, walltime=None, dataformats=\'CHW\'):\n        """"""Add image data to summary.\n\n        Note that this requires the ``pillow`` package.\n\n        Args:\n            tag (string): Data identifier\n            img_tensor (torch.Tensor, numpy.array): An `uint8` or `float`\n                Tensor of shape `[channel, height, width]` where `channel` is 1, 3, or 4.\n                The elements in img_tensor can either have values in [0, 1] (float32) or [0, 255] (uint8).\n                Users are responsible to scale the data in the correct range/type.\n            walltime (float): Optional override default walltime (time.time()) of event.\n            dataformats (string): This parameter specifies the meaning of each dimension of the input tensor.\n        Shape:\n            img_tensor: Default is :math:`(3, H, W)`. You can use ``torchvision.utils.make_grid()`` to\n            convert a batch of tensor into 3xHxW format or use ``add_images()`` and let us do the job.\n            Tensor with :math:`(1, H, W)`, :math:`(H, W)`, :math:`(H, W, 3)` is also suitible as long as\n            corresponding ``dataformats`` argument is passed. e.g. CHW, HWC, HW.\n        """"""\n        with self.lock:\n            if tag in self.image_tag_to_step:\n                self.image_tag_to_step[tag] += 1\n            else:\n                self.image_tag_to_step[tag] = 0\n\n            self.smw.add_image(tag, img_tensor, self.image_tag_to_step[tag], walltime=walltime, dataformats=dataformats)\n\n    # def add_audio(self, tag, snd_tensor, sample_rate=44100, walltime=None):\n    #     """"""Add audio data to summary.\n\n    #     Args:\n    #         tag (string): Data identifier\n    #         snd_tensor (torch.Tensor): Sound data\n    #         sample_rate (int): sample rate in Hz\n    #         walltime (float): Optional override default walltime (time.time()) of event\n    #     Shape:\n    #         snd_tensor: :math:`(1, L)`. The values should lie between [-1, 1].\n    #     """"""\n\n    #     with self.new_tag_mutex.get_lock():\n    #         if tag in self.audio_tag_to_step:\n    #             self.audio_tag_to_step[tag] += 1\n    #         else:\n    #             self.audio_tag_to_step[tag] = 0\n\n    #         self.smw.add_audio(tag, snd_tensor, self.audio_tag_to_step[tag], sample_rate=44100, walltime=walltime)\n\n    def add_text(self, tag, text_string, walltime=None):\n        """"""Add text data to summary.\n\n        Args:\n            tag (string): Data identifier\n            text_string (string): String to save\n            walltime (float): Optional override default walltime (time.time()) of event\n\n        """"""\n        with self.lock:\n            if tag in self.text_tag_to_step:\n                self.text_tag_to_step[tag] += 1\n            else:\n                self.text_tag_to_step[tag] = 0\n\n            self.smw.add_text(tag, text_string, global_step=self.text_tag_to_step[tag], walltime=walltime)\n\n    @staticmethod\n    def getSummaryWriter():\n        """"""Get the writer from global namespace.\n\n        Examples::\n\n            # main.py\n            import global_1\n            import global_2\n\n            # global1.py\n            from tensorboardX import GlobalSummaryWriter\n            writer = GlobalSummaryWriter.getSummaryWriter()  # This creates a new instance.\n            writer.add_text(\'my_log\', \'greeting from global1\')\n\n            # global2.py\n            from tensorboardX import GlobalSummaryWriter\n            writer = GlobalSummaryWriter.getSummaryWriter()  # Get the instance in global1.py.\n            writer.add_text(\'my_log\', \'greeting from global2\')\n\n        """"""\n        global _writer\n        if not hasattr(_writer, ""smw"") or _writer.smw is None:\n            _writer = GlobalSummaryWriter()\n\n        print(""Using the global logger in:"", _writer.smw.file_writer.get_logdir())\n        return _writer\n\n    @property\n    def file_writer(self):\n        return self.smw._get_file_writer()\n\n    def close(self):\n        self.smw.flush()\n        self.smw.close()\n'"
tensorboardX/onnx_graph.py,0,"b""from .proto.graph_pb2 import GraphDef\nfrom .proto.node_def_pb2 import NodeDef\nfrom .proto.versions_pb2 import VersionDef\nfrom .proto.attr_value_pb2 import AttrValue\nfrom .proto.tensor_shape_pb2 import TensorShapeProto\n\n\ndef load_onnx_graph(fname):\n    import onnx\n    m = onnx.load(fname)\n    g = m.graph\n    return parse(g)\n\n\ndef parse(graph):\n    nodes_proto = []\n    nodes = []\n    import itertools\n    for node in itertools.chain(graph.input, graph.output):\n        nodes_proto.append(node)\n\n    for node in nodes_proto:\n        print(node.name)\n        shapeproto = TensorShapeProto(\n            dim=[TensorShapeProto.Dim(size=d.dim_value) for d in node.type.tensor_type.shape.dim])\n        nodes.append(NodeDef(\n            name=node.name.encode(encoding='utf_8'),\n            op='Variable',\n            input=[],\n            attr={\n                'dtype': AttrValue(type=node.type.tensor_type.elem_type),\n                'shape': AttrValue(shape=shapeproto),\n            })\n        )\n\n    for node in graph.node:\n        attr = []\n        for s in node.attribute:\n            attr.append(' = '.join([str(f[1]) for f in s.ListFields()]))\n        attr = ', '.join(attr).encode(encoding='utf_8')\n        print(node.output[0])\n        nodes.append(NodeDef(\n            name=node.output[0].encode(encoding='utf_8'),\n            op=node.op_type,\n            input=node.input,\n            attr={'parameters': AttrValue(s=attr)},\n        ))\n\n    # two pass token replacement, appends opname to object id\n    mapping = {}\n    for node in nodes:\n        mapping[node.name] = node.op + '_' + node.name\n\n    return GraphDef(node=nodes, versions=VersionDef(producer=22))\n"""
tensorboardX/openvino_graph.py,0,"b""from .proto.graph_pb2 import GraphDef\nfrom .proto.node_def_pb2 import NodeDef\nfrom .proto.versions_pb2 import VersionDef\nfrom .proto.attr_value_pb2 import AttrValue\nfrom .proto.tensor_shape_pb2 import TensorShapeProto\n\n\ndef load_openvino_graph(fname):\n    nodes = []\n\n    import xml.etree.ElementTree as ET\n    tree = ET.parse(fname)\n    root = tree.getroot()\n    layers = root.find('layers')\n    edges = root.find('edges')\n    layers_dict = {}\n    for layer in layers:\n        nodeid = layer.attrib['id']\n        name = layer.attrib['name']\n        layers_dict[nodeid] = name\n    for edge in edges:\n        nodeinput = edge.attrib['from-layer']\n        nodeself = edge.attrib['to-layer']\n        attr = []\n        # for s in node.attribute:\n        #     attr.append(' = '.join([str(f[1]) for f in s.ListFields()]))\n        attr = ', '.join(attr).encode(encoding='utf_8')\n        nodes.append(NodeDef(\n            name=layers_dict[nodeself],\n            op='op',\n            input=[str(layers_dict[nodeinput])],\n            attr={'parameters': AttrValue(s=attr)},\n        ))\n    return GraphDef(node=nodes, versions=VersionDef(producer=22))\n"""
tensorboardX/proto_graph.py,0,"b'from .proto.graph_pb2 import GraphDef\nfrom .proto.node_def_pb2 import NodeDef\nfrom .proto.versions_pb2 import VersionDef\nfrom .proto.attr_value_pb2 import AttrValue\nfrom .proto.tensor_shape_pb2 import TensorShapeProto\n\n\ndef attr_value_proto(dtype, shape, s):\n    """"""Creates a dict of objects matching\n    https://github.com/tensorflow/tensorboard/blob/master/tensorboard/compat/proto/attr_value.proto\n    specifically designed for a NodeDef. The values have been\n    reverse engineered from standard TensorBoard logged data.\n    """"""\n    attr = {}\n    if s is not None:\n        attr[\'attr\'] = AttrValue(s=s.encode(encoding=\'utf_8\'))\n    if shape is not None:\n        shapeproto = tensor_shape_proto(shape)\n        attr[\'_output_shapes\'] = AttrValue(list=AttrValue.ListValue(shape=[shapeproto]))\n    return attr\n\n\ndef tensor_shape_proto(outputsize):\n    """"""Creates an object matching\n    https://github.com/tensorflow/tensorboard/blob/master/tensorboard/compat/proto/tensor_shape.proto\n    """"""\n    return TensorShapeProto(dim=[TensorShapeProto.Dim(size=d) for d in outputsize])\n\n\ndef node_proto(name,\n               op=\'UnSpecified\',\n               input=None,\n               dtype=None,\n               shape=None,  # type: tuple\n               outputsize=None,\n               attributes=\'\'\n               ):\n    """"""Creates an object matching\n    https://github.com/tensorflow/tensorboard/blob/master/tensorboard/compat/proto/node_def.proto\n    """"""\n    if input is None:\n        input = []\n    if not isinstance(input, list):\n        input = [input]\n    return NodeDef(\n        name=name.encode(encoding=\'utf_8\'),\n        op=op,\n        input=input,\n        attr=attr_value_proto(dtype, outputsize, attributes)\n    )\n'"
tensorboardX/pytorch_graph.py,10,"b'import logging\nimport time\nfrom collections import OrderedDict\nfrom .proto.attr_value_pb2 import AttrValue\nfrom .proto.graph_pb2 import GraphDef\nfrom .proto.node_def_pb2 import NodeDef\nfrom .proto.step_stats_pb2 import RunMetadata, StepStats, DeviceStepStats, NodeExecStats, AllocatorMemoryUsed\nfrom .proto.tensor_shape_pb2 import TensorShapeProto\nfrom .proto.versions_pb2 import VersionDef\nfrom .proto_graph import node_proto\n\nmethods_OP = [\'attributeNames\', \'hasMultipleOutputs\', \'hasUses\', \'inputs\',\n              \'kind\', \'outputs\', \'outputsSize\', \'scopeName\']\nmethods_IO = []\n\nGETATTR_KIND = \'prim::GetAttr\'\nCLASSTYPE_KIND = \'ClassType\'\nCONST_KIND = \'prim::Constant\'\n\n\nclass NodeBase(object):\n    def __init__(self,\n                 debugName=None,\n                 inputs=None,\n                 scope=None,\n                 tensor_size=None,\n                 op_type=\'UnSpecified\',\n                 attributes=\'\'):\n        self.debugName = debugName\n        self.inputs = inputs\n        self.tensor_size = tensor_size\n        self.kind = op_type\n        self.attributes = attributes\n        if scope is not None:\n            self.scope = scope\n\n    def __repr__(self):\n        repr = []\n        repr.append(str(type(self)))\n        for m in dir(self):\n            if \'__\' not in m:\n                repr.append(m + \': \' + str(getattr(self, m)) + str(type(getattr(self, m))))\n        return \'\\n\'.join(repr) + \'\\n\\n\'\n\n\nclass NodePy(NodeBase):\n    def __init__(self, node_cpp, valid_methods):\n        super(NodePy, self).__init__(node_cpp)\n        valid_methods = valid_methods[:]\n        self.inputs = []\n        for m in valid_methods:\n            if m == \'inputs\' or m == \'outputs\':\n                list_of_node = list(getattr(node_cpp, m)())\n                io_unique_names = []\n                io_tensor_sizes = []\n                for n in list_of_node:\n                    io_unique_names.append(n.debugName())\n\n                    if n.isCompleteTensor():\n                        io_tensor_sizes.append(n.type().sizes())\n                    else:\n                        io_tensor_sizes.append(None)\n\n                setattr(self, m, io_unique_names)\n                setattr(self, m + \'tensor_size\', io_tensor_sizes)\n\n            else:\n                setattr(self, m, getattr(node_cpp, m)())\n\n\nclass NodePyIO(NodePy):\n    def __init__(self, node_cpp, input_or_output=None, debugName=\'\', tensor_size=[]):\n        super(NodePyIO, self).__init__(node_cpp, methods_IO)\n        self.tensor_size = tensor_size\n        # Kind attribute string is purely descriptive and will be shown\n        # in detailed information for the node in TensorBoard\'s graph plugin.\n        #\n        # NodePyOP nodes get this from their kind() method.\n        self.debugName = debugName\n        self.kind = \'Parameter\'\n        if input_or_output:\n            self.input_or_output = input_or_output\n            self.kind = \'IO Node\'\n\n\nclass NodePyOP(NodePy):\n    def __init__(self, node_cpp):\n        super(NodePyOP, self).__init__(node_cpp, methods_OP)\n        # Replace single quote which causes strange behavior in TensorBoard\n        # TODO: See if we can remove this in the future\n        self.attributes = str({k: node_cpp[k] for k in node_cpp.attributeNames()}).replace(""\'"", \' \')\n        self.kind = node_cpp.kind()\n\n\nclass GraphPy(object):\n    """"""Helper class to convert torch.nn.Module to GraphDef proto and visualization\n    with TensorBoard.\n\n    GraphDef generation operates in two passes:\n\n    In the first pass, all nodes are read and saved to two lists.\n    One list is for input/output nodes (nodes_io), which only have inbound\n    or outbound connections, but not both. Another list is for internal\n    operator nodes (nodes_op). The first pass also saves all scope name\n    appeared in the nodes in scope_name_appeared list for later processing.\n\n    In the second pass, scope names are fully applied to all nodes.\n    debugNameToScopedName is a mapping from a node\'s ID to its fully qualified\n    scope name. e.g. Net1/Linear[0]/1. Unfortunately torch.jit doesn\'t have\n    totally correct scope output, so this is nontrivial. The function\n    populate_namespace_from_OP_to_IO and find_common_root are used to\n    assign scope name to a node based on the connection between nodes\n    in a heuristic kind of way. Bookkeeping is done with shallowest_scope_name\n    and scope_name_appeared.\n    """"""\n    def __init__(self):\n        self.nodes_op = []\n        self.nodes_io = OrderedDict()\n        self.unique_name_to_scoped_name = {}\n        self.shallowest_scope_name = \'default\'\n        self.scope_name_appeared = []\n        self.profile_result = None\n\n    def append(self, x):\n        if isinstance(x, NodePyIO):\n            self.nodes_io[x.debugName] = x\n        if isinstance(x, NodePyOP):\n            self.nodes_op.append(x)\n            for node_output, outputSize in zip(x.outputs, x.outputstensor_size):\n                self.scope_name_appeared.append(x.scopeName)\n                self.nodes_io[node_output] = NodeBase(node_output,\n                                                      x.inputs,\n                                                      x.scopeName,\n                                                      outputSize,\n                                                      op_type=x.kind,\n                                                      attributes=x.attributes)\n\n    def printall(self):\n        print(\'all nodes\')\n        for node in self.nodes_op:\n            print(node)\n        for key in self.nodes_io:\n            print(self.nodes_io[key])\n\n    def find_common_root(self):\n        """"""\n        Find the shallowest scope name among the appeared nodes.\n        """"""\n        for fullscope in self.scope_name_appeared:\n            if fullscope:\n                self.shallowest_scope_name = fullscope.split(\'/\')[0]\n\n    def populate_namespace_from_OP_to_IO(self):\n        for node in self.nodes_op:\n            for node_output, outputSize in zip(node.outputs, node.outputstensor_size):\n                self.scope_name_appeared.append(node.scopeName)\n                self.nodes_io[node_output] = NodeBase(node_output,\n                                                      node.inputs,\n                                                      node.scopeName,\n                                                      outputSize,\n                                                      op_type=node.kind,\n                                                      attributes=node.attributes)\n\n        self.find_common_root()\n\n        for node in self.nodes_op:\n            for input_node_id in node.inputs:\n                self.unique_name_to_scoped_name[input_node_id] = node.scopeName + \'/\' + input_node_id\n\n        for key, node in self.nodes_io.items():\n            if type(node) == NodeBase:\n                self.unique_name_to_scoped_name[key] = node.scope + \'/\' + node.debugName\n            if hasattr(node, \'input_or_output\'):\n                self.unique_name_to_scoped_name[key] = node.input_or_output + \'/\' + node.debugName\n            if hasattr(node, \'scope\') and node.scope is not None:\n                self.unique_name_to_scoped_name[key] = node.scope + \'/\' + node.debugName\n                if node.scope == \'\' and self.shallowest_scope_name:\n                    self.unique_name_to_scoped_name[node.debugName] = \\\n                        self.shallowest_scope_name + \'/\' + node.debugName\n\n        # replace name\n        for key, node in self.nodes_io.items():\n            self.nodes_io[key].inputs = \\\n                [self.unique_name_to_scoped_name[node_input_id] for node_input_id in node.inputs]\n            if node.debugName in self.unique_name_to_scoped_name:\n                self.nodes_io[key].debugName = self.unique_name_to_scoped_name[node.debugName]\n\n    def to_proto(self):\n        """"""\n        Converts graph representation of GraphPy object to TensorBoard\n        required format.\n        """"""\n        # TODO: compute correct memory usage and CPU time once\n        # PyTorch supports it\n        import numpy as np\n        nodes = []\n        node_stats = []\n\n        if self.profile_result is not None:\n            profile_result = self.profile_result.function_events\n\n        _time_used_for_op = {}\n\n        # We assume that the model is executed sequentially. So get the timing from\n        # the first matched item. If it is matched, remove that item with `pop()`\n        def find_time_for(node_name):\n            for i, n in enumerate(profile_result):\n                if n.key == node_name:\n                    profile_result.pop(i)\n                    time_we_want_cpu = n.cpu_time_total\n                    time_we_want_cuda = n.cuda_time_total\n\n                    return int(time_we_want_cpu), int(time_we_want_cuda)\n            return None, None\n\n        should_show_warning = False\n        for v in self.nodes_io.values():\n            nodes.append(node_proto(v.debugName,\n                                    input=v.inputs,\n                                    outputsize=v.tensor_size,\n                                    op=v.kind,\n                                    attributes=v.attributes))\n\n            # For timing information, we are only interested in aten operators now.\n            # prim:: and Parameter\n            if \'aten\' in v.kind and self.profile_result is not None:\n                opname = v.kind.split(\'::\')[1]\n                exe_time_cpu, exe_time_cuda = find_time_for(opname)\n                if exe_time_cpu is not None:\n                    total_time = exe_time_cpu + exe_time_cuda\n\n                    # assume that the operation will not executed on both device simultaneously.\n                    if total_time - max(exe_time_cpu, exe_time_cuda) > 0.01:\n                        should_show_warning = True\n\n                    node_stats.append(\n                        NodeExecStats(node_name=v.debugName,\n                                      all_start_micros=int(time.time() * 1e7),\n                                      all_end_rel_micros=total_time))\n\n            if v.tensor_size and len(v.tensor_size) > 0:  # assume data is float32, only parameter is counted\n                node_stats.append(\n                    NodeExecStats(node_name=v.debugName,\n                                  all_start_micros=int(time.time() * 1e7),\n                                  all_end_rel_micros=42,\n                                  memory=[AllocatorMemoryUsed(allocator_name=""unknown"",\n                                                              total_bytes=int(np.prod(v.tensor_size)) * 4)]))\n        if should_show_warning:\n            logging.warning(\'time cost for node is the sum of CPU + GPU.\')\n\n        return nodes, node_stats\n\n\n# one argument: \'hasAttribute\', \'hasAttributes\',\ndef parse(graph, trace, args=None, profile_result=None):\n    """"""This method parses an optimized PyTorch model graph and produces\n    a list of nodes and node stats for eventual conversion to TensorBoard\n    protobuf format.\n\n    Args:\n      graph (PyTorch module): The model graph to be parsed.\n      trace (PyTorch JIT TracedModule): The model trace to be parsed.\n      args (tuple): input tensor[s] for the model.\n    """"""\n    import torch\n    n_inputs = len(args)  # not sure...\n\n    inputnodes = list(graph.inputs())\n\n    nodes_py = GraphPy()\n    nodes_py.profile_result = profile_result\n\n    for node in graph.inputs():\n        if node.type().kind() == CLASSTYPE_KIND:\n            continue\n        try:\n            tensor_size = node.type().sizes()\n        except RuntimeError:\n            # INTERNAL ASSERT FAILED at ../aten/src/ATen/core/jit_type.h:131, please report a bug to PyTorch.\n            tensor_size = []\n        nodes_py.append(NodePyIO(node, input_or_output=\'Input\', debugName=node.debugName(), tensor_size=tensor_size))\n    attr_to_scope = dict()\n    for node in graph.nodes():\n        # These nodes refers to parameters such as kernel size, stride, etc.\n        # The graph will be very tedious if we include all of them. So skip.\n        # p.s. Those Constant will be composed by \'prim::listConstruct\' and then\n        # send to common OPs such as Maxpool, Conv, Linear.\n        # We can let user pass verbosity value to dicide how detailed the graph is.\n        if node.kind() == CONST_KIND:\n            continue\n        if node.kind() == GETATTR_KIND:\n            attr_name = node.s(\'name\')\n            parent = node.input().node()\n            if parent.kind() == GETATTR_KIND:  # If the parent node is not the top-level ""self"" node\n                parent_attr_name = parent.s(\'name\')\n                parent_scope = attr_to_scope[parent_attr_name]\n                attr_scope = parent_scope.split(\'/\')[-1]\n                attr_to_scope[attr_name] = \'{}/{}.{}\'.format(parent_scope, attr_scope, attr_name)\n            else:\n                attr_to_scope[attr_name] = \'__module.{}\'.format(attr_name)\n            # We don\'t need classtype nodes; scope will provide this information\n            if node.output().type().kind() == CLASSTYPE_KIND:\n                continue\n            node_py = NodePyOP(node)\n            node_py.scopeName = attr_to_scope[attr_name]\n            nodes_py.append(node_py)\n        else:\n            nodes_py.append(NodePyOP(node))\n    for i, node in enumerate(graph.outputs()):  # Create sink nodes for output ops\n        if node.isCompleteTensor():\n            node_py = NodePyIO(node, \'output\')\n            node_py.debugName = ""output.{}.alias"".format(node.debugName())\n            node_py.inputs = [node.debugName()]\n            nodes_py.append(node_py)\n        else:  # tuple output (prim::TupleConstruct)\n            graph_outputs = list(node.node().inputs())\n            for go in graph_outputs:\n                node_py = NodePyIO(go, \'output\')\n                node_py.debugName = ""output.{}.alias"".format(go.debugName())\n                node_py.inputs = [go.debugName()]\n                nodes_py.append(node_py)\n\n    def parse_traced_name(module):\n        if isinstance(module, torch.jit.TracedModule):\n            module_name = module._name\n        else:\n            module_name = getattr(module, \'original_name\', ""Module"")\n        return module_name\n\n    alias_to_name = dict()\n    base_name = parse_traced_name(trace)\n    for name, module in trace.named_modules(prefix=\'__module\'):\n        mod_name = parse_traced_name(module)\n        attr_name = name.split(\'.\')[-1]\n        alias_to_name[name] = \'{}[{}]\'.format(mod_name, attr_name)\n    for node in nodes_py.nodes_op:\n        module_aliases = node.scopeName.split(\'/\')\n        replacements = [\n            alias_to_name[alias]\n            if alias in alias_to_name\n            else alias.split(\'.\')[-1]\n            for alias in module_aliases\n        ]\n        node.scopeName = base_name\n        if any(replacements):\n            node.scopeName += \'/\' + \'/\'.join(replacements)\n\n    nodes_py.populate_namespace_from_OP_to_IO()\n    return nodes_py.to_proto()\n\n\ndef recursive_to_cuda(x):\n    """"""\n    Recursively convert tensors in a tuple or list to GPU tensor.\n    """"""\n    import torch\n\n    if isinstance(x, torch.Tensor):\n        return x.cuda()\n    else:\n        return [recursive_to_cuda(_x) for _x in x]\n\n\ndef graph(model, args, verbose=False, use_cuda=False, **kwargs):\n    """"""\n    This method processes a PyTorch model and produces a `GraphDef` proto\n    that can be logged to TensorBoard.\n\n    Args:\n      model (PyTorch module): The model to be parsed.\n      args (tuple): input tensor[s] for the model.\n      verbose (bool): Whether to print out verbose information while\n        processing.\n    """"""\n    import torch\n    from packaging import version\n    assert version.parse(torch.__version__) >= version.parse(""1.4.0""), ""add_graph needs torch>=1.4.0""\n\n    with torch.onnx.set_training(model, False):  # TODO: move outside of torch.onnx\n        try:\n            trace = torch.jit.trace(model, args)\n            if type(trace) == torch.jit.ScriptModule:\n                graph = trace.forward_impl.graph\n            else:\n                graph = trace.graph\n            torch._C._jit_pass_inline(graph)\n        except RuntimeError as e:\n            print(e)\n            print(\'Error occurs, No graph saved\')\n            raise e\n            # Create an object matching\n            # https://github.com/tensorflow/tensorboard/blob/master/tensorboard/compat/proto/graph.proto\n            # The producer version has been reverse engineered from standard\n            # TensorBoard logged data.\n\n        try:\n            if use_cuda:\n                model.cuda()\n                args = recursive_to_cuda(args)\n            with torch.autograd.profiler.profile(record_shapes=True, use_cuda=use_cuda) as prof:\n                result = model(*args)\n\n        except RuntimeError as e:\n            print(\'profiler execution failed\')\n            prof = None\n\n    if verbose:\n        print(graph)\n    list_of_nodes, node_stats = parse(graph, trace, args, prof)\n    # We are hardcoding that this was run on CPU even though it might have actually\n    # run on GPU. Note this is what is shown in TensorBoard and has no bearing\n    # on actual execution.\n    # TODO: See if we can extract GPU vs CPU information from the PyTorch model\n    # and pass it correctly to TensorBoard.\n    #\n    # Definition of StepStats and DeviceStepStats can be found at\n    # https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/graph/tf_graph_common/test/graph-test.ts\n    # and\n    # https://github.com/tensorflow/tensorboard/blob/master/tensorboard/compat/proto/step_stats.proto\n\n    if use_cuda:\n        device = ""/device:GPU:0""\n    else:\n        device = ""/device:CPU:0""\n    stepstats = RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device=device,\n                                                                            node_stats=node_stats)]))\n    return GraphDef(node=list_of_nodes, versions=VersionDef(producer=22)), stepstats\n'"
tensorboardX/record_writer.py,0,"b'""""""\nTo write tf_record into file. Here we use it for tensorboard\'s event writting.\nThe code was borrowed from https://github.com/TeamHG-Memex/tensorboard_logger\n""""""\n\nimport os\nimport copy\nimport io\nimport os.path\nimport re\nimport struct\ntry:\n    import boto3\n    S3_ENABLED = True\nexcept ImportError:\n    S3_ENABLED = False\ntry:\n    from google.cloud import storage\n    GCS_ENABLED = True\nexcept ImportError:\n    GCS_ENABLED = False\n\nfrom .crc32c import crc32c\n\n\n_VALID_OP_NAME_START = re.compile(\'^[A-Za-z0-9.]\')\n_VALID_OP_NAME_PART = re.compile(\'[A-Za-z0-9_.\\\\-/]+\')\n\n# Registry of writer factories by prefix backends.\n#\n# Currently supports ""s3://"" URLs for S3 based on boto,\n# ""gs://"" URLs for Google Cloud Storage and falls\n# back to local filesystem.\nREGISTERED_FACTORIES = {}\n\n\ndef register_writer_factory(prefix, factory):\n    if \':\' in prefix:\n        raise ValueError(\'prefix cannot contain a :\')\n    REGISTERED_FACTORIES[prefix] = factory\n\n\ndef directory_check(path):\n    \'\'\'Initialize the directory for log files.\'\'\'\n    try:\n        prefix = path.split(\':\')[0]\n        factory = REGISTERED_FACTORIES[prefix]\n        return factory.directory_check(path)\n    except KeyError:\n        if not os.path.exists(path):\n            os.makedirs(path)\n\n\ndef open_file(path):\n    \'\'\'Open a writer for outputting event files.\'\'\'\n    try:\n        prefix = path.split(\':\')[0]\n        factory = REGISTERED_FACTORIES[prefix]\n        return factory.open(path)\n    except KeyError:\n        return open(path, \'wb\')\n\n\nclass S3RecordWriter(object):\n    """"""Writes tensorboard protocol buffer files to S3.""""""\n\n    def __init__(self, path):\n        if not S3_ENABLED:\n            raise ImportError(""boto3 must be installed for S3 support."")\n        self.path = path\n        self.buffer = io.BytesIO()\n\n    def __del__(self):\n        self.close()\n\n    def bucket_and_path(self):\n        path = self.path\n        if path.startswith(""s3://""):\n            path = path[len(""s3://""):]\n        bp = path.split(""/"")\n        bucket = bp[0]\n        path = path[1 + len(bucket):]\n        return bucket, path\n\n    def write(self, val):\n        self.buffer.write(val)\n\n    def flush(self):\n        s3 = boto3.client(\'s3\', endpoint_url=os.environ.get(\'S3_ENDPOINT\'))\n        bucket, path = self.bucket_and_path()\n        upload_buffer = copy.copy(self.buffer)\n        upload_buffer.seek(0)\n        s3.upload_fileobj(upload_buffer, bucket, path)\n\n    def close(self):\n        self.flush()\n\n\nclass S3RecordWriterFactory(object):\n    """"""Factory for event protocol buffer files to S3.""""""\n\n    def open(self, path):\n        return S3RecordWriter(path)\n\n    def directory_check(self, path):\n        # S3 doesn\'t need directories created before files are added\n        # so we can just skip this check\n        pass\n\n\nregister_writer_factory(""s3"", S3RecordWriterFactory())\n\n\nclass GCSRecordWriter(object):\n    """"""Writes tensorboard protocol buffer files to Google Cloud Storage.""""""\n\n    def __init__(self, path):\n        if not GCS_ENABLED:\n            raise ImportError(""`google-cloud-storage` must be installed in order to use ""\n                              ""the \'gs://\' protocol"")\n\n        self.path = path\n        self.buffer = io.BytesIO()\n\n        client = storage.Client()\n        bucket_name, filepath = self.bucket_and_path()\n        bucket = storage.Bucket(client, bucket_name)\n        self.blob = storage.Blob(filepath, bucket)\n\n    def __del__(self):\n        self.close()\n\n    def bucket_and_path(self):\n        path = self.path\n        if path.startswith(""gs://""):\n            path = path[len(""gs://""):]\n        bp = path.split(""/"")\n        bucket = bp[0]\n        path = path[1 + len(bucket):]\n        return bucket, path\n\n    def write(self, val):\n        self.buffer.write(val)\n\n    def flush(self):\n        upload_buffer = copy.copy(self.buffer)\n        upload_buffer.seek(0)\n\n        self.blob.upload_from_string(upload_buffer.getvalue())\n\n    def close(self):\n        self.flush()\n\n\nclass GCSRecordWriterFactory(object):\n    """"""Factory for event protocol buffer files to Google Cloud Storage.""""""\n\n    def open(self, path):\n        return GCSRecordWriter(path)\n\n    def directory_check(self, path):\n        # Google Cloud Storage doesn\'t need directories created before files\n        # are added so we can just skip this check\n        pass\n\n\nregister_writer_factory(""gs"", GCSRecordWriterFactory())\n\n\nclass RecordWriter(object):\n    def __init__(self, path):\n        self._name_to_tf_name = {}\n        self._tf_names = set()\n        self.path = path\n        self._writer = None\n        self._writer = open_file(path)\n\n    def write(self, data):\n        w = self._writer.write\n        header = struct.pack(\'Q\', len(data))\n        w(header)\n        w(struct.pack(\'I\', masked_crc32c(header)))\n        w(data)\n        w(struct.pack(\'I\', masked_crc32c(data)))\n\n    def flush(self):\n        self._writer.flush()\n\n    def close(self):\n        self._writer.close()\n\n\ndef masked_crc32c(data):\n    x = u32(crc32c(data))\n    return u32(((x >> 15) | u32(x << 17)) + 0xa282ead8)\n\n\ndef u32(x):\n    return x & 0xffffffff\n\n\ndef make_valid_tf_name(name):\n    if not _VALID_OP_NAME_START.match(name):\n        # Must make it valid somehow, but don\'t want to remove stuff\n        name = \'.\' + name\n    return \'_\'.join(_VALID_OP_NAME_PART.findall(name))\n'"
tensorboardX/summary.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport logging\nimport numpy as np\nimport os\nimport re as _re\n\n# pylint: disable=unused-import\nfrom six.moves import range\n\nfrom .proto.summary_pb2 import Summary\nfrom .proto.summary_pb2 import HistogramProto\nfrom .proto.summary_pb2 import SummaryMetadata\nfrom .proto.tensor_pb2 import TensorProto\nfrom .proto.tensor_shape_pb2 import TensorShapeProto\nfrom .proto.plugin_pr_curve_pb2 import PrCurvePluginData\nfrom .proto.plugin_text_pb2 import TextPluginData\nfrom .proto.plugin_mesh_pb2 import MeshPluginData\nfrom .proto import layout_pb2\nfrom .x2num import make_np\nfrom .utils import _prepare_video, convert_to_HWC\n\n_INVALID_TAG_CHARACTERS = _re.compile(r\'[^-/\\w\\.]\')\n\n\ndef _clean_tag(name):\n    # In the past, the first argument to summary ops was a tag, which allowed\n    # arbitrary characters. Now we are changing the first argument to be the node\n    # name. This has a number of advantages (users of summary ops now can\n    # take advantage of the tf name scope system) but risks breaking existing\n    # usage, because a much smaller set of characters are allowed in node names.\n    # This function replaces all illegal characters with _s, and logs a warning.\n    # It also strips leading slashes from the name.\n    if name is not None:\n        new_name = _INVALID_TAG_CHARACTERS.sub(\'_\', name)\n        new_name = new_name.lstrip(\'/\')  # Remove leading slashes\n        if new_name != name:\n            logging.info(\n                \'Summary name %s is illegal; using %s instead.\' % (name, new_name))\n            name = new_name\n    return name\n\n\ndef _draw_single_box(image, xmin, ymin, xmax, ymax, display_str, color=\'black\', color_text=\'black\', thickness=2):\n    from PIL import ImageDraw, ImageFont\n    font = ImageFont.load_default()\n    draw = ImageDraw.Draw(image)\n    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n    draw.line([(left, top), (left, bottom), (right, bottom),\n               (right, top), (left, top)], width=thickness, fill=color)\n    if display_str:\n        text_bottom = bottom\n        # Reverse list and print from bottom to top.\n        text_width, text_height = font.getsize(display_str)\n        margin = np.ceil(0.05 * text_height)\n        draw.rectangle(\n            [(left, text_bottom - text_height - 2 * margin),\n             (left + text_width, text_bottom)], fill=color\n        )\n        draw.text(\n            (left + margin, text_bottom - text_height - margin),\n            display_str, fill=color_text, font=font\n        )\n    return image\n\n\ndef hparams(hparam_dict=None, metric_dict=None):\n    from tensorboardX.proto.plugin_hparams_pb2 import HParamsPluginData, SessionEndInfo, SessionStartInfo\n    from tensorboardX.proto.api_pb2 import Experiment, HParamInfo, MetricInfo, MetricName, Status, DataType\n    from six import string_types\n\n    PLUGIN_NAME = \'hparams\'\n    PLUGIN_DATA_VERSION = 0\n\n    EXPERIMENT_TAG = \'_hparams_/experiment\'\n    SESSION_START_INFO_TAG = \'_hparams_/session_start_info\'\n    SESSION_END_INFO_TAG = \'_hparams_/session_end_info\'\n\n    # TODO: expose other parameters in the future.\n    # hp = HParamInfo(name=\'lr\',display_name=\'learning rate\', type=DataType.DATA_TYPE_FLOAT64, domain_interval=Interval(min_value=10, max_value=100))  # noqa E501\n    # mt = MetricInfo(name=MetricName(tag=\'accuracy\'), display_name=\'accuracy\', description=\'\', dataset_type=DatasetType.DATASET_VALIDATION)  # noqa E501\n    # exp = Experiment(name=\'123\', description=\'456\', time_created_secs=100.0, hparam_infos=[hp], metric_infos=[mt], user=\'tw\')  # noqa E501\n\n    hps = []\n\n    ssi = SessionStartInfo()\n    for k, v in hparam_dict.items():\n        if v is None:\n            continue\n\n        if isinstance(v, string_types):\n            ssi.hparams[k].string_value = v\n            hps.append(HParamInfo(name=k, type=DataType.Value(""DATA_TYPE_STRING"")))\n            continue\n\n        if isinstance(v, bool):\n            ssi.hparams[k].bool_value = v\n            hps.append(HParamInfo(name=k, type=DataType.Value(""DATA_TYPE_BOOL"")))\n            continue\n\n        if isinstance(v, int) or isinstance(v, float):\n            v = make_np(v)[0]\n            ssi.hparams[k].number_value = v\n            hps.append(HParamInfo(name=k, type=DataType.Value(""DATA_TYPE_FLOAT64"")))\n            continue\n\n        if callable(v):\n            ssi.hparams[k].string_value = getattr(v, \'__name__\', str(v))\n            hps.append(HParamInfo(name=k, type=DataType.Value(""DATA_TYPE_STRING"")))\n            continue\n\n        hps.append(HParamInfo(name=k, type=DataType.Value(""DATA_TYPE_UNSET"")))\n\n    content = HParamsPluginData(session_start_info=ssi, version=PLUGIN_DATA_VERSION)\n    smd = SummaryMetadata(plugin_data=SummaryMetadata.PluginData(plugin_name=PLUGIN_NAME,\n                                                                 content=content.SerializeToString()))\n    ssi = Summary(value=[Summary.Value(tag=SESSION_START_INFO_TAG, metadata=smd)])\n\n    mts = [MetricInfo(name=MetricName(tag=k)) for k in metric_dict.keys()]\n\n    exp = Experiment(hparam_infos=hps, metric_infos=mts)\n    content = HParamsPluginData(experiment=exp, version=PLUGIN_DATA_VERSION)\n    smd = SummaryMetadata(plugin_data=SummaryMetadata.PluginData(plugin_name=PLUGIN_NAME,\n                                                                 content=content.SerializeToString()))\n    exp = Summary(value=[Summary.Value(tag=EXPERIMENT_TAG, metadata=smd)])\n\n    sei = SessionEndInfo(status=Status.Value(""STATUS_SUCCESS""))\n    content = HParamsPluginData(session_end_info=sei, version=PLUGIN_DATA_VERSION)\n    smd = SummaryMetadata(plugin_data=SummaryMetadata.PluginData(plugin_name=PLUGIN_NAME,\n                                                                 content=content.SerializeToString()))\n    sei = Summary(value=[Summary.Value(tag=SESSION_END_INFO_TAG, metadata=smd)])\n    return exp, ssi, sei\n\n\ndef scalar(name, scalar, display_name="""", summary_description=""""):\n    """"""Outputs a `Summary` protocol buffer containing a single scalar value.\n    The generated Summary has a Tensor.proto containing the input Tensor.\n    Args:\n      name: A name for the generated node. Will also serve as the series name in\n        TensorBoard.\n      tensor: A real numeric Tensor containing a single value.\n      display_name: The title of the plot. If empty string is passed, `name` will be used.\n      summary_description: The comprehensive text that will showed by clicking the information icon on TensorBoard.\n    Returns:\n      A scalar `Tensor` of type `string`. Which contains a `Summary` protobuf.\n    Raises:\n      ValueError: If tensor has the wrong shape or type.\n    """"""\n    name = _clean_tag(name)\n    scalar = make_np(scalar)\n    assert(scalar.squeeze().ndim == 0), \'scalar should be 0D\'\n    scalar = float(scalar)\n    if display_name == """" and summary_description == """":\n        return Summary(value=[Summary.Value(tag=name, simple_value=scalar)])\n\n    metadata = SummaryMetadata(display_name=display_name, summary_description=summary_description)\n    return Summary(value=[Summary.Value(tag=name, simple_value=scalar, metadata=metadata)])\n\n\ndef histogram_raw(name, min, max, num, sum, sum_squares, bucket_limits, bucket_counts):\n    # pylint: disable=line-too-long\n    """"""Outputs a `Summary` protocol buffer with a histogram.\n    The generated\n    [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)\n    has one summary value containing a histogram for `values`.\n    Args:\n      name: A name for the generated node. Will also serve as a series name in\n        TensorBoard.\n      min: A float or int min value\n      max: A float or int max value\n      num: Int number of values\n      sum: Float or int sum of all values\n      sum_squares: Float or int sum of squares for all values\n      bucket_limits: A numeric `Tensor` with upper value per bucket\n      bucket_counts: A numeric `Tensor` with number of values per bucket\n    Returns:\n      A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n      buffer.\n    """"""\n    hist = HistogramProto(min=min,\n                          max=max,\n                          num=num,\n                          sum=sum,\n                          sum_squares=sum_squares,\n                          bucket_limit=bucket_limits,\n                          bucket=bucket_counts)\n    return Summary(value=[Summary.Value(tag=name, histo=hist)])\n\n\ndef histogram(name, values, bins, max_bins=None):\n    # pylint: disable=line-too-long\n    """"""Outputs a `Summary` protocol buffer with a histogram.\n    The generated\n    [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)\n    has one summary value containing a histogram for `values`.\n    This op reports an `InvalidArgument` error if any value is not finite.\n    Args:\n      name: A name for the generated node. Will also serve as a series name in\n        TensorBoard.\n      values: A real numeric `Tensor`. Any shape. Values to use to\n        build the histogram.\n    Returns:\n      A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n      buffer.\n    """"""\n    name = _clean_tag(name)\n    values = make_np(values)\n    hist = make_histogram(values.astype(float), bins, max_bins)\n    return Summary(value=[Summary.Value(tag=name, histo=hist)])\n\n\ndef make_histogram(values, bins, max_bins=None):\n    """"""Convert values into a histogram proto using logic from histogram.cc.""""""\n    if values.size == 0:\n        raise ValueError(\'The input has no element.\')\n    values = values.reshape(-1)\n    counts, limits = np.histogram(values, bins=bins)\n    num_bins = len(counts)\n    if max_bins is not None and num_bins > max_bins:\n        subsampling = num_bins // max_bins\n        subsampling_remainder = num_bins % subsampling\n        if subsampling_remainder != 0:\n            counts = np.pad(counts, pad_width=[[0, subsampling - subsampling_remainder]],\n                            mode=""constant"", constant_values=0)\n        counts = counts.reshape(-1, subsampling).sum(axis=-1)\n        new_limits = np.empty((counts.size + 1,), limits.dtype)\n        new_limits[:-1] = limits[:-1:subsampling]\n        new_limits[-1] = limits[-1]\n        limits = new_limits\n\n    # Find the first and the last bin defining the support of the histogram:\n    cum_counts = np.cumsum(np.greater(counts, 0, dtype=np.int32))\n    start, end = np.searchsorted(cum_counts, [0, cum_counts[-1] - 1], side=""right"")\n    start = int(start)\n    end = int(end) + 1\n    del cum_counts\n\n    # TensorBoard only includes the right bin limits. To still have the leftmost limit\n    # included, we include an empty bin left.\n    # If start == 0, we need to add an empty one left, otherwise we can just include the bin left to the\n    # first nonzero-count bin:\n    counts = counts[start - 1:end] if start > 0 else np.concatenate([[0], counts[:end]])\n    limits = limits[start:end + 1]\n\n    if counts.size == 0 or limits.size == 0:\n        raise ValueError(\'The histogram is empty, please file a bug report.\')\n\n    sum_sq = values.dot(values)\n    return HistogramProto(min=values.min(),\n                          max=values.max(),\n                          num=len(values),\n                          sum=values.sum(),\n                          sum_squares=sum_sq,\n                          bucket_limit=limits.tolist(),\n                          bucket=counts.tolist())\n\n\ndef image(tag, tensor, rescale=1, dataformats=\'CHW\'):\n    """"""Outputs a `Summary` protocol buffer with images.\n    The summary has up to `max_images` summary values containing images. The\n    images are built from `tensor` which must be 3-D with shape `[height, width,\n    channels]` and where `channels` can be:\n    *  1: `tensor` is interpreted as Grayscale.\n    *  3: `tensor` is interpreted as RGB.\n    *  4: `tensor` is interpreted as RGBA.\n\n    Args:\n      tag: A name for the generated node. Will also serve as a series name in\n        TensorBoard.\n      tensor: A 3-D `uint8` or `float32` `Tensor` of shape `[height, width,\n        channels]` where `channels` is 1, 3, or 4.\n        \'tensor\' can either have values in [0, 1] (float32) or [0, 255] (uint8).\n        The image() function will scale the image values to [0, 255] by applying\n        a scale factor of either 1 (uint8) or 255 (float32).\n    Returns:\n      A scalar `Tensor` of type `string`. The serialized `Summary` protocol\n      buffer.\n    """"""\n    tag = _clean_tag(tag)\n    tensor = make_np(tensor)\n    tensor = convert_to_HWC(tensor, dataformats)\n    # Do not assume that user passes in values in [0, 255], use data type to detect\n    if tensor.dtype != np.uint8:\n        tensor = (tensor * 255.0).astype(np.uint8)\n\n    image = make_image(tensor, rescale=rescale)\n    return Summary(value=[Summary.Value(tag=tag, image=image)])\n\n\ndef image_boxes(tag, tensor_image, tensor_boxes, rescale=1, dataformats=\'CHW\', labels=None):\n    \'\'\'Outputs a `Summary` protocol buffer with images.\'\'\'\n    tensor_image = make_np(tensor_image)\n    tensor_image = convert_to_HWC(tensor_image, dataformats)\n    tensor_boxes = make_np(tensor_boxes)\n\n    if tensor_image.dtype != np.uint8:\n        tensor_image = (tensor_image * 255.0).astype(np.uint8)\n\n    image = make_image(tensor_image,\n                       rescale=rescale,\n                       rois=tensor_boxes, labels=labels)\n    return Summary(value=[Summary.Value(tag=tag, image=image)])\n\n\ndef draw_boxes(disp_image, boxes, labels=None):\n    # xyxy format\n    num_boxes = boxes.shape[0]\n    list_gt = range(num_boxes)\n    for i in list_gt:\n        disp_image = _draw_single_box(disp_image,\n                                      boxes[i, 0],\n                                      boxes[i, 1],\n                                      boxes[i, 2],\n                                      boxes[i, 3],\n                                      display_str=None if labels is None else labels[i],\n                                      color=\'Red\')\n    return disp_image\n\n\ndef make_image(tensor, rescale=1, rois=None, labels=None):\n    """"""Convert an numpy representation image to Image protobuf""""""\n    from PIL import Image\n    height, width, channel = tensor.shape\n    scaled_height = int(height * rescale)\n    scaled_width = int(width * rescale)\n    image = Image.fromarray(tensor)\n    if rois is not None:\n        image = draw_boxes(image, rois, labels=labels)\n    image = image.resize((scaled_width, scaled_height), Image.ANTIALIAS)\n    import io\n    output = io.BytesIO()\n    image.save(output, format=\'PNG\')\n    image_string = output.getvalue()\n    output.close()\n    return Summary.Image(height=height,\n                         width=width,\n                         colorspace=channel,\n                         encoded_image_string=image_string)\n\n\ndef video(tag, tensor, fps=4):\n    tag = _clean_tag(tag)\n    tensor = make_np(tensor)\n    tensor = _prepare_video(tensor)\n    # If user passes in uint8, then we don\'t need to rescale by 255\n    if tensor.dtype != np.uint8:\n        tensor = (tensor * 255.0).astype(np.uint8)\n\n    video = make_video(tensor, fps)\n    return Summary(value=[Summary.Value(tag=tag, image=video)])\n\n\ndef make_video(tensor, fps):\n    try:\n        import moviepy  # noqa: F401\n    except ImportError:\n        print(\'add_video needs package moviepy\')\n        return\n    try:\n        from moviepy import editor as mpy\n    except ImportError:\n        print(""moviepy is installed, but can\'t import moviepy.editor."",\n              ""Some packages could be missing [imageio, requests]"")\n        return\n    import tempfile\n\n    t, h, w, c = tensor.shape\n\n    # encode sequence of images into gif string\n    clip = mpy.ImageSequenceClip(list(tensor), fps=fps)\n\n    filename = tempfile.NamedTemporaryFile(suffix=\'.gif\', delete=False).name\n\n    # moviepy >= 1.0.0 use logger=None to suppress output.\n    try:\n        clip.write_gif(filename, verbose=False, logger=None)\n    except TypeError:\n        logging.warning(\'Upgrade to moviepy >= 1.0.0 to supress the progress bar.\')\n        clip.write_gif(filename, verbose=False)\n\n    with open(filename, \'rb\') as f:\n        tensor_string = f.read()\n\n    try:\n        os.remove(filename)\n    except OSError:\n        logging.warning(\'The temporary file used by moviepy cannot be deleted.\')\n\n    return Summary.Image(height=h, width=w, colorspace=c, encoded_image_string=tensor_string)\n\n\ndef audio(tag, tensor, sample_rate=44100):\n    tensor = make_np(tensor)\n    tensor = tensor.squeeze()\n    if abs(tensor).max() > 1:\n        print(\'warning: audio amplitude out of range, auto clipped.\')\n        tensor = tensor.clip(-1, 1)\n    assert(tensor.ndim == 1), \'input tensor should be 1 dimensional.\'\n\n    tensor_list = [int(32767.0 * x) for x in tensor]\n    import io\n    import wave\n    import struct\n    fio = io.BytesIO()\n    Wave_write = wave.open(fio, \'wb\')\n    Wave_write.setnchannels(1)\n    Wave_write.setsampwidth(2)\n    Wave_write.setframerate(sample_rate)\n    tensor_enc = b\'\'\n    tensor_enc += struct.pack(""<"" + ""h"" * len(tensor_list), *tensor_list)\n\n    Wave_write.writeframes(tensor_enc)\n    Wave_write.close()\n    audio_string = fio.getvalue()\n    fio.close()\n    audio = Summary.Audio(sample_rate=sample_rate,\n                          num_channels=1,\n                          length_frames=len(tensor_list),\n                          encoded_audio_string=audio_string,\n                          content_type=\'audio/wav\')\n    return Summary(value=[Summary.Value(tag=tag, audio=audio)])\n\n\ndef custom_scalars(layout):\n    categoriesnames = layout.keys()\n    categories = []\n    layouts = []\n    for k, v in layout.items():\n        charts = []\n        for chart_name, chart_meatadata in v.items():\n            tags = chart_meatadata[1]\n            if chart_meatadata[0] == \'Margin\':\n                assert len(tags) == 3\n                mgcc = layout_pb2.MarginChartContent(series=[layout_pb2.MarginChartContent.Series(value=tags[0],\n                                                                                                  lower=tags[1],\n                                                                                                  upper=tags[2])])\n                chart = layout_pb2.Chart(title=chart_name, margin=mgcc)\n            else:\n                mlcc = layout_pb2.MultilineChartContent(tag=tags)\n                chart = layout_pb2.Chart(title=chart_name, multiline=mlcc)\n            charts.append(chart)\n        categories.append(layout_pb2.Category(title=k, chart=charts))\n\n    layout = layout_pb2.Layout(category=categories)\n    PluginData = SummaryMetadata.PluginData(plugin_name=\'custom_scalars\')\n    smd = SummaryMetadata(plugin_data=PluginData)\n    tensor = TensorProto(dtype=\'DT_STRING\',\n                         string_val=[layout.SerializeToString()],\n                         tensor_shape=TensorShapeProto())\n    return Summary(value=[Summary.Value(tag=\'custom_scalars__config__\', tensor=tensor, metadata=smd)])\n\n\ndef text(tag, text):\n    import json\n    PluginData = SummaryMetadata.PluginData(\n        plugin_name=\'text\', content=TextPluginData(version=0).SerializeToString())\n    smd = SummaryMetadata(plugin_data=PluginData)\n    tensor = TensorProto(dtype=\'DT_STRING\',\n                         string_val=[text.encode(encoding=\'utf_8\')],\n                         tensor_shape=TensorShapeProto(dim=[TensorShapeProto.Dim(size=1)]))\n    return Summary(value=[Summary.Value(tag=tag + \'/text_summary\', metadata=smd, tensor=tensor)])\n\n\ndef pr_curve_raw(tag, tp, fp, tn, fn, precision, recall, num_thresholds=127, weights=None):\n    if num_thresholds > 127:  # weird, value > 127 breaks protobuf\n        num_thresholds = 127\n    data = np.stack((tp, fp, tn, fn, precision, recall))\n    pr_curve_plugin_data = PrCurvePluginData(\n        version=0, num_thresholds=num_thresholds).SerializeToString()\n    PluginData = SummaryMetadata.PluginData(\n        plugin_name=\'pr_curves\', content=pr_curve_plugin_data)\n    smd = SummaryMetadata(plugin_data=PluginData)\n    tensor = TensorProto(dtype=\'DT_FLOAT\',\n                         float_val=data.reshape(-1).tolist(),\n                         tensor_shape=TensorShapeProto(\n                             dim=[TensorShapeProto.Dim(size=data.shape[0]), TensorShapeProto.Dim(size=data.shape[1])]))\n    return Summary(value=[Summary.Value(tag=tag, metadata=smd, tensor=tensor)])\n\n\ndef pr_curve(tag, labels, predictions, num_thresholds=127, weights=None):\n    # weird, value > 127 breaks protobuf\n    num_thresholds = min(num_thresholds, 127)\n    data = compute_curve(labels, predictions,\n                         num_thresholds=num_thresholds, weights=weights)\n    pr_curve_plugin_data = PrCurvePluginData(\n        version=0, num_thresholds=num_thresholds).SerializeToString()\n    PluginData = SummaryMetadata.PluginData(\n        plugin_name=\'pr_curves\', content=pr_curve_plugin_data)\n    smd = SummaryMetadata(plugin_data=PluginData)\n    tensor = TensorProto(dtype=\'DT_FLOAT\',\n                         float_val=data.reshape(-1).tolist(),\n                         tensor_shape=TensorShapeProto(\n                             dim=[TensorShapeProto.Dim(size=data.shape[0]), TensorShapeProto.Dim(size=data.shape[1])]))\n    return Summary(value=[Summary.Value(tag=tag, metadata=smd, tensor=tensor)])\n\n\n# https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/summary.py\ndef compute_curve(labels, predictions, num_thresholds=None, weights=None):\n    _MINIMUM_COUNT = 1e-7\n\n    if weights is None:\n        weights = 1.0\n\n    # Compute bins of true positives and false positives.\n    bucket_indices = np.int32(np.floor(predictions * (num_thresholds - 1)))\n    float_labels = labels.astype(np.float)\n    histogram_range = (0, num_thresholds - 1)\n    tp_buckets, _ = np.histogram(\n        bucket_indices,\n        bins=num_thresholds,\n        range=histogram_range,\n        weights=float_labels * weights)\n    fp_buckets, _ = np.histogram(\n        bucket_indices,\n        bins=num_thresholds,\n        range=histogram_range,\n        weights=(1.0 - float_labels) * weights)\n\n    # Obtain the reverse cumulative sum.\n    tp = np.cumsum(tp_buckets[::-1])[::-1]\n    fp = np.cumsum(fp_buckets[::-1])[::-1]\n    tn = fp[0] - fp\n    fn = tp[0] - tp\n    precision = tp / np.maximum(_MINIMUM_COUNT, tp + fp)\n    recall = tp / np.maximum(_MINIMUM_COUNT, tp + fn)\n    return np.stack((tp, fp, tn, fn, precision, recall))\n\n\ndef _get_tensor_summary(tag, tensor, content_type, json_config):\n    mesh_plugin_data = MeshPluginData(\n        version=0,\n        name=tag,\n        content_type=content_type,\n        json_config=json_config,\n        shape=tensor.shape,\n    )\n    content = mesh_plugin_data.SerializeToString()\n    smd = SummaryMetadata(\n        plugin_data=SummaryMetadata.PluginData(\n            plugin_name=\'mesh\',\n            content=content))\n\n    tensor = TensorProto(dtype=\'DT_FLOAT\',\n                         float_val=tensor.reshape(-1).tolist(),\n                         tensor_shape=TensorShapeProto(dim=[\n                             TensorShapeProto.Dim(size=tensor.shape[0]),\n                             TensorShapeProto.Dim(size=tensor.shape[1]),\n                             TensorShapeProto.Dim(size=tensor.shape[2]),\n                         ]))\n    tensor_summary = Summary.Value(\n        tag=\'{}_{}\'.format(tag, content_type),\n        tensor=tensor,\n        metadata=smd,\n    )\n    return tensor_summary\n\n\ndef mesh(tag, vertices, colors, faces, config_dict=None):\n\n    import json\n    summaries = []\n    tensors = [\n        (vertices, 1),\n        (faces, 2),\n        (colors, 3)\n    ]\n\n    for tensor, content_type in tensors:\n        if tensor is None:\n            continue\n        summaries.append(\n            _get_tensor_summary(tag, make_np(tensor), content_type, json.dumps(config_dict, sort_keys=True)))\n\n    return Summary(value=summaries)\n'"
tensorboardX/torchvis.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport gc\nimport six\nimport time\n\nfrom functools import wraps\nfrom .writer import SummaryWriter\nfrom .visdom_writer import VisdomWriter\n\n\n# Supports both TensorBoard and Visdom (no embedding or graph visualization with Visdom)\nvis_formats = {\'tensorboard\': SummaryWriter, \'visdom\': VisdomWriter}\n\n\nclass TorchVis:\n    def __init__(self, *args, **init_kwargs):\n        """"""\n        Args:\n            args (list of strings): The name of the visualization target(s).\n              Accepted targets are \'tensorboard\' and \'visdom\'.\n            init_kwargs: Additional keyword parameters for the visdom writer (For example, server IP).\n              See https://github.com/facebookresearch/visdom/blob/master/README.md#visdom-arguments-python-only\n              for more.\n        """"""\n        self.subscribers = {}\n        self.register(*args, **init_kwargs)\n\n    def register(self, *args, **init_kwargs):\n        # Sets tensorboard as the default visualization format if not specified\n        formats = [\'tensorboard\'] if not args else args\n        for format in formats:\n            if self.subscribers.get(format) is None and format in vis_formats.keys():\n                self.subscribers[format] = vis_formats[format](**init_kwargs.get(format, {}))\n\n    def unregister(self, *args):\n        for format in args:\n            self.subscribers[format].close()\n            del self.subscribers[format]\n            gc.collect()\n\n    def __getattr__(self, attr):\n        for _, subscriber in six.iteritems(self.subscribers):\n            def wrapper(*args, **kwargs):\n                for _, subscriber in six.iteritems(self.subscribers):\n                    if hasattr(subscriber, attr):\n                        getattr(subscriber, attr)(*args, **kwargs)\n            return wrapper\n        raise AttributeError\n\n    # Handle writer management (open/close) for the user\n    def __del__(self):\n        for _, subscriber in six.iteritems(self.subscribers):\n            subscriber.close()\n'"
tensorboardX/utils.py,0,"b'# Functions for converting\ndef figure_to_image(figures, close=True):\n    """"""Render matplotlib figure to numpy format.\n\n    Note that this requires the ``matplotlib`` package.\n\n    Args:\n        figure (matplotlib.pyplot.figure) or list of figures: figure or a list of figures\n        close (bool): Flag to automatically close the figure\n\n    Returns:\n        numpy.array: image in [CHW] order\n    """"""\n    import numpy as np\n    try:\n        import matplotlib.pyplot as plt\n        import matplotlib.backends.backend_agg as plt_backend_agg\n    except ModuleNotFoundError:\n        print(\'please install matplotlib\')\n\n    def render_to_rgb(figure):\n        canvas = plt_backend_agg.FigureCanvasAgg(figure)\n        canvas.draw()\n        data = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)\n        w, h = figure.canvas.get_width_height()\n        image_hwc = data.reshape([h, w, 4])[:, :, 0:3]\n        image_chw = np.moveaxis(image_hwc, source=2, destination=0)\n        if close:\n            plt.close(figure)\n        return image_chw\n\n    if isinstance(figures, list):\n        images = [render_to_rgb(figure) for figure in figures]\n        return np.stack(images)\n    else:\n        image = render_to_rgb(figures)\n        return image\n\n\ndef graphviz_to_image():\n    pass\n\n\ndef _prepare_video(V):\n    import numpy as np\n    b, t, c, h, w = V.shape\n\n    if V.dtype == np.uint8:\n        V = np.float32(V) / 255.\n\n    def is_power2(num):\n        return num != 0 and ((num & (num - 1)) == 0)\n\n    # pad to nearest power of 2, all at once\n    if not is_power2(V.shape[0]):\n        len_addition = int(2**V.shape[0].bit_length() - V.shape[0])\n        V = np.concatenate(\n            (V, np.zeros(shape=(len_addition, t, c, h, w))), axis=0)\n\n    n_rows = 2**((b.bit_length() - 1) // 2)\n    n_cols = V.shape[0] // n_rows\n\n    V = np.reshape(V, newshape=(n_rows, n_cols, t, c, h, w))\n    V = np.transpose(V, axes=(2, 0, 4, 1, 5, 3))\n    V = np.reshape(V, newshape=(t, n_rows * h, n_cols * w, c))\n\n    return V\n\n\ndef make_grid(I, ncols=8):\n    # I: N1HW or N3HW\n    import numpy as np\n    assert isinstance(\n        I, np.ndarray), \'plugin error, should pass numpy array here\'\n    if I.shape[1] == 1:\n        I = np.concatenate([I, I, I], 1)\n    assert I.ndim == 4 and I.shape[1] == 3 or I.shape[1] == 4\n    nimg = I.shape[0]\n    H = I.shape[2]\n    W = I.shape[3]\n    ncols = min(nimg, ncols)\n    nrows = int(np.ceil(float(nimg) / ncols))\n    canvas = np.zeros((I.shape[1], H * nrows, W * ncols))\n    i = 0\n    for y in range(nrows):\n        for x in range(ncols):\n            if i >= nimg:\n                break\n            canvas[:, y * H:(y + 1) * H, x * W:(x + 1) * W] = I[i]\n            i = i + 1\n    return canvas\n\n    # if modality == \'IMG\':\n    #     if x.dtype == np.uint8:\n    #         x = x.astype(np.float32) / 255.0\n\n\ndef convert_to_HWC(tensor, input_format):  # tensor: numpy array\n    import numpy as np\n    assert(len(set(input_format)) == len(input_format)), ""You can not use the same dimension shordhand twice. \\\n        input_format: {}"".format(input_format)\n    assert(len(tensor.shape) == len(input_format)), ""size of input tensor and input format are different. \\\n        tensor shape: {}, input_format: {}"".format(tensor.shape, input_format)\n    input_format = input_format.upper()\n\n    if len(input_format) == 4:\n        index = [input_format.find(c) for c in \'NCHW\']\n        tensor_NCHW = tensor.transpose(index)\n        tensor_CHW = make_grid(tensor_NCHW)\n        return tensor_CHW.transpose(1, 2, 0)\n\n    if len(input_format) == 3:\n        index = [input_format.find(c) for c in \'HWC\']\n        tensor_HWC = tensor.transpose(index)\n        if tensor_HWC.shape[2] == 1:\n            tensor_HWC = np.concatenate([tensor_HWC, tensor_HWC, tensor_HWC], 2)\n        return tensor_HWC\n\n    if len(input_format) == 2:\n        index = [input_format.find(c) for c in \'HW\']\n        tensor = tensor.transpose(index)\n        tensor = np.stack([tensor, tensor, tensor], 2)\n        return tensor\n'"
tensorboardX/visdom_writer.py,13,"b'import gc\nimport numpy as np\nimport math\nimport json\nimport time\n\nfrom .summary import compute_curve\nfrom .utils import figure_to_image\nfrom .x2num import make_np\n\n\n# Decorator that checks if there is a Visdom connection\ndef _check_connection(fn):\n    def wrapper(self, *args, **kwargs):\n        if not self.server_connected:\n            print(\'ERROR: No Visdom server currently connected\')\n            self._try_connect()\n            return\n        fn(self, *args, **kwargs)\n    return wrapper\n\n\nclass VisdomWriter:\n    def __init__(self, *args, **kwargs):\n        try:\n            from visdom import Visdom\n        except ImportError:\n            raise ImportError(\n                ""Visdom visualization requires installation of Visdom"")\n\n        self.scalar_dict = {}\n        self.server_connected = False\n        self.vis = Visdom(*args, **kwargs)\n        self.windows = {}\n\n        self._try_connect()\n\n    def _try_connect(self):\n        startup_sec = 1\n        self.server_connected = self.vis.check_connection()\n        while not self.server_connected and startup_sec > 0:\n            time.sleep(0.1)\n            startup_sec -= 0.1\n            self.server_connected = self.vis.check_connection()\n        assert self.server_connected, \'No connection could be formed quickly\'\n\n    @_check_connection\n    def add_scalar(self, tag, scalar_value, global_step=None, main_tag=\'default\'):\n        """"""Add scalar data to Visdom. Plots the values in a plot titled\n           {main_tag}-{tag}.\n\n        Args:\n            tag (string): Data identifier\n            scalar_value (float or string/blobname): Value to save\n            global_step (int): Global step value to record\n            main_tag (string): Data group identifier\n        """"""\n        if self.scalar_dict.get(main_tag) is None:\n            self.scalar_dict[main_tag] = {}\n        exists = self.scalar_dict[main_tag].get(tag) is not None\n        self.scalar_dict[main_tag][tag] = self.scalar_dict[main_tag][tag] + \\\n            [scalar_value] if exists else [scalar_value]\n        plot_name = \'{}-{}\'.format(main_tag, tag)\n        # If there is no global_step provided, follow sequential order\n        x_val = len(self.scalar_dict[main_tag][tag]\n                    ) if not global_step else global_step\n        if exists:\n            # Update our existing Visdom window\n            self.vis.line(\n                X=make_np(x_val),\n                Y=make_np(scalar_value),\n                name=plot_name,\n                update=\'append\',\n                win=self.windows[plot_name],\n            )\n        else:\n            # Save the window if we are creating this graph for the first time\n            self.windows[plot_name] = self.vis.line(\n                X=make_np(x_val),\n                Y=make_np(scalar_value),\n                name=plot_name,\n                opts={\n                    \'title\': plot_name,\n                    \'xlabel\': \'timestep\',\n                    \'ylabel\': tag,\n                },\n            )\n\n    @_check_connection\n    def add_scalars(self, main_tag, tag_scalar_dict, global_step=None):\n        """"""Adds many scalar data to summary.\n\n        Note that this function also keeps logged scalars in memory. In extreme case it explodes your RAM.\n\n        Args:\n            tag (string): Data identifier\n            main_tag (string): Data group identifier\n            tag_scalar_dict (dict): Key-value pair storing the tag and corresponding values\n            global_step (int): Global step value to record\n\n        Examples::\n\n            writer.add_scalars(\'run_14h\',{\'xsinx\':i*np.sin(i/r),\n                                          \'xcosx\':i*np.cos(i/r),\n                                          \'arctanx\': numsteps*np.arctan(i/r)}, i)\n            This function adds three plots:\n                \'run_14h-xsinx\',\n                \'run_14h-xcosx\',\n                \'run_14h-arctanx\'\n            with the corresponding values.\n        """"""\n        for key in tag_scalar_dict.keys():\n            self.add_scalar(key, tag_scalar_dict[key], global_step, main_tag)\n\n    @_check_connection\n    def export_scalars_to_json(self, path):\n        """"""Exports to the given \'path\' an ASCII file containing all the scalars written\n        so far by this instance, with the following format:\n        {writer_id : [[timestamp, step, value], ...], ...}\n\n        The scalars saved by ``add_scalars()`` will be flushed after export.\n        """"""\n        with open(path, ""w"") as f:\n            json.dump(self.scalar_dict, f)\n        self.scalar_dict = {}\n\n    @_check_connection\n    def add_histogram(self, tag, values, global_step=None, bins=\'tensorflow\'):\n        """"""Add histogram to summary.\n\n        Args:\n            tag (string): Data identifier\n            values (torch.Tensor, numpy.array, or string/blobname): Values to build histogram\n            global_step (int): Global step value to record\n            bins (string): one of {\'tensorflow\', \'auto\', \'fd\', ...}, this determines how the bins are made. You can find\n              other options in: https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html\n        """"""\n        values = make_np(values)\n        self.vis.histogram(make_np(values), opts={\'title\': tag})\n\n    @_check_connection\n    def add_image(self, tag, img_tensor, global_step=None, caption=None):\n        """"""Add image data to summary.\n\n        Note that this requires the ``pillow`` package.\n\n        Args:\n            tag (string): Data identifier\n            img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data\n            global_step (int): Global step value to record\n        Shape:\n            img_tensor: :math:`(C, H, W)`. Use ``torchvision.utils.make_grid()`` to prepare it is a good idea.\n            C = colors (can be 1 - grayscale, 3 - RGB, 4 - RGBA)\n        """"""\n        img_tensor = make_np(img_tensor)\n        self.vis.image(img_tensor, opts={\'title\': tag, \'caption\': caption})\n\n    @_check_connection\n    def add_figure(self, tag, figure, global_step=None, close=True):\n        """"""Render matplotlib figure into an image and add it to summary.\n\n        Note that this requires the ``matplotlib`` package.\n\n        Args:\n            tag (string): Data identifier\n            figure (matplotlib.pyplot.figure) or list of figures: figure or a list of figures\n            global_step (int): Global step value to record\n            close (bool): Flag to automatically close the figure\n        """"""\n        self.add_image(tag, figure_to_image(figure, close), global_step)\n\n    @_check_connection\n    def add_video(self, tag, vid_tensor, global_step=None, fps=4):\n        """"""Add video data to summary.\n\n        Note that this requires the ``moviepy`` package.\n\n        Args:\n            tag (string): Data identifier\n            vid_tensor (torch.Tensor): Video data, the pixel value should in [0, 1]\n            global_step (int): Global step value to record\n            fps (float or int): Frames per second\n        Shape:\n            vid_tensor: :math:`(B, C, T, H, W)`. (if following tensorboardX format)\n            vid_tensor: :math:`(T, H, W, C)`. (if following visdom format)\n            B = batches, C = colors (1, 3, or 4), T = time frames, H = height, W = width\n        """"""\n        shape = vid_tensor.shape\n        # A batch of videos (tensorboardX format) is a 5D tensor\n        if len(shape) > 4:\n            for i in range(shape[0]):\n                # Reshape each video to Visdom\'s (T x H x W x C) and write each video\n                # TODO: reverse the logic here, shoudl do the permutation in numpy\n                if isinstance(vid_tensor, np.ndarray):\n                    import torch\n                    ind_vid = torch.from_numpy(\n                        vid_tensor[i, :, :, :, :]).permute(1, 2, 3, 0)\n                else:\n                    ind_vid = vid_tensor[i, :, :, :, :].permute(1, 2, 3, 0)\n                scale_factor = 255\n                # Visdom looks for .ndim attr, this is something raw Tensors don\'t have\n                # Cast to Numpy array to get .ndim attr\n                ind_vid = ind_vid.numpy()\n                ind_vid = (ind_vid * scale_factor).astype(np.uint8)\n                assert ind_vid.shape[3] in [1, 3, 4], \\\n                    \'Visdom requires the last dimension to be color, which can be 1 (grayscale), 3 (RGB) or 4 (RGBA)\'\n                self.vis.video(tensor=ind_vid, opts={\'fps\': fps})\n        else:\n            self.vis.video(tensor=vid_tensor, opts={\'fps\': fps})\n\n    @_check_connection\n    def add_audio(self, tag, snd_tensor, global_step=None, sample_rate=44100):\n        """"""Add audio data to summary.\n\n        Args:\n            tag (string): Data identifier\n            snd_tensor (torch.Tensor, numpy.array, or string/blobname): Sound data\n            global_step (int): Global step value to record\n            sample_rate (int): sample rate in Hz\n\n        Shape:\n            snd_tensor: :math:`(1, L)`. The values should lie between [-1, 1].\n        """"""\n        snd_tensor = make_np(snd_tensor)\n        self.vis.audio(tensor=snd_tensor, opts={\n                       \'sample_frequency\': sample_rate})\n\n    @_check_connection\n    def add_text(self, tag, text_string, global_step=None):\n        """"""Add text data to summary.\n\n        Args:\n            tag (string): Data identifier\n            text_string (string): String to save\n            global_step (int): Global step value to record\n        Examples::\n            writer.add_text(\'lstm\', \'This is an lstm\', 0)\n            writer.add_text(\'rnn\', \'This is an rnn\', 10)\n        """"""\n        if text_string is None:\n            # Visdom doesn\'t support tags, write the tag as the text_string\n            text_string = tag\n        self.vis.text(text_string)\n\n    @_check_connection\n    def add_onnx_graph(self, prototxt):\n        # TODO: Visdom doesn\'t support graph visualization yet, so this is a no-op\n        return\n\n    @_check_connection\n    def add_graph(self, model, input_to_model=None, verbose=False, **kwargs):\n        # TODO: Visdom doesn\'t support graph visualization yet, so this is a no-op\n        return\n\n    @_check_connection\n    def add_embedding(self, mat, metadata=None, label_img=None, global_step=None, tag=\'default\', metadata_header=None):\n        # TODO: Visdom doesn\'t support embeddings yet, so this is a no-op\n        return\n\n    @_check_connection\n    def add_pr_curve(self, tag, labels, predictions, global_step=None, num_thresholds=127, weights=None):\n        """"""Adds precision recall curve.\n\n        Args:\n            tag (string): Data identifier\n            labels (torch.Tensor, numpy.array, or string/blobname): Ground truth data. Binary label for each element.\n            predictions (torch.Tensor, numpy.array, or string/blobname):\n            The probability that an element be classified as true. Value should in [0, 1]\n            global_step (int): Global step value to record\n            num_thresholds (int): Number of thresholds used to draw the curve.\n\n        """"""\n        labels, predictions = make_np(labels), make_np(predictions)\n        raw_data = compute_curve(labels, predictions, num_thresholds, weights)\n\n        # compute_curve returns np.stack((tp, fp, tn, fn, precision, recall))\n        # We want to access \'precision\' and \'recall\'\n        precision, recall = raw_data[4, :], raw_data[5, :]\n\n        self.vis.line(\n            X=recall,\n            Y=precision,\n            name=tag,\n            opts={\n                \'title\': \'PR Curve for {}\'.format(tag),\n                \'xlabel\': \'recall\',\n                \'ylabel\': \'precision\',\n            },\n        )\n\n    @_check_connection\n    def add_pr_curve_raw(self, tag, true_positive_counts,\n                         false_positive_counts,\n                         true_negative_counts,\n                         false_negative_counts,\n                         precision,\n                         recall, global_step=None, num_thresholds=127, weights=None):\n        """"""Adds precision recall curve with raw data.\n\n        Args:\n            tag (string): Data identifier\n            true_positive_counts (torch.Tensor, numpy.array, or string/blobname): true positive counts\n            false_positive_counts (torch.Tensor, numpy.array, or string/blobname): false positive counts\n            true_negative_counts (torch.Tensor, numpy.array, or string/blobname): true negative counts\n            false_negative_counts (torch.Tensor, numpy.array, or string/blobname): false negative counts\n            precision (torch.Tensor, numpy.array, or string/blobname): precision\n            recall (torch.Tensor, numpy.array, or string/blobname): recall\n            global_step (int): Global step value to record\n            num_thresholds (int): Number of thresholds used to draw the curve.\n            see: https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/README.md\n        """"""\n        precision, recall = make_np(precision), make_np(recall)\n        self.vis.line(\n            X=recall,\n            Y=precision,\n            name=tag,\n            opts={\n                \'title\': \'PR Curve for {}\'.format(tag),\n                \'xlabel\': \'recall\',\n                \'ylabel\': \'precision\',\n            },\n        )\n\n    def close(self):\n        del self.vis\n        del self.scalar_dict\n        gc.collect()\n'"
tensorboardX/writer.py,33,"b'""""""Provides an API for writing protocol buffers to event files to be\nconsumed by TensorBoard for visualization.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport json\nimport os\nimport six\nimport time\nimport logging\nimport atexit\n\nfrom .embedding import make_mat, make_sprite, make_tsv, append_pbtxt\nfrom .event_file_writer import EventFileWriter\nfrom .onnx_graph import load_onnx_graph\nfrom .openvino_graph import load_openvino_graph\nfrom .pytorch_graph import graph\nfrom .proto import event_pb2\nfrom .proto import summary_pb2\nfrom .proto.event_pb2 import SessionLog, Event\nfrom .utils import figure_to_image\nfrom .summary import (\n    scalar, histogram, histogram_raw, image, audio, text,\n    pr_curve, pr_curve_raw, video, custom_scalars, image_boxes, mesh, hparams\n)\n\n\nclass DummyFileWriter(object):\n    """"""A fake file writer that writes nothing to the disk.\n    """"""\n    def __init__(self, logdir):\n        self._logdir = logdir\n\n    def get_logdir(self):\n        """"""Returns the directory where event file will be written.""""""\n        return self._logdir\n\n    def add_event(self, event, step=None, walltime=None):\n        return\n\n    def add_summary(self, summary, global_step=None, walltime=None):\n        return\n\n    def add_graph(self, graph_profile, walltime=None):\n        return\n\n    def add_onnx_graph(self, graph, walltime=None):\n        return\n\n    def flush(self):\n        return\n\n    def close(self):\n        return\n\n    def reopen(self):\n        return\n\n\nclass FileWriter(object):\n    """"""Writes protocol buffers to event files to be consumed by TensorBoard.\n\n    The `FileWriter` class provides a mechanism to create an event file in a\n    given directory and add summaries and events to it. The class updates the\n    file contents asynchronously. This allows a training program to call methods\n    to add data to the file directly from the training loop, without slowing down\n    training.\n    """"""\n\n    def __init__(self, logdir, max_queue=10, flush_secs=120, filename_suffix=\'\'):\n        """"""Creates a `FileWriter` and an event file.\n        On construction the writer creates a new event file in `logdir`.\n        The other arguments to the constructor control the asynchronous writes to\n        the event file.\n\n        Args:\n          logdir: A string. Directory where event file will be written.\n          max_queue: Integer. Size of the queue for pending events and\n            summaries before one of the \'add\' calls forces a flush to disk.\n            Default is ten items.\n          flush_secs: Number. How often, in seconds, to flush the\n            pending events and summaries to disk. Default is every two minutes.\n          filename_suffix: A string. Suffix added to all event filenames\n            in the logdir directory. More details on filename construction in\n            tensorboard.summary.writer.event_file_writer.EventFileWriter.\n        """"""\n        # Sometimes PosixPath is passed in and we need to coerce it to\n        # a string in all cases\n        # TODO: See if we can remove this in the future if we are\n        # actually the ones passing in a PosixPath\n        logdir = str(logdir)\n        self.event_writer = EventFileWriter(\n            logdir, max_queue, flush_secs, filename_suffix)\n\n        def cleanup():\n            self.event_writer.close()\n\n        atexit.register(cleanup)\n\n    def get_logdir(self):\n        """"""Returns the directory where event file will be written.""""""\n        return self.event_writer.get_logdir()\n\n    def add_event(self, event, step=None, walltime=None):\n        """"""Adds an event to the event file.\n        Args:\n          event: An `Event` protocol buffer.\n          step: Number. Optional global step value for training process\n            to record with the event.\n          walltime: float. Optional walltime to override the default (current)\n            walltime (from time.time())\n        """"""\n        event.wall_time = time.time() if walltime is None else walltime\n        if step is not None:\n            # Make sure step is converted from numpy or other formats\n            # since protobuf might not convert depending on version\n            event.step = int(step)\n        self.event_writer.add_event(event)\n\n    def add_summary(self, summary, global_step=None, walltime=None):\n        """"""Adds a `Summary` protocol buffer to the event file.\n        This method wraps the provided summary in an `Event` protocol buffer\n        and adds it to the event file.\n\n        Args:\n          summary: A `Summary` protocol buffer.\n          global_step: Number. Optional global step value for training process\n            to record with the summary.\n          walltime: float. Optional walltime to override the default (current)\n            walltime (from time.time())\n        """"""\n        event = event_pb2.Event(summary=summary)\n        self.add_event(event, global_step, walltime)\n\n    def add_graph(self, graph_profile, walltime=None):\n        """"""Adds a `Graph` and step stats protocol buffer to the event file.\n\n        Args:\n          graph_profile: A `Graph` and step stats protocol buffer.\n          walltime: float. Optional walltime to override the default (current)\n            walltime (from time.time()) seconds after epoch\n        """"""\n        graph = graph_profile[0]\n        stepstats = graph_profile[1]\n        event = event_pb2.Event(graph_def=graph.SerializeToString())\n        self.add_event(event, None, walltime)\n\n        trm = event_pb2.TaggedRunMetadata(\n            tag=\'profiler\', run_metadata=stepstats.SerializeToString())\n        event = event_pb2.Event(tagged_run_metadata=trm)\n        self.add_event(event, None, walltime)\n\n    def add_onnx_graph(self, graph, walltime=None):\n        """"""Adds a `Graph` protocol buffer to the event file.\n\n        Args:\n          graph: A `Graph` protocol buffer.\n          walltime: float. Optional walltime to override the default (current)\n            _get_file_writerfrom time.time())\n        """"""\n        event = event_pb2.Event(graph_def=graph.SerializeToString())\n        self.add_event(event, None, walltime)\n\n    def add_openvino_graph(self, graph, walltime=None):\n        """"""Adds a `Graph` protocol buffer to the event file.\n\n        Args:\n          graph: A `Graph` protocol buffer.\n          walltime: float. Optional walltime to override the default (current)\n            _get_file_writerfrom time.time())\n        """"""\n        event = event_pb2.Event(graph_def=graph.SerializeToString())\n        self.add_event(event, None, walltime)\n\n    def flush(self):\n        """"""Flushes the event file to disk.\n        Call this method to make sure that all pending events have been written to\n        disk.\n        """"""\n        self.event_writer.flush()\n\n    def close(self):\n        """"""Flushes the event file to disk and close the file.\n        Call this method when you do not need the summary writer anymore.\n        """"""\n        self.event_writer.close()\n\n    def reopen(self):\n        """"""Reopens the EventFileWriter.\n        Can be called after `close()` to add more events in the same directory.\n        The events will go into a new events file.\n        Does nothing if the EventFileWriter was not closed.\n        """"""\n        self.event_writer.reopen()\n\n\nclass SummaryWriter(object):\n    """"""Writes entries directly to event files in the logdir to be\n    consumed by TensorBoard.\n\n    The `SummaryWriter` class provides a high-level API to create an event file\n    in a given directory and add summaries and events to it. The class updates the\n    file contents asynchronously. This allows a training program to call methods\n    to add data to the file directly from the training loop, without slowing down\n    training.\n    """"""\n\n    def __init__(self, logdir=None, comment=\'\', purge_step=None, max_queue=10,\n                 flush_secs=120, filename_suffix=\'\', write_to_disk=True, log_dir=None, **kwargs):\n        """"""Creates a `SummaryWriter` that will write out events and summaries\n        to the event file.\n\n        Args:\n            logdir (string): Save directory location. Default is\n              runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run.\n              Use hierarchical folder structure to compare\n              between runs easily. e.g. pass in \'runs/exp1\', \'runs/exp2\', etc.\n              for each new experiment to compare across them.\n            comment (string): Comment logdir suffix appended to the default\n              ``logdir``. If ``logdir`` is assigned, this argument has no effect.\n            purge_step (int):\n              When logging crashes at step :math:`T+X` and restarts at step :math:`T`,\n              any events whose global_step larger or equal to :math:`T` will be\n              purged and hidden from TensorBoard.\n              Note that crashed and resumed experiments should have the same ``logdir``.\n            max_queue (int): Size of the queue for pending events and\n              summaries before one of the \'add\' calls forces a flush to disk.\n              Default is ten items.\n            flush_secs (int): How often, in seconds, to flush the\n              pending events and summaries to disk. Default is every two minutes.\n            filename_suffix (string): Suffix added to all event filenames in\n              the logdir directory. More details on filename construction in\n              tensorboard.summary.writer.event_file_writer.EventFileWriter.\n            write_to_disk (boolean):\n              If pass `False`, SummaryWriter will not write to disk.\n\n        Examples::\n\n            from tensorboardX import SummaryWriter\n\n            # create a summary writer with automatically generated folder name.\n            writer = SummaryWriter()\n            # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/\n\n            # create a summary writer using the specified folder name.\n            writer = SummaryWriter(""my_experiment"")\n            # folder location: my_experiment\n\n            # create a summary writer with comment appended.\n            writer = SummaryWriter(comment=""LR_0.1_BATCH_16"")\n            # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/\n\n        """"""\n        if log_dir is not None and logdir is None:\n            logdir = log_dir\n        if not logdir:\n            import socket\n            from datetime import datetime\n            current_time = datetime.now().strftime(\'%b%d_%H-%M-%S\')\n            logdir = os.path.join(\n                \'runs\', current_time + \'_\' + socket.gethostname() + comment)\n        self.logdir = logdir\n        self.purge_step = purge_step\n        self._max_queue = max_queue\n        self._flush_secs = flush_secs\n        self._filename_suffix = filename_suffix\n        self._write_to_disk = write_to_disk\n        self.kwargs = kwargs\n\n        # Initialize the file writers, but they can be cleared out on close\n        # and recreated later as needed.\n        self.file_writer = self.all_writers = None\n        self._get_file_writer()\n\n        # Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\n        v = 1E-12\n        buckets = []\n        neg_buckets = []\n        while v < 1E20:\n            buckets.append(v)\n            neg_buckets.append(-v)\n            v *= 1.1\n        self.default_bins = neg_buckets[::-1] + [0] + buckets\n\n        self.scalar_dict = {}\n\n    def __append_to_scalar_dict(self, tag, scalar_value, global_step,\n                                timestamp):\n        """"""This adds an entry to the self.scalar_dict datastructure with format\n        {writer_id : [[timestamp, step, value], ...], ...}.\n        """"""\n        from .x2num import make_np\n        if tag not in self.scalar_dict.keys():\n            self.scalar_dict[tag] = []\n        self.scalar_dict[tag].append(\n            [timestamp, global_step, float(make_np(scalar_value))])\n\n    def _check_caffe2_blob(self, item):\n        """"""\n        Caffe2 users have the option of passing a string representing the name of\n        a blob in the workspace instead of passing the actual Tensor/array containing\n        the numeric values. Thus, we need to check if we received a string as input\n        instead of an actual Tensor/array, and if so, we need to fetch the Blob\n        from the workspace corresponding to that name. Fetching can be done with the\n        following:\n\n        from caffe2.python import workspace (if not already imported)\n        workspace.FetchBlob(blob_name)\n        workspace.FetchBlobs([blob_name1, blob_name2, ...])\n        """"""\n        return isinstance(item, six.string_types)\n\n    def _get_file_writer(self):\n        """"""Returns the default FileWriter instance. Recreates it if closed.""""""\n        if not self._write_to_disk:\n            self.file_writer = DummyFileWriter(logdir=self.logdir)\n            self.all_writers = {self.file_writer.get_logdir(): self.file_writer}\n            return self.file_writer\n\n        if self.all_writers is None or self.file_writer is None:\n            if \'purge_step\' in self.kwargs.keys():\n                most_recent_step = self.kwargs.pop(\'purge_step\')\n                self.file_writer = FileWriter(logdir=self.logdir,\n                                              max_queue=self._max_queue,\n                                              flush_secs=self._flush_secs,\n                                              filename_suffix=self._filename_suffix,\n                                              **self.kwargs)\n                self.file_writer.add_event(\n                    Event(step=most_recent_step, file_version=\'brain.Event:2\'))\n                self.file_writer.add_event(\n                    Event(step=most_recent_step, session_log=SessionLog(status=SessionLog.START)))\n            else:\n                self.file_writer = FileWriter(logdir=self.logdir,\n                                              max_queue=self._max_queue,\n                                              flush_secs=self._flush_secs,\n                                              filename_suffix=self._filename_suffix,\n                                              **self.kwargs)\n            self.all_writers = {self.file_writer.get_logdir(): self.file_writer}\n        return self.file_writer\n\n    def add_hparams(self, hparam_dict=None, metric_dict=None, name=None, global_step=None):\n        """"""Add a set of hyperparameters to be compared in tensorboard.\n\n        Args:\n            hparam_dict (dictionary): Each key-value pair in the dictionary is the\n              name of the hyper parameter and it\'s corresponding value. The type of the value\n              can be one of `bool`, `string`, `float`, `int`, or `None`.\n            metric_dict (dictionary): Each key-value pair in the dictionary is the\n              name of the metric and it\'s corresponding value. Note that the key used\n              here should be unique in the tensorboard record. Otherwise the value\n              you added by `add_scalar` will be displayed in hparam plugin. In most\n              cases, this is unwanted.\n            name (string): Personnalised name of the hparam session\n            global_step (int): Current time step\n\n        Examples::\n\n            from tensorboardX import SummaryWriter\n            with SummaryWriter() as w:\n                for i in range(5):\n                    w.add_hparams({\'lr\': 0.1*i, \'bsize\': i},\n                                  {\'hparam/accuracy\': 10*i, \'hparam/loss\': 10*i})\n\n        Expected result:\n\n        .. image:: _static/img/tensorboard/add_hparam.png\n           :scale: 50 %\n        """"""\n        if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n            raise TypeError(\'hparam_dict and metric_dict should be dictionary.\')\n        exp, ssi, sei = hparams(hparam_dict, metric_dict)\n\n        if not name:\n            name = str(time.time())\n\n        with SummaryWriter(logdir=os.path.join(self.file_writer.get_logdir(), name)) as w_hp:\n            w_hp.file_writer.add_summary(exp)\n            w_hp.file_writer.add_summary(ssi)\n            w_hp.file_writer.add_summary(sei)\n            for k, v in metric_dict.items():\n                w_hp.add_scalar(k, v, global_step)\n\n    def add_scalar(self, tag, scalar_value, global_step=None, walltime=None,\n                   display_name="""", summary_description=""""):\n        """"""Add scalar data to summary.\n\n        Args:\n            tag (string): Data identifier\n            scalar_value (float or string/blobname): Value to save\n            global_step (int): Global step value to record\n            walltime (float): Optional override default walltime (time.time()) of event\n            display_name (string): The title of the plot. If empty string is passed,\n              `tag` will be used.\n            summary_description (string): The comprehensive text that will showed\n              by clicking the information icon on TensorBoard.\n        Examples::\n\n            from tensorboardX import SummaryWriter\n            writer = SummaryWriter()\n            x = range(100)\n            for i in x:\n                writer.add_scalar(\'y=2x\', i * 2, i)\n            writer.close()\n\n        Expected result:\n\n        .. image:: _static/img/tensorboard/add_scalar.png\n           :scale: 50 %\n\n        """"""\n        if self._check_caffe2_blob(scalar_value):\n            scalar_value = workspace.FetchBlob(scalar_value)\n        self._get_file_writer().add_summary(\n            scalar(tag, scalar_value, display_name, summary_description), global_step, walltime)\n\n    def add_scalars(self, main_tag, tag_scalar_dict, global_step=None, walltime=None):\n        """"""Adds many scalar data to summary.\n\n        Note that this function also keeps logged scalars in memory. In extreme case it explodes your RAM.\n\n        Args:\n            main_tag (string): The parent name for the tags\n            tag_scalar_dict (dict): Key-value pair storing the tag and corresponding values\n            global_step (int): Global step value to record\n            walltime (float): Optional override default walltime (time.time()) of event\n\n        Examples::\n\n            from tensorboardX import SummaryWriter\n            writer = SummaryWriter()\n            r = 5\n            for i in range(100):\n                writer.add_scalars(\'run_14h\', {\'xsinx\':i*np.sin(i/r),\n                                                \'xcosx\':i*np.cos(i/r),\n                                                \'tanx\': np.tan(i/r)}, i)\n            writer.close()\n            # This call adds three values to the same scalar plot with the tag\n            # \'run_14h\' in TensorBoard\'s scalar section.\n\n        Expected result:\n\n        .. image:: _static/img/tensorboard/add_scalars.png\n           :scale: 50 %\n\n        """"""\n        walltime = time.time() if walltime is None else walltime\n        fw_logdir = self._get_file_writer().get_logdir()\n        for tag, scalar_value in tag_scalar_dict.items():\n            fw_tag = fw_logdir + ""/"" + main_tag + ""/"" + tag\n            if fw_tag in self.all_writers.keys():\n                fw = self.all_writers[fw_tag]\n            else:\n                fw = FileWriter(logdir=fw_tag)\n                self.all_writers[fw_tag] = fw\n            if self._check_caffe2_blob(scalar_value):\n                scalar_value = workspace.FetchBlob(scalar_value)\n            fw.add_summary(scalar(main_tag, scalar_value),\n                           global_step, walltime)\n            self.__append_to_scalar_dict(\n                fw_tag, scalar_value, global_step, walltime)\n\n    def export_scalars_to_json(self, path):\n        """"""Exports to the given path an ASCII file containing all the scalars written\n        so far by this instance, with the following format:\n        {writer_id : [[timestamp, step, value], ...], ...}\n\n        The scalars saved by ``add_scalars()`` will be flushed after export.\n        """"""\n        with open(path, ""w"") as f:\n            json.dump(self.scalar_dict, f)\n        self.scalar_dict = {}\n\n    def add_histogram(self, tag, values, global_step=None, bins=\'tensorflow\', walltime=None, max_bins=None):\n        """"""Add histogram to summary.\n\n        Args:\n            tag (string): Data identifier\n            values (torch.Tensor, numpy.array, or string/blobname): Values to build histogram\n            global_step (int): Global step value to record\n            bins (string): One of {\'tensorflow\',\'auto\', \'fd\', ...}. This determines how the bins are made. You can find\n              other options in: https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html\n            walltime (float): Optional override default walltime (time.time()) of event\n\n        Examples::\n\n            from tensorboardX import SummaryWriter\n            import numpy as np\n            writer = SummaryWriter()\n            for i in range(10):\n                x = np.random.random(1000)\n                writer.add_histogram(\'distribution centers\', x + i, i)\n            writer.close()\n\n        Expected result:\n\n        .. image:: _static/img/tensorboard/add_histogram.png\n           :scale: 50 %\n\n        """"""\n        if self._check_caffe2_blob(values):\n            values = workspace.FetchBlob(values)\n        if isinstance(bins, six.string_types) and bins == \'tensorflow\':\n            bins = self.default_bins\n        self._get_file_writer().add_summary(\n            histogram(tag, values, bins, max_bins=max_bins), global_step, walltime)\n\n    def add_histogram_raw(self, tag, min, max, num, sum, sum_squares,\n                          bucket_limits, bucket_counts, global_step=None,\n                          walltime=None):\n        """"""Adds histogram with raw data.\n\n        Args:\n            tag (string): Data identifier\n            min (float or int): Min value\n            max (float or int): Max value\n            num (int): Number of values\n            sum (float or int): Sum of all values\n            sum_squares (float or int): Sum of squares for all values\n            bucket_limits (torch.Tensor, numpy.array): Upper value per\n              bucket, note that the bucket_limits returned from `np.histogram`\n              has one more element. See the comment in the following example.\n            bucket_counts (torch.Tensor, numpy.array): Number of values per bucket\n            global_step (int): Global step value to record\n            walltime (float): Optional override default walltime (time.time()) of event\n\n        Examples::\n\n            import numpy as np\n            dummy_data = []\n            for idx, value in enumerate(range(30)):\n                dummy_data += [idx + 0.001] * value\n            values = np.array(dummy_data).astype(float).reshape(-1)\n            counts, limits = np.histogram(values)\n            sum_sq = values.dot(values)\n            with SummaryWriter() as summary_writer:\n                summary_writer.add_histogram_raw(\n                        tag=\'hist_dummy_data\',\n                        min=values.min(),\n                        max=values.max(),\n                        num=len(values),\n                        sum=values.sum(),\n                        sum_squares=sum_sq,\n                        bucket_limits=limits[1:].tolist(),  # <- note here.\n                        bucket_counts=counts.tolist(),\n                        global_step=0)\n\n        """"""\n        if len(bucket_limits) != len(bucket_counts):\n            raise ValueError(\'len(bucket_limits) != len(bucket_counts), see the document.\')\n        self._get_file_writer().add_summary(\n            histogram_raw(tag,\n                          min,\n                          max,\n                          num,\n                          sum,\n                          sum_squares,\n                          bucket_limits,\n                          bucket_counts),\n            global_step,\n            walltime)\n\n    def add_image(self, tag, img_tensor, global_step=None, walltime=None, dataformats=\'CHW\'):\n        """"""Add image data to summary.\n\n        Note that this requires the ``pillow`` package.\n\n        Args:\n            tag (string): Data identifier\n            img_tensor (torch.Tensor, numpy.array, or string/blobname): An `uint8` or `float`\n                Tensor of shape `[channel, height, width]` where `channel` is 1, 3, or 4.\n                The elements in img_tensor can either have values in [0, 1] (float32) or [0, 255] (uint8).\n                Users are responsible to scale the data in the correct range/type.\n            global_step (int): Global step value to record\n            walltime (float): Optional override default walltime (time.time()) of event.\n            dataformats (string): This parameter specifies the meaning of each dimension of the input tensor.\n        Shape:\n            img_tensor: Default is :math:`(3, H, W)`. You can use ``torchvision.utils.make_grid()`` to\n            convert a batch of tensor into 3xHxW format or use ``add_images()`` and let us do the job.\n            Tensor with :math:`(1, H, W)`, :math:`(H, W)`, :math:`(H, W, 3)` is also suitible as long as\n            corresponding ``dataformats`` argument is passed. e.g. CHW, HWC, HW.\n\n        Examples::\n\n            from tensorboardX import SummaryWriter\n            import numpy as np\n            img = np.zeros((3, 100, 100))\n            img[0] = np.arange(0, 10000).reshape(100, 100) / 10000\n            img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n\n            img_HWC = np.zeros((100, 100, 3))\n            img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000\n            img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n\n            writer = SummaryWriter()\n            writer.add_image(\'my_image\', img, 0)\n\n            # If you have non-default dimension setting, set the dataformats argument.\n            writer.add_image(\'my_image_HWC\', img_HWC, 0, dataformats=\'HWC\')\n            writer.close()\n\n        Expected result:\n\n        .. image:: _static/img/tensorboard/add_image.png\n           :scale: 50 %\n\n        """"""\n        if self._check_caffe2_blob(img_tensor):\n            img_tensor = workspace.FetchBlob(img_tensor)\n        self._get_file_writer().add_summary(\n            image(tag, img_tensor, dataformats=dataformats), global_step, walltime)\n\n    def add_images(self, tag, img_tensor, global_step=None, walltime=None, dataformats=\'NCHW\'):\n        """"""Add batched (4D) image data to summary.\n        Besides passing 4D (NCHW) tensor, you can also pass a list of tensors of the same size.\n        In this case, the ``dataformats`` should be `CHW` or `HWC`.\n        Note that this requires the ``pillow`` package.\n\n        Args:\n            tag (string): Data identifier\n            img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data\n                The elements in img_tensor can either have values in [0, 1] (float32) or [0, 255] (uint8).\n                Users are responsible to scale the data in the correct range/type.\n            global_step (int): Global step value to record\n            walltime (float): Optional override default walltime (time.time()) of event\n        Shape:\n            img_tensor: Default is :math:`(N, 3, H, W)`. If ``dataformats`` is specified, other shape will be\n            accepted. e.g. NCHW or NHWC.\n\n        Examples::\n\n            from tensorboardX import SummaryWriter\n            import numpy as np\n\n            img_batch = np.zeros((16, 3, 100, 100))\n            for i in range(16):\n                img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i\n                img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i\n\n            writer = SummaryWriter()\n            writer.add_images(\'my_image_batch\', img_batch, 0)\n            writer.close()\n\n        Expected result:\n\n        .. image:: _static/img/tensorboard/add_images.png\n           :scale: 30 %\n\n        """"""\n        if self._check_caffe2_blob(img_tensor):\n            img_tensor = workspace.FetchBlob(img_tensor)\n        if isinstance(img_tensor, list):  # a list of tensors in CHW or HWC\n            if dataformats.upper() != \'CHW\' and dataformats.upper() != \'HWC\':\n                print(\'A list of image is passed, but the dataformat is neither CHW nor HWC.\')\n                print(\'Nothing is written.\')\n                return\n            import torch\n            try:\n                img_tensor = torch.stack(img_tensor, 0)\n            except TypeError as e:\n                import numpy as np\n                img_tensor = np.stack(img_tensor, 0)\n\n            dataformats = \'N\' + dataformats\n\n        self._get_file_writer().add_summary(\n            image(tag, img_tensor, dataformats=dataformats), global_step, walltime)\n\n    def add_image_with_boxes(self, tag, img_tensor, box_tensor, global_step=None,\n                             walltime=None, dataformats=\'CHW\', labels=None, **kwargs):\n        """"""Add image and draw bounding boxes on the image.\n\n        Args:\n            tag (string): Data identifier\n            img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data\n            box_tensor (torch.Tensor, numpy.array, or string/blobname): Box data (for detected objects)\n              box should be represented as [x1, y1, x2, y2].\n            global_step (int): Global step value to record\n            walltime (float): Optional override default walltime (time.time()) of event\n            labels (list of string): The strings to be show on each bounding box.\n        Shape:\n            img_tensor: Default is :math:`(3, H, W)`. It can be specified with ``dataformats`` argument.\n            e.g. CHW or HWC\n\n            box_tensor: (torch.Tensor, numpy.array, or string/blobname): NX4,  where N is the number of\n            boxes and each 4 elememts in a row represents (xmin, ymin, xmax, ymax).\n        """"""\n        if self._check_caffe2_blob(img_tensor):\n            img_tensor = workspace.FetchBlob(img_tensor)\n        if self._check_caffe2_blob(box_tensor):\n            box_tensor = workspace.FetchBlob(box_tensor)\n        if labels is not None:\n            if isinstance(labels, str):\n                labels = [labels]\n            if len(labels) != box_tensor.shape[0]:\n                logging.warning(\'Number of labels do not equal to number of box, skip the labels.\')\n                labels = None\n        self._get_file_writer().add_summary(image_boxes(\n            tag, img_tensor, box_tensor, dataformats=dataformats, labels=labels, **kwargs), global_step, walltime)\n\n    def add_figure(self, tag, figure, global_step=None, close=True, walltime=None):\n        """"""Render matplotlib figure into an image and add it to summary.\n\n        Note that this requires the ``matplotlib`` package.\n\n        Args:\n            tag (string): Data identifier\n            figure (matplotlib.pyplot.figure) or list of figures: Figure or a list of figures\n            global_step (int): Global step value to record\n            close (bool): Flag to automatically close the figure\n            walltime (float): Optional override default walltime (time.time()) of event\n        """"""\n        if isinstance(figure, list):\n            self.add_image(tag, figure_to_image(figure, close), global_step, walltime, dataformats=\'NCHW\')\n        else:\n            self.add_image(tag, figure_to_image(figure, close), global_step, walltime, dataformats=\'CHW\')\n\n    def add_video(self, tag, vid_tensor, global_step=None, fps=4, walltime=None):\n        """"""Add video data to summary.\n\n        Note that this requires the ``moviepy`` package.\n\n        Args:\n            tag (string): Data identifier\n            vid_tensor (torch.Tensor): Video data\n            global_step (int): Global step value to record\n            fps (float or int): Frames per second\n            walltime (float): Optional override default walltime (time.time()) of event\n        Shape:\n            vid_tensor: :math:`(N, T, C, H, W)`. The values should lie in [0, 255] for type\n              `uint8` or [0, 1] for type `float`.\n        """"""\n        self._get_file_writer().add_summary(\n            video(tag, vid_tensor, fps), global_step, walltime)\n\n    def add_audio(self, tag, snd_tensor, global_step=None, sample_rate=44100, walltime=None):\n        """"""Add audio data to summary.\n\n        Args:\n            tag (string): Data identifier\n            snd_tensor (torch.Tensor): Sound data\n            global_step (int): Global step value to record\n            sample_rate (int): sample rate in Hz\n            walltime (float): Optional override default walltime (time.time()) of event\n        Shape:\n            snd_tensor: :math:`(1, L)`. The values should lie between [-1, 1].\n        """"""\n        if self._check_caffe2_blob(snd_tensor):\n            snd_tensor = workspace.FetchBlob(snd_tensor)\n        self._get_file_writer().add_summary(\n            audio(tag, snd_tensor, sample_rate=sample_rate), global_step, walltime)\n\n    def add_text(self, tag, text_string, global_step=None, walltime=None):\n        """"""Add text data to summary.\n\n        Args:\n            tag (string): Data identifier\n            text_string (string): String to save\n            global_step (int): Global step value to record\n            walltime (float): Optional override default walltime (time.time()) of event\n        Examples::\n\n            writer.add_text(\'lstm\', \'This is an lstm\', 0)\n            writer.add_text(\'rnn\', \'This is an rnn\', 10)\n        """"""\n        self._get_file_writer().add_summary(\n            text(tag, text_string), global_step, walltime)\n\n    def add_onnx_graph(self, onnx_model_file):\n        """"""Add onnx graph to TensorBoard.\n\n        Args:\n            onnx_model_file (string): The path to the onnx model.\n        """"""\n        self._get_file_writer().add_onnx_graph(load_onnx_graph(onnx_model_file))\n\n    def add_openvino_graph(self, xmlname):\n        """"""Add openvino graph to TensorBoard.\n\n        Args:\n            xmlname (string): The path to the openvino model. (the xml file)\n        """"""\n        self._get_file_writer().add_openvino_graph(load_openvino_graph(xmlname))\n\n    def add_graph(self, model, input_to_model=None, verbose=False, profile_with_cuda=False, **kwargs):\n        # prohibit second call?\n        # no, let tensorboard handle it and show its warning message.\n        """"""Add graph data to summary.\n\n        Args:\n            model (torch.nn.Module): Model to draw.\n            input_to_model (torch.Tensor or list of torch.Tensor): A variable or a tuple of\n                variables to be fed.\n            verbose (bool): Whether to print graph structure in console.\n            omit_useless_nodes (bool): Default to ``true``, which eliminates unused nodes.\n            operator_export_type (string): One of: ``""ONNX""``, ``""RAW""``. This determines\n                the optimization level of the graph. If error happens during exporting\n                the graph, using ``""RAW""`` might help.\n\n        """"""\n        if hasattr(model, \'forward\'):\n            # A valid PyTorch model should have a \'forward\' method\n            import torch\n            from distutils.version import LooseVersion\n            if LooseVersion(torch.__version__) >= LooseVersion(""0.3.1""):\n                pass\n            else:\n                if LooseVersion(torch.__version__) >= LooseVersion(""0.3.0""):\n                    print(\'You are using PyTorch==0.3.0, use add_onnx_graph()\')\n                    return\n                if not hasattr(torch.autograd.Variable, \'grad_fn\'):\n                    print(\'add_graph() only supports PyTorch v0.2.\')\n                    return\n            self._get_file_writer().add_graph(graph(model, input_to_model, verbose, profile_with_cuda, **kwargs))\n        else:\n            # Caffe2 models do not have the \'forward\' method\n            from caffe2.proto import caffe2_pb2\n            from caffe2.python import core\n            from .caffe2_graph import (\n                model_to_graph_def, nets_to_graph_def, protos_to_graph_def\n            )\n            if isinstance(model, list):\n                if isinstance(model[0], core.Net):\n                    current_graph = nets_to_graph_def(\n                        model, **kwargs)\n                elif isinstance(model[0], caffe2_pb2.NetDef):\n                    current_graph = protos_to_graph_def(\n                        model, **kwargs)\n            else:\n                # Handles cnn.CNNModelHelper, model_helper.ModelHelper\n                current_graph = model_to_graph_def(\n                    model, **kwargs)\n            event = event_pb2.Event(\n                graph_def=current_graph.SerializeToString())\n            self._get_file_writer().add_event(event)\n\n    @staticmethod\n    def _encode(rawstr):\n        # I\'d use urllib but, I\'m unsure about the differences from python3 to python2, etc.\n        retval = rawstr\n        retval = retval.replace(""%"", ""%%%02x"" % (ord(""%"")))\n        retval = retval.replace(""/"", ""%%%02x"" % (ord(""/"")))\n        retval = retval.replace(""\\\\"", ""%%%02x"" % (ord(""\\\\"")))\n        return retval\n\n    def add_embedding(self, mat, metadata=None, label_img=None, global_step=None, tag=\'default\', metadata_header=None):\n        r""""""Add embedding projector data to summary.\n\n        Args:\n            mat (torch.Tensor or numpy.array): A matrix which each row is the feature vector of the data point\n            metadata (list): A list of labels, each element will be convert to string\n            label_img (torch.Tensor or numpy.array): Images correspond to each data point. Each image should\n                be square. The amount and size of the images are limited by the Tensorboard frontend,\n                see limits below.\n            global_step (int): Global step value to record\n            tag (string): Name for the embedding\n        Shape:\n            mat: :math:`(N, D)`, where N is number of data and D is feature dimension\n\n            label_img: :math:`(N, C, H, W)`, where `Height` should be equal to `Width`.\n            Also, :math:`\\sqrt{N}*W` must be less than or equal to 8192, so that the generated sprite\n            image can be loaded by the Tensorboard frontend\n            (see `tensorboardX#516 <https://github.com/lanpa/tensorboardX/issues/516>`_ for more).\n\n        Examples::\n\n            import keyword\n            import torch\n            meta = []\n            while len(meta)<100:\n                meta = meta+keyword.kwlist # get some strings\n            meta = meta[:100]\n\n            for i, v in enumerate(meta):\n                meta[i] = v+str(i)\n\n            label_img = torch.rand(100, 3, 32, 32)\n            for i in range(100):\n                label_img[i]*=i/100.0\n\n            writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\n            writer.add_embedding(torch.randn(100, 5), label_img=label_img)\n            writer.add_embedding(torch.randn(100, 5), metadata=meta)\n        """"""\n\n        # programmer\'s note: This function has nothing to do with event files.\n        # The hard-coded projector_config.pbtxt is the only source for TensorBoard\'s\n        # current implementation. (as of Dec. 2019)\n        from .x2num import make_np\n        mat = make_np(mat)\n        if global_step is None:\n            global_step = 0\n            # clear pbtxt?\n        # Maybe we should encode the tag so slashes don\'t trip us up?\n        # I don\'t think this will mess us up, but better safe than sorry.\n        subdir = ""%s/%s"" % (str(global_step).zfill(5), self._encode(tag))\n        save_path = os.path.join(self._get_file_writer().get_logdir(), subdir)\n        try:\n            os.makedirs(save_path)\n        except OSError:\n            print(\n                \'warning: Embedding dir exists, did you set global_step for add_embedding()?\')\n        if metadata is not None:\n            assert mat.shape[0] == len(\n                metadata), \'#labels should equal with #data points\'\n            make_tsv(metadata, save_path, metadata_header=metadata_header)\n        if label_img is not None:\n            assert mat.shape[0] == label_img.shape[0], \'#images should equal with #data points\'\n            assert label_img.shape[2] == label_img.shape[3], \'Image should be square, see tensorflow/tensorboard#670\'\n            make_sprite(label_img, save_path)\n        assert mat.ndim == 2, \'mat should be 2D, where mat.size(0) is the number of data points\'\n        make_mat(mat, save_path)\n        # new funcion to append to the config file a new embedding\n        append_pbtxt(metadata, label_img,\n                     self._get_file_writer().get_logdir(), subdir, global_step, tag)\n\n    def add_pr_curve(self, tag, labels, predictions, global_step=None,\n                     num_thresholds=127, weights=None, walltime=None):\n        """"""Adds precision recall curve.\n        Plotting a precision-recall curve lets you understand your model\'s\n        performance under different threshold settings. With this function,\n        you provide the ground truth labeling (T/F) and prediction confidence\n        (usually the output of your model) for each target. The TensorBoard UI\n        will let you choose the threshold interactively.\n\n        Args:\n            tag (string): Data identifier\n            labels (torch.Tensor, numpy.array, or string/blobname):\n              Ground truth data. Binary label for each element.\n            predictions (torch.Tensor, numpy.array, or string/blobname):\n              The probability that an element be classified as true.\n              Value should in [0, 1]\n            global_step (int): Global step value to record\n            num_thresholds (int): Number of thresholds used to draw the curve.\n            walltime (float): Optional override default walltime (time.time()) of event\n\n        Examples::\n\n            from tensorboardX import SummaryWriter\n            import numpy as np\n            labels = np.random.randint(2, size=100)  # binary label\n            predictions = np.random.rand(100)\n            writer = SummaryWriter()\n            writer.add_pr_curve(\'pr_curve\', labels, predictions, 0)\n            writer.close()\n\n        """"""\n        from .x2num import make_np\n        labels, predictions = make_np(labels), make_np(predictions)\n        self._get_file_writer().add_summary(\n            pr_curve(tag, labels, predictions, num_thresholds, weights),\n            global_step, walltime)\n\n    def add_pr_curve_raw(self, tag, true_positive_counts,\n                         false_positive_counts,\n                         true_negative_counts,\n                         false_negative_counts,\n                         precision,\n                         recall,\n                         global_step=None,\n                         num_thresholds=127,\n                         weights=None,\n                         walltime=None):\n        """"""Adds precision recall curve with raw data.\n\n        Args:\n            tag (string): Data identifier\n            true_positive_counts (torch.Tensor, numpy.array, or string/blobname): true positive counts\n            false_positive_counts (torch.Tensor, numpy.array, or string/blobname): false positive counts\n            true_negative_counts (torch.Tensor, numpy.array, or string/blobname): true negative counts\n            false_negative_counts (torch.Tensor, numpy.array, or string/blobname): false negative counts\n            precision (torch.Tensor, numpy.array, or string/blobname): precision\n            recall (torch.Tensor, numpy.array, or string/blobname): recall\n            global_step (int): Global step value to record\n            num_thresholds (int): Number of thresholds used to draw the curve.\n            walltime (float): Optional override default walltime (time.time()) of event\n            see: https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/README.md\n        """"""\n        self._get_file_writer().add_summary(\n            pr_curve_raw(tag,\n                         true_positive_counts,\n                         false_positive_counts,\n                         true_negative_counts,\n                         false_negative_counts,\n                         precision,\n                         recall,\n                         num_thresholds,\n                         weights),\n            global_step,\n            walltime)\n\n    def add_custom_scalars_multilinechart(self, tags, category=\'default\', title=\'untitled\'):\n        """"""Shorthand for creating multilinechart. Similar to ``add_custom_scalars()``, but the only necessary argument\n        is *tags*.\n\n        Args:\n            tags (list): list of tags that have been used in ``add_scalar()``\n\n        Examples::\n\n            writer.add_custom_scalars_multilinechart([\'twse/0050\', \'twse/2330\'])\n        """"""\n        layout = {category: {title: [\'Multiline\', tags]}}\n        self._get_file_writer().add_summary(custom_scalars(layout))\n\n    def add_custom_scalars_marginchart(self, tags, category=\'default\', title=\'untitled\'):\n        """"""Shorthand for creating marginchart. Similar to ``add_custom_scalars()``, but the only necessary argument\n        is *tags*, which should have exactly 3 elements.\n\n        Args:\n            tags (list): list of tags that have been used in ``add_scalar()``\n\n        Examples::\n\n            writer.add_custom_scalars_marginchart([\'twse/0050\', \'twse/2330\', \'twse/2006\'])\n        """"""\n        assert len(tags) == 3\n        layout = {category: {title: [\'Margin\', tags]}}\n        self._get_file_writer().add_summary(custom_scalars(layout))\n\n    def add_custom_scalars(self, layout):\n        """"""Create special chart by collecting charts tags in \'scalars\'. Note that this function can only be called once\n        for each SummaryWriter() object. Because it only provides metadata to tensorboard, the function can be called\n        before or after the training loop. See ``examples/demo_custom_scalars.py`` for more.\n\n        Args:\n            layout (dict): {categoryName: *charts*}, where *charts* is also a dictionary\n              {chartName: *ListOfProperties*}. The first element in *ListOfProperties* is the chart\'s type\n              (one of **Multiline** or **Margin**) and the second element should be a list containing the tags\n              you have used in add_scalar function, which will be collected into the new chart.\n\n        Examples::\n\n            layout = {\'Taiwan\':{\'twse\':[\'Multiline\',[\'twse/0050\', \'twse/2330\']]},\n                         \'USA\':{ \'dow\':[\'Margin\',   [\'dow/aaa\', \'dow/bbb\', \'dow/ccc\']],\n                              \'nasdaq\':[\'Margin\',   [\'nasdaq/aaa\', \'nasdaq/bbb\', \'nasdaq/ccc\']]}}\n\n            writer.add_custom_scalars(layout)\n        """"""\n        self._get_file_writer().add_summary(custom_scalars(layout))\n\n    def add_mesh(self, tag, vertices, colors=None, faces=None, config_dict=None, global_step=None, walltime=None):\n        """"""Add meshes or 3D point clouds to TensorBoard. The visualization is based on Three.js,\n        so it allows users to interact with the rendered object. Besides the basic definitions\n        such as vertices, faces, users can further provide camera parameter, lighting condition, etc.\n        Please check https://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene for\n        advanced usage. Note that currently this depends on tb-nightly to show.\n\n        Args:\n            tag (string): Data identifier\n            vertices (torch.Tensor): List of the 3D coordinates of vertices.\n            colors (torch.Tensor): Colors for each vertex\n            faces (torch.Tensor): Indices of vertices within each triangle. (Optional)\n            config_dict: Dictionary with ThreeJS classes names and configuration.\n            global_step (int): Global step value to record\n            walltime (float): Optional override default walltime (time.time())\n              seconds after epoch of event\n\n        Shape:\n            vertices: :math:`(B, N, 3)`. (batch, number_of_vertices, channels). If you see nothing on\n              tensorboard, try normalizing the values to [-1, 1].\n\n            colors: :math:`(B, N, 3)`. The values should lie in [0, 255].\n\n            faces: :math:`(B, N, 3)`. The values should lie in [0, number_of_vertices] for type `uint8`.\n\n        Examples::\n\n            from tensorboardX import SummaryWriter\n            vertices_tensor = np.array([[\n                [1, 1, 1],\n                [-1, -1, 1],\n                [1, -1, -1],\n                [-1, 1, -1],\n            ]], dtype=float)\n            colors_tensor = np.array([[\n                [255, 0, 0],\n                [0, 255, 0],\n                [0, 0, 255],\n                [255, 0, 255],\n            ]], dtype=int)\n            faces_tensor = np.array([[\n                [0, 2, 3],\n                [0, 3, 1],\n                [0, 1, 2],\n                [1, 3, 2],\n            ]], dtype=int)\n\n            writer = SummaryWriter()\n            writer.add_mesh(\'my_mesh\', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor)\n\n            writer.close()\n        """"""\n        self._get_file_writer().add_summary(mesh(tag, vertices, colors, faces, config_dict), global_step, walltime)\n\n    def close(self):\n        """"""Close the current SummaryWriter. This call flushes the unfinished write operation.\n        Use context manager (with statement) whenever it\'s possible.\n        """"""\n        if self.all_writers is None:\n            return  # ignore double close\n        for writer in self.all_writers.values():\n            writer.flush()\n            writer.close()\n        self.file_writer = self.all_writers = None\n\n    def flush(self):\n        """"""Force the data in memory to be flushed to disk. Use this call if tensorboard does not update reqularly.\n        Another way is to set the `flush_secs` when creating the SummaryWriter.\n        """"""\n        if self.all_writers is None:\n            return  # ignore double close\n        for writer in self.all_writers.values():\n            writer.flush()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n'"
tensorboardX/x2num.py,1,"b""# DO NOT alter/distruct/free input object !\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport logging\nimport numpy as np\nimport six\n\n\ndef check_nan(array):\n    tmp = np.sum(array)\n    if np.isnan(tmp) or np.isinf(tmp):\n        logging.warning('NaN or Inf found in input tensor.')\n    return array\n\n\ndef make_np(x):\n    if isinstance(x, list):\n        return check_nan(np.array(x))\n    if isinstance(x, np.ndarray):\n        return check_nan(x)\n    if isinstance(x, six.string_types):  # Caffe2 will pass name of blob(s) to fetch\n        return check_nan(prepare_caffe2(x))\n    if np.isscalar(x):\n        return check_nan(np.array([x]))\n    if 'torch' in str(type(x)):\n        return check_nan(prepare_pytorch(x))\n    if 'chainer' in str(type(x)):\n        return check_nan(prepare_chainer(x))\n    if 'mxnet' in str(type(x)):\n        return check_nan(prepare_mxnet(x))\n    raise NotImplementedError(\n        'Got {}, but expected numpy array or torch tensor.'.format(type(x)))\n\n\ndef prepare_pytorch(x):\n    import torch\n    if isinstance(x, torch.autograd.Variable):\n        x = x.data\n    x = x.cpu().numpy()\n    return x\n\n\ndef prepare_theano(x):\n    import theano\n    pass\n\n\ndef prepare_caffe2(x):\n    from caffe2.python import workspace\n    x = workspace.FetchBlob(x)\n    return x\n\n\ndef prepare_mxnet(x):\n    x = x.asnumpy()\n    return x\n\n\ndef prepare_chainer(x):\n    import chainer\n    x = chainer.cuda.to_cpu(x.data)\n    return x\n"""
tests/__init__.py,0,b'import torch\nimport tensorboardX.proto\n'
tests/event_file_writer_test.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n# """"""Tests for EventFileWriter and _AsyncWriter""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\nimport glob\nimport os\nfrom tensorboardX.event_file_writer import EventFileWriter\nfrom tensorboardX.event_file_writer import EventFileWriter as _AsyncWriter\n\n\nfrom tensorboardX.proto import event_pb2\nfrom tensorboardX.proto.summary_pb2 import Summary\n\nfrom tensorboard.compat.tensorflow_stub.pywrap_tensorflow import PyRecordReader_New\nimport unittest\n\n\nclass EventFileWriterTest(unittest.TestCase):\n  def get_temp_dir(self):\n    import tempfile\n    return tempfile.mkdtemp()\n\n  def test_event_file_writer_roundtrip(self):\n    _TAGNAME = \'dummy\'\n    _DUMMY_VALUE = 42\n    logdir = self.get_temp_dir()\n    w = EventFileWriter(logdir)\n    summary = Summary(value=[Summary.Value(tag=_TAGNAME, simple_value=_DUMMY_VALUE)])\n    fakeevent = event_pb2.Event(summary=summary)\n    w.add_event(fakeevent)\n    w.close()\n    event_files = sorted(glob.glob(os.path.join(logdir, \'*\')))\n    self.assertEqual(len(event_files), 1)\n    r = PyRecordReader_New(event_files[0])\n    r.GetNext()  # meta data, so skip\n    r.GetNext()\n    self.assertEqual(fakeevent.SerializeToString(), r.record())\n\n  def test_setting_filename_suffix_works(self):\n    logdir = self.get_temp_dir()\n\n    w = EventFileWriter(logdir, filename_suffix=\'.event_horizon\')\n    w.close()\n    event_files = sorted(glob.glob(os.path.join(logdir, \'*\')))\n    self.assertEqual(event_files[0].split(\'.\')[-1], \'event_horizon\')\n\n  def test_async_writer_without_write(self):\n    logdir = self.get_temp_dir()\n    w = EventFileWriter(logdir)\n    w.close()\n    event_files = sorted(glob.glob(os.path.join(logdir, \'*\')))\n    r = PyRecordReader_New(event_files[0])\n    r.GetNext()\n    s = event_pb2.Event.FromString(r.record())\n    self.assertEqual(s.file_version, ""brain.Event:2"")\n\n\n# skip the test, because tensorboard\'s implementaion of filewriter\n# writes raw data while that in tensorboardX writes event protobuf.\nclass AsyncWriterTest(): #unittest.TestCase):\n  def get_temp_dir(self):\n    import tempfile\n    return tempfile.mkdtemp()\n\n  def test_async_writer_write_once(self):\n    foldername = os.path.join(self.get_temp_dir(), ""async_writer_write_once"")\n    w = _AsyncWriter(foldername)\n    filename = w._ev_writer._file_name\n    bytes_to_write = b""hello world""\n    w.add_event(bytes_to_write)\n    w.close()\n    with open(filename, \'rb\') as f:\n      self.assertEqual(f.read(), bytes_to_write)\n\n  def test_async_writer_write_queue_full(self):\n    filename = os.path.join(self.get_temp_dir(), ""async_writer_write_queue_full"")\n    w = _AsyncWriter(filename)\n    bytes_to_write = b""hello world""\n    repeat = 100\n    for i in range(repeat):\n      w.write(bytes_to_write)\n    w.close()\n    with open(filename, \'rb\') as f:\n      self.assertEqual(f.read(), bytes_to_write * repeat)\n\n  def test_async_writer_write_one_slot_queue(self):\n    filename = os.path.join(self.get_temp_dir(), ""async_writer_write_one_slot_queue"")\n    w = _AsyncWriter(filename, max_queue_size=1)\n    bytes_to_write = b""hello world""\n    repeat = 10  # faster\n    for i in range(repeat):\n      w.write(bytes_to_write)\n    w.close()\n    with open(filename, \'rb\') as f:\n      self.assertEqual(f.read(), bytes_to_write * repeat)\n\n  def test_async_writer_close_triggers_flush(self):\n    filename = os.path.join(self.get_temp_dir(), ""async_writer_close_triggers_flush"")\n    w = _AsyncWriter(filename)\n    bytes_to_write = b""x"" * 64\n    w.write(bytes_to_write)\n    w.close()\n    with open(filename, \'rb\') as f:\n      self.assertEqual(f.read(), bytes_to_write)\n\n  def test_write_after_async_writer_closed(self):\n    filename = os.path.join(self.get_temp_dir(), ""write_after_async_writer_closed"")\n    w = _AsyncWriter(filename)\n    bytes_to_write = b""x"" * 64\n    w.write(bytes_to_write)\n    w.close()\n\n    with self.assertRaises(IOError):\n      w.write(bytes_to_write)\n    # nothing is written to the file after close\n    with open(filename, \'rb\') as f:\n      self.assertEqual(f.read(), bytes_to_write)\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
tests/expect_reader.py,0,"b'from __future__ import absolute_import, division, print_function, unicode_literals\nimport os\nimport sys\n\n\ndef removeWhiteChar(string):\n    return string.replace(\' \', \'\').replace(\'\\t\', \'\').replace(\'\\n\', \'\')\n\n\ndef compare_proto(str_to_compare, function_ptr):\n    module_id = function_ptr.__class__.__module__\n    functionName = function_ptr.id().split(\'.\')[-1]\n    test_file = os.path.realpath(sys.modules[module_id].__file__)\n    expected_file = os.path.join(os.path.dirname(test_file),\n                        ""expect"",\n                        module_id.split(\'.\')[-1] + \'.\' + functionName + "".expect"")\n    print(""expected_file: %s"" % expected_file)\n    assert os.path.exists(expected_file)\n    with open(expected_file) as f:\n        expected = f.read()\n    str_to_compare = str(str_to_compare)\n    print(""str_to_compare:"", removeWhiteChar(str_to_compare))\n    print(""expected:"", removeWhiteChar(expected))\n    assert removeWhiteChar(str_to_compare) == removeWhiteChar(expected)\n\n\ndef write_proto(str_to_compare, function_ptr):\n    module_id = function_ptr.__class__.__module__\n    functionName = function_ptr.id().split(\'.\')[-1]\n    test_file = os.path.realpath(sys.modules[module_id].__file__)\n    expected_file = os.path.join(os.path.dirname(test_file),\n                    ""expect"",\n                    module_id.split(\'.\')[-1] + \'.\' + functionName + "".expect"")\n    print(expected_file)\n    with open(expected_file, \'w\') as f:\n        f.write(str(str_to_compare))\n'"
tests/record_writer_test.py,0,"b'# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n# """"""Tests for RecordWriter""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport six\nimport os\nfrom tensorboardX.record_writer import RecordWriter\nfrom tensorboard.compat.tensorflow_stub.pywrap_tensorflow import PyRecordReader_New\nimport unittest\n\n\nclass RecordWriterTest(unittest.TestCase):\n  def get_temp_dir(self):\n    import tempfile\n    return tempfile.mkdtemp()\n\n  def test_expect_bytes_written(self):\n    filename = os.path.join(self.get_temp_dir(), ""expect_bytes_written"")\n    byte_len = 64\n    w = RecordWriter(filename)\n    bytes_to_write = b""x"" * byte_len\n    w.write(bytes_to_write)\n    w.close()\n    with open(filename, \'rb\') as f:\n      self.assertEqual(len(f.read()), (8 + 4 + byte_len + 4))  # uint64+uint32+data+uint32\n\n  def test_empty_record(self):\n    filename = os.path.join(self.get_temp_dir(), ""empty_record"")\n    w = RecordWriter(filename)\n    bytes_to_write = b""""\n    w.write(bytes_to_write)\n    w.close()\n    r = PyRecordReader_New(filename)\n    r.GetNext()\n    self.assertEqual(r.record(), bytes_to_write)\n\n  def test_record_writer_roundtrip(self):\n    filename = os.path.join(self.get_temp_dir(), ""record_writer_roundtrip"")\n    w = RecordWriter(filename)\n    bytes_to_write = b""hello world""\n    times_to_test = 50\n    for _ in range(times_to_test):\n      w.write(bytes_to_write)\n    w.close()\n\n    r = PyRecordReader_New(filename)\n    for i in range(times_to_test):\n      r.GetNext()\n      self.assertEqual(r.record(), bytes_to_write)\n\n  # def test_expect_bytes_written_bytes_IO(self):\n  #   byte_len = 64\n  #   Bytes_io = six.BytesIO()\n  #   w = RecordWriter(Bytes_io)\n  #   bytes_to_write = b""x"" * byte_len\n  #   w.write(bytes_to_write)\n  #   self.assertEqual(len(Bytes_io.getvalue()), (8 + 4 + byte_len + 4))  # uint64+uint32+data+uint32\n\n\nif __name__ == \'__main__\':\n  unittest.main()\n'"
tests/test_beholder.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorboardX import SummaryWriter\nimport numpy as np\nimport pytest\nimport unittest\nimport tensorboardX.beholder as beholder_lib\nimport tensorboardX.beholder.file_system_tools as fio\nfrom collections import namedtuple\n\n\nclass BeholderTest(unittest.TestCase):\n    def test_beholder(self):\n        LOG_DIRECTORY = '/tmp/beholder-demo'\n        tensor_and_name = namedtuple('tensor_and_name', 'tensor, name')\n        fake_param = [tensor_and_name(np.random.randn(128, 768, 3), 'test' + str(i)) for i in range(5)]\n        arrays = [tensor_and_name(np.random.randn(128, 768, 3), 'test' + str(i)) for i in range(5)]\n        beholder = beholder_lib.Beholder(logdir=LOG_DIRECTORY)\n        beholder.update(\n            trainable=fake_param,\n            arrays=arrays,\n            frame=np.random.randn(128, 128),\n        )\n\n    def test_beholder_video(self):\n        LOG_DIRECTORY = '/tmp/beholder-demo-recording'\n        tensor_and_name = namedtuple('tensor_and_name', 'tensor, name')\n        fake_param = [tensor_and_name(np.random.randn(128, 768, 3), 'test' + str(i)) for i in range(5)]\n        arrays = [tensor_and_name(np.random.randn(128, 768, 3), 'test' + str(i)) for i in range(5)]\n        beholder = beholder_lib.Beholder(logdir=LOG_DIRECTORY)\n        pkl = fio.read_pickle(LOG_DIRECTORY + '/plugins/beholder/config.pkl')\n        pkl['is_recording'] = True\n        fio.write_pickle(pkl, LOG_DIRECTORY + '/plugins/beholder/config.pkl')\n        for i in range(3):\n            if i == 2:\n                pkl = fio.read_pickle(LOG_DIRECTORY + '/plugins/beholder/config.pkl')\n                pkl['is_recording'] = False\n                fio.write_pickle(pkl, LOG_DIRECTORY + '/plugins/beholder/config.pkl')\n            beholder.update(\n                trainable=fake_param,\n                arrays=arrays,\n                frame=np.random.randn(128, 128),\n            )\n"""
tests/test_caffe2.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom tensorboardX import SummaryWriter\nimport os\nimport unittest\n\n# try:\nimport numpy as np\nimport caffe2.python.brew as brew\nimport caffe2.python.cnn as cnn\nimport caffe2.python.core as core\nimport caffe2.python.model_helper as model_helper\nfrom caffe2.proto import caffe2_pb2\nfrom caffe2.python import workspace\nimport tensorboardX.caffe2_graph as tb\nfrom tensorboardX import x2num\nfrom .expect_reader import compare_proto, write_proto\n\n\nclass Caffe2Test(unittest.TestCase):\n    def test_caffe2_np(self):\n        workspace.FeedBlob(""testBlob"", np.random.randn(1, 3, 64, 64).astype(np.float32))\n        assert isinstance(x2num.make_np(\'testBlob\'), np.ndarray)\n        # assert isinstance(x2num.make_np(\'testBlob\', \'IMG\'), np.ndarray)\n\n    def test_that_operators_gets_non_colliding_names(self):\n        op = caffe2_pb2.OperatorDef()\n        op.type = \'foo\'\n        op.input.extend([\'foo\'])\n        tb._fill_missing_operator_names([op])\n        self.assertEqual(op.input[0], \'foo\')\n        self.assertEqual(op.name, \'foo_1\')\n\n    def test_that_replacing_colons_gives_non_colliding_names(self):\n        # .. and update shapes\n        op = caffe2_pb2.OperatorDef()\n        op.name = \'foo:0\'\n        op.input.extend([\'foo:0\', \'foo$0\'])\n        shapes = {\'foo:0\': [1]}\n        blob_name_tracker = tb._get_blob_names([op])\n        tb._replace_colons(shapes, blob_name_tracker, [op], \'$\')\n        self.assertEqual(op.input[0], \'foo$0\')\n        self.assertEqual(op.input[1], \'foo$0_1\')\n        # Collision but blobs and op names are handled later by\n        # _fill_missing_operator_names.\n        self.assertEqual(op.name, \'foo$0\')\n        self.assertEqual(len(shapes), 1)\n        self.assertEqual(shapes[\'foo$0\'], [1])\n        self.assertEqual(len(blob_name_tracker), 2)\n        self.assertEqual(blob_name_tracker[\'foo$0\'], \'foo:0\')\n        self.assertEqual(blob_name_tracker[\'foo$0_1\'], \'foo$0\')\n\n    def test_that_adding_gradient_scope_does_no_fancy_renaming(self):\n        # because it cannot create collisions\n        op = caffe2_pb2.OperatorDef()\n        op.name = \'foo_grad\'\n        op.input.extend([\'foo_grad\', \'foo_grad_1\'])\n        shapes = {\'foo_grad\': [1]}\n        blob_name_tracker = tb._get_blob_names([op])\n        tb._add_gradient_scope(shapes, blob_name_tracker, [op])\n        self.assertEqual(op.input[0], \'GRADIENTS/foo_grad\')\n        self.assertEqual(op.input[1], \'GRADIENTS/foo_grad_1\')\n        self.assertEqual(op.name, \'GRADIENTS/foo_grad\')\n        self.assertEqual(len(shapes), 1)\n        self.assertEqual(shapes[\'GRADIENTS/foo_grad\'], [1])\n        self.assertEqual(len(blob_name_tracker), 2)\n        self.assertEqual(\n            blob_name_tracker[\'GRADIENTS/foo_grad\'], \'foo_grad\')\n        self.assertEqual(\n            blob_name_tracker[\'GRADIENTS/foo_grad_1\'], \'foo_grad_1\')\n\n    def test_that_auto_ssa_gives_non_colliding_names(self):\n        op1 = caffe2_pb2.OperatorDef()\n        op1.output.extend([\'foo\'])\n        op2 = caffe2_pb2.OperatorDef()\n        op2.input.extend([\'foo\'])\n        op2.output.extend([\'foo\'])\n        op2.output.extend([\'foo_1\'])\n        shapes = {\'foo\': [1], \'foo_1\': [2]}\n        blob_name_tracker = tb._get_blob_names([op1, op2])\n        tb._convert_to_ssa(shapes, blob_name_tracker, [op1, op2])\n        self.assertEqual(op1.output[0], \'foo\')\n        self.assertEqual(op2.input[0], \'foo\')\n        self.assertEqual(op2.output[0], \'foo_1\')\n        # Unfortunate name but we do not parse original `_` for now.\n        self.assertEqual(op2.output[1], \'foo_1_1\')\n        self.assertEqual(len(shapes), 3)\n        self.assertEqual(shapes[\'foo\'], [1])\n        self.assertEqual(shapes[\'foo_1\'], [1])\n        self.assertEqual(shapes[\'foo_1_1\'], [2])\n        self.assertEqual(len(blob_name_tracker), 3)\n        self.assertEqual(blob_name_tracker[\'foo\'], \'foo\')\n        self.assertEqual(blob_name_tracker[\'foo_1\'], \'foo\')\n        self.assertEqual(blob_name_tracker[\'foo_1_1\'], \'foo_1\')\n\n    def test_renaming_tensorflow_style(self):\n        # Construct some dummy operators here\n        # NOTE: \'_w\', \'_bn\', etc without the postfix \'_\' are only renamed when\n        # they are at the very end of the name.\n        # Test that \'_w\', \'_w_\' are renamed to \'/weight\', \'/weight_\', resp.\n        op1 = caffe2_pb2.OperatorDef()\n        op1.input.extend([\'foo_w\'])\n        op1.output.extend([\'foo_w_2\'])\n        # Test that \'_bn\', \'_bn_\' are renamed to \'/batchnorm\', \'/batchnorm_\',\n        # respectively.\n        op2 = caffe2_pb2.OperatorDef()\n        op2.input.extend([\'foo_bn\'])\n        op2.output.extend([\'foo_bn_2\'])\n        # Test that \'_b\', \'_b_\', are renamed to \'/bias\', \'/bias_\', resp.\n        op3 = caffe2_pb2.OperatorDef()\n        op3.input.extend([\'foo_b\'])\n        op3.output.extend([\'foo_b_2\'])\n        # Test that \'_s\', \'_s_\', are renamed to \'/scale\', \'/scale_\', resp.\n        op4 = caffe2_pb2.OperatorDef()\n        op4.input.extend([\'foo_s\'])\n        op4.output.extend([\'foo_s_2\'])\n        # Test that \'_sum\', \'_sum_\', are renamed to \'/sum\', \'/sum_\', resp.\n        op5 = caffe2_pb2.OperatorDef()\n        op5.input.extend([\'foo_sum\'])\n        op5.output.extend([\'foo_sum_2\'])\n        # Test that \'_branch\', \'_branch_\', are renamed to \'/branch\', \'/branch_\',\n        # respectively. Multiple inputs/outputs are also tested in this case.\n        op6 = caffe2_pb2.OperatorDef()\n        op6.input.extend([\'foo_branch\'])\n        op6.input.extend([\'test_branch_2\'])\n        op6.output.extend([\'foo_branch_3\'])\n        op6.output.extend([\'test_branch4\'])\n        shapes = {\n            \'foo_w\': [1], \'foo_w_2\': [2], \'foo_bn\': [3], \'foo_bn_2\': [4],\n            \'foo_b\': [5], \'foo_b_2\': [6], \'foo_s\': [7], \'foo_s_2\': [8],\n            \'foo_sum\': [9], \'foo_sum_2\': [10], \'foo_branch\': [11],\n            \'test_branch_2\': [12], \'foo_branch_3\': [13], \'test_branch4\': [14],\n        }\n        ops = [op1, op2, op3, op4, op5, op6]\n        blob_name_tracker = tb._get_blob_names(ops)\n        tb._rename_tensorflow_style(shapes, blob_name_tracker, ops)\n        # Testing that keys in blob name tracker were renamed correctly\n        self.assertEqual(blob_name_tracker[\'foo/weight\'], \'foo_w\')\n        self.assertEqual(blob_name_tracker[\'foo/weight_2\'], \'foo_w_2\')\n        self.assertEqual(blob_name_tracker[\'foo/batchnorm\'], \'foo_bn\')\n        self.assertEqual(blob_name_tracker[\'foo/batchnorm_2\'], \'foo_bn_2\')\n        self.assertEqual(blob_name_tracker[\'foo/bias\'], \'foo_b\')\n        self.assertEqual(blob_name_tracker[\'foo/bias_2\'], \'foo_b_2\')\n        self.assertEqual(blob_name_tracker[\'foo/scale\'], \'foo_s\')\n        self.assertEqual(blob_name_tracker[\'foo/scale_2\'], \'foo_s_2\')\n        self.assertEqual(blob_name_tracker[\'foo/sum\'], \'foo_sum\')\n        self.assertEqual(blob_name_tracker[\'foo/sum_2\'], \'foo_sum_2\')\n        self.assertEqual(blob_name_tracker[\'foo/branch\'], \'foo_branch\')\n        self.assertEqual(blob_name_tracker[\'test/branch_2\'], \'test_branch_2\')\n        self.assertEqual(blob_name_tracker[\'foo/branch_3\'], \'foo_branch_3\')\n        self.assertEqual(blob_name_tracker[\'test/branch4\'], \'test_branch4\')\n        # Testing that keys in shapes were renamed correctly\n        self.assertEqual(shapes[\'foo/weight\'], [1])\n        self.assertEqual(shapes[\'foo/batchnorm_2\'], [4])\n        self.assertEqual(shapes[\'foo/sum\'], [9])\n        self.assertEqual(shapes[\'test/branch_2\'], [12])\n        # Testing that the ops were renamed correctly\n        self.assertEqual(op1.input[0], \'foo/weight\')\n        self.assertEqual(op1.output[0], \'foo/weight_2\')\n        self.assertEqual(op2.input[0], \'foo/batchnorm\')\n        self.assertEqual(op2.output[0], \'foo/batchnorm_2\')\n        self.assertEqual(op3.input[0], \'foo/bias\')\n        self.assertEqual(op3.output[0], \'foo/bias_2\')\n        self.assertEqual(op4.input[0], \'foo/scale\')\n        self.assertEqual(op4.output[0], \'foo/scale_2\')\n        self.assertEqual(op5.input[0], \'foo/sum\')\n        self.assertEqual(op5.output[0], \'foo/sum_2\')\n        self.assertEqual(op6.input[0], \'foo/branch\')\n        self.assertEqual(op6.input[1], \'test/branch_2\')\n        self.assertEqual(op6.output[0], \'foo/branch_3\')\n        self.assertEqual(op6.output[1], \'test/branch4\')\n\n    def test_filter_ops(self):\n        op1 = caffe2_pb2.OperatorDef()\n        op1.input.extend([\'remove_this\'])\n        op1.output.extend([\'random_output\'])\n        op2 = caffe2_pb2.OperatorDef()\n        op2.input.extend([\'leave_this\'])\n        op2.output.extend([\'leave_this_also\'])\n        op3 = caffe2_pb2.OperatorDef()\n        op3.input.extend([\'random_input\'])\n        op3.output.extend([\'remove_this_also\'])\n\n        def filter_fn(blob):\n            # Filter all blobs with names containing \'remove\'\n            return \'remove\' not in str(blob)\n\n        op_set1 = [op1, op2, op3]\n        op_set2 = [op1, op2, op3]\n\n        # Test case for when perform_filter = True.\n        result_ops1 = tb._filter_ops(op_set1, filter_fn, True)\n        new_op1, new_op2 = result_ops1[0], result_ops1[1]\n        # input named \'remove_this\' should have been filtered\n        self.assertEqual(len(new_op1.input), 0)\n        self.assertEqual(new_op1.output, [\'random_output\'])\n        self.assertEqual(new_op2.input, [\'leave_this\'])\n        self.assertEqual(new_op2.output, [\'leave_this_also\'])\n        # output named \'remove_this_also\' should have been filtered as well.\n        # This should have also removed op3 as the filter function excludes ops\n        # with no outputs.\n        self.assertEqual(len(result_ops1), 2)\n\n        # Test case for when perform_filter = False. op_set2 should remain\n        # unchanged.\n        result_ops2 = tb._filter_ops(op_set2, filter_fn, False)\n        self.assertEqual(result_ops2, op_set2)\n\n    # Use show_simplified=False. This shows the original style of graph\n    # visualization from caffe2.contrib.tensorboard.\n    # TODO: Add test for show_simplified=True.\n    def test_simple_cnnmodel(self):\n        model = cnn.CNNModelHelper(""NCHW"", name=""overfeat"")\n        workspace.FeedBlob(""data"", np.random.randn(1, 3, 64, 64).astype(np.float32))\n        workspace.FeedBlob(""label"", np.random.randn(1, 1000).astype(np.int))\n        with core.NameScope(""conv1""):\n            conv1 = model.Conv(""data"", ""conv1"", 3, 96, 11, stride=4)\n            relu1 = model.Relu(conv1, conv1)\n            pool1 = model.MaxPool(relu1, ""pool1"", kernel=2, stride=2)\n        with core.NameScope(""classifier""):\n            fc = model.FC(pool1, ""fc"", 4096, 1000)\n            pred = model.Softmax(fc, ""pred"")\n            xent = model.LabelCrossEntropy([pred, ""label""], ""xent"")\n            loss = model.AveragedLoss(xent, ""loss"")\n\n        blob_name_tracker = {}\n        graph = tb.model_to_graph_def(\n            model,\n            blob_name_tracker=blob_name_tracker,\n            shapes={},\n            show_simplified=False,\n        )\n\n        compare_proto(graph, self)\n\n    # cnn.CNNModelHelper is deprecated, so we also test with\n    # model_helper.ModelHelper. The model used in this test is taken from the\n    # Caffe2 MNIST tutorial. Also use show_simplified=False here.\n    def test_simple_model(self):\n        model = model_helper.ModelHelper(name=""mnist"")\n        # how come those inputs don\'t break the forward pass =.=a\n        workspace.FeedBlob(""data"", np.random.randn(1, 3, 64, 64).astype(np.float32))\n        workspace.FeedBlob(""label"", np.random.randn(1, 1000).astype(np.int))\n\n        with core.NameScope(""conv1""):\n            conv1 = brew.conv(model, ""data"", \'conv1\', dim_in=1, dim_out=20, kernel=5)\n            # Image size: 24 x 24 -> 12 x 12\n            pool1 = brew.max_pool(model, conv1, \'pool1\', kernel=2, stride=2)\n            # Image size: 12 x 12 -> 8 x 8\n            conv2 = brew.conv(model, pool1, \'conv2\', dim_in=20, dim_out=100, kernel=5)\n            # Image size: 8 x 8 -> 4 x 4\n            pool2 = brew.max_pool(model, conv2, \'pool2\', kernel=2, stride=2)\n        with core.NameScope(""classifier""):\n            # 50 * 4 * 4 stands for dim_out from previous layer multiplied by the image size\n            fc3 = brew.fc(model, pool2, \'fc3\', dim_in=100 * 4 * 4, dim_out=500)\n            relu = brew.relu(model, fc3, fc3)\n            pred = brew.fc(model, relu, \'pred\', 500, 10)\n            softmax = brew.softmax(model, pred, \'softmax\')\n            xent = model.LabelCrossEntropy([softmax, ""label""], \'xent\')\n            # compute the expected loss\n            loss = model.AveragedLoss(xent, ""loss"")\n        model.net.RunAllOnMKL()\n        model.param_init_net.RunAllOnMKL()\n        model.AddGradientOperators([loss], skip=1)\n        blob_name_tracker = {}\n        graph = tb.model_to_graph_def(\n            model,\n            blob_name_tracker=blob_name_tracker,\n            shapes={},\n            show_simplified=False,\n        )\n\n        compare_proto(graph, self)\n\n\nif __name__ == ""__main__"":\n    unittest.main()\n'"
tests/test_chainer_np.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom tensorboardX import x2num, SummaryWriter\ntry:\n    import chainer\n    chainer_installed = True\nexcept ImportError:\n    print('Chainer is not installed, skipping test')\n    chainer_installed = False\nimport numpy as np\nimport unittest\n\n\nif chainer_installed:\n    chainer.Variable\n    tensors = [chainer.Variable(np.random.rand(3, 10, 10)),\n               chainer.Variable(np.random.rand(1)),\n               chainer.Variable(np.random.rand(1, 2, 3, 4, 5))]\n\n    class ChainerTest(unittest.TestCase):\n        def test_chainer_np(self):\n            for tensor in tensors:\n                # regular variable\n                assert isinstance(x2num.make_np(tensor), np.ndarray)\n\n            # python primitive type\n            assert(isinstance(x2num.make_np(0), np.ndarray))\n            assert(isinstance(x2num.make_np(0.1), np.ndarray))\n\n        def test_chainer_img(self):\n            shapes = [(77, 3, 13, 7), (77, 1, 13, 7), (3, 13, 7), (1, 13, 7), (13, 7)]\n            for s in shapes:\n                x = chainer.Variable(np.random.random_sample(s))\n                # assert x2num.make_np(x, 'IMG').shape[2] == 3\n\n        def test_chainer_write(self):\n            with SummaryWriter() as w:\n                w.add_scalar('scalar', chainer.Variable(np.random.rand(1)), 0)\n"""
tests/test_crc32c.py,0,"b""import unittest\nfrom tensorboardX.crc32c import _crc32c, _crc32c_native, crc32c\n\n\nclass CRC32CTest(unittest.TestCase):\n    def test_crc32c(self):\n        data = b'abcd'\n        assert crc32c(data) == 0x92c80a31\n\n    def test_crc32c_python(self):\n        data = b'abcd'\n        assert _crc32c(data) == 0x92c80a31\n\n    def test_crc32c_native(self):\n        if _crc32c_native is None:\n            return\n        data = b'abcd'\n        assert _crc32c_native(data) == 0x92c80a31\n"""
tests/test_embedding.py,13,"b'import unittest\nimport torch\nimport boto3\nfrom tensorboardX import SummaryWriter\nfrom moto import mock_s3\n\n\n\nclass EmbeddingTest(unittest.TestCase):\n    def test_embedding(self):\n        w = SummaryWriter()\n        all_features = torch.Tensor([[1, 2, 3], [5, 4, 1], [3, 7, 7]])\n        all_labels = torch.Tensor([33, 44, 55])\n        all_images = torch.zeros(3, 3, 5, 5)\n\n        w.add_embedding(all_features,\n                        metadata=all_labels,\n                        label_img=all_images,\n                        global_step=2)\n\n        dataset_label = [\'test\'] * 2 + [\'train\'] * 2\n        all_labels = list(zip(all_labels, dataset_label))\n        w.add_embedding(all_features,\n                        metadata=all_labels,\n                        label_img=all_images,\n                        metadata_header=[\'digit\', \'dataset\'],\n                        global_step=2)\n\n    def test_embedding_64(self):\n        w = SummaryWriter()\n        all_features = torch.Tensor([[1, 2, 3], [5, 4, 1], [3, 7, 7]])\n        all_labels = torch.Tensor([33, 44, 55])\n        all_images = torch.zeros((3, 3, 5, 5), dtype=torch.float64)\n\n        w.add_embedding(all_features,\n                        metadata=all_labels,\n                        label_img=all_images,\n                        global_step=2)\n\n        dataset_label = [\'test\'] * 2 + [\'train\'] * 2\n        all_labels = list(zip(all_labels, dataset_label))\n        w.add_embedding(all_features,\n                        metadata=all_labels,\n                        label_img=all_images,\n                        metadata_header=[\'digit\', \'dataset\'],\n                        global_step=2)\n\n    def test_embedding_square(self):\n        w = SummaryWriter(comment=\'sq\')\n        all_features = torch.rand(228,256)\n        all_images = torch.rand(228, 3, 32, 32)\n        for i in range(all_images.shape[0]):\n            all_images[i] *= (float(i)+60)/(all_images.shape[0]+60)\n        w.add_embedding(all_features,\n                        label_img=all_images,\n                        global_step=2)\n\n    def test_embedding_fail(self):\n        with self.assertRaises(AssertionError):\n            w = SummaryWriter(comment=\'shouldfail\')\n            all_features = torch.rand(228,256)\n            all_images = torch.rand(228, 3, 16, 32)\n            for i in range(all_images.shape[0]):\n                all_images[i] *= (float(i)+60)/(all_images.shape[0]+60)\n            w.add_embedding(all_features,\n                            label_img=all_images,\n                            global_step=2)\n    @mock_s3\n    def test_embedding_s3_mock(self):\n        client = boto3.client(\'s3\', region_name=\'us-east-1\')\n        client.create_bucket(Bucket=\'this\')\n        w = SummaryWriter(""s3://this/is/apen"")\n        all_features = torch.Tensor([[1, 2, 3], [5, 4, 1], [3, 7, 7]])\n        all_labels = torch.Tensor([33, 44, 55])\n        all_images = torch.zeros(3, 3, 5, 5)\n\n        w.add_embedding(all_features,\n                        metadata=all_labels,\n                        label_img=all_images,\n                        global_step=2)\n\n        dataset_label = [\'test\'] * 2 + [\'train\'] * 2\n        all_labels = list(zip(all_labels, dataset_label))\n        w.add_embedding(all_features,\n                        metadata=all_labels,\n                        label_img=all_images,\n                        metadata_header=[\'digit\', \'dataset\'],\n                        global_step=2)\n'"
tests/test_figure.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport matplotlib.pyplot as plt\nimport unittest\n\nfrom tensorboardX import SummaryWriter\n\n\nclass FigureTest(unittest.TestCase):\n    def test_figure(self):\n        writer = SummaryWriter()\n\n        figure, axes = plt.figure(), plt.gca()\n        circle1 = plt.Circle((0.2, 0.5), 0.2, color=\'r\')\n        circle2 = plt.Circle((0.8, 0.5), 0.2, color=\'g\')\n        axes.add_patch(circle1)\n        axes.add_patch(circle2)\n        plt.axis(\'scaled\')\n        plt.tight_layout()\n\n        writer.add_figure(""add_figure/figure"", figure, 0, close=False)\n        assert plt.fignum_exists(figure.number) is True\n\n        writer.add_figure(""add_figure/figure"", figure, 1)\n        assert plt.fignum_exists(figure.number) is False\n\n        writer.close()\n\n    def test_figure_list(self):\n        writer = SummaryWriter()\n\n        figures = []\n        for i in range(5):\n            figure = plt.figure()\n            plt.plot([i * 1, i * 2, i * 3], label=""Plot "" + str(i))\n            plt.xlabel(""X"")\n            plt.xlabel(""Y"")\n            plt.legend()\n            plt.tight_layout()\n            figures.append(figure)\n\n        writer.add_figure(""add_figure/figure_list"", figures, 0, close=False)\n        assert all([plt.fignum_exists(figure.number) is True for figure in figures])\n\n        writer.add_figure(""add_figure/figure_list"", figures, 1)\n        assert all([plt.fignum_exists(figure.number) is False for figure in figures])\n\n        writer.close()\n'"
tests/test_hparams.py,0,"b'import unittest\nimport numpy as np\nfrom tensorboardX import SummaryWriter\n\nhparam = {\'lr\': [0.1, 0.01, 0.001],\n          \'bsize\': [1, 2, 4],\n          \'n_hidden\': [100, 200],\n          \'bn\': [True, False]}\n\nmetrics = {\'accuracy\', \'loss\'}\n\ndef train(lr, bsize, n_hidden):\n    x = lr + bsize + n_hidden\n    return x, x*5\n\n\nclass HparamsTest(unittest.TestCase):\n    def test_smoke(self):\n        i = 0\n        with SummaryWriter() as w:\n            for lr in hparam[\'lr\']:\n                for bsize in hparam[\'bsize\']:\n                    for n_hidden in hparam[\'n_hidden\']:\n                        for bn in hparam[\'bn\']:\n                            accu, loss = train(lr, bsize, n_hidden)\n                            i = i + 1\n                            w.add_hparams({\'lr\': lr, \'bsize\': bsize, \'n_hidden\': n_hidden, \'bn\': bn},\n                                            {\'accuracy\': accu, \'loss\': loss}, name=""trial""+str(i))\n\n'"
tests/test_lint.py,0,"b""def test_linting():\n    import subprocess\n    subprocess.check_output(['flake8', 'tensorboardX'])\n"""
tests/test_numpy.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport numpy as np\nimport unittest\n\nfrom tensorboardX import x2num\n\n\nclass NumpyTest(unittest.TestCase):\n    def test_scalar(self):\n        res = x2num.make_np(1.1)\n        assert isinstance(res, np.ndarray) and res.shape == (1,)\n        res = x2num.make_np(1 << 64 - 1)  # uint64_max\n        assert isinstance(res, np.ndarray) and res.shape == (1,)\n        res = x2num.make_np(np.float16(1.00000087))\n        assert isinstance(res, np.ndarray) and res.shape == (1,)\n        res = x2num.make_np(np.float128(1.00008 + 9))\n        assert isinstance(res, np.ndarray) and res.shape == (1,)\n        res = x2num.make_np(np.int64(100000000000))\n        assert isinstance(res, np.ndarray) and res.shape == (1,)\n\n    def test_make_grid(self):\n        pass\n\n    def test_numpy_vid(self):\n        shapes = [(16, 3, 30, 28, 28), (19, 3, 30, 28, 28), (19, 3, 29, 23, 19)]\n        for s in shapes:\n            x = np.random.random_sample(s)\n            # assert x2num.make_np(x, 'VID').shape[3] == 3\n\n    def test_numpy_vid_uint8(self):\n        x = np.random.randint(0, 256, (16, 3, 30, 28, 28)).astype(np.uint8)\n        # x2num.make_np(x, 'VID').shape[3] == 3\n"""
tests/test_onnx_graph.py,0,"b""import unittest\nimport torch\nfrom tensorboardX import SummaryWriter\n\n\nclass ONNXGraphTest(unittest.TestCase):\n    def test_onnx_graph(self):\n        import subprocess\n        zoo_address = 'https://onnxzoo.blob.core.windows.net/models/opset_8/mnist/mnist.tar.gz'\n\n        res = subprocess.call(['wget', '-nc', zoo_address])\n        assert res == 0, 'cannot download example onnx model from the zoo'\n        res = subprocess.call(['tar', 'xf', 'mnist.tar.gz', '-C', 'examples/', 'mnist/model.onnx'])\n\n        with SummaryWriter() as w:\n            w.add_onnx_graph('examples/mnist/model.onnx')\n"""
tests/test_openvino_graph.py,0,"b""import unittest\nfrom tensorboardX import SummaryWriter\n\nclass OPENVINOGraphTest(unittest.TestCase):\n    def test_openvino_graph(self):\n        with SummaryWriter() as w:\n            w.add_openvino_graph('examples/mobilenetv2.xml')\n"""
tests/test_pr_curve.py,0,"b""import unittest\nimport torch\nimport numpy as np\nfrom tensorboardX import SummaryWriter\nfrom tensorboardX import summary\nfrom .expect_reader import compare_proto\n\nnp.random.seed(0)\ntrue_positive_counts = [75, 64, 21, 5, 0]\nfalse_positive_counts = [150, 105, 18, 0, 0]\ntrue_negative_counts = [0, 45, 132, 150, 150]\nfalse_negative_counts = [0, 11, 54, 70, 75]\nprecision = [0.3333333, 0.3786982, 0.5384616, 1.0, 0.0]\nrecall = [1.0, 0.8533334, 0.28, 0.0666667, 0.0]\n\n\nclass PRCurveTest(unittest.TestCase):\n    def test_smoke(self):\n        with SummaryWriter() as writer:\n            writer.add_pr_curve('xoxo', np.random.randint(2, size=100), np.random.rand(\n                100), 1)\n            writer.add_pr_curve_raw('prcurve with raw data',\n                                    true_positive_counts,\n                                    false_positive_counts,\n                                    true_negative_counts,\n                                    false_negative_counts,\n                                    precision,\n                                    recall,\n                                    1)\n\n    def test_pr_purve(self):\n        random_labels = np.array([0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n            1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n            0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n            1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n            1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0])\n        random_probs = np.array([0.33327776, 0.30032885, 0.79012837, 0.04306813, 0.65221544,\n            0.58481968, 0.28305522, 0.53795795, 0.00729739, 0.52266951,\n            0.22464247, 0.11262435, 0.41573075, 0.92493992, 0.73066758,\n            0.43867735, 0.27955449, 0.56975382, 0.53933028, 0.34392824,\n            0.30312509, 0.81732807, 0.55408544, 0.3969487 , 0.31768033,\n            0.24353266, 0.47198005, 0.19999122, 0.05788022, 0.24046305,\n            0.04651082, 0.30061738, 0.78321545, 0.82670207, 0.49200517,\n            0.80904619, 0.96711993, 0.3160946 , 0.01049424, 0.60108337,\n            0.56508792, 0.83729429, 0.9717386 , 0.46306053, 0.80232138,\n            0.24166823, 0.7393237 , 0.50820418, 0.04944932, 0.53854157,\n            0.10765172, 0.84723855, 0.20518299, 0.3143431 , 0.51299074,\n            0.47065695, 0.54267833, 0.1812676 , 0.06265177, 0.34110327,\n            0.30915171, 0.91870169, 0.91309447, 0.31395817, 0.36780571,\n            0.98297986, 0.00594547, 0.52839042, 0.70229202, 0.37779588,\n            0.15207045, 0.59759632, 0.72397032, 0.71502195, 0.90135725,\n            0.43970107, 0.17123532, 0.08785938, 0.04986818, 0.62702444,\n            0.69171023, 0.30537792, 0.30285433, 0.27124347, 0.27693729,\n            0.7136039 , 0.48022489, 0.20916285, 0.2018599 , 0.92401008,\n            0.30189681, 0.46862626, 0.96353024, 0.30468533, 0.68281294,\n            0.30623562, 0.40795975, 0.76824531, 0.89824215, 0.69845035], dtype=np.float16)\n        compare_proto(summary.pr_curve('tag', random_labels, random_probs, 1), self)\n\n    def test_pr_purve_raw(self):\n        compare_proto(summary.pr_curve_raw('prcurve with raw data',\n                                           true_positive_counts,\n                                           false_positive_counts,\n                                           true_negative_counts,\n                                           false_negative_counts,\n                                           precision,\n                                           recall,\n                                           1),\n                      self)\n"""
tests/test_pytorch_graph.py,5,"b""from __future__ import absolute_import, division, print_function, unicode_literals\nimport unittest\nimport torch\nfrom tensorboardX import SummaryWriter\n\n\nclass PytorchGraphTest(unittest.TestCase):\n    def test_pytorch_graph(self):\n        dummy_input = (torch.zeros(1, 3),)\n\n        class myLinear(torch.nn.Module):\n            def __init__(self):\n                super(myLinear, self).__init__()\n                self.linear = torch.nn.Linear(3, 5)\n\n            def forward(self, x):\n                return self.linear(x)\n\n        with SummaryWriter(comment='LinearModel') as w:\n            w.add_graph(myLinear(), dummy_input, True)\n\n    def test_wrong_input_size(self):\n        print('expect error here:')\n        with self.assertRaises(RuntimeError):\n            dummy_input = torch.rand(1, 9)\n            model = torch.nn.Linear(3, 5)\n            with SummaryWriter(comment='expect_error') as w:\n                w.add_graph(model, dummy_input)  # error\n"""
tests/test_pytorch_np.py,10,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nfrom tensorboardX import x2num, SummaryWriter\nimport torch\nimport numpy as np\nimport unittest\n\n\nclass PyTorchNumpyTest(unittest.TestCase):\n    def test_pytorch_np(self):\n        tensors = [torch.rand(3, 10, 10), torch.rand(1), torch.rand(1, 2, 3, 4, 5)]\n        for tensor in tensors:\n            # regular tensor\n            assert isinstance(x2num.make_np(tensor), np.ndarray)\n\n            # CUDA tensor\n            if torch.cuda.device_count() > 0:\n                assert isinstance(x2num.make_np(tensor.cuda()), np.ndarray)\n\n            # regular variable\n            assert isinstance(x2num.make_np(torch.autograd.Variable(tensor)), np.ndarray)\n\n            # CUDA variable\n            if torch.cuda.device_count() > 0:\n                assert isinstance(x2num.make_np(torch.autograd.Variable(tensor).cuda()), np.ndarray)\n\n        # python primitive type\n        assert(isinstance(x2num.make_np(0), np.ndarray))\n        assert(isinstance(x2num.make_np(0.1), np.ndarray))\n\n    def test_pytorch_write(self):\n        with SummaryWriter() as w:\n            w.add_scalar('scalar', torch.autograd.Variable(torch.rand(1)), 0)\n\n    def test_pytorch_histogram(self):\n        with SummaryWriter() as w:\n            w.add_histogram('float histogram', torch.rand((50,)))\n            w.add_histogram('int histogram', torch.randint(0, 100, (50,)))\n\n    def test_pytorch_histogram_raw(self):\n        with SummaryWriter() as w:\n            num = 50\n            floats = x2num.make_np(torch.rand((num,)))\n            bins = [0.0, 0.25, 0.5, 0.75, 1.0]\n            counts, limits = np.histogram(floats, bins)\n            sum_sq = floats.dot(floats).item()\n            w.add_histogram_raw('float histogram raw',\n                                min=floats.min().item(),\n                                max=floats.max().item(),\n                                num=num,\n                                sum=floats.sum().item(),\n                                sum_squares=sum_sq,\n                                bucket_limits=limits[1:].tolist(),\n                                bucket_counts=counts.tolist())\n\n            ints = x2num.make_np(torch.randint(0, 100, (num,)))\n            bins = [0, 25, 50, 75, 100]\n            counts, limits = np.histogram(ints, bins)\n            sum_sq = ints.dot(ints).item()\n            w.add_histogram_raw('int histogram raw',\n                                min=ints.min().item(),\n                                max=ints.max().item(),\n                                num=num,\n                                sum=ints.sum().item(),\n                                sum_squares=sum_sq,\n                                bucket_limits=limits[1:].tolist(),\n                                bucket_counts=counts.tolist())\n"""
tests/test_record_writer.py,0,"b'from tensorboardX import SummaryWriter\nimport unittest\nfrom tensorboardX.record_writer import S3RecordWriter, make_valid_tf_name, GCSRecordWriter\nimport os\nimport boto3\nfrom moto import mock_s3\n\nos.environ.setdefault(""AWS_ACCESS_KEY_ID"", ""foobar_key"")\nos.environ.setdefault(""AWS_SECRET_ACCESS_KEY"", ""foobar_secret"")\n\n\nclass RecordWriterTest(unittest.TestCase):\n    @mock_s3\n    def test_record_writer_s3(self):\n        client = boto3.client(\'s3\', region_name=\'us-east-1\')\n        client.create_bucket(Bucket=\'this\')\n        writer = S3RecordWriter(\'s3://this/is/apen\')\n        bucket, path = writer.bucket_and_path()\n        assert bucket == \'this\'\n        assert path == \'is/apen\'\n        writer.write(bytes(42))\n        writer.flush()\n\n    def test_make_valid_tf_name(self):\n        newname = make_valid_tf_name(\'$ave/&sound\')\n        assert newname == \'._ave/_sound\'\n\n    def test_record_writer_gcs(self):\n        pass\n        # we don\'t have mock test, so expect error here. However,\n        # Travis CI env won\'t raise exception for the following code,\n        # so I commented it out.\n        # with self.assertRaises(Exception):\n        #   writer = GCSRecordWriter(\'gs://this/is/apen\')\n        #   writer.write(bytes(42))\n        #   writer.flush()\n'"
tests/test_summary.py,0,"b'from __future__ import absolute_import, division, print_function, unicode_literals\nfrom tensorboardX import summary\nfrom .expect_reader import compare_proto, write_proto\nimport numpy as np\nimport pytest\nimport unittest\n# compare_proto = write_proto  # massive update expect\n\ndef tensor_N(shape, dtype=float):\n    numel = np.prod(shape)\n    x = (np.arange(numel, dtype=dtype)).reshape(shape)\n    return x\n\nclass SummaryTest(unittest.TestCase):\n    def test_uint8_image(self):\n        \'\'\'\n        Tests that uint8 image (pixel values in [0, 255]) is not changed\n        \'\'\'\n        test_image = tensor_N(shape=(3, 32, 32), dtype=np.uint8)\n        compare_proto(summary.image(\'dummy\', test_image), self)\n\n    def test_float32_image(self):\n        \'\'\'\n        Tests that float32 image (pixel values in [0, 1]) are scaled correctly\n        to [0, 255]\n        \'\'\'\n        test_image = tensor_N(shape=(3, 32, 32))\n        compare_proto(summary.image(\'dummy\', test_image), self)\n\n    def test_float_1_converts_to_uint8_255(self):\n        green_uint8 = np.array([[[0, 255, 0]]], dtype=\'uint8\') \n        green_float32 = np.array([[[0, 1, 0]]], dtype=\'float32\') \n\n        a = summary.image(tensor=green_uint8, tag=\'\')\n        b = summary.image(tensor=green_float32, tag=\'\')\n        self.assertEqual(a, b)\n\n    def test_list_input(self):\n        with pytest.raises(Exception):\n            summary.histogram(\'dummy\', [1, 3, 4, 5, 6], \'tensorflow\')\n\n    def test_empty_input(self):\n        print(\'expect error here:\')\n        with pytest.raises(Exception):\n            summary.histogram(\'dummy\', np.ndarray(0), \'tensorflow\')\n\n    def test_image_with_boxes(self):\n        compare_proto(summary.image_boxes(\'dummy\',\n                            tensor_N(shape=(3, 32, 32)),\n                            np.array([[10, 10, 40, 40]])), self)\n\n    def test_image_with_one_channel(self):\n        compare_proto(summary.image(\'dummy\', tensor_N(shape=(1, 8, 8)), dataformats=\'CHW\'), self)\n\n    def test_image_with_four_channel(self):\n        compare_proto(summary.image(\'dummy\', tensor_N(shape=(4, 8, 8)), dataformats=\'CHW\'), self)\n\n    def test_image_with_one_channel_batched(self):\n        compare_proto(summary.image(\'dummy\', tensor_N(shape=(2, 1, 8, 8)), dataformats=\'NCHW\'), self)\n\n    def test_image_with_3_channel_batched(self):\n        compare_proto(summary.image(\'dummy\', tensor_N(shape=(2, 3, 8, 8)), dataformats=\'NCHW\'), self)\n\n    def test_image_with_four_channel_batched(self):\n        compare_proto(summary.image(\'dummy\', tensor_N(shape=(2, 4, 8, 8)), dataformats=\'NCHW\'), self)\n\n    def test_image_without_channel(self):\n        compare_proto(summary.image(\'dummy\', tensor_N(shape=(8, 8)), dataformats=\'HW\'), self)\n\n    def test_video(self):\n        try:\n            import moviepy\n        except ImportError:\n            return\n        compare_proto(summary.video(\'dummy\', tensor_N(shape=(4, 3, 1, 8, 8))), self)\n        summary.video(\'dummy\', tensor_N(shape=(16, 48, 1, 28, 28)))\n        summary.video(\'dummy\', tensor_N(shape=(20, 7, 1, 8, 8)))\n\n    def test_audio(self):\n        compare_proto(summary.audio(\'dummy\', tensor_N(shape=(42,))), self)\n\n    def test_text(self):\n        compare_proto(summary.text(\'dummy\', \'text 123\'), self)\n\n    def test_histogram_auto(self):\n        compare_proto(summary.histogram(\'dummy\', tensor_N(shape=(1024,)), bins=\'auto\', max_bins=5), self)\n\n    def test_histogram_fd(self):\n        compare_proto(summary.histogram(\'dummy\', tensor_N(shape=(1024,)), bins=\'fd\', max_bins=5), self)\n\n    def test_histogram_doane(self):\n        compare_proto(summary.histogram(\'dummy\', tensor_N(shape=(1024,)), bins=\'doane\', max_bins=5), self)\n\n    def test_custom_scalars(self):\n        layout = {\'Taiwan\': {\'twse\': [\'Multiline\', [\'twse/0050\', \'twse/2330\']]},\n                    \'USA\': {\'dow\': [\'Margin\', [\'dow/aaa\', \'dow/bbb\', \'dow/ccc\']],\n                            \'nasdaq\': [\'Margin\', [\'nasdaq/aaa\', \'nasdaq/bbb\', \'nasdaq/ccc\']]}}\n        summary.custom_scalars(layout)  # smoke test only.\n\n    def test_mesh(self):\n        vertices_tensor = np.array([[\n            [1, 1, 1],\n            [-1, -1, 1],\n            [1, -1, -1],\n            [-1, 1, -1],\n        ]], dtype=float)\n        colors_tensor = np.array([[\n            [255, 0, 0],\n            [0, 255, 0],\n            [0, 0, 255],\n            [255, 0, 255],\n        ]], dtype=int)\n        faces_tensor = np.array([[\n            [0, 2, 3],\n            [0, 3, 1],\n            [0, 1, 2],\n            [1, 3, 2],\n        ]], dtype=int)\n        compare_proto(summary.mesh(\'my_mesh\', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor), self)\n\n    # It\'s hard to get dictionary sorted with same result in various envs. So only use one key per dict.\n    def test_hparams(self):\n        hp = {\'lr\': 0.1}\n        mt = {\'accuracy\': 0.1}\n        compare_proto(summary.hparams(hp, mt), self)\n\n    def test_hparams_bool(self):\n        hp = {\'bool_var\': True}\n        mt = {\'accuracy\': 0.1}\n        compare_proto(summary.hparams(hp, mt), self)\n\n    def test_hparams_string(self):\n        hp = {\'string_var\': ""hi""}\n        mt = {\'accuracy\': 0.1}\n        compare_proto(summary.hparams(hp, mt), self)\n\n    def test_hparams_smoke(self):\n        hp = {\'lr\': 0.1, \'bsize\': 4}\n        mt = {\'accuracy\': 0.1, \'loss\': 10}\n        summary.hparams(hp, mt)\n        \n        hp = {\'string\': ""1b"", \'use magic\': True}\n        summary.hparams(hp, mt)\n'"
tests/test_summary_writer.py,0,"b'from tensorboardX import SummaryWriter\nimport unittest\n\n\nclass SummaryWriterTest(unittest.TestCase):\n    def test_summary_writer_ctx(self):\n        # after using a SummaryWriter as a ctx it should be closed\n        with SummaryWriter(filename_suffix=\'.test\') as writer:\n            writer.add_scalar(\'test\', 1)\n        assert writer.file_writer is None\n\n    def test_summary_writer_backcomapt(self):\n        with SummaryWriter(log_dir=\'/tmp/tbxtest\') as writer:\n            writer.add_scalar(\'test\', 1)\n\n    def test_summary_writer_close(self):\n        # Opening and closing SummaryWriter a lot should not run into\n        # OSError: [Errno 24] Too many open files\n        for i in range(1000):\n            writer = SummaryWriter()\n            writer.close()\n\n    def test_windowsPath(self):\n        dummyPath = ""C:\\\\Downloads\\\\fjoweifj02utj43tj430""\n        with SummaryWriter(dummyPath) as writer:\n            writer.add_scalar(\'test\', 1)\n        import shutil\n        shutil.rmtree(dummyPath)\n\n    def test_pathlib(self):\n        import sys\n        if sys.version_info.major == 2:\n            import pathlib2 as pathlib\n        else:\n            import pathlib\n        p = pathlib.Path(\'./pathlibtest\')\n        with SummaryWriter(p) as writer:\n            writer.add_scalar(\'test\', 1)\n        import shutil\n        shutil.rmtree(str(p))\n\n    def test_dummy_summary_writer(self):\n        # You can\'t write to root folder without sudo.\n        with SummaryWriter(\'/\', write_to_disk=False) as writer:\n            writer.add_scalar(\'test\', 1)\n            writer.flush()'"
tests/test_utils.py,0,"b""from tensorboardX import summary\nfrom tensorboardX.utils import make_grid, _prepare_video, convert_to_HWC\nimport numpy as np\nimport pytest\nimport unittest\n\n\nclass UtilsTest(unittest.TestCase):\n    def test_to_HWC(self):\n        np.random.seed(1)\n        test_image = np.random.randint(0, 256, size=(3, 32, 32), dtype=np.uint8)\n        converted = convert_to_HWC(test_image, 'chw')\n        assert converted.shape == (32, 32, 3)\n        test_image = np.random.randint(0, 256, size=(16, 3, 32, 32), dtype=np.uint8)\n        converted = convert_to_HWC(test_image, 'nchw')\n        assert converted.shape == (64, 256, 3)\n        test_image = np.random.randint(0, 256, size=(32, 32), dtype=np.uint8)\n        converted = convert_to_HWC(test_image, 'hw')\n        assert converted.shape == (32, 32, 3)\n\n    def test_prepare_video(self):\n        # at each timestep the sum over all other dimensions of the video should stay the same\n        np.random.seed(1)\n        V_before = np.random.random((4, 10, 3, 20, 20))\n        V_after = _prepare_video(np.copy(V_before))\n        V_before = np.swapaxes(V_before, 0, 1)\n        V_before = np.reshape(V_before, newshape=(10, -1))\n        V_after = np.reshape(V_after, newshape=(10, -1))\n        np.testing.assert_array_almost_equal(np.sum(V_before, axis=1), np.sum(V_after, axis=1))\n"""
tests/test_visdom.py,0,"b""from tensorboardX import TorchVis\n\nimport numpy as np\nimport pytest\nimport unittest\n\ntrue_positive_counts = [75, 64, 21, 5, 0]\nfalse_positive_counts = [150, 105, 18, 0, 0]\ntrue_negative_counts = [0, 45, 132, 150, 150]\nfalse_negative_counts = [0, 11, 54, 70, 75]\nprecision = [0.3333333, 0.3786982, 0.5384616, 1.0, 0.0]\nrecall = [1.0, 0.8533334, 0.28, 0.0666667, 0.0]\n\n\nclass VisdomTest(unittest.TestCase):\n    def test_TorchVis(self):\n        w = TorchVis('visdom')\n        w.add_scalar('scalar_visdom', 1, 0)\n        w.add_scalar('scalar_visdom', 2, 1)\n        w.add_histogram('histogram_visdom', np.array([1, 2, 3, 4, 5]), 1)\n        w.add_image('image_visdom', np.ndarray((3, 20, 20)), 2)\n        # w.add_video('video_visdom', np.random.randn(1, 3, 100, 200, 200), 3)\n        w.add_audio('audio_visdom', [1, 2, 3, 4, 5])\n        w.add_text('text_visdom', 'mystring')\n        w.add_pr_curve('pr_curve_visdom', np.random.randint(2, size=100), np.random.rand(100), 10)\n        w.add_pr_curve_raw('prcurve with raw data',\n                           true_positive_counts,\n                           false_positive_counts,\n                           true_negative_counts,\n                           false_negative_counts,\n                           precision,\n                           recall, 20)\n        del w\n"""
tests/test_writer.py,0,"b'from tensorboardX import SummaryWriter\nfrom tensorboard.compat.tensorflow_stub.pywrap_tensorflow import PyRecordReader_New\nfrom tensorboardX.proto import event_pb2\n\nimport numpy as np\nimport pytest\nimport unittest\nimport time\nfreqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]\n\ntrue_positive_counts = [75, 64, 21, 5, 0]\nfalse_positive_counts = [150, 105, 18, 0, 0]\ntrue_negative_counts = [0, 45, 132, 150, 150]\nfalse_negative_counts = [0, 11, 54, 70, 75]\nprecision = [0.3333333, 0.3786982, 0.5384616, 1.0, 0.0]\nrecall = [1.0, 0.8533334, 0.28, 0.0666667, 0.0]\n\n\nclass WriterTest(unittest.TestCase):\n    def test_flush(self):\n        N_TEST = 5\n        w = SummaryWriter(flush_secs=1)\n        f = w.file_writer.event_writer._ev_writer._file_name\n        for i in range(N_TEST):\n            w.add_scalar(\'a\', i)\n            time.sleep(2)\n        r = PyRecordReader_New(f)\n        r.GetNext()  # meta data, so skip\n        for _ in range(N_TEST):  # all of the data should be flushed\n            r.GetNext()\n\n    def test_flush_timer_is_long_so_data_is_not_there(self):\n        with self.assertRaises(BaseException):\n            N_TEST = 5\n            w = SummaryWriter(flush_secs=20)\n            f = w.file_writer.event_writer._ev_writer._file_name\n            for i in range(N_TEST):\n                w.add_scalar(\'a\', i)\n                time.sleep(2)\n            r = PyRecordReader_New(f)\n            r.GetNext()  # meta data, so skip\n            for _ in range(N_TEST):  # missing data\n                r.GetNext()\n\n    def test_flush_after_close(self):\n        N_TEST = 5\n        w = SummaryWriter(flush_secs=20)\n        f = w.file_writer.event_writer._ev_writer._file_name\n        for i in range(N_TEST):\n            w.add_scalar(\'a\', i)\n            time.sleep(2)\n        w.close()\n        r = PyRecordReader_New(f)\n        r.GetNext()  # meta data, so skip\n        for _ in range(N_TEST):  # all of the data should be flushed\n            r.GetNext()\n\n    def test_flush(self):\n        N_TEST = 5\n        w = SummaryWriter(flush_secs=20)\n        f = w.file_writer.event_writer._ev_writer._file_name\n        for i in range(N_TEST):\n            w.add_scalar(\'a\', i)\n            time.sleep(2)\n        w.flush()\n        r = PyRecordReader_New(f)\n        r.GetNext()  # meta data, so skip\n        for _ in range(N_TEST):  # all of the data should be flushed\n            r.GetNext()\n\n    def test_auto_close(self):\n        pass\n\n    def test_writer(self):\n        with SummaryWriter() as writer:\n            sample_rate = 44100\n\n            n_iter = 0\n            writer.add_scalar(\'data/scalar_systemtime\', 0.1, n_iter)\n            writer.add_scalar(\'data/scalar_customtime\', 0.2, n_iter, walltime=n_iter)\n            writer.add_scalars(\'data/scalar_group\', {""xsinx"": n_iter * np.sin(n_iter),\n                                                     ""xcosx"": n_iter * np.cos(n_iter),\n                                                     ""arctanx"": np.arctan(n_iter)}, n_iter)\n            x = np.zeros((32, 3, 64, 64))  # output from network\n            writer.add_images(\'Image\', x, n_iter)  # Tensor\n            writer.add_image_with_boxes(\'imagebox\',\n                                        np.zeros((3, 64, 64)),\n                                        np.array([[10, 10, 40, 40], [40, 40, 60, 60]]),\n                                        n_iter)\n            x = np.zeros(sample_rate * 2)\n\n            writer.add_audio(\'myAudio\', x, n_iter)\n            writer.add_video(\'myVideo\', np.random.rand(16, 48, 1, 28, 28).astype(np.float32), n_iter)\n            writer.add_text(\'Text\', \'text logged at step:\' + str(n_iter), n_iter)\n            writer.add_text(\'markdown Text\', \'\'\'a|b\\n-|-\\nc|d\'\'\', n_iter)\n            writer.add_histogram(\'hist\', np.random.rand(100, 100), n_iter)\n            writer.add_pr_curve(\'xoxo\', np.random.randint(2, size=100), np.random.rand(\n                100), n_iter)  # needs tensorboard 0.4RC or later\n            writer.add_pr_curve_raw(\'prcurve with raw data\', true_positive_counts,\n                                    false_positive_counts,\n                                    true_negative_counts,\n                                    false_negative_counts,\n                                    precision,\n                                    recall, n_iter)\n            # export scalar data to JSON for external processing\n            writer.export_scalars_to_json(""./all_scalars.json"")\n            imgs = []\n            for i in range(5):\n                imgs.append(np.ones((3, 100, 110)))\n            with SummaryWriter() as w:\n                w.add_images(\'img_list\', imgs, dataformats=\'CHW\')'"
tests/tset_multiprocess_write.py,0,"b""# the file name is intended. pytest don't play well with multiprocessing\n\nfrom tensorboardX import GlobalSummaryWriter as SummaryWriter\nfrom tensorboard.compat.tensorflow_stub.pywrap_tensorflow import PyRecordReader_New\nfrom tensorboardX.proto import event_pb2\nimport multiprocessing as mp\nimport numpy as np\nimport pytest\nimport unittest\nimport time\n\n\nclass GlobalWriterTest(unittest.TestCase):\n    def test_flush(self):\n        N_TEST = 5\n        w = SummaryWriter(flush_secs=1)\n        f = w.file_writer.event_writer._ev_writer._file_name\n        for i in range(N_TEST):\n            w.add_scalar('a', i)\n            time.sleep(2)\n        r = PyRecordReader_New(f)\n        r.GetNext()  # meta data, so skip\n        for _ in range(N_TEST):  # all of the data should be flushed\n            r.GetNext()\n\n    def test_flush_timer_is_long_so_data_is_not_there(self):\n        with self.assertRaises(BaseException):\n            N_TEST = 5\n            w = SummaryWriter(flush_secs=20)\n            f = w.file_writer.event_writer._ev_writer._file_name\n            for i in range(N_TEST):\n                w.add_scalar('a', i)\n                time.sleep(2)\n            r = PyRecordReader_New(f)\n            r.GetNext()  # meta data, so skip\n            for _ in range(N_TEST):  # missing data\n                r.GetNext()\n\n    def test_flush_after_close(self):\n        N_TEST = 5\n        w = SummaryWriter(flush_secs=20)\n        f = w.file_writer.event_writer._ev_writer._file_name\n        for i in range(N_TEST):\n            w.add_scalar('a', i)\n            time.sleep(2)\n        w.close()\n        r = PyRecordReader_New(f)\n        r.GetNext()  # meta data, so skip\n        for _ in range(N_TEST):  # all of the data should be flushed\n            r.GetNext()\n\n\n    def test_auto_close(self):\n        pass\n\n    def test_writer(self):\n        TEST_LEN = 100\n        N_PROC = 4\n        writer = SummaryWriter()\n        event_filename = writer.file_writer.event_writer._ev_writer._file_name\n\n        predifined_values = list(range(TEST_LEN))\n        def train3():\n            for i in range(TEST_LEN):\n                writer.add_scalar('many_write_in_func', predifined_values[i])\n                time.sleep(0.01*np.random.randint(0, 10))\n\n        processes = []\n        for i in range(N_PROC):\n            p1 = mp.Process(target=train3)\n            processes.append(p1)\n            p1.start()\n\n        for p in processes:\n            p.join()\n        writer.close()\n\n\n        collected_values = []\n        r = PyRecordReader_New(event_filename)\n        r.GetNext()  # meta data, so skip\n        for _ in range(TEST_LEN*N_PROC):  # all of the data should be flushed\n            r.GetNext()\n            ev = event_pb2.Event()\n            value = ev.FromString(r.record()).summary.value\n            collected_values.append(value[0].simple_value)\n\n        collected_values = sorted(collected_values)\n        for i in range(TEST_LEN):\n            for j in range(N_PROC):\n                assert collected_values[i*N_PROC+j] == i """
tensorboardX/beholder/__init__.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom .beholder import Beholder\nfrom .beholder import BeholderHook\n'"
tensorboardX/beholder/beholder.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom ..proto.summary_pb2 import Summary\nfrom ..proto.summary_pb2 import SummaryMetadata\nfrom ..proto.tensor_pb2 import TensorProto\nfrom ..proto.tensor_shape_pb2 import TensorShapeProto\n\nimport os\nimport time\n\nimport numpy as np\n# import tensorflow as tf\n\n# from tensorboard.plugins.beholder import im_util\n# from . import im_util\nfrom .file_system_tools import read_pickle,\\\n    write_pickle, write_file\nfrom .shared_config import PLUGIN_NAME, TAG_NAME,\\\n    SUMMARY_FILENAME, DEFAULT_CONFIG, CONFIG_FILENAME, SUMMARY_COLLECTION_KEY_NAME, SECTION_INFO_FILENAME\nfrom . import video_writing\n# from .visualizer import Visualizer\n\n\nclass Beholder(object):\n\n    def __init__(self, logdir):\n        self.PLUGIN_LOGDIR = logdir + \'/plugins/\' + PLUGIN_NAME\n\n        self.is_recording = False\n        self.video_writer = video_writing.VideoWriter(\n            self.PLUGIN_LOGDIR,\n            outputs=[video_writing.FFmpegVideoOutput, video_writing.PNGVideoOutput])\n\n        self.last_image_shape = []\n        self.last_update_time = time.time()\n        self.config_last_modified_time = -1\n        self.previous_config = dict(DEFAULT_CONFIG)\n\n        if not os.path.exists(self.PLUGIN_LOGDIR + \'/config.pkl\'):\n            os.makedirs(self.PLUGIN_LOGDIR)\n            write_pickle(DEFAULT_CONFIG,\n                         \'{}/{}\'.format(self.PLUGIN_LOGDIR, CONFIG_FILENAME))\n\n        # self.visualizer = Visualizer(self.PLUGIN_LOGDIR)\n    def _get_config(self):\n        \'\'\'Reads the config file from disk or creates a new one.\'\'\'\n        filename = \'{}/{}\'.format(self.PLUGIN_LOGDIR, CONFIG_FILENAME)\n        modified_time = os.path.getmtime(filename)\n\n        if modified_time != self.config_last_modified_time:\n            config = read_pickle(filename, default=self.previous_config)\n            self.previous_config = config\n        else:\n            config = self.previous_config\n\n        self.config_last_modified_time = modified_time\n        return config\n\n    def _write_summary(self, frame):\n        \'\'\'Writes the frame to disk as a tensor summary.\'\'\'\n        path = \'{}/{}\'.format(self.PLUGIN_LOGDIR, SUMMARY_FILENAME)\n        smd = SummaryMetadata()\n        tensor = TensorProto(\n            dtype=\'DT_FLOAT\',\n            float_val=frame.reshape(-1).tolist(),\n            tensor_shape=TensorShapeProto(\n                dim=[TensorShapeProto.Dim(size=frame.shape[0]),\n                     TensorShapeProto.Dim(size=frame.shape[1]),\n                     TensorShapeProto.Dim(size=frame.shape[2])]\n            )\n        )\n        summary = Summary(value=[Summary.Value(\n            tag=TAG_NAME, metadata=smd, tensor=tensor)]).SerializeToString()\n        write_file(summary, path)\n\n    @staticmethod\n    def stats(tensor_and_name):\n        imgstats = []\n        for (img, name) in tensor_and_name:\n            immax = img.max()\n            immin = img.min()\n            imgstats.append(\n                {\n                    \'height\': img.shape[0],\n                    \'max\': str(immax),\n                    \'mean\': str(img.mean()),\n                    \'min\': str(immin),\n                    \'name\': name,\n                    \'range\': str(immax - immin),\n                    \'shape\': str((img.shape[1], img.shape[2]))\n                })\n        return imgstats\n\n    def _get_final_image(self, config, trainable=None, arrays=None, frame=None):\n        if config[\'values\'] == \'frames\':\n            # print(\'===frames===\')\n            final_image = frame\n        elif config[\'values\'] == \'arrays\':\n            # print(\'===arrays===\')\n            final_image = np.concatenate([arr for arr, _ in arrays])\n            stat = self.stats(arrays)\n            write_pickle(\n                stat, \'{}/{}\'.format(self.PLUGIN_LOGDIR, SECTION_INFO_FILENAME))\n        elif config[\'values\'] == \'trainable_variables\':\n            # print(\'===trainable===\')\n            final_image = np.concatenate([arr for arr, _ in trainable])\n            stat = self.stats(trainable)\n            write_pickle(\n                stat, \'{}/{}\'.format(self.PLUGIN_LOGDIR, SECTION_INFO_FILENAME))\n        if len(final_image.shape) == 2:  # Map grayscale images to 3D tensors.\n            final_image = np.expand_dims(final_image, -1)\n\n        return final_image\n\n    def _enough_time_has_passed(self, FPS):\n        \'\'\'For limiting how often frames are computed.\'\'\'\n        if FPS == 0:\n            return False\n        else:\n            earliest_time = self.last_update_time + (1.0 / FPS)\n            return time.time() >= earliest_time\n\n    def _update_frame(self, trainable, arrays, frame, config):\n        final_image = self._get_final_image(config, trainable, arrays, frame)\n        self._write_summary(final_image)\n        self.last_image_shape = final_image.shape\n\n        return final_image\n\n    def _update_recording(self, frame, config):\n        \'\'\'Adds a frame to the current video output.\'\'\'\n        # pylint: disable=redefined-variable-type\n        should_record = config[\'is_recording\']\n\n        if should_record:\n            if not self.is_recording:\n                self.is_recording = True\n                print(\'Starting recording using %s\',\n                      self.video_writer.current_output().name())\n            self.video_writer.write_frame(frame)\n        elif self.is_recording:\n            self.is_recording = False\n            self.video_writer.finish()\n            print(\'Finished recording\')\n\n    # TODO: blanket try and except for production? I don\'t someone\'s script to die\n    #       after weeks of running because of a visualization.\n    def update(self, trainable=None, arrays=None, frame=None):\n        \'\'\'Creates a frame and writes it to disk.\n\n        Args:\n            trainable: a list of namedtuple (tensors, name).\n            arrays: a list of namedtuple (tensors, name).\n            frame: lalala\n        \'\'\'\n\n        new_config = self._get_config()\n        if True or self._enough_time_has_passed(self.previous_config[\'FPS\']):\n            # self.visualizer.update(new_config)\n            self.last_update_time = time.time()\n            final_image = self._update_frame(\n                trainable, arrays, frame, new_config)\n            self._update_recording(final_image, new_config)\n\n    ##############################################################################\n    # @staticmethod\n    # def gradient_helper(optimizer, loss, var_list=None):\n    #   \'\'\'A helper to get the gradients out at each step.\n\n    #   Args:\n    #     optimizer: the optimizer op.\n    #     loss: the op that computes your loss value.\n\n    #   Returns: the gradient tensors and the train_step op.\n    #   \'\'\'\n    #   if var_list is None:\n    #     var_list = tf.trainable_variables()\n\n    #   grads_and_vars = optimizer.compute_gradients(loss, var_list=var_list)\n    #   grads = [pair[0] for pair in grads_and_vars]\n\n    #   return grads, optimizer.apply_gradients(grads_and_vars)\n\n\n# implements pytorch backward later\nclass BeholderHook():\n    pass\n    # """"""SessionRunHook implementation that runs Beholder every step.\n\n    # Convenient when using tf.train.MonitoredSession:\n    # ```python\n    # beholder_hook = BeholderHook(LOG_DIRECTORY)\n    # with MonitoredSession(..., hooks=[beholder_hook]) as sess:\n    #   sess.run(train_op)\n    # ```\n    # """"""\n    # def __init__(self, logdir):\n    #   """"""Creates new Hook instance\n\n    #   Args:\n    #     logdir: Directory where Beholder should write data.\n    #   """"""\n    #   self._logdir = logdir\n    #   self.beholder = None\n\n    # def begin(self):\n    #   self.beholder = Beholder(self._logdir)\n\n    # def after_run(self, run_context, unused_run_values):\n    #   self.beholder.update(run_context.session)\n'"
tensorboardX/beholder/file_system_tools.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport pickle\n\n# import tensorflow as tf\n# from google.protobuf import message\n\n\ndef write_file(contents, path, mode=\'wb\'):\n    with open(path, mode) as new_file:\n        new_file.write(contents)\n\n\ndef write_pickle(obj, path):\n    with open(path, \'wb\') as new_file:\n        pickle.dump(obj, new_file)\n\n\ndef read_pickle(path, default=None):\n    with open(path, \'rb\') as pickle_file:\n        result = pickle.load(pickle_file)\n    return result\n'"
tensorboardX/beholder/shared_config.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nPLUGIN_NAME = \'beholder\'\nTAG_NAME = \'beholder-frame\'\nSUMMARY_FILENAME = \'frame.summary\'\nCONFIG_FILENAME = \'config.pkl\'\nSECTION_INFO_FILENAME = \'section-info.pkl\'\nSUMMARY_COLLECTION_KEY_NAME = \'summaries_beholder\'\n\nDEFAULT_CONFIG = {\n    \'values\': \'trainable_variables\',\n    \'mode\': \'variance\',\n    \'scaling\': \'layer\',\n    \'window_size\': 15,\n    \'FPS\': 10,\n    \'is_recording\': False,\n    \'show_all\': False,\n    \'colormap\': \'magma\'\n}\n\nSECTION_HEIGHT = 128\nIMAGE_WIDTH = 512 + 256\n\nTB_WHITE = 245\n'"
tensorboardX/beholder/video_writing.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport os\nimport subprocess\nimport time\n\nimport numpy as np\n\n\nclass VideoWriter(object):\n    """"""Video file writer that can use different output types.\n\n    Each VideoWriter instance writes video files to a specified directory, using\n    the first available VideoOutput from the provided list.\n    """"""\n\n    def __init__(self, directory, outputs):\n        self.directory = directory\n        # Filter to the available outputs\n        self.outputs = [out for out in outputs if out.available()]\n        if not self.outputs:\n            raise IOError(\'No available video outputs\')\n        self.output_index = 0\n        self.output = None\n        self.frame_shape = None\n\n    def current_output(self):\n        return self.outputs[self.output_index]\n\n    def write_frame(self, np_array):\n        # Reset whenever we encounter a new frame shape.\n        if self.frame_shape != np_array.shape:\n            if self.output:\n                self.output.close()\n            self.output = None\n            self.frame_shape = np_array.shape\n            print(\'Starting video with frame shape: %s\', self.frame_shape)\n        # Write the frame, advancing across output types as necessary.\n        original_output_index = self.output_index\n        for self.output_index in range(original_output_index, len(self.outputs)):\n            try:\n                if not self.output:\n                    new_output = self.outputs[self.output_index]\n                    if self.output_index > original_output_index:\n                        print(\'Falling back to video output %s\',\n                              new_output.name())\n                    self.output = new_output(self.directory, self.frame_shape)\n                self.output.emit_frame(np_array)\n                return\n            except (IOError, OSError) as e:\n                print(\'Video output type %s not available: %s\',\n                      self.current_output().name(), str(e))\n                if self.output:\n                    self.output.close()\n                self.output = None\n        raise IOError(\'Exhausted available video outputs\')\n\n    def finish(self):\n        if self.output:\n            self.output.close()\n        self.output = None\n        self.frame_shape = None\n        # Reconsider failed outputs when video is manually restarted.\n        self.output_index = 0\n\n\nclass VideoOutput(object):\n    """"""Base class for video outputs supported by VideoWriter.""""""\n\n    __metaclass__ = abc.ABCMeta\n\n    # Would add @abc.abstractmethod in python 3.3+\n    @classmethod\n    def available(cls):\n        raise NotImplementedError()\n\n    @classmethod\n    def name(cls):\n        return cls.__name__\n\n    @abc.abstractmethod\n    def emit_frame(self, np_array):\n        raise NotImplementedError()\n\n    @abc.abstractmethod\n    def close(self):\n        raise NotImplementedError()\n\n\nclass PNGVideoOutput(VideoOutput):\n    """"""Video output implemented by writing individual PNGs to disk.""""""\n\n    @classmethod\n    def available(cls):\n        return True\n\n    def __init__(self, directory, frame_shape):\n        del frame_shape  # unused\n        self.directory = directory + \'/video-frames-{}\'.format(time.time())\n        self.frame_num = 0\n        os.makedirs(self.directory)\n\n    def emit_frame(self, np_array):\n        filename = self.directory + \'/{:05}.png\'.format(self.frame_num)\n        self._write_image(np_array.astype(np.uint8), filename)\n        self.frame_num += 1\n\n    def _write_image(self, im, filename):\n        from PIL import Image\n        Image.fromarray(im).save(filename)\n\n    def close(self):\n        pass\n\n\nclass FFmpegVideoOutput(VideoOutput):\n    """"""Video output implemented by streaming to FFmpeg with .mp4 output.""""""\n\n    @classmethod\n    def available(cls):\n        # Silently check if ffmpeg is available.\n        try:\n            with open(os.devnull, \'wb\') as devnull:\n                subprocess.check_call(\n                    [\'ffmpeg\', \'-version\'], stdout=devnull, stderr=devnull)\n            return True\n        except (OSError, subprocess.CalledProcessError):\n            return False\n\n    def __init__(self, directory, frame_shape):\n        self.filename = directory + \'/video-{}.webm\'.format(time.time())\n        if len(frame_shape) != 3:\n            raise ValueError(\n                \'Expected rank-3 array for frame, got %s\' % str(frame_shape))\n        # Set input pixel format based on channel count.\n        if frame_shape[2] == 1:\n            pix_fmt = \'gray\'\n        elif frame_shape[2] == 3:\n            pix_fmt = \'rgb24\'\n        else:\n            raise ValueError(\'Unsupported channel count %d\' % frame_shape[2])\n\n        command = [\n            \'ffmpeg\',\n            \'-y\',  # Overwite output\n            # Input options - raw video file format and codec.\n            \'-f\', \'rawvideo\',\n            \'-vcodec\', \'rawvideo\',\n            # Width x height.\n            \'-s\', \'%dx%d\' % (frame_shape[1], frame_shape[0]),\n            \'-pix_fmt\', pix_fmt,\n            \'-r\', \'15\',  # Frame rate: arbitrarily use 15 frames per second.\n            \'-i\', \'-\',  # Use stdin.\n            \'-an\',  # No audio.\n            # Output options - use lossless VP9 codec inside .webm.\n            \'-vcodec\', \'libvpx-vp9\',\n            \'-lossless\', \'1\',\n            # Using YUV is most compatible, though conversion from RGB skews colors.\n            \'-pix_fmt\', \'yuv420p\',\n            self.filename\n        ]\n        PIPE = subprocess.PIPE\n        self.ffmpeg = subprocess.Popen(\n            command, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n\n    def _handle_error(self):\n        _, stderr = self.ffmpeg.communicate()\n        bar = \'=\' * 40\n        print(\'Error writing to FFmpeg:\\n{}\\n{}\\n{}\',\n              bar, stderr, bar)\n\n    def emit_frame(self, np_array):\n        try:\n            self.ffmpeg.stdin.write(np_array.tobytes())\n            self.ffmpeg.stdin.flush()\n        except IOError:\n            self._handle_error()\n            raise IOError(\'Failure invoking FFmpeg\')\n\n    def close(self):\n        if self.ffmpeg.poll() is None:\n            # Close stdin and consume and discard stderr/stdout.\n            self.ffmpeg.communicate()\n        self.ffmpeg = None\n'"
tensorboardX/proto/__init__.py,0,b''
tensorboardX/proto/api_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/api.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom google.protobuf import struct_pb2 as google_dot_protobuf_dot_struct__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/api.proto\',\n  package=\'tensorboardX.hparam\',\n  syntax=\'proto3\',\n  serialized_options=None,\n  serialized_pb=_b(\'\\n\\x1ctensorboardX/proto/api.proto\\x12\\x13tensorboardX.hparam\\x1a\\x1cgoogle/protobuf/struct.proto\\""\\xc6\\x01\\n\\nExperiment\\x12\\x0c\\n\\x04name\\x18\\x06 \\x01(\\t\\x12\\x13\\n\\x0b\\x64\\x65scription\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04user\\x18\\x02 \\x01(\\t\\x12\\x19\\n\\x11time_created_secs\\x18\\x03 \\x01(\\x01\\x12\\x35\\n\\x0chparam_infos\\x18\\x04 \\x03(\\x0b\\x32\\x1f.tensorboardX.hparam.HParamInfo\\x12\\x35\\n\\x0cmetric_infos\\x18\\x05 \\x03(\\x0b\\x32\\x1f.tensorboardX.hparam.MetricInfo\\""\\xed\\x01\\n\\nHParamInfo\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x14\\n\\x0c\\x64isplay_name\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\x0b\\x64\\x65scription\\x18\\x03 \\x01(\\t\\x12+\\n\\x04type\\x18\\x04 \\x01(\\x0e\\x32\\x1d.tensorboardX.hparam.DataType\\x12\\x35\\n\\x0f\\x64omain_discrete\\x18\\x05 \\x01(\\x0b\\x32\\x1a.google.protobuf.ListValueH\\x00\\x12\\x38\\n\\x0f\\x64omain_interval\\x18\\x06 \\x01(\\x0b\\x32\\x1d.tensorboardX.hparam.IntervalH\\x00\\x42\\x08\\n\\x06\\x64omain\\""0\\n\\x08Interval\\x12\\x11\\n\\tmin_value\\x18\\x01 \\x01(\\x01\\x12\\x11\\n\\tmax_value\\x18\\x02 \\x01(\\x01\\""(\\n\\nMetricName\\x12\\r\\n\\x05group\\x18\\x01 \\x01(\\t\\x12\\x0b\\n\\x03tag\\x18\\x02 \\x01(\\t\\""\\x9e\\x01\\n\\nMetricInfo\\x12-\\n\\x04name\\x18\\x01 \\x01(\\x0b\\x32\\x1f.tensorboardX.hparam.MetricName\\x12\\x14\\n\\x0c\\x64isplay_name\\x18\\x03 \\x01(\\t\\x12\\x13\\n\\x0b\\x64\\x65scription\\x18\\x04 \\x01(\\t\\x12\\x36\\n\\x0c\\x64\\x61taset_type\\x18\\x05 \\x01(\\x0e\\x32 .tensorboardX.hparam.DatasetType\\""\\xa3\\x02\\n\\x0cSessionGroup\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12?\\n\\x07hparams\\x18\\x02 \\x03(\\x0b\\x32..tensorboardX.hparam.SessionGroup.HparamsEntry\\x12\\x37\\n\\rmetric_values\\x18\\x03 \\x03(\\x0b\\x32 .tensorboardX.hparam.MetricValue\\x12.\\n\\x08sessions\\x18\\x04 \\x03(\\x0b\\x32\\x1c.tensorboardX.hparam.Session\\x12\\x13\\n\\x0bmonitor_url\\x18\\x05 \\x01(\\t\\x1a\\x46\\n\\x0cHparamsEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12%\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x16.google.protobuf.Value:\\x02\\x38\\x01\\""z\\n\\x0bMetricValue\\x12-\\n\\x04name\\x18\\x01 \\x01(\\x0b\\x32\\x1f.tensorboardX.hparam.MetricName\\x12\\r\\n\\x05value\\x18\\x02 \\x01(\\x01\\x12\\x15\\n\\rtraining_step\\x18\\x03 \\x01(\\x05\\x12\\x16\\n\\x0ewall_time_secs\\x18\\x04 \\x01(\\x01\\""\\xd5\\x01\\n\\x07Session\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x17\\n\\x0fstart_time_secs\\x18\\x02 \\x01(\\x01\\x12\\x15\\n\\rend_time_secs\\x18\\x03 \\x01(\\x01\\x12+\\n\\x06status\\x18\\x04 \\x01(\\x0e\\x32\\x1b.tensorboardX.hparam.Status\\x12\\x11\\n\\tmodel_uri\\x18\\x05 \\x01(\\t\\x12\\x37\\n\\rmetric_values\\x18\\x06 \\x03(\\x0b\\x32 .tensorboardX.hparam.MetricValue\\x12\\x13\\n\\x0bmonitor_url\\x18\\x07 \\x01(\\t\\""/\\n\\x14GetExperimentRequest\\x12\\x17\\n\\x0f\\x65xperiment_name\\x18\\x01 \\x01(\\t\\""\\xc4\\x02\\n\\x18ListSessionGroupsRequest\\x12\\x17\\n\\x0f\\x65xperiment_name\\x18\\x06 \\x01(\\t\\x12\\x35\\n\\x10\\x61llowed_statuses\\x18\\x07 \\x03(\\x0e\\x32\\x1b.tensorboardX.hparam.Status\\x12\\x32\\n\\ncol_params\\x18\\x01 \\x03(\\x0b\\x32\\x1e.tensorboardX.hparam.ColParams\\x12>\\n\\x10\\x61ggregation_type\\x18\\x02 \\x01(\\x0e\\x32$.tensorboardX.hparam.AggregationType\\x12;\\n\\x12\\x61ggregation_metric\\x18\\x03 \\x01(\\x0b\\x32\\x1f.tensorboardX.hparam.MetricName\\x12\\x13\\n\\x0bstart_index\\x18\\x04 \\x01(\\x05\\x12\\x12\\n\\nslice_size\\x18\\x05 \\x01(\\x05\\""\\xd9\\x02\\n\\tColParams\\x12\\x31\\n\\x06metric\\x18\\x01 \\x01(\\x0b\\x32\\x1f.tensorboardX.hparam.MetricNameH\\x00\\x12\\x10\\n\\x06hparam\\x18\\x02 \\x01(\\tH\\x00\\x12-\\n\\x05order\\x18\\x03 \\x01(\\x0e\\x32\\x1e.tensorboardX.hparam.SortOrder\\x12\\x1c\\n\\x14missing_values_first\\x18\\x04 \\x01(\\x08\\x12\\x17\\n\\rfilter_regexp\\x18\\x05 \\x01(\\tH\\x01\\x12\\x38\\n\\x0f\\x66ilter_interval\\x18\\x06 \\x01(\\x0b\\x32\\x1d.tensorboardX.hparam.IntervalH\\x01\\x12\\x35\\n\\x0f\\x66ilter_discrete\\x18\\x07 \\x01(\\x0b\\x32\\x1a.google.protobuf.ListValueH\\x01\\x12\\x1e\\n\\x16\\x65xclude_missing_values\\x18\\x08 \\x01(\\x08\\x42\\x06\\n\\x04nameB\\x08\\n\\x06\\x66ilter\\""j\\n\\x19ListSessionGroupsResponse\\x12\\x39\\n\\x0esession_groups\\x18\\x01 \\x03(\\x0b\\x32!.tensorboardX.hparam.SessionGroup\\x12\\x12\\n\\ntotal_size\\x18\\x03 \\x01(\\x05\\""}\\n\\x16ListMetricEvalsRequest\\x12\\x17\\n\\x0f\\x65xperiment_name\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\x0csession_name\\x18\\x01 \\x01(\\t\\x12\\x34\\n\\x0bmetric_name\\x18\\x02 \\x01(\\x0b\\x32\\x1f.tensorboardX.hparam.MetricName*`\\n\\x08\\x44\\x61taType\\x12\\x13\\n\\x0f\\x44\\x41TA_TYPE_UNSET\\x10\\x00\\x12\\x14\\n\\x10\\x44\\x41TA_TYPE_STRING\\x10\\x01\\x12\\x12\\n\\x0e\\x44\\x41TA_TYPE_BOOL\\x10\\x02\\x12\\x15\\n\\x11\\x44\\x41TA_TYPE_FLOAT64\\x10\\x03*P\\n\\x0b\\x44\\x61tasetType\\x12\\x13\\n\\x0f\\x44\\x41TASET_UNKNOWN\\x10\\x00\\x12\\x14\\n\\x10\\x44\\x41TASET_TRAINING\\x10\\x01\\x12\\x16\\n\\x12\\x44\\x41TASET_VALIDATION\\x10\\x02*X\\n\\x06Status\\x12\\x12\\n\\x0eSTATUS_UNKNOWN\\x10\\x00\\x12\\x12\\n\\x0eSTATUS_SUCCESS\\x10\\x01\\x12\\x12\\n\\x0eSTATUS_FAILURE\\x10\\x02\\x12\\x12\\n\\x0eSTATUS_RUNNING\\x10\\x03*A\\n\\tSortOrder\\x12\\x15\\n\\x11ORDER_UNSPECIFIED\\x10\\x00\\x12\\r\\n\\tORDER_ASC\\x10\\x01\\x12\\x0e\\n\\nORDER_DESC\\x10\\x02*\\x7f\\n\\x0f\\x41ggregationType\\x12\\x15\\n\\x11\\x41GGREGATION_UNSET\\x10\\x00\\x12\\x13\\n\\x0f\\x41GGREGATION_AVG\\x10\\x01\\x12\\x16\\n\\x12\\x41GGREGATION_MEDIAN\\x10\\x02\\x12\\x13\\n\\x0f\\x41GGREGATION_MIN\\x10\\x03\\x12\\x13\\n\\x0f\\x41GGREGATION_MAX\\x10\\x04\\x62\\x06proto3\')\n  ,\n  dependencies=[google_dot_protobuf_dot_struct__pb2.DESCRIPTOR,])\n\n_DATATYPE = _descriptor.EnumDescriptor(\n  name=\'DataType\',\n  full_name=\'tensorboardX.hparam.DataType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA_TYPE_UNSET\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA_TYPE_STRING\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA_TYPE_BOOL\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA_TYPE_FLOAT64\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=2370,\n  serialized_end=2466,\n)\n_sym_db.RegisterEnumDescriptor(_DATATYPE)\n\nDataType = enum_type_wrapper.EnumTypeWrapper(_DATATYPE)\n_DATASETTYPE = _descriptor.EnumDescriptor(\n  name=\'DatasetType\',\n  full_name=\'tensorboardX.hparam.DatasetType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DATASET_UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATASET_TRAINING\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATASET_VALIDATION\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=2468,\n  serialized_end=2548,\n)\n_sym_db.RegisterEnumDescriptor(_DATASETTYPE)\n\nDatasetType = enum_type_wrapper.EnumTypeWrapper(_DATASETTYPE)\n_STATUS = _descriptor.EnumDescriptor(\n  name=\'Status\',\n  full_name=\'tensorboardX.hparam.Status\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STATUS_UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STATUS_SUCCESS\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STATUS_FAILURE\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STATUS_RUNNING\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=2550,\n  serialized_end=2638,\n)\n_sym_db.RegisterEnumDescriptor(_STATUS)\n\nStatus = enum_type_wrapper.EnumTypeWrapper(_STATUS)\n_SORTORDER = _descriptor.EnumDescriptor(\n  name=\'SortOrder\',\n  full_name=\'tensorboardX.hparam.SortOrder\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ORDER_UNSPECIFIED\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ORDER_ASC\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ORDER_DESC\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=2640,\n  serialized_end=2705,\n)\n_sym_db.RegisterEnumDescriptor(_SORTORDER)\n\nSortOrder = enum_type_wrapper.EnumTypeWrapper(_SORTORDER)\n_AGGREGATIONTYPE = _descriptor.EnumDescriptor(\n  name=\'AggregationType\',\n  full_name=\'tensorboardX.hparam.AggregationType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'AGGREGATION_UNSET\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AGGREGATION_AVG\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AGGREGATION_MEDIAN\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AGGREGATION_MIN\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AGGREGATION_MAX\', index=4, number=4,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=2707,\n  serialized_end=2834,\n)\n_sym_db.RegisterEnumDescriptor(_AGGREGATIONTYPE)\n\nAggregationType = enum_type_wrapper.EnumTypeWrapper(_AGGREGATIONTYPE)\nDATA_TYPE_UNSET = 0\nDATA_TYPE_STRING = 1\nDATA_TYPE_BOOL = 2\nDATA_TYPE_FLOAT64 = 3\nDATASET_UNKNOWN = 0\nDATASET_TRAINING = 1\nDATASET_VALIDATION = 2\nSTATUS_UNKNOWN = 0\nSTATUS_SUCCESS = 1\nSTATUS_FAILURE = 2\nSTATUS_RUNNING = 3\nORDER_UNSPECIFIED = 0\nORDER_ASC = 1\nORDER_DESC = 2\nAGGREGATION_UNSET = 0\nAGGREGATION_AVG = 1\nAGGREGATION_MEDIAN = 2\nAGGREGATION_MIN = 3\nAGGREGATION_MAX = 4\n\n\n\n_EXPERIMENT = _descriptor.Descriptor(\n  name=\'Experiment\',\n  full_name=\'tensorboardX.hparam.Experiment\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.hparam.Experiment.name\', index=0,\n      number=6, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'description\', full_name=\'tensorboardX.hparam.Experiment.description\', index=1,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'user\', full_name=\'tensorboardX.hparam.Experiment.user\', index=2,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'time_created_secs\', full_name=\'tensorboardX.hparam.Experiment.time_created_secs\', index=3,\n      number=3, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hparam_infos\', full_name=\'tensorboardX.hparam.Experiment.hparam_infos\', index=4,\n      number=4, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'metric_infos\', full_name=\'tensorboardX.hparam.Experiment.metric_infos\', index=5,\n      number=5, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=84,\n  serialized_end=282,\n)\n\n\n_HPARAMINFO = _descriptor.Descriptor(\n  name=\'HParamInfo\',\n  full_name=\'tensorboardX.hparam.HParamInfo\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.hparam.HParamInfo.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'display_name\', full_name=\'tensorboardX.hparam.HParamInfo.display_name\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'description\', full_name=\'tensorboardX.hparam.HParamInfo.description\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'tensorboardX.hparam.HParamInfo.type\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'domain_discrete\', full_name=\'tensorboardX.hparam.HParamInfo.domain_discrete\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'domain_interval\', full_name=\'tensorboardX.hparam.HParamInfo.domain_interval\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'domain\', full_name=\'tensorboardX.hparam.HParamInfo.domain\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=285,\n  serialized_end=522,\n)\n\n\n_INTERVAL = _descriptor.Descriptor(\n  name=\'Interval\',\n  full_name=\'tensorboardX.hparam.Interval\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'min_value\', full_name=\'tensorboardX.hparam.Interval.min_value\', index=0,\n      number=1, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max_value\', full_name=\'tensorboardX.hparam.Interval.max_value\', index=1,\n      number=2, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=524,\n  serialized_end=572,\n)\n\n\n_METRICNAME = _descriptor.Descriptor(\n  name=\'MetricName\',\n  full_name=\'tensorboardX.hparam.MetricName\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'tensorboardX.hparam.MetricName.group\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tag\', full_name=\'tensorboardX.hparam.MetricName.tag\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=574,\n  serialized_end=614,\n)\n\n\n_METRICINFO = _descriptor.Descriptor(\n  name=\'MetricInfo\',\n  full_name=\'tensorboardX.hparam.MetricInfo\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.hparam.MetricInfo.name\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'display_name\', full_name=\'tensorboardX.hparam.MetricInfo.display_name\', index=1,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'description\', full_name=\'tensorboardX.hparam.MetricInfo.description\', index=2,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dataset_type\', full_name=\'tensorboardX.hparam.MetricInfo.dataset_type\', index=3,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=617,\n  serialized_end=775,\n)\n\n\n_SESSIONGROUP_HPARAMSENTRY = _descriptor.Descriptor(\n  name=\'HparamsEntry\',\n  full_name=\'tensorboardX.hparam.SessionGroup.HparamsEntry\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'key\', full_name=\'tensorboardX.hparam.SessionGroup.HparamsEntry.key\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'tensorboardX.hparam.SessionGroup.HparamsEntry.value\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=_b(\'8\\001\'),\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=999,\n  serialized_end=1069,\n)\n\n_SESSIONGROUP = _descriptor.Descriptor(\n  name=\'SessionGroup\',\n  full_name=\'tensorboardX.hparam.SessionGroup\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.hparam.SessionGroup.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hparams\', full_name=\'tensorboardX.hparam.SessionGroup.hparams\', index=1,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'metric_values\', full_name=\'tensorboardX.hparam.SessionGroup.metric_values\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sessions\', full_name=\'tensorboardX.hparam.SessionGroup.sessions\', index=3,\n      number=4, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'monitor_url\', full_name=\'tensorboardX.hparam.SessionGroup.monitor_url\', index=4,\n      number=5, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_SESSIONGROUP_HPARAMSENTRY, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=778,\n  serialized_end=1069,\n)\n\n\n_METRICVALUE = _descriptor.Descriptor(\n  name=\'MetricValue\',\n  full_name=\'tensorboardX.hparam.MetricValue\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.hparam.MetricValue.name\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'tensorboardX.hparam.MetricValue.value\', index=1,\n      number=2, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'training_step\', full_name=\'tensorboardX.hparam.MetricValue.training_step\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'wall_time_secs\', full_name=\'tensorboardX.hparam.MetricValue.wall_time_secs\', index=3,\n      number=4, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1071,\n  serialized_end=1193,\n)\n\n\n_SESSION = _descriptor.Descriptor(\n  name=\'Session\',\n  full_name=\'tensorboardX.hparam.Session\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.hparam.Session.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'start_time_secs\', full_name=\'tensorboardX.hparam.Session.start_time_secs\', index=1,\n      number=2, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'end_time_secs\', full_name=\'tensorboardX.hparam.Session.end_time_secs\', index=2,\n      number=3, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'status\', full_name=\'tensorboardX.hparam.Session.status\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'model_uri\', full_name=\'tensorboardX.hparam.Session.model_uri\', index=4,\n      number=5, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'metric_values\', full_name=\'tensorboardX.hparam.Session.metric_values\', index=5,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'monitor_url\', full_name=\'tensorboardX.hparam.Session.monitor_url\', index=6,\n      number=7, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1196,\n  serialized_end=1409,\n)\n\n\n_GETEXPERIMENTREQUEST = _descriptor.Descriptor(\n  name=\'GetExperimentRequest\',\n  full_name=\'tensorboardX.hparam.GetExperimentRequest\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'experiment_name\', full_name=\'tensorboardX.hparam.GetExperimentRequest.experiment_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1411,\n  serialized_end=1458,\n)\n\n\n_LISTSESSIONGROUPSREQUEST = _descriptor.Descriptor(\n  name=\'ListSessionGroupsRequest\',\n  full_name=\'tensorboardX.hparam.ListSessionGroupsRequest\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'experiment_name\', full_name=\'tensorboardX.hparam.ListSessionGroupsRequest.experiment_name\', index=0,\n      number=6, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'allowed_statuses\', full_name=\'tensorboardX.hparam.ListSessionGroupsRequest.allowed_statuses\', index=1,\n      number=7, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'col_params\', full_name=\'tensorboardX.hparam.ListSessionGroupsRequest.col_params\', index=2,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'aggregation_type\', full_name=\'tensorboardX.hparam.ListSessionGroupsRequest.aggregation_type\', index=3,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'aggregation_metric\', full_name=\'tensorboardX.hparam.ListSessionGroupsRequest.aggregation_metric\', index=4,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'start_index\', full_name=\'tensorboardX.hparam.ListSessionGroupsRequest.start_index\', index=5,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'slice_size\', full_name=\'tensorboardX.hparam.ListSessionGroupsRequest.slice_size\', index=6,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1461,\n  serialized_end=1785,\n)\n\n\n_COLPARAMS = _descriptor.Descriptor(\n  name=\'ColParams\',\n  full_name=\'tensorboardX.hparam.ColParams\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'metric\', full_name=\'tensorboardX.hparam.ColParams.metric\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hparam\', full_name=\'tensorboardX.hparam.ColParams.hparam\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'order\', full_name=\'tensorboardX.hparam.ColParams.order\', index=2,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'missing_values_first\', full_name=\'tensorboardX.hparam.ColParams.missing_values_first\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'filter_regexp\', full_name=\'tensorboardX.hparam.ColParams.filter_regexp\', index=4,\n      number=5, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'filter_interval\', full_name=\'tensorboardX.hparam.ColParams.filter_interval\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'filter_discrete\', full_name=\'tensorboardX.hparam.ColParams.filter_discrete\', index=6,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'exclude_missing_values\', full_name=\'tensorboardX.hparam.ColParams.exclude_missing_values\', index=7,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'name\', full_name=\'tensorboardX.hparam.ColParams.name\',\n      index=0, containing_type=None, fields=[]),\n    _descriptor.OneofDescriptor(\n      name=\'filter\', full_name=\'tensorboardX.hparam.ColParams.filter\',\n      index=1, containing_type=None, fields=[]),\n  ],\n  serialized_start=1788,\n  serialized_end=2133,\n)\n\n\n_LISTSESSIONGROUPSRESPONSE = _descriptor.Descriptor(\n  name=\'ListSessionGroupsResponse\',\n  full_name=\'tensorboardX.hparam.ListSessionGroupsResponse\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'session_groups\', full_name=\'tensorboardX.hparam.ListSessionGroupsResponse.session_groups\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'total_size\', full_name=\'tensorboardX.hparam.ListSessionGroupsResponse.total_size\', index=1,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2135,\n  serialized_end=2241,\n)\n\n\n_LISTMETRICEVALSREQUEST = _descriptor.Descriptor(\n  name=\'ListMetricEvalsRequest\',\n  full_name=\'tensorboardX.hparam.ListMetricEvalsRequest\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'experiment_name\', full_name=\'tensorboardX.hparam.ListMetricEvalsRequest.experiment_name\', index=0,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'session_name\', full_name=\'tensorboardX.hparam.ListMetricEvalsRequest.session_name\', index=1,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'metric_name\', full_name=\'tensorboardX.hparam.ListMetricEvalsRequest.metric_name\', index=2,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2243,\n  serialized_end=2368,\n)\n\n_EXPERIMENT.fields_by_name[\'hparam_infos\'].message_type = _HPARAMINFO\n_EXPERIMENT.fields_by_name[\'metric_infos\'].message_type = _METRICINFO\n_HPARAMINFO.fields_by_name[\'type\'].enum_type = _DATATYPE\n_HPARAMINFO.fields_by_name[\'domain_discrete\'].message_type = google_dot_protobuf_dot_struct__pb2._LISTVALUE\n_HPARAMINFO.fields_by_name[\'domain_interval\'].message_type = _INTERVAL\n_HPARAMINFO.oneofs_by_name[\'domain\'].fields.append(\n  _HPARAMINFO.fields_by_name[\'domain_discrete\'])\n_HPARAMINFO.fields_by_name[\'domain_discrete\'].containing_oneof = _HPARAMINFO.oneofs_by_name[\'domain\']\n_HPARAMINFO.oneofs_by_name[\'domain\'].fields.append(\n  _HPARAMINFO.fields_by_name[\'domain_interval\'])\n_HPARAMINFO.fields_by_name[\'domain_interval\'].containing_oneof = _HPARAMINFO.oneofs_by_name[\'domain\']\n_METRICINFO.fields_by_name[\'name\'].message_type = _METRICNAME\n_METRICINFO.fields_by_name[\'dataset_type\'].enum_type = _DATASETTYPE\n_SESSIONGROUP_HPARAMSENTRY.fields_by_name[\'value\'].message_type = google_dot_protobuf_dot_struct__pb2._VALUE\n_SESSIONGROUP_HPARAMSENTRY.containing_type = _SESSIONGROUP\n_SESSIONGROUP.fields_by_name[\'hparams\'].message_type = _SESSIONGROUP_HPARAMSENTRY\n_SESSIONGROUP.fields_by_name[\'metric_values\'].message_type = _METRICVALUE\n_SESSIONGROUP.fields_by_name[\'sessions\'].message_type = _SESSION\n_METRICVALUE.fields_by_name[\'name\'].message_type = _METRICNAME\n_SESSION.fields_by_name[\'status\'].enum_type = _STATUS\n_SESSION.fields_by_name[\'metric_values\'].message_type = _METRICVALUE\n_LISTSESSIONGROUPSREQUEST.fields_by_name[\'allowed_statuses\'].enum_type = _STATUS\n_LISTSESSIONGROUPSREQUEST.fields_by_name[\'col_params\'].message_type = _COLPARAMS\n_LISTSESSIONGROUPSREQUEST.fields_by_name[\'aggregation_type\'].enum_type = _AGGREGATIONTYPE\n_LISTSESSIONGROUPSREQUEST.fields_by_name[\'aggregation_metric\'].message_type = _METRICNAME\n_COLPARAMS.fields_by_name[\'metric\'].message_type = _METRICNAME\n_COLPARAMS.fields_by_name[\'order\'].enum_type = _SORTORDER\n_COLPARAMS.fields_by_name[\'filter_interval\'].message_type = _INTERVAL\n_COLPARAMS.fields_by_name[\'filter_discrete\'].message_type = google_dot_protobuf_dot_struct__pb2._LISTVALUE\n_COLPARAMS.oneofs_by_name[\'name\'].fields.append(\n  _COLPARAMS.fields_by_name[\'metric\'])\n_COLPARAMS.fields_by_name[\'metric\'].containing_oneof = _COLPARAMS.oneofs_by_name[\'name\']\n_COLPARAMS.oneofs_by_name[\'name\'].fields.append(\n  _COLPARAMS.fields_by_name[\'hparam\'])\n_COLPARAMS.fields_by_name[\'hparam\'].containing_oneof = _COLPARAMS.oneofs_by_name[\'name\']\n_COLPARAMS.oneofs_by_name[\'filter\'].fields.append(\n  _COLPARAMS.fields_by_name[\'filter_regexp\'])\n_COLPARAMS.fields_by_name[\'filter_regexp\'].containing_oneof = _COLPARAMS.oneofs_by_name[\'filter\']\n_COLPARAMS.oneofs_by_name[\'filter\'].fields.append(\n  _COLPARAMS.fields_by_name[\'filter_interval\'])\n_COLPARAMS.fields_by_name[\'filter_interval\'].containing_oneof = _COLPARAMS.oneofs_by_name[\'filter\']\n_COLPARAMS.oneofs_by_name[\'filter\'].fields.append(\n  _COLPARAMS.fields_by_name[\'filter_discrete\'])\n_COLPARAMS.fields_by_name[\'filter_discrete\'].containing_oneof = _COLPARAMS.oneofs_by_name[\'filter\']\n_LISTSESSIONGROUPSRESPONSE.fields_by_name[\'session_groups\'].message_type = _SESSIONGROUP\n_LISTMETRICEVALSREQUEST.fields_by_name[\'metric_name\'].message_type = _METRICNAME\nDESCRIPTOR.message_types_by_name[\'Experiment\'] = _EXPERIMENT\nDESCRIPTOR.message_types_by_name[\'HParamInfo\'] = _HPARAMINFO\nDESCRIPTOR.message_types_by_name[\'Interval\'] = _INTERVAL\nDESCRIPTOR.message_types_by_name[\'MetricName\'] = _METRICNAME\nDESCRIPTOR.message_types_by_name[\'MetricInfo\'] = _METRICINFO\nDESCRIPTOR.message_types_by_name[\'SessionGroup\'] = _SESSIONGROUP\nDESCRIPTOR.message_types_by_name[\'MetricValue\'] = _METRICVALUE\nDESCRIPTOR.message_types_by_name[\'Session\'] = _SESSION\nDESCRIPTOR.message_types_by_name[\'GetExperimentRequest\'] = _GETEXPERIMENTREQUEST\nDESCRIPTOR.message_types_by_name[\'ListSessionGroupsRequest\'] = _LISTSESSIONGROUPSREQUEST\nDESCRIPTOR.message_types_by_name[\'ColParams\'] = _COLPARAMS\nDESCRIPTOR.message_types_by_name[\'ListSessionGroupsResponse\'] = _LISTSESSIONGROUPSRESPONSE\nDESCRIPTOR.message_types_by_name[\'ListMetricEvalsRequest\'] = _LISTMETRICEVALSREQUEST\nDESCRIPTOR.enum_types_by_name[\'DataType\'] = _DATATYPE\nDESCRIPTOR.enum_types_by_name[\'DatasetType\'] = _DATASETTYPE\nDESCRIPTOR.enum_types_by_name[\'Status\'] = _STATUS\nDESCRIPTOR.enum_types_by_name[\'SortOrder\'] = _SORTORDER\nDESCRIPTOR.enum_types_by_name[\'AggregationType\'] = _AGGREGATIONTYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nExperiment = _reflection.GeneratedProtocolMessageType(\'Experiment\', (_message.Message,), {\n  \'DESCRIPTOR\' : _EXPERIMENT,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.Experiment)\n  })\n_sym_db.RegisterMessage(Experiment)\n\nHParamInfo = _reflection.GeneratedProtocolMessageType(\'HParamInfo\', (_message.Message,), {\n  \'DESCRIPTOR\' : _HPARAMINFO,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.HParamInfo)\n  })\n_sym_db.RegisterMessage(HParamInfo)\n\nInterval = _reflection.GeneratedProtocolMessageType(\'Interval\', (_message.Message,), {\n  \'DESCRIPTOR\' : _INTERVAL,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.Interval)\n  })\n_sym_db.RegisterMessage(Interval)\n\nMetricName = _reflection.GeneratedProtocolMessageType(\'MetricName\', (_message.Message,), {\n  \'DESCRIPTOR\' : _METRICNAME,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.MetricName)\n  })\n_sym_db.RegisterMessage(MetricName)\n\nMetricInfo = _reflection.GeneratedProtocolMessageType(\'MetricInfo\', (_message.Message,), {\n  \'DESCRIPTOR\' : _METRICINFO,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.MetricInfo)\n  })\n_sym_db.RegisterMessage(MetricInfo)\n\nSessionGroup = _reflection.GeneratedProtocolMessageType(\'SessionGroup\', (_message.Message,), {\n\n  \'HparamsEntry\' : _reflection.GeneratedProtocolMessageType(\'HparamsEntry\', (_message.Message,), {\n    \'DESCRIPTOR\' : _SESSIONGROUP_HPARAMSENTRY,\n    \'__module__\' : \'tensorboardX.proto.api_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.hparam.SessionGroup.HparamsEntry)\n    })\n  ,\n  \'DESCRIPTOR\' : _SESSIONGROUP,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.SessionGroup)\n  })\n_sym_db.RegisterMessage(SessionGroup)\n_sym_db.RegisterMessage(SessionGroup.HparamsEntry)\n\nMetricValue = _reflection.GeneratedProtocolMessageType(\'MetricValue\', (_message.Message,), {\n  \'DESCRIPTOR\' : _METRICVALUE,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.MetricValue)\n  })\n_sym_db.RegisterMessage(MetricValue)\n\nSession = _reflection.GeneratedProtocolMessageType(\'Session\', (_message.Message,), {\n  \'DESCRIPTOR\' : _SESSION,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.Session)\n  })\n_sym_db.RegisterMessage(Session)\n\nGetExperimentRequest = _reflection.GeneratedProtocolMessageType(\'GetExperimentRequest\', (_message.Message,), {\n  \'DESCRIPTOR\' : _GETEXPERIMENTREQUEST,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.GetExperimentRequest)\n  })\n_sym_db.RegisterMessage(GetExperimentRequest)\n\nListSessionGroupsRequest = _reflection.GeneratedProtocolMessageType(\'ListSessionGroupsRequest\', (_message.Message,), {\n  \'DESCRIPTOR\' : _LISTSESSIONGROUPSREQUEST,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.ListSessionGroupsRequest)\n  })\n_sym_db.RegisterMessage(ListSessionGroupsRequest)\n\nColParams = _reflection.GeneratedProtocolMessageType(\'ColParams\', (_message.Message,), {\n  \'DESCRIPTOR\' : _COLPARAMS,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.ColParams)\n  })\n_sym_db.RegisterMessage(ColParams)\n\nListSessionGroupsResponse = _reflection.GeneratedProtocolMessageType(\'ListSessionGroupsResponse\', (_message.Message,), {\n  \'DESCRIPTOR\' : _LISTSESSIONGROUPSRESPONSE,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.ListSessionGroupsResponse)\n  })\n_sym_db.RegisterMessage(ListSessionGroupsResponse)\n\nListMetricEvalsRequest = _reflection.GeneratedProtocolMessageType(\'ListMetricEvalsRequest\', (_message.Message,), {\n  \'DESCRIPTOR\' : _LISTMETRICEVALSREQUEST,\n  \'__module__\' : \'tensorboardX.proto.api_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.ListMetricEvalsRequest)\n  })\n_sym_db.RegisterMessage(ListMetricEvalsRequest)\n\n\n_SESSIONGROUP_HPARAMSENTRY._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/attr_value_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/attr_value.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2\nfrom tensorboardX.proto import tensor_shape_pb2 as tensorboardX_dot_proto_dot_tensor__shape__pb2\nfrom tensorboardX.proto import types_pb2 as tensorboardX_dot_proto_dot_types__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/attr_value.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\017AttrValueProtosP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n#tensorboardX/proto/attr_value.proto\\x12\\x0ctensorboardX\\x1a\\x1ftensorboardX/proto/tensor.proto\\x1a%tensorboardX/proto/tensor_shape.proto\\x1a\\x1etensorboardX/proto/types.proto\\""\\xb8\\x04\\n\\tAttrValue\\x12\\x0b\\n\\x01s\\x18\\x02 \\x01(\\x0cH\\x00\\x12\\x0b\\n\\x01i\\x18\\x03 \\x01(\\x03H\\x00\\x12\\x0b\\n\\x01\\x66\\x18\\x04 \\x01(\\x02H\\x00\\x12\\x0b\\n\\x01\\x62\\x18\\x05 \\x01(\\x08H\\x00\\x12&\\n\\x04type\\x18\\x06 \\x01(\\x0e\\x32\\x16.tensorboardX.DataTypeH\\x00\\x12/\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x1e.tensorboardX.TensorShapeProtoH\\x00\\x12+\\n\\x06tensor\\x18\\x08 \\x01(\\x0b\\x32\\x19.tensorboardX.TensorProtoH\\x00\\x12\\x31\\n\\x04list\\x18\\x01 \\x01(\\x0b\\x32!.tensorboardX.AttrValue.ListValueH\\x00\\x12*\\n\\x04\\x66unc\\x18\\n \\x01(\\x0b\\x32\\x1a.tensorboardX.NameAttrListH\\x00\\x12\\x15\\n\\x0bplaceholder\\x18\\t \\x01(\\tH\\x00\\x1a\\xf1\\x01\\n\\tListValue\\x12\\t\\n\\x01s\\x18\\x02 \\x03(\\x0c\\x12\\r\\n\\x01i\\x18\\x03 \\x03(\\x03\\x42\\x02\\x10\\x01\\x12\\r\\n\\x01\\x66\\x18\\x04 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\r\\n\\x01\\x62\\x18\\x05 \\x03(\\x08\\x42\\x02\\x10\\x01\\x12(\\n\\x04type\\x18\\x06 \\x03(\\x0e\\x32\\x16.tensorboardX.DataTypeB\\x02\\x10\\x01\\x12-\\n\\x05shape\\x18\\x07 \\x03(\\x0b\\x32\\x1e.tensorboardX.TensorShapeProto\\x12)\\n\\x06tensor\\x18\\x08 \\x03(\\x0b\\x32\\x19.tensorboardX.TensorProto\\x12(\\n\\x04\\x66unc\\x18\\t \\x03(\\x0b\\x32\\x1a.tensorboardX.NameAttrListB\\x07\\n\\x05value\\""\\x96\\x01\\n\\x0cNameAttrList\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x32\\n\\x04\\x61ttr\\x18\\x02 \\x03(\\x0b\\x32$.tensorboardX.NameAttrList.AttrEntry\\x1a\\x44\\n\\tAttrEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12&\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x17.tensorboardX.AttrValue:\\x02\\x38\\x01\\x42\\x30\\n\\x18org.tensorflow.frameworkB\\x0f\\x41ttrValueProtosP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n  ,\n  dependencies=[tensorboardX_dot_proto_dot_tensor__pb2.DESCRIPTOR,tensorboardX_dot_proto_dot_tensor__shape__pb2.DESCRIPTOR,tensorboardX_dot_proto_dot_types__pb2.DESCRIPTOR,])\n\n\n\n\n_ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n  name=\'ListValue\',\n  full_name=\'tensorboardX.AttrValue.ListValue\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'s\', full_name=\'tensorboardX.AttrValue.ListValue.s\', index=0,\n      number=2, type=12, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'i\', full_name=\'tensorboardX.AttrValue.ListValue.i\', index=1,\n      number=3, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'f\', full_name=\'tensorboardX.AttrValue.ListValue.f\', index=2,\n      number=4, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'b\', full_name=\'tensorboardX.AttrValue.ListValue.b\', index=3,\n      number=5, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'tensorboardX.AttrValue.ListValue.type\', index=4,\n      number=6, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'tensorboardX.AttrValue.ListValue.shape\', index=5,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tensor\', full_name=\'tensorboardX.AttrValue.ListValue.tensor\', index=6,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'func\', full_name=\'tensorboardX.AttrValue.ListValue.func\', index=7,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=476,\n  serialized_end=717,\n)\n\n_ATTRVALUE = _descriptor.Descriptor(\n  name=\'AttrValue\',\n  full_name=\'tensorboardX.AttrValue\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'s\', full_name=\'tensorboardX.AttrValue.s\', index=0,\n      number=2, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'i\', full_name=\'tensorboardX.AttrValue.i\', index=1,\n      number=3, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'f\', full_name=\'tensorboardX.AttrValue.f\', index=2,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'b\', full_name=\'tensorboardX.AttrValue.b\', index=3,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'tensorboardX.AttrValue.type\', index=4,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'tensorboardX.AttrValue.shape\', index=5,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tensor\', full_name=\'tensorboardX.AttrValue.tensor\', index=6,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'list\', full_name=\'tensorboardX.AttrValue.list\', index=7,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'func\', full_name=\'tensorboardX.AttrValue.func\', index=8,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'placeholder\', full_name=\'tensorboardX.AttrValue.placeholder\', index=9,\n      number=9, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_ATTRVALUE_LISTVALUE, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'value\', full_name=\'tensorboardX.AttrValue.value\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=158,\n  serialized_end=726,\n)\n\n\n_NAMEATTRLIST_ATTRENTRY = _descriptor.Descriptor(\n  name=\'AttrEntry\',\n  full_name=\'tensorboardX.NameAttrList.AttrEntry\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'key\', full_name=\'tensorboardX.NameAttrList.AttrEntry.key\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'tensorboardX.NameAttrList.AttrEntry.value\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=_b(\'8\\001\'),\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=811,\n  serialized_end=879,\n)\n\n_NAMEATTRLIST = _descriptor.Descriptor(\n  name=\'NameAttrList\',\n  full_name=\'tensorboardX.NameAttrList\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.NameAttrList.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'attr\', full_name=\'tensorboardX.NameAttrList.attr\', index=1,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_NAMEATTRLIST_ATTRENTRY, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=729,\n  serialized_end=879,\n)\n\n_ATTRVALUE_LISTVALUE.fields_by_name[\'type\'].enum_type = tensorboardX_dot_proto_dot_types__pb2._DATATYPE\n_ATTRVALUE_LISTVALUE.fields_by_name[\'shape\'].message_type = tensorboardX_dot_proto_dot_tensor__shape__pb2._TENSORSHAPEPROTO\n_ATTRVALUE_LISTVALUE.fields_by_name[\'tensor\'].message_type = tensorboardX_dot_proto_dot_tensor__pb2._TENSORPROTO\n_ATTRVALUE_LISTVALUE.fields_by_name[\'func\'].message_type = _NAMEATTRLIST\n_ATTRVALUE_LISTVALUE.containing_type = _ATTRVALUE\n_ATTRVALUE.fields_by_name[\'type\'].enum_type = tensorboardX_dot_proto_dot_types__pb2._DATATYPE\n_ATTRVALUE.fields_by_name[\'shape\'].message_type = tensorboardX_dot_proto_dot_tensor__shape__pb2._TENSORSHAPEPROTO\n_ATTRVALUE.fields_by_name[\'tensor\'].message_type = tensorboardX_dot_proto_dot_tensor__pb2._TENSORPROTO\n_ATTRVALUE.fields_by_name[\'list\'].message_type = _ATTRVALUE_LISTVALUE\n_ATTRVALUE.fields_by_name[\'func\'].message_type = _NAMEATTRLIST\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'s\'])\n_ATTRVALUE.fields_by_name[\'s\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'i\'])\n_ATTRVALUE.fields_by_name[\'i\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'f\'])\n_ATTRVALUE.fields_by_name[\'f\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'b\'])\n_ATTRVALUE.fields_by_name[\'b\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'type\'])\n_ATTRVALUE.fields_by_name[\'type\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'shape\'])\n_ATTRVALUE.fields_by_name[\'shape\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'tensor\'])\n_ATTRVALUE.fields_by_name[\'tensor\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'list\'])\n_ATTRVALUE.fields_by_name[\'list\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'func\'])\n_ATTRVALUE.fields_by_name[\'func\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'placeholder\'])\n_ATTRVALUE.fields_by_name[\'placeholder\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_NAMEATTRLIST_ATTRENTRY.fields_by_name[\'value\'].message_type = _ATTRVALUE\n_NAMEATTRLIST_ATTRENTRY.containing_type = _NAMEATTRLIST\n_NAMEATTRLIST.fields_by_name[\'attr\'].message_type = _NAMEATTRLIST_ATTRENTRY\nDESCRIPTOR.message_types_by_name[\'AttrValue\'] = _ATTRVALUE\nDESCRIPTOR.message_types_by_name[\'NameAttrList\'] = _NAMEATTRLIST\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nAttrValue = _reflection.GeneratedProtocolMessageType(\'AttrValue\', (_message.Message,), {\n\n  \'ListValue\' : _reflection.GeneratedProtocolMessageType(\'ListValue\', (_message.Message,), {\n    \'DESCRIPTOR\' : _ATTRVALUE_LISTVALUE,\n    \'__module__\' : \'tensorboardX.proto.attr_value_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.AttrValue.ListValue)\n    })\n  ,\n  \'DESCRIPTOR\' : _ATTRVALUE,\n  \'__module__\' : \'tensorboardX.proto.attr_value_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.AttrValue)\n  })\n_sym_db.RegisterMessage(AttrValue)\n_sym_db.RegisterMessage(AttrValue.ListValue)\n\nNameAttrList = _reflection.GeneratedProtocolMessageType(\'NameAttrList\', (_message.Message,), {\n\n  \'AttrEntry\' : _reflection.GeneratedProtocolMessageType(\'AttrEntry\', (_message.Message,), {\n    \'DESCRIPTOR\' : _NAMEATTRLIST_ATTRENTRY,\n    \'__module__\' : \'tensorboardX.proto.attr_value_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.NameAttrList.AttrEntry)\n    })\n  ,\n  \'DESCRIPTOR\' : _NAMEATTRLIST,\n  \'__module__\' : \'tensorboardX.proto.attr_value_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.NameAttrList)\n  })\n_sym_db.RegisterMessage(NameAttrList)\n_sym_db.RegisterMessage(NameAttrList.AttrEntry)\n\n\nDESCRIPTOR._options = None\n_ATTRVALUE_LISTVALUE.fields_by_name[\'i\']._options = None\n_ATTRVALUE_LISTVALUE.fields_by_name[\'f\']._options = None\n_ATTRVALUE_LISTVALUE.fields_by_name[\'b\']._options = None\n_ATTRVALUE_LISTVALUE.fields_by_name[\'type\']._options = None\n_NAMEATTRLIST_ATTRENTRY._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/event_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/event.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorboardX.proto import summary_pb2 as tensorboardX_dot_proto_dot_summary__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/event.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\023org.tensorflow.utilB\\013EventProtosP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n\\x1etensorboardX/proto/event.proto\\x12\\x0ctensorboardX\\x1a tensorboardX/proto/summary.proto\\""\\xc3\\x02\\n\\x05\\x45vent\\x12\\x11\\n\\twall_time\\x18\\x01 \\x01(\\x01\\x12\\x0c\\n\\x04step\\x18\\x02 \\x01(\\x03\\x12\\x16\\n\\x0c\\x66ile_version\\x18\\x03 \\x01(\\tH\\x00\\x12\\x13\\n\\tgraph_def\\x18\\x04 \\x01(\\x0cH\\x00\\x12(\\n\\x07summary\\x18\\x05 \\x01(\\x0b\\x32\\x15.tensorboardX.SummaryH\\x00\\x12/\\n\\x0blog_message\\x18\\x06 \\x01(\\x0b\\x32\\x18.tensorboardX.LogMessageH\\x00\\x12/\\n\\x0bsession_log\\x18\\x07 \\x01(\\x0b\\x32\\x18.tensorboardX.SessionLogH\\x00\\x12>\\n\\x13tagged_run_metadata\\x18\\x08 \\x01(\\x0b\\x32\\x1f.tensorboardX.TaggedRunMetadataH\\x00\\x12\\x18\\n\\x0emeta_graph_def\\x18\\t \\x01(\\x0cH\\x00\\x42\\x06\\n\\x04what\\""\\x97\\x01\\n\\nLogMessage\\x12-\\n\\x05level\\x18\\x01 \\x01(\\x0e\\x32\\x1e.tensorboardX.LogMessage.Level\\x12\\x0f\\n\\x07message\\x18\\x02 \\x01(\\t\\""I\\n\\x05Level\\x12\\x0b\\n\\x07UNKNOWN\\x10\\x00\\x12\\t\\n\\x05\\x44\\x45\\x42UG\\x10\\n\\x12\\x08\\n\\x04INFO\\x10\\x14\\x12\\x08\\n\\x04WARN\\x10\\x1e\\x12\\t\\n\\x05\\x45RROR\\x10(\\x12\\t\\n\\x05\\x46\\x41TAL\\x10\\x32\\""\\xb8\\x01\\n\\nSessionLog\\x12\\x36\\n\\x06status\\x18\\x01 \\x01(\\x0e\\x32&.tensorboardX.SessionLog.SessionStatus\\x12\\x17\\n\\x0f\\x63heckpoint_path\\x18\\x02 \\x01(\\t\\x12\\x0b\\n\\x03msg\\x18\\x03 \\x01(\\t\\""L\\n\\rSessionStatus\\x12\\x16\\n\\x12STATUS_UNSPECIFIED\\x10\\x00\\x12\\t\\n\\x05START\\x10\\x01\\x12\\x08\\n\\x04STOP\\x10\\x02\\x12\\x0e\\n\\nCHECKPOINT\\x10\\x03\\""6\\n\\x11TaggedRunMetadata\\x12\\x0b\\n\\x03tag\\x18\\x01 \\x01(\\t\\x12\\x14\\n\\x0crun_metadata\\x18\\x02 \\x01(\\x0c\\x42\\\'\\n\\x13org.tensorflow.utilB\\x0b\\x45ventProtosP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n  ,\n  dependencies=[tensorboardX_dot_proto_dot_summary__pb2.DESCRIPTOR,])\n\n\n\n_LOGMESSAGE_LEVEL = _descriptor.EnumDescriptor(\n  name=\'Level\',\n  full_name=\'tensorboardX.LogMessage.Level\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'UNKNOWN\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DEBUG\', index=1, number=10,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INFO\', index=2, number=20,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WARN\', index=3, number=30,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ERROR\', index=4, number=40,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FATAL\', index=5, number=50,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=487,\n  serialized_end=560,\n)\n_sym_db.RegisterEnumDescriptor(_LOGMESSAGE_LEVEL)\n\n_SESSIONLOG_SESSIONSTATUS = _descriptor.EnumDescriptor(\n  name=\'SessionStatus\',\n  full_name=\'tensorboardX.SessionLog.SessionStatus\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STATUS_UNSPECIFIED\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'START\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOP\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CHECKPOINT\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=671,\n  serialized_end=747,\n)\n_sym_db.RegisterEnumDescriptor(_SESSIONLOG_SESSIONSTATUS)\n\n\n_EVENT = _descriptor.Descriptor(\n  name=\'Event\',\n  full_name=\'tensorboardX.Event\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'wall_time\', full_name=\'tensorboardX.Event.wall_time\', index=0,\n      number=1, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'step\', full_name=\'tensorboardX.Event.step\', index=1,\n      number=2, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'file_version\', full_name=\'tensorboardX.Event.file_version\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'graph_def\', full_name=\'tensorboardX.Event.graph_def\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'summary\', full_name=\'tensorboardX.Event.summary\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'log_message\', full_name=\'tensorboardX.Event.log_message\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'session_log\', full_name=\'tensorboardX.Event.session_log\', index=6,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tagged_run_metadata\', full_name=\'tensorboardX.Event.tagged_run_metadata\', index=7,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'meta_graph_def\', full_name=\'tensorboardX.Event.meta_graph_def\', index=8,\n      number=9, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'what\', full_name=\'tensorboardX.Event.what\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=83,\n  serialized_end=406,\n)\n\n\n_LOGMESSAGE = _descriptor.Descriptor(\n  name=\'LogMessage\',\n  full_name=\'tensorboardX.LogMessage\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'level\', full_name=\'tensorboardX.LogMessage.level\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'message\', full_name=\'tensorboardX.LogMessage.message\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LOGMESSAGE_LEVEL,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=409,\n  serialized_end=560,\n)\n\n\n_SESSIONLOG = _descriptor.Descriptor(\n  name=\'SessionLog\',\n  full_name=\'tensorboardX.SessionLog\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'status\', full_name=\'tensorboardX.SessionLog.status\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'checkpoint_path\', full_name=\'tensorboardX.SessionLog.checkpoint_path\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'msg\', full_name=\'tensorboardX.SessionLog.msg\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SESSIONLOG_SESSIONSTATUS,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=563,\n  serialized_end=747,\n)\n\n\n_TAGGEDRUNMETADATA = _descriptor.Descriptor(\n  name=\'TaggedRunMetadata\',\n  full_name=\'tensorboardX.TaggedRunMetadata\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'tag\', full_name=\'tensorboardX.TaggedRunMetadata.tag\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'run_metadata\', full_name=\'tensorboardX.TaggedRunMetadata.run_metadata\', index=1,\n      number=2, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=749,\n  serialized_end=803,\n)\n\n_EVENT.fields_by_name[\'summary\'].message_type = tensorboardX_dot_proto_dot_summary__pb2._SUMMARY\n_EVENT.fields_by_name[\'log_message\'].message_type = _LOGMESSAGE\n_EVENT.fields_by_name[\'session_log\'].message_type = _SESSIONLOG\n_EVENT.fields_by_name[\'tagged_run_metadata\'].message_type = _TAGGEDRUNMETADATA\n_EVENT.oneofs_by_name[\'what\'].fields.append(\n  _EVENT.fields_by_name[\'file_version\'])\n_EVENT.fields_by_name[\'file_version\'].containing_oneof = _EVENT.oneofs_by_name[\'what\']\n_EVENT.oneofs_by_name[\'what\'].fields.append(\n  _EVENT.fields_by_name[\'graph_def\'])\n_EVENT.fields_by_name[\'graph_def\'].containing_oneof = _EVENT.oneofs_by_name[\'what\']\n_EVENT.oneofs_by_name[\'what\'].fields.append(\n  _EVENT.fields_by_name[\'summary\'])\n_EVENT.fields_by_name[\'summary\'].containing_oneof = _EVENT.oneofs_by_name[\'what\']\n_EVENT.oneofs_by_name[\'what\'].fields.append(\n  _EVENT.fields_by_name[\'log_message\'])\n_EVENT.fields_by_name[\'log_message\'].containing_oneof = _EVENT.oneofs_by_name[\'what\']\n_EVENT.oneofs_by_name[\'what\'].fields.append(\n  _EVENT.fields_by_name[\'session_log\'])\n_EVENT.fields_by_name[\'session_log\'].containing_oneof = _EVENT.oneofs_by_name[\'what\']\n_EVENT.oneofs_by_name[\'what\'].fields.append(\n  _EVENT.fields_by_name[\'tagged_run_metadata\'])\n_EVENT.fields_by_name[\'tagged_run_metadata\'].containing_oneof = _EVENT.oneofs_by_name[\'what\']\n_EVENT.oneofs_by_name[\'what\'].fields.append(\n  _EVENT.fields_by_name[\'meta_graph_def\'])\n_EVENT.fields_by_name[\'meta_graph_def\'].containing_oneof = _EVENT.oneofs_by_name[\'what\']\n_LOGMESSAGE.fields_by_name[\'level\'].enum_type = _LOGMESSAGE_LEVEL\n_LOGMESSAGE_LEVEL.containing_type = _LOGMESSAGE\n_SESSIONLOG.fields_by_name[\'status\'].enum_type = _SESSIONLOG_SESSIONSTATUS\n_SESSIONLOG_SESSIONSTATUS.containing_type = _SESSIONLOG\nDESCRIPTOR.message_types_by_name[\'Event\'] = _EVENT\nDESCRIPTOR.message_types_by_name[\'LogMessage\'] = _LOGMESSAGE\nDESCRIPTOR.message_types_by_name[\'SessionLog\'] = _SESSIONLOG\nDESCRIPTOR.message_types_by_name[\'TaggedRunMetadata\'] = _TAGGEDRUNMETADATA\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nEvent = _reflection.GeneratedProtocolMessageType(\'Event\', (_message.Message,), {\n  \'DESCRIPTOR\' : _EVENT,\n  \'__module__\' : \'tensorboardX.proto.event_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.Event)\n  })\n_sym_db.RegisterMessage(Event)\n\nLogMessage = _reflection.GeneratedProtocolMessageType(\'LogMessage\', (_message.Message,), {\n  \'DESCRIPTOR\' : _LOGMESSAGE,\n  \'__module__\' : \'tensorboardX.proto.event_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.LogMessage)\n  })\n_sym_db.RegisterMessage(LogMessage)\n\nSessionLog = _reflection.GeneratedProtocolMessageType(\'SessionLog\', (_message.Message,), {\n  \'DESCRIPTOR\' : _SESSIONLOG,\n  \'__module__\' : \'tensorboardX.proto.event_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.SessionLog)\n  })\n_sym_db.RegisterMessage(SessionLog)\n\nTaggedRunMetadata = _reflection.GeneratedProtocolMessageType(\'TaggedRunMetadata\', (_message.Message,), {\n  \'DESCRIPTOR\' : _TAGGEDRUNMETADATA,\n  \'__module__\' : \'tensorboardX.proto.event_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.TaggedRunMetadata)\n  })\n_sym_db.RegisterMessage(TaggedRunMetadata)\n\n\nDESCRIPTOR._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/graph_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/graph.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorboardX.proto import node_def_pb2 as tensorboardX_dot_proto_dot_node__def__pb2\nfrom tensorboardX.proto import versions_pb2 as tensorboardX_dot_proto_dot_versions__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/graph.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\013GraphProtosP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n\\x1etensorboardX/proto/graph.proto\\x12\\x0ctensorboardX\\x1a!tensorboardX/proto/node_def.proto\\x1a!tensorboardX/proto/versions.proto\\""p\\n\\x08GraphDef\\x12#\\n\\x04node\\x18\\x01 \\x03(\\x0b\\x32\\x15.tensorboardX.NodeDef\\x12*\\n\\x08versions\\x18\\x04 \\x01(\\x0b\\x32\\x18.tensorboardX.VersionDef\\x12\\x13\\n\\x07version\\x18\\x03 \\x01(\\x05\\x42\\x02\\x18\\x01\\x42,\\n\\x18org.tensorflow.frameworkB\\x0bGraphProtosP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n  ,\n  dependencies=[tensorboardX_dot_proto_dot_node__def__pb2.DESCRIPTOR,tensorboardX_dot_proto_dot_versions__pb2.DESCRIPTOR,])\n\n\n\n\n_GRAPHDEF = _descriptor.Descriptor(\n  name=\'GraphDef\',\n  full_name=\'tensorboardX.GraphDef\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'node\', full_name=\'tensorboardX.GraphDef.node\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'versions\', full_name=\'tensorboardX.GraphDef.versions\', index=1,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'version\', full_name=\'tensorboardX.GraphDef.version\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\030\\001\'), file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=118,\n  serialized_end=230,\n)\n\n_GRAPHDEF.fields_by_name[\'node\'].message_type = tensorboardX_dot_proto_dot_node__def__pb2._NODEDEF\n_GRAPHDEF.fields_by_name[\'versions\'].message_type = tensorboardX_dot_proto_dot_versions__pb2._VERSIONDEF\nDESCRIPTOR.message_types_by_name[\'GraphDef\'] = _GRAPHDEF\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nGraphDef = _reflection.GeneratedProtocolMessageType(\'GraphDef\', (_message.Message,), {\n  \'DESCRIPTOR\' : _GRAPHDEF,\n  \'__module__\' : \'tensorboardX.proto.graph_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.GraphDef)\n  })\n_sym_db.RegisterMessage(GraphDef)\n\n\nDESCRIPTOR._options = None\n_GRAPHDEF.fields_by_name[\'version\']._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/layout_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/layout.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/layout.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=None,\n  serialized_pb=_b(\'\\n\\x1ftensorboardX/proto/layout.proto\\x12\\x0ctensorboardX\\""\\x8f\\x01\\n\\x05\\x43hart\\x12\\r\\n\\x05title\\x18\\x01 \\x01(\\t\\x12\\x38\\n\\tmultiline\\x18\\x02 \\x01(\\x0b\\x32#.tensorboardX.MultilineChartContentH\\x00\\x12\\x32\\n\\x06margin\\x18\\x03 \\x01(\\x0b\\x32 .tensorboardX.MarginChartContentH\\x00\\x42\\t\\n\\x07\\x63ontent\\""$\\n\\x15MultilineChartContent\\x12\\x0b\\n\\x03tag\\x18\\x01 \\x03(\\t\\""\\x84\\x01\\n\\x12MarginChartContent\\x12\\x37\\n\\x06series\\x18\\x01 \\x03(\\x0b\\x32\\\'.tensorboardX.MarginChartContent.Series\\x1a\\x35\\n\\x06Series\\x12\\r\\n\\x05value\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05lower\\x18\\x02 \\x01(\\t\\x12\\r\\n\\x05upper\\x18\\x03 \\x01(\\t\\""M\\n\\x08\\x43\\x61tegory\\x12\\r\\n\\x05title\\x18\\x01 \\x01(\\t\\x12\\""\\n\\x05\\x63hart\\x18\\x02 \\x03(\\x0b\\x32\\x13.tensorboardX.Chart\\x12\\x0e\\n\\x06\\x63losed\\x18\\x03 \\x01(\\x08\\""C\\n\\x06Layout\\x12\\x0f\\n\\x07version\\x18\\x01 \\x01(\\x05\\x12(\\n\\x08\\x63\\x61tegory\\x18\\x02 \\x03(\\x0b\\x32\\x16.tensorboardX.Categoryb\\x06proto3\')\n)\n\n\n\n\n_CHART = _descriptor.Descriptor(\n  name=\'Chart\',\n  full_name=\'tensorboardX.Chart\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'title\', full_name=\'tensorboardX.Chart.title\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'multiline\', full_name=\'tensorboardX.Chart.multiline\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'tensorboardX.Chart.margin\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'content\', full_name=\'tensorboardX.Chart.content\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=50,\n  serialized_end=193,\n)\n\n\n_MULTILINECHARTCONTENT = _descriptor.Descriptor(\n  name=\'MultilineChartContent\',\n  full_name=\'tensorboardX.MultilineChartContent\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'tag\', full_name=\'tensorboardX.MultilineChartContent.tag\', index=0,\n      number=1, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=195,\n  serialized_end=231,\n)\n\n\n_MARGINCHARTCONTENT_SERIES = _descriptor.Descriptor(\n  name=\'Series\',\n  full_name=\'tensorboardX.MarginChartContent.Series\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'tensorboardX.MarginChartContent.Series.value\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'lower\', full_name=\'tensorboardX.MarginChartContent.Series.lower\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'upper\', full_name=\'tensorboardX.MarginChartContent.Series.upper\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=313,\n  serialized_end=366,\n)\n\n_MARGINCHARTCONTENT = _descriptor.Descriptor(\n  name=\'MarginChartContent\',\n  full_name=\'tensorboardX.MarginChartContent\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'series\', full_name=\'tensorboardX.MarginChartContent.series\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_MARGINCHARTCONTENT_SERIES, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=234,\n  serialized_end=366,\n)\n\n\n_CATEGORY = _descriptor.Descriptor(\n  name=\'Category\',\n  full_name=\'tensorboardX.Category\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'title\', full_name=\'tensorboardX.Category.title\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'chart\', full_name=\'tensorboardX.Category.chart\', index=1,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'closed\', full_name=\'tensorboardX.Category.closed\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=368,\n  serialized_end=445,\n)\n\n\n_LAYOUT = _descriptor.Descriptor(\n  name=\'Layout\',\n  full_name=\'tensorboardX.Layout\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'version\', full_name=\'tensorboardX.Layout.version\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'category\', full_name=\'tensorboardX.Layout.category\', index=1,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=447,\n  serialized_end=514,\n)\n\n_CHART.fields_by_name[\'multiline\'].message_type = _MULTILINECHARTCONTENT\n_CHART.fields_by_name[\'margin\'].message_type = _MARGINCHARTCONTENT\n_CHART.oneofs_by_name[\'content\'].fields.append(\n  _CHART.fields_by_name[\'multiline\'])\n_CHART.fields_by_name[\'multiline\'].containing_oneof = _CHART.oneofs_by_name[\'content\']\n_CHART.oneofs_by_name[\'content\'].fields.append(\n  _CHART.fields_by_name[\'margin\'])\n_CHART.fields_by_name[\'margin\'].containing_oneof = _CHART.oneofs_by_name[\'content\']\n_MARGINCHARTCONTENT_SERIES.containing_type = _MARGINCHARTCONTENT\n_MARGINCHARTCONTENT.fields_by_name[\'series\'].message_type = _MARGINCHARTCONTENT_SERIES\n_CATEGORY.fields_by_name[\'chart\'].message_type = _CHART\n_LAYOUT.fields_by_name[\'category\'].message_type = _CATEGORY\nDESCRIPTOR.message_types_by_name[\'Chart\'] = _CHART\nDESCRIPTOR.message_types_by_name[\'MultilineChartContent\'] = _MULTILINECHARTCONTENT\nDESCRIPTOR.message_types_by_name[\'MarginChartContent\'] = _MARGINCHARTCONTENT\nDESCRIPTOR.message_types_by_name[\'Category\'] = _CATEGORY\nDESCRIPTOR.message_types_by_name[\'Layout\'] = _LAYOUT\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nChart = _reflection.GeneratedProtocolMessageType(\'Chart\', (_message.Message,), {\n  \'DESCRIPTOR\' : _CHART,\n  \'__module__\' : \'tensorboardX.proto.layout_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.Chart)\n  })\n_sym_db.RegisterMessage(Chart)\n\nMultilineChartContent = _reflection.GeneratedProtocolMessageType(\'MultilineChartContent\', (_message.Message,), {\n  \'DESCRIPTOR\' : _MULTILINECHARTCONTENT,\n  \'__module__\' : \'tensorboardX.proto.layout_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.MultilineChartContent)\n  })\n_sym_db.RegisterMessage(MultilineChartContent)\n\nMarginChartContent = _reflection.GeneratedProtocolMessageType(\'MarginChartContent\', (_message.Message,), {\n\n  \'Series\' : _reflection.GeneratedProtocolMessageType(\'Series\', (_message.Message,), {\n    \'DESCRIPTOR\' : _MARGINCHARTCONTENT_SERIES,\n    \'__module__\' : \'tensorboardX.proto.layout_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.MarginChartContent.Series)\n    })\n  ,\n  \'DESCRIPTOR\' : _MARGINCHARTCONTENT,\n  \'__module__\' : \'tensorboardX.proto.layout_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.MarginChartContent)\n  })\n_sym_db.RegisterMessage(MarginChartContent)\n_sym_db.RegisterMessage(MarginChartContent.Series)\n\nCategory = _reflection.GeneratedProtocolMessageType(\'Category\', (_message.Message,), {\n  \'DESCRIPTOR\' : _CATEGORY,\n  \'__module__\' : \'tensorboardX.proto.layout_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.Category)\n  })\n_sym_db.RegisterMessage(Category)\n\nLayout = _reflection.GeneratedProtocolMessageType(\'Layout\', (_message.Message,), {\n  \'DESCRIPTOR\' : _LAYOUT,\n  \'__module__\' : \'tensorboardX.proto.layout_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.Layout)\n  })\n_sym_db.RegisterMessage(Layout)\n\n\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/node_def_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/node_def.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorboardX.proto import attr_value_pb2 as tensorboardX_dot_proto_dot_attr__value__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/node_def.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\tNodeProtoP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n!tensorboardX/proto/node_def.proto\\x12\\x0ctensorboardX\\x1a#tensorboardX/proto/attr_value.proto\\""\\xb7\\x01\\n\\x07NodeDef\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\n\\n\\x02op\\x18\\x02 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12\\x0e\\n\\x06\\x64\\x65vice\\x18\\x04 \\x01(\\t\\x12-\\n\\x04\\x61ttr\\x18\\x05 \\x03(\\x0b\\x32\\x1f.tensorboardX.NodeDef.AttrEntry\\x1a\\x44\\n\\tAttrEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12&\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x17.tensorboardX.AttrValue:\\x02\\x38\\x01\\x42*\\n\\x18org.tensorflow.frameworkB\\tNodeProtoP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n  ,\n  dependencies=[tensorboardX_dot_proto_dot_attr__value__pb2.DESCRIPTOR,])\n\n\n\n\n_NODEDEF_ATTRENTRY = _descriptor.Descriptor(\n  name=\'AttrEntry\',\n  full_name=\'tensorboardX.NodeDef.AttrEntry\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'key\', full_name=\'tensorboardX.NodeDef.AttrEntry.key\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'tensorboardX.NodeDef.AttrEntry.value\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=_b(\'8\\001\'),\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=204,\n  serialized_end=272,\n)\n\n_NODEDEF = _descriptor.Descriptor(\n  name=\'NodeDef\',\n  full_name=\'tensorboardX.NodeDef\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.NodeDef.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'op\', full_name=\'tensorboardX.NodeDef.op\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'tensorboardX.NodeDef.input\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'device\', full_name=\'tensorboardX.NodeDef.device\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'attr\', full_name=\'tensorboardX.NodeDef.attr\', index=4,\n      number=5, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_NODEDEF_ATTRENTRY, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=89,\n  serialized_end=272,\n)\n\n_NODEDEF_ATTRENTRY.fields_by_name[\'value\'].message_type = tensorboardX_dot_proto_dot_attr__value__pb2._ATTRVALUE\n_NODEDEF_ATTRENTRY.containing_type = _NODEDEF\n_NODEDEF.fields_by_name[\'attr\'].message_type = _NODEDEF_ATTRENTRY\nDESCRIPTOR.message_types_by_name[\'NodeDef\'] = _NODEDEF\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nNodeDef = _reflection.GeneratedProtocolMessageType(\'NodeDef\', (_message.Message,), {\n\n  \'AttrEntry\' : _reflection.GeneratedProtocolMessageType(\'AttrEntry\', (_message.Message,), {\n    \'DESCRIPTOR\' : _NODEDEF_ATTRENTRY,\n    \'__module__\' : \'tensorboardX.proto.node_def_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.NodeDef.AttrEntry)\n    })\n  ,\n  \'DESCRIPTOR\' : _NODEDEF,\n  \'__module__\' : \'tensorboardX.proto.node_def_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.NodeDef)\n  })\n_sym_db.RegisterMessage(NodeDef)\n_sym_db.RegisterMessage(NodeDef.AttrEntry)\n\n\nDESCRIPTOR._options = None\n_NODEDEF_ATTRENTRY._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/plugin_hparams_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/plugin_hparams.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorboardX.proto import api_pb2 as tensorboardX_dot_proto_dot_api__pb2\nfrom google.protobuf import struct_pb2 as google_dot_protobuf_dot_struct__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/plugin_hparams.proto\',\n  package=\'tensorboardX.hparam\',\n  syntax=\'proto3\',\n  serialized_options=None,\n  serialized_pb=_b(\'\\n\\\'tensorboardX/proto/plugin_hparams.proto\\x12\\x13tensorboardX.hparam\\x1a\\x1ctensorboardX/proto/api.proto\\x1a\\x1cgoogle/protobuf/struct.proto\\""\\xe9\\x01\\n\\x11HParamsPluginData\\x12\\x0f\\n\\x07version\\x18\\x01 \\x01(\\x05\\x12\\x35\\n\\nexperiment\\x18\\x02 \\x01(\\x0b\\x32\\x1f.tensorboardX.hparam.ExperimentH\\x00\\x12\\x43\\n\\x12session_start_info\\x18\\x03 \\x01(\\x0b\\x32%.tensorboardX.hparam.SessionStartInfoH\\x00\\x12?\\n\\x10session_end_info\\x18\\x04 \\x01(\\x0b\\x32#.tensorboardX.hparam.SessionEndInfoH\\x00\\x42\\x06\\n\\x04\\x64\\x61ta\\""\\xf4\\x01\\n\\x10SessionStartInfo\\x12\\x43\\n\\x07hparams\\x18\\x01 \\x03(\\x0b\\x32\\x32.tensorboardX.hparam.SessionStartInfo.HparamsEntry\\x12\\x11\\n\\tmodel_uri\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\x0bmonitor_url\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\ngroup_name\\x18\\x04 \\x01(\\t\\x12\\x17\\n\\x0fstart_time_secs\\x18\\x05 \\x01(\\x01\\x1a\\x46\\n\\x0cHparamsEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12%\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\x16.google.protobuf.Value:\\x02\\x38\\x01\\""T\\n\\x0eSessionEndInfo\\x12+\\n\\x06status\\x18\\x01 \\x01(\\x0e\\x32\\x1b.tensorboardX.hparam.Status\\x12\\x15\\n\\rend_time_secs\\x18\\x02 \\x01(\\x01\\x62\\x06proto3\')\n  ,\n  dependencies=[tensorboardX_dot_proto_dot_api__pb2.DESCRIPTOR,google_dot_protobuf_dot_struct__pb2.DESCRIPTOR,])\n\n\n\n\n_HPARAMSPLUGINDATA = _descriptor.Descriptor(\n  name=\'HParamsPluginData\',\n  full_name=\'tensorboardX.hparam.HParamsPluginData\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'version\', full_name=\'tensorboardX.hparam.HParamsPluginData.version\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'experiment\', full_name=\'tensorboardX.hparam.HParamsPluginData.experiment\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'session_start_info\', full_name=\'tensorboardX.hparam.HParamsPluginData.session_start_info\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'session_end_info\', full_name=\'tensorboardX.hparam.HParamsPluginData.session_end_info\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'data\', full_name=\'tensorboardX.hparam.HParamsPluginData.data\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=125,\n  serialized_end=358,\n)\n\n\n_SESSIONSTARTINFO_HPARAMSENTRY = _descriptor.Descriptor(\n  name=\'HparamsEntry\',\n  full_name=\'tensorboardX.hparam.SessionStartInfo.HparamsEntry\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'key\', full_name=\'tensorboardX.hparam.SessionStartInfo.HparamsEntry.key\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'tensorboardX.hparam.SessionStartInfo.HparamsEntry.value\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=_b(\'8\\001\'),\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=535,\n  serialized_end=605,\n)\n\n_SESSIONSTARTINFO = _descriptor.Descriptor(\n  name=\'SessionStartInfo\',\n  full_name=\'tensorboardX.hparam.SessionStartInfo\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'hparams\', full_name=\'tensorboardX.hparam.SessionStartInfo.hparams\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'model_uri\', full_name=\'tensorboardX.hparam.SessionStartInfo.model_uri\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'monitor_url\', full_name=\'tensorboardX.hparam.SessionStartInfo.monitor_url\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'group_name\', full_name=\'tensorboardX.hparam.SessionStartInfo.group_name\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'start_time_secs\', full_name=\'tensorboardX.hparam.SessionStartInfo.start_time_secs\', index=4,\n      number=5, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_SESSIONSTARTINFO_HPARAMSENTRY, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=361,\n  serialized_end=605,\n)\n\n\n_SESSIONENDINFO = _descriptor.Descriptor(\n  name=\'SessionEndInfo\',\n  full_name=\'tensorboardX.hparam.SessionEndInfo\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'status\', full_name=\'tensorboardX.hparam.SessionEndInfo.status\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'end_time_secs\', full_name=\'tensorboardX.hparam.SessionEndInfo.end_time_secs\', index=1,\n      number=2, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=607,\n  serialized_end=691,\n)\n\n_HPARAMSPLUGINDATA.fields_by_name[\'experiment\'].message_type = tensorboardX_dot_proto_dot_api__pb2._EXPERIMENT\n_HPARAMSPLUGINDATA.fields_by_name[\'session_start_info\'].message_type = _SESSIONSTARTINFO\n_HPARAMSPLUGINDATA.fields_by_name[\'session_end_info\'].message_type = _SESSIONENDINFO\n_HPARAMSPLUGINDATA.oneofs_by_name[\'data\'].fields.append(\n  _HPARAMSPLUGINDATA.fields_by_name[\'experiment\'])\n_HPARAMSPLUGINDATA.fields_by_name[\'experiment\'].containing_oneof = _HPARAMSPLUGINDATA.oneofs_by_name[\'data\']\n_HPARAMSPLUGINDATA.oneofs_by_name[\'data\'].fields.append(\n  _HPARAMSPLUGINDATA.fields_by_name[\'session_start_info\'])\n_HPARAMSPLUGINDATA.fields_by_name[\'session_start_info\'].containing_oneof = _HPARAMSPLUGINDATA.oneofs_by_name[\'data\']\n_HPARAMSPLUGINDATA.oneofs_by_name[\'data\'].fields.append(\n  _HPARAMSPLUGINDATA.fields_by_name[\'session_end_info\'])\n_HPARAMSPLUGINDATA.fields_by_name[\'session_end_info\'].containing_oneof = _HPARAMSPLUGINDATA.oneofs_by_name[\'data\']\n_SESSIONSTARTINFO_HPARAMSENTRY.fields_by_name[\'value\'].message_type = google_dot_protobuf_dot_struct__pb2._VALUE\n_SESSIONSTARTINFO_HPARAMSENTRY.containing_type = _SESSIONSTARTINFO\n_SESSIONSTARTINFO.fields_by_name[\'hparams\'].message_type = _SESSIONSTARTINFO_HPARAMSENTRY\n_SESSIONENDINFO.fields_by_name[\'status\'].enum_type = tensorboardX_dot_proto_dot_api__pb2._STATUS\nDESCRIPTOR.message_types_by_name[\'HParamsPluginData\'] = _HPARAMSPLUGINDATA\nDESCRIPTOR.message_types_by_name[\'SessionStartInfo\'] = _SESSIONSTARTINFO\nDESCRIPTOR.message_types_by_name[\'SessionEndInfo\'] = _SESSIONENDINFO\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nHParamsPluginData = _reflection.GeneratedProtocolMessageType(\'HParamsPluginData\', (_message.Message,), {\n  \'DESCRIPTOR\' : _HPARAMSPLUGINDATA,\n  \'__module__\' : \'tensorboardX.proto.plugin_hparams_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.HParamsPluginData)\n  })\n_sym_db.RegisterMessage(HParamsPluginData)\n\nSessionStartInfo = _reflection.GeneratedProtocolMessageType(\'SessionStartInfo\', (_message.Message,), {\n\n  \'HparamsEntry\' : _reflection.GeneratedProtocolMessageType(\'HparamsEntry\', (_message.Message,), {\n    \'DESCRIPTOR\' : _SESSIONSTARTINFO_HPARAMSENTRY,\n    \'__module__\' : \'tensorboardX.proto.plugin_hparams_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.hparam.SessionStartInfo.HparamsEntry)\n    })\n  ,\n  \'DESCRIPTOR\' : _SESSIONSTARTINFO,\n  \'__module__\' : \'tensorboardX.proto.plugin_hparams_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.SessionStartInfo)\n  })\n_sym_db.RegisterMessage(SessionStartInfo)\n_sym_db.RegisterMessage(SessionStartInfo.HparamsEntry)\n\nSessionEndInfo = _reflection.GeneratedProtocolMessageType(\'SessionEndInfo\', (_message.Message,), {\n  \'DESCRIPTOR\' : _SESSIONENDINFO,\n  \'__module__\' : \'tensorboardX.proto.plugin_hparams_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.hparam.SessionEndInfo)\n  })\n_sym_db.RegisterMessage(SessionEndInfo)\n\n\n_SESSIONSTARTINFO_HPARAMSENTRY._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/plugin_mesh_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/plugin_mesh.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/plugin_mesh.proto\',\n  package=\'tensorboardX.mesh\',\n  syntax=\'proto3\',\n  serialized_options=None,\n  serialized_pb=_b(\'\\n$tensorboardX/proto/plugin_mesh.proto\\x12\\x11tensorboardX.mesh\\""\\xd7\\x01\\n\\x0eMeshPluginData\\x12\\x0f\\n\\x07version\\x18\\x01 \\x01(\\x05\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\t\\x12\\x43\\n\\x0c\\x63ontent_type\\x18\\x03 \\x01(\\x0e\\x32-.tensorboardX.mesh.MeshPluginData.ContentType\\x12\\x13\\n\\x0bjson_config\\x18\\x05 \\x01(\\t\\x12\\r\\n\\x05shape\\x18\\x06 \\x03(\\x05\\""=\\n\\x0b\\x43ontentType\\x12\\r\\n\\tUNDEFINED\\x10\\x00\\x12\\n\\n\\x06VERTEX\\x10\\x01\\x12\\x08\\n\\x04\\x46\\x41\\x43\\x45\\x10\\x02\\x12\\t\\n\\x05\\x43OLOR\\x10\\x03\\x62\\x06proto3\')\n)\n\n\n\n_MESHPLUGINDATA_CONTENTTYPE = _descriptor.EnumDescriptor(\n  name=\'ContentType\',\n  full_name=\'tensorboardX.mesh.MeshPluginData.ContentType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'UNDEFINED\', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VERTEX\', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FACE\', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'COLOR\', index=3, number=3,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=214,\n  serialized_end=275,\n)\n_sym_db.RegisterEnumDescriptor(_MESHPLUGINDATA_CONTENTTYPE)\n\n\n_MESHPLUGINDATA = _descriptor.Descriptor(\n  name=\'MeshPluginData\',\n  full_name=\'tensorboardX.mesh.MeshPluginData\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'version\', full_name=\'tensorboardX.mesh.MeshPluginData.version\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.mesh.MeshPluginData.name\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'content_type\', full_name=\'tensorboardX.mesh.MeshPluginData.content_type\', index=2,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'json_config\', full_name=\'tensorboardX.mesh.MeshPluginData.json_config\', index=3,\n      number=5, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'tensorboardX.mesh.MeshPluginData.shape\', index=4,\n      number=6, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _MESHPLUGINDATA_CONTENTTYPE,\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=60,\n  serialized_end=275,\n)\n\n_MESHPLUGINDATA.fields_by_name[\'content_type\'].enum_type = _MESHPLUGINDATA_CONTENTTYPE\n_MESHPLUGINDATA_CONTENTTYPE.containing_type = _MESHPLUGINDATA\nDESCRIPTOR.message_types_by_name[\'MeshPluginData\'] = _MESHPLUGINDATA\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nMeshPluginData = _reflection.GeneratedProtocolMessageType(\'MeshPluginData\', (_message.Message,), {\n  \'DESCRIPTOR\' : _MESHPLUGINDATA,\n  \'__module__\' : \'tensorboardX.proto.plugin_mesh_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.mesh.MeshPluginData)\n  })\n_sym_db.RegisterMessage(MeshPluginData)\n\n\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/plugin_pr_curve_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/plugin_pr_curve.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/plugin_pr_curve.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=None,\n  serialized_pb=_b(\'\\n(tensorboardX/proto/plugin_pr_curve.proto\\x12\\x0ctensorboardX\\""<\\n\\x11PrCurvePluginData\\x12\\x0f\\n\\x07version\\x18\\x01 \\x01(\\x05\\x12\\x16\\n\\x0enum_thresholds\\x18\\x02 \\x01(\\rb\\x06proto3\')\n)\n\n\n\n\n_PRCURVEPLUGINDATA = _descriptor.Descriptor(\n  name=\'PrCurvePluginData\',\n  full_name=\'tensorboardX.PrCurvePluginData\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'version\', full_name=\'tensorboardX.PrCurvePluginData.version\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_thresholds\', full_name=\'tensorboardX.PrCurvePluginData.num_thresholds\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=58,\n  serialized_end=118,\n)\n\nDESCRIPTOR.message_types_by_name[\'PrCurvePluginData\'] = _PRCURVEPLUGINDATA\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nPrCurvePluginData = _reflection.GeneratedProtocolMessageType(\'PrCurvePluginData\', (_message.Message,), {\n  \'DESCRIPTOR\' : _PRCURVEPLUGINDATA,\n  \'__module__\' : \'tensorboardX.proto.plugin_pr_curve_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.PrCurvePluginData)\n  })\n_sym_db.RegisterMessage(PrCurvePluginData)\n\n\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/plugin_text_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/plugin_text.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/plugin_text.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=None,\n  serialized_pb=_b(\'\\n$tensorboardX/proto/plugin_text.proto\\x12\\x0ctensorboardX\\""!\\n\\x0eTextPluginData\\x12\\x0f\\n\\x07version\\x18\\x01 \\x01(\\x05\\x62\\x06proto3\')\n)\n\n\n\n\n_TEXTPLUGINDATA = _descriptor.Descriptor(\n  name=\'TextPluginData\',\n  full_name=\'tensorboardX.TextPluginData\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'version\', full_name=\'tensorboardX.TextPluginData.version\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=54,\n  serialized_end=87,\n)\n\nDESCRIPTOR.message_types_by_name[\'TextPluginData\'] = _TEXTPLUGINDATA\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nTextPluginData = _reflection.GeneratedProtocolMessageType(\'TextPluginData\', (_message.Message,), {\n  \'DESCRIPTOR\' : _TEXTPLUGINDATA,\n  \'__module__\' : \'tensorboardX.proto.plugin_text_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.TextPluginData)\n  })\n_sym_db.RegisterMessage(TextPluginData)\n\n\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/resource_handle_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/resource_handle.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/resource_handle.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\016ResourceHandleP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n(tensorboardX/proto/resource_handle.proto\\x12\\x0ctensorboardX\\""r\\n\\x13ResourceHandleProto\\x12\\x0e\\n\\x06\\x64\\x65vice\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\tcontainer\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x11\\n\\thash_code\\x18\\x04 \\x01(\\x04\\x12\\x17\\n\\x0fmaybe_type_name\\x18\\x05 \\x01(\\tB/\\n\\x18org.tensorflow.frameworkB\\x0eResourceHandleP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n)\n\n\n\n\n_RESOURCEHANDLEPROTO = _descriptor.Descriptor(\n  name=\'ResourceHandleProto\',\n  full_name=\'tensorboardX.ResourceHandleProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'device\', full_name=\'tensorboardX.ResourceHandleProto.device\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'container\', full_name=\'tensorboardX.ResourceHandleProto.container\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.ResourceHandleProto.name\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'hash_code\', full_name=\'tensorboardX.ResourceHandleProto.hash_code\', index=3,\n      number=4, type=4, cpp_type=4, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'maybe_type_name\', full_name=\'tensorboardX.ResourceHandleProto.maybe_type_name\', index=4,\n      number=5, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=58,\n  serialized_end=172,\n)\n\nDESCRIPTOR.message_types_by_name[\'ResourceHandleProto\'] = _RESOURCEHANDLEPROTO\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nResourceHandleProto = _reflection.GeneratedProtocolMessageType(\'ResourceHandleProto\', (_message.Message,), {\n  \'DESCRIPTOR\' : _RESOURCEHANDLEPROTO,\n  \'__module__\' : \'tensorboardX.proto.resource_handle_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.ResourceHandleProto)\n  })\n_sym_db.RegisterMessage(ResourceHandleProto)\n\n\nDESCRIPTOR._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/step_stats_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/step_stats.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/step_stats.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\017StepStatsProtosP\\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n#tensorboardX/proto/step_stats.proto\\x12\\x0ctensorboardX\\""=\\n\\x10\\x41llocationRecord\\x12\\x14\\n\\x0c\\x61lloc_micros\\x18\\x01 \\x01(\\x03\\x12\\x13\\n\\x0b\\x61lloc_bytes\\x18\\x02 \\x01(\\x03\\""\\xc6\\x01\\n\\x13\\x41llocatorMemoryUsed\\x12\\x16\\n\\x0e\\x61llocator_name\\x18\\x01 \\x01(\\t\\x12\\x13\\n\\x0btotal_bytes\\x18\\x02 \\x01(\\x03\\x12\\x12\\n\\npeak_bytes\\x18\\x03 \\x01(\\x03\\x12\\x12\\n\\nlive_bytes\\x18\\x04 \\x01(\\x03\\x12:\\n\\x12\\x61llocation_records\\x18\\x06 \\x03(\\x0b\\x32\\x1e.tensorboardX.AllocationRecord\\x12\\x1e\\n\\x16\\x61llocator_bytes_in_use\\x18\\x05 \\x01(\\x03\\""\\x1a\\n\\nNodeOutput\\x12\\x0c\\n\\x04slot\\x18\\x01 \\x01(\\x05\\""\\xec\\x01\\n\\x0bMemoryStats\\x12\\x18\\n\\x10temp_memory_size\\x18\\x01 \\x01(\\x03\\x12\\x1e\\n\\x16persistent_memory_size\\x18\\x03 \\x01(\\x03\\x12#\\n\\x1bpersistent_tensor_alloc_ids\\x18\\x05 \\x03(\\x03\\x12#\\n\\x17\\x64\\x65vice_temp_memory_size\\x18\\x02 \\x01(\\x03\\x42\\x02\\x18\\x01\\x12)\\n\\x1d\\x64\\x65vice_persistent_memory_size\\x18\\x04 \\x01(\\x03\\x42\\x02\\x18\\x01\\x12.\\n\\""device_persistent_tensor_alloc_ids\\x18\\x06 \\x03(\\x03\\x42\\x02\\x18\\x01\\""\\xe3\\x02\\n\\rNodeExecStats\\x12\\x11\\n\\tnode_name\\x18\\x01 \\x01(\\t\\x12\\x18\\n\\x10\\x61ll_start_micros\\x18\\x02 \\x01(\\x03\\x12\\x1b\\n\\x13op_start_rel_micros\\x18\\x03 \\x01(\\x03\\x12\\x19\\n\\x11op_end_rel_micros\\x18\\x04 \\x01(\\x03\\x12\\x1a\\n\\x12\\x61ll_end_rel_micros\\x18\\x05 \\x01(\\x03\\x12\\x31\\n\\x06memory\\x18\\x06 \\x03(\\x0b\\x32!.tensorboardX.AllocatorMemoryUsed\\x12(\\n\\x06output\\x18\\x07 \\x03(\\x0b\\x32\\x18.tensorboardX.NodeOutput\\x12\\x16\\n\\x0etimeline_label\\x18\\x08 \\x01(\\t\\x12\\x18\\n\\x10scheduled_micros\\x18\\t \\x01(\\x03\\x12\\x11\\n\\tthread_id\\x18\\n \\x01(\\r\\x12/\\n\\x0cmemory_stats\\x18\\x0c \\x01(\\x0b\\x32\\x19.tensorboardX.MemoryStats\\""R\\n\\x0f\\x44\\x65viceStepStats\\x12\\x0e\\n\\x06\\x64\\x65vice\\x18\\x01 \\x01(\\t\\x12/\\n\\nnode_stats\\x18\\x02 \\x03(\\x0b\\x32\\x1b.tensorboardX.NodeExecStats\\""=\\n\\tStepStats\\x12\\x30\\n\\tdev_stats\\x18\\x01 \\x03(\\x0b\\x32\\x1d.tensorboardX.DeviceStepStats\\"":\\n\\x0bRunMetadata\\x12+\\n\\nstep_stats\\x18\\x01 \\x01(\\x0b\\x32\\x17.tensorboardX.StepStatsBo\\n\\x18org.tensorflow.frameworkB\\x0fStepStatsProtosP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3\')\n)\n\n\n\n\n_ALLOCATIONRECORD = _descriptor.Descriptor(\n  name=\'AllocationRecord\',\n  full_name=\'tensorboardX.AllocationRecord\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'alloc_micros\', full_name=\'tensorboardX.AllocationRecord.alloc_micros\', index=0,\n      number=1, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'alloc_bytes\', full_name=\'tensorboardX.AllocationRecord.alloc_bytes\', index=1,\n      number=2, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=53,\n  serialized_end=114,\n)\n\n\n_ALLOCATORMEMORYUSED = _descriptor.Descriptor(\n  name=\'AllocatorMemoryUsed\',\n  full_name=\'tensorboardX.AllocatorMemoryUsed\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'allocator_name\', full_name=\'tensorboardX.AllocatorMemoryUsed.allocator_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'total_bytes\', full_name=\'tensorboardX.AllocatorMemoryUsed.total_bytes\', index=1,\n      number=2, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'peak_bytes\', full_name=\'tensorboardX.AllocatorMemoryUsed.peak_bytes\', index=2,\n      number=3, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'live_bytes\', full_name=\'tensorboardX.AllocatorMemoryUsed.live_bytes\', index=3,\n      number=4, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'allocation_records\', full_name=\'tensorboardX.AllocatorMemoryUsed.allocation_records\', index=4,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'allocator_bytes_in_use\', full_name=\'tensorboardX.AllocatorMemoryUsed.allocator_bytes_in_use\', index=5,\n      number=5, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=117,\n  serialized_end=315,\n)\n\n\n_NODEOUTPUT = _descriptor.Descriptor(\n  name=\'NodeOutput\',\n  full_name=\'tensorboardX.NodeOutput\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'slot\', full_name=\'tensorboardX.NodeOutput.slot\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=317,\n  serialized_end=343,\n)\n\n\n_MEMORYSTATS = _descriptor.Descriptor(\n  name=\'MemoryStats\',\n  full_name=\'tensorboardX.MemoryStats\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'temp_memory_size\', full_name=\'tensorboardX.MemoryStats.temp_memory_size\', index=0,\n      number=1, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'persistent_memory_size\', full_name=\'tensorboardX.MemoryStats.persistent_memory_size\', index=1,\n      number=3, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'persistent_tensor_alloc_ids\', full_name=\'tensorboardX.MemoryStats.persistent_tensor_alloc_ids\', index=2,\n      number=5, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'device_temp_memory_size\', full_name=\'tensorboardX.MemoryStats.device_temp_memory_size\', index=3,\n      number=2, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\030\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'device_persistent_memory_size\', full_name=\'tensorboardX.MemoryStats.device_persistent_memory_size\', index=4,\n      number=4, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\030\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'device_persistent_tensor_alloc_ids\', full_name=\'tensorboardX.MemoryStats.device_persistent_tensor_alloc_ids\', index=5,\n      number=6, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\030\\001\'), file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=346,\n  serialized_end=582,\n)\n\n\n_NODEEXECSTATS = _descriptor.Descriptor(\n  name=\'NodeExecStats\',\n  full_name=\'tensorboardX.NodeExecStats\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'node_name\', full_name=\'tensorboardX.NodeExecStats.node_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'all_start_micros\', full_name=\'tensorboardX.NodeExecStats.all_start_micros\', index=1,\n      number=2, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'op_start_rel_micros\', full_name=\'tensorboardX.NodeExecStats.op_start_rel_micros\', index=2,\n      number=3, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'op_end_rel_micros\', full_name=\'tensorboardX.NodeExecStats.op_end_rel_micros\', index=3,\n      number=4, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'all_end_rel_micros\', full_name=\'tensorboardX.NodeExecStats.all_end_rel_micros\', index=4,\n      number=5, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'memory\', full_name=\'tensorboardX.NodeExecStats.memory\', index=5,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'output\', full_name=\'tensorboardX.NodeExecStats.output\', index=6,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'timeline_label\', full_name=\'tensorboardX.NodeExecStats.timeline_label\', index=7,\n      number=8, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scheduled_micros\', full_name=\'tensorboardX.NodeExecStats.scheduled_micros\', index=8,\n      number=9, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'thread_id\', full_name=\'tensorboardX.NodeExecStats.thread_id\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'memory_stats\', full_name=\'tensorboardX.NodeExecStats.memory_stats\', index=10,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=585,\n  serialized_end=940,\n)\n\n\n_DEVICESTEPSTATS = _descriptor.Descriptor(\n  name=\'DeviceStepStats\',\n  full_name=\'tensorboardX.DeviceStepStats\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'device\', full_name=\'tensorboardX.DeviceStepStats.device\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'node_stats\', full_name=\'tensorboardX.DeviceStepStats.node_stats\', index=1,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=942,\n  serialized_end=1024,\n)\n\n\n_STEPSTATS = _descriptor.Descriptor(\n  name=\'StepStats\',\n  full_name=\'tensorboardX.StepStats\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dev_stats\', full_name=\'tensorboardX.StepStats.dev_stats\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1026,\n  serialized_end=1087,\n)\n\n\n_RUNMETADATA = _descriptor.Descriptor(\n  name=\'RunMetadata\',\n  full_name=\'tensorboardX.RunMetadata\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'step_stats\', full_name=\'tensorboardX.RunMetadata.step_stats\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=1089,\n  serialized_end=1147,\n)\n\n_ALLOCATORMEMORYUSED.fields_by_name[\'allocation_records\'].message_type = _ALLOCATIONRECORD\n_NODEEXECSTATS.fields_by_name[\'memory\'].message_type = _ALLOCATORMEMORYUSED\n_NODEEXECSTATS.fields_by_name[\'output\'].message_type = _NODEOUTPUT\n_NODEEXECSTATS.fields_by_name[\'memory_stats\'].message_type = _MEMORYSTATS\n_DEVICESTEPSTATS.fields_by_name[\'node_stats\'].message_type = _NODEEXECSTATS\n_STEPSTATS.fields_by_name[\'dev_stats\'].message_type = _DEVICESTEPSTATS\n_RUNMETADATA.fields_by_name[\'step_stats\'].message_type = _STEPSTATS\nDESCRIPTOR.message_types_by_name[\'AllocationRecord\'] = _ALLOCATIONRECORD\nDESCRIPTOR.message_types_by_name[\'AllocatorMemoryUsed\'] = _ALLOCATORMEMORYUSED\nDESCRIPTOR.message_types_by_name[\'NodeOutput\'] = _NODEOUTPUT\nDESCRIPTOR.message_types_by_name[\'MemoryStats\'] = _MEMORYSTATS\nDESCRIPTOR.message_types_by_name[\'NodeExecStats\'] = _NODEEXECSTATS\nDESCRIPTOR.message_types_by_name[\'DeviceStepStats\'] = _DEVICESTEPSTATS\nDESCRIPTOR.message_types_by_name[\'StepStats\'] = _STEPSTATS\nDESCRIPTOR.message_types_by_name[\'RunMetadata\'] = _RUNMETADATA\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nAllocationRecord = _reflection.GeneratedProtocolMessageType(\'AllocationRecord\', (_message.Message,), {\n  \'DESCRIPTOR\' : _ALLOCATIONRECORD,\n  \'__module__\' : \'tensorboardX.proto.step_stats_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.AllocationRecord)\n  })\n_sym_db.RegisterMessage(AllocationRecord)\n\nAllocatorMemoryUsed = _reflection.GeneratedProtocolMessageType(\'AllocatorMemoryUsed\', (_message.Message,), {\n  \'DESCRIPTOR\' : _ALLOCATORMEMORYUSED,\n  \'__module__\' : \'tensorboardX.proto.step_stats_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.AllocatorMemoryUsed)\n  })\n_sym_db.RegisterMessage(AllocatorMemoryUsed)\n\nNodeOutput = _reflection.GeneratedProtocolMessageType(\'NodeOutput\', (_message.Message,), {\n  \'DESCRIPTOR\' : _NODEOUTPUT,\n  \'__module__\' : \'tensorboardX.proto.step_stats_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.NodeOutput)\n  })\n_sym_db.RegisterMessage(NodeOutput)\n\nMemoryStats = _reflection.GeneratedProtocolMessageType(\'MemoryStats\', (_message.Message,), {\n  \'DESCRIPTOR\' : _MEMORYSTATS,\n  \'__module__\' : \'tensorboardX.proto.step_stats_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.MemoryStats)\n  })\n_sym_db.RegisterMessage(MemoryStats)\n\nNodeExecStats = _reflection.GeneratedProtocolMessageType(\'NodeExecStats\', (_message.Message,), {\n  \'DESCRIPTOR\' : _NODEEXECSTATS,\n  \'__module__\' : \'tensorboardX.proto.step_stats_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.NodeExecStats)\n  })\n_sym_db.RegisterMessage(NodeExecStats)\n\nDeviceStepStats = _reflection.GeneratedProtocolMessageType(\'DeviceStepStats\', (_message.Message,), {\n  \'DESCRIPTOR\' : _DEVICESTEPSTATS,\n  \'__module__\' : \'tensorboardX.proto.step_stats_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.DeviceStepStats)\n  })\n_sym_db.RegisterMessage(DeviceStepStats)\n\nStepStats = _reflection.GeneratedProtocolMessageType(\'StepStats\', (_message.Message,), {\n  \'DESCRIPTOR\' : _STEPSTATS,\n  \'__module__\' : \'tensorboardX.proto.step_stats_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.StepStats)\n  })\n_sym_db.RegisterMessage(StepStats)\n\nRunMetadata = _reflection.GeneratedProtocolMessageType(\'RunMetadata\', (_message.Message,), {\n  \'DESCRIPTOR\' : _RUNMETADATA,\n  \'__module__\' : \'tensorboardX.proto.step_stats_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.RunMetadata)\n  })\n_sym_db.RegisterMessage(RunMetadata)\n\n\nDESCRIPTOR._options = None\n_MEMORYSTATS.fields_by_name[\'device_temp_memory_size\']._options = None\n_MEMORYSTATS.fields_by_name[\'device_persistent_memory_size\']._options = None\n_MEMORYSTATS.fields_by_name[\'device_persistent_tensor_alloc_ids\']._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/summary_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/summary.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorboardX.proto import tensor_pb2 as tensorboardX_dot_proto_dot_tensor__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/summary.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\rSummaryProtosP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n tensorboardX/proto/summary.proto\\x12\\x0ctensorboardX\\x1a\\x1ftensorboardX/proto/tensor.proto\\""\\\'\\n\\x12SummaryDescription\\x12\\x11\\n\\ttype_hint\\x18\\x01 \\x01(\\t\\""\\x87\\x01\\n\\x0eHistogramProto\\x12\\x0b\\n\\x03min\\x18\\x01 \\x01(\\x01\\x12\\x0b\\n\\x03max\\x18\\x02 \\x01(\\x01\\x12\\x0b\\n\\x03num\\x18\\x03 \\x01(\\x01\\x12\\x0b\\n\\x03sum\\x18\\x04 \\x01(\\x01\\x12\\x13\\n\\x0bsum_squares\\x18\\x05 \\x01(\\x01\\x12\\x18\\n\\x0c\\x62ucket_limit\\x18\\x06 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x12\\n\\x06\\x62ucket\\x18\\x07 \\x03(\\x01\\x42\\x02\\x10\\x01\\""\\xb7\\x01\\n\\x0fSummaryMetadata\\x12=\\n\\x0bplugin_data\\x18\\x01 \\x01(\\x0b\\x32(.tensorboardX.SummaryMetadata.PluginData\\x12\\x14\\n\\x0c\\x64isplay_name\\x18\\x02 \\x01(\\t\\x12\\x1b\\n\\x13summary_description\\x18\\x03 \\x01(\\t\\x1a\\x32\\n\\nPluginData\\x12\\x13\\n\\x0bplugin_name\\x18\\x01 \\x01(\\t\\x12\\x0f\\n\\x07\\x63ontent\\x18\\x02 \\x01(\\x0c\\""\\xea\\x04\\n\\x07Summary\\x12*\\n\\x05value\\x18\\x01 \\x03(\\x0b\\x32\\x1b.tensorboardX.Summary.Value\\x1aX\\n\\x05Image\\x12\\x0e\\n\\x06height\\x18\\x01 \\x01(\\x05\\x12\\r\\n\\x05width\\x18\\x02 \\x01(\\x05\\x12\\x12\\n\\ncolorspace\\x18\\x03 \\x01(\\x05\\x12\\x1c\\n\\x14\\x65ncoded_image_string\\x18\\x04 \\x01(\\x0c\\x1a}\\n\\x05\\x41udio\\x12\\x13\\n\\x0bsample_rate\\x18\\x01 \\x01(\\x02\\x12\\x14\\n\\x0cnum_channels\\x18\\x02 \\x01(\\x03\\x12\\x15\\n\\rlength_frames\\x18\\x03 \\x01(\\x03\\x12\\x1c\\n\\x14\\x65ncoded_audio_string\\x18\\x04 \\x01(\\x0c\\x12\\x14\\n\\x0c\\x63ontent_type\\x18\\x05 \\x01(\\t\\x1a\\xd9\\x02\\n\\x05Value\\x12\\x11\\n\\tnode_name\\x18\\x07 \\x01(\\t\\x12\\x0b\\n\\x03tag\\x18\\x01 \\x01(\\t\\x12/\\n\\x08metadata\\x18\\t \\x01(\\x0b\\x32\\x1d.tensorboardX.SummaryMetadata\\x12\\x16\\n\\x0csimple_value\\x18\\x02 \\x01(\\x02H\\x00\\x12&\\n\\x1cobsolete_old_style_histogram\\x18\\x03 \\x01(\\x0cH\\x00\\x12,\\n\\x05image\\x18\\x04 \\x01(\\x0b\\x32\\x1b.tensorboardX.Summary.ImageH\\x00\\x12-\\n\\x05histo\\x18\\x05 \\x01(\\x0b\\x32\\x1c.tensorboardX.HistogramProtoH\\x00\\x12,\\n\\x05\\x61udio\\x18\\x06 \\x01(\\x0b\\x32\\x1b.tensorboardX.Summary.AudioH\\x00\\x12+\\n\\x06tensor\\x18\\x08 \\x01(\\x0b\\x32\\x19.tensorboardX.TensorProtoH\\x00\\x42\\x07\\n\\x05valueB.\\n\\x18org.tensorflow.frameworkB\\rSummaryProtosP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n  ,\n  dependencies=[tensorboardX_dot_proto_dot_tensor__pb2.DESCRIPTOR,])\n\n\n\n\n_SUMMARYDESCRIPTION = _descriptor.Descriptor(\n  name=\'SummaryDescription\',\n  full_name=\'tensorboardX.SummaryDescription\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type_hint\', full_name=\'tensorboardX.SummaryDescription.type_hint\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=83,\n  serialized_end=122,\n)\n\n\n_HISTOGRAMPROTO = _descriptor.Descriptor(\n  name=\'HistogramProto\',\n  full_name=\'tensorboardX.HistogramProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'min\', full_name=\'tensorboardX.HistogramProto.min\', index=0,\n      number=1, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'max\', full_name=\'tensorboardX.HistogramProto.max\', index=1,\n      number=2, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'tensorboardX.HistogramProto.num\', index=2,\n      number=3, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sum\', full_name=\'tensorboardX.HistogramProto.sum\', index=3,\n      number=4, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'sum_squares\', full_name=\'tensorboardX.HistogramProto.sum_squares\', index=4,\n      number=5, type=1, cpp_type=5, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bucket_limit\', full_name=\'tensorboardX.HistogramProto.bucket_limit\', index=5,\n      number=6, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bucket\', full_name=\'tensorboardX.HistogramProto.bucket\', index=6,\n      number=7, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=125,\n  serialized_end=260,\n)\n\n\n_SUMMARYMETADATA_PLUGINDATA = _descriptor.Descriptor(\n  name=\'PluginData\',\n  full_name=\'tensorboardX.SummaryMetadata.PluginData\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'plugin_name\', full_name=\'tensorboardX.SummaryMetadata.PluginData.plugin_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'content\', full_name=\'tensorboardX.SummaryMetadata.PluginData.content\', index=1,\n      number=2, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=396,\n  serialized_end=446,\n)\n\n_SUMMARYMETADATA = _descriptor.Descriptor(\n  name=\'SummaryMetadata\',\n  full_name=\'tensorboardX.SummaryMetadata\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'plugin_data\', full_name=\'tensorboardX.SummaryMetadata.plugin_data\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'display_name\', full_name=\'tensorboardX.SummaryMetadata.display_name\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'summary_description\', full_name=\'tensorboardX.SummaryMetadata.summary_description\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_SUMMARYMETADATA_PLUGINDATA, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=263,\n  serialized_end=446,\n)\n\n\n_SUMMARY_IMAGE = _descriptor.Descriptor(\n  name=\'Image\',\n  full_name=\'tensorboardX.Summary.Image\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'tensorboardX.Summary.Image.height\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'tensorboardX.Summary.Image.width\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'colorspace\', full_name=\'tensorboardX.Summary.Image.colorspace\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'encoded_image_string\', full_name=\'tensorboardX.Summary.Image.encoded_image_string\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=504,\n  serialized_end=592,\n)\n\n_SUMMARY_AUDIO = _descriptor.Descriptor(\n  name=\'Audio\',\n  full_name=\'tensorboardX.Summary.Audio\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'sample_rate\', full_name=\'tensorboardX.Summary.Audio.sample_rate\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'num_channels\', full_name=\'tensorboardX.Summary.Audio.num_channels\', index=1,\n      number=2, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'length_frames\', full_name=\'tensorboardX.Summary.Audio.length_frames\', index=2,\n      number=3, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'encoded_audio_string\', full_name=\'tensorboardX.Summary.Audio.encoded_audio_string\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'content_type\', full_name=\'tensorboardX.Summary.Audio.content_type\', index=4,\n      number=5, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=594,\n  serialized_end=719,\n)\n\n_SUMMARY_VALUE = _descriptor.Descriptor(\n  name=\'Value\',\n  full_name=\'tensorboardX.Summary.Value\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'node_name\', full_name=\'tensorboardX.Summary.Value.node_name\', index=0,\n      number=7, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tag\', full_name=\'tensorboardX.Summary.Value.tag\', index=1,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'metadata\', full_name=\'tensorboardX.Summary.Value.metadata\', index=2,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'simple_value\', full_name=\'tensorboardX.Summary.Value.simple_value\', index=3,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'obsolete_old_style_histogram\', full_name=\'tensorboardX.Summary.Value.obsolete_old_style_histogram\', index=4,\n      number=3, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'image\', full_name=\'tensorboardX.Summary.Value.image\', index=5,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'histo\', full_name=\'tensorboardX.Summary.Value.histo\', index=6,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'audio\', full_name=\'tensorboardX.Summary.Value.audio\', index=7,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tensor\', full_name=\'tensorboardX.Summary.Value.tensor\', index=8,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'value\', full_name=\'tensorboardX.Summary.Value.value\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=722,\n  serialized_end=1067,\n)\n\n_SUMMARY = _descriptor.Descriptor(\n  name=\'Summary\',\n  full_name=\'tensorboardX.Summary\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'tensorboardX.Summary.value\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_SUMMARY_IMAGE, _SUMMARY_AUDIO, _SUMMARY_VALUE, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=449,\n  serialized_end=1067,\n)\n\n_SUMMARYMETADATA_PLUGINDATA.containing_type = _SUMMARYMETADATA\n_SUMMARYMETADATA.fields_by_name[\'plugin_data\'].message_type = _SUMMARYMETADATA_PLUGINDATA\n_SUMMARY_IMAGE.containing_type = _SUMMARY\n_SUMMARY_AUDIO.containing_type = _SUMMARY\n_SUMMARY_VALUE.fields_by_name[\'metadata\'].message_type = _SUMMARYMETADATA\n_SUMMARY_VALUE.fields_by_name[\'image\'].message_type = _SUMMARY_IMAGE\n_SUMMARY_VALUE.fields_by_name[\'histo\'].message_type = _HISTOGRAMPROTO\n_SUMMARY_VALUE.fields_by_name[\'audio\'].message_type = _SUMMARY_AUDIO\n_SUMMARY_VALUE.fields_by_name[\'tensor\'].message_type = tensorboardX_dot_proto_dot_tensor__pb2._TENSORPROTO\n_SUMMARY_VALUE.containing_type = _SUMMARY\n_SUMMARY_VALUE.oneofs_by_name[\'value\'].fields.append(\n  _SUMMARY_VALUE.fields_by_name[\'simple_value\'])\n_SUMMARY_VALUE.fields_by_name[\'simple_value\'].containing_oneof = _SUMMARY_VALUE.oneofs_by_name[\'value\']\n_SUMMARY_VALUE.oneofs_by_name[\'value\'].fields.append(\n  _SUMMARY_VALUE.fields_by_name[\'obsolete_old_style_histogram\'])\n_SUMMARY_VALUE.fields_by_name[\'obsolete_old_style_histogram\'].containing_oneof = _SUMMARY_VALUE.oneofs_by_name[\'value\']\n_SUMMARY_VALUE.oneofs_by_name[\'value\'].fields.append(\n  _SUMMARY_VALUE.fields_by_name[\'image\'])\n_SUMMARY_VALUE.fields_by_name[\'image\'].containing_oneof = _SUMMARY_VALUE.oneofs_by_name[\'value\']\n_SUMMARY_VALUE.oneofs_by_name[\'value\'].fields.append(\n  _SUMMARY_VALUE.fields_by_name[\'histo\'])\n_SUMMARY_VALUE.fields_by_name[\'histo\'].containing_oneof = _SUMMARY_VALUE.oneofs_by_name[\'value\']\n_SUMMARY_VALUE.oneofs_by_name[\'value\'].fields.append(\n  _SUMMARY_VALUE.fields_by_name[\'audio\'])\n_SUMMARY_VALUE.fields_by_name[\'audio\'].containing_oneof = _SUMMARY_VALUE.oneofs_by_name[\'value\']\n_SUMMARY_VALUE.oneofs_by_name[\'value\'].fields.append(\n  _SUMMARY_VALUE.fields_by_name[\'tensor\'])\n_SUMMARY_VALUE.fields_by_name[\'tensor\'].containing_oneof = _SUMMARY_VALUE.oneofs_by_name[\'value\']\n_SUMMARY.fields_by_name[\'value\'].message_type = _SUMMARY_VALUE\nDESCRIPTOR.message_types_by_name[\'SummaryDescription\'] = _SUMMARYDESCRIPTION\nDESCRIPTOR.message_types_by_name[\'HistogramProto\'] = _HISTOGRAMPROTO\nDESCRIPTOR.message_types_by_name[\'SummaryMetadata\'] = _SUMMARYMETADATA\nDESCRIPTOR.message_types_by_name[\'Summary\'] = _SUMMARY\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nSummaryDescription = _reflection.GeneratedProtocolMessageType(\'SummaryDescription\', (_message.Message,), {\n  \'DESCRIPTOR\' : _SUMMARYDESCRIPTION,\n  \'__module__\' : \'tensorboardX.proto.summary_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.SummaryDescription)\n  })\n_sym_db.RegisterMessage(SummaryDescription)\n\nHistogramProto = _reflection.GeneratedProtocolMessageType(\'HistogramProto\', (_message.Message,), {\n  \'DESCRIPTOR\' : _HISTOGRAMPROTO,\n  \'__module__\' : \'tensorboardX.proto.summary_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.HistogramProto)\n  })\n_sym_db.RegisterMessage(HistogramProto)\n\nSummaryMetadata = _reflection.GeneratedProtocolMessageType(\'SummaryMetadata\', (_message.Message,), {\n\n  \'PluginData\' : _reflection.GeneratedProtocolMessageType(\'PluginData\', (_message.Message,), {\n    \'DESCRIPTOR\' : _SUMMARYMETADATA_PLUGINDATA,\n    \'__module__\' : \'tensorboardX.proto.summary_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.SummaryMetadata.PluginData)\n    })\n  ,\n  \'DESCRIPTOR\' : _SUMMARYMETADATA,\n  \'__module__\' : \'tensorboardX.proto.summary_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.SummaryMetadata)\n  })\n_sym_db.RegisterMessage(SummaryMetadata)\n_sym_db.RegisterMessage(SummaryMetadata.PluginData)\n\nSummary = _reflection.GeneratedProtocolMessageType(\'Summary\', (_message.Message,), {\n\n  \'Image\' : _reflection.GeneratedProtocolMessageType(\'Image\', (_message.Message,), {\n    \'DESCRIPTOR\' : _SUMMARY_IMAGE,\n    \'__module__\' : \'tensorboardX.proto.summary_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.Summary.Image)\n    })\n  ,\n\n  \'Audio\' : _reflection.GeneratedProtocolMessageType(\'Audio\', (_message.Message,), {\n    \'DESCRIPTOR\' : _SUMMARY_AUDIO,\n    \'__module__\' : \'tensorboardX.proto.summary_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.Summary.Audio)\n    })\n  ,\n\n  \'Value\' : _reflection.GeneratedProtocolMessageType(\'Value\', (_message.Message,), {\n    \'DESCRIPTOR\' : _SUMMARY_VALUE,\n    \'__module__\' : \'tensorboardX.proto.summary_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.Summary.Value)\n    })\n  ,\n  \'DESCRIPTOR\' : _SUMMARY,\n  \'__module__\' : \'tensorboardX.proto.summary_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.Summary)\n  })\n_sym_db.RegisterMessage(Summary)\n_sym_db.RegisterMessage(Summary.Image)\n_sym_db.RegisterMessage(Summary.Audio)\n_sym_db.RegisterMessage(Summary.Value)\n\n\nDESCRIPTOR._options = None\n_HISTOGRAMPROTO.fields_by_name[\'bucket_limit\']._options = None\n_HISTOGRAMPROTO.fields_by_name[\'bucket\']._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/tensor_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/tensor.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\nfrom tensorboardX.proto import resource_handle_pb2 as tensorboardX_dot_proto_dot_resource__handle__pb2\nfrom tensorboardX.proto import tensor_shape_pb2 as tensorboardX_dot_proto_dot_tensor__shape__pb2\nfrom tensorboardX.proto import types_pb2 as tensorboardX_dot_proto_dot_types__pb2\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/tensor.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\014TensorProtosP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n\\x1ftensorboardX/proto/tensor.proto\\x12\\x0ctensorboardX\\x1a(tensorboardX/proto/resource_handle.proto\\x1a%tensorboardX/proto/tensor_shape.proto\\x1a\\x1etensorboardX/proto/types.proto\\""\\xa9\\x03\\n\\x0bTensorProto\\x12%\\n\\x05\\x64type\\x18\\x01 \\x01(\\x0e\\x32\\x16.tensorboardX.DataType\\x12\\x34\\n\\x0ctensor_shape\\x18\\x02 \\x01(\\x0b\\x32\\x1e.tensorboardX.TensorShapeProto\\x12\\x16\\n\\x0eversion_number\\x18\\x03 \\x01(\\x05\\x12\\x16\\n\\x0etensor_content\\x18\\x04 \\x01(\\x0c\\x12\\x14\\n\\x08half_val\\x18\\r \\x03(\\x05\\x42\\x02\\x10\\x01\\x12\\x15\\n\\tfloat_val\\x18\\x05 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x16\\n\\ndouble_val\\x18\\x06 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x13\\n\\x07int_val\\x18\\x07 \\x03(\\x05\\x42\\x02\\x10\\x01\\x12\\x12\\n\\nstring_val\\x18\\x08 \\x03(\\x0c\\x12\\x18\\n\\x0cscomplex_val\\x18\\t \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x15\\n\\tint64_val\\x18\\n \\x03(\\x03\\x42\\x02\\x10\\x01\\x12\\x14\\n\\x08\\x62ool_val\\x18\\x0b \\x03(\\x08\\x42\\x02\\x10\\x01\\x12\\x18\\n\\x0c\\x64\\x63omplex_val\\x18\\x0c \\x03(\\x01\\x42\\x02\\x10\\x01\\x12>\\n\\x13resource_handle_val\\x18\\x0e \\x03(\\x0b\\x32!.tensorboardX.ResourceHandleProtoB-\\n\\x18org.tensorflow.frameworkB\\x0cTensorProtosP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n  ,\n  dependencies=[tensorboardX_dot_proto_dot_resource__handle__pb2.DESCRIPTOR,tensorboardX_dot_proto_dot_tensor__shape__pb2.DESCRIPTOR,tensorboardX_dot_proto_dot_types__pb2.DESCRIPTOR,])\n\n\n\n\n_TENSORPROTO = _descriptor.Descriptor(\n  name=\'TensorProto\',\n  full_name=\'tensorboardX.TensorProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dtype\', full_name=\'tensorboardX.TensorProto.dtype\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tensor_shape\', full_name=\'tensorboardX.TensorProto.tensor_shape\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'version_number\', full_name=\'tensorboardX.TensorProto.version_number\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'tensor_content\', full_name=\'tensorboardX.TensorProto.tensor_content\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'half_val\', full_name=\'tensorboardX.TensorProto.half_val\', index=4,\n      number=13, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'float_val\', full_name=\'tensorboardX.TensorProto.float_val\', index=5,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'double_val\', full_name=\'tensorboardX.TensorProto.double_val\', index=6,\n      number=6, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'int_val\', full_name=\'tensorboardX.TensorProto.int_val\', index=7,\n      number=7, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'string_val\', full_name=\'tensorboardX.TensorProto.string_val\', index=8,\n      number=8, type=12, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'scomplex_val\', full_name=\'tensorboardX.TensorProto.scomplex_val\', index=9,\n      number=9, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'int64_val\', full_name=\'tensorboardX.TensorProto.int64_val\', index=10,\n      number=10, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bool_val\', full_name=\'tensorboardX.TensorProto.bool_val\', index=11,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'dcomplex_val\', full_name=\'tensorboardX.TensorProto.dcomplex_val\', index=12,\n      number=12, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=_b(\'\\020\\001\'), file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'resource_handle_val\', full_name=\'tensorboardX.TensorProto.resource_handle_val\', index=13,\n      number=14, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=163,\n  serialized_end=588,\n)\n\n_TENSORPROTO.fields_by_name[\'dtype\'].enum_type = tensorboardX_dot_proto_dot_types__pb2._DATATYPE\n_TENSORPROTO.fields_by_name[\'tensor_shape\'].message_type = tensorboardX_dot_proto_dot_tensor__shape__pb2._TENSORSHAPEPROTO\n_TENSORPROTO.fields_by_name[\'resource_handle_val\'].message_type = tensorboardX_dot_proto_dot_resource__handle__pb2._RESOURCEHANDLEPROTO\nDESCRIPTOR.message_types_by_name[\'TensorProto\'] = _TENSORPROTO\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nTensorProto = _reflection.GeneratedProtocolMessageType(\'TensorProto\', (_message.Message,), {\n  \'DESCRIPTOR\' : _TENSORPROTO,\n  \'__module__\' : \'tensorboardX.proto.tensor_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.TensorProto)\n  })\n_sym_db.RegisterMessage(TensorProto)\n\n\nDESCRIPTOR._options = None\n_TENSORPROTO.fields_by_name[\'half_val\']._options = None\n_TENSORPROTO.fields_by_name[\'float_val\']._options = None\n_TENSORPROTO.fields_by_name[\'double_val\']._options = None\n_TENSORPROTO.fields_by_name[\'int_val\']._options = None\n_TENSORPROTO.fields_by_name[\'scomplex_val\']._options = None\n_TENSORPROTO.fields_by_name[\'int64_val\']._options = None\n_TENSORPROTO.fields_by_name[\'bool_val\']._options = None\n_TENSORPROTO.fields_by_name[\'dcomplex_val\']._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/tensor_shape_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/tensor_shape.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/tensor_shape.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\021TensorShapeProtosP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n%tensorboardX/proto/tensor_shape.proto\\x12\\x0ctensorboardX\\""|\\n\\x10TensorShapeProto\\x12/\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32\\"".tensorboardX.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tB2\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n)\n\n\n\n\n_TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n  name=\'Dim\',\n  full_name=\'tensorboardX.TensorShapeProto.Dim\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'size\', full_name=\'tensorboardX.TensorShapeProto.Dim.size\', index=0,\n      number=1, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'tensorboardX.TensorShapeProto.Dim.name\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=146,\n  serialized_end=179,\n)\n\n_TENSORSHAPEPROTO = _descriptor.Descriptor(\n  name=\'TensorShapeProto\',\n  full_name=\'tensorboardX.TensorShapeProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'tensorboardX.TensorShapeProto.dim\', index=0,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'unknown_rank\', full_name=\'tensorboardX.TensorShapeProto.unknown_rank\', index=1,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[_TENSORSHAPEPROTO_DIM, ],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=55,\n  serialized_end=179,\n)\n\n_TENSORSHAPEPROTO_DIM.containing_type = _TENSORSHAPEPROTO\n_TENSORSHAPEPROTO.fields_by_name[\'dim\'].message_type = _TENSORSHAPEPROTO_DIM\nDESCRIPTOR.message_types_by_name[\'TensorShapeProto\'] = _TENSORSHAPEPROTO\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nTensorShapeProto = _reflection.GeneratedProtocolMessageType(\'TensorShapeProto\', (_message.Message,), {\n\n  \'Dim\' : _reflection.GeneratedProtocolMessageType(\'Dim\', (_message.Message,), {\n    \'DESCRIPTOR\' : _TENSORSHAPEPROTO_DIM,\n    \'__module__\' : \'tensorboardX.proto.tensor_shape_pb2\'\n    # @@protoc_insertion_point(class_scope:tensorboardX.TensorShapeProto.Dim)\n    })\n  ,\n  \'DESCRIPTOR\' : _TENSORSHAPEPROTO,\n  \'__module__\' : \'tensorboardX.proto.tensor_shape_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.TensorShapeProto)\n  })\n_sym_db.RegisterMessage(TensorShapeProto)\n_sym_db.RegisterMessage(TensorShapeProto.Dim)\n\n\nDESCRIPTOR._options = None\n# @@protoc_insertion_point(module_scope)\n'"
tensorboardX/proto/types_pb2.py,0,"b""# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/types.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name='tensorboardX/proto/types.proto',\n  package='tensorboardX',\n  syntax='proto3',\n  serialized_options=_b('\\n\\030org.tensorflow.frameworkB\\013TypesProtosP\\001\\370\\001\\001'),\n  serialized_pb=_b('\\n\\x1etensorboardX/proto/types.proto\\x12\\x0ctensorboardX*\\xc2\\x05\\n\\x08\\x44\\x61taType\\x12\\x0e\\n\\nDT_INVALID\\x10\\x00\\x12\\x0c\\n\\x08\\x44T_FLOAT\\x10\\x01\\x12\\r\\n\\tDT_DOUBLE\\x10\\x02\\x12\\x0c\\n\\x08\\x44T_INT32\\x10\\x03\\x12\\x0c\\n\\x08\\x44T_UINT8\\x10\\x04\\x12\\x0c\\n\\x08\\x44T_INT16\\x10\\x05\\x12\\x0b\\n\\x07\\x44T_INT8\\x10\\x06\\x12\\r\\n\\tDT_STRING\\x10\\x07\\x12\\x10\\n\\x0c\\x44T_COMPLEX64\\x10\\x08\\x12\\x0c\\n\\x08\\x44T_INT64\\x10\\t\\x12\\x0b\\n\\x07\\x44T_BOOL\\x10\\n\\x12\\x0c\\n\\x08\\x44T_QINT8\\x10\\x0b\\x12\\r\\n\\tDT_QUINT8\\x10\\x0c\\x12\\r\\n\\tDT_QINT32\\x10\\r\\x12\\x0f\\n\\x0b\\x44T_BFLOAT16\\x10\\x0e\\x12\\r\\n\\tDT_QINT16\\x10\\x0f\\x12\\x0e\\n\\nDT_QUINT16\\x10\\x10\\x12\\r\\n\\tDT_UINT16\\x10\\x11\\x12\\x11\\n\\rDT_COMPLEX128\\x10\\x12\\x12\\x0b\\n\\x07\\x44T_HALF\\x10\\x13\\x12\\x0f\\n\\x0b\\x44T_RESOURCE\\x10\\x14\\x12\\x10\\n\\x0c\\x44T_FLOAT_REF\\x10\\x65\\x12\\x11\\n\\rDT_DOUBLE_REF\\x10\\x66\\x12\\x10\\n\\x0c\\x44T_INT32_REF\\x10g\\x12\\x10\\n\\x0c\\x44T_UINT8_REF\\x10h\\x12\\x10\\n\\x0c\\x44T_INT16_REF\\x10i\\x12\\x0f\\n\\x0b\\x44T_INT8_REF\\x10j\\x12\\x11\\n\\rDT_STRING_REF\\x10k\\x12\\x14\\n\\x10\\x44T_COMPLEX64_REF\\x10l\\x12\\x10\\n\\x0c\\x44T_INT64_REF\\x10m\\x12\\x0f\\n\\x0b\\x44T_BOOL_REF\\x10n\\x12\\x10\\n\\x0c\\x44T_QINT8_REF\\x10o\\x12\\x11\\n\\rDT_QUINT8_REF\\x10p\\x12\\x11\\n\\rDT_QINT32_REF\\x10q\\x12\\x13\\n\\x0f\\x44T_BFLOAT16_REF\\x10r\\x12\\x11\\n\\rDT_QINT16_REF\\x10s\\x12\\x12\\n\\x0e\\x44T_QUINT16_REF\\x10t\\x12\\x11\\n\\rDT_UINT16_REF\\x10u\\x12\\x15\\n\\x11\\x44T_COMPLEX128_REF\\x10v\\x12\\x0f\\n\\x0b\\x44T_HALF_REF\\x10w\\x12\\x13\\n\\x0f\\x44T_RESOURCE_REF\\x10xB,\\n\\x18org.tensorflow.frameworkB\\x0bTypesProtosP\\x01\\xf8\\x01\\x01\\x62\\x06proto3')\n)\n\n_DATATYPE = _descriptor.EnumDescriptor(\n  name='DataType',\n  full_name='tensorboardX.DataType',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name='DT_INVALID', index=0, number=0,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_FLOAT', index=1, number=1,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_DOUBLE', index=2, number=2,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_INT32', index=3, number=3,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_UINT8', index=4, number=4,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_INT16', index=5, number=5,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_INT8', index=6, number=6,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_STRING', index=7, number=7,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_COMPLEX64', index=8, number=8,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_INT64', index=9, number=9,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_BOOL', index=10, number=10,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QINT8', index=11, number=11,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QUINT8', index=12, number=12,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QINT32', index=13, number=13,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_BFLOAT16', index=14, number=14,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QINT16', index=15, number=15,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QUINT16', index=16, number=16,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_UINT16', index=17, number=17,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_COMPLEX128', index=18, number=18,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_HALF', index=19, number=19,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_RESOURCE', index=20, number=20,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_FLOAT_REF', index=21, number=101,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_DOUBLE_REF', index=22, number=102,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_INT32_REF', index=23, number=103,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_UINT8_REF', index=24, number=104,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_INT16_REF', index=25, number=105,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_INT8_REF', index=26, number=106,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_STRING_REF', index=27, number=107,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_COMPLEX64_REF', index=28, number=108,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_INT64_REF', index=29, number=109,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_BOOL_REF', index=30, number=110,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QINT8_REF', index=31, number=111,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QUINT8_REF', index=32, number=112,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QINT32_REF', index=33, number=113,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_BFLOAT16_REF', index=34, number=114,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QINT16_REF', index=35, number=115,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_QUINT16_REF', index=36, number=116,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_UINT16_REF', index=37, number=117,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_COMPLEX128_REF', index=38, number=118,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_HALF_REF', index=39, number=119,\n      serialized_options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name='DT_RESOURCE_REF', index=40, number=120,\n      serialized_options=None,\n      type=None),\n  ],\n  containing_type=None,\n  serialized_options=None,\n  serialized_start=49,\n  serialized_end=755,\n)\n_sym_db.RegisterEnumDescriptor(_DATATYPE)\n\nDataType = enum_type_wrapper.EnumTypeWrapper(_DATATYPE)\nDT_INVALID = 0\nDT_FLOAT = 1\nDT_DOUBLE = 2\nDT_INT32 = 3\nDT_UINT8 = 4\nDT_INT16 = 5\nDT_INT8 = 6\nDT_STRING = 7\nDT_COMPLEX64 = 8\nDT_INT64 = 9\nDT_BOOL = 10\nDT_QINT8 = 11\nDT_QUINT8 = 12\nDT_QINT32 = 13\nDT_BFLOAT16 = 14\nDT_QINT16 = 15\nDT_QUINT16 = 16\nDT_UINT16 = 17\nDT_COMPLEX128 = 18\nDT_HALF = 19\nDT_RESOURCE = 20\nDT_FLOAT_REF = 101\nDT_DOUBLE_REF = 102\nDT_INT32_REF = 103\nDT_UINT8_REF = 104\nDT_INT16_REF = 105\nDT_INT8_REF = 106\nDT_STRING_REF = 107\nDT_COMPLEX64_REF = 108\nDT_INT64_REF = 109\nDT_BOOL_REF = 110\nDT_QINT8_REF = 111\nDT_QUINT8_REF = 112\nDT_QINT32_REF = 113\nDT_BFLOAT16_REF = 114\nDT_QINT16_REF = 115\nDT_QUINT16_REF = 116\nDT_UINT16_REF = 117\nDT_COMPLEX128_REF = 118\nDT_HALF_REF = 119\nDT_RESOURCE_REF = 120\n\n\nDESCRIPTOR.enum_types_by_name['DataType'] = _DATATYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\n\nDESCRIPTOR._options = None\n# @@protoc_insertion_point(module_scope)\n"""
tensorboardX/proto/versions_pb2.py,0,"b'# -*- coding: utf-8 -*-\n# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: tensorboardX/proto/versions.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'tensorboardX/proto/versions.proto\',\n  package=\'tensorboardX\',\n  syntax=\'proto3\',\n  serialized_options=_b(\'\\n\\030org.tensorflow.frameworkB\\016VersionsProtosP\\001\\370\\001\\001\'),\n  serialized_pb=_b(\'\\n!tensorboardX/proto/versions.proto\\x12\\x0ctensorboardX\\""K\\n\\nVersionDef\\x12\\x10\\n\\x08producer\\x18\\x01 \\x01(\\x05\\x12\\x14\\n\\x0cmin_consumer\\x18\\x02 \\x01(\\x05\\x12\\x15\\n\\rbad_consumers\\x18\\x03 \\x03(\\x05\\x42/\\n\\x18org.tensorflow.frameworkB\\x0eVersionsProtosP\\x01\\xf8\\x01\\x01\\x62\\x06proto3\')\n)\n\n\n\n\n_VERSIONDEF = _descriptor.Descriptor(\n  name=\'VersionDef\',\n  full_name=\'tensorboardX.VersionDef\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'producer\', full_name=\'tensorboardX.VersionDef.producer\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'min_consumer\', full_name=\'tensorboardX.VersionDef.min_consumer\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n    _descriptor.FieldDescriptor(\n      name=\'bad_consumers\', full_name=\'tensorboardX.VersionDef.bad_consumers\', index=2,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      serialized_options=None, file=DESCRIPTOR),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  serialized_options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=51,\n  serialized_end=126,\n)\n\nDESCRIPTOR.message_types_by_name[\'VersionDef\'] = _VERSIONDEF\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nVersionDef = _reflection.GeneratedProtocolMessageType(\'VersionDef\', (_message.Message,), {\n  \'DESCRIPTOR\' : _VERSIONDEF,\n  \'__module__\' : \'tensorboardX.proto.versions_pb2\'\n  # @@protoc_insertion_point(class_scope:tensorboardX.VersionDef)\n  })\n_sym_db.RegisterMessage(VersionDef)\n\n\nDESCRIPTOR._options = None\n# @@protoc_insertion_point(module_scope)\n'"
examples/chainer/extension_logger/net.py,0,"b'#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport numpy\n\nimport chainer\nfrom chainer import cuda\nimport chainer.functions as F\nimport chainer.links as L\n\n\ndef add_noise(h, sigma=0.2):\n    xp = cuda.get_array_module(h.data)\n    if chainer.config.train:\n        return h + sigma * xp.random.randn(*h.shape)\n    else:\n        return h\n\n\nclass Generator(chainer.Chain):\n\n    def __init__(self, n_hidden, bottom_width=4, ch=512, wscale=0.02):\n        super(Generator, self).__init__()\n        self.n_hidden = n_hidden\n        self.ch = ch\n        self.bottom_width = bottom_width\n\n        with self.init_scope():\n            w = chainer.initializers.Normal(wscale)\n            self.l0 = L.Linear(self.n_hidden, bottom_width * bottom_width * ch,\n                               initialW=w)\n            self.dc1 = L.Deconvolution2D(ch, ch // 2, 4, 2, 1, initialW=w)\n            self.dc2 = L.Deconvolution2D(ch // 2, ch // 4, 4, 2, 1, initialW=w)\n            self.dc3 = L.Deconvolution2D(ch // 4, ch // 8, 4, 2, 1, initialW=w)\n            self.dc4 = L.Deconvolution2D(ch // 8, 3, 3, 1, 1, initialW=w)\n            self.bn0 = L.BatchNormalization(bottom_width * bottom_width * ch)\n            self.bn1 = L.BatchNormalization(ch // 2)\n            self.bn2 = L.BatchNormalization(ch // 4)\n            self.bn3 = L.BatchNormalization(ch // 8)\n\n    def make_hidden(self, batchsize):\n        return numpy.random.uniform(-1, 1, (batchsize, self.n_hidden, 1, 1))\\\n            .astype(numpy.float32)\n\n    def __call__(self, z):\n        h = F.reshape(F.relu(self.bn0(self.l0(z))),\n                      (len(z), self.ch, self.bottom_width, self.bottom_width))\n        h = F.relu(self.bn1(self.dc1(h)))\n        h = F.relu(self.bn2(self.dc2(h)))\n        h = F.relu(self.bn3(self.dc3(h)))\n        x = F.sigmoid(self.dc4(h))\n        return x\n\n\nclass Discriminator(chainer.Chain):\n\n    def __init__(self, bottom_width=4, ch=512, wscale=0.02):\n        w = chainer.initializers.Normal(wscale)\n        super(Discriminator, self).__init__()\n        with self.init_scope():\n            self.c0_0 = L.Convolution2D(3, ch // 8, 3, 1, 1, initialW=w)\n            self.c0_1 = L.Convolution2D(ch // 8, ch // 4, 4, 2, 1, initialW=w)\n            self.c1_0 = L.Convolution2D(ch // 4, ch // 4, 3, 1, 1, initialW=w)\n            self.c1_1 = L.Convolution2D(ch // 4, ch // 2, 4, 2, 1, initialW=w)\n            self.c2_0 = L.Convolution2D(ch // 2, ch // 2, 3, 1, 1, initialW=w)\n            self.c2_1 = L.Convolution2D(ch // 2, ch // 1, 4, 2, 1, initialW=w)\n            self.c3_0 = L.Convolution2D(ch // 1, ch // 1, 3, 1, 1, initialW=w)\n            self.l4 = L.Linear(bottom_width * bottom_width * ch, 1, initialW=w)\n            self.bn0_1 = L.BatchNormalization(ch // 4, use_gamma=False)\n            self.bn1_0 = L.BatchNormalization(ch // 4, use_gamma=False)\n            self.bn1_1 = L.BatchNormalization(ch // 2, use_gamma=False)\n            self.bn2_0 = L.BatchNormalization(ch // 2, use_gamma=False)\n            self.bn2_1 = L.BatchNormalization(ch // 1, use_gamma=False)\n            self.bn3_0 = L.BatchNormalization(ch // 1, use_gamma=False)\n\n    def __call__(self, x):\n        h = add_noise(x)\n        h = F.leaky_relu(add_noise(self.c0_0(h)))\n        h = F.leaky_relu(add_noise(self.bn0_1(self.c0_1(h))))\n        h = F.leaky_relu(add_noise(self.bn1_0(self.c1_0(h))))\n        h = F.leaky_relu(add_noise(self.bn1_1(self.c1_1(h))))\n        h = F.leaky_relu(add_noise(self.bn2_0(self.c2_0(h))))\n        h = F.leaky_relu(add_noise(self.bn2_1(self.c2_1(h))))\n        h = F.leaky_relu(add_noise(self.bn3_0(self.c3_0(h))))\n        return self.l4(h)\n'"
examples/chainer/extension_logger/train_dcgan.py,0,"b""#!/usr/bin/env python\n\nfrom __future__ import print_function\nimport argparse\nimport os\n\nimport chainer\nfrom chainer import training\nfrom chainer.training import extensions\n\nfrom net import Discriminator\nfrom net import Generator\nfrom updater import DCGANUpdater\nfrom visualize import out_generated_image\nfrom tensorboardX import SummaryWriter\nfrom writetensorboard import LogTensorboard\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Chainer example: DCGAN')\n    parser.add_argument('--batchsize', '-b', type=int, default=50,\n                        help='Number of images in each mini-batch')\n    parser.add_argument('--epoch', '-e', type=int, default=1000,\n                        help='Number of sweeps over the dataset to train')\n    parser.add_argument('--gpu', '-g', type=int, default=-1,\n                        help='GPU ID (negative value indicates CPU)')\n    parser.add_argument('--dataset', '-i', default='',\n                        help='Directory of image files.  Default is cifar-10.')\n    parser.add_argument('--out', '-o', default='result',\n                        help='Directory to output the result')\n    parser.add_argument('--resume', '-r', default='',\n                        help='Resume the training from snapshot')\n    parser.add_argument('--n_hidden', '-n', type=int, default=100,\n                        help='Number of hidden units (z)')\n    parser.add_argument('--seed', type=int, default=0,\n                        help='Random seed of z at visualization stage')\n    parser.add_argument('--snapshot_interval', type=int, default=1000,\n                        help='Interval of snapshot')\n    parser.add_argument('--display_interval', type=int, default=100,\n                        help='Interval of displaying log to console')\n    args = parser.parse_args()\n\n    print('GPU: {}'.format(args.gpu))\n    print('# Minibatch-size: {}'.format(args.batchsize))\n    print('# n_hidden: {}'.format(args.n_hidden))\n    print('# epoch: {}'.format(args.epoch))\n    print('')\n    writer = SummaryWriter()\n    # Set up a neural network to train\n    gen = Generator(n_hidden=args.n_hidden)\n    dis = Discriminator()\n\n    if args.gpu >= 0:\n        # Make a specified GPU current\n        chainer.cuda.get_device_from_id(args.gpu).use()\n        gen.to_gpu()  # Copy the model to the GPU\n        dis.to_gpu()\n\n    # Setup an optimizer\n    def make_optimizer(model, alpha=0.0002, beta1=0.5):\n        optimizer = chainer.optimizers.Adam(alpha=alpha, beta1=beta1)\n        optimizer.setup(model)\n        optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001), 'hook_dec')\n        return optimizer\n    opt_gen = make_optimizer(gen)\n    opt_dis = make_optimizer(dis)\n\n    if args.dataset == '':\n        # Load the CIFAR10 dataset if args.dataset is not specified\n        train, _ = chainer.datasets.get_cifar10(withlabel=False, scale=255.)\n    else:\n        all_files = os.listdir(args.dataset)\n        image_files = [f for f in all_files if ('png' in f or 'jpg' in f)]\n        print('{} contains {} image files'\n              .format(args.dataset, len(image_files)))\n        train = chainer.datasets\\\n            .ImageDataset(paths=image_files, root=args.dataset)\n\n    train_iter = chainer.iterators.SerialIterator(train, args.batchsize)\n\n    # Set up a trainer\n    updater = DCGANUpdater(\n        models=(gen, dis),\n        iterator=train_iter,\n        optimizer={\n            'gen': opt_gen, 'dis': opt_dis},\n        device=args.gpu)\n    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n\n    snapshot_interval = (args.snapshot_interval, 'iteration')\n    display_interval = (args.display_interval, 'iteration')\n    trainer.extend(\n        extensions.snapshot(filename='snapshot_iter_{.updater.iteration}.npz'),\n        trigger=snapshot_interval)\n    trainer.extend(extensions.snapshot_object(\n        gen, 'gen_iter_{.updater.iteration}.npz'), trigger=snapshot_interval)\n    trainer.extend(extensions.snapshot_object(\n        dis, 'dis_iter_{.updater.iteration}.npz'), trigger=snapshot_interval)\n    trainer.extend(extensions.LogReport(trigger=display_interval))\n    trainer.extend(LogTensorboard(trigger=display_interval, logger=writer))\n    trainer.extend(extensions.PrintReport([\n        'epoch', 'iteration', 'gen/loss', 'dis/loss',\n    ]), trigger=display_interval)\n    trainer.extend(extensions.ProgressBar(update_interval=10))\n    trainer.extend(\n        out_generated_image(\n            gen, dis,\n            10, 10, args.seed, args.out, writer),\n        trigger=snapshot_interval)\n\n    if args.resume:\n        # Resume from a snapshot\n        chainer.serializers.load_npz(args.resume, trainer)\n\n    # Run the training\n    trainer.run()\n\n\nif __name__ == '__main__':\n    main()\n"""
examples/chainer/extension_logger/updater.py,0,"b""#!/usr/bin/env python\n\nfrom __future__ import print_function\n\nimport chainer\nimport chainer.functions as F\nfrom chainer import Variable\n\n\nclass DCGANUpdater(chainer.training.StandardUpdater):\n\n    def __init__(self, *args, **kwargs):\n        self.gen, self.dis = kwargs.pop('models')\n        super(DCGANUpdater, self).__init__(*args, **kwargs)\n\n    def loss_dis(self, dis, y_fake, y_real):\n        batchsize = len(y_fake)\n        L1 = F.sum(F.softplus(-y_real)) / batchsize\n        L2 = F.sum(F.softplus(y_fake)) / batchsize\n        loss = L1 + L2\n        chainer.report({'loss': loss}, dis)\n        return loss\n\n    def loss_gen(self, gen, y_fake):\n        batchsize = len(y_fake)\n        loss = F.sum(F.softplus(-y_fake)) / batchsize\n        chainer.report({'loss': loss}, gen)\n        return loss\n\n    def update_core(self):\n        gen_optimizer = self.get_optimizer('gen')\n        dis_optimizer = self.get_optimizer('dis')\n\n        batch = self.get_iterator('main').next()\n        x_real = Variable(self.converter(batch, self.device)) / 255.\n        xp = chainer.cuda.get_array_module(x_real.data)\n\n        gen, dis = self.gen, self.dis\n        batchsize = len(batch)\n\n        y_real = dis(x_real)\n\n        z = Variable(xp.asarray(gen.make_hidden(batchsize)))\n        x_fake = gen(z)\n        y_fake = dis(x_fake)\n\n        dis_optimizer.update(self.loss_dis, dis, y_fake, y_real)\n        gen_optimizer.update(self.loss_gen, gen, y_fake)\n"""
examples/chainer/extension_logger/visualize.py,0,"b""#!/usr/bin/env python\n\nimport os\n\nimport numpy as np\nfrom PIL import Image\n\nimport chainer\nimport chainer.cuda\nfrom chainer import Variable\n\n\ndef out_generated_image(gen, dis, rows, cols, seed, dst, writer):\n    @chainer.training.make_extension()\n    def make_image(trainer):\n        np.random.seed(seed)\n        n_images = rows * cols\n        xp = gen.xp\n        z = Variable(xp.asarray(gen.make_hidden(n_images)))\n        with chainer.using_config('train', False):\n            x = gen(z)\n        writer.add_image('img', x, trainer.updater.iteration)\n\n    return make_image\n"""
examples/chainer/extension_logger/writetensorboard.py,0,"b'import json\nimport os\nimport shutil\nimport tempfile\n\nimport six\nfrom chainer import reporter\nfrom chainer import serializer as serializer_module\nfrom chainer.training import extension\nfrom chainer.training import trigger as trigger_module\n\n\nclass LogTensorboard(extension.Extension):\n\n    """"""Trainer extension to output the accumulated results to a log file.\n\n    This extension accumulates the observations of the trainer to\n    :class:`~chainer.DictSummary` at a regular interval specified by a supplied\n    trigger, and writes them into a log file in JSON format.\n\n    There are two triggers to handle this extension. One is the trigger to\n    invoke this extension, which is used to handle the timing of accumulating\n    the results. It is set to ``1, \'iteration\'`` by default. The other is the\n    trigger to determine when to emit the result. When this trigger returns\n    True, this extension appends the summary of accumulated values to the list\n    of past summaries, and writes the list to the log file. Then, this\n    extension makes a new fresh summary object which is used until the next\n    time that the trigger fires.\n\n    It also adds some entries to each result dictionary.\n\n    - ``\'epoch\'`` and ``\'iteration\'`` are the epoch and iteration counts at the\n      output, respectively.\n    - ``\'elapsed_time\'`` is the elapsed time in seconds since the training\n      begins. The value is taken from :attr:`Trainer.elapsed_time`.\n\n    Args:\n        keys (iterable of strs): Keys of values to accumulate. If this is None,\n            all the values are accumulated and output to the log file.\n        trigger: Trigger that decides when to aggregate the result and output\n            the values. This is distinct from the trigger of this extension\n            itself. If it is a tuple in the form ``<int>, \'epoch\'`` or\n            ``<int>, \'iteration\'``, it is passed to :class:`IntervalTrigger`.\n        postprocess: Callback to postprocess the result dictionaries. Each\n            result dictionary is passed to this callback on the output. This\n            callback can modify the result dictionaries, which are used to\n            output to the log file.\n        log_name (str): Name of the log file under the output directory. It can\n            be a format string: the last result dictionary is passed for the\n            formatting. For example, users can use \'{iteration}\' to separate\n            the log files for different iterations. If the log name is None, it\n            does not output the log to any file.\n\n    """"""\n\n    def __init__(self, keys=None, trigger=(1, \'epoch\'), postprocess=None,\n                 log_name=\'log\', logger=None):\n        self._keys = keys\n        self._trigger = trigger_module.get_trigger(trigger)\n        self._postprocess = postprocess\n        self._log_name = log_name\n        self._log = []\n        self._logger = logger\n        self._init_summary()\n\n    def __call__(self, trainer):\n        # accumulate the observations\n        keys = self._keys\n        observation = trainer.observation\n        summary = self._summary\n\n        if keys is None:\n            summary.add(observation)\n        else:\n            summary.add({k: observation[k] for k in keys if k in observation})\n        for k, v in observation.items():\n            #self._logger.add_scalar(k, chainer.cuda.to_cpu(observation[k].data), trainer.updater.iteration)\n            self._logger.add_scalar(\n                k, observation[k], trainer.updater.iteration)\n        if self._trigger(trainer):\n            # output the result\n            stats = self._summary.compute_mean()\n            stats_cpu = {}\n            for name, value in six.iteritems(stats):\n                stats_cpu[name] = float(value)  # copy to CPU\n\n            updater = trainer.updater\n            stats_cpu[\'epoch\'] = updater.epoch\n            stats_cpu[\'iteration\'] = updater.iteration\n            stats_cpu[\'elapsed_time\'] = trainer.elapsed_time\n\n            if self._postprocess is not None:\n                self._postprocess(stats_cpu)\n\n            self._log.append(stats_cpu)\n\n            # write to the log file\n            if self._log_name is not None:\n                log_name = self._log_name.format(**stats_cpu)\n                fd, path = tempfile.mkstemp(prefix=log_name, dir=trainer.out)\n                with os.fdopen(fd, \'w\') as f:\n                    json.dump(self._log, f, indent=4)\n\n                new_path = os.path.join(trainer.out, log_name)\n                shutil.move(path, new_path)\n\n            # reset the summary for the next output\n            self._init_summary()\n\n    @property\n    def log(self):\n        """"""The current list of observation dictionaries.""""""\n        return self._log\n\n    def serialize(self, serializer):\n        if hasattr(self._trigger, \'serialize\'):\n            self._trigger.serialize(serializer[\'_trigger\'])\n\n        # Note that this serialization may lose some information of small\n        # numerical differences.\n        if isinstance(serializer, serializer_module.Serializer):\n            log = json.dumps(self._log)\n            serializer(\'_log\', log)\n        else:\n            log = serializer(\'_log\', \'\')\n            self._log = json.loads(log)\n\n    def _init_summary(self):\n        self._summary = reporter.DictSummary()\n'"
examples/chainer/plain_logger/data.py,0,"b""import gzip\nimport os\n\nimport numpy as np\nimport six\nfrom six.moves.urllib import request\n\nparent = 'http://yann.lecun.com/exdb/mnist'\ntrain_images = 'train-images-idx3-ubyte.gz'\ntrain_labels = 'train-labels-idx1-ubyte.gz'\ntest_images = 't10k-images-idx3-ubyte.gz'\ntest_labels = 't10k-labels-idx1-ubyte.gz'\nnum_train = 60000\nnum_test = 10000\ndim = 784\n\n\ndef load_mnist(images, labels, num):\n    data = np.zeros(num * dim, dtype=np.uint8).reshape((num, dim))\n    target = np.zeros(num, dtype=np.uint8).reshape((num, ))\n\n    with gzip.open(images, 'rb') as f_images,\\\n            gzip.open(labels, 'rb') as f_labels:\n        f_images.read(16)\n        f_labels.read(8)\n        for i in six.moves.range(num):\n            target[i] = ord(f_labels.read(1))\n            for j in six.moves.range(dim):\n                data[i, j] = ord(f_images.read(1))\n\n    return data, target\n\n\ndef download_mnist_data():\n    print('Downloading {:s}...'.format(train_images))\n    request.urlretrieve('{:s}/{:s}'.format(parent, train_images), train_images)\n    print('Done')\n    print('Downloading {:s}...'.format(train_labels))\n    request.urlretrieve('{:s}/{:s}'.format(parent, train_labels), train_labels)\n    print('Done')\n    print('Downloading {:s}...'.format(test_images))\n    request.urlretrieve('{:s}/{:s}'.format(parent, test_images), test_images)\n    print('Done')\n    print('Downloading {:s}...'.format(test_labels))\n    request.urlretrieve('{:s}/{:s}'.format(parent, test_labels), test_labels)\n    print('Done')\n\n    print('Converting training data...')\n    data_train, target_train = load_mnist(train_images, train_labels,\n                                          num_train)\n    print('Done')\n    print('Converting test data...')\n    data_test, target_test = load_mnist(test_images, test_labels, num_test)\n    mnist = {'data': np.append(data_train, data_test, axis=0),\n             'target': np.append(target_train, target_test, axis=0)}\n    print('Done')\n    print('Save output...')\n    with open('mnist.pkl', 'wb') as output:\n        six.moves.cPickle.dump(mnist, output, -1)\n    print('Done')\n    print('Convert completed')\n\n\ndef load_mnist_data():\n    if not os.path.exists('mnist.pkl'):\n        download_mnist_data()\n    with open('mnist.pkl', 'rb') as mnist_pickle:\n        mnist = six.moves.cPickle.load(mnist_pickle)\n    return mnist\n"""
examples/chainer/plain_logger/net.py,0,"b'import six\n\nimport chainer\nimport chainer.functions as F\nfrom chainer.functions.loss.vae import gaussian_kl_divergence\nimport chainer.links as L\n\n\nclass VAE(chainer.Chain):\n    """"""Variational AutoEncoder""""""\n\n    def __init__(self, n_in, n_latent, n_h):\n        super(VAE, self).__init__()\n        with self.init_scope():\n            # encoder\n            self.le1 = L.Linear(n_in, n_h)\n            self.le2_mu = L.Linear(n_h, n_latent)\n            self.le2_ln_var = L.Linear(n_h, n_latent)\n            # decoder\n            self.ld1 = L.Linear(n_latent, n_h)\n            self.ld2 = L.Linear(n_h, n_in)\n\n    def __call__(self, x, sigmoid=True):\n        """"""AutoEncoder""""""\n        return self.decode(self.encode(x)[0], sigmoid)\n\n    def encode(self, x):\n        h1 = F.tanh(self.le1(x))\n        mu = self.le2_mu(h1)\n        ln_var = self.le2_ln_var(h1)  # log(sigma**2)\n        return mu, ln_var\n\n    def decode(self, z, sigmoid=True):\n        h1 = F.tanh(self.ld1(z))\n        h2 = self.ld2(h1)\n        if sigmoid:\n            return F.sigmoid(h2)\n        else:\n            return h2\n\n    def get_loss_func(self, C=1.0, k=1):\n        """"""Get loss function of VAE.\n\n        The loss value is equal to ELBO (Evidence Lower Bound)\n        multiplied by -1.\n\n        Args:\n            C (int): Usually this is 1.0. Can be changed to control the\n                second term of ELBO bound, which works as regularization.\n            k (int): Number of Monte Carlo samples used in encoded vector.\n        """"""\n        def lf(x):\n            mu, ln_var = self.encode(x)\n            batchsize = len(mu.data)\n            # reconstruction loss\n            rec_loss = 0\n            for l in six.moves.range(k):\n                z = F.gaussian(mu, ln_var)\n                rec_loss += F.bernoulli_nll(x, self.decode(z, sigmoid=False)) \\\n                    / (k * batchsize)\n            self.rec_loss = rec_loss\n            self.loss = self.rec_loss + \\\n                C * gaussian_kl_divergence(mu, ln_var) / batchsize\n            return self.loss\n        return lf\n'"
examples/chainer/plain_logger/train_vae.py,0,"b'#!/usr/bin/env python\n""""""Chainer example: train a VAE on MNIST\n""""""\nfrom __future__ import print_function\nimport argparse\n\nimport matplotlib\n# Disable interactive backend\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport six\n\nimport chainer\nfrom chainer import computational_graph\nfrom chainer import cuda\nfrom chainer import optimizers\nfrom chainer import serializers\nfrom tensorboardX import SummaryWriter\nimport data\nimport net\n\nwriter = SummaryWriter()\n\nparser = argparse.ArgumentParser(description=\'Chainer example: MNIST\')\nparser.add_argument(\'--initmodel\', \'-m\', default=\'\',\n                    help=\'Initialize the model from given file\')\nparser.add_argument(\'--resume\', \'-r\', default=\'\',\n                    help=\'Resume the optimization from snapshot\')\nparser.add_argument(\'--gpu\', \'-g\', default=-1, type=int,\n                    help=\'GPU ID (negative value indicates CPU)\')\nparser.add_argument(\'--epoch\', \'-e\', default=100, type=int,\n                    help=\'number of epochs to learn\')\nparser.add_argument(\'--dimz\', \'-z\', default=20, type=int,\n                    help=\'dimention of encoded vector\')\nparser.add_argument(\'--batchsize\', \'-b\', type=int, default=100,\n                    help=\'learning minibatch size\')\nparser.add_argument(\'--test\', action=\'store_true\',\n                    help=\'Use tiny datasets for quick tests\')\nargs = parser.parse_args()\n\nbatchsize = args.batchsize\nn_epoch = args.epoch\nn_latent = args.dimz\n\nwriter.add_text(\'config\', str(args))\n\nprint(\'GPU: {}\'.format(args.gpu))\nprint(\'# dim z: {}\'.format(args.dimz))\nprint(\'# Minibatch-size: {}\'.format(args.batchsize))\nprint(\'# epoch: {}\'.format(args.epoch))\nprint(\'\')\n\n# Prepare dataset\nprint(\'load MNIST dataset\')\nmnist = data.load_mnist_data()\nmnist[\'data\'] = mnist[\'data\'].astype(np.float32)\nmnist[\'data\'] /= 255\nmnist[\'target\'] = mnist[\'target\'].astype(np.int32)\n\nif args.test:\n    mnist[\'data\'] = mnist[\'data\'][0:100]\n    mnist[\'target\'] = mnist[\'target\'][0:100]\n    N = 30\nelse:\n    N = 60000\n\nx_train, x_test = np.split(mnist[\'data\'],   [N])\ny_train, y_test = np.split(mnist[\'target\'], [N])\nN_test = y_test.size\n\n# Prepare VAE model, defined in net.py\nmodel = net.VAE(784, n_latent, 500)\nif args.gpu >= 0:\n    cuda.get_device_from_id(args.gpu).use()\n    model.to_gpu()\nxp = np if args.gpu < 0 else cuda.cupy\n\n# Setup optimizer\noptimizer = optimizers.Adam()\noptimizer.setup(model)\n\n# Init/Resume\nif args.initmodel:\n    print(\'Load model from\', args.initmodel)\n    serializers.load_npz(args.initmodel, model)\nif args.resume:\n    print(\'Load optimizer state from\', args.resume)\n    serializers.load_npz(args.resume, optimizer)\n\n# Learning loop\nfor epoch in six.moves.range(1, n_epoch + 1):\n    print(\'epoch\', epoch)\n\n    # training\n    perm = np.random.permutation(N)\n    sum_loss = 0       # total loss\n    sum_rec_loss = 0   # reconstruction loss\n    for i in six.moves.range(0, N, batchsize):\n        x = chainer.Variable(xp.asarray(x_train[perm[i:i + batchsize]]))\n        optimizer.update(model.get_loss_func(), x)\n        if epoch == 1 and i == 0:\n            with open(\'graph.dot\', \'w\') as o:\n                g = computational_graph.build_computational_graph(\n                    (model.loss, ))\n                o.write(g.dump())\n            print(\'graph generated\')\n        writer.add_scalar(\'train/loss\', model.loss, epoch * N + i)\n        writer.add_scalar(\'train/rec_loss\', model.rec_loss, epoch * N + i)\n        sum_loss += float(model.loss.data) * len(x.data)\n        sum_rec_loss += float(model.rec_loss.data) * len(x.data)\n\n    print(\'train mean loss={}, mean reconstruction loss={}\'\n          .format(sum_loss / N, sum_rec_loss / N))\n\n    # evaluation\n    sum_loss = 0\n    sum_rec_loss = 0\n    with chainer.no_backprop_mode():\n        for i in six.moves.range(0, N_test, batchsize):\n            x = chainer.Variable(xp.asarray(x_test[i:i + batchsize]))\n            loss_func = model.get_loss_func(k=10)\n            loss_func(x)\n            sum_loss += float(model.loss.data) * len(x.data)\n            sum_rec_loss += float(model.rec_loss.data) * len(x.data)\n            writer.add_scalar(\'test/loss\', model.loss, epoch * N_test + i)\n            writer.add_scalar(\'test/rec_loss\', model.rec_loss,\n                              epoch * N_test + i)\n            writer.add_image(\'reconstructed\', model(\n                x).reshape(-1, 1, 28, 28), epoch * N_test + i)\n            writer.add_image(\'input\', x.reshape(-1, 1, 28, 28),\n                             epoch * N_test + i)\n            del model.loss\n    print(\'test  mean loss={}, mean reconstruction loss={}\'\n          .format(sum_loss / N_test, sum_rec_loss / N_test))\n\n\n# Save the model and the optimizer\nprint(\'save the model\')\nserializers.save_npz(\'mlp.model\', model)\nprint(\'save the optimizer\')\nserializers.save_npz(\'mlp.state\', optimizer)\n\nmodel.to_cpu()\n\n\n# original images and reconstructed images\ndef save_images(x, filename):\n    fig, ax = plt.subplots(3, 3, figsize=(9, 9), dpi=100)\n    for ai, xi in zip(ax.flatten(), x):\n        ai.imshow(xi.reshape(28, 28))\n    fig.savefig(filename)\n\n\ntrain_ind = [1, 3, 5, 10, 2, 0, 13, 15, 17]\nx = chainer.Variable(np.asarray(x_train[train_ind]))\nwith chainer.no_backprop_mode():\n    x1 = model(x)\nsave_images(x.data, \'train\')\nsave_images(x1.data, \'train_reconstructed\')\n\ntest_ind = [3, 2, 1, 18, 4, 8, 11, 17, 61]\nx = chainer.Variable(np.asarray(x_test[test_ind]))\nwith chainer.no_backprop_mode():\n    x1 = model(x)\nsave_images(x.data, \'test\')\nsave_images(x1.data, \'test_reconstructed\')\n\n\n# draw images from randomly sampled z\nz = chainer.Variable(np.random.normal(0, 1, (9, n_latent)).astype(np.float32))\nx = model.decode(z)\nsave_images(x.data, \'sampled\')\n'"
