file_path,api_count,code
acnn_train.py,24,"b""from attention.utils import *\r\nimport attention.pyt_acnn as pa\r\nfrom torch.utils.data import DataLoader, dataset\r\nimport numpy as np\r\nimport torch.nn.functional as F\r\nfrom attention.config import opt\r\n\r\ndevice = torch.device('cuda:0') if opt.use_gpu else 'cpu'\r\n\r\n\r\ndef gen_dataloader(data, word_dict, arg):\r\n    tp = vectorize(data, word_dict, arg.N)\r\n    x, y, e1, e2, e1d2, e2d1, zd, d1, d2 = tp\r\n    y_t = torch.LongTensor(np.array(y).astype(np.int64))\r\n    zd = np.array(zd).reshape(-1, 1)\r\n    e1, e1d2, d1 = np.array(e1).reshape(-1, 1), np.array(e1d2).reshape(-1, 1), np.array(d1)\r\n    e2, e2d1, d2 = np.array(e2).reshape(-1, 1), np.array(e2d1).reshape(-1, 1), np.array(d2)\r\n    np_cat = np.concatenate((x, e1, e1d2, e2, e2d1, zd, d1, d2), 1)\r\n    d_t = torch.from_numpy(np_cat.astype(np.int64))\r\n    ds = dataset.TensorDataset(d_t, y_t)\r\n    return DataLoader(ds, arg.BATCH_SIZE, True)\r\n\r\n\r\ndef data_unpack(cat_data, N):\r\n    list_x = np.split(cat_data.numpy(), [N, N + 1, N + 2, N + 3, N + 4, N + 5, 2 * N + 5], 1)\r\n    x = torch.from_numpy(list_x[0]).to(device)\r\n    e1 = torch.from_numpy(list_x[1]).to(device)\r\n    e1d2 = torch.from_numpy(list_x[2]).to(device)\r\n    e2 = torch.from_numpy(list_x[3]).to(device)\r\n    e2d1 = torch.from_numpy(list_x[4]).to(device)\r\n    zd = torch.from_numpy(list_x[5]).to(device)\r\n    d1 = torch.from_numpy(list_x[6]).to(device)\r\n    d2 = torch.from_numpy(list_x[7]).to(device)\r\n    return x, e1, e1d2, e2, e2d1, zd, d1, d2\r\n\r\n\r\ndef prediction(wo, rel_weight, y, all_y):\r\n    wo_norm = F.normalize(wo)  # (bs, dc)\r\n    wo_norm_tile = wo_norm.unsqueeze(1).repeat(1, all_y.size()[0], 1)  # (bs, nr, dc)\r\n    ay_emb = torch.mm(all_y, rel_weight)  # (nr, dc)\r\n    dist = torch.norm(wo_norm_tile - ay_emb, 2, 2)  # (bs, nr)\r\n    predict = torch.min(dist, 1)[1].long()\r\n    y = torch.max(y, 1)[1]\r\n    correct = torch.eq(predict, y)\r\n    return correct.sum().float() / float(correct.data.size()[0])\r\n# def prediction(wo, rel_weight, y):\r\n#     wo_norm = F.normalize(wo)  # (bs, dc)\r\n#     wo_norm_tile = wo_norm.unsqueeze(1).repeat(1, y.size()[-1], 1)  # (bs, nr, dc)\r\n#     dist = torch.norm(wo_norm_tile - rel_weight, 2, 2)  # (bs, nr)\r\n#     predict = torch.min(dist, 1)[1].long()\r\n#     y = torch.max(y, 1)[1]\r\n#     correct = torch.eq(predict, y)\r\n#     return correct.sum().float() / float(correct.data.size()[0])\r\n\r\n\r\ndef model_run(opt, dataloader, loss_func, model, all_y, optimizer=None):\r\n    acc, loss = 0, 0\r\n    for i, (bx_cat, by) in enumerate(dataloader):\r\n        by = by.float().to(device)\r\n        bin_tup = data_unpack(bx_cat, opt.N)\r\n        # wo, rel_weight = model(bin_tup, all_y)\r\n        wo, rel_weight = model(bin_tup)\r\n        a = prediction(wo, rel_weight, by, all_y)\r\n        l = loss_func(wo, rel_weight, by, all_y)\r\n        # a = prediction(wo, rel_weight, by)\r\n        # l = loss_func(wo, rel_weight, by)\r\n        # print('%.2f%%, %.2f' % (a.cpu().data.numpy() * 100, l.detach().cpu().numpy()))\r\n        acc += a.cpu().data.numpy() * 100\r\n        loss += l.detach().cpu().numpy()\r\n        if optimizer is not None:\r\n            l.backward(), optimizer.step(), optimizer.zero_grad()\r\n    return acc / i, loss / i\r\n\r\n\r\nall_y = to_categorical([i for i in range(opt.NR)], opt.NR)\r\nall_y = torch.from_numpy(all_y.astype(np.float)).float().to(device)\r\ntrain_data = load_data('attention/train.txt', opt.NR)\r\neval_data = load_data('attention/test.txt', opt.NR)\r\nword_dict = build_dict(train_data[0])\r\n\r\ntrain_dataloader = gen_dataloader(train_data, word_dict, opt)\r\neval_dataloader = gen_dataloader(eval_data, word_dict, opt)\r\n\r\nembed_file = 'attention/embeddings.txt'\r\nvac_file = 'attention/words.lst'\r\nembedding = load_embedding(embed_file, vac_file, word_dict)\r\n\r\nmodel = pa.ACNN(opt, embedding).to(device)\r\noptimizer = torch.optim.Adam(model.parameters(), lr=opt.LR, weight_decay=0.0001)  # optimize all rnn parameters\r\nloss_func = pa.DistanceLoss(opt.NR)\r\n\r\nfor i in range(opt.epochs):\r\n    acc, loss = model_run(opt, train_dataloader, loss_func, model, all_y, optimizer)\r\n    val_acc, val_loss = model_run(opt, eval_dataloader, loss_func, model, all_y)\r\n    print('epoch: %d, t_l: %.2f, t_a: %.2f%%, v_l: %.2f, v_a: %.2f%%' % (i, loss, acc, val_loss, val_acc))\r\n"""
attention/config.py,0,"b'# -*- coding: utf-8 -*-\n\ndata_dic = {\n    \'ranking_data\': {\n        \'data_root\': \'C:/Users/LawLi/PycharmProjects/dialogResearch/dialog/dataset/data\',\n        \'vocab_size\': 9185,\n        \'num_class\': 4\n    }\n}\n\n\nclass DefaultConfig(object):\n    DP = 25\n    DC = 500\n    N = 123\n    NP = 123\n    NR = 19\n    KP = 0.6\n    K = 3\n    LR = 0.03\n    BATCH_SIZE = 32\n    epochs = 100\n    use_gpu = True\n\n\ndef parse(self, kwargs):\n    \'\'\'\n    user can update the default hyperparamter\n    \'\'\'\n    for k in kwargs.keys():\n        if not hasattr(self, k):\n            raise Exception(\'opt has No key: {}\'.format(k))\n        setattr(self, k, kwargs[k])\n\n    data_list = [\'data_root\', \'w2v_path\', \'rel_num\', \'vocab_size\']\n    for r in data_list:\n        setattr(self, r, data_dic[self.data][r])\n\n    if self.model.startswith(\'PCNN\'):\n        setattr(self, \'rel_dim\', 3 * self.filters_num * len(self.filters))\n\n    print(\'*************************************************\')\n    print(\'user config:\')\n    for k in self.__class__.__dict__.keys():\n        if not k.startswith(\'__\'):\n            print(""{} => {}"".format(k, getattr(self, k)))\n\n    print(\'*************************************************\')\n\n\nDefaultConfig.parse = parse\nopt = DefaultConfig()\n'"
attention/pyt_acnn.py,29,"b'from torch import nn\r\nimport torch.nn.functional as F\r\nfrom attention.utils import *\r\n\r\n\r\nclass ACNN(nn.Module):\r\n    def __init__(self, opt, embedding):\r\n        super(ACNN, self).__init__()\r\n        self.opt = opt\r\n        self.dw = embedding.shape[1]\r\n        self.vac_len = embedding.shape[0]\r\n        self.d = self.dw + 2 * self.opt.DP\r\n        self.p = (self.opt.K - 1) // 2\r\n        self.x_embedding = nn.Embedding(self.vac_len, self.dw)\r\n        self.x_embedding.weight = nn.Parameter(torch.from_numpy(embedding))\r\n        # self.e1_embedding = nn.Embedding(self.vac_len, self.dw)\r\n        # self.e1_embedding.weight = nn.Parameter(torch.from_numpy(embedding))\r\n        # self.e2_embedding = nn.Embedding(self.vac_len, self.dw)\r\n        # self.e2_embedding.weight = nn.Parameter(torch.from_numpy(embedding))\r\n        self.dist_embedding = nn.Embedding(self.opt.NP, self.opt.DP)\r\n        self.rel_weight = nn.Parameter(torch.randn(self.opt.NR, self.opt.DC))\r\n        self.dropout = nn.Dropout(self.opt.KP)\r\n        self.conv = nn.Conv2d(1, self.opt.DC, (self.opt.K, self.d), (1, self.d), (self.p, 0), bias=True)\r\n        self.U = nn.Parameter(torch.randn(self.opt.DC, self.opt.NR))\r\n        self.max_pool = nn.MaxPool1d(self.opt.N, stride=1)\r\n\r\n    def input_attention(self, input_tuple, is_training=True):\r\n        x, e1, e1d2, e2, e2d1, zd, d1, d2 = input_tuple\r\n        x_emb = self.x_embedding(x)  # (bs, n, dw)\r\n        e1_emb = self.x_embedding(e1)\r\n        e2_emb = self.x_embedding(e2)\r\n        # zd_emb = self.dist_embedding(zd)\r\n        # e1d2_emb = self.dist_embedding(e1d2)\r\n        # e2d1_emb = self.dist_embedding(e2d1)\r\n        dist1_emb = self.dist_embedding(d1)\r\n        dist2_emb = self.dist_embedding(d2)\r\n        x_cat = torch.cat((x_emb, dist1_emb, dist2_emb), 2)\r\n        # e1_cat = torch.cat((e1_emb, zd_emb, e1d2_emb), 2)\r\n        # e2_cat = torch.cat((e2_emb, e2d1_emb, zd_emb), 2)\r\n        # if is_training:\r\n        #     x_cat = self.dropout(x_cat)\r\n        ine1_aw = F.softmax(torch.bmm(x_emb, e1_emb.transpose(2, 1)), 1)  # (bs, n, 1)\r\n        ine2_aw = F.softmax(torch.bmm(x_emb, e2_emb.transpose(2, 1)), 1)\r\n        # ine1_aw = F.softmax(torch.bmm(x_cat, e1_cat.transpose(2, 1)), 1)  # (bs, n, 1)\r\n        # ine2_aw = F.softmax(torch.bmm(x_cat, e2_cat.transpose(2, 1)), 1)\r\n        in_aw = (ine1_aw + ine2_aw) / 2\r\n        R = torch.mul(x_cat, in_aw)\r\n        return R\r\n\r\n    # def attentive_pooling(self, R_star, all_y):\r\n    #     rel_emb = torch.mm(all_y, self.rel_weight)  # (NR, NR) * (NR, DC)\r\n    #     RU = torch.matmul(R_star.transpose(2, 1), self.U)  # (bs, n, nr)\r\n    #     G = torch.matmul(RU, rel_emb)  # (bs, n, dc)\r\n    #     AP = F.softmax(G, dim=1)\r\n    #     RA = torch.mul(R_star, AP.transpose(2, 1))\r\n    #     wo = self.max_pool(RA).squeeze(-1)\r\n    #     return wo, self.rel_weight\r\n\r\n    def attentive_pooling(self, R_star):\r\n        RU = torch.matmul(R_star.transpose(2, 1), self.U)  # (bs, n, nr)\r\n        G = torch.matmul(RU, self.rel_weight)  # (bs, n, dc)\r\n        AP = F.softmax(G, dim=1)\r\n        RA = torch.mul(R_star, AP.transpose(2, 1))\r\n        wo = self.max_pool(RA).squeeze(-1)\r\n        return wo\r\n\r\n    def forward(self, input_tuple, is_training=True):\r\n        R = self.input_attention(input_tuple, is_training)\r\n        R_star = self.conv(R.unsqueeze(1)).squeeze(-1)  # (bs, dc, n)\r\n        R_star = torch.tanh(R_star)\r\n        wo = self.attentive_pooling(R_star)\r\n        return wo, self.rel_weight\r\n\r\n\r\nclass DistanceLoss(nn.Module):\r\n    def __init__(self, nr, margin=1):\r\n        super(DistanceLoss, self).__init__()\r\n        self.nr = nr\r\n        self.margin = margin\r\n\r\n    def forward(self, wo, rel_weight, in_y, all_y):\r\n        wo_norm = F.normalize(wo)  # (bs, dc)  in_y (bs, nr)\r\n        wo_norm_tile = wo_norm.unsqueeze(1).repeat(1, in_y.size()[-1], 1)  # (bs, nr, dc)\r\n        rel_emb = torch.mm(in_y, rel_weight)  # (bs, dc)\r\n        ay_emb = torch.mm(all_y, rel_weight)  # (nr, dc)\r\n        gt_dist = torch.norm(wo_norm - rel_emb, 2, 1)  # (bs, 1)\r\n        all_dist = torch.norm(wo_norm_tile - ay_emb, 2, 2)  # (bs, nr)\r\n        masking_y = torch.mul(in_y, 10000)\r\n        _t_dist = torch.min(torch.add(all_dist, masking_y), 1)[0]\r\n        loss = torch.mean(self.margin + gt_dist - _t_dist)\r\n        return loss\r\n'"
attention/utils.py,0,"b""import numpy as np\r\nimport logging\r\nimport torch\r\nfrom collections import Counter\r\nfrom keras.utils.np_utils import to_categorical\r\n\r\n\r\ndef load_data(file, NR):\r\n    sentences = []\r\n    relations = []\r\n    e1_pos = []\r\n    e2_pos = []\r\n\r\n    with open(file, 'r', encoding='utf-8', errors='ignore') as f:\r\n        for line in f.readlines():\r\n            line = line.strip().lower().split()\r\n            relations.append(int(line[0]))\r\n            e1_pos.append((int(line[1]), int(line[2])))  # (start_pos, end_pos)\r\n            e2_pos.append((int(line[3]), int(line[4])))  # (start_pos, end_pos)\r\n            sentences.append(line[5:])\r\n    relations = to_categorical(relations, NR)\r\n    return sentences, relations, e1_pos, e2_pos\r\n\r\n\r\ndef build_dict(sentences):\r\n    word_count = Counter()\r\n    for sent in sentences:\r\n        for w in sent:\r\n            word_count[w] += 1\r\n\r\n    ls = word_count.most_common()\r\n    word_dict = {w[0]: index + 1 for (index, w) in enumerate(ls)}\r\n    # leave 0 to PAD\r\n    return word_dict\r\n\r\n\r\ndef load_embedding(emb_file, emb_vocab, word_dict):\r\n    vocab = {}\r\n    with open(emb_vocab, 'r') as f:\r\n        for id, w in enumerate(f.readlines()):\r\n            w = w.strip().lower()\r\n            vocab[w] = id\r\n\r\n    f = open(emb_file, 'r')\r\n    embed = f.readlines()\r\n\r\n    dim = len(embed[0].split())\r\n    num_words = len(word_dict) + 1\r\n    embeddings = np.random.uniform(-0.01, 0.01, size=(num_words, dim))\r\n\r\n    pre_trained = 0\r\n    for w in vocab.keys():\r\n        if w in word_dict:\r\n            embeddings[word_dict[w]] = [float(x) for x in embed[vocab[w]].split()]\r\n            pre_trained += 1\r\n    embeddings[0] = np.zeros(dim)\r\n\r\n    logging.info(\r\n        'embeddings: %.2f%%(pre_trained) unknown: %d' % (pre_trained / num_words * 100, num_words - pre_trained))\r\n\r\n    f.close()\r\n    return embeddings.astype(np.float32)\r\n\r\n\r\ndef pos(x):\r\n    '''\r\n    map the relative distance between [0, 123)\r\n    '''\r\n    if x < -60:\r\n        return 0\r\n    if 60 >= x >= -60:\r\n        return x + 61\r\n    if x > 60:\r\n        return 122\r\n\r\n\r\ndef vectorize(data, word_dict, max_len):\r\n    sentences, relations, e1_pos, e2_pos = data\r\n    # replace word with word-id\r\n    d1, d2, e1d2, e2d1 = [], [], [], []\r\n    e1_vec, e2_vec = [], []\r\n    num_data = len(sentences)\r\n    zd = [0 for _ in range(num_data)]\r\n    sents_vec = np.zeros((num_data, max_len), dtype=int)\r\n    logging.debug('data shape: (%d, %d)' % (num_data, max_len))\r\n\r\n    for idx, (sent, pos1, pos2) in enumerate(zip(sentences, e1_pos, e2_pos)):\r\n        vec = [word_dict[w] if w in word_dict else 0 for w in sent]\r\n        sents_vec[idx, :len(vec)] = vec\r\n        # last word of e1 and e2\r\n        e1_vec.append(vec[pos1[1]])\r\n        e2_vec.append(vec[pos2[1]])\r\n\r\n    # compute relative distance\r\n    for sent, p1, p2 in zip(sents_vec, e1_pos, e2_pos):\r\n        # current word position - last word position of e1 or e2\r\n        e1d2.append(pos(p1[1] - p2[1]))\r\n        e2d1.append(pos(p2[1] - p1[1]))\r\n        d1.append([pos(p1[1] - idx) for idx, _ in enumerate(sent)])\r\n        d2.append([pos(p2[1] - idx) for idx, _ in enumerate(sent)])\r\n\r\n    return sents_vec, relations, e1_vec, e2_vec, e1d2, e2d1, zd, d1, d2\r\n"""
