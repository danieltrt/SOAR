file_path,api_count,code
model.py,6,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.distributions.categorical import Categorical\nimport torch_ac\n\n\n# Function from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/blob/master/model.py\ndef init_params(m):\n    classname = m.__class__.__name__\n    if classname.find(""Linear"") != -1:\n        m.weight.data.normal_(0, 1)\n        m.weight.data *= 1 / torch.sqrt(m.weight.data.pow(2).sum(1, keepdim=True))\n        if m.bias is not None:\n            m.bias.data.fill_(0)\n\n\nclass ACModel(nn.Module, torch_ac.RecurrentACModel):\n    def __init__(self, obs_space, action_space, use_memory=False, use_text=False):\n        super().__init__()\n\n        # Decide which components are enabled\n        self.use_text = use_text\n        self.use_memory = use_memory\n\n        # Define image embedding\n        self.image_conv = nn.Sequential(\n            nn.Conv2d(3, 16, (2, 2)),\n            nn.ReLU(),\n            nn.MaxPool2d((2, 2)),\n            nn.Conv2d(16, 32, (2, 2)),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, (2, 2)),\n            nn.ReLU()\n        )\n        n = obs_space[""image""][0]\n        m = obs_space[""image""][1]\n        self.image_embedding_size = ((n-1)//2-2)*((m-1)//2-2)*64\n\n        # Define memory\n        if self.use_memory:\n            self.memory_rnn = nn.LSTMCell(self.image_embedding_size, self.semi_memory_size)\n\n        # Define text embedding\n        if self.use_text:\n            self.word_embedding_size = 32\n            self.word_embedding = nn.Embedding(obs_space[""text""], self.word_embedding_size)\n            self.text_embedding_size = 128\n            self.text_rnn = nn.GRU(self.word_embedding_size, self.text_embedding_size, batch_first=True)\n\n        # Resize image embedding\n        self.embedding_size = self.semi_memory_size\n        if self.use_text:\n            self.embedding_size += self.text_embedding_size\n\n        # Define actor\'s model\n        self.actor = nn.Sequential(\n            nn.Linear(self.embedding_size, 64),\n            nn.Tanh(),\n            nn.Linear(64, action_space.n)\n        )\n\n        # Define critic\'s model\n        self.critic = nn.Sequential(\n            nn.Linear(self.embedding_size, 64),\n            nn.Tanh(),\n            nn.Linear(64, 1)\n        )\n\n        # Initialize parameters correctly\n        self.apply(init_params)\n\n    @property\n    def memory_size(self):\n        return 2*self.semi_memory_size\n\n    @property\n    def semi_memory_size(self):\n        return self.image_embedding_size\n\n    def forward(self, obs, memory):\n        x = obs.image.transpose(1, 3).transpose(2, 3)\n        x = self.image_conv(x)\n        x = x.reshape(x.shape[0], -1)\n\n        if self.use_memory:\n            hidden = (memory[:, :self.semi_memory_size], memory[:, self.semi_memory_size:])\n            hidden = self.memory_rnn(x, hidden)\n            embedding = hidden[0]\n            memory = torch.cat(hidden, dim=1)\n        else:\n            embedding = x\n\n        if self.use_text:\n            embed_text = self._get_embed_text(obs.text)\n            embedding = torch.cat((embedding, embed_text), dim=1)\n\n        x = self.actor(embedding)\n        dist = Categorical(logits=F.log_softmax(x, dim=1))\n\n        x = self.critic(embedding)\n        value = x.squeeze(1)\n\n        return dist, value, memory\n\n    def _get_embed_text(self, text):\n        _, hidden = self.text_rnn(self.word_embedding(text))\n        return hidden[-1]\n'"
scripts/evaluate.py,6,"b'import argparse\nimport time\nimport torch\nfrom torch_ac.utils.penv import ParallelEnv\n\nimport utils\n\n\n# Parse arguments\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--env"", required=True,\n                    help=""name of the environment (REQUIRED)"")\nparser.add_argument(""--model"", required=True,\n                    help=""name of the trained model (REQUIRED)"")\nparser.add_argument(""--episodes"", type=int, default=100,\n                    help=""number of episodes of evaluation (default: 100)"")\nparser.add_argument(""--seed"", type=int, default=0,\n                    help=""random seed (default: 0)"")\nparser.add_argument(""--procs"", type=int, default=16,\n                    help=""number of processes (default: 16)"")\nparser.add_argument(""--argmax"", action=""store_true"", default=False,\n                    help=""action with highest probability is selected"")\nparser.add_argument(""--worst-episodes-to-show"", type=int, default=10,\n                    help=""how many worst episodes to show"")\nparser.add_argument(""--memory"", action=""store_true"", default=False,\n                    help=""add a LSTM to the model"")\nparser.add_argument(""--text"", action=""store_true"", default=False,\n                    help=""add a GRU to the model"")\nargs = parser.parse_args()\n\n# Set seed for all randomness sources\n\nutils.seed(args.seed)\n\n# Set device\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\nprint(f""Device: {device}\\n"")\n\n# Load environments\n\nenvs = []\nfor i in range(args.procs):\n    env = utils.make_env(args.env, args.seed + 10000 * i)\n    envs.append(env)\nenv = ParallelEnv(envs)\nprint(""Environments loaded\\n"")\n\n# Load agent\n\nmodel_dir = utils.get_model_dir(args.model)\nagent = utils.Agent(env.observation_space, env.action_space, model_dir,\n                    device=device, argmax=args.argmax, num_envs=args.procs,\n                    use_memory=args.memory, use_text=args.text)\nprint(""Agent loaded\\n"")\n\n# Initialize logs\n\nlogs = {""num_frames_per_episode"": [], ""return_per_episode"": []}\n\n# Run agent\n\nstart_time = time.time()\n\nobss = env.reset()\n\nlog_done_counter = 0\nlog_episode_return = torch.zeros(args.procs, device=device)\nlog_episode_num_frames = torch.zeros(args.procs, device=device)\n\nwhile log_done_counter < args.episodes:\n    actions = agent.get_actions(obss)\n    obss, rewards, dones, _ = env.step(actions)\n    agent.analyze_feedbacks(rewards, dones)\n\n    log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)\n    log_episode_num_frames += torch.ones(args.procs, device=device)\n\n    for i, done in enumerate(dones):\n        if done:\n            log_done_counter += 1\n            logs[""return_per_episode""].append(log_episode_return[i].item())\n            logs[""num_frames_per_episode""].append(log_episode_num_frames[i].item())\n\n    mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)\n    log_episode_return *= mask\n    log_episode_num_frames *= mask\n\nend_time = time.time()\n\n# Print logs\n\nnum_frames = sum(logs[""num_frames_per_episode""])\nfps = num_frames/(end_time - start_time)\nduration = int(end_time - start_time)\nreturn_per_episode = utils.synthesize(logs[""return_per_episode""])\nnum_frames_per_episode = utils.synthesize(logs[""num_frames_per_episode""])\n\nprint(""F {} | FPS {:.0f} | D {} | R:\xce\xbc\xcf\x83mM {:.2f} {:.2f} {:.2f} {:.2f} | F:\xce\xbc\xcf\x83mM {:.1f} {:.1f} {} {}""\n      .format(num_frames, fps, duration,\n              *return_per_episode.values(),\n              *num_frames_per_episode.values()))\n\n# Print worst episodes\n\nn = args.worst_episodes_to_show\nif n > 0:\n    print(""\\n{} worst episodes:"".format(n))\n\n    indexes = sorted(range(len(logs[""return_per_episode""])), key=lambda k: logs[""return_per_episode""][k])\n    for i in indexes[:n]:\n        print(""- episode {}: R={}, F={}"".format(i, logs[""return_per_episode""][i], logs[""num_frames_per_episode""][i]))\n'"
scripts/train.py,1,"b'import argparse\nimport time\nimport datetime\nimport torch\nimport torch_ac\nimport tensorboardX\nimport sys\n\nimport utils\nfrom model import ACModel\n\n\n# Parse arguments\n\nparser = argparse.ArgumentParser()\n\n## General parameters\nparser.add_argument(""--algo"", required=True,\n                    help=""algorithm to use: a2c | ppo (REQUIRED)"")\nparser.add_argument(""--env"", required=True,\n                    help=""name of the environment to train on (REQUIRED)"")\nparser.add_argument(""--model"", default=None,\n                    help=""name of the model (default: {ENV}_{ALGO}_{TIME})"")\nparser.add_argument(""--seed"", type=int, default=1,\n                    help=""random seed (default: 1)"")\nparser.add_argument(""--log-interval"", type=int, default=1,\n                    help=""number of updates between two logs (default: 1)"")\nparser.add_argument(""--save-interval"", type=int, default=10,\n                    help=""number of updates between two saves (default: 10, 0 means no saving)"")\nparser.add_argument(""--procs"", type=int, default=16,\n                    help=""number of processes (default: 16)"")\nparser.add_argument(""--frames"", type=int, default=10**7,\n                    help=""number of frames of training (default: 1e7)"")\n\n## Parameters for main algorithm\nparser.add_argument(""--epochs"", type=int, default=4,\n                    help=""number of epochs for PPO (default: 4)"")\nparser.add_argument(""--batch-size"", type=int, default=256,\n                    help=""batch size for PPO (default: 256)"")\nparser.add_argument(""--frames-per-proc"", type=int, default=None,\n                    help=""number of frames per process before update (default: 5 for A2C and 128 for PPO)"")\nparser.add_argument(""--discount"", type=float, default=0.99,\n                    help=""discount factor (default: 0.99)"")\nparser.add_argument(""--lr"", type=float, default=0.001,\n                    help=""learning rate (default: 0.001)"")\nparser.add_argument(""--gae-lambda"", type=float, default=0.95,\n                    help=""lambda coefficient in GAE formula (default: 0.95, 1 means no gae)"")\nparser.add_argument(""--entropy-coef"", type=float, default=0.01,\n                    help=""entropy term coefficient (default: 0.01)"")\nparser.add_argument(""--value-loss-coef"", type=float, default=0.5,\n                    help=""value loss term coefficient (default: 0.5)"")\nparser.add_argument(""--max-grad-norm"", type=float, default=0.5,\n                    help=""maximum norm of gradient (default: 0.5)"")\nparser.add_argument(""--optim-eps"", type=float, default=1e-8,\n                    help=""Adam and RMSprop optimizer epsilon (default: 1e-8)"")\nparser.add_argument(""--optim-alpha"", type=float, default=0.99,\n                    help=""RMSprop optimizer alpha (default: 0.99)"")\nparser.add_argument(""--clip-eps"", type=float, default=0.2,\n                    help=""clipping epsilon for PPO (default: 0.2)"")\nparser.add_argument(""--recurrence"", type=int, default=1,\n                    help=""number of time-steps gradient is backpropagated (default: 1). If > 1, a LSTM is added to the model to have memory."")\nparser.add_argument(""--text"", action=""store_true"", default=False,\n                    help=""add a GRU to the model to handle text input"")\n\nargs = parser.parse_args()\n\nargs.mem = args.recurrence > 1\n\n# Set run dir\n\ndate = datetime.datetime.now().strftime(""%y-%m-%d-%H-%M-%S"")\ndefault_model_name = f""{args.env}_{args.algo}_seed{args.seed}_{date}""\n\nmodel_name = args.model or default_model_name\nmodel_dir = utils.get_model_dir(model_name)\n\n# Load loggers and Tensorboard writer\n\ntxt_logger = utils.get_txt_logger(model_dir)\ncsv_file, csv_logger = utils.get_csv_logger(model_dir)\ntb_writer = tensorboardX.SummaryWriter(model_dir)\n\n# Log command and all script arguments\n\ntxt_logger.info(""{}\\n"".format("" "".join(sys.argv)))\ntxt_logger.info(""{}\\n"".format(args))\n\n# Set seed for all randomness sources\n\nutils.seed(args.seed)\n\n# Set device\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\ntxt_logger.info(f""Device: {device}\\n"")\n\n# Load environments\n\nenvs = []\nfor i in range(args.procs):\n    envs.append(utils.make_env(args.env, args.seed + 10000 * i))\ntxt_logger.info(""Environments loaded\\n"")\n\n# Load training status\n\ntry:\n    status = utils.get_status(model_dir)\nexcept OSError:\n    status = {""num_frames"": 0, ""update"": 0}\ntxt_logger.info(""Training status loaded\\n"")\n\n# Load observations preprocessor\n\nobs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)\nif ""vocab"" in status:\n    preprocess_obss.vocab.load_vocab(status[""vocab""])\ntxt_logger.info(""Observations preprocessor loaded"")\n\n# Load model\n\nacmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text)\nif ""model_state"" in status:\n    acmodel.load_state_dict(status[""model_state""])\nacmodel.to(device)\ntxt_logger.info(""Model loaded\\n"")\ntxt_logger.info(""{}\\n"".format(acmodel))\n\n# Load algo\n\nif args.algo == ""a2c"":\n    algo = torch_ac.A2CAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n                            args.optim_alpha, args.optim_eps, preprocess_obss)\nelif args.algo == ""ppo"":\n    algo = torch_ac.PPOAlgo(envs, acmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,\n                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,\n                            args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss)\nelse:\n    raise ValueError(""Incorrect algorithm name: {}"".format(args.algo))\n\nif ""optimizer_state"" in status:\n    algo.optimizer.load_state_dict(status[""optimizer_state""])\ntxt_logger.info(""Optimizer loaded\\n"")\n\n# Train model\n\nnum_frames = status[""num_frames""]\nupdate = status[""update""]\nstart_time = time.time()\n\nwhile num_frames < args.frames:\n    # Update model parameters\n\n    update_start_time = time.time()\n    exps, logs1 = algo.collect_experiences()\n    logs2 = algo.update_parameters(exps)\n    logs = {**logs1, **logs2}\n    update_end_time = time.time()\n\n    num_frames += logs[""num_frames""]\n    update += 1\n\n    # Print logs\n\n    if update % args.log_interval == 0:\n        fps = logs[""num_frames""]/(update_end_time - update_start_time)\n        duration = int(time.time() - start_time)\n        return_per_episode = utils.synthesize(logs[""return_per_episode""])\n        rreturn_per_episode = utils.synthesize(logs[""reshaped_return_per_episode""])\n        num_frames_per_episode = utils.synthesize(logs[""num_frames_per_episode""])\n\n        header = [""update"", ""frames"", ""FPS"", ""duration""]\n        data = [update, num_frames, fps, duration]\n        header += [""rreturn_"" + key for key in rreturn_per_episode.keys()]\n        data += rreturn_per_episode.values()\n        header += [""num_frames_"" + key for key in num_frames_per_episode.keys()]\n        data += num_frames_per_episode.values()\n        header += [""entropy"", ""value"", ""policy_loss"", ""value_loss"", ""grad_norm""]\n        data += [logs[""entropy""], logs[""value""], logs[""policy_loss""], logs[""value_loss""], logs[""grad_norm""]]\n\n        txt_logger.info(\n            ""U {} | F {:06} | FPS {:04.0f} | D {} | rR:\xce\xbc\xcf\x83mM {:.2f} {:.2f} {:.2f} {:.2f} | F:\xce\xbc\xcf\x83mM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | \xe2\x88\x87 {:.3f}""\n            .format(*data))\n\n        header += [""return_"" + key for key in return_per_episode.keys()]\n        data += return_per_episode.values()\n\n        if status[""num_frames""] == 0:\n            csv_logger.writerow(header)\n        csv_logger.writerow(data)\n        csv_file.flush()\n\n        for field, value in zip(header, data):\n            tb_writer.add_scalar(field, value, num_frames)\n\n    # Save status\n\n    if args.save_interval > 0 and update % args.save_interval == 0:\n        status = {""num_frames"": num_frames, ""update"": update,\n                  ""model_state"": acmodel.state_dict(), ""optimizer_state"": algo.optimizer.state_dict()}\n        if hasattr(preprocess_obss, ""vocab""):\n            status[""vocab""] = preprocess_obss.vocab.vocab\n        utils.save_status(status, model_dir)\n        txt_logger.info(""Status saved"")\n'"
scripts/visualize.py,1,"b'import argparse\nimport time\nimport numpy\nimport torch\n\nimport utils\n\n\n# Parse arguments\n\nparser = argparse.ArgumentParser()\nparser.add_argument(""--env"", required=True,\n                    help=""name of the environment to be run (REQUIRED)"")\nparser.add_argument(""--model"", required=True,\n                    help=""name of the trained model (REQUIRED)"")\nparser.add_argument(""--seed"", type=int, default=0,\n                    help=""random seed (default: 0)"")\nparser.add_argument(""--shift"", type=int, default=0,\n                    help=""number of times the environment is reset at the beginning (default: 0)"")\nparser.add_argument(""--argmax"", action=""store_true"", default=False,\n                    help=""select the action with highest probability (default: False)"")\nparser.add_argument(""--pause"", type=float, default=0.1,\n                    help=""pause duration between two consequent actions of the agent (default: 0.1)"")\nparser.add_argument(""--gif"", type=str, default=None,\n                    help=""store output as gif with the given filename"")\nparser.add_argument(""--episodes"", type=int, default=1000000,\n                    help=""number of episodes to visualize"")\nparser.add_argument(""--memory"", action=""store_true"", default=False,\n                    help=""add a LSTM to the model"")\nparser.add_argument(""--text"", action=""store_true"", default=False,\n                    help=""add a GRU to the model"")\n\nargs = parser.parse_args()\n\n# Set seed for all randomness sources\n\nutils.seed(args.seed)\n\n# Set device\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\nprint(f""Device: {device}\\n"")\n\n# Load environment\n\nenv = utils.make_env(args.env, args.seed)\nfor _ in range(args.shift):\n    env.reset()\nprint(""Environment loaded\\n"")\n\n# Load agent\n\nmodel_dir = utils.get_model_dir(args.model)\nagent = utils.Agent(env.observation_space, env.action_space, model_dir,\n                    device=device, argmax=args.argmax, use_memory=args.memory, use_text=args.text)\nprint(""Agent loaded\\n"")\n\n# Run the agent\n\nif args.gif:\n   from array2gif import write_gif\n   frames = []\n\n# Create a window to view the environment\nenv.render(\'human\')\n\nfor episode in range(args.episodes):\n    obs = env.reset()\n\n    while True:\n        env.render(\'human\')\n        if args.gif:\n            frames.append(numpy.moveaxis(env.render(""rgb_array""), 2, 0))\n\n        action = agent.get_action(obs)\n        obs, reward, done, _ = env.step(action)\n        agent.analyze_feedback(reward, done)\n\n        if done or env.window.closed:\n            break\n\n    if env.window.closed:\n        break\n\nif args.gif:\n    print(""Saving gif... "", end="""")\n    write_gif(numpy.array(frames), args.gif+"".gif"", fps=1/args.pause)\n    print(""Done."")\n'"
utils/__init__.py,0,b'from .agent import *\nfrom .env import *\nfrom .format import *\nfrom .other import *\nfrom .storage import *\n'
utils/agent.py,3,"b'import torch\n\nimport utils\nfrom model import ACModel\n\n\nclass Agent:\n    """"""An agent.\n\n    It is able:\n    - to choose an action given an observation,\n    - to analyze the feedback (i.e. reward and done state) of its action.""""""\n\n    def __init__(self, obs_space, action_space, model_dir,\n                 device=None, argmax=False, num_envs=1, use_memory=False, use_text=False):\n        obs_space, self.preprocess_obss = utils.get_obss_preprocessor(obs_space)\n        self.acmodel = ACModel(obs_space, action_space, use_memory=use_memory, use_text=use_text)\n        self.device = device\n        self.argmax = argmax\n        self.num_envs = num_envs\n\n        if self.acmodel.recurrent:\n            self.memories = torch.zeros(self.num_envs, self.acmodel.memory_size)\n\n        self.acmodel.load_state_dict(utils.get_model_state(model_dir))\n        self.acmodel.to(self.device)\n        self.acmodel.eval()\n        if hasattr(self.preprocess_obss, ""vocab""):\n            self.preprocess_obss.vocab.load_vocab(utils.get_vocab(model_dir))\n\n    def get_actions(self, obss):\n        preprocessed_obss = self.preprocess_obss(obss, device=self.device)\n\n        with torch.no_grad():\n            if self.acmodel.recurrent:\n                dist, _, self.memories = self.acmodel(preprocessed_obss, self.memories)\n            else:\n                dist, _ = self.acmodel(preprocessed_obss)\n\n        if self.argmax:\n            actions = dist.probs.max(1, keepdim=True)[1]\n        else:\n            actions = dist.sample()\n\n        return actions.cpu().numpy()\n\n    def get_action(self, obs):\n        return self.get_actions([obs])[0]\n\n    def analyze_feedbacks(self, rewards, dones):\n        if self.acmodel.recurrent:\n            masks = 1 - torch.tensor(dones, dtype=torch.float).unsqueeze(1)\n            self.memories *= masks\n\n    def analyze_feedback(self, reward, done):\n        return self.analyze_feedbacks([reward], [done])\n'"
utils/env.py,0,"b'import gym\nimport gym_minigrid\n\n\ndef make_env(env_key, seed=None):\n    env = gym.make(env_key)\n    env.seed(seed)\n    return env\n'"
utils/format.py,2,"b'import os\nimport json\nimport numpy\nimport re\nimport torch\nimport torch_ac\nimport gym\n\nimport utils\n\n\ndef get_obss_preprocessor(obs_space):\n    # Check if obs_space is an image space\n    if isinstance(obs_space, gym.spaces.Box):\n        obs_space = {""image"": obs_space.shape}\n\n        def preprocess_obss(obss, device=None):\n            return torch_ac.DictList({\n                ""image"": preprocess_images(obss, device=device)\n            })\n\n    # Check if it is a MiniGrid observation space\n    elif isinstance(obs_space, gym.spaces.Dict) and list(obs_space.spaces.keys()) == [""image""]:\n        obs_space = {""image"": obs_space.spaces[""image""].shape, ""text"": 100}\n\n        vocab = Vocabulary(obs_space[""text""])\n        def preprocess_obss(obss, device=None):\n            return torch_ac.DictList({\n                ""image"": preprocess_images([obs[""image""] for obs in obss], device=device),\n                ""text"": preprocess_texts([obs[""mission""] for obs in obss], vocab, device=device)\n            })\n        preprocess_obss.vocab = vocab\n\n    else:\n        raise ValueError(""Unknown observation space: "" + str(obs_space))\n\n    return obs_space, preprocess_obss\n\n\ndef preprocess_images(images, device=None):\n    # Bug of Pytorch: very slow if not first converted to numpy array\n    images = numpy.array(images)\n    return torch.tensor(images, device=device, dtype=torch.float)\n\n\ndef preprocess_texts(texts, vocab, device=None):\n    var_indexed_texts = []\n    max_text_len = 0\n\n    for text in texts:\n        tokens = re.findall(""([a-z]+)"", text.lower())\n        var_indexed_text = numpy.array([vocab[token] for token in tokens])\n        var_indexed_texts.append(var_indexed_text)\n        max_text_len = max(len(var_indexed_text), max_text_len)\n\n    indexed_texts = numpy.zeros((len(texts), max_text_len))\n\n    for i, indexed_text in enumerate(var_indexed_texts):\n        indexed_texts[i, :len(indexed_text)] = indexed_text\n\n    return torch.tensor(indexed_texts, device=device, dtype=torch.long)\n\n\nclass Vocabulary:\n    """"""A mapping from tokens to ids with a capacity of `max_size` words.\n    It can be saved in a `vocab.json` file.""""""\n\n    def __init__(self, max_size):\n        self.max_size = max_size\n        self.vocab = {}\n\n    def load_vocab(self, vocab):\n        self.vocab = vocab\n\n    def __getitem__(self, token):\n        if not token in self.vocab.keys():\n            if len(self.vocab) >= self.max_size:\n                raise ValueError(""Maximum vocabulary capacity reached"")\n            self.vocab[token] = len(self.vocab) + 1\n        return self.vocab[token]\n'"
utils/other.py,3,"b'import random\nimport numpy\nimport torch\nimport collections\n\n\ndef seed(seed):\n    random.seed(seed)\n    numpy.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n\ndef synthesize(array):\n    d = collections.OrderedDict()\n    d[""mean""] = numpy.mean(array)\n    d[""std""] = numpy.std(array)\n    d[""min""] = numpy.amin(array)\n    d[""max""] = numpy.amax(array)\n    return d\n'"
utils/storage.py,2,"b'import csv\nimport os\nimport torch\nimport logging\nimport sys\n\nimport utils\n\n\ndef create_folders_if_necessary(path):\n    dirname = os.path.dirname(path)\n    if not os.path.isdir(dirname):\n        os.makedirs(dirname)\n\n\ndef get_storage_dir():\n    if ""RL_STORAGE"" in os.environ:\n        return os.environ[""RL_STORAGE""]\n    return ""storage""\n\n\ndef get_model_dir(model_name):\n    return os.path.join(get_storage_dir(), model_name)\n\n\ndef get_status_path(model_dir):\n    return os.path.join(model_dir, ""status.pt"")\n\n\ndef get_status(model_dir):\n    path = get_status_path(model_dir)\n    return torch.load(path)\n\n\ndef save_status(status, model_dir):\n    path = get_status_path(model_dir)\n    utils.create_folders_if_necessary(path)\n    torch.save(status, path)\n\n\ndef get_vocab(model_dir):\n    return get_status(model_dir)[""vocab""]\n\n\ndef get_model_state(model_dir):\n    return get_status(model_dir)[""model_state""]\n\n\ndef get_txt_logger(model_dir):\n    path = os.path.join(model_dir, ""log.txt"")\n    utils.create_folders_if_necessary(path)\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format=""%(message)s"",\n        handlers=[\n            logging.FileHandler(filename=path),\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n\n    return logging.getLogger()\n\n\ndef get_csv_logger(model_dir):\n    csv_path = os.path.join(model_dir, ""log.csv"")\n    utils.create_folders_if_necessary(csv_path)\n    csv_file = open(csv_path, ""a"")\n    return csv_file, csv.writer(csv_file)\n'"
