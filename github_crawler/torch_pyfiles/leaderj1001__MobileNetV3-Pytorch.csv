file_path,api_count,code
main.py,10,"b'import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom preprocess import load_data\nfrom model import MobileNetV3\n\nimport argparse\nfrom tqdm import tqdm\nimport time\nimport os\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(""parameters"")\n\n    parser.add_argument(""--dataset-mode"", type=str, default=""IMAGENET"", help=""(example: CIFAR10, CIFAR100, IMAGENET), (default: IMAGENET)"")\n    parser.add_argument(""--epochs"", type=int, default=100, help=""number of epochs, (default: 100)"")\n    parser.add_argument(""--batch-size"", type=int, default=512, help=""number of batch size, (default, 512)"")\n    parser.add_argument(""--learning-rate"", type=float, default=1e-1, help=""learning_rate, (default: 1e-1)"")\n    parser.add_argument(""--dropout"", type=float, default=0.8, help=""dropout rate, not implemented yet, (default: 0.8)"")\n    parser.add_argument(\'--model-mode\', type=str, default=""LARGE"", help=""(example: LARGE, SMALL), (default: LARGE)"")\n    parser.add_argument(""--load-pretrained"", type=bool, default=False, help=""(default: False)"")\n    parser.add_argument(\'--evaluate\', type=bool, default=False, help=""Testing time: True, (default: False)"")\n    parser.add_argument(\'--multiplier\', type=float, default=1.0, help=""(default: 1.0)"")\n    parser.add_argument(\'--print-interval\', type=int, default=5, help=""training information and evaluation information output frequency, (default: 5)"")\n    parser.add_argument(\'--data\', default=\'D:/ILSVRC/Data/CLS-LOC\')\n    parser.add_argument(\'--workers\', type=int, default=4)\n    parser.add_argument(\'--distributed\', type=bool, default=False)\n\n    args = parser.parse_args()\n\n    return args\n\n\ndef adjust_learning_rate(optimizer, epoch, args):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.learning_rate * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n\n# reference,\n# https://github.com/pytorch/examples/blob/master/imagenet/main.py\n# Thank you.\nclass AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self, name, fmt=\':f\'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = \'{name} {val\' + self.fmt + \'} ({avg\' + self.fmt + \'})\'\n        return fmtstr.format(**self.__dict__)\n\n\ndef train(train_loader, model, criterion, optimizer, epoch, args):\n    batch_time = AverageMeter(\'Time\', \':6.3f\')\n    data_time = AverageMeter(\'Data\', \':6.3f\')\n    losses = AverageMeter(\'Loss\', \':.4e\')\n    top1 = AverageMeter(\'Acc@1\', \':6.2f\')\n    top5 = AverageMeter(\'Acc@5\', \':6.2f\')\n    progress = ProgressMeter(len(train_loader), batch_time, data_time, losses, top1, top5, prefix=""Epoch: [{}]"".format(epoch))\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for i, (data, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        data, target = data.to(device), target.to(device)\n\n        # if args.gpu is not None:\n        #     data = data.cuda(args.gpu, non_blocking=True)\n        # target = target.cuda(args.gpu, non_blocking=True)\n\n        # compute output\n        output = model(data)\n        loss = criterion(output, target)\n\n        # measure accuracy and record loss\n        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n        losses.update(loss.item(), data.size(0))\n        top1.update(acc1[0], data.size(0))\n        top5.update(acc5[0], data.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_interval == 0:\n            progress.print(i)\n\n\ndef validate(val_loader, model, criterion, args):\n    batch_time = AverageMeter(\'Time\', \':6.3f\')\n    losses = AverageMeter(\'Loss\', \':.4e\')\n    top1 = AverageMeter(\'Acc@1\', \':6.2f\')\n    top5 = AverageMeter(\'Acc@5\', \':6.2f\')\n    progress = ProgressMeter(len(val_loader), batch_time, losses, top1, top5,\n                             prefix=\'Test: \')\n\n    # switch to evaluate mode\n    model.eval()\n    with torch.no_grad():\n        end = time.time()\n        for i, (data, target) in enumerate(val_loader):\n            # if args.gpu is not None:\n            #     input = input.cuda(args.gpu, non_blocking=True)\n            # target = target.cuda(args.gpu, non_blocking=True)\n            data, target = data.to(device), target.to(device)\n\n            # compute output\n            output = model(data)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n            losses.update(loss.item(), data.size(0))\n            top1.update(acc1[0], data.size(0))\n            top5.update(acc5[0], data.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n\n            if i % args.print_interval == 0:\n                progress.print(i)\n\n        # TODO: this should also be done with the ProgressMeter\n        print(\' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\'\n              .format(top1=top1, top5=top5))\n\n    return top1.avg, top5.avg\n\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, *meters, prefix=""""):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def print(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print(\'\\t\'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = \'{:\' + str(num_digits) + \'d}\'\n        return \'[\' + fmt + \'/\' + fmt.format(num_batches) + \']\'\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the accuracy over the k top predictions for the specified values of k""""""\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n\ndef main():\n    args = get_args()\n    train_loader, test_loader = load_data(args)\n\n    if args.dataset_mode == ""CIFAR10"":\n        num_classes = 10\n    elif args.dataset_mode == ""CIFAR100"":\n        num_classes = 100\n    elif args.dataset_mode == ""IMAGENET"":\n        num_classes = 1000\n    print(\'num_classes: \', num_classes)\n\n    model = MobileNetV3(model_mode=args.model_mode, num_classes=num_classes, multiplier=args.multiplier, dropout_rate=args.dropout).to(device)\n    if torch.cuda.device_count() >= 1:\n        print(""num GPUs: "", torch.cuda.device_count())\n        model = nn.DataParallel(model).to(device)\n\n    if args.load_pretrained or args.evaluate:\n        filename = ""best_model_"" + str(args.model_mode)\n        checkpoint = torch.load(\'./checkpoint/\' + filename + \'_ckpt.t7\')\n        model.load_state_dict(checkpoint[\'model\'])\n        epoch = checkpoint[\'epoch\']\n        acc1 = checkpoint[\'best_acc1\']\n        acc5 = checkpoint[\'best_acc5\']\n        best_acc1 = acc1\n        print(""Load Model Accuracy1: "", acc1, "" acc5: "", acc5, ""Load Model end epoch: "", epoch)\n    else:\n        print(""init model load ..."")\n        epoch = 1\n        best_acc1 = 0\n\n    optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, weight_decay=1e-5, momentum=0.9)\n    # optimizer = optim.RMSprop(model.parameters(), lr=args.learning_rate, momentum=0.9, weight_decay=1e-5)\n    criterion = nn.CrossEntropyLoss().to(device)\n\n    if args.evaluate:\n        acc1, acc5 = validate(test_loader, model, criterion, args)\n        print(""Acc1: "", acc1, ""Acc5: "", acc5)\n        return\n\n    if not os.path.isdir(""reporting""):\n        os.mkdir(""reporting"")\n\n    start_time = time.time()\n    with open(""./reporting/"" + ""best_model_"" + args.model_mode + "".txt"", ""w"") as f:\n        for epoch in range(epoch, args.epochs):\n            adjust_learning_rate(optimizer, epoch, args)\n            train(train_loader, model, criterion, optimizer, epoch, args)\n            acc1, acc5 = validate(test_loader, model, criterion, args)\n\n            is_best = acc1 > best_acc1\n            best_acc1 = max(acc1, best_acc1)\n\n            if is_best:\n                print(\'Saving..\')\n                best_acc5 = acc5\n                state = {\n                    \'model\': model.state_dict(),\n                    \'best_acc1\': best_acc1,\n                    \'best_acc5\': best_acc5,\n                    \'epoch\': epoch,\n                }\n                if not os.path.isdir(\'checkpoint\'):\n                    os.mkdir(\'checkpoint\')\n                filename = ""best_model_"" + str(args.model_mode)\n                torch.save(state, \'./checkpoint/\' + filename + \'_ckpt.t7\')\n\n            time_interval = time.time() - start_time\n            time_split = time.gmtime(time_interval)\n            print(""Training time: "", time_interval, ""Hour: "", time_split.tm_hour, ""Minute: "", time_split.tm_min, ""Second: "", time_split.tm_sec, end=\'\')\n            print("" Test best acc1:"", best_acc1, "" acc1: "", acc1, "" acc5: "", acc5)\n\n            f.write(""Epoch: "" + str(epoch) + "" "" + "" Best acc: "" + str(best_acc1) + "" Test acc: "" + str(acc1) + ""\\n"")\n            f.write(""Training time: "" + str(time_interval) + "" Hour: "" + str(time_split.tm_hour) + "" Minute: "" + str(\n                time_split.tm_min) + "" Second: "" + str(time_split.tm_sec))\n            f.write(""\\n"")\n\n\nif __name__ == ""__main__"":\n    main()\n'"
model.py,5,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef get_model_parameters(model):\n    total_parameters = 0\n    for layer in list(model.parameters()):\n        layer_parameter = 1\n        for l in list(layer.size()):\n            layer_parameter *= l\n        total_parameters += layer_parameter\n    return total_parameters\n\n\ndef _weights_init(m):\n    if isinstance(m, nn.Conv2d):\n        torch.nn.init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            torch.nn.init.zeros_(m.bias)\n    elif isinstance(m, nn.BatchNorm2d):\n        m.weight.data.fill_(1)\n        m.bias.data.zero_()\n    elif isinstance(m, nn.Linear):\n        n = m.weight.size(1)\n        m.weight.data.normal_(0, 0.01)\n        m.bias.data.zero_()\n\n\nclass h_sigmoid(nn.Module):\n    def __init__(self, inplace=True):\n        super(h_sigmoid, self).__init__()\n        self.inplace = inplace\n\n    def forward(self, x):\n        return F.relu6(x + 3., inplace=self.inplace) / 6.\n\n\nclass h_swish(nn.Module):\n    def __init__(self, inplace=True):\n        super(h_swish, self).__init__()\n        self.inplace = inplace\n\n    def forward(self, x):\n        out = F.relu6(x + 3., self.inplace) / 6.\n        return out * x\n\n\ndef _make_divisible(v, divisor=8, min_value=None):\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\nclass SqueezeBlock(nn.Module):\n    def __init__(self, exp_size, divide=4):\n        super(SqueezeBlock, self).__init__()\n        self.dense = nn.Sequential(\n            nn.Linear(exp_size, exp_size // divide),\n            nn.ReLU(inplace=True),\n            nn.Linear(exp_size // divide, exp_size),\n            h_sigmoid()\n        )\n\n    def forward(self, x):\n        batch, channels, height, width = x.size()\n        out = F.avg_pool2d(x, kernel_size=[height, width]).view(batch, -1)\n        out = self.dense(out)\n        out = out.view(batch, channels, 1, 1)\n        # out = hard_sigmoid(out)\n\n        return out * x\n\n\nclass MobileBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernal_size, stride, nonLinear, SE, exp_size):\n        super(MobileBlock, self).__init__()\n        self.out_channels = out_channels\n        self.nonLinear = nonLinear\n        self.SE = SE\n        padding = (kernal_size - 1) // 2\n\n        self.use_connect = stride == 1 and in_channels == out_channels\n\n        if self.nonLinear == ""RE"":\n            activation = nn.ReLU\n        else:\n            activation = h_swish\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, exp_size, kernel_size=1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(exp_size),\n            activation(inplace=True)\n        )\n        self.depth_conv = nn.Sequential(\n            nn.Conv2d(exp_size, exp_size, kernel_size=kernal_size, stride=stride, padding=padding, groups=exp_size),\n            nn.BatchNorm2d(exp_size),\n        )\n\n        if self.SE:\n            self.squeeze_block = SqueezeBlock(exp_size)\n\n        self.point_conv = nn.Sequential(\n            nn.Conv2d(exp_size, out_channels, kernel_size=1, stride=1, padding=0),\n            nn.BatchNorm2d(out_channels),\n            activation(inplace=True)\n        )\n\n    def forward(self, x):\n        # MobileNetV2\n        out = self.conv(x)\n        out = self.depth_conv(out)\n\n        # Squeeze and Excite\n        if self.SE:\n            out = self.squeeze_block(out)\n\n        # point-wise conv\n        out = self.point_conv(out)\n\n        # connection\n        if self.use_connect:\n            return x + out\n        else:\n            return out\n\n\nclass MobileNetV3(nn.Module):\n    def __init__(self, model_mode=""LARGE"", num_classes=1000, multiplier=1.0, dropout_rate=0.0):\n        super(MobileNetV3, self).__init__()\n        self.num_classes = num_classes\n\n        if model_mode == ""LARGE"":\n            layers = [\n                [16, 16, 3, 1, ""RE"", False, 16],\n                [16, 24, 3, 2, ""RE"", False, 64],\n                [24, 24, 3, 1, ""RE"", False, 72],\n                [24, 40, 5, 2, ""RE"", True, 72],\n                [40, 40, 5, 1, ""RE"", True, 120],\n\n                [40, 40, 5, 1, ""RE"", True, 120],\n                [40, 80, 3, 2, ""HS"", False, 240],\n                [80, 80, 3, 1, ""HS"", False, 200],\n                [80, 80, 3, 1, ""HS"", False, 184],\n                [80, 80, 3, 1, ""HS"", False, 184],\n\n                [80, 112, 3, 1, ""HS"", True, 480],\n                [112, 112, 3, 1, ""HS"", True, 672],\n                [112, 160, 5, 1, ""HS"", True, 672],\n                [160, 160, 5, 2, ""HS"", True, 672],\n                [160, 160, 5, 1, ""HS"", True, 960],\n            ]\n            init_conv_out = _make_divisible(16 * multiplier)\n            self.init_conv = nn.Sequential(\n                nn.Conv2d(in_channels=3, out_channels=init_conv_out, kernel_size=3, stride=2, padding=1),\n                nn.BatchNorm2d(init_conv_out),\n                h_swish(inplace=True),\n            )\n\n            self.block = []\n            for in_channels, out_channels, kernal_size, stride, nonlinear, se, exp_size in layers:\n                in_channels = _make_divisible(in_channels * multiplier)\n                out_channels = _make_divisible(out_channels * multiplier)\n                exp_size = _make_divisible(exp_size * multiplier)\n                self.block.append(MobileBlock(in_channels, out_channels, kernal_size, stride, nonlinear, se, exp_size))\n            self.block = nn.Sequential(*self.block)\n\n            out_conv1_in = _make_divisible(160 * multiplier)\n            out_conv1_out = _make_divisible(960 * multiplier)\n            self.out_conv1 = nn.Sequential(\n                nn.Conv2d(out_conv1_in, out_conv1_out, kernel_size=1, stride=1),\n                nn.BatchNorm2d(out_conv1_out),\n                h_swish(inplace=True),\n            )\n\n            out_conv2_in = _make_divisible(960 * multiplier)\n            out_conv2_out = _make_divisible(1280 * multiplier)\n            self.out_conv2 = nn.Sequential(\n                nn.Conv2d(out_conv2_in, out_conv2_out, kernel_size=1, stride=1),\n                h_swish(inplace=True),\n                nn.Dropout(dropout_rate),\n                nn.Conv2d(out_conv2_out, self.num_classes, kernel_size=1, stride=1),\n            )\n\n        elif model_mode == ""SMALL"":\n            layers = [\n                [16, 16, 3, 2, ""RE"", True, 16],\n                [16, 24, 3, 2, ""RE"", False, 72],\n                [24, 24, 3, 1, ""RE"", False, 88],\n                [24, 40, 5, 2, ""RE"", True, 96],\n                [40, 40, 5, 1, ""RE"", True, 240],\n                [40, 40, 5, 1, ""RE"", True, 240],\n                [40, 48, 5, 1, ""HS"", True, 120],\n                [48, 48, 5, 1, ""HS"", True, 144],\n                [48, 96, 5, 2, ""HS"", True, 288],\n                [96, 96, 5, 1, ""HS"", True, 576],\n                [96, 96, 5, 1, ""HS"", True, 576],\n            ]\n\n            init_conv_out = _make_divisible(16 * multiplier)\n            self.init_conv = nn.Sequential(\n                nn.Conv2d(in_channels=3, out_channels=init_conv_out, kernel_size=3, stride=2, padding=1),\n                nn.BatchNorm2d(init_conv_out),\n                h_swish(inplace=True),\n            )\n\n            self.block = []\n            for in_channels, out_channels, kernal_size, stride, nonlinear, se, exp_size in layers:\n                in_channels = _make_divisible(in_channels * multiplier)\n                out_channels = _make_divisible(out_channels * multiplier)\n                exp_size = _make_divisible(exp_size * multiplier)\n                self.block.append(MobileBlock(in_channels, out_channels, kernal_size, stride, nonlinear, se, exp_size))\n            self.block = nn.Sequential(*self.block)\n\n            out_conv1_in = _make_divisible(96 * multiplier)\n            out_conv1_out = _make_divisible(576 * multiplier)\n            self.out_conv1 = nn.Sequential(\n                nn.Conv2d(out_conv1_in, out_conv1_out, kernel_size=1, stride=1),\n                SqueezeBlock(out_conv1_out),\n                nn.BatchNorm2d(out_conv1_out),\n                h_swish(inplace=True),\n            )\n\n            out_conv2_in = _make_divisible(576 * multiplier)\n            out_conv2_out = _make_divisible(1280 * multiplier)\n            self.out_conv2 = nn.Sequential(\n                nn.Conv2d(out_conv2_in, out_conv2_out, kernel_size=1, stride=1),\n                h_swish(inplace=True),\n                nn.Dropout(dropout_rate),\n                nn.Conv2d(out_conv2_out, self.num_classes, kernel_size=1, stride=1),\n            )\n\n        self.apply(_weights_init)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.block(out)\n        out = self.out_conv1(out)\n        batch, channels, height, width = out.size()\n        out = F.avg_pool2d(out, kernel_size=[height, width])\n        out = self.out_conv2(out).view(batch, -1)\n        return out\n\n\n# temp = torch.zeros((1, 3, 224, 224))\n# model = MobileNetV3(model_mode=""LARGE"", num_classes=1000, multiplier=1.0)\n# print(model(temp).shape)\n# print(get_model_parameters(model))\n'"
preprocess.py,7,"b'import torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nimport os\n\n\ndef load_data(args):\n    if args.dataset_mode == ""CIFAR100"":\n        transform_train = transforms.Compose([\n            transforms.Resize(224),\n            transforms.RandomCrop(224, padding=4),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n        ])\n\n        transform_test = transforms.Compose([\n            transforms.Resize(224),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n        ])\n        train_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'data\', train=True, download=True, transform=transform_train),\n            batch_size=args.batch_size,\n            shuffle=True,\n            num_workers=args.workers\n        )\n\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR100(\'data\', train=False, transform=transform_test),\n            batch_size=args.batch_size,\n            shuffle=False,\n            num_workers=args.workers\n        )\n    elif args.dataset_mode == ""CIFAR10"":\n        transform_train = transforms.Compose([\n            transforms.Resize(224),\n            transforms.RandomCrop(224, padding=4),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ])\n\n        transform_test = transforms.Compose([\n            transforms.Resize(224),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ])\n        train_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'data\', train=True, download=True, transform=transform_train),\n            batch_size=args.batch_size,\n            shuffle=True,\n            num_workers=args.workers\n        )\n\n        test_loader = torch.utils.data.DataLoader(\n            datasets.CIFAR10(\'data\', train=False, transform=transform_test),\n            batch_size=args.batch_size,\n            shuffle=False,\n            num_workers=args.workers\n        )\n\n    elif args.dataset_mode == ""IMAGENET"":\n        traindir = os.path.join(args.data, \'train\')\n        valdir = os.path.join(args.data, \'val\')\n\n        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                         std=[0.229, 0.224, 0.225])\n\n        train_dataset = datasets.ImageFolder(\n            traindir,\n            transforms.Compose([\n                transforms.RandomResizedCrop(224),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                normalize,\n            ]))\n\n        # Check class labels\n        # print(train_dataset.classes)\n\n        if args.distributed:\n            train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n        else:\n            train_sampler = None\n\n        train_loader = torch.utils.data.DataLoader(\n            train_dataset,\n            batch_size=args.batch_size,\n            shuffle=(train_sampler is None),\n            num_workers=args.workers,\n            pin_memory=True,\n            sampler=train_sampler\n        )\n\n        test_loader = torch.utils.data.DataLoader(\n            datasets.ImageFolder(valdir, transforms.Compose([\n                transforms.Resize(256),\n                transforms.CenterCrop(224),\n                transforms.ToTensor(),\n                normalize,\n            ])),\n            batch_size=args.batch_size,\n            shuffle=False,\n            num_workers=args.workers,\n            pin_memory=True\n        )\n\n    return train_loader, test_loader\n'"
