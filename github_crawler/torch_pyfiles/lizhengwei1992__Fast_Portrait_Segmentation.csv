file_path,api_count,code
data/data_config.py,2,"b""'''\ndataconfig: \nAuthor: Zhengwei Li\nData: July 22 2018\n'''\n\nimport torch, cv2\nimport random as r\nimport numpy as np\nimport math\n\n\n## ---------------------------------\ndef crop_patch(Img, Tar, patch):\n    (h, w, c) = Img.shape\n\n    if r.random() < 0.5:\n        if h>patch and w>patch:\n            x = r.randrange(0, (w - patch))\n            y = r.randrange(0, (h - patch))\n\n            Img = Img[y:y + patch, x:x + patch, :]\n            Tar = Tar[y:y + patch, x:x + patch, :]\n        else:\n            Img = cv2.resize(Img, (patch,patch), interpolation=cv2.INTER_CUBIC)\n            Tar = cv2.resize(Tar, (patch,patch), interpolation=cv2.INTER_NEAREST)\n    else:\n        Img = cv2.resize(Img, (patch,patch), interpolation=cv2.INTER_CUBIC)\n        Tar = cv2.resize(Tar, (patch,patch), interpolation=cv2.INTER_NEAREST) \n              \n    return Img, Tar\n\n\ndef augment(Img, Tar):\n    if r.random() < 0.5:\n        Img = Img[:, ::-1, :]\n        Tar = Tar[:, ::-1, :]\n    if r.random() < 0.5:\n        Img = Img[::-1, :, :]\n        Tar = Tar[::-1, :, :]\n    return Img, Tar\n\ndef np2Tensor(Img, Tar):\n    ts = (2, 0, 1)\n\n    Img = torch.FloatTensor(Img.transpose(ts).astype(float)).mul_(1.0)\n    Tar = torch.FloatTensor(Tar.transpose(ts).astype(float)).mul_(1.0)\n    \n    return Img, Tar\n\n"""
data/dataset.py,0,"b'\'\'\'\ndataset: \n\nAuthor: Zhengwei Li\nData: July 20 2018\n\'\'\'\n\nfrom __future__ import print_function, division\nimport os\n\nimport numpy as np\nfrom data import data_config\nimport torch\nimport cv2\n\nINPUT_SIZE = 512\n\n\nclass coco(data.Dataset):\n\n    def __init__(self,\n                 base_dir=\'\',\n                 ):\n        """"""\n\t\t\tdataset: portrait segmentation\n        """"""\n        super().__init__()\n        self._base_dir = base_dir\n        self._image_dir = os.path.join(self._base_dir, \'images\')\n        self._label_dir = os.path.join(self._base_dir, \'masks\')\n\n        self.img_List = os.listdir(self._image_dir)\n        self.lal_List = os.listdir(self._label_dir)\n        self.img_List.sort()\n        self.lal_List.sort()\n\n        self.data_num = len(self.img_List)\n\n        print(""Dataset : ulsee_coco !"")\n        print(\'file number %d\' % len(self.img_List))\n\n\n    def __getitem__(self, index):\n\n        _img = cv2.imread(os.path.join(self._image_dir, self.img_List[index])).astype(np.float32)\n        _img = (_img - (104., 112., 121.,)) / 255.0\n        _target = cv2.imread(os.path.join(self._label_dir, self.lal_List[index])).astype(np.float32) #(0,1)\n\n        _img, _target = data_config.crop_patch(_img, _target, INPUT_SIZE)\n\n        _img, _target = data_config.augment(_img, _target)\n\n        _img, _target = data_config.np2Tensor(_img, _target)\n        _target = _target[0,:,:].unsqueeze_(0)\n\n        sample = {\'image\': _img, \'gt\': _target}\n\n        return sample\n\n    def __len__(self):\n        return self.data_num\n        \n        \n \n'"
models/esp_dense_seg.py,8,"b""\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass make_dense(nn.Module):\n    def __init__(self, nChannels, growthRate, dilation):\n        super(make_dense, self).__init__()\n        self.conv = nn.Conv2d(nChannels, growthRate, kernel_size=3, padding=dilation, dilation=dilation, bias=False)\n        self.bn = nn.BatchNorm2d(growthRate)\n    def forward(self, x):\n\n        out = F.relu(self.conv(x))\n        out = torch.cat((x, out), 1)\n        return out\n\nclass DenseBlock(nn.Module):\n    def __init__(self, nChannels, nDenselayer, growthRate, d, reset_channel=False):\n        super(DenseBlock, self).__init__()\n        nChannels_ = nChannels\n        modules = []\n        for i in range(nDenselayer):    \n            modules.append(make_dense(nChannels_, growthRate, dilation=d[i]))\n            nChannels_ += growthRate \n        self.dense_layers = nn.Sequential(*modules)\n\n        self.reset_channel = reset_channel\n        if  self.reset_channel:\n            self.conv_1x1 = nn.Conv2d(nChannels_, nChannels, kernel_size=1, stride=1,padding=0, bias=False)\n\n    def forward(self, x):\n        out = self.dense_layers(x)\n        if self.reset_channel:\n            out = self.conv_1x1(out)\n\n        return out\n# DilatedDenseResidualBlock\nclass DDRB(nn.Module):\n    def __init__(self, nIn, s=4, d =[1,2,4], add=True):\n\n        super().__init__()\n\n        n = int(nIn//s) \n\n        self.conv =  nn.Conv2d(nIn, n, 1, stride=1, padding=0, bias=False)\n        self.dense_block = DenseBlock(n, nDenselayer=(s-1), growthRate=n, d=d)\n\n        self.bn = nn.BatchNorm2d(nIn)\n        self.act = nn.ReLU()\n\n        self.add = add\n\n    def forward(self, input):\n\n        # reduce\n        inter = self.conv(input)\n        dense_out =self.dense_block(inter)\n\n        # if residual version\n        if self.add:\n            combine = input + dense_out\n        output = self.act(self.bn(combine))\n        return output\n\n# DilatedDenseBlock\nclass DDB(nn.Module):\n\n    def __init__(self, nIn, d =[1,2,4]):\n\n        super().__init__()\n\n        self.dense_block = DenseBlock(nIn, nDenselayer=3, growthRate=nIn, d=d, reset_channel=True)\n\n        self.bn = nn.BatchNorm2d(nIn)\n        self.act = nn.ReLU()\n\n\n    def forward(self, input):\n\n        # reduce\n        dense_out =self.dense_block(input)\n        output = self.act(self.bn(dense_out))\n        return output\n\n# DilatedParllelResidualBlock\nclass DPRB(nn.Module):\n    '''\n    This class defines the ESP block, which is based on the following principle\n        Reduce ---> Split ---> Transform --> Merge\n    '''\n    def __init__(self, nIn, add=True):\n        '''\n        :param nIn: number of input channels\n        :param nOut: number of output channels\n        :param add: if true, add a residual connection through identity operation. You can use projection too as\n                in ResNet paper, but we avoid to use it if the dimensions are not the same because we do not want to\n                increase the module complexity\n        '''\n        super().__init__()\n\n        # s = 2 dowm\n        n = int(nIn//6) \n\n        self.conv =  nn.Conv2d(nIn, n, 3, stride=1, padding=1, bias=False)\n\n        self.d0  = nn.Conv2d(n, n, 1, 1, 0, bias=False) # conv 1x1 \n        self.d1  = nn.Conv2d(n, n, 3, 1, padding=1,  dilation=1,  bias=False) # dilation rate of 2^0\n        self.d2  = nn.Conv2d(n, n, 3, 1, padding=2,  dilation=2,  bias=False) # dilation rate of 2^1\n        self.d4  = nn.Conv2d(n, n, 3, 1, padding=4,  dilation=4,  bias=False) # dilation rate of 2^2\n        self.d8  = nn.Conv2d(n, n, 3, 1, padding=8,  dilation=8,  bias=False) # dilation rate of 2^3\n        self.d16 = nn.Conv2d(n, n, 3, 1, padding=16, dilation=16, bias=False) # dilation rate of 2^4\n\n        self.bn = nn.BatchNorm2d(nIn, eps=1e-03)\n        self.act = nn.PReLU(nIn)\n\n        self.add = add\n\n    def forward(self, input):\n\n        # reduce\n        inter = self.conv(input)\n\n        d0 = self.d0(inter)\n        # split and transform\n        d1 = self.d1(inter)\n        d2 = self.d2(inter)\n        d4 = self.d4(inter)\n        d8 = self.d8(inter)\n        d16 = self.d16(inter)\n\n        # heirarchical fusion for de-gridding\n        add1 = d2\n        add2 = add1 + d4\n        add3 = add2 + d8\n        add4 = add3 + d16\n   \n        #merge\n        combine = torch.cat([d0, d1, add1, add2, add3, add4], 1)\n\n        # if residual version\n        if self.add:\n            combine = input + combine\n        output = self.act(self.bn(combine))\n        return output\n\n\nclass ESPD_SegNet(nn.Module):\n\n    def __init__(self, classes=1, p=1, q=1, r=2, t=2):\n        '''\n        :param classes: number of classes in the dataset.\n        '''\n        super().__init__()\n\n        # -----------------------------------------------------------------\n        # encoder \n        # ---------------------\n        self.conv0 = nn.Conv2d(3, 12, 3, stride=1, padding=1, bias=False)\n\n        self.b0 = nn.BatchNorm2d(12, eps=1e-03)\n        self.a0 = nn.PReLU(12)\n\n        self.down_1 = nn.Conv2d(12, 12, 3, stride=2, padding=1, bias=False)\n        self.stage_1_0 = DPRB(12, add=True)\n        block = [DDRB(12, s=6, d=[1,2,4,6,8], add=True) for _ in range(p)]\n        self.stage_1 = nn.Sequential(*block)\n\n        self.b1 = nn.BatchNorm2d(24, eps=1e-03)\n        self.a1 = nn.PReLU(24)\n\n        self.down_2 = nn.Conv2d(24, 24, 3, stride=2, padding=1, bias=False)\n        self.stage_2_0 = DPRB(24, add=True)\n        block = [DDRB(24, s=6, d=[1,2,4,6,8], add=True) for _ in range(q)]\n        self.stage_2 = nn.Sequential(*block)\n\n        self.b2 = nn.BatchNorm2d(48, eps=1e-03)\n        self.a2 = nn.PReLU(48)\n\n        self.down_3 = nn.Conv2d(48, 48, 3, stride=2, padding=1, bias=False)\n        self.stage_3_0 = DPRB(48, add=True)\n        block = [DDRB(48, s=6, d=[1,2,4,6,8], add=True) for _ in range(r)]\n        self.stage_3 = nn.Sequential(*block)\n\n        self.b3 = nn.BatchNorm2d(96, eps=1e-03)\n        self.a3 = nn.PReLU(96)\n\n        self.down_4 = nn.Conv2d(96, 96, 3, stride=2, padding=1, bias=False)\n        self.stage_4_0 = DPRB(96, add=True)\n        block = [DDRB(96, s=6, d=[1,2,4,6,8], add=True) for _ in range(t)]\n        self.stage_4 = nn.Sequential(*block)\n\n        self.b4 = nn.BatchNorm2d(192, eps=1e-03)\n        self.a4 = nn.PReLU(192)\n\n        # -----------------------------------------------------------------\n        # heatmap \n        # ---------------------\n\n        self.classifier = nn.Conv2d(192, 1, 1, stride=1, padding=0, bias=False)\n\n        # -----------------------------------------------------------------\n        # decoder \n        # ---------------------\n        self.bn_ = nn.BatchNorm2d(1, eps=1e-03)\n        self.relu_ = nn.ReLU()\n\n        self.stage3_down = nn.Conv2d(96, 1, kernel_size=1, stride=1, padding=0, bias=False)\n        self.conv_1 = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n        \n        self.stage2_down = nn.Conv2d(48, 1, kernel_size=1, stride=1, padding=0, bias=False)\n        self.conv_2 = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n\n        self.stage1_down = nn.Conv2d(24, 1, kernel_size=1, stride=1, padding=0, bias=False)\n        self.conv_3 = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n \n        # init weights\n        self._init_weight()\n\n    def _init_weight(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, input):\n\n        x = self.conv0(input)\n        x = self.a0(self.b0(x))\n        # ---------------\n        # pool\n        s1_pool = self.down_1(x)\n        s1_0 = self.stage_1_0(s1_pool)\n        s1 = self.stage_1(s1_0)\n        # concat\n        concat_1 = torch.cat((s1, s1_0), dim=1)\n        concat_1 = self.a1(self.b1(concat_1))\n        # ---------------\n        # pool\n        s2_pool = self.down_2(concat_1)\n        s2_0 = self.stage_2_0(s2_pool)\n        s2 = self.stage_2(s2_0)\n        # concat\n        concat_2 = torch.cat((s2, s2_0), dim=1)\n        concat_2 = self.a2(self.b2(concat_2))\n        # ---------------\n        # pool\n        s3_pool = self.down_3(concat_2)\n        s3_0 = self.stage_3_0(s3_pool)\n        s3 = self.stage_3(s3_0)\n        # concat\n        concat_3 = torch.cat((s3, s3_0), dim=1)\n        concat_3 = self.a3(self.b3(concat_3))\n        # ---------------\n        # pool\n        s4_pool = self.down_4(concat_3)\n        s4_0 = self.stage_4_0(s4_pool)\n        s4 = self.stage_4(s4_0)\n        # concat\n        concat_4 = torch.cat((s4, s4_0), dim=1)\n        concat_4 = self.a4(self.b4(concat_4))\n\n\n        heatmap = self.classifier(concat_4)\n\n        \n        # heatmap_1 = self.bn_(self.up1(heatmap))\n        heatmap_1 = F.upsample(heatmap, scale_factor=2, mode='bilinear', align_corners=True)  \n        s3_heatmap = self.bn_(self.stage3_down(concat_3))\n        heatmap_1 = heatmap_1 + s3_heatmap\n        heatmap_1 = self.conv_1(heatmap_1)\n\n        # heatmap_2 = self.bn_(self.up2(heatmap_1))\n        heatmap_2 = F.upsample(heatmap_1, scale_factor=2, mode='bilinear', align_corners=True)  \n        s2_heatmap = self.bn_(self.stage2_down(concat_2))\n        heatmap_2 = heatmap_2 + s2_heatmap\n        heatmap_2 = self.conv_2(heatmap_2)\n\n        # heatmap_3 = self.bn_(self.up3(heatmap_2))\n        heatmap_3 = F.upsample(heatmap_2, scale_factor=2, mode='bilinear', align_corners=True)  \n        s1_heatmap = self.bn_(self.stage1_down(concat_1))\n        heatmap_3 = heatmap_3 + s1_heatmap\n        heatmap_3 = self.conv_3(heatmap_3)\n\n        out = F.upsample(heatmap_3, scale_factor=2, mode='bilinear', align_corners=True)  \n        # out = self.up4(heatmap_3)\n        # return heatmap, heatmap_1, heatmap_2, heatmap_3, out\n        return out\n\n\n\n\n"""
models/mv2_dilate_unet.py,3,"b""'''\n\tmobilenetv2_dilate_unet\n\nAuthor: Zhengwei Li\nData: July 20 2018\n'''\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef conv_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU6(inplace=True)\n    )\n\n\nclass InvertedResidual(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio):\n        super(InvertedResidual, self).__init__()\n        self.stride = stride\n        assert stride in [1, 2]\n\n        self.use_res_connect = self.stride == 1 and inp == oup\n\n        self.conv = nn.Sequential(\n            # pw\n            nn.Conv2d(inp, inp * expand_ratio, 1, 1, 0, bias=False),\n            nn.BatchNorm2d(inp * expand_ratio),\n            nn.ReLU6(inplace=True),\n            # dw\n            nn.Conv2d(inp * expand_ratio, inp * expand_ratio, 3, stride, 1, groups=inp * expand_ratio, bias=False),\n            nn.BatchNorm2d(inp * expand_ratio),\n            nn.ReLU6(inplace=True),\n            # pw-linear\n            nn.Conv2d(inp * expand_ratio, oup, 1, 1, 0, bias=False),\n            nn.BatchNorm2d(oup),\n        )\n\n    def forward(self, x):\n        if self.use_res_connect:\n            return x + self.conv(x)\n        else:\n            return self.conv(x)\n\n#-------------------------------------------------------------------------------------------------\n# MobileNet_v2_os_32_MFo\n#--------------------\nclass MobileNet_v2_os_32_MFo(nn.Module):\n    def __init__(self, nInputChannels=3):\n        super(MobileNet_v2_os_32_MFo, self).__init__()\n        # 1/2\n        # 256 x 256\n        self.head_conv = conv_bn(nInputChannels, 32, 2)\n\n        # 1/2\n        # 256 x 256\n        self.block_1 = InvertedResidual(32, 16, 1, 1)\n        # 1/4 128 x 128\n        self.block_2 = nn.Sequential( \n            InvertedResidual(16, 24, 2, 6),\n            InvertedResidual(24, 24, 1, 6)\n            )\n        # 1/8 64 x 64\n        self.block_3 = nn.Sequential( \n            InvertedResidual(24, 32, 2, 6),\n            InvertedResidual(32, 32, 1, 6),\n            InvertedResidual(32, 32, 1, 6)\n            )\n        # 1/16 32 x 32\n        self.block_4 = nn.Sequential( \n            InvertedResidual(32, 64, 2, 6),\n            InvertedResidual(64, 64, 1, 6),\n            InvertedResidual(64, 64, 1, 6),\n            InvertedResidual(64, 64, 1, 6)            \n            )\n        # 1/16 32 x 32\n        self.block_5 = nn.Sequential( \n            InvertedResidual(64, 96, 1, 6),\n            InvertedResidual(96, 96, 1, 6),\n            InvertedResidual(96, 96, 1, 6)          \n            )\n        # 1/32 16 x 16\n        self.block_6 = nn.Sequential( \n            InvertedResidual(96, 160, 2, 6),\n            InvertedResidual(160, 160, 1, 6),\n            InvertedResidual(160, 160, 1, 6)          \n            )\n        # 1/32 16 x 16\n        self.block_7 = InvertedResidual(160, 320, 1, 6)\n\n\n    def forward(self, x):\n        x = self.head_conv(x)\n\n        x1 = self.block_1(x)\n        x2 = self.block_2(x1)\n        x3 = self.block_3(x2)\n        x4 = self.block_4(x3)\n        x4 = self.block_5(x4)\n        x5 = self.block_6(x4)\n        x5 = self.block_7(x5)\n\n        return x1, x2, x3, x4, x5\n\n\n\n# up amd concat and dilate\nclass UCD(nn.Module):\n    def __init__(self, inplanes, planes, dilation):\n        super(UCD, self).__init__()\n\n\n        self.up = nn.ConvTranspose2d(inplanes, planes, kernel_size=2, stride=2, padding=0)\n        self.aspp = nn.Sequential(nn.Conv2d(planes*2, planes*2, kernel_size=3,\n                                            stride=1, padding=dilation, dilation=dilation, bias=False),\n                    nn.BatchNorm2d(planes*2))\n\n    def forward(self, e, x):\n\n        x = self.up(x)\n        x = torch.cat((x, e), dim=1)\n        x = self.aspp(x)\n\n        return x\n\n#-------------------------------------------------------------------------------------------------\n# mv2_dilate_unet\n# feature exstractor : MobileNet_v2_os_32_MFo\n#-----------------------------------------\nclass MobileNet_v2_Dilate_Unet(nn.Module):\n    def __init__(self, nInputChannels=3, n_classes=1):\n\n        super(MobileNet_v2_Dilate_Unet, self).__init__()\n\n        # mobilenetv2 feature \n        self.mobilenet_features = MobileNet_v2_os_32_MFo(nInputChannels)\n\n        self.up_concat_dilate_1 = UCD(320, 96, dilation = 2)\n        self.up_concat_dilate_2 = UCD(192, 32, dilation = 6)\n        self.up_concat_dilate_3 = UCD(64, 24, dilation = 12)\n        self.up_concat_dilate_4 = UCD(48, 16, dilation = 18)\n\n        self.last_conv = nn.Sequential(nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n                                       nn.BatchNorm2d(32),\n                                       nn.Conv2d(32, n_classes, kernel_size=1, stride=1))\n        # init weights\n        self._init_weight()\n\n    def _init_weight(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n\n        # x1 - x4 : 1/8 64 x 64\n        e1, e2, e3, e4, feature_map = self.mobilenet_features(x)\n\n        feature_map = self.up_concat_dilate_1(e4, feature_map) \n        feature_map = self.up_concat_dilate_2(e3, feature_map) \n        feature_map = self.up_concat_dilate_3(e2, feature_map) \n        feature_map = self.up_concat_dilate_4(e1, feature_map) \n\n        heat_map = self.last_conv(feature_map) \n\n        heat_map = F.upsample(heat_map, scale_factor=2, mode='bilinear', align_corners=True)   \n\n\n        return heat_map\n"""
models/residualdense_bisenet.py,6,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef conv_bn(inp, oup, kernel_size=3, padding=1, stride=1):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, kernel_size, stride, padding, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.PReLU(oup)\n    )\n\nclass make_dense(nn.Module):\n    def __init__(self, nChannels, growthRate):\n        super(make_dense, self).__init__()\n\n        self.bn = nn.BatchNorm2d(nChannels)\n        self.act = nn.PReLU(nChannels)\n        self.conv = nn.Conv2d(nChannels, growthRate, kernel_size=3, padding=1, bias=False)\n        \n\n    def forward(self, input):\n        \n        x = self.bn(input)\n        x = self.act(x)\n        x = self.conv(x)\n\n        out = torch.cat((input, x), 1)\n        return out\n\nclass DenseBlock(nn.Module):\n    def __init__(self, nChannels, nDenselayer, growthRate):\n        super(DenseBlock, self).__init__()\n        nChannels_ = nChannels\n        modules = []\n        for i in range(nDenselayer):    \n            modules.append(make_dense(nChannels_, growthRate))\n            nChannels_ += growthRate \n        self.dense_layers = nn.Sequential(*modules)\n\n\n    def forward(self, x):\n        out = self.dense_layers(x)\n\n        return out\n\n# DenseResidualBlock\nclass DRB(nn.Module):\n    def __init__(self, nIn, s=4, add=True):\n\n        super(DRB, self).__init__()\n\n        n = int(nIn//s) \n\n        self.conv =  nn.Conv2d(nIn, n, 3, stride=1, padding=1, bias=False)\n\n        self.bn = nn.BatchNorm2d(n)\n        self.act = nn.PReLU(n)\n\n        self.dense_block = DenseBlock(n, nDenselayer=(s-1), growthRate=n)\n\n        self.add = add\n\n    def forward(self, input):\n\n        residual = input\n        # reduce\n        x = self.conv(input)\n        x = self.bn(x)\n        x = self.act(x)\n        x =self.dense_block(x)\n\n        if self.add:\n            out = x + residual\n        else:\n            out = x\n\n        return out\n\n# Attention Refinement Module (ARM)\nclass ARM(nn.Module):\n    def __init__(self, in_channels, kernel_size):\n        super(ARM, self).__init__()\n\n        self.global_pool = nn.AvgPool2d(kernel_size, stride=kernel_size)\n        self.conv_1x1 = nn.Conv2d(in_channels, in_channels, 1, stride=1, padding=0, bias=False)\n        # self.bn = nn.BatchNorm1d(in_channels)\n        self.sigmod = nn.Sigmoid()\n\n    def forward(self, input):\n        x = self.global_pool(input)\n\n        x = self.conv_1x1(x)\n        # x = self.bn(x)\n\n        x = self.sigmod(x)\n\n        out = torch.mul(input, x)\n        return out\n\n# Feature Fusion Module\nclass FFM(nn.Module):\n    def __init__(self, in_channels, kernel_size, alpha=3):\n        super(FFM, self).__init__()\n        inter_channels = in_channels // alpha\n        self.conv_bn_relu = conv_bn(in_channels, inter_channels, kernel_size=1, padding=0)\n\n        self.global_pool = nn.AvgPool2d(kernel_size, stride=kernel_size)\n        self.conv_1x1_1 = nn.Conv2d(inter_channels, inter_channels, 1, stride=1, padding=0, bias=False)\n        self.relu = nn.ReLU()\n        self.conv_1x1_2 = nn.Conv2d(inter_channels, inter_channels, 1, stride=1, padding=0, bias=False)\n        self.sigmod = nn.Sigmoid()\n\n        self.classifier = nn.Conv2d(inter_channels, 1, 1, stride=1, padding=0, bias=True)\n\n    def forward(self, input):\n\n        input = self.conv_bn_relu(input)\n\n        x = self.global_pool(input)\n\n        x = self.conv_1x1_1(x)\n        x = self.relu(x)\n        x = self.conv_1x1_2(x)\n        x = self.sigmod(x)\n\n        out = torch.mul(input, x)\n        out = input + out\n\n        out = self.classifier(out)\n        return out\n # -----------------------------------------------------------------------------------\n # RD_BiSeNet sparsity-regularization\n # -----------------------------------------------------------------------------------\nclass RD_BiSeNet(nn.Module):\n\n    def __init__(self, classes=1, cfg=None):\n\n        super(RD_BiSeNet, self).__init__()\n\n\n        # -----------------------------------------------------------------\n        # Spatial Path \n        # ---------------------\n        self.conv_bn_relu_1 = conv_bn(3, 8, stride=2)\n        self.conv_bn_relu_2 = conv_bn(8, 12, stride=2)\n        self.conv_bn_relu_3 = conv_bn(12, 16, stride=2)\n        # -----------------------------------------------------------------\n        # Context Path \n        # ---------------------\n        self.conv = conv_bn(3, 8, stride=2)\n        self.stage_0 = DRB(8, s=2, add=True)\n\n        self.down_1 = conv_bn(8, 12, stride=2) \n        self.stage_1 = DRB(12, s=3, add=True)\n\n        self.down_2 = conv_bn(12, 24, stride=2)        \n        self.stage_2 = nn.Sequential(DRB(24, s=6, add=True),\n                                     DRB(24, s=6, add=True))\n\n        self.down_3 = conv_bn(24, 48, stride=2)  \n        self.stage_3 = nn.Sequential(DRB(48, s=6, add=True),\n                                     DRB(48, s=6, add=True))\n\n        self.down_4 = conv_bn(48, 64, stride=2)  \n        self.stage_4 = nn.Sequential(DRB(64, s=8, add=True),\n                                     DRB(64, s=8, add=True))\n\n        # ARM\n        self.arm_16 = ARM(48, kernel_size=32)\n        self.arm_32 = ARM(64, kernel_size=16)\n\n        self.global_pool = nn.AvgPool2d(kernel_size=16, stride=16)\n        self.tail_up = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=True)\n\n        self.level_16_up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.level_32_up = nn.Sequential(nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True),\n                                         nn.Conv2d(64, 48, 1, stride=1, padding=0, bias=True))\n\n        # FFM\n        self.ffm = FFM(48+16, kernel_size=64, alpha=1)\n\n        self.up = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n\n        # init weights\n        self._init_weight()\n\n    def _init_weight(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, input):\n\n        # -----------------------------------------------\n        # Spatial Path \n        # ---------------------\n        spatial = self.conv_bn_relu_1(input)\n        spatial = self.conv_bn_relu_2(spatial)\n        spatial = self.conv_bn_relu_3(spatial)\n        # -----------------------------------------------\n        # Context Path \n        # ---------------------\n        x = self.conv(input)\n        s0 = self.stage_0(x)\n        # 1/4\n        s1_0 = self.down_1(s0)\n        s1 = self.stage_1(s1_0)\n        # 1/8\n        s2_0 = self.down_2(s1)\n        s2 = self.stage_2(s2_0)\n        # 1/16\n        s3_0 = self.down_3(s2)\n        s3 = self.stage_3(s3_0) \n        # 1/32\n        s4_0 = self.down_4(s3)\n        s4 = self.stage_4(s4_0) \n\n\n        level_global = self.global_pool(s4)\n        level_global = self.tail_up(level_global)\n\n\n        level_32 = self.arm_32(s4)\n        level_32 = level_32 + level_global\n        level_32 = self.level_32_up(level_32)\n\n        level_16 = self.arm_16(s3)\n        level_16 = self.level_16_up(level_16)\n\n        context = level_16+level_32\n\n        feature = torch.cat((spatial, context), 1)\n        \n        heatmap = self.ffm(feature)\n        out = self.up(heatmap)\n    \n        return out\n"""
models/shuffle_seg_skipnet.py,5,"b'\n\n\'\'\'\n\tShuffle_Seg_SkipNet\n\nAuthor: Zhengwei Li\nData: July 30 2018\n\'\'\'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom collections import OrderedDict\nfrom torch.nn import init\n\nfrom model.layers import *\n\ndef conv3x3(in_channels, out_channels, stride=1, \n            padding=1, bias=True, groups=1):    \n    """"""3x3 convolution with padding\n    """"""\n    return nn.Conv2d(\n        in_channels, \n        out_channels, \n        kernel_size=3, \n        stride=stride,\n        padding=padding,\n        bias=bias,\n        groups=groups)\n\n\ndef conv1x1(in_channels, out_channels, groups=1, bias=True):\n    """"""1x1 convolution with padding\n    - Normal pointwise convolution When groups == 1\n    - Grouped pointwise convolution when groups > 1\n    """"""\n    return nn.Conv2d(\n        in_channels, \n        out_channels, \n        kernel_size=1, \n        groups=groups,\n        stride=1,\n        bias=bias)\n\n\ndef channel_shuffle(x, groups):\n    batchsize, num_channels, height, width = x.data.size()\n\n    channels_per_group = num_channels // groups\n    \n    # reshape\n    x = x.view(batchsize, groups, \n        channels_per_group, height, width)\n\n    # transpose\n    # - contiguous() required if transpose() is used before view().\n    #   See https://github.com/pytorch/pytorch/issues/764\n    x = torch.transpose(x, 1, 2).contiguous()\n\n    # flatten\n    x = x.view(batchsize, -1, height, width)\n\n    return x\n\n\nclass ShuffleUnit(nn.Module):\n    def __init__(self, in_channels, out_channels, groups=3,\n                 grouped_conv=True, combine=\'add\'):\n        \n        super(ShuffleUnit, self).__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.grouped_conv = grouped_conv\n        self.combine = combine\n        self.groups = groups\n        self.bottleneck_channels = self.out_channels // 4\n\n        # define the type of ShuffleUnit\n        if self.combine == \'add\':\n            # ShuffleUnit Figure 2b\n            self.depthwise_stride = 1\n            self._combine_func = self._add\n        elif self.combine == \'concat\':\n            # ShuffleUnit Figure 2c\n            self.depthwise_stride = 2\n            self._combine_func = self._concat\n            \n            # ensure output of concat has the same channels as \n            # original output channels.\n            self.out_channels -= self.in_channels\n        else:\n            raise ValueError(""Cannot combine tensors with \\""{}\\"""" \\\n                             ""Only \\""add\\"" and \\""concat\\"" are"" \\\n                             ""supported"".format(self.combine))\n\n        # Use a 1x1 grouped or non-grouped convolution to reduce input channels\n        # to bottleneck channels, as in a ResNet bottleneck module.\n        # NOTE: Do not use group convolution for the first conv1x1 in Stage 2.\n        self.first_1x1_groups = self.groups if grouped_conv else 1\n\n        self.g_conv_1x1_compress = self._make_grouped_conv1x1(\n            self.in_channels,\n            self.bottleneck_channels,\n            self.first_1x1_groups,\n            batch_norm=True,\n            relu=True\n            )\n\n        # 3x3 depthwise convolution followed by batch normalization\n        self.depthwise_conv3x3 = conv3x3(\n            self.bottleneck_channels, self.bottleneck_channels,\n            stride=self.depthwise_stride, groups=self.bottleneck_channels)\n        self.bn_after_depthwise = nn.BatchNorm2d(self.bottleneck_channels)\n\n        # Use 1x1 grouped convolution to expand from \n        # bottleneck_channels to out_channels\n        self.g_conv_1x1_expand = self._make_grouped_conv1x1(\n            self.bottleneck_channels,\n            self.out_channels,\n            self.groups,\n            batch_norm=True,\n            relu=False\n            )\n\n\n    @staticmethod\n    def _add(x, out):\n        # residual connection\n        return x + out\n\n\n    @staticmethod\n    def _concat(x, out):\n        # concatenate along channel axis\n        return torch.cat((x, out), 1)\n\n\n    def _make_grouped_conv1x1(self, in_channels, out_channels, groups,\n        batch_norm=True, relu=False):\n\n        modules = OrderedDict()\n\n        conv = conv1x1(in_channels, out_channels, groups=groups)\n        modules[\'conv1x1\'] = conv\n\n        if batch_norm:\n            modules[\'batch_norm\'] = nn.BatchNorm2d(out_channels)\n        if relu:\n            modules[\'relu\'] = nn.ReLU()\n        if len(modules) > 1:\n            return nn.Sequential(modules)\n        else:\n            return conv\n\n\n    def forward(self, x):\n        # save for combining later with output\n        residual = x\n\n        if self.combine == \'concat\':\n            residual = F.avg_pool2d(residual, kernel_size=3, \n                stride=2, padding=1)\n\n        out = self.g_conv_1x1_compress(x)\n        out = channel_shuffle(out, self.groups)\n        out = self.depthwise_conv3x3(out)\n        out = self.bn_after_depthwise(out)\n        out = self.g_conv_1x1_expand(out)\n        \n        out = self._combine_func(residual, out)\n        return F.relu(out)\n\n\n\nclass ShuffleNet(nn.Module):\n    """"""ShuffleNet implementation.\n    """"""\n\n    def __init__(self, groups=3, in_channels=3):\n        """"""ShuffleNet constructor.\n\n        Arguments:\n            groups (int, optional): number of groups to be used in grouped \n                1x1 convolutions in each ShuffleUnit. Default is 3 for best\n                performance according to original paper.\n            in_channels (int, optional): number of channels in the input tensor.\n                Default is 3 for RGB image inputs.\n            num_classes (int, optional): number of classes to predict. Default\n                is 1000 for ImageNet.\n\n        """"""\n        super(ShuffleNet, self).__init__()\n\n        self.groups = groups\n        self.stage_repeats = [3, 7, 3]\n        self.in_channels =  in_channels\n\n        # index 0 is invalid and should never be called.\n        # only used for indexing convenience.\n        if groups == 1:\n            self.stage_out_channels = [-1, 24, 144, 288, 567]\n        elif groups == 2:\n            self.stage_out_channels = [-1, 24, 200, 400, 800]\n        elif groups == 3:\n            self.stage_out_channels = [-1, 24, 240, 480, 960]\n        elif groups == 4:\n            self.stage_out_channels = [-1, 24, 272, 544, 1088]\n        elif groups == 8:\n            self.stage_out_channels = [-1, 24, 384, 768, 1536]\n        else:\n            raise ValueError(\n                """"""{} groups is not supported for\n                   1x1 Grouped Convolutions"""""".format(num_groups))\n        \n        # Stage 1 always has 24 output channels\n        self.conv1 = conv3x3(self.in_channels,\n                             self.stage_out_channels[1], # stage 1\n                             stride=2)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Stage 2\n        self.stage2 = self._make_stage(2)\n        # Stage 3\n        self.stage3 = self._make_stage(3)\n        # Stage 4\n        self.stage4 = self._make_stage(4)\n\n    def _make_stage(self, stage):\n        modules = OrderedDict()\n        stage_name = ""ShuffleUnit_Stage{}"".format(stage)\n        \n        # First ShuffleUnit in the stage\n        # 1. non-grouped 1x1 convolution (i.e. pointwise convolution)\n        #   is used in Stage 2. Group convolutions used everywhere else.\n        grouped_conv = stage > 2\n        \n        # 2. concatenation unit is always used.\n        first_module = ShuffleUnit(\n            self.stage_out_channels[stage-1],\n            self.stage_out_channels[stage],\n            groups=self.groups,\n            grouped_conv=grouped_conv,\n            combine=\'concat\'\n            )\n        modules[stage_name+""_0""] = first_module\n\n        # add more ShuffleUnits depending on pre-defined number of repeats\n        for i in range(self.stage_repeats[stage-2]):\n            name = stage_name + ""_{}"".format(i+1)\n            module = ShuffleUnit(\n                self.stage_out_channels[stage],\n                self.stage_out_channels[stage],\n                groups=self.groups,\n                grouped_conv=True,\n                combine=\'add\'\n                )\n            modules[name] = module\n\n        return nn.Sequential(modules)\n\n\n    def forward(self, x):\n        s0 = self.conv1(x)\n        s1 = self.maxpool(s0)\n\n        s2 = self.stage2(s1)     \n        s3 = self.stage3(s2)\n        s4 = self.stage4(s3)\n\n\n        return s0, s1, s2, s3, s4\n\nclass Shuffle_Seg_SkipNet(nn.Module):\n\n    def __init__(self, groups=3, in_channels=3, n_classes=1):\n        """"""ShuffleNet constructor.\n        """"""\n        super(Shuffle_Seg_SkipNet, self).__init__()\n\n        self.encoder = ShuffleNet(groups=groups, in_channels=in_channels)\n\n        self.scorelayer = conv1x1(960, 1, bias=True)\n\n        self.bn_ = nn.BatchNorm2d(1)\n        self.up1 = BilinearConvTranspose2d(1, stride=2, groups=1)\n        self.stage3_down = conv1x1(480, 1, groups=1, bias=False)\n        self.up2 = BilinearConvTranspose2d(1, stride=2, groups=1)\n        self.stage2_down = conv1x1(240, 1, groups=1, bias=False)\n        self.up3 = BilinearConvTranspose2d(1, stride=2, groups=1)\n        self.stage1_down = conv1x1(24, 1, groups=1, bias=False)\n        self.up4 = BilinearConvTranspose2d(1, stride=2, groups=1)\n        self.stage0_down = conv1x1(24, 1, groups=1, bias=False)\n\n        self.deconv = BilinearConvTranspose2d(1, stride=2, groups=1)\n        \n\n        self.init_params()\n\n\n    def init_params(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode=\'fan_out\')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n\n    def _make_stage(self, stage):\n        modules = OrderedDict()\n        stage_name = ""ShuffleUnit_Stage{}"".format(stage)\n        \n        # First ShuffleUnit in the stage\n        # 1. non-grouped 1x1 convolution (i.e. pointwise convolution)\n        #   is used in Stage 2. Group convolutions used everywhere else.\n        grouped_conv = stage > 2\n        \n        # 2. concatenation unit is always used.\n        first_module = ShuffleUnit(\n            self.stage_out_channels[stage-1],\n            self.stage_out_channels[stage],\n            groups=self.groups,\n            grouped_conv=grouped_conv,\n            combine=\'concat\'\n            )\n        modules[stage_name+""_0""] = first_module\n\n        # add more ShuffleUnits depending on pre-defined number of repeats\n        for i in range(self.stage_repeats[stage-2]):\n            name = stage_name + ""_{}"".format(i+1)\n            module = ShuffleUnit(\n                self.stage_out_channels[stage],\n                self.stage_out_channels[stage],\n                groups=self.groups,\n                grouped_conv=True,\n                combine=\'add\'\n                )\n            modules[name] = module\n\n        return nn.Sequential(modules)\n\n\n    def forward(self, x):\n\n\n        s0, s1, s2, s3, s4 = self.encoder(x)\n\n        # to n_class heat_map\n        heat_map = self.bn_(self.scorelayer(s4))\n\n        heat_map = self.bn_(self.up1(heat_map))\n        s3_heat_map = self.bn_(self.stage3_down(s3))\n        heat_map = heat_map + s3_heat_map\n\n        heat_map = self.bn_(self.up2(heat_map))\n        s2_heat_map = self.bn_(self.stage2_down(s2))\n        heat_map = heat_map + s2_heat_map\n\n        heat_map = self.bn_(self.up3(heat_map))\n        s1_heat_map = self.bn_(self.stage1_down(s1))\n        heat_map = heat_map + s1_heat_map\n\n        heat_map = self.bn_(self.up4(heat_map))\n        s0_heat_map = self.bn_(self.stage0_down(s0))\n        heat_map = heat_map + s0_heat_map\n\n        heat_map = self.deconv(heat_map)\n\n        return heat_map\n'"
