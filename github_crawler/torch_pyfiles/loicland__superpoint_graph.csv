file_path,api_count,code
learning/__init__.py,0,"b'import os,sys\n\nDIR_PATH = os.path.dirname(os.path.realpath(__file__))\nsys.path.insert(0, DIR_PATH)'"
learning/custom_dataset.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Mar 20 16:16:14 2018\n\n@author: landrieuloic\n""""""""""""\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\n    http://arxiv.org/abs/1711.09869\n    2017 Loic Landrieu, Martin Simonovsky\n    Template file for processing custome datasets\n""""""\nfrom __future__ import division\nfrom __future__ import print_function\nfrom builtins import range\n\nimport random\nimport numpy as np\nimport os\nimport functools\nimport torch\nimport torchnet as tnt\nimport h5py\nimport spg\n\n\ndef get_datasets(args, test_seed_offset=0):\n    """"""build training and testing set""""""\n    \n    #for a simple train/test organization\n    trainset = [\'train/\' + f for f in os.listdir(args.CUSTOM_SET_PATH + \'/superpoint_graphs/train\')]\n    testset  = [\'test/\' + f for f in os.listdir(args.CUSTOM_SET_PATH + \'/superpoint_graphs/train\')]\n    \n    # Load superpoints graphs\n    testlist, trainlist = [], []\n    for n in trainset:\n        trainlist.append(spg.spg_reader(args, args.CUSTOM_SET_PATH + \'/superpoint_graphs/\' + n + \'.h5\', True))\n    for n in testset:\n        testlist.append(spg.spg_reader(args, args.CUSTOM_SET_PATH + \'/superpoint_graphs/\' + n + \'.h5\', True))\n\n    # Normalize edge features\n    if args.spg_attribs01:\n       trainlist, testlist, validlist, scaler = spg.scaler01(trainlist, testlist)\n\n    return tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in trainlist],\n                                    functools.partial(spg.loader, train=True, args=args, db_path=args.CUSTOM_SET_PATH)), \\\n           tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in testlist],\n                                    functools.partial(spg.loader, train=False, args=args, db_path=args.CUSTOM_SET_PATH, test_seed_offset=test_seed_offset)) ,\\\n            scaler\n\ndef get_info(args):\n    edge_feats = 0\n    for attrib in args.edge_attribs.split(\',\'):\n        a = attrib.split(\'/\')[0]\n        if a in [\'delta_avg\', \'delta_std\', \'xyz\']:\n            edge_feats += 3\n        else:\n            edge_feats += 1\n\n    return {\n        \'node_feats\': 11 if args.pc_attribs==\'\' else len(args.pc_attribs),\n        \'edge_feats\': edge_feats,\n        \'classes\': 10, #CHANGE TO YOUR NUMBER OF CLASS\n        \'inv_class_map\': {0:\'class_A\', 1:\'class_B\'}, #etc...\n    }\n\ndef preprocess_pointclouds(SEMA3D_PATH):\n    """""" Preprocesses data by splitting them by components and normalizing.""""""\n\n    for n in [\'train\', \'test_reduced\', \'test_full\']:\n        pathP = \'{}/parsed/{}/\'.format(SEMA3D_PATH, n)\n        pathD = \'{}/features/{}/\'.format(SEMA3D_PATH, n)\n        pathC = \'{}/superpoint_graphs/{}/\'.format(SEMA3D_PATH, n)\n        if not os.path.exists(pathP):\n            os.makedirs(pathP)\n        random.seed(0)\n\n        for file in os.listdir(pathC):\n            print(file)\n            if file.endswith("".h5""):\n                f = h5py.File(pathD + file, \'r\')\n                xyz = f[\'xyz\'][:]\n                rgb = f[\'rgb\'][:].astype(np.float)\n                elpsv = np.stack([ f[\'xyz\'][:,2][:], f[\'linearity\'][:], f[\'planarity\'][:], f[\'scattering\'][:], f[\'verticality\'][:] ], axis=1)\n\n                # rescale to [-0.5,0.5]; keep xyz\n                #warning - to use the trained model, make sure the elevation is comparable\n                #to the set they were trained on\n                #i.e. ~0 for roads and ~0.2-0.3 for builings for sema3d\n                # and -0.5 for floor and 0.5 for ceiling for s3dis\n                elpsv[:,0] /= 100 # (rough guess) #adapt \n                elpsv[:,1:] -= 0.5\n                rgb = rgb/255.0 - 0.5\n\n                P = np.concatenate([xyz, rgb, elpsv], axis=1)\n\n                f = h5py.File(pathC + file, \'r\')\n                numc = len(f[\'components\'].keys())\n\n                with h5py.File(pathP + file, \'w\') as hf:\n                    for c in range(numc):\n                        idx = f[\'components/{:d}\'.format(c)][:].flatten()\n                        if idx.size > 10000: # trim extra large segments, just for speed-up of loading time\n                            ii = random.sample(range(idx.size), k=10000)\n                            idx = idx[ii]\n\n                        hf.create_dataset(name=\'{:d}\'.format(c), data=P[idx,...])\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\n    parser.add_argument(\'--CUSTOM_SET_PATH\', default=\'datasets/custom_set\')\n    args = parser.parse_args()\n    preprocess_pointclouds(args.CUSTOM_SET_PATH)\n\n\n'"
learning/evaluate.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Jul  4 09:22:55 2019\n\n@author: landrieuloic\n""""""\n\n""""""\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\n    http://arxiv.org/abs/1711.09869\n    2017 Loic Landrieu, Martin Simonovsky\n""""""\nimport argparse\nimport numpy as np\nimport sys\nsys.path.append(""./learning"")\nfrom metrics import *\n\nparser = argparse.ArgumentParser(description=\'Evaluation function for S3DIS\')\n\nparser.add_argument(\'--odir\', default=\'./results/s3dis/best\', help=\'Directory to store results\')\nparser.add_argument(\'--dataset\', default=\'s3dis\', help=\'Directory to store results\')\nparser.add_argument(\'--cvfold\', default=\'123456\', help=\'which fold to consider\')\n\nargs = parser.parse_args()\n\n\n\nif args.dataset == \'s3dis\':\n    n_labels = 13\n    inv_class_map = {0:\'ceiling\', 1:\'floor\', 2:\'wall\', 3:\'column\', 4:\'beam\', 5:\'window\', 6:\'door\', 7:\'table\', 8:\'chair\', 9:\'bookcase\', 10:\'sofa\', 11:\'board\', 12:\'clutter\'}\n    base_name = args.odir+\'/cv\'\nelif args.dataset == \'vkitti\':\n    n_labels = 13\n    inv_class_map = {0:\'Terrain\', 1:\'Tree\', 2:\'Vegetation\', 3:\'Building\', 4:\'Road\', 5:\'GuardRail\', 6:\'TrafficSign\', 7:\'TrafficLight\', 8:\'Pole\', 9:\'Misc\', 10:\'Truck\', 11:\'Car\', 12:\'Van\'}\n    base_name = args.odir+\'/cv\'\n    \nC = ConfusionMatrix(n_labels)\nC.confusion_matrix=np.zeros((n_labels, n_labels))\n\n\nfor i_fold in range(len(args.cvfold)):\n    fold = int(args.cvfold[i_fold])\n    cm = ConfusionMatrix(n_labels)\n    cm.confusion_matrix=np.load(base_name+str(fold) +\'/pointwise_cm.npy\')\n    print(""Fold %d : \\t OA = %3.2f \\t mA = %3.2f \\t mIoU = %3.2f"" % (fold, \\\n        100 * ConfusionMatrix.get_overall_accuracy(cm) \\\n      , 100 * ConfusionMatrix.get_mean_class_accuracy(cm) \\\n      , 100 * ConfusionMatrix.get_average_intersection_union(cm)\n      ))\n    C.confusion_matrix += cm.confusion_matrix\n    \nprint(""\\nOverall accuracy : %3.2f %%"" % (100 * (ConfusionMatrix.get_overall_accuracy(C))))\nprint(""Mean accuracy    : %3.2f %%"" % (100 * (ConfusionMatrix.get_mean_class_accuracy(C))))\nprint(""Mean IoU         : %3.2f %%\\n"" % (100 * (ConfusionMatrix.get_average_intersection_union(C))))\nprint(""         Classe :   IoU"")\nfor c in range(0,n_labels):\n    print (""   %12s : %6.2f %% \\t %.1e points"" %(inv_class_map[c],100*ConfusionMatrix.get_intersection_union_per_class(C)[c], ConfusionMatrix.count_gt(C,c)))\n'"
learning/graphnet.py,2,"b'""""""\r\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\r\n    http://arxiv.org/abs/1711.09869\r\n    2017 Loic Landrieu, Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.init as init\r\nfrom learning import ecc\r\nfrom learning.modules import RNNGraphConvModule, ECC_CRFModule, GRUCellEx, LSTMCellEx\r\n\r\n\r\ndef create_fnet(widths, orthoinit, llbias, bnidx=-1):\r\n    """""" Creates feature-generating network, a multi-layer perceptron.\r\n    Parameters:\r\n    widths: list of widths of layers (including input and output widths)\r\n    orthoinit: whether to use orthogonal weight initialization\r\n    llbias: whether to use bias in the last layer\r\n    bnidx: index of batch normalization (-1 if not used)\r\n    """"""\r\n    fnet_modules = []\r\n    for k in range(len(widths)-2):\r\n        fnet_modules.append(nn.Linear(widths[k], widths[k+1]))\r\n        if orthoinit: init.orthogonal_(fnet_modules[-1].weight, gain=init.calculate_gain(\'relu\'))\r\n        if bnidx==k: fnet_modules.append(nn.BatchNorm1d(widths[k+1]))\r\n        fnet_modules.append(nn.ReLU(True))\r\n    fnet_modules.append(nn.Linear(widths[-2], widths[-1], bias=llbias))\r\n    if orthoinit: init.orthogonal_(fnet_modules[-1].weight)\r\n    if bnidx==len(widths)-1: fnet_modules.append(nn.BatchNorm1d(fnet_modules[-1].weight.size(0)))\r\n    return nn.Sequential(*fnet_modules)\r\n\r\n\r\nclass GraphNetwork(nn.Module):\r\n    """""" It is constructed in a flexible way based on `config` string, which contains sequence of comma-delimited layer definiton tokens layer_arg1_arg2_... See README.md for examples.\r\n    """"""\r\n    def __init__(self, config, nfeat, fnet_widths, fnet_orthoinit=True, fnet_llbias=True, fnet_bnidx=-1, edge_mem_limit=1e20, use_pyg = True, cuda = True):\r\n        super(GraphNetwork, self).__init__()\r\n        self.gconvs = []\r\n\r\n        for d, conf in enumerate(config.split(\',\')):\r\n            conf = conf.strip().split(\'_\')\r\n\r\n            if conf[0]==\'f\':    #Fully connected layer;  args: output_feats\r\n                self.add_module(str(d), nn.Linear(nfeat, int(conf[1])))\r\n                nfeat = int(conf[1])\r\n            elif conf[0]==\'b\':  #Batch norm;             args: not_affine\r\n                self.add_module(str(d), nn.BatchNorm1d(nfeat, eps=1e-5, affine=len(conf)==1))\r\n            elif conf[0]==\'r\':  #ReLU;\r\n                self.add_module(str(d), nn.ReLU(True))\r\n            elif conf[0]==\'d\':  #Dropout;                args: dropout_prob\r\n                self.add_module(str(d), nn.Dropout(p=float(conf[1]), inplace=False))\r\n\r\n            elif conf[0]==\'crf\': #ECC-CRF;               args: repeats\r\n                nrepeats = int(conf[1])\r\n\r\n                fnet = create_fnet(fnet_widths + [nfeat*nfeat], fnet_orthoinit, fnet_llbias, fnet_bnidx)\r\n                gconv = ecc.GraphConvModule(nfeat, nfeat, fnet, edge_mem_limit=edge_mem_limit)\r\n                crf = ECC_CRFModule(gconv, nrepeats)\r\n                self.add_module(str(d), crf)\r\n                self.gconvs.append(gconv)\r\n\r\n            elif conf[0]==\'gru\' or conf[0]==\'lstm\': #RNN-ECC     args: repeats, mv=False, layernorm=True, ingate=True, cat_all=True\r\n                nrepeats = int(conf[1])\r\n                vv = bool(int(conf[2])) if len(conf)>2 else True # whether ECC does matrix-value mult or element-wise mult\r\n                layernorm = bool(int(conf[3])) if len(conf)>3 else True\r\n                ingate = bool(int(conf[4])) if len(conf)>4 else True\r\n                cat_all = bool(int(conf[5])) if len(conf)>5 else True\r\n\r\n                fnet = create_fnet(fnet_widths + [nfeat**2 if not vv else nfeat], fnet_orthoinit, fnet_llbias, fnet_bnidx)\r\n                if conf[0]==\'gru\':\r\n                    cell = GRUCellEx(nfeat, nfeat, bias=True, layernorm=layernorm, ingate=ingate)\r\n                else:\r\n                    cell = LSTMCellEx(nfeat, nfeat, bias=True, layernorm=layernorm, ingate=ingate)\r\n                gconv = RNNGraphConvModule(cell, fnet, nfeat, vv = vv, nrepeats=nrepeats, cat_all=cat_all, edge_mem_limit=edge_mem_limit, use_pyg = use_pyg, cuda = cuda)\r\n                self.add_module(str(d), gconv)\r\n                self.gconvs.append(gconv)\r\n                if cat_all: nfeat *= nrepeats + 1\r\n\r\n            elif len(conf[0])>0:\r\n                raise NotImplementedError(\'Unknown module: \' + conf[0])\r\n\r\n\r\n    def set_info(self, gc_infos, cuda):\r\n        """""" Provides convolution modules with graph structure information for the current batch.\r\n        """"""\r\n        gc_infos = gc_infos if isinstance(gc_infos,(list,tuple)) else [gc_infos]\r\n        for i,gc in enumerate(self.gconvs):\r\n            if cuda: gc_infos[i].cuda()\r\n            gc.set_info(gc_infos[i])\r\n\r\n    def forward(self, input):\r\n        for module in self._modules.values():\r\n            input = module(input)\r\n        return input\r\n\r\n'"
learning/main.py,17,"b'""""""\r\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\r\n    http://arxiv.org/abs/1711.09869\r\n    2017 Loic Landrieu, Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport time\r\nimport random\r\nimport numpy as np\r\nimport json\r\nimport os\r\nimport sys\r\nimport math\r\nimport argparse\r\nimport ast\r\nfrom tqdm import tqdm\r\nimport logging\r\nfrom collections import defaultdict\r\nimport h5py\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\nfrom torch.optim.lr_scheduler import MultiStepLR\r\nfrom torch.autograd import Variable\r\nimport torchnet as tnt\r\n\r\nDIR_PATH = os.path.dirname(os.path.realpath(__file__))\r\nsys.path.insert(0, os.path.join(DIR_PATH,\'..\'))\r\n\r\nfrom learning import spg\r\nfrom learning import graphnet\r\nfrom learning import pointnet\r\nfrom learning import metrics\r\n\r\ndef main():\r\n    parser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\r\n\r\n    # Optimization arguments\r\n    parser.add_argument(\'--wd\', default=0, type=float, help=\'Weight decay\')\r\n    parser.add_argument(\'--lr\', default=1e-2, type=float, help=\'Initial learning rate\')\r\n    parser.add_argument(\'--lr_decay\', default=0.7, type=float, help=\'Multiplicative factor used on learning rate at `lr_steps`\')\r\n    parser.add_argument(\'--lr_steps\', default=\'[]\', help=\'List of epochs where the learning rate is decreased by `lr_decay`\')\r\n    parser.add_argument(\'--momentum\', default=0.9, type=float, help=\'Momentum\')\r\n    parser.add_argument(\'--epochs\', default=10, type=int, help=\'Number of epochs to train. If <=0, only testing will be done.\')\r\n    parser.add_argument(\'--batch_size\', default=2, type=int, help=\'Batch size\')\r\n    parser.add_argument(\'--optim\', default=\'adam\', help=\'Optimizer: sgd|adam\')\r\n    parser.add_argument(\'--grad_clip\', default=1, type=float, help=\'Element-wise clipping of gradient. If 0, does not clip\')\r\n    parser.add_argument(\'--loss_weights\', default=\'none\', help=\'[none, proportional, sqrt] how to weight the loss function\')\r\n\r\n    # Learning process arguments\r\n    parser.add_argument(\'--cuda\', default=1, type=int, help=\'Bool, use cuda\')\r\n    parser.add_argument(\'--nworkers\', default=0, type=int, help=\'Num subprocesses to use for data loading. 0 means that the data will be loaded in the main process\')\r\n    parser.add_argument(\'--test_nth_epoch\', default=1, type=int, help=\'Test each n-th epoch during training\')\r\n    parser.add_argument(\'--save_nth_epoch\', default=1, type=int, help=\'Save model each n-th epoch during training\')\r\n    parser.add_argument(\'--test_multisamp_n\', default=10, type=int, help=\'Average logits obtained over runs with different seeds\')\r\n\r\n    # Dataset\r\n    parser.add_argument(\'--dataset\', default=\'sema3d\', help=\'Dataset name: sema3d|s3dis\')\r\n    parser.add_argument(\'--cvfold\', default=0, type=int, help=\'Fold left-out for testing in leave-one-out setting (S3DIS)\')\r\n    parser.add_argument(\'--odir\', default=\'results\', help=\'Directory to store results\')\r\n    parser.add_argument(\'--resume\', default=\'\', help=\'Loads a previously saved model.\')\r\n    parser.add_argument(\'--db_train_name\', default=\'train\')\r\n    parser.add_argument(\'--db_test_name\', default=\'test\')\r\n    parser.add_argument(\'--use_val_set\', type=int, default=0)\r\n    parser.add_argument(\'--SEMA3D_PATH\', default=\'datasets/semantic3d\')\r\n    parser.add_argument(\'--S3DIS_PATH\', default=\'datasets/s3dis\')\r\n    parser.add_argument(\'--VKITTI_PATH\', default=\'datasets/vkitti\')\r\n    parser.add_argument(\'--CUSTOM_SET_PATH\', default=\'datasets/custom_set\')\r\n    parser.add_argument(\'--use_pyg\', default=0, type=int, help=\'Wether to use Pytorch Geometric for graph convolutions\')\r\n\r\n    # Model\r\n    parser.add_argument(\'--model_config\', default=\'gru_10,f_8\', help=\'Defines the model as a sequence of layers, see graphnet.py for definitions of respective layers and acceptable arguments. In short: rectype_repeats_mv_layernorm_ingate_concat, with rectype the type of recurrent unit [gru/crf/lstm], repeats the number of message passing iterations, mv (default True) the use of matrix-vector (mv) instead vector-vector (vv) edge filters, layernorm (default True) the use of layernorms in the recurrent units, ingate (default True) the use of input gating, concat (default True) the use of state concatenation\')\r\n    parser.add_argument(\'--seed\', default=1, type=int, help=\'Seed for random initialisation\')\r\n    parser.add_argument(\'--edge_attribs\', default=\'delta_avg,delta_std,nlength/ld,surface/ld,volume/ld,size/ld,xyz/d\', help=\'Edge attribute definition, see spg_edge_features() in spg.py for definitions.\')\r\n\r\n    # Point cloud processing\r\n    parser.add_argument(\'--pc_attribs\', default=\'xyzrgbelpsvXYZ\', help=\'Point attributes fed to PointNets, if empty then all possible. xyz = coordinates, rgb = color, e = elevation, lpsv = geometric feature, d = distance to center\')\r\n    parser.add_argument(\'--pc_augm_scale\', default=0, type=float, help=\'Training augmentation: Uniformly random scaling in [1/scale, scale]\')\r\n    parser.add_argument(\'--pc_augm_rot\', default=1, type=int, help=\'Training augmentation: Bool, random rotation around z-axis\')\r\n    parser.add_argument(\'--pc_augm_mirror_prob\', default=0, type=float, help=\'Training augmentation: Probability of mirroring about x or y axes\')\r\n    parser.add_argument(\'--pc_augm_jitter\', default=1, type=int, help=\'Training augmentation: Bool, Gaussian jittering of all attributes\')\r\n    parser.add_argument(\'--pc_xyznormalize\', default=1, type=int, help=\'Bool, normalize xyz into unit ball, i.e. in [-0.5,0.5]\')\r\n\r\n    # Filter generating network\r\n    parser.add_argument(\'--fnet_widths\', default=\'[32,128,64]\', help=\'List of width of hidden filter gen net layers (excluding the input and output ones, they are automatic)\')\r\n    parser.add_argument(\'--fnet_llbias\', default=0, type=int, help=\'Bool, use bias in the last layer in filter gen net\')\r\n    parser.add_argument(\'--fnet_orthoinit\', default=1, type=int, help=\'Bool, use orthogonal weight initialization for filter gen net.\')\r\n    parser.add_argument(\'--fnet_bnidx\', default=2, type=int, help=\'Layer index to insert batchnorm to. -1=do not insert.\')\r\n    parser.add_argument(\'--edge_mem_limit\', default=30000, type=int, help=\'Number of edges to process in parallel during computation, a low number can reduce memory peaks.\')\r\n\r\n    # Superpoint graph\r\n    parser.add_argument(\'--spg_attribs01\', default=1, type=int, help=\'Bool, normalize edge features to 0 mean 1 deviation\')\r\n    parser.add_argument(\'--spg_augm_nneigh\', default=100, type=int, help=\'Number of neighborhoods to sample in SPG\')\r\n    parser.add_argument(\'--spg_augm_order\', default=3, type=int, help=\'Order of neighborhoods to sample in SPG\')\r\n    parser.add_argument(\'--spg_augm_hardcutoff\', default=512, type=int, help=\'Maximum number of superpoints larger than args.ptn_minpts to sample in SPG\')\r\n    parser.add_argument(\'--spg_superedge_cutoff\', default=-1, type=float, help=\'Artificially constrained maximum length of superedge, -1=do not constrain\')\r\n\r\n    # Point net\r\n    parser.add_argument(\'--ptn_minpts\', default=40, type=int, help=\'Minimum number of points in a superpoint for computing its embedding.\')\r\n    parser.add_argument(\'--ptn_npts\', default=128, type=int, help=\'Number of input points for PointNet.\')\r\n    parser.add_argument(\'--ptn_widths\', default=\'[[64,64,128,128,256], [256,64,32]]\', help=\'PointNet widths\')\r\n    parser.add_argument(\'--ptn_widths_stn\', default=\'[[64,64,128], [128,64]]\', help=\'PointNet\\\'s Transformer widths\')\r\n    parser.add_argument(\'--ptn_nfeat_stn\', default=11, type=int, help=\'PointNet\\\'s Transformer number of input features\')\r\n    parser.add_argument(\'--ptn_prelast_do\', default=0, type=float)\r\n    parser.add_argument(\'--ptn_mem_monger\', default=1, type=int, help=\'Bool, save GPU memory by recomputing PointNets in back propagation.\')\r\n\r\n    # Decoder\r\n    parser.add_argument(\'--sp_decoder_config\', default=""[]"", type=str,\r\n                        help=\'Size of the decoder : sp_embedding -> sp_class. First layer of size sp_embed (* (1+n_ecc_iteration) if concatenation) and last layer is n_classes\')\r\n\r\n    args = parser.parse_args()\r\n    args.start_epoch = 0\r\n    args.lr_steps = ast.literal_eval(args.lr_steps)\r\n    args.fnet_widths = ast.literal_eval(args.fnet_widths)\r\n    args.ptn_widths = ast.literal_eval(args.ptn_widths)\r\n    args.sp_decoder_config = ast.literal_eval(args.sp_decoder_config)\r\n    args.ptn_widths_stn = ast.literal_eval(args.ptn_widths_stn)\r\n\r\n\r\n    print(\'Will save to \' + args.odir)\r\n    if not os.path.exists(args.odir):\r\n        os.makedirs(args.odir)\r\n    with open(os.path.join(args.odir, \'cmdline.txt\'), \'w\') as f:\r\n        f.write("" "".join([""\'""+a+""\'"" if (len(a)==0 or a[0]!=\'-\') else a for a in sys.argv]))\r\n\r\n    set_seed(args.seed, args.cuda)\r\n    logging.getLogger().setLevel(logging.INFO)  #set to logging.DEBUG to allow for more prints\r\n    if (args.dataset==\'sema3d\' and args.db_test_name.startswith(\'test\')) or (args.dataset.startswith(\'s3dis_02\') and args.cvfold==2):\r\n        # needed in pytorch 0.2 for super-large graphs with batchnorm in fnet  (https://github.com/pytorch/pytorch/pull/2919)\r\n        torch.backends.cudnn.enabled = False\r\n\r\n    if args.use_pyg:\r\n        torch.backends.cudnn.enabled = False\r\n\r\n    # Decide on the dataset\r\n    if args.dataset==\'sema3d\':\r\n        import sema3d_dataset\r\n        dbinfo = sema3d_dataset.get_info(args)\r\n        create_dataset = sema3d_dataset.get_datasets\r\n    elif args.dataset==\'s3dis\':\r\n        import s3dis_dataset\r\n        dbinfo = s3dis_dataset.get_info(args)\r\n        create_dataset = s3dis_dataset.get_datasets\r\n    elif args.dataset==\'vkitti\':\r\n        import vkitti_dataset\r\n        dbinfo = vkitti_dataset.get_info(args)\r\n        create_dataset = vkitti_dataset.get_datasets\r\n    elif args.dataset==\'custom_dataset\':\r\n        import custom_dataset #<- to write!\r\n        dbinfo = custom_dataset.get_info(args)\r\n        create_dataset = custom_dataset.get_datasets\r\n    else:\r\n        raise NotImplementedError(\'Unknown dataset \' + args.dataset)\r\n\r\n    # Create model and optimizer\r\n    if args.resume != \'\':\r\n        if args.resume==\'RESUME\': args.resume = args.odir + \'/model.pth.tar\'\r\n        model, optimizer, stats = resume(args, dbinfo)\r\n    else:\r\n        model = create_model(args, dbinfo)\r\n        optimizer = create_optimizer(args, model)\r\n        stats = []\r\n\r\n    train_dataset, test_dataset, valid_dataset, scaler = create_dataset(args)\r\n\r\n    print(\'Train dataset: %i elements - Test dataset: %i elements - Validation dataset: %i elements\' % (len(train_dataset),len(test_dataset),len(valid_dataset)))\r\n    ptnCloudEmbedder = pointnet.CloudEmbedder(args)\r\n    scheduler = MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_decay, last_epoch=args.start_epoch-1)\r\n\r\n\r\n    ############\r\n    def train():\r\n        """""" Trains for one epoch """"""\r\n        model.train()\r\n\r\n        loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=spg.eccpc_collate, num_workers=args.nworkers, shuffle=True, drop_last=True)\r\n        if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=65)\r\n\r\n        loss_meter = tnt.meter.AverageValueMeter()\r\n        acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\r\n        confusion_matrix = metrics.ConfusionMatrix(dbinfo[\'classes\'])\r\n        t0 = time.time()\r\n\r\n        # iterate over dataset in batches\r\n        for bidx, (targets, GIs, clouds_data) in enumerate(loader):\r\n            t_loader = 1000*(time.time()-t0)\r\n\r\n            model.ecc.set_info(GIs, args.cuda)\r\n            label_mode_cpu, label_vec_cpu, segm_size_cpu = targets[:,0], targets[:,2:], targets[:,1:].sum(1)\r\n            if args.cuda:\r\n                label_mode, label_vec, segm_size = label_mode_cpu.cuda(), label_vec_cpu.float().cuda(), segm_size_cpu.float().cuda()\r\n            else:\r\n                label_mode, label_vec, segm_size = label_mode_cpu, label_vec_cpu.float(), segm_size_cpu.float()\r\n\r\n            optimizer.zero_grad()\r\n            t0 = time.time()\r\n\r\n            embeddings = ptnCloudEmbedder.run(model, *clouds_data)\r\n            outputs = model.ecc(embeddings)\r\n            \r\n            loss = nn.functional.cross_entropy(outputs, Variable(label_mode), weight=dbinfo[""class_weights""])\r\n\r\n            loss.backward()\r\n            ptnCloudEmbedder.bw_hook()\r\n\r\n            if args.grad_clip>0:\r\n                for p in model.parameters():\r\n                    p.grad.data.clamp_(-args.grad_clip, args.grad_clip)\r\n            optimizer.step()\r\n\r\n            t_trainer = 1000*(time.time()-t0)\r\n            #loss_meter.add(loss.data[0]) # pytorch 0.3\r\n            loss_meter.add(loss.item()) # pytorch 0.4\r\n\r\n            o_cpu, t_cpu, tvec_cpu = filter_valid(outputs.data.cpu().numpy(), label_mode_cpu.numpy(), label_vec_cpu.numpy())\r\n            acc_meter.add(o_cpu, t_cpu)\r\n            confusion_matrix.count_predicted_batch(tvec_cpu, np.argmax(o_cpu,1))\r\n\r\n            logging.debug(\'Batch loss %f, Loader time %f ms, Trainer time %f ms.\', loss.data.item(), t_loader, t_trainer)\r\n            t0 = time.time()\r\n\r\n        return acc_meter.value()[0], loss_meter.value()[0], confusion_matrix.get_overall_accuracy(), confusion_matrix.get_average_intersection_union()\r\n\r\n    ############\r\n    def eval(is_valid = False):\r\n        """""" Evaluated model on test set """"""\r\n        model.eval()\r\n        \r\n        if is_valid: #validation\r\n            loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, collate_fn=spg.eccpc_collate, num_workers=args.nworkers)\r\n        else: #evaluation\r\n            loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, collate_fn=spg.eccpc_collate, num_workers=args.nworkers)\r\n            \r\n        if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=65)\r\n\r\n        acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\r\n        loss_meter = tnt.meter.AverageValueMeter()\r\n        confusion_matrix = metrics.ConfusionMatrix(dbinfo[\'classes\'])\r\n\r\n        # iterate over dataset in batches\r\n        for bidx, (targets, GIs, clouds_data) in enumerate(loader):\r\n            model.ecc.set_info(GIs, args.cuda)\r\n            label_mode_cpu, label_vec_cpu, segm_size_cpu = targets[:,0], targets[:,2:], targets[:,1:].sum(1).float()\r\n            if args.cuda:\r\n                label_mode, label_vec, segm_size = label_mode_cpu.cuda(), label_vec_cpu.float().cuda(), segm_size_cpu.float().cuda()\r\n            else:\r\n                label_mode, label_vec, segm_size = label_mode_cpu, label_vec_cpu.float(), segm_size_cpu.float()\r\n\r\n            embeddings = ptnCloudEmbedder.run(model, *clouds_data)\r\n            outputs = model.ecc(embeddings)\r\n            \r\n            loss = nn.functional.cross_entropy(outputs, Variable(label_mode), weight=dbinfo[""class_weights""])\r\n            loss_meter.add(loss.item()) \r\n\r\n            o_cpu, t_cpu, tvec_cpu = filter_valid(outputs.data.cpu().numpy(), label_mode_cpu.numpy(), label_vec_cpu.numpy())\r\n            if t_cpu.size > 0:\r\n                acc_meter.add(o_cpu, t_cpu)\r\n                confusion_matrix.count_predicted_batch(tvec_cpu, np.argmax(o_cpu,1))\r\n\r\n        return meter_value(acc_meter), loss_meter.value()[0], confusion_matrix.get_overall_accuracy(), confusion_matrix.get_average_intersection_union(), confusion_matrix.get_mean_class_accuracy()\r\n\r\n    ############\r\n    def eval_final():\r\n        """""" Evaluated model on test set in an extended way: computes estimates over multiple samples of point clouds and stores predictions """"""\r\n        model.eval()\r\n\r\n        acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\r\n        confusion_matrix = metrics.ConfusionMatrix(dbinfo[\'classes\'])\r\n        collected, predictions = defaultdict(list), {}\r\n\r\n        # collect predictions over multiple sampling seeds\r\n        for ss in range(args.test_multisamp_n):\r\n            test_dataset_ss = create_dataset(args, ss)[1]\r\n            loader = torch.utils.data.DataLoader(test_dataset_ss, batch_size=1, collate_fn=spg.eccpc_collate, num_workers=args.nworkers)\r\n            if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=65)\r\n\r\n            # iterate over dataset in batches\r\n            for bidx, (targets, GIs, clouds_data) in enumerate(loader):\r\n                model.ecc.set_info(GIs, args.cuda)\r\n                label_mode_cpu, label_vec_cpu, segm_size_cpu = targets[:,0], targets[:,2:], targets[:,1:].sum(1).float()\r\n\r\n                embeddings = ptnCloudEmbedder.run(model, *clouds_data)\r\n                outputs = model.ecc(embeddings)\r\n\r\n                fname = clouds_data[0][0][:clouds_data[0][0].rfind(\'.\')]\r\n                collected[fname].append((outputs.data.cpu().numpy(), label_mode_cpu.numpy(), label_vec_cpu.numpy()))\r\n\r\n        # aggregate predictions (mean)\r\n        for fname, lst in collected.items():\r\n            o_cpu, t_cpu, tvec_cpu = list(zip(*lst))\r\n            if args.test_multisamp_n > 1:\r\n                o_cpu = np.mean(np.stack(o_cpu,0),0)\r\n            else:\r\n                o_cpu = o_cpu[0]\r\n            t_cpu, tvec_cpu = t_cpu[0], tvec_cpu[0]\r\n            predictions[fname] = np.argmax(o_cpu,1)\r\n            o_cpu, t_cpu, tvec_cpu = filter_valid(o_cpu, t_cpu, tvec_cpu)\r\n            if t_cpu.size > 0:\r\n                acc_meter.add(o_cpu, t_cpu)\r\n                confusion_matrix.count_predicted_batch(tvec_cpu, np.argmax(o_cpu,1))\r\n\r\n        per_class_iou = {}\r\n        perclsiou = confusion_matrix.get_intersection_union_per_class()\r\n        for c, name in dbinfo[\'inv_class_map\'].items():\r\n            per_class_iou[name] = perclsiou[c]\r\n\r\n        return meter_value(acc_meter), confusion_matrix.get_overall_accuracy(), confusion_matrix.get_average_intersection_union(), per_class_iou, predictions,  confusion_matrix.get_mean_class_accuracy(), confusion_matrix.confusion_matrix\r\n\r\n    ############\r\n    # Training loop\r\n    try:\r\n        best_iou = stats[-1][\'best_iou\']\r\n    except:\r\n        best_iou = 0\r\n    TRAIN_COLOR = \'\\033[0m\'\r\n    VAL_COLOR = \'\\033[0;94m\' \r\n    TEST_COLOR = \'\\033[0;93m\'\r\n    BEST_COLOR = \'\\033[0;92m\'\r\n    epoch = args.start_epoch\r\n    \r\n    for epoch in range(args.start_epoch, args.epochs):\r\n        print(\'Epoch {}/{} ({}):\'.format(epoch, args.epochs, args.odir))\r\n        scheduler.step()\r\n\r\n        acc, loss, oacc, avg_iou = train()\r\n\r\n        print(TRAIN_COLOR + \'-> Train Loss: %1.4f   Train accuracy: %3.2f%%\' % (loss, acc))\r\n\r\n        new_best_model = False\r\n        if args.use_val_set:\r\n            acc_val, loss_val, oacc_val, avg_iou_val, avg_acc_val = eval(True)\r\n            print(VAL_COLOR + \'-> Val Loss: %1.4f  Val accuracy: %3.2f%%  Val oAcc: %3.2f%%  Val IoU: %3.2f%%  best ioU: %3.2f%%\' % \\\r\n                 (loss_val, acc_val, 100*oacc_val, 100*avg_iou_val,100*max(best_iou,avg_iou_val)) + TRAIN_COLOR)\r\n            if avg_iou_val>best_iou: #best score yet on the validation set\r\n                print(BEST_COLOR + \'-> New best model achieved!\' + TRAIN_COLOR)\r\n                best_iou = avg_iou_val\r\n                new_best_model = True\r\n                torch.save({\'epoch\': epoch + 1, \'args\': args, \'state_dict\': model.state_dict(), \'optimizer\' : optimizer.state_dict(), \'scaler\': scaler},\r\n                       os.path.join(args.odir, \'model.pth.tar\'))\r\n        elif epoch % args.save_nth_epoch == 0 or epoch==args.epochs-1:\r\n                torch.save({\'epoch\': epoch + 1, \'args\': args, \'state_dict\': model.state_dict(), \'optimizer\' : optimizer.state_dict(), \'scaler\': scaler},\r\n                       os.path.join(args.odir, \'model.pth.tar\'))\r\n        #test every test_nth_epochs\r\n        #or test after each enw model (but skip the first 5 for efficiency)\r\n        if (not(args.use_val_set) and (epoch+1) % args.test_nth_epoch == 0)  \\\r\n           or (args.use_val_set and new_best_model and epoch > 5): \r\n            acc_test, loss_test, oacc_test, avg_iou_test, avg_acc_test = eval(False)\r\n            print(TEST_COLOR + \'-> Test Loss: %1.4f  Test accuracy: %3.2f%%  Test oAcc: %3.2f%%  Test avgIoU: %3.2f%%\' % \\\r\n                 (loss_test, acc_test, 100*oacc_test, 100*avg_iou_test) + TRAIN_COLOR)\r\n        else:\r\n            acc_test, loss_test, oacc_test, avg_iou_test, avg_acc_test = 0, 0, 0, 0, 0\r\n\r\n        stats.append({\'epoch\': epoch, \'acc\': acc, \'loss\': loss, \'oacc\': oacc, \'avg_iou\': avg_iou, \'acc_test\': acc_test, \'oacc_test\': oacc_test, \'avg_iou_test\': avg_iou_test, \'avg_acc_test\': avg_acc_test, \'best_iou\' : best_iou})\r\n\r\n        """"""\r\n        if epoch % args.save_nth_epoch == 0 or epoch==args.epochs-1:\r\n            with open(os.path.join(args.odir, \'trainlog.json\'), \'w\') as outfile:\r\n                json.dump(stats, outfile,indent=4)\r\n            torch.save({\'epoch\': epoch + 1, \'args\': args, \'state_dict\': model.state_dict(), \'optimizer\' : optimizer.state_dict(), \'scaler\': scaler},\r\n                       os.path.join(args.odir, \'model.pth.tar\'))\r\n        """"""\r\n        \r\n        if math.isnan(loss): break\r\n    \r\n        if len(stats)>0:\r\n            with open(os.path.join(args.odir, \'trainlog.json\'), \'w\') as outfile:\r\n                json.dump(stats, outfile, indent=4)\r\n\r\n    if args.use_val_set :\r\n        args.resume = args.odir + \'/model.pth.tar\'\r\n        model, optimizer, stats = resume(args, dbinfo)\r\n        torch.save({\'epoch\': epoch + 1, \'args\': args, \'state_dict\': model.state_dict(), \'optimizer\' : optimizer.state_dict()},\r\n                       os.path.join(args.odir, \'model.pth.tar\'))\r\n    \r\n    # Final evaluation\r\n    if args.test_multisamp_n>0 and \'test\' in args.db_test_name:\r\n        acc_test, oacc_test, avg_iou_test, per_class_iou_test, predictions_test, avg_acc_test, confusion_matrix = eval_final()\r\n        print(\'-> Multisample {}: Test accuracy: {}, \\tTest oAcc: {}, \\tTest avgIoU: {}, \\tTest mAcc: {}\'.format(args.test_multisamp_n, acc_test, oacc_test, avg_iou_test, avg_acc_test))\r\n        with h5py.File(os.path.join(args.odir, \'predictions_\'+args.db_test_name+\'.h5\'), \'w\') as hf:\r\n            for fname, o_cpu in predictions_test.items():\r\n                hf.create_dataset(name=fname, data=o_cpu) #(0-based classes)\r\n        with open(os.path.join(args.odir, \'scores_\'+args.db_test_name+\'.json\'), \'w\') as outfile:\r\n            json.dump([{\'epoch\': args.start_epoch, \'acc_test\': acc_test, \'oacc_test\': oacc_test, \'avg_iou_test\': avg_iou_test, \'per_class_iou_test\': per_class_iou_test, \'avg_acc_test\': avg_acc_test}], outfile)\r\n        np.save(os.path.join(args.odir, \'pointwise_cm.npy\'), confusion_matrix)\r\n\r\ndef resume(args, dbinfo):\r\n    """""" Loads model and optimizer state from a previous checkpoint. """"""\r\n    print(""=> loading checkpoint \'{}\'"".format(args.resume))\r\n    checkpoint = torch.load(args.resume)\r\n    \r\n    checkpoint[\'args\'].model_config = args.model_config #to ensure compatibility with previous arguments convention\r\n    #this should be removed once new models are uploaded\r\n    \r\n    model = create_model(checkpoint[\'args\'], dbinfo) #use original arguments, architecture can\'t change\r\n    optimizer = create_optimizer(args, model)\r\n    \r\n    #model.load_state_dict(checkpoint[\'state_dict\'])\r\n    #to ensure compatbility of previous trained models with new InstanceNormD behavior comment line below and uncomment line above if not using our trained  models\r\n    model.load_state_dict({k:checkpoint[\'state_dict\'][k] for k in checkpoint[\'state_dict\'] if k not in [\'ecc.0._cell.inh.running_mean\',\'ecc.0._cell.inh.running_var\',\'ecc.0._cell.ini.running_mean\',\'ecc.0._cell.ini.running_var\']})\r\n\r\n    if \'optimizer\' in checkpoint: optimizer.load_state_dict(checkpoint[\'optimizer\'])\r\n    for group in optimizer.param_groups: group[\'initial_lr\'] = args.lr\r\n    args.start_epoch = checkpoint[\'epoch\']\r\n    try:\r\n        stats = json.loads(open(os.path.join(os.path.dirname(args.resume), \'trainlog.json\')).read())\r\n    except:\r\n        stats = []\r\n    return model, optimizer, stats\r\n    \r\ndef create_model(args, dbinfo):\r\n    """""" Creates model """"""\r\n\r\n    if not \'use_pyg\' in args:\r\n        args.use_pyg = 0\r\n\r\n    model = nn.Module()\r\n\r\n    nfeat = args.ptn_widths[1][-1]\r\n    model.ecc = graphnet.GraphNetwork(args.model_config, nfeat, [dbinfo[\'edge_feats\']] + args.fnet_widths, args.fnet_orthoinit, args.fnet_llbias,args.fnet_bnidx, args.edge_mem_limit, use_pyg = args.use_pyg, cuda = args.cuda)\r\n\r\n    model.ptn = pointnet.PointNet(args.ptn_widths[0], args.ptn_widths[1], args.ptn_widths_stn[0], args.ptn_widths_stn[1], dbinfo[\'node_feats\'], args.ptn_nfeat_stn, prelast_do=args.ptn_prelast_do)\r\n\r\n    print(\'Total number of parameters: {}\'.format(sum([p.numel() for p in model.parameters()])))\r\n    print(model)    \r\n    if args.cuda: \r\n        model.cuda()\r\n    return model \r\n\r\ndef create_optimizer(args, model):\r\n    if args.optim==\'sgd\':\r\n        return optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.wd)\r\n    elif args.optim==\'adam\':\r\n        return optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\r\n\r\ndef set_seed(seed, cuda=True):\r\n    """""" Sets seeds in all frameworks""""""\r\n    random.seed(seed)\r\n    np.random.seed(seed)\r\n    torch.manual_seed(seed)\r\n    if cuda: \r\n        torch.cuda.manual_seed(seed)    \r\n\r\ndef filter_valid(output, target, other=None):\r\n    """""" Removes predictions for nodes without ground truth """"""\r\n    idx = target!=-100\r\n    if other is not None:\r\n        return output[idx,:], target[idx], other[idx,...]\r\n    return output[idx,:], target[idx]\r\n    \r\ndef meter_value(meter):   \r\n    return meter.value()[0] if meter.n>0 else 0\r\n\r\n\r\nif __name__ == ""__main__"": \r\n    main()\r\n'"
learning/metrics.py,0,"b'from __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport numpy as np\r\n\r\n# extended official code from http://www.semantic3d.net/scripts/metric.py\r\nclass ConfusionMatrix:\r\n  """"""Streaming interface to allow for any source of predictions. Initialize it, count predictions one by one, then print confusion matrix and intersection-union score""""""\r\n  def __init__(self, number_of_labels = 2):\r\n    self.number_of_labels = number_of_labels\r\n    self.confusion_matrix = np.zeros(shape=(self.number_of_labels,self.number_of_labels))\r\n  def count_predicted(self, ground_truth, predicted, number_of_added_elements=1):\r\n    self.confusion_matrix[ground_truth][predicted] += number_of_added_elements\r\n\r\n  def count_predicted_batch(self, ground_truth_vec, predicted): # added\r\n    for i in range(ground_truth_vec.shape[0]):\r\n      self.confusion_matrix[:,predicted[i]] += ground_truth_vec[i,:]\r\n     \r\n  def count_predicted_batch_hard(self, ground_truth_vec, predicted): # added\r\n    for i in range(ground_truth_vec.shape[0]):\r\n      self.confusion_matrix[ground_truth_vec[i],predicted[i]] += 1\r\n\r\n  """"""labels are integers from 0 to number_of_labels-1""""""\r\n  def get_count(self, ground_truth, predicted):\r\n    return self.confusion_matrix[ground_truth][predicted]\r\n  """"""returns list of lists of integers; use it as result[ground_truth][predicted]\r\n     to know how many samples of class ground_truth were reported as class predicted""""""\r\n  def get_confusion_matrix(self):\r\n    return self.confusion_matrix\r\n  """"""returns list of 64-bit floats""""""\r\n  def get_intersection_union_per_class(self):\r\n    matrix_diagonal = [self.confusion_matrix[i][i] for i in range(self.number_of_labels)]\r\n    errors_summed_by_row = [0] * self.number_of_labels\r\n    for row in range(self.number_of_labels):\r\n      for column in range(self.number_of_labels):\r\n        if row != column:\r\n          errors_summed_by_row[row] += self.confusion_matrix[row][column]\r\n    errors_summed_by_column = [0] * self.number_of_labels\r\n    for column in range(self.number_of_labels):\r\n      for row in range(self.number_of_labels):\r\n        if row != column:\r\n          errors_summed_by_column[column] += self.confusion_matrix[row][column]\r\n\r\n    divisor = [0] * self.number_of_labels\r\n    for i in range(self.number_of_labels):\r\n      divisor[i] = matrix_diagonal[i] + errors_summed_by_row[i] + errors_summed_by_column[i]\r\n      if matrix_diagonal[i] == 0:\r\n        divisor[i] = 1\r\n\r\n    return [float(matrix_diagonal[i]) / divisor[i] for i in range(self.number_of_labels)]\r\n  """"""returns 64-bit float""""""\r\n\r\n  def get_overall_accuracy(self):\r\n    matrix_diagonal = 0\r\n    all_values = 0\r\n    for row in range(self.number_of_labels):\r\n      for column in range(self.number_of_labels):\r\n        all_values += self.confusion_matrix[row][column]\r\n        if row == column:\r\n          matrix_diagonal += self.confusion_matrix[row][column]\r\n    if all_values == 0:\r\n      all_values = 1\r\n    return float(matrix_diagonal) / all_values\r\n\r\n\r\n  def get_average_intersection_union(self):\r\n    values = self.get_intersection_union_per_class()\r\n    class_seen = ((self.confusion_matrix.sum(1)+self.confusion_matrix.sum(0))!=0).sum()\r\n    return sum(values) / class_seen\r\n\r\n  def get_mean_class_accuracy(self):  # added\r\n    re = 0\r\n    for i in range(self.number_of_labels):\r\n        re = re + self.confusion_matrix[i][i] / max(1,np.sum(self.confusion_matrix[i,:]))\r\n    return re/self.number_of_labels\r\n\r\n  def count_gt(self, ground_truth):\r\n      return self.confusion_matrix[ground_truth,:].sum()\r\n\r\ndef compute_predicted_transitions(in_component, edg_source, edg_target):\r\n \r\n  pred_transitions = in_component[edg_source] != in_component[edg_target]\r\n  return pred_transitions\r\n\r\n#-----------------------------------------------------------\r\ndef compute_boundary_recall(is_transition, pred_transitions):\r\n  return 100*((is_transition==pred_transitions)*is_transition).sum()/is_transition.sum()\r\n\r\n#-----------------------------------------------------------\r\ndef compute_boundary_precision(is_transition, pred_transitions):\r\n  return 100*((is_transition==pred_transitions)*pred_transitions).sum()/pred_transitions.sum()\r\n#--------------------------------------------\r\n\r\ndef mode(array, only_freq=False):\r\n  value, counts = np.unique(array, return_counts=True)\r\n  if only_freq:\r\n     return np.amax(counts)\r\n  else:\r\n     return value[np.argmax(counts)], np.amax(counts)\r\n#------------------------------------------------\r\ndef compute_OOA(components, labels):\r\n  hard_labels = labels.argmax(1)\r\n  correct_labels=0\r\n  for comp in components:\r\n      dump, freq = mode(hard_labels[comp])\r\n      correct_labels+=freq\r\n  return 100*correct_labels/len(labels)\r\n'"
learning/modules.py,26,"b'""""""\r\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\r\n    http://arxiv.org/abs/1711.09869\r\n    2017 Loic Landrieu, Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as nnf\r\nfrom torch.autograd import Variable\r\nfrom learning import ecc\r\n\r\nHAS_PYG = False\r\ntry:\r\n    from torch_geometric.nn.conv import MessagePassing\r\n    from torch_geometric.nn.inits import uniform\r\n    HAS_PYG = True\r\nexcept:\r\n    pass\r\n\r\nif HAS_PYG:\r\n    class NNConv(MessagePassing):\r\n        r""""""The continuous kernel-based convolutional operator from the\r\n        `""Neural Message Passing for Quantum Chemistry""\r\n        <https://arxiv.org/abs/1704.01212>`_ paper.\r\n        This convolution is also known as the edge-conditioned convolution from the\r\n        `""Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on\r\n        Graphs"" <https://arxiv.org/abs/1704.02901>`_ paper (see\r\n        :class:`torch_geometric.nn.conv.ECConv` for an alias):\r\n\r\n        .. math::\r\n            \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta} \\mathbf{x}_i +\r\n            \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{x}_j \\cdot\r\n            h_{\\mathbf{\\Theta}}(\\mathbf{e}_{i,j}),\r\n\r\n        where :math:`h_{\\mathbf{\\Theta}}` denotes a neural network, *.i.e.*\r\n        a MLP.\r\n\r\n        Args:\r\n            in_channels (int): Size of each input sample.\r\n            out_channels (int): Size of each output sample.\r\n            nn (torch.nn.Module): A neural network :math:`h_{\\mathbf{\\Theta}}` that\r\n                maps edge features :obj:`edge_attr` of shape :obj:`[-1,\r\n                num_edge_features]` to shape\r\n                    :obj:`[-1, in_channels * out_channels]`, *e.g.*, defined by\r\n                    :class:`torch.nn.Sequential`.\r\n                aggr (string, optional): The aggregation scheme to use\r\n                    (:obj:`""add""`, :obj:`""mean""`, :obj:`""max""`).\r\n                    (default: :obj:`""add""`)\r\n                root_weight (bool, optional): If set to :obj:`False`, the layer will\r\n                    not add the transformed root node features to the output.\r\n                    (default: :obj:`True`)\r\n                bias (bool, optional): If set to :obj:`False`, the layer will not learn\r\n                    an additive bias. (default: :obj:`True`)\r\n                **kwargs (optional): Additional arguments of\r\n                    :class:`torch_geometric.nn.conv.MessagePassing`.\r\n            """"""\r\n        def __init__(self,\r\n                    in_channels,\r\n                    out_channels,\r\n                    aggr=\'mean\',\r\n                    root_weight=False,\r\n                    bias=False,\r\n                    vv=True,\r\n                    flow=""target_to_source"",\r\n                    negative_slope=0.2,\r\n                    softmax=False,\r\n                    **kwargs):\r\n            super(NNConv, self).__init__(aggr=aggr, **kwargs)\r\n\r\n            self.in_channels = in_channels\r\n            self.out_channels = out_channels\r\n            self.aggr = aggr\r\n            self.vv = vv\r\n            self.negative_slope = negative_slope\r\n            self.softmax = softmax\r\n\r\n            if root_weight:\r\n                self.root = Parameter(torch.Tensor(in_channels, out_channels))\r\n            else:\r\n                self.register_parameter(\'root\', None)\r\n\r\n            if bias:\r\n                self.bias = Parameter(torch.Tensor(out_channels))\r\n            else:\r\n                self.register_parameter(\'bias\', None)\r\n\r\n            self.reset_parameters()\r\n\r\n        def reset_parameters(self):\r\n            uniform(self.in_channels, self.root)\r\n            uniform(self.in_channels, self.bias)\r\n\r\n        def forward(self, x, edge_index, weights):\r\n            """"""""""""\r\n            x = x.unsqueeze(-1) if x.dim() == 1 else x\r\n            return self.propagate(edge_index, x=x, weights=weights)\r\n\r\n        def message(self, edge_index_i, x_j, size_i, weights):\r\n            if not self.vv:\r\n                weight = weights.view(-1, self.in_channels, self.out_channels)\r\n                if self.softmax: # APPLY A TWO DIMENSIONAL NON-DEPENDENT SPARSE SOFTMAX\r\n                    weight = F.leaky_relu(weight, self.negative_slope)\r\n                    weight = torch.cat([softmax(weight[:, k, :], edge_index_i, size_i).unsqueeze(1) for k in range(self.out_channels)], dim=1)\r\n                return torch.matmul(x_j.unsqueeze(1), weight).squeeze(1)\r\n            else:\r\n                weight = weights.view(-1, self.in_channels)\r\n                if self.softmax:\r\n                    weight = F.leaky_relu(weight, self.negative_slope)\r\n                    weight = torch.cat([softmax(w.unsqueeze(-1), edge_index_i, size_i).t() for w in weight.t()], dim=0).t()\r\n                return x_j *  weight\r\n\r\n        def update(self, aggr_out, x):\r\n            if self.root is not None:\r\n                aggr_out = aggr_out + torch.mm(x, self.root)\r\n            if self.bias is not None:\r\n                aggr_out = aggr_out + self.bias\r\n            return aggr_out\r\n\r\n        def __repr__(self):\r\n            return \'{}({}, {})\'.format(self.__class__.__name__, self.in_channels,\r\n                                        self.out_channels)\r\n\r\n\r\nclass RNNGraphConvModule(nn.Module):\r\n    """"""\r\n    Computes recurrent graph convolution using filter weights obtained from a Filter generating network (`filter_net`).\r\n    Its result is passed to RNN `cell` and the process is repeated over `nrepeats` iterations.\r\n    Weight sharing over iterations is done both in RNN cell and in Filter generating network.\r\n    """"""\r\n    def __init__(self, cell, filter_net, nfeat, vv = True, gc_info=None, nrepeats=1, cat_all=False, edge_mem_limit=1e20, use_pyg = True, cuda = True):\r\n        super(RNNGraphConvModule, self).__init__()\r\n        self._cell = cell\r\n        self._isLSTM = \'LSTM\' in type(cell).__name__\r\n        self._fnet = filter_net\r\n        self._nrepeats = nrepeats\r\n        self._cat_all = cat_all\r\n        self._edge_mem_limit = edge_mem_limit\r\n        self.set_info(gc_info)\r\n        self.use_pyg = use_pyg\r\n        if use_pyg:\r\n            self.nn = NNConv(nfeat, nfeat, vv = vv)\r\n            if cuda:\r\n                self.nn = self.nn.cuda()\r\n\r\n    def set_info(self, gc_info):\r\n        self._gci = gc_info\r\n\r\n    def forward(self, hx):\r\n        # get graph structure information tensors\r\n        idxn, idxe, degs, degs_gpu, edgefeats = self._gci.get_buffers()\r\n\r\n        edge_indexes = self._gci.get_pyg_buffers()\r\n        ###edgefeats = Variable(edgefeats, requires_grad=False)\r\n\r\n        # evalute and reshape filter weights (shared among RNN iterations)\r\n        weights = self._fnet(edgefeats)\r\n        nc = hx.size(1)\r\n        assert hx.dim()==2 and weights.dim()==2 and weights.size(1) in [nc, nc*nc]\r\n        if weights.size(1) != nc:\r\n            weights = weights.view(-1, nc, nc)\r\n\r\n        # repeatedly evaluate RNN cell\r\n        hxs = [hx]\r\n        if self._isLSTM:\r\n            cx = Variable(hx.data.new(hx.size()).fill_(0))\r\n\r\n        for r in range(self._nrepeats):\r\n            if self.use_pyg:\r\n                input = self.nn(hx, edge_indexes, weights)\r\n            else:\r\n                input = ecc.GraphConvFunction.apply(hx, weights, nc, nc, idxn, idxe, degs, degs_gpu,\r\n                                                    self._edge_mem_limit)\r\n            if self._isLSTM:\r\n                hx, cx = self._cell(input, (hx, cx))\r\n            else:\r\n                hx = self._cell(input, hx)\r\n            hxs.append(hx)\r\n\r\n        return torch.cat(hxs,1) if self._cat_all else hx\r\n\r\nclass ECC_CRFModule(nn.Module):\r\n    """"""\r\n    Adapted ""Conditional Random Fields as Recurrent Neural Networks"" (https://arxiv.org/abs/1502.03240)\r\n    `propagation` should be ECC with Filter generating network producing 2D matrix.\r\n    """"""\r\n    def __init__(self, propagation, nrepeats=1):\r\n        super(ECC_CRFModule, self).__init__()\r\n        self._propagation = propagation\r\n        self._nrepeats = nrepeats\r\n\r\n    def forward(self, input):\r\n        Q = nnf.softmax(input)\r\n        for i in range(self._nrepeats):\r\n            Q = self._propagation(Q) # todo: speedup possible by sharing computation of fnet\r\n            Q = input - Q\r\n            if i < self._nrepeats-1:\r\n                Q = nnf.softmax(Q) # last softmax will be part of cross-entropy loss\r\n        return Q\r\n\r\n\r\nclass GRUCellEx(nn.GRUCell):\r\n    """""" Usual GRU cell extended with layer normalization and input gate.\r\n    """"""\r\n    def __init__(self, input_size, hidden_size, bias=True, layernorm=True, ingate=True):\r\n        super(GRUCellEx, self).__init__(input_size, hidden_size, bias)\r\n        self._layernorm = layernorm\r\n        self._ingate = ingate\r\n        if layernorm:\r\n            self.add_module(\'ini\', nn.InstanceNorm1d(1, eps=1e-5, affine=False, track_running_stats=False))\r\n            self.add_module(\'inh\', nn.InstanceNorm1d(1, eps=1e-5, affine=False, track_running_stats=False))\r\n        if ingate:\r\n            self.add_module(\'ig\', nn.Linear(hidden_size, input_size, bias=True))\r\n\r\n    def _normalize(self, gi, gh):\r\n        if self._layernorm: # layernorm on input&hidden, as in https://arxiv.org/abs/1607.06450 (Layer Normalization)\r\n            gi = self._modules[\'ini\'](gi.unsqueeze(1)).squeeze(1)\r\n            gh = self._modules[\'inh\'](gh.unsqueeze(1)).squeeze(1)\r\n        return gi, gh\r\n\r\n    def forward(self, input, hidden):\r\n        if self._ingate:\r\n            input = torch.sigmoid(self._modules[\'ig\'](hidden)) * input\r\n\r\n        # GRUCell in https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/rnn.py extended with layer normalization\r\n        if input.is_cuda and torch.__version__.split(\'.\')[0]==\'0\':\r\n            gi = nnf.linear(input, self.weight_ih)\r\n            gh = nnf.linear(hidden, self.weight_hh)\r\n            gi, gh = self._normalize(gi, gh)\r\n            state = torch.nn._functions.thnn.rnnFusedPointwise.GRUFused\r\n            try: #pytorch >=0.3\r\n                return state.apply(gi, gh, hidden) if self.bias_ih is None else state.apply(gi, gh, hidden, self.bias_ih, self.bias_hh)\r\n            except: #pytorch <=0.2\r\n                return state()(gi, gh, hidden) if self.bias_ih is None else state()(gi, gh, hidden, self.bias_ih, self.bias_hh)\r\n\r\n        gi = nnf.linear(input, self.weight_ih)\r\n        gh = nnf.linear(hidden, self.weight_hh)\r\n        gi, gh = self._normalize(gi, gh)\r\n        i_r, i_i, i_n = gi.chunk(3, 1)\r\n        h_r, h_i, h_n = gh.chunk(3, 1)\r\n        bih_r, bih_i, bih_n = self.bias_ih.chunk(3)\r\n        bhh_r, bhh_i, bhh_n = self.bias_hh.chunk(3)\r\n\r\n        resetgate = torch.sigmoid(i_r + bih_r + h_r + bhh_r)\r\n        inputgate = torch.sigmoid(i_i + bih_i + h_i + bhh_i)\r\n        newgate = torch.tanh(i_n + bih_n + resetgate * (h_n + bhh_n))\r\n        hy = newgate + inputgate * (hidden - newgate)\r\n        return hy\r\n\r\n    def __repr__(self):\r\n        s = super(GRUCellEx, self).__repr__() + \'(\'\r\n        if self._ingate:\r\n            s += \'ingate\'\r\n        if self._layernorm:\r\n            s += \' layernorm\'\r\n        return s + \')\'\r\n\r\n\r\nclass LSTMCellEx(nn.LSTMCell):\r\n    """""" Usual LSTM cell extended with layer normalization and input gate.\r\n    """"""\r\n    def __init__(self, input_size, hidden_size, bias=True, layernorm=True, ingate=True):\r\n        super(LSTMCellEx, self).__init__(input_size, hidden_size, bias)\r\n        self._layernorm = layernorm\r\n        self._ingate = ingate\r\n        if layernorm:\r\n            self.add_module(\'ini\', nn.InstanceNorm1d(1, eps=1e-5, affine=False, track_running_stats=False))\r\n            self.add_module(\'inh\', nn.InstanceNorm1d(1, eps=1e-5, affine=False, track_running_stats=False))\r\n        if ingate:\r\n            self.add_module(\'ig\', nn.Linear(hidden_size, input_size, bias=True))\r\n\r\n    def _normalize(self, gi, gh):\r\n        if self._layernorm: # layernorm on input&hidden, as in https://arxiv.org/abs/1607.06450 (Layer Normalization)\r\n            gi = self._modules[\'ini\'](gi.unsqueeze(1)).squeeze(1)\r\n            gh = self._modules[\'inh\'](gh.unsqueeze(1)).squeeze(1)\r\n        return gi, gh\r\n\r\n    def forward(self, input, hidden):\r\n        if self._ingate:\r\n            input = torch.sigmoid(self._modules[\'ig\'](hidden[0])) * input\r\n\r\n        # GRUCell in https://github.com/pytorch/pytorch/blob/master/torch/nn/_functions/rnn.py extended with layer normalization\r\n        if input.is_cuda and torch.__version__.split(\'.\')[0]==\'0\':\r\n            gi = nnf.linear(input, self.weight_ih)\r\n            gh = nnf.linear(hidden[0], self.weight_hh)\r\n            gi, gh = self._normalize(gi, gh)\r\n            state = torch.nn._functions.thnn.rnnFusedPointwise.LSTMFused\r\n            try: #pytorch >=0.3\r\n                return state.apply(gi, gh, hidden[1]) if self.bias_ih is None else state.apply(gi, gh, hidden[1], self.bias_ih, self.bias_hh)\r\n            except: #pytorch <=0.2\r\n                return state()(gi, gh, hidden[1]) if self.bias_ih is None else state()(gi, gh, hidden[1], self.bias_ih, self.bias_hh)\r\n\r\n        gi = nnf.linear(input, self.weight_ih, self.bias_ih)\r\n        gh = nnf.linear(hidden[0], self.weight_hh, self.bias_hh)\r\n        gi, gh = self._normalize(gi, gh)\r\n\r\n        ingate, forgetgate, cellgate, outgate = (gi+gh).chunk(4, 1)\r\n        ingate = torch.sigmoid(ingate)\r\n        forgetgate = torch.sigmoid(forgetgate)\r\n        cellgate = torch.tanh(cellgate)\r\n        outgate = torch.sigmoid(outgate)\r\n\r\n        cy = (forgetgate * hidden[1]) + (ingate * cellgate)\r\n        hy = outgate * torch.tanh(cy)\r\n        return hy, cy\r\n\r\n    def __repr__(self):\r\n        s = super(LSTMCellEx, self).__repr__() + \'(\'\r\n        if self._ingate:\r\n            s += \'ingate\'\r\n        if self._layernorm:\r\n            s += \' layernorm\'\r\n        return s + \')\'\r\n'"
learning/pointnet.py,18,"b'""""""\r\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\r\n    http://arxiv.org/abs/1711.09869\r\n    2017 Loic Landrieu, Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as nnf\r\nfrom torch.autograd import Variable\r\n\r\nclass STNkD(nn.Module):\r\n    """"""\r\n    Spatial Transformer Net for PointNet, producing a KxK transformation matrix.\r\n    Parameters:\r\n      nfeat: number of input features\r\n      nf_conv: list of layer widths of point embeddings (before maxpool)\r\n      nf_fc: list of layer widths of joint embeddings (after maxpool)\r\n    """"""\r\n    def __init__(self, nfeat, nf_conv, nf_fc, K=2, norm = \'batch\', affine = True, n_group = 1):\r\n        super(STNkD, self).__init__()\r\n\r\n        modules = []\r\n        for i in range(len(nf_conv)):\r\n            modules.append(nn.Conv1d(nf_conv[i-1] if i>0 else nfeat, nf_conv[i], 1))\r\n            if norm == \'batch\':\r\n                modules.append(nn.BatchNorm1d(nf_conv[i]))\r\n            elif norm == \'layer\':\r\n                modules.append(nn.GroupNorm(1,nf_conv[i]))\r\n            elif norm == \'group\':\r\n                 modules.append(nn.GroupNorm(n_group,nf_conv[i]))\r\n            modules.append(nn.ReLU(True))\r\n        self.convs = nn.Sequential(*modules)\r\n\r\n        modules = []\r\n        for i in range(len(nf_fc)):\r\n            modules.append(nn.Linear(nf_fc[i-1] if i>0 else nf_conv[-1], nf_fc[i]))\r\n            if norm == \'batch\':\r\n                modules.append(nn.BatchNorm1d(nf_fc[i]))\r\n            elif norm == \'layer\':\r\n                modules.append(nn.GroupNorm(1,nf_fc[i]))\r\n            elif norm == \'group\':\r\n                 modules.append(nn.GroupNorm(n_group,nf_fc[i]))\r\n            modules.append(nn.ReLU(True))\r\n        self.fcs = nn.Sequential(*modules)\r\n\r\n        self.proj = nn.Linear(nf_fc[-1], K*K)\r\n        nn.init.constant_(self.proj.weight, 0); nn.init.constant_(self.proj.bias, 0)\r\n        self.eye = torch.eye(K).unsqueeze(0)\r\n\r\n    def forward(self, input):\r\n        self.eye = self.eye.cuda() if input.is_cuda else self.eye\r\n        input = self.convs(input)\r\n        input = nnf.max_pool1d(input, input.size(2)).squeeze(2)\r\n        input = self.fcs(input)\r\n        input = self.proj(input)\r\n        return input.view(-1,self.eye.size(1),self.eye.size(2)) + Variable(self.eye)\r\n\r\nclass PointNet(nn.Module):\r\n    """"""\r\n    PointNet with only one spatial transformer and additional ""global"" input concatenated after maxpool.\r\n    Parameters:\r\n      nf_conv: list of layer widths of point embeddings (before maxpool)\r\n      nf_fc: list of layer widths of joint embeddings (after maxpool)\r\n      nfeat: number of input features\r\n      nf_conv_stn, nf_fc_stn, nfeat_stn: as above but for Spatial transformer\r\n      nfeat_global: number of features concatenated after maxpooling\r\n      prelast_do: dropout after the pre-last parameteric layer\r\n      last_ac: whether to use batch norm and relu after the last parameteric layer\r\n    """"""\r\n    def __init__(self, nf_conv, nf_fc, nf_conv_stn, nf_fc_stn, nfeat, nfeat_stn=2, nfeat_global=1, prelast_do=0.5, last_ac=False, is_res=False, norm = \'batch\', affine = True, n_group = 1, last_bn = False):\r\n\r\n        super(PointNet, self).__init__()\r\n        torch.manual_seed(0)\r\n        if nfeat_stn > 0:\r\n            self.stn = STNkD(nfeat_stn, nf_conv_stn, nf_fc_stn, norm=norm, n_group = n_group)\r\n        self.nfeat_stn = nfeat_stn\r\n        \r\n        modules = []\r\n        for i in range(len(nf_conv)):\r\n            modules.append(nn.Conv1d(nf_conv[i-1] if i>0 else nfeat, nf_conv[i], 1))\r\n            if norm == \'batch\':\r\n                modules.append(nn.BatchNorm1d(nf_conv[i]))\r\n            elif norm == \'layer\':\r\n                modules.append(nn.GroupNorm(1, nf_conv[i]))\r\n            elif norm == \'group\':\r\n                 modules.append(nn.GroupNorm(n_group, nf_conv[i]))\r\n            modules.append(nn.ReLU(True))\r\n        \r\n        # Initialization of BN parameters.\r\n        \r\n        self.convs = nn.Sequential(*modules)\r\n\r\n        modules = []\r\n        for i in range(len(nf_fc)):\r\n            modules.append(nn.Linear(nf_fc[i-1] if i>0 else nf_conv[-1]+nfeat_global, nf_fc[i]))\r\n            if i<len(nf_fc)-1 or last_ac:\r\n                if norm == \'batch\':\r\n                    modules.append(nn.BatchNorm1d(nf_fc[i]))\r\n                elif norm == \'layer\':\r\n                    modules.append(nn.GroupNorm(1,nf_fc[i]))\r\n                elif norm == \'group\':\r\n                 modules.append(nn.GroupNorm(n_group,nf_fc[i]))\r\n                modules.append(nn.ReLU(True))\r\n            if i==len(nf_fc)-2 and prelast_do>0:\r\n                modules.append(nn.Dropout(prelast_do))\r\n        if is_res: #init with small number so that at first the residual pointnet is close to zero\r\n            nn.init.normal_(modules[-1].weight, mean=0, std = 1e-2)\r\n            nn.init.normal_(modules[-1].bias, mean=0, std = 1e-2)\r\n        \r\n        #if last_bn:\r\n            #modules.append(nn.BatchNorm1d(nf_fc[-1]))\r\n        \r\n        self.fcs = nn.Sequential(*modules)\r\n\r\n    def forward(self, input, input_global):\r\n        if self.nfeat_stn > 0:\r\n            T = self.stn(input[:,:self.nfeat_stn,:])\r\n            xy_transf = torch.bmm(input[:,:2,:].transpose(1,2), T).transpose(1,2)\r\n            input = torch.cat([xy_transf, input[:,2:,:]], 1)\r\n\r\n        input = self.convs(input)\r\n        input = nnf.max_pool1d(input, input.size(2)).squeeze(2)\r\n        if input_global is not None:\r\n            if len(input_global.shape)== 1 or input_global.shape[1]==1:\r\n                input = torch.cat([input, input_global.view(-1,1)], 1)\r\n            else:\r\n                input = torch.cat([input, input_global], 1)\r\n        return self.fcs(input)\r\n\r\n\r\n\r\n\r\nclass CloudEmbedder():\r\n    """""" Evaluates PointNet on superpoints. Too small superpoints are assigned zero embeddings. Can optionally apply memory mongering\r\n        (https://arxiv.org/pdf/1604.06174.pdf) to decrease memory usage.\r\n    """"""\r\n    def __init__(self, args):\r\n        self.args = args\r\n        self.bw_hook = lambda: None  # could be more elegant in the upcoming pytorch release: http://bit.ly/2A8PI7p\r\n        self.run = self.run_full_monger if args.ptn_mem_monger else self.run_full\r\n\r\n    def run_full(self, model, clouds_meta, clouds_flag, clouds, clouds_global):\r\n        """""" Simply evaluates all clouds in a differentiable way, assumes that all pointnet\'s feature maps fit into mem.""""""\r\n        idx_valid = torch.nonzero(clouds_flag.eq(0)).squeeze()\r\n        if self.args.cuda:\r\n            clouds, clouds_global, idx_valid = clouds.cuda(), clouds_global.cuda(), idx_valid.cuda()\r\n        clouds, clouds_global = Variable(clouds, volatile=not model.training), Variable(clouds_global, volatile=not model.training)\r\n        #print(\'Ptn with\', clouds.size(0), \'clouds\')\r\n\r\n        out = model.ptn(clouds, clouds_global)\r\n        descriptors = Variable(out.data.new(clouds_flag.size(0), out.size(1)).fill_(0))\r\n        descriptors.index_copy_(0, Variable(idx_valid), out)\r\n        return descriptors\r\n\r\n    def run_full_monger(self, model, clouds_meta, clouds_flag, clouds, clouds_global):\r\n        """""" Evaluates all clouds in forward pass, but uses memory mongering to compute backward pass.""""""\r\n        idx_valid = torch.nonzero(clouds_flag.eq(0)).squeeze()\r\n        if self.args.cuda:\r\n            clouds, clouds_global, idx_valid = clouds.cuda(), clouds_global.cuda(), idx_valid.cuda()\r\n        #print(\'Ptn with\', clouds.size(0), \'clouds\')\r\n        with torch.no_grad():\r\n            out = model.ptn(Variable(clouds), (clouds_global))\r\n            if not model.training:\r\n                out = Variable(out.data, requires_grad=model.training) # cut autograd\r\n        if model.training:\r\n            out = Variable(out.data, requires_grad=model.training)\r\n        def bw_hook():\r\n            out_v2 = model.ptn(Variable(clouds), Variable(clouds_global)) # re-run fw pass\r\n            out_v2.backward(out.grad)\r\n\r\n        self.bw_hook = bw_hook\r\n\r\n        descriptors = Variable(out.data.new(clouds_flag.size(0), out.size(1)).fill_(0))\r\n        descriptors.index_copy_(0, Variable(idx_valid), out)\r\n        return descriptors\r\n    \r\nclass LocalCloudEmbedder():\r\n    """""" Local PointNet\r\n    """"""\r\n    def __init__(self, args):\r\n        self.nfeat_stn = args.ptn_nfeat_stn\r\n        self.stn_as_global = args.stn_as_global\r\n        \r\n    def run_batch(self, model, clouds, clouds_global, *excess):\r\n        """""" Evaluates all clouds in a differentiable way, use a batch approach.\r\n        Use when embedding many small point clouds with small PointNets at once""""""\r\n        #cudnn cannot handle arrays larger than 2**16 in one go, uses batch\r\n        batch_size = 2**16-1\r\n        n_batches = int((clouds.shape[0]-1)/batch_size)\r\n        if self.nfeat_stn > 0:\r\n            T = model.stn(clouds[:batch_size,:self.nfeat_stn,:])\r\n            for i in range(1,n_batches+1):\r\n                T = torch.cat((T,model.stn(clouds[i * batch_size:(i+1) * batch_size,:self.nfeat_stn,:])))\r\n            xy_transf = torch.bmm(clouds[:,:2,:].transpose(1,2), T).transpose(1,2)\r\n            clouds = torch.cat([xy_transf, clouds[:,2:,:]], 1)\r\n            if self.stn_as_global:\r\n                clouds_global = torch.cat([clouds_global, T.view(-1,4)], 1)\r\n        \r\n        out = model.ptn(clouds[:batch_size,:,:], clouds_global[:batch_size,:])\r\n        for i in range(1,n_batches+1):\r\n            out = torch.cat((out,model.ptn(clouds[i * batch_size:(i+1) * batch_size,:,:], clouds_global[i * batch_size:(i+1) * batch_size,:])))\r\n        return nnf.normalize(out)\r\n\r\n    def run_batch_cpu(self, model, clouds, clouds_global, *excess):\r\n        """""" Evaluates the cloud on CPU, but put the values in the CPU as soon as they are computed""""""\r\n        #cudnn cannot handle arrays larger than 2**16 in one go, uses batch\r\n        batch_size = 2**10-1\r\n        n_batches = int(clouds.shape[0]/batch_size)\r\n        emb_total = self.run_batch(model, clouds[:batch_size,:,:], clouds_global[:batch_size,:]).cpu()\r\n        for i in range(1,n_batches+1):\r\n            emb = self.run_batch(model, clouds[i * batch_size:(i+1) * batch_size,:,:], clouds_global[i * batch_size:(i+1) * batch_size,:])\r\n            emb_total = torch.cat((emb_total,emb.cpu()))\r\n        return emb_total\r\n\r\n'"
learning/s3dis_dataset.py,1,"b'""""""\r\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\r\n    http://arxiv.org/abs/1711.09869\r\n    2017 Loic Landrieu, Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport sys\r\nsys.path.append(""./learning"")\r\n\r\nimport random\r\nimport numpy as np\r\nimport os\r\nimport functools\r\nimport torch\r\nimport torchnet as tnt\r\nimport h5py\r\nimport spg\r\nfrom sklearn.linear_model import RANSACRegressor\r\n\r\ndef get_datasets(args, test_seed_offset=0):\r\n    """""" Gets training and test datasets. """"""\r\n\r\n    # Load superpoints graphs\r\n    testlist, trainlist, validlist = [], [], []\r\n    valid_names = [\'hallway_1.h5\', \'hallway_6.h5\', \'hallway_11.h5\', \'office_1.h5\' \\\r\n                 , \'office_6.h5\', \'office_11.h5\', \'office_16.h5\', \'office_21.h5\', \'office_26.h5\' \\\r\n                 , \'office_31.h5\', \'office_36.h5\'\\\r\n                 ,\'WC_2.h5\', \'storage_1.h5\', \'storage_5.h5\', \'conferenceRoom_2.h5\', \'auditorium_1.h5\']\r\n    \r\n     #if args.db_test_name == \'test\' then the test set is the evaluation set\r\n     #otherwise it serves as valdiation set to select the best epoch\r\n    \r\n    for n in range(1,7):\r\n        if n != args.cvfold:\r\n            path = \'{}/superpoint_graphs/Area_{:d}/\'.format(args.S3DIS_PATH, n)\r\n            for fname in sorted(os.listdir(path)):\r\n                if fname.endswith("".h5"") and not (args.use_val_set and fname in valid_names):\r\n                    #training set\r\n                    trainlist.append(spg.spg_reader(args, path + fname, True))\r\n                if fname.endswith("".h5"") and (args.use_val_set  and fname in valid_names):\r\n                    #validation set\r\n                    validlist.append(spg.spg_reader(args, path + fname, True))\r\n    path = \'{}/superpoint_graphs/Area_{:d}/\'.format(args.S3DIS_PATH, args.cvfold)\r\n    \r\n    #evaluation set\r\n    for fname in sorted(os.listdir(path)):\r\n        if fname.endswith("".h5""):\r\n            testlist.append(spg.spg_reader(args, path + fname, True))\r\n\r\n    # Normalize edge features\r\n    if args.spg_attribs01:\r\n        trainlist, testlist, validlist, scaler = spg.scaler01(trainlist, testlist, validlist=validlist)\r\n\r\n    return tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in trainlist],\r\n                                    functools.partial(spg.loader, train=True, args=args, db_path=args.S3DIS_PATH)), \\\r\n           tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in testlist],\r\n                                    functools.partial(spg.loader, train=False, args=args, db_path=args.S3DIS_PATH, test_seed_offset=test_seed_offset)), \\\r\n           tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in validlist], \r\n                                    functools.partial(spg.loader, train=False, args=args, db_path=args.S3DIS_PATH, test_seed_offset=test_seed_offset)), \\\r\n            scaler\r\n                                \r\n\r\ndef get_info(args):\r\n    edge_feats = 0\r\n    for attrib in args.edge_attribs.split(\',\'):\r\n        a = attrib.split(\'/\')[0]\r\n        if a in [\'delta_avg\', \'delta_std\', \'xyz\']:\r\n            edge_feats += 3\r\n        else:\r\n            edge_feats += 1\r\n    if args.loss_weights == \'none\':\r\n        weights = np.ones((13,),dtype=\'f4\')\r\n    else:\r\n        weights = h5py.File(args.S3DIS_PATH + ""/parsed/class_count.h5"")[""class_count""][:].astype(\'f4\')\r\n        weights = weights[:,[i for i in range(6) if i != args.cvfold-1]].sum(1)\r\n        weights = weights.mean()/weights\r\n    if args.loss_weights == \'sqrt\':\r\n        weights = np.sqrt(weights)\r\n    weights = torch.from_numpy(weights).cuda() if args.cuda else torch.from_numpy(weights)\r\n    return {\r\n        \'node_feats\': 14 if args.pc_attribs==\'\' else len(args.pc_attribs),\r\n        \'edge_feats\': edge_feats,\r\n        \'class_weights\': weights,\r\n        \'classes\': 13,\r\n        \'inv_class_map\': {0:\'ceiling\', 1:\'floor\', 2:\'wall\', 3:\'column\', 4:\'beam\', 5:\'window\', 6:\'door\', 7:\'table\', 8:\'chair\', 9:\'bookcase\', 10:\'sofa\', 11:\'board\', 12:\'clutter\'},\r\n    }\r\n\r\n\r\n\r\ndef preprocess_pointclouds(args):\r\n    """""" Preprocesses data by splitting them by components and normalizing.""""""\r\n    S3DIS_PATH = args.S3DIS_PATH\r\n    class_count = np.zeros((13,6),dtype=\'int\')\r\n    for n in range(1,7):\r\n        pathP = \'{}/parsed/Area_{:d}/\'.format(S3DIS_PATH, n)\r\n        if args.supervized_partition:\r\n            pathD = \'{}/features_supervision/Area_{:d}/\'.format(S3DIS_PATH, n)\r\n        else:\r\n            pathD = \'{}/features/Area_{:d}/\'.format(S3DIS_PATH, n)\r\n        pathC = \'{}/superpoint_graphs/Area_{:d}/\'.format(S3DIS_PATH, n)\r\n        if not os.path.exists(pathP):\r\n            os.makedirs(pathP)\r\n        random.seed(n)\r\n        \r\n        for file in os.listdir(pathC):\r\n            print(file)\r\n            if file.endswith("".h5""):\r\n                f = h5py.File(pathD + file, \'r\')\r\n                xyz = f[\'xyz\'][:]\r\n                rgb = f[\'rgb\'][:].astype(np.float)\r\n\r\n                labels = f[\'labels\'][:]\r\n                hard_labels = np.argmax(labels[:,1:],1)\r\n                label_count = np.bincount(hard_labels, minlength=13)\r\n                class_count[:,n-1] = class_count[:,n-1] + label_count\r\n                \r\n                if not args.supervized_partition:\r\n                    lpsv = f[\'geof\'][:]\r\n                    lpsv -= 0.5 #normalize\r\n                else:\r\n                    lpsv = np.stack([f[""geof""][:] ]).squeeze()\r\n                # rescale to [-0.5,0.5]; keep xyz\r\n                \r\n                if args.plane_model_elevation:\r\n                    if args.supervized_partition: #already computed\r\n                        e = f[\'elevation\'][:]\r\n                    else:   #simple plane model\r\n                        low_points = ((xyz[:,2]-xyz[:,2].min() < 0.5)).nonzero()[0]\r\n                        reg = RANSACRegressor(random_state=0).fit(xyz[low_points,:2], xyz[low_points,2])\r\n                        e = xyz[:,2]-reg.predict(xyz[:,:2])\r\n                else:   #compute elevation from zmin\r\n                    e = xyz[:,2] / 4 - 0.5 # (4m rough guess)\r\n                    \r\n                rgb = rgb/255.0 - 0.5\r\n                \r\n                room_center = xyz[:,[0,1]].mean(0) #compute distance to room center, useful to detect walls and doors\r\n                distance_to_center = np.sqrt(((xyz[:,[0,1]]-room_center)**2).sum(1))\r\n                distance_to_center = (distance_to_center - distance_to_center.mean())/distance_to_center.std()\r\n\r\n                ma, mi = np.max(xyz,axis=0,keepdims=True), np.min(xyz,axis=0,keepdims=True)\r\n                xyzn = (xyz - mi) / (ma - mi + 1e-8)   # as in PointNet (""normalized location as to the room (from 0 to 1)"")\r\n\r\n                P = np.concatenate([xyz, rgb, e[:,np.newaxis], lpsv, xyzn, distance_to_center[:,None]], axis=1)\r\n\r\n                f = h5py.File(pathC + file, \'r\')\r\n                numc = len(f[\'components\'].keys())\r\n\r\n                with h5py.File(pathP + file, \'w\') as hf:\r\n                    hf.create_dataset(name=\'centroid\',data=xyz.mean(0))\r\n                    for c in range(numc):\r\n                        idx = f[\'components/{:d}\'.format(c)][:].flatten()\r\n                        if idx.size > 10000: # trim extra large segments, just for speed-up of loading time\r\n                            ii = random.sample(range(idx.size), k=10000)\r\n                            idx = idx[ii]\r\n                        hf.create_dataset(name=\'{:d}\'.format(c), data=P[idx,...])\r\n\r\n    path = \'{}/parsed/\'.format(S3DIS_PATH)\r\n    data_file = h5py.File(path+\'class_count.h5\', \'w\')\r\n    data_file.create_dataset(\'class_count\', data=class_count, dtype=\'int\')\r\n\r\nif __name__ == ""__main__"":\r\n    import argparse\r\n    parser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\r\n    parser.add_argument(\'--S3DIS_PATH\', default=\'datasets/s3dis\')\r\n    parser.add_argument(\'--supervized_partition\', type=int, default=0)\r\n    parser.add_argument(\'--plane_model_elevation\', type=int, default=0, help=\'compute elevation with a simple RANSAC based plane model\')\r\n    args = parser.parse_args()\r\n    preprocess_pointclouds(args)\r\n'"
learning/sema3d_dataset.py,1,"b'""""""\r\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\r\n    http://arxiv.org/abs/1711.09869\r\n    2017 Loic Landrieu, Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport random\r\nimport numpy as np\r\nimport os\r\nimport functools\r\nimport torch\r\nimport torchnet as tnt\r\nimport h5py\r\nimport spg\r\n\r\n\r\ndef get_datasets(args, test_seed_offset=0):\r\n\r\n    train_names = [\'bildstein_station1\', \'bildstein_station5\', \'domfountain_station1\', \'domfountain_station3\', \'neugasse_station1\', \'sg27_station1\', \'sg27_station2\', \'sg27_station5\', \'sg27_station9\', \'sg28_station4\', \'untermaederbrunnen_station1\']\r\n    valid_names = [\'bildstein_station3\', \'domfountain_station2\', \'sg27_station4\', \'untermaederbrunnen_station3\']\r\n\r\n    if args.db_train_name == \'train\':\r\n        trainset = [\'train/\' + f for f in train_names]\r\n    elif args.db_train_name == \'trainval\':\r\n        trainset = [\'train/\' + f for f in train_names + valid_names]\r\n\r\n    validset = []\r\n    testset = []\r\n    if args.use_val_set:\r\n        validset = [\'train/\' + f for f in valid_names]\r\n    if args.db_test_name == \'testred\':\r\n        testset = [\'test_reduced/\' + os.path.splitext(f)[0] for f in os.listdir(args.SEMA3D_PATH + \'/superpoint_graphs/test_reduced\')]\r\n    elif args.db_test_name == \'testfull\':\r\n        testset = [\'test_full/\' + os.path.splitext(f)[0] for f in os.listdir(args.SEMA3D_PATH + \'/superpoint_graphs/test_full\')]\r\n        \r\n    # Load superpoints graphs\r\n    testlist, trainlist, validlist = [], [],  []\r\n    for n in trainset:\r\n        trainlist.append(spg.spg_reader(args, args.SEMA3D_PATH + \'/superpoint_graphs/\' + n + \'.h5\', True))\r\n    for n in validset:\r\n        validlist.append(spg.spg_reader(args, args.SEMA3D_PATH + \'/superpoint_graphs/\' + n + \'.h5\', True))\r\n    for n in testset:\r\n        testlist.append(spg.spg_reader(args, args.SEMA3D_PATH + \'/superpoint_graphs/\' + n + \'.h5\', True))\r\n\r\n    # Normalize edge features\r\n    if args.spg_attribs01:\r\n        trainlist, testlist, validlist, scaler = spg.scaler01(trainlist, testlist, validlist=validlist)\r\n\r\n    return tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in trainlist],\r\n                                    functools.partial(spg.loader, train=True, args=args, db_path=args.SEMA3D_PATH)), \\\r\n           tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in testlist],\r\n                                    functools.partial(spg.loader, train=False, args=args, db_path=args.SEMA3D_PATH, test_seed_offset=test_seed_offset)), \\\r\n           tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in validlist],\r\n                                    functools.partial(spg.loader, train=False, args=args, db_path=args.SEMA3D_PATH, test_seed_offset=test_seed_offset)),\\\r\n            scaler\r\n\r\n    \r\ndef get_info(args):\r\n    edge_feats = 0\r\n    for attrib in args.edge_attribs.split(\',\'):\r\n        a = attrib.split(\'/\')[0]\r\n        if a in [\'delta_avg\', \'delta_std\', \'xyz\']:\r\n            edge_feats += 3\r\n        else:\r\n            edge_feats += 1\r\n    if args.loss_weights == \'none\':\r\n        weights = np.ones((8,),dtype=\'f4\')\r\n    else:\r\n        weights = h5py.File(args.SEMA3D_PATH + ""/parsed/class_count.h5"")[""class_count""][:].astype(\'f4\')\r\n        weights = weights.mean()/weights\r\n    if args.loss_weights == \'sqrt\':\r\n        weights = np.sqrt(weights)\r\n    weights = torch.from_numpy(weights).cuda() if args.cuda else torch.from_numpy(weights)\r\n    return {\r\n        \'node_feats\': 14 if args.pc_attribs==\'\' else len(args.pc_attribs),\r\n        \'edge_feats\': edge_feats,\r\n        \'class_weights\': weights,\r\n        \'classes\': 8,\r\n        \'inv_class_map\': {0:\'terrain_man\', 1:\'terrain_nature\', 2:\'veget_hi\', 3:\'veget_low\', 4:\'building\', 5:\'scape\', 6:\'artefact\', 7:\'cars\'},\r\n    }\r\n\r\ndef preprocess_pointclouds(SEMA3D_PATH):\r\n    """""" Preprocesses data by splitting them by components and normalizing.""""""\r\n    class_count = np.zeros((8,),dtype=\'int\')\r\n    for n in [\'train\', \'test_reduced\', \'test_full\']:\r\n        pathP = \'{}/parsed/{}/\'.format(SEMA3D_PATH, n)\r\n        if args.supervised_partition :\r\n            pathD = \'{}/features_supervision/{}/\'.format(SEMA3D_PATH, n)\r\n        else:\r\n            pathD = \'{}/features/{}/\'.format(SEMA3D_PATH, n)\r\n        pathC = \'{}/superpoint_graphs/{}/\'.format(SEMA3D_PATH, n)\r\n        if not os.path.exists(pathP):\r\n            os.makedirs(pathP)\r\n        random.seed(0)\r\n\r\n        for file in os.listdir(pathC):\r\n            print(file)\r\n            if file.endswith("".h5""):\r\n                f = h5py.File(pathD + file, \'r\')\r\n\r\n                if n == \'train\':\r\n                    labels = f[\'labels\'][:]\r\n                    hard_labels = np.argmax(labels[:,1:],1)\r\n                    label_count = np.bincount(hard_labels, minlength=8)\r\n                    class_count = class_count + label_count\r\n                \r\n                xyz = f[\'xyz\'][:]\r\n                rgb = f[\'rgb\'][:].astype(np.float)\r\n                elpsv = np.concatenate((f[\'xyz\'][:,2][:,None], f[\'geof\'][:]), axis=1)\r\n\r\n                # rescale to [-0.5,0.5]; keep xyz\r\n                elpsv[:,0] /= 100 # (rough guess)\r\n                elpsv[:,1:] -= 0.5\r\n                rgb = rgb/255.0 - 0.5\r\n                \r\n                P = np.concatenate([xyz, rgb, elpsv], axis=1)\r\n\r\n                f = h5py.File(pathC + file, \'r\')\r\n                numc = len(f[\'components\'].keys())\r\n\r\n                with h5py.File(pathP + file, \'w\') as hf:\r\n                    hf.create_dataset(name=\'centroid\',data=xyz.mean(0))\r\n                    for c in range(numc):\r\n                        idx = f[\'components/{:d}\'.format(c)][:].flatten()\r\n                        if idx.size > 10000: # trim extra large segments, just for speed-up of loading time\r\n                            ii = random.sample(range(idx.size), k=10000)\r\n                            idx = idx[ii]\r\n\r\n                        hf.create_dataset(name=\'{:d}\'.format(c), data=P[idx,...])\r\n    path = \'{}/parsed/\'.format(SEMA3D_PATH)\r\n    data_file = h5py.File(path+\'class_count.h5\', \'w\')\r\n    data_file.create_dataset(\'class_count\', data=class_count, dtype=\'int\')\r\n\r\nif __name__ == ""__main__"":\r\n    import argparse\r\n    parser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\r\n    parser.add_argument(\'--SEMA3D_PATH\', default=\'datasets/semantic3d\')\r\n    parser.add_argument(\'--supervised_partition\', default=0, type=int, help = \'wether to use supervized partition features\')\r\n    args = parser.parse_args()\r\n    preprocess_pointclouds(args.SEMA3D_PATH)\r\n'"
learning/spg.py,5,"b'""""""\r\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\r\n    http://arxiv.org/abs/1711.09869\r\n    2017 Loic Landrieu, Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport random\r\nimport numpy as np\r\nimport os\r\nimport math\r\nimport transforms3d\r\nimport torch\r\nimport ecc\r\nimport h5py\r\nfrom sklearn import preprocessing\r\nimport igraph\r\n\r\n\r\n\r\ndef spg_edge_features(edges, node_att, edge_att, args):\r\n    """""" Assembles edge features from edge attributes and differences of node attributes. """"""\r\n    columns = []\r\n    for attrib in args.edge_attribs.split(\',\'):\r\n        attrib = attrib.split(\'/\')\r\n        a, opt = attrib[0], attrib[1].lower() if len(attrib)==2 else \'\'\r\n\r\n        if a in [\'delta_avg\', \'delta_std\']:\r\n            columns.append(edge_att[a])\r\n        elif a==\'constant\': # for isotropic baseline\r\n            columns.append(np.ones((edges.shape[0],1), dtype=np.float32))\r\n        elif a in [\'nlength\',\'surface\',\'volume\', \'size\', \'xyz\']:\r\n            attr = node_att[a]\r\n            if opt==\'d\': # difference\r\n                attr = attr[edges[:,0],:] - attr[edges[:,1],:]\r\n            elif opt==\'ld\': # log ratio\r\n                attr = np.log(attr + 1e-10)\r\n                attr = attr[edges[:,0],:] - attr[edges[:,1],:]\r\n            elif opt==\'r\': # ratio\r\n                attr = attr[edges[:,0],:] / (attr[edges[:,1],:] + 1e-10)\r\n            else:\r\n                raise NotImplementedError\r\n            columns.append(attr)\r\n        else:\r\n            raise NotImplementedError\r\n\r\n    return np.concatenate(columns, axis=1).astype(np.float32)\r\n\r\ndef scaler01(trainlist, testlist, transform_train=True, validlist = []):\r\n    """""" Scale edge features to 0 mean 1 stddev """"""\r\n    edge_feats = np.concatenate([ trainlist[i][3] for i in range(len(trainlist)) ], 0)\r\n    scaler = preprocessing.StandardScaler().fit(edge_feats)\r\n\r\n    if transform_train:\r\n        for i in range(len(trainlist)):\r\n            scaler.transform(trainlist[i][3], copy=False)\r\n    for i in range(len(testlist)):\r\n        scaler.transform(testlist[i][3], copy=False)\r\n    if len(validlist)>0:\r\n        for i in range(len(validlist)):\r\n            scaler.transform(validlist[i][3], copy=False)\r\n    return trainlist, testlist, validlist, scaler\r\n\r\ndef spg_reader(args, fname, incl_dir_in_name=False):\r\n    """""" Loads a supergraph from H5 file. """"""\r\n    f = h5py.File(fname,\'r\')\r\n\r\n    if f[\'sp_labels\'].size > 0:\r\n        node_gt_size = f[\'sp_labels\'][:].astype(np.int64) # column 0: no of unlabeled points, column 1+: no of labeled points per class\r\n        node_gt = np.argmax(node_gt_size[:,1:], 1)[:,None]\r\n        node_gt[node_gt_size[:,1:].sum(1)==0,:] = -100    # superpoints without labels are to be ignored in loss computation\r\n    else:\r\n        N = f[\'sp_point_count\'].shape[0]\r\n        node_gt_size = np.concatenate([f[\'sp_point_count\'][:].astype(np.int64), np.zeros((N,8), dtype=np.int64)], 1)\r\n        node_gt = np.zeros((N,1), dtype=np.int64)\r\n\r\n    node_att = {}\r\n    node_att[\'xyz\'] = f[\'sp_centroids\'][:]\r\n    node_att[\'nlength\'] = np.maximum(0, f[\'sp_length\'][:])\r\n    node_att[\'volume\'] = np.maximum(0, f[\'sp_volume\'][:] ** 2)\r\n    node_att[\'surface\'] = np.maximum(0, f[\'sp_surface\'][:] ** 2)\r\n    node_att[\'size\'] = f[\'sp_point_count\'][:]\r\n\r\n    edges = np.concatenate([ f[\'source\'][:], f[\'target\'][:] ], axis=1).astype(np.int64)\r\n\r\n    edge_att = {}\r\n    edge_att[\'delta_avg\'] = f[\'se_delta_mean\'][:]\r\n    edge_att[\'delta_std\'] = f[\'se_delta_std\'][:]\r\n\r\n    if args.spg_superedge_cutoff > 0:\r\n        filtered = np.linalg.norm(edge_att[\'delta_avg\'],axis=1) < args.spg_superedge_cutoff\r\n        edges = edges[filtered,:]\r\n        edge_att[\'delta_avg\'] = edge_att[\'delta_avg\'][filtered,:]\r\n        edge_att[\'delta_std\'] = edge_att[\'delta_std\'][filtered,:]\r\n\r\n    edge_feats = spg_edge_features(edges, node_att, edge_att, args)\r\n\r\n    name = os.path.basename(fname)[:-len(\'.h5\')]\r\n    if incl_dir_in_name: name = os.path.basename(os.path.dirname(fname)) + \'/\' + name\r\n\r\n    return node_gt, node_gt_size, edges, edge_feats, name\r\n\r\n\r\ndef spg_to_igraph(node_gt, node_gt_size, edges, edge_feats, fname):\r\n    """""" Builds representation of superpoint graph as igraph. """"""\r\n    targets = np.concatenate([node_gt, node_gt_size], axis=1)\r\n    G = igraph.Graph(n=node_gt.shape[0], edges=edges.tolist(), directed=True,\r\n                     edge_attrs={\'f\':edge_feats},\r\n                     vertex_attrs={\'v\':list(range(node_gt.shape[0])), \'t\':targets, \'s\':node_gt_size.sum(1)})\r\n    return G, fname\r\n\r\ndef random_neighborhoods(G, num, order):\r\n    """""" Samples `num` random neighborhoods of size `order`.\r\n        Graph nodes are then treated as set, i.e. after hardcutoff, neighborhoods may be broken (sort of data augmentation). """"""\r\n    centers = random.sample(range(G.vcount()), k=num)\r\n    neighb = G.neighborhood(centers, order)\r\n    subset = [item for sublist in neighb for item in sublist]\r\n    subset = sorted(set(subset))\r\n    return G.subgraph(subset)\r\n\r\ndef k_big_enough(G, minpts, k):\r\n    """""" Returns a induced graph on maximum k superpoints of size >= minpts (smaller ones are not counted) """"""\r\n    valid = np.array(G.vs[\'s\']) >= minpts\r\n    n = np.argwhere(np.cumsum(valid)<=k)[-1][0]+1\r\n    return G.subgraph(range(n))\r\n\r\n\r\ndef loader(entry, train, args, db_path, test_seed_offset=0):\r\n    """""" Prepares a superpoint graph (potentially subsampled in training) and associated superpoints. """"""\r\n    G, fname = entry\r\n    # 1) subset (neighborhood) selection of (permuted) superpoint graph\r\n    if train:\r\n        if 0 < args.spg_augm_hardcutoff < G.vcount():\r\n            perm = list(range(G.vcount())); random.shuffle(perm)\r\n            G = G.permute_vertices(perm)\r\n\r\n        if 0 < args.spg_augm_nneigh < G.vcount():\r\n            G = random_neighborhoods(G, args.spg_augm_nneigh, args.spg_augm_order)\r\n\r\n        if 0 < args.spg_augm_hardcutoff < G.vcount():\r\n            G = k_big_enough(G, args.ptn_minpts, args.spg_augm_hardcutoff)\r\n\r\n    # Only stores graph with edges\r\n    if len(G.get_edgelist()) != 0:\r\n        # 2) loading clouds for chosen superpoint graph nodes\r\n        clouds_meta, clouds_flag = [], [] # meta: textual id of the superpoint; flag: 0/-1 if no cloud because too small\r\n        clouds, clouds_global = [], [] # clouds: point cloud arrays; clouds_global: diameters before scaling\r\n\r\n        for s in range(G.vcount()):\r\n            cloud, diam = load_superpoint(args, db_path + \'/parsed/\' + fname + \'.h5\', G.vs[s][\'v\'], train, test_seed_offset)\r\n            if cloud is not None:\r\n                clouds_meta.append(\'{}.{:d}\'.format(fname,G.vs[s][\'v\'])); clouds_flag.append(0)\r\n                clouds.append(cloud.T)\r\n                clouds_global.append(diam)\r\n            else:\r\n                clouds_meta.append(\'{}.{:d}\'.format(fname,G.vs[s][\'v\'])); clouds_flag.append(-1)\r\n\r\n        clouds_flag = np.array(clouds_flag)\r\n        if len(clouds) != 0:\r\n            clouds = np.stack(clouds)\r\n        if len(clouds_global) != 0:\r\n            clouds_global = np.concatenate(clouds_global)\r\n\r\n        return np.array(G.vs[\'t\']), G, clouds_meta, clouds_flag, clouds, clouds_global\r\n\r\n    # Don\'t use the graph if it doesn\'t have edges.\r\n    else:\r\n        target, G, clouds_meta, clouds_flag, clouds, clouds_global = None, None, None, None, None, None\r\n        return target, G, clouds_meta, clouds_flag, clouds, clouds_global\r\n\r\n\r\ndef cloud_edge_feats(edgeattrs):\r\n    edgefeats = np.asarray(edgeattrs[\'f\'])\r\n    return torch.from_numpy(edgefeats), None\r\n\r\ndef eccpc_collate(batch):\r\n    """""" Collates a list of dataset samples into a single batch (adapted in ecc.graph_info_collate_classification())\r\n    """"""\r\n    targets, graphs, clouds_meta, clouds_flag, clouds, clouds_global = list(zip(*batch))\r\n\r\n    targets = torch.cat([torch.from_numpy(t) for t in targets if t is not None], 0).long()\r\n    graphs = [graph for graph in graphs if graph is not None]\r\n    GIs = [ecc.GraphConvInfo(graphs, cloud_edge_feats)]\r\n\r\n    if len(clouds_meta[0]) > 0:\r\n        clouds = torch.cat([torch.from_numpy(f) for f in clouds if f is not None], 0)\r\n        clouds_global = torch.cat([torch.from_numpy(f) for f in clouds_global if f is not None], 0)\r\n        clouds_flag = torch.cat([torch.from_numpy(f) for f in clouds_flag if f is not None], 0)\r\n        clouds_meta = [item for sublist in clouds_meta if sublist is not None for item in sublist]\r\n\r\n    return targets, GIs, (clouds_meta, clouds_flag, clouds, clouds_global)\r\n\r\n\r\n############### POINT CLOUD PROCESSING ##########\r\n\r\ndef load_superpoint(args, fname, id, train, test_seed_offset):\r\n    """""" """"""\r\n    hf = h5py.File(fname,\'r\')\r\n    P = hf[\'{:d}\'.format(id)]\r\n    N = P.shape[0]\r\n    if N < args.ptn_minpts: # skip if too few pts (this must be consistent at train and test time)\r\n        return None, N\r\n    P = P[:].astype(np.float32)\r\n\r\n    rs = np.random.random.__self__ if train else np.random.RandomState(seed=id+test_seed_offset) # fix seed for test\r\n\r\n    if N > args.ptn_npts: # need to subsample\r\n        ii = rs.choice(N, args.ptn_npts)\r\n        P = P[ii, ...]\r\n    elif N < args.ptn_npts: # need to pad by duplication\r\n        ii = rs.choice(N, args.ptn_npts - N)\r\n        P = np.concatenate([P, P[ii,...]], 0)\r\n\r\n    if args.pc_xyznormalize:\r\n        # normalize xyz into unit ball, i.e. in [-0.5,0.5]\r\n        diameter = np.max(np.max(P[:,:3],axis=0) - np.min(P[:,:3],axis=0))\r\n        P[:,:3] = (P[:,:3] - np.mean(P[:,:3], axis=0, keepdims=True)) / (diameter + 1e-10)\r\n    else:\r\n        diameter = 0.0\r\n        P[:,:3] = (P[:,:3] - np.mean(P[:,:3], axis=0, keepdims=True))\r\n\r\n    if args.pc_attribs != \'\':\r\n        columns = []\r\n        if \'xyz\' in args.pc_attribs: columns.append(P[:,:3])\r\n        if \'rgb\' in args.pc_attribs: columns.append(P[:,3:6])\r\n        if \'e\' in args.pc_attribs: columns.append(P[:,6,None])\r\n        if \'lpsv\' in args.pc_attribs: columns.append(P[:,7:11])\r\n        if \'XYZ\' in args.pc_attribs: columns.append(P[:,11:14])\r\n        if \'d\' in args.pc_attribs: columns.append(P[:,14])\r\n        P = np.concatenate(columns, axis=1)\r\n\r\n    if train:\r\n        P = augment_cloud(P, args)\r\n    return P, np.array([diameter], dtype=np.float32)\r\n\r\n\r\ndef augment_cloud(P, args):\r\n    """""""" Augmentation on XYZ and jittering of everything """"""\r\n    M = transforms3d.zooms.zfdir2mat(1)\r\n    if args.pc_augm_scale > 1:\r\n        s = random.uniform(1/args.pc_augm_scale, args.pc_augm_scale)\r\n        M = np.dot(transforms3d.zooms.zfdir2mat(s), M)\r\n    if args.pc_augm_rot==1:\r\n        angle = random.uniform(0, 2*math.pi)\r\n        M = np.dot(transforms3d.axangles.axangle2mat([0,0,1], angle), M) # z=upright assumption\r\n    if args.pc_augm_mirror_prob > 0: # mirroring x&y, not z\r\n        if random.random() < args.pc_augm_mirror_prob/2:\r\n            M = np.dot(transforms3d.zooms.zfdir2mat(-1, [1,0,0]), M)\r\n        if random.random() < args.pc_augm_mirror_prob/2:\r\n            M = np.dot(transforms3d.zooms.zfdir2mat(-1, [0,1,0]), M)\r\n    P[:,:3] = np.dot(P[:,:3], M.T)\r\n\r\n    if args.pc_augm_jitter:\r\n        sigma, clip= 0.01, 0.05 # https://github.com/charlesq34/pointnet/blob/master/provider.py#L74\r\n        P = P + np.clip(sigma * np.random.randn(*P.shape), -1*clip, clip).astype(np.float32)\r\n    return P\r\n    \r\ndef global_rotation(P, args):\r\n    print(""e"")\r\n'"
learning/vkitti_dataset.py,1,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Nov  6 16:45:16 2018\n@author: landrieuloic\n""""""\nfrom __future__ import division\nfrom __future__ import print_function\nfrom builtins import range\n\nimport random\nimport numpy as np\nimport os\nimport functools\nimport torch\nimport torchnet as tnt\nimport h5py\nimport spg\n\ndef get_datasets(args, test_seed_offset=0):\n    """""" Gets training and test datasets. """"""\n\n    # Load superpoints graphs\n    testlist, trainlist, validlist = [], [], []\n    valid_names = [\'0001_00000.h5\',\'0001_00085.h5\', \'0001_00170.h5\',\'0001_00230.h5\',\'0001_00325.h5\',\'0001_00420.h5\', \\\n                   \'0002_00000.h5\',\'0002_00111.h5\',\'0002_00223.h5\',\'0018_00030.h5\',\'0018_00184.h5\',\'0018_00338.h5\',\\\n                   \'0020_00080.h5\',\'0020_00262.h5\',\'0020_00444.h5\',\'0020_00542.h5\',\'0020_00692.h5\', \'0020_00800.h5\']\n    \n    for n in range(1,7):\n        if n != args.cvfold:\n            path = \'{}/superpoint_graphs/0{:d}/\'.format(args.VKITTI_PATH, n)\n            for fname in sorted(os.listdir(path)):\n                if fname.endswith("".h5"") and not (args.use_val_set and fname in valid_names):\n                    #training set\n                    trainlist.append(spg.spg_reader(args, path + fname, True))\n                if fname.endswith("".h5"") and (args.use_val_set  and fname in valid_names):\n                    #validation set\n                    validlist.append(spg.spg_reader(args, path + fname, True))\n    path = \'{}/superpoint_graphs/0{:d}/\'.format(args.VKITTI_PATH, args.cvfold)\n    #evaluation set\n    for fname in sorted(os.listdir(path)):\n        if fname.endswith("".h5""):\n            testlist.append(spg.spg_reader(args, path + fname, True))\n\n    # Normalize edge features\n    if args.spg_attribs01:\n        trainlist, testlist, validlist, scaler = spg.scaler01(trainlist, testlist, validlist=validlist)\n        \n    return tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in trainlist],\n                                    functools.partial(spg.loader, train=True, args=args, db_path=args.VKITTI_PATH)), \\\n           tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in testlist],\n                                    functools.partial(spg.loader, train=False, args=args, db_path=args.VKITTI_PATH, test_seed_offset=test_seed_offset)), \\\n           tnt.dataset.ListDataset([spg.spg_to_igraph(*tlist) for tlist in validlist],\n                                    functools.partial(spg.loader, train=False, args=args, db_path=args.VKITTI_PATH, test_seed_offset=test_seed_offset)), \\\n            scaler\n\n\ndef get_info(args):\n    edge_feats = 0\n    for attrib in args.edge_attribs.split(\',\'):\n        a = attrib.split(\'/\')[0]\n        if a in [\'delta_avg\', \'delta_std\', \'xyz\']:\n            edge_feats += 3\n        else:\n            edge_feats += 1\n    if args.loss_weights == \'none\':\n        weights = np.ones((13,),dtype=\'f4\')\n    else:\n        weights = h5py.File(args.VKITTI_PATH + ""/parsed/class_count.h5"")[""class_count""][:].astype(\'f4\')\n        weights = weights[:,[i for i in range(6) if i != args.cvfold-1]].sum(1)\n        weights = (weights+1).mean()/(weights+1)\n    if args.loss_weights == \'sqrt\':\n        weights = np.sqrt(weights)\n    weights = torch.from_numpy(weights).cuda() if args.cuda else torch.from_numpy(weights)\n    return {\n        \'node_feats\': 9 if args.pc_attribs==\'\' else len(args.pc_attribs),\n        \'edge_feats\': edge_feats,\n        \'classes\': 13,\n        \'class_weights\': weights,\n        \'inv_class_map\': {0:\'Terrain\', 1:\'Tree\', 2:\'Vegetation\', 3:\'Building\', 4:\'Road\', 5:\'GuardRail\', 6:\'TrafficSign\', 7:\'TrafficLight\', 8:\'Pole\', 9:\'Misc\', 10:\'Truck\', 11:\'Car\', 12:\'Van\'},\n    }\n\ndef preprocess_pointclouds(VKITTI_PATH):\n    """""" Preprocesses data by splitting them by components and normalizing.""""""\n    class_count = np.zeros((13,6),dtype=\'int\')\n    for n in range(1,7):\n        pathP = \'{}/parsed/0{:d}/\'.format(VKITTI_PATH, n)\n        pathD = \'{}/features_supervision/0{:d}/\'.format(VKITTI_PATH, n)\n        pathC = \'{}/superpoint_graphs/0{:d}/\'.format(VKITTI_PATH, n)\n        if not os.path.exists(pathP):\n            os.makedirs(pathP)\n        random.seed(n)\n\n        for file in os.listdir(pathC):\n            print(file)\n            if file.endswith("".h5""):\n                f = h5py.File(pathD + file, \'r\')\n                xyz = f[\'xyz\'][:]\n                rgb = f[\'rgb\'][:].astype(np.float)\n                \n                labels = f[\'labels\'][:]\n                hard_labels = np.argmax(labels[:,1:],1)\n                label_count = np.bincount(hard_labels, minlength=13)\n                class_count[:,n-1] = class_count[:,n-1] + label_count\n                \n                e = (f[\'xyz\'][:,2][:] -  np.min(f[\'xyz\'][:,2]))/ (np.max(f[\'xyz\'][:,2]) -  np.min(f[\'xyz\'][:,2]))-0.5\n\n                rgb = rgb/255.0 - 0.5\n                \n                xyzn = (xyz - np.array([30,0,0])) / np.array([30,5,3])\n                \n                lpsv = np.zeros((e.shape[0],4))\n\n                P = np.concatenate([xyz, rgb, e[:,np.newaxis], lpsv, xyzn], axis=1)\n\n                f = h5py.File(pathC + file, \'r\')\n                numc = len(f[\'components\'].keys())\n\n                with h5py.File(pathP + file, \'w\') as hf:\n                    hf.create_dataset(name=\'centroid\',data=xyz.mean(0))\n                    for c in range(numc):\n                        idx = f[\'components/{:d}\'.format(c)][:].flatten()\n                        if idx.size > 10000: # trim extra large segments, just for speed-up of loading time\n                            ii = random.sample(range(idx.size), k=10000)\n                            idx = idx[ii]\n\n                        hf.create_dataset(name=\'{:d}\'.format(c), data=P[idx,...])\n    path = \'{}/parsed/\'.format(VKITTI_PATH)\n    data_file = h5py.File(path+\'class_count.h5\', \'w\')\n    data_file.create_dataset(\'class_count\', data=class_count, dtype=\'int\')\n\nif __name__ == ""__main__"":\n    import argparse\n    parser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\n    parser.add_argument(\'--VKITTI_PATH\', default=\'datasets/s3dis\')\n    args = parser.parse_args()\n    preprocess_pointclouds(args.VKITTI_PATH)'"
partition/__init__.py,0,b''
partition/graphs.py,0,"b'#------------------------------------------------------------------------------\n#---------  Graph methods for SuperPoint Graph   ------------------------------\n#---------     Loic Landrieu, Dec. 2017     -----------------------------------\n#------------------------------------------------------------------------------\nimport numpy as np\nfrom sklearn.neighbors import NearestNeighbors\nfrom scipy.spatial import Delaunay\nfrom numpy import linalg as LA\nimport numpy.matlib\n#------------------------------------------------------------------------------\ndef compute_graph_nn(xyz, k_nn):\n    """"""compute the knn graph""""""\n    num_ver = xyz.shape[0]\n    graph = dict([(""is_nn"", True)])\n    nn = NearestNeighbors(n_neighbors=k_nn+1, algorithm=\'kd_tree\').fit(xyz)\n    distances, neighbors = nn.kneighbors(xyz)\n    neighbors = neighbors[:, 1:]\n    distances = distances[:, 1:]\n    source = np.matlib.repmat(range(0, num_ver), k_nn, 1).flatten(order=\'F\')\n    #save the graph\n    graph[""source""] = source.flatten().astype(\'uint32\')\n    graph[""target""] = neighbors.flatten().astype(\'uint32\')\n    graph[""distances""] = distances.flatten().astype(\'float32\')\n    return graph\n#------------------------------------------------------------------------------\ndef compute_graph_nn_2(xyz, k_nn1, k_nn2, voronoi = 0.0):\n    """"""compute simulteneoulsy 2 knn structures\n    only saves target for knn2\n    assumption : knn1 <= knn2""""""\n    assert k_nn1 <= k_nn2, ""knn1 must be smaller than knn2""\n    n_ver = xyz.shape[0]\n    #compute nearest neighbors\n    graph = dict([(""is_nn"", True)])\n    nn = NearestNeighbors(n_neighbors=k_nn2+1, algorithm=\'kd_tree\').fit(xyz)\n    distances, neighbors = nn.kneighbors(xyz)\n    del nn\n    neighbors = neighbors[:, 1:]\n    distances = distances[:, 1:]\n    #---knn2---\n    target2 = (neighbors.flatten()).astype(\'uint32\')\n    #---knn1-----\n    if voronoi>0:\n        tri = Delaunay(xyz)\n        graph[""source""] = np.hstack((tri.vertices[:,0],tri.vertices[:,0], \\\n              tri.vertices[:,0], tri.vertices[:,1], tri.vertices[:,1], tri.vertices[:,2])).astype(\'uint64\')\n        graph[""target""]= np.hstack((tri.vertices[:,1],tri.vertices[:,2], \\\n              tri.vertices[:,3], tri.vertices[:,2], tri.vertices[:,3], tri.vertices[:,3])).astype(\'uint64\')\n        graph[""distances""] = ((xyz[graph[""source""],:] - xyz[graph[""target""],:])**2).sum(1)\n        keep_edges = graph[""distances""]<voronoi\n        graph[""source""] = graph[""source""][keep_edges]\n        graph[""target""] = graph[""target""][keep_edges]\n        \n        graph[""source""] = np.hstack((graph[""source""], np.matlib.repmat(range(0, n_ver)\n            , k_nn1, 1).flatten(order=\'F\').astype(\'uint32\')))\n        neighbors = neighbors[:, :k_nn1]\n        graph[""target""] =  np.hstack((graph[""target""],np.transpose(neighbors.flatten(order=\'C\')).astype(\'uint32\')))\n        \n        edg_id = graph[""source""] + n_ver * graph[""target""]\n        \n        dump, unique_edges = np.unique(edg_id, return_index = True)\n        graph[""source""] = graph[""source""][unique_edges]\n        graph[""target""] = graph[""target""][unique_edges]\n       \n        graph[""distances""] = graph[""distances""][keep_edges]\n    else:\n        neighbors = neighbors[:, :k_nn1]\n        distances = distances[:, :k_nn1]\n        graph[""source""] = np.matlib.repmat(range(0, n_ver)\n            , k_nn1, 1).flatten(order=\'F\').astype(\'uint32\')\n        graph[""target""] = np.transpose(neighbors.flatten(order=\'C\')).astype(\'uint32\')\n        graph[""distances""] = distances.flatten().astype(\'float32\')\n    #save the graph\n    return graph, target2\n#------------------------------------------------------------------------------\ndef compute_sp_graph(xyz, d_max, in_component, components, labels, n_labels):\n    """"""compute the superpoint graph with superpoints and superedges features""""""\n    n_com = max(in_component)+1\n    in_component = np.array(in_component)\n    has_labels = len(labels) > 1\n    label_hist = has_labels and len(labels.shape) > 1 and labels.shape[1] > 1\n    #---compute delaunay triangulation---\n    tri = Delaunay(xyz)\n    #interface select the edges between different components\n    #edgx and edgxr converts from tetrahedrons to edges\n\t#done separatly for each edge of the tetrahedrons to limit memory impact\n    interface = in_component[tri.vertices[:, 0]] != in_component[tri.vertices[:, 1]]\n    edg1 = np.vstack((tri.vertices[interface, 0], tri.vertices[interface, 1]))\n    edg1r = np.vstack((tri.vertices[interface, 1], tri.vertices[interface, 0]))\n    interface = in_component[tri.vertices[:, 0]] != in_component[tri.vertices[:, 2]]\n    edg2 = np.vstack((tri.vertices[interface, 0], tri.vertices[interface, 2]))\n    edg2r = np.vstack((tri.vertices[interface, 2], tri.vertices[interface, 0]))\n    interface = in_component[tri.vertices[:, 0]] != in_component[tri.vertices[:, 3]]\n    edg3 = np.vstack((tri.vertices[interface, 0], tri.vertices[interface, 3]))\n    edg3r = np.vstack((tri.vertices[interface, 3], tri.vertices[interface, 0]))\n    interface = in_component[tri.vertices[:, 1]] != in_component[tri.vertices[:, 2]]\n    edg4 = np.vstack((tri.vertices[interface, 1], tri.vertices[interface, 2]))\n    edg4r = np.vstack((tri.vertices[interface, 2], tri.vertices[interface, 1]))\n    interface = in_component[tri.vertices[:, 1]] != in_component[tri.vertices[:, 3]]\n    edg5 = np.vstack((tri.vertices[interface, 1], tri.vertices[interface, 3]))\n    edg5r = np.vstack((tri.vertices[interface, 3], tri.vertices[interface, 1]))\n    interface = in_component[tri.vertices[:, 2]] != in_component[tri.vertices[:, 3]]\n    edg6 = np.vstack((tri.vertices[interface, 2], tri.vertices[interface, 3]))\n    edg6r = np.vstack((tri.vertices[interface, 3], tri.vertices[interface, 2]))\n    del tri, interface\n    edges = np.hstack((edg1, edg2, edg3, edg4 ,edg5, edg6, edg1r, edg2r,\n                       edg3r, edg4r ,edg5r, edg6r))\n    del edg1, edg2, edg3, edg4 ,edg5, edg6, edg1r, edg2r, edg3r, edg4r, edg5r, edg6r\n    edges = np.unique(edges, axis=1)\n    \n    if d_max > 0:\n        dist = np.sqrt(((xyz[edges[0,:]]-xyz[edges[1,:]])**2).sum(1))\n        edges = edges[:,dist<d_max]\n\t\n    #---sort edges by alpha numeric order wrt to the components of their source/target---\n    n_edg = len(edges[0])\n    edge_comp = in_component[edges]\n    edge_comp_index = n_com * edge_comp[0,:] +  edge_comp[1,:]\n    order = np.argsort(edge_comp_index)\n    edges = edges[:, order]\n    edge_comp = edge_comp[:, order]\n    edge_comp_index = edge_comp_index[order]\n    #marks where the edges change components iot compting them by blocks\n    jump_edg = np.vstack((0, np.argwhere(np.diff(edge_comp_index)) + 1, n_edg)).flatten()\n    n_sedg = len(jump_edg) - 1\n    #---set up the edges descriptors---\n    graph = dict([(""is_nn"", False)])\n    graph[""sp_centroids""] = np.zeros((n_com, 3), dtype=\'float32\')\n    graph[""sp_length""] = np.zeros((n_com, 1), dtype=\'float32\')\n    graph[""sp_surface""] = np.zeros((n_com, 1), dtype=\'float32\')\n    graph[""sp_volume""] = np.zeros((n_com, 1), dtype=\'float32\')\n    graph[""sp_point_count""] = np.zeros((n_com, 1), dtype=\'uint64\')\n    graph[""source""] = np.zeros((n_sedg, 1), dtype=\'uint32\')\n    graph[""target""] = np.zeros((n_sedg, 1), dtype=\'uint32\')\n    graph[""se_delta_mean""] = np.zeros((n_sedg, 3), dtype=\'float32\')\n    graph[""se_delta_std""] = np.zeros((n_sedg, 3), dtype=\'float32\')\n    graph[""se_delta_norm""] = np.zeros((n_sedg, 1), dtype=\'float32\')\n    graph[""se_delta_centroid""] = np.zeros((n_sedg, 3), dtype=\'float32\')\n    graph[""se_length_ratio""] = np.zeros((n_sedg, 1), dtype=\'float32\')\n    graph[""se_surface_ratio""] = np.zeros((n_sedg, 1), dtype=\'float32\')\n    graph[""se_volume_ratio""] = np.zeros((n_sedg, 1), dtype=\'float32\')\n    graph[""se_point_count_ratio""] = np.zeros((n_sedg, 1), dtype=\'float32\')\n    if has_labels:\n        graph[""sp_labels""] = np.zeros((n_com, n_labels + 1), dtype=\'uint32\')\n    else:\n        graph[""sp_labels""] = []\n    #---compute the superpoint features---\n    for i_com in range(0, n_com):\n        comp = components[i_com]\n        if has_labels and not label_hist:\n            graph[""sp_labels""][i_com, :] = np.histogram(labels[comp]\n                , bins=[float(i)-0.5 for i in range(0, n_labels + 2)])[0]\n        if has_labels and label_hist:\n            graph[""sp_labels""][i_com, :] = sum(labels[comp,:])\n        graph[""sp_point_count""][i_com] = len(comp)\n        xyz_sp = np.unique(xyz[comp, :], axis=0)\n        if len(xyz_sp) == 1:\n            graph[""sp_centroids""][i_com] = xyz_sp\n            graph[""sp_length""][i_com] = 0\n            graph[""sp_surface""][i_com] = 0\n            graph[""sp_volume""][i_com] = 0\n        elif len(xyz_sp) == 2:\n            graph[""sp_centroids""][i_com] = np.mean(xyz_sp, axis=0)\n            graph[""sp_length""][i_com] = np.sqrt(np.sum(np.var(xyz_sp, axis=0)))\n            graph[""sp_surface""][i_com] = 0\n            graph[""sp_volume""][i_com] = 0\n        else:\n            ev = LA.eig(np.cov(np.transpose(xyz_sp), rowvar=True))\n            ev = -np.sort(-ev[0]) #descending order\n            graph[""sp_centroids""][i_com] = np.mean(xyz_sp, axis=0)\n            try:\n                graph[""sp_length""][i_com] = ev[0]\n            except TypeError:\n                graph[""sp_length""][i_com] = 0\n            try:\n                graph[""sp_surface""][i_com] = np.sqrt(ev[0] * ev[1] + 1e-10)\n            except TypeError:\n                graph[""sp_surface""][i_com] = 0\n            try:\n                graph[""sp_volume""][i_com] = np.sqrt(ev[0] * ev[1] * ev[2] + 1e-10)\n            except TypeError:\n                graph[""sp_volume""][i_com] = 0\n    #---compute the superedges features---\n    for i_sedg in range(0, n_sedg):\n        i_edg_begin = jump_edg[i_sedg]\n        i_edg_end = jump_edg[i_sedg + 1]\n        ver_source = edges[0, range(i_edg_begin, i_edg_end)]\n        ver_target = edges[1, range(i_edg_begin, i_edg_end)]\n        com_source = edge_comp[0, i_edg_begin]\n        com_target = edge_comp[1, i_edg_begin]\n        xyz_source = xyz[ver_source, :]\n        xyz_target = xyz[ver_target, :]\n        graph[""source""][i_sedg] = com_source\n        graph[""target""][i_sedg] = com_target\n        #---compute the ratio features---\n        graph[""se_delta_centroid""][i_sedg,:] = graph[""sp_centroids""][com_source,:] - graph[""sp_centroids""][com_target, :]\n        graph[""se_length_ratio""][i_sedg] = graph[""sp_length""][com_source] / (graph[""sp_length""][com_target] + 1e-6)\n        graph[""se_surface_ratio""][i_sedg] = graph[""sp_surface""][com_source] / (graph[""sp_surface""][com_target] + 1e-6)\n        graph[""se_volume_ratio""][i_sedg] = graph[""sp_volume""][com_source] / (graph[""sp_volume""][com_target] + 1e-6)\n        graph[""se_point_count_ratio""][i_sedg] = graph[""sp_point_count""][com_source] / (graph[""sp_point_count""][com_target] + 1e-6)\n        #---compute the offset set---\n        delta = xyz_source - xyz_target\n        if len(delta) > 1:\n            graph[""se_delta_mean""][i_sedg] = np.mean(delta, axis=0)\n            graph[""se_delta_std""][i_sedg] = np.std(delta, axis=0)\n            graph[""se_delta_norm""][i_sedg] = np.mean(np.sqrt(np.sum(delta ** 2, axis=1)))\n        else:\n            graph[""se_delta_mean""][i_sedg, :] = delta\n            graph[""se_delta_std""][i_sedg, :] = [0, 0, 0]\n            graph[""se_delta_norm""][i_sedg] = np.sqrt(np.sum(delta ** 2))\n    return graph\n'"
partition/partition.py,0,"b'""""""\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\n    http://arxiv.org/abs/1711.09869\n    2017 Loic Landrieu, Martin Simonovsky\n    Script for partioning into simples shapes\n""""""\nimport os.path\nimport sys\nimport numpy as np\nimport argparse\nfrom timeit import default_timer as timer\nsys.path.append(""./partition/cut-pursuit/build/src"")\nsys.path.append(""./partition/ply_c"")\nsys.path.append(""./partition"")\nimport libcp\nimport libply_c\nfrom graphs import *\nfrom provider import *\n\nparser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\nparser.add_argument(\'--ROOT_PATH\', default=\'datasets/s3dis\')\nparser.add_argument(\'--dataset\', default=\'s3dis\', help=\'s3dis/sema3d/your_dataset\')\nparser.add_argument(\'--k_nn_geof\', default=45, type=int, help=\'number of neighbors for the geometric features\')\nparser.add_argument(\'--k_nn_adj\', default=10, type=int, help=\'adjacency structure for the minimal partition\')\nparser.add_argument(\'--lambda_edge_weight\', default=1., type=float, help=\'parameter determine the edge weight for minimal part.\')\nparser.add_argument(\'--reg_strength\', default=0.1, type=float, help=\'regularization strength for the minimal partition\')\nparser.add_argument(\'--d_se_max\', default=0, type=float, help=\'max length of super edges\')\nparser.add_argument(\'--voxel_width\', default=0.03, type=float, help=\'voxel size when subsampling (in m)\')\nparser.add_argument(\'--ver_batch\', default=0, type=int, help=\'Batch size for reading large files, 0 do disable batch loading\')\nparser.add_argument(\'--overwrite\', default=0, type=int, help=\'Wether to read existing files or overwrite them\')\nargs = parser.parse_args()\n\n#path to data\nroot = args.ROOT_PATH+\'/\'\n#list of subfolders to be processed\nif args.dataset == \'s3dis\':\n    folders = [""Area_1/"", ""Area_2/"", ""Area_3/"", ""Area_4/"", ""Area_5/"", ""Area_6/""]\n    n_labels = 13\nelif args.dataset == \'sema3d\':\n    folders = [""test_reduced/"", ""test_full/"", ""train/""]\n    n_labels = 8\nelif args.dataset == \'custom_dataset\':\n    folders = [""train/"", ""test/""]\n    n_labels = 10 #number of classes\nelse:\n    raise ValueError(\'%s is an unknown data set\' % dataset)\n\ntimes = [0,0,0] #time for computing: features / partition / spg\n\nif not os.path.isdir(root + ""clouds""):\n    os.mkdir(root + ""clouds"")\nif not os.path.isdir(root + ""features""):\n    os.mkdir(root + ""features"")\nif not os.path.isdir(root + ""superpoint_graphs""):\n    os.mkdir(root + ""superpoint_graphs"")\n\nfor folder in folders:\n    print(""=================\\n   ""+folder+""\\n================="")\n    \n    data_folder = root   + ""data/""              + folder\n    cloud_folder  = root + ""clouds/""            + folder\n    fea_folder  = root   + ""features/""          + folder\n    spg_folder  = root   + ""superpoint_graphs/"" + folder\n    if not os.path.isdir(data_folder):\n        raise ValueError(""%s does not exist"" % data_folder)\n        \n    if not os.path.isdir(cloud_folder):\n        os.mkdir(cloud_folder)\n    if not os.path.isdir(fea_folder):\n        os.mkdir(fea_folder)\n    if not os.path.isdir(spg_folder):\n        os.mkdir(spg_folder)\n    \n    if args.dataset==\'s3dis\':    \n        files = [os.path.join(data_folder, o) for o in os.listdir(data_folder) \n                if os.path.isdir(os.path.join(data_folder,o))]\n    elif args.dataset==\'sema3d\':\n        files = glob.glob(data_folder+""*.txt"")\n    elif args.dataset==\'custom_dataset\':\n        #list all ply files in the folder\n        files = glob.glob(data_folder+""*.ply"")\n        #list all las files in the folder\n        files = glob.glob(data_folder+""*.las"")\n        \n    if (len(files) == 0):\n        raise ValueError(\'%s is empty\' % data_folder)\n        \n    n_files = len(files)\n    i_file = 0\n    for file in files:\n        file_name   = os.path.splitext(os.path.basename(file))[0]\n        \n        if args.dataset==\'s3dis\':\n            data_file   = data_folder      + file_name + \'/\' + file_name + "".txt""\n            cloud_file  = cloud_folder     + file_name\n            fea_file    = fea_folder       + file_name + \'.h5\'\n            spg_file    = spg_folder       + file_name + \'.h5\'\n        elif args.dataset==\'sema3d\':\n            file_name_short = \'_\'.join(file_name.split(\'_\')[:2])\n            data_file  = data_folder + file_name + "".txt""\n            label_file = data_folder + file_name_short + "".labels""\n            cloud_file = cloud_folder+ file_name_short\n            fea_file   = fea_folder  + file_name_short + \'.h5\'\n            spg_file   = spg_folder  + file_name_short + \'.h5\'\n        elif args.dataset==\'custom_dataset\':\n            #adapt to your hierarchy. The following 4 files must be defined\n            data_file   = data_folder      + file_name + \'.ply\' #or .las\n            cloud_file  = cloud_folder     + file_name\n            fea_file    = fea_folder       + file_name + \'.h5\'\n            spg_file    = spg_folder       + file_name + \'.h5\'\n        \n        i_file = i_file + 1\n        print(str(i_file) + "" / "" + str(n_files) + ""---> ""+file_name)\n        #--- build the geometric feature file h5 file ---\n        if os.path.isfile(fea_file) and not args.overwrite:\n            print(""    reading the existing feature file..."")\n            geof, xyz, rgb, graph_nn, labels = read_features(fea_file)\n        else :\n            print(""    creating the feature file..."")\n            #--- read the data files and compute the labels---\n            if args.dataset==\'s3dis\':\n                xyz, rgb, labels, objects = read_s3dis_format(data_file)\n                if args.voxel_width > 0:\n                    xyz, rgb, labels, dump = libply_c.prune(xyz.astype(\'f4\'), args.voxel_width, rgb.astype(\'uint8\'), labels.astype(\'uint8\'), np.zeros(1, dtype=\'uint8\'), n_labels, 0)\n            elif args.dataset==\'sema3d\':\n                label_file = data_folder + file_name + "".labels""\n                has_labels = (os.path.isfile(label_file))\n                if (has_labels):\n                    xyz, rgb, labels = read_semantic3d_format(data_file, n_labels, label_file, args.voxel_width, args.ver_batch)\n                else:\n                    xyz, rgb = read_semantic3d_format(data_file, 0, \'\', args.voxel_width, args.ver_batch)\n                    labels = []\n            elif args.dataset==\'custom_dataset\':\n                #implement in provider.py your own read_custom_format outputing xyz, rgb, labels\n                #example for ply files\n                xyz, rgb, labels = read_ply(data_file)\n                #another one for las files without rgb\n                xyz = read_las(data_file)\n                if args.voxel_width > 0:\n                    #an example of pruning without labels\n                    xyz, rgb, labels = libply_c.prune(xyz, args.voxel_width, rgb, np.array(1,dtype=\'u1\'), 0)\n                    #another one without rgb information nor labels\n                    xyz = libply_c.prune(xyz, args.voxel_width, np.zeros(xyz.shape,dtype=\'u1\'), np.array(1,dtype=\'u1\'), 0)[0]\n                #if no labels available simply set here labels = []\n                #if no rgb available simply set here rgb = [] and make sure to not use it later on\n            start = timer()\n            #---compute 10 nn graph-------\n            graph_nn, target_fea = compute_graph_nn_2(xyz, args.k_nn_adj, args.k_nn_geof)\n            #---compute geometric features-------\n            geof = libply_c.compute_geof(xyz, target_fea, args.k_nn_geof).astype(\'float32\')\n            end = timer()\n            times[0] = times[0] + end - start\n            del target_fea\n            write_features(fea_file, geof, xyz, rgb, graph_nn, labels)\n        #--compute the partition------\n        sys.stdout.flush()\n        if os.path.isfile(spg_file) and not args.overwrite:\n            print(""    reading the existing superpoint graph file..."")\n            graph_sp, components, in_component = read_spg(spg_file)\n        else:\n            print(""    computing the superpoint graph..."")\n            #--- build the spg h5 file --\n            start = timer()\n            if args.dataset==\'s3dis\':\n                features = np.hstack((geof, rgb/255.)).astype(\'float32\')#add rgb as a feature for partitioning\n                features[:,3] = 2. * features[:,3] #increase importance of verticality (heuristic)\n            elif args.dataset==\'sema3d\':\n                 features = geof\n                 geof[:,3] = 2. * geof[:, 3]\n            elif args.dataset==\'custom_dataset\':\n                #choose here which features to use for the partition\n                 features = geof\n                 geof[:,3] = 2. * geof[:, 3]\n                \n            graph_nn[""edge_weight""] = np.array(1. / ( args.lambda_edge_weight + graph_nn[""distances""] / np.mean(graph_nn[""distances""])), dtype = \'float32\')\n            print(""        minimal partition..."")\n            components, in_component = libcp.cutpursuit(features, graph_nn[""source""], graph_nn[""target""]\n                                         , graph_nn[""edge_weight""], args.reg_strength)\n            components = np.array(components, dtype = \'object\')\n            end = timer()\n            times[1] = times[1] + end - start\n            print(""        computation of the SPG..."")\n            start = timer()\n            graph_sp = compute_sp_graph(xyz, args.d_se_max, in_component, components, labels, n_labels)\n            end = timer()\n            times[2] = times[2] + end - start\n            write_spg(spg_file, graph_sp, components, in_component)\n        \n        print(""Timer : %5.1f / %5.1f / %5.1f "" % (times[0], times[1], times[2]))\n'"
partition/provider.py,0,"b'""""""\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\n    http://arxiv.org/abs/1711.09869\n    2017 Loic Landrieu, Martin Simonovsky\n\nfunctions for writing and reading features and superpoint graph\n\n""""""\nimport os\nimport sys\nimport random\nimport glob\nfrom plyfile import PlyData, PlyElement\nimport numpy as np\n#from numpy import genfromtxt\nimport pandas as pd\nimport h5py\n#import laspy\nfrom sklearn.neighbors import NearestNeighbors\n\n\nDIR_PATH = os.path.dirname(os.path.realpath(__file__))\nsys.path.insert(0, os.path.join(DIR_PATH, \'..\'))\nfrom partition.ply_c import libply_c\nimport colorsys\nfrom sklearn.decomposition import PCA\n#------------------------------------------------------------------------------\ndef partition2ply(filename, xyz, components):\n    """"""write a ply with random colors for each components""""""\n    random_color = lambda: random.randint(0, 255)\n    color = np.zeros(xyz.shape)\n    for i_com in range(0, len(components)):\n        color[components[i_com], :] = [random_color(), random_color()\n        , random_color()]\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\')\n    , (\'green\', \'u1\'), (\'blue\', \'u1\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i in range(0, 3):\n        vertex_all[prop[i][0]] = xyz[:, i]\n    for i in range(0, 3):\n        vertex_all[prop[i+3][0]] = color[:, i]\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    ply.write(filename)\n#------------------------------------------------------------------------------\ndef geof2ply(filename, xyz, geof):\n    """"""write a ply with colors corresponding to geometric features""""""\n    color = np.array(255 * geof[:, [0, 1, 3]], dtype=\'uint8\')\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\'), (\'green\', \'u1\'), (\'blue\', \'u1\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i in range(0, 3):\n        vertex_all[prop[i][0]] = xyz[:, i]\n    for i in range(0, 3):\n        vertex_all[prop[i+3][0]] = color[:, i]\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    ply.write(filename)\n#------------------------------------------------------------------------------\ndef prediction2ply(filename, xyz, prediction, n_label, dataset):\n    """"""write a ply with colors for each class""""""\n    if len(prediction.shape) > 1 and prediction.shape[1] > 1:\n        prediction = np.argmax(prediction, axis = 1)\n    color = np.zeros(xyz.shape)\n    for i_label in range(0, n_label + 1):\n        color[np.where(prediction == i_label), :] = get_color_from_label(i_label, dataset)\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\'), (\'green\', \'u1\'), (\'blue\', \'u1\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i in range(0, 3):\n        vertex_all[prop[i][0]] = xyz[:, i]\n    for i in range(0, 3):\n        vertex_all[prop[i+3][0]] = color[:, i]\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    ply.write(filename)\n#------------------------------------------------------------------------------\ndef error2ply(filename, xyz, rgb, labels, prediction):\n    """"""write a ply with green hue for correct classifcation and red for error""""""\n    if len(prediction.shape) > 1 and prediction.shape[1] > 1:\n        prediction = np.argmax(prediction, axis = 1)\n    if len(labels.shape) > 1 and labels.shape[1] > 1:\n        labels = np.argmax(labels, axis = 1)\n    color_rgb = rgb/255\n    for i_ver in range(0, len(labels)):\n        \n        color_hsv = list(colorsys.rgb_to_hsv(color_rgb[i_ver,0], color_rgb[i_ver,1], color_rgb[i_ver,2]))\n        if (labels[i_ver] == prediction[i_ver]) or (labels[i_ver]==0):\n            color_hsv[0] = 0.333333\n        else:\n            color_hsv[0] = 0\n        color_hsv[1] = min(1, color_hsv[1] + 0.3)\n        color_hsv[2] = min(1, color_hsv[2] + 0.1)\n        color_rgb[i_ver,:] = list(colorsys.hsv_to_rgb(color_hsv[0], color_hsv[1], color_hsv[2]))\n    color_rgb = np.array(color_rgb*255, dtype=\'u1\')\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\'), (\'green\', \'u1\'), (\'blue\', \'u1\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i in range(0, 3):\n        vertex_all[prop[i][0]] = xyz[:, i]\n    for i in range(0, 3):\n        vertex_all[prop[i+3][0]] = color_rgb[:, i]        \n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    ply.write(filename)\n#------------------------------------------------------------------------------\ndef spg2ply(filename, spg_graph):\n    """"""write a ply displaying the SPG by adding edges between its centroid""""""\n    vertex_prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\')]\n    vertex_val = np.empty((spg_graph[\'sp_centroids\']).shape[0], dtype=vertex_prop)\n    for i in range(0, 3):\n        vertex_val[vertex_prop[i][0]] = spg_graph[\'sp_centroids\'][:, i]\n    edges_prop = [(\'vertex1\', \'int32\'), (\'vertex2\', \'int32\')]\n    edges_val = np.empty((spg_graph[\'source\']).shape[0], dtype=edges_prop)\n    edges_val[edges_prop[0][0]] = spg_graph[\'source\'].flatten()\n    edges_val[edges_prop[1][0]] = spg_graph[\'target\'].flatten()\n    ply = PlyData([PlyElement.describe(vertex_val, \'vertex\'), PlyElement.describe(edges_val, \'edge\')], text=True)\n    ply.write(filename)\n#------------------------------------------------------------------------------\ndef scalar2ply(filename, xyz, scalar):\n    """"""write a ply with an unisgned integer scalar field""""""\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'scalar\', \'f4\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i in range(0, 3):\n        vertex_all[prop[i][0]] = xyz[:, i]\n    vertex_all[prop[3][0]] = scalar\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    \n    ply.write(filename)\n#------------------------------------------------------------------------------\ndef get_color_from_label(object_label, dataset):\n    """"""associate the color corresponding to the class""""""\n    if dataset == \'s3dis\': #S3DIS\n        object_label = {\n            0: [0   ,   0,   0], #unlabelled .->. black\n            1: [ 233, 229, 107], #\'ceiling\' .-> .yellow\n            2: [  95, 156, 196], #\'floor\' .-> . blue\n            3: [ 179, 116,  81], #\'wall\'  ->  brown\n            4: [  81, 163, 148], #\'column\'  ->  bluegreen\n            5: [ 241, 149, 131], #\'beam\'  ->  salmon\n            6: [  77, 174,  84], #\'window\'  ->  bright green\n            7: [ 108, 135,  75], #\'door\'   ->  dark green\n            8: [  79,  79,  76], #\'table\'  ->  dark grey\n            9: [  41,  49, 101], #\'chair\'  ->  darkblue\n            10: [223,  52,  52], #\'bookcase\'  ->  red\n            11: [ 89,  47,  95], #\'sofa\'  ->  purple\n            12: [ 81, 109, 114], #\'board\'   ->  grey\n            13: [233, 233, 229], #\'clutter\'  ->  light grey\n            }.get(object_label, -1)\n    elif (dataset == \'sema3d\'): #Semantic3D\n        object_label =  {\n            0: [0   ,   0,   0], #unlabelled .->. black\n            1: [ 200, 200, 200], #\'man-made terrain\'  ->  grey\n            2: [   0,  70,   0], #\'natural terrain\'  ->  dark green\n            3: [   0, 255,   0], #\'high vegetation\'  ->  bright green\n            4: [ 255, 255,   0], #\'low vegetation\'  ->  yellow\n            5: [ 255,   0,   0], #\'building\'  ->  red\n            6: [ 148,   0, 211], #\'hard scape\'  ->  violet\n            7: [   0, 255, 255], #\'artifact\'   ->  cyan\n            8: [ 255,   8, 127], #\'cars\'  ->  pink\n            }.get(object_label, -1)\n    elif (dataset == \'vkitti\'): #vkitti3D\n        object_label =  {\n            0:  [   0,   0,   0], # None-> black\n            1:  [ 200,  90,   0], # Terrain .->.brown\n            2:  [   0, 128,  50], # Tree  -> dark green\n            3:  [   0, 220,   0], # Vegetation-> bright green\n            4:  [ 255,   0,   0], # Building-> red\n            5:  [ 100, 100, 100] , # Road-> dark gray\n            6:  [ 200, 200, 200], # GuardRail-> bright gray\n            7:  [ 255,   0, 255], # TrafficSign-> pink\n            8:  [ 255, 255,   0], # TrafficLight-> yellow\n            9:  [ 128,   0, 255], # Pole-> violet\n            10:  [ 255, 200, 150], # Misc-> skin\n            11: [   0, 128, 255], # Truck-> dark blue\n            12: [   0, 200, 255], # Car-> bright blue\n            13: [ 255, 128,   0], # Van-> orange\n            }.get(object_label, -1)\n    elif (dataset == \'custom_dataset\'): #Custom set\n        object_label =  {\n            0: [0   ,   0,   0], #unlabelled .->. black\n            1: [ 255, 0, 0], #\'classe A\' -> red\n            2: [ 0, 255, 0], #\'classeB\' -> green\n            }.get(object_label, -1)\n    else: \n        raise ValueError(\'Unknown dataset: %s\' % (dataset))\n    if object_label == -1:\n        raise ValueError(\'Type not recognized: %s\' % (object_label))\n    return object_label\n#------------------------------------------------------------------------------\n#------------------------------------------------------------------------------\ndef read_s3dis_format(raw_path, label_out=True):\n#S3DIS specific\n    """"""extract data from a room folder""""""\n    #room_ver = genfromtxt(raw_path, delimiter=\' \')\n    room_ver = pd.read_csv(raw_path, sep=\' \', header=None).values\n    xyz = np.ascontiguousarray(room_ver[:, 0:3], dtype=\'float32\')\n    try:\n        rgb = np.ascontiguousarray(room_ver[:, 3:6], dtype=\'uint8\')\n    except ValueError:\n        rgb = np.zeros((room_ver.shape[0],3), dtype=\'uint8\')\n        print(\'WARN - corrupted rgb data for file %s\' % raw_path)\n    if not label_out:\n        return xyz, rgb\n    n_ver = len(room_ver)\n    del room_ver\n    nn = NearestNeighbors(1, algorithm=\'kd_tree\').fit(xyz)\n    room_labels = np.zeros((n_ver,), dtype=\'uint8\')\n    room_object_indices = np.zeros((n_ver,), dtype=\'uint32\')\n    objects = glob.glob(os.path.dirname(raw_path) + ""/Annotations/*.txt"")\n    i_object = 1\n    for single_object in objects:\n        object_name = os.path.splitext(os.path.basename(single_object))[0]\n        print(""        adding object "" + str(i_object) + "" : ""  + object_name)\n        object_class = object_name.split(\'_\')[0]\n        object_label = object_name_to_label(object_class)\n        #obj_ver = genfromtxt(single_object, delimiter=\' \')\n        obj_ver = pd.read_csv(single_object, sep=\' \', header=None).values\n        distances, obj_ind = nn.kneighbors(obj_ver[:, 0:3])\n        room_labels[obj_ind] = object_label\n        room_object_indices[obj_ind] = i_object\n        i_object = i_object + 1\n    \n    return xyz, rgb, room_labels, room_object_indices\n#------------------------------------------------------------------------------\ndef read_vkitti_format(raw_path):\n#S3DIS specific\n    """"""extract data from a room folder""""""\n    data = np.load(raw_path)\n    xyz = data[:, 0:3]\n    rgb = data[:, 3:6]\n    labels = data[:, -1]+1\n    labels[(labels==14).nonzero()] = 0\n    return xyz, rgb, labels\n#------------------------------------------------------------------------------\ndef object_name_to_label(object_class):\n    """"""convert from object name in S3DIS to an int""""""\n    object_label = {\n        \'ceiling\': 1,\n        \'floor\': 2,\n        \'wall\': 3,\n        \'column\': 4,\n        \'beam\': 5,\n        \'window\': 6,\n        \'door\': 7,\n        \'table\': 8,\n        \'chair\': 9,\n        \'bookcase\': 10,\n        \'sofa\': 11,\n        \'board\': 12,\n        \'clutter\': 13,\n        \'stairs\': 0,\n        }.get(object_class, 0)\n    return object_label\n\n#------------------------------------------------------------------------------\ndef read_semantic3d_format(data_file, n_class, file_label_path, voxel_width, ver_batch):\n    """"""read the format of semantic3d. \n    ver_batch : if ver_batch>0 then load the file ver_batch lines at a time.\n                useful for huge files (> 5millions lines)\n    voxel_width: if voxel_width>0, voxelize data with a regular grid\n    n_class : the number of class; if 0 won\'t search for labels (test set)\n    implements batch-loading for huge files\n    and pruning""""""\n    \n    xyz = np.zeros((0, 3), dtype=\'float32\')\n    rgb = np.zeros((0, 3), dtype=\'uint8\')\n    labels = np.zeros((0, n_class+1), dtype=\'uint32\')\n    #---the clouds can potentially be too big to parse directly---\n    #---they are cut in batches in the order they are stored---\n    \n    def process_chunk(vertex_chunk, label_chunk, has_labels, xyz, rgb, labels):\n        xyz_full = np.ascontiguousarray(np.array(vertex_chunk.values[:, 0:3], dtype=\'float32\'))\n        rgb_full = np.ascontiguousarray(np.array(vertex_chunk.values[:, 4:7], dtype=\'uint8\'))\n        if has_labels:\n            labels_full = label_chunk.values.squeeze()\n        else:\n            labels_full = None\n        if voxel_width > 0:\n            if has_labels > 0:\n                xyz_sub, rgb_sub, labels_sub, objets_sub = libply_c.prune(xyz_full, voxel_width\n                                             , rgb_full, labels_full , np.zeros(1, dtype=\'uint8\'), n_class, 0)\n                labels = np.vstack((labels, labels_sub))\n                del labels_full\n            else:\n                xyz_sub, rgb_sub, l, o = libply_c.prune(xyz_full, voxel_width\n                                    , rgb_full, np.zeros(1, dtype=\'uint8\'), np.zeros(1, dtype=\'uint8\'), 0,0)            \n            xyz = np.vstack((xyz, xyz_sub))\n            rgb = np.vstack((rgb, rgb_sub))\n        else:\n            xyz = xyz_full\n            rgb = xyz_full\n            labels = labels_full\n        return xyz, rgb, labels\n    if n_class>0:\n        for (i_chunk, (vertex_chunk, label_chunk)) in \\\n            enumerate(zip(pd.read_csv(data_file,chunksize=ver_batch, delimiter=\' \'), \\\n                pd.read_csv(file_label_path, dtype=""u1"",chunksize=ver_batch))):\n            print(""processing lines %d to %d"" % (i_chunk * ver_batch, (i_chunk+1) * ver_batch))\n            xyz, rgb, labels = process_chunk(vertex_chunk, label_chunk, 1, xyz, rgb, labels)\n    else:\n        for (i_chunk, vertex_chunk) in enumerate(pd.read_csv(data_file, delimiter=\' \',chunksize=ver_batch)):\n            print(""processing lines %d to %d"" % (i_chunk * ver_batch, (i_chunk+1) * ver_batch))\n            xyz, rgb, dump = process_chunk(vertex_chunk, None, 0, xyz, rgb, None)\n        \n    print(""Reading done"")\n    if n_class>0:\n        return xyz, rgb, labels\n    else:\n        return xyz, rgb\n#------------------------------------------------------------------------------\ndef read_semantic3d_format2(data_file, n_class, file_label_path, voxel_width, ver_batch):\n    """"""read the format of semantic3d. \n    ver_batch : if ver_batch>0 then load the file ver_batch lines at a time.\n                useful for huge files (> 5millions lines)\n    voxel_width: if voxel_width>0, voxelize data with a regular grid\n    n_class : the number of class; if 0 won\'t search for labels (test set)\n    implements batch-loading for huge files\n    and pruning""""""\n    \n    xyz = np.zeros((0, 3), dtype=\'float32\')\n    rgb = np.zeros((0, 3), dtype=\'uint8\')\n    labels = np.zeros((0, n_class+1), dtype=\'uint32\')\n    #---the clouds can potentially be too big to parse directly---\n    #---they are cut in batches in the order they are stored---\n    i_rows = 0\n    while True:\n        try:\n            head = None\n            if ver_batch>0:\n                print(""Reading lines %d to %d"" % (i_rows, i_rows + ver_batch))\n                vertices = np.genfromtxt(data_file\n                         , delimiter=\' \', max_rows=ver_batch\n                         , skip_header=i_rows)\n                #if i_rows > 0:\n                #    head = i_rows-1\n                #vertices = pd.read_csv(data_file\n                #         , sep=\' \', nrows=ver_batch\n                #         , header=head).values\n                \n            else:\n                #vertices = np.genfromtxt(data_file, delimiter=\' \')\n                vertices = np.pd.read_csv(data_file, sep=\' \', header=None).values\n                break\n                \n        except (StopIteration, pd.errors.ParserError):\n            #end of file\n            break\n        if len(vertices)==0:\n            break\n        xyz_full = np.ascontiguousarray(np.array(vertices[:, 0:3], dtype=\'float32\'))\n        rgb_full = np.ascontiguousarray(np.array(vertices[:, 4:7], dtype=\'uint8\'))\n        del vertices\n        if n_class > 0:\n            #labels_full = pd.read_csv(file_label_path, dtype=""u1""\n            #             , nrows=ver_batch, header=head).values.squeeze()\n            labels_full = np.genfromtxt(file_label_path, dtype=""u1"", delimiter=\' \'\n                            , max_rows=ver_batch, skip_header=i_rows)\n                \n        if voxel_width > 0:\n            if n_class > 0:\n                xyz_sub, rgb_sub, labels_sub, objets_sub = libply_c.prune(xyz_full, voxel_width\n                                             , rgb_full, labels_full , np.zeros(1, dtype=\'uint8\'), n_class, 0)\n                labels = np.vstack((labels, labels_sub))\n            else:\n                xyz_sub, rgb_sub, l, o = libply_c.prune(xyz_full, voxel_width\n                                    , rgb_full, np.zeros(1, dtype=\'uint8\'), np.zeros(1, dtype=\'uint8\'), 0,0)            \n            del xyz_full, rgb_full\n            xyz = np.vstack((xyz, xyz_sub))\n            rgb = np.vstack((rgb, rgb_sub))\n        i_rows = i_rows + ver_batch        \n    print(""Reading done"")\n    if n_class>0:\n        return xyz, rgb, labels\n    else:\n        return xyz, rgb\n#------------------------------------------------------------------------------\ndef read_ply(filename):\n    """"""convert from a ply file. include the label and the object number""""""\n    #---read the ply file--------\n    plydata = PlyData.read(filename)\n    xyz = np.stack([plydata[\'vertex\'][n] for n in[\'x\', \'y\', \'z\']], axis=1)\n    try:\n        rgb = np.stack([plydata[\'vertex\'][n]\n                        for n in [\'red\', \'green\', \'blue\']]\n                       , axis=1).astype(np.uint8)\n    except ValueError:\n        rgb = np.stack([plydata[\'vertex\'][n]\n                        for n in [\'r\', \'g\', \'b\']]\n                       , axis=1).astype(np.float32)\n    if np.max(rgb) > 1:\n        rgb = rgb\n    try:\n        object_indices = plydata[\'vertex\'][\'object_index\']\n        labels = plydata[\'vertex\'][\'label\']\n        return xyz, rgb, labels, object_indices\n    except ValueError:\n        try:\n            labels = plydata[\'vertex\'][\'label\']\n            return xyz, rgb, labels\n        except ValueError:\n            return xyz, rgb\n#------------------------------------------------------------------------------\ndef read_las(filename):\n    """"""convert from a las file with no rgb""""""\n    #---read the ply file--------\n    try:\n        inFile = laspy.file.File(filename, mode=\'r\')\n    except NameError:\n        raise ValueError(""laspy package not found. uncomment import in /partition/provider and make sure it is installed in your environment"")\n    N_points = len(inFile)\n    x = np.reshape(inFile.x, (N_points,1))\n    y = np.reshape(inFile.y, (N_points,1))\n    z = np.reshape(inFile.z, (N_points,1))\n    xyz = np.hstack((x,y,z)).astype(\'f4\')\n    return xyz\n#------------------------------------------------------------------------------\ndef write_ply_obj(filename, xyz, rgb, labels, object_indices):\n    """"""write into a ply file. include the label and the object number""""""\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\')\n            , (\'green\', \'u1\'), (\'blue\', \'u1\'), (\'label\', \'u1\')\n            , (\'object_index\', \'uint32\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i_prop in range(0, 3):\n        vertex_all[prop[i_prop][0]] = xyz[:, i_prop]\n    for i_prop in range(0, 3):\n        vertex_all[prop[i_prop+3][0]] = rgb[:, i_prop]\n    vertex_all[prop[6][0]] = labels\n    vertex_all[prop[7][0]] = object_indices\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    ply.write(filename)\n    \n#------------------------------------------------------------------------------\ndef embedding2ply(filename, xyz, embeddings):\n    """"""write a ply with colors corresponding to geometric features""""""\n    \n    if embeddings.shape[1]>3:\n        pca = PCA(n_components=3)\n        #pca.fit(np.eye(embeddings.shape[1]))\n        pca.fit(np.vstack((np.zeros((embeddings.shape[1],)),np.eye(embeddings.shape[1]))))\n        embeddings = pca.transform(embeddings)\n        \n    #value = (embeddings-embeddings.mean(axis=0))/(2*embeddings.std())+0.5\n    #value = np.minimum(np.maximum(value,0),1)\n    #value = (embeddings)/(3 * embeddings.std())+0.5\n    value = np.minimum(np.maximum((embeddings+1)/2,0),1)\n    \n    \n    color = np.array(255 * value, dtype=\'uint8\')\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\'), (\'green\', \'u1\'), (\'blue\', \'u1\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i in range(0, 3):\n        vertex_all[prop[i][0]] = xyz[:, i]\n    for i in range(0, 3):\n        vertex_all[prop[i+3][0]] = color[:, i]\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    \n    ply.write(filename)\n\n#------------------------------------------------------------------------------\ndef edge_class2ply2(filename, edg_class, xyz, edg_source, edg_target):\n    """"""write a ply with edge weight color coded into the midway point""""""\n    \n    n_edg = len(edg_target)\n    \n    midpoint = (xyz[edg_source,]+xyz[edg_target,])/2\n    \n    color = np.zeros((edg_source.shape[0],3), dtype = \'uint8\')\n    color[edg_class==0,] = [0,0,0]\n    color[(edg_class==1).nonzero(),] = [255,0,0]\n    color[(edg_class==2).nonzero(),] = [125,255,0]\n    color[(edg_class==3).nonzero(),] = [0,125,255]\n    \n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\'), (\'green\', \'u1\'), (\'blue\', \'u1\')]\n    vertex_all = np.empty(n_edg, dtype=prop)\n    for i in range(0, 3):\n        vertex_all[prop[i][0]] = np.hstack(midpoint[:, i])\n    for i in range(3, 6):\n        vertex_all[prop[i][0]] = color[:,i-3]\n    \n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    \n    ply.write(filename)\n    \n#------------------------------------------------------------------------------\ndef write_ply_labels(filename, xyz, rgb, labels):\n    """"""write into a ply file. include the label""""""\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\'), (\'green\', \'u1\')\n            , (\'blue\', \'u1\'), (\'label\', \'u1\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i_prop in range(0, 3):\n        vertex_all[prop[i_prop][0]] = xyz[:, i_prop]\n    for i_prop in range(0, 3):\n        vertex_all[prop[i_prop+3][0]] = rgb[:, i_prop]\n    vertex_all[prop[6][0]] = labels\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    ply.write(filename)\n#------------------------------------------------------------------------------\ndef write_ply(filename, xyz, rgb):\n    """"""write into a ply file""""""\n    prop = [(\'x\', \'f4\'), (\'y\', \'f4\'), (\'z\', \'f4\'), (\'red\', \'u1\'), (\'green\', \'u1\'), (\'blue\', \'u1\')]\n    vertex_all = np.empty(len(xyz), dtype=prop)\n    for i_prop in range(0, 3):\n        vertex_all[prop[i_prop][0]] = xyz[:, i_prop]\n    for i_prop in range(0, 3):\n        vertex_all[prop[i_prop+3][0]] = rgb[:, i_prop]\n    ply = PlyData([PlyElement.describe(vertex_all, \'vertex\')], text=True)\n    ply.write(filename)\n#------------------------------------------------------------------------------\ndef write_features(file_name, geof, xyz, rgb, graph_nn, labels):\n    """"""write the geometric features, labels and clouds in a h5 file""""""\n    if os.path.isfile(file_name):\n        os.remove(file_name)\n    data_file = h5py.File(file_name, \'w\')\n    data_file.create_dataset(\'geof\', data=geof, dtype=\'float32\')\n    data_file.create_dataset(\'source\', data=graph_nn[""source""], dtype=\'uint32\')\n    data_file.create_dataset(\'target\', data=graph_nn[""target""], dtype=\'uint32\')\n    data_file.create_dataset(\'distances\', data=graph_nn[""distances""], dtype=\'float32\')\n    data_file.create_dataset(\'xyz\', data=xyz, dtype=\'float32\')\n    if len(rgb) > 0:\n        data_file.create_dataset(\'rgb\', data=rgb, dtype=\'uint8\')\n    if len(labels) > 0 and len(labels.shape)>1 and labels.shape[1]>1:\n        data_file.create_dataset(\'labels\', data=labels, dtype=\'uint32\')\n    else:\n        data_file.create_dataset(\'labels\', data=labels, dtype=\'uint8\')\n    data_file.close()\n#------------------------------------------------------------------------------\ndef read_features(file_name):\n    """"""read the geometric features, clouds and labels from a h5 file""""""\n    data_file = h5py.File(file_name, \'r\')\n    #fist get the number of vertices\n    n_ver = len(data_file[""geof""][:, 0])\n    has_labels = len(data_file[""labels""])\n    #the labels can be empty in the case of a test set\n    if has_labels:\n        labels = np.array(data_file[""labels""])\n    else:\n        labels = []\n    #---fill the arrays---\n    geof = data_file[""geof""][:]\n    xyz = data_file[""xyz""][:]\n    rgb = data_file[""rgb""][:]\n    source = data_file[""source""][:]\n    target = data_file[""target""][:]\n\n    #---set the graph---\n    graph_nn = dict([(""is_nn"", True)])\n    graph_nn[""source""] = source\n    graph_nn[""target""] = target\n    return geof, xyz, rgb, graph_nn, labels\n#------------------------------------------------------------------------------\ndef write_spg(file_name, graph_sp, components, in_component):\n    """"""save the partition and spg information""""""\n    if os.path.isfile(file_name):\n        os.remove(file_name)\n    data_file = h5py.File(file_name, \'w\')\n    grp = data_file.create_group(\'components\')\n    n_com = len(components)\n    for i_com in range(0, n_com):\n        grp.create_dataset(str(i_com), data=components[i_com], dtype=\'uint32\')\n    data_file.create_dataset(\'in_component\'\n                             , data=in_component, dtype=\'uint32\')\n    data_file.create_dataset(\'sp_labels\'\n                             , data=graph_sp[""sp_labels""], dtype=\'uint32\')\n    data_file.create_dataset(\'sp_centroids\'\n                             , data=graph_sp[""sp_centroids""], dtype=\'float32\')\n    data_file.create_dataset(\'sp_length\'\n                             , data=graph_sp[""sp_length""], dtype=\'float32\')\n    data_file.create_dataset(\'sp_surface\'\n                             , data=graph_sp[""sp_surface""], dtype=\'float32\')\n    data_file.create_dataset(\'sp_volume\'\n                             , data=graph_sp[""sp_volume""], dtype=\'float32\')\n    data_file.create_dataset(\'sp_point_count\'\n                             , data=graph_sp[""sp_point_count""], dtype=\'uint64\')\n    data_file.create_dataset(\'source\'\n                             , data=graph_sp[""source""], dtype=\'uint32\')\n    data_file.create_dataset(\'target\'\n                             , data=graph_sp[""target""], dtype=\'uint32\')\n    data_file.create_dataset(\'se_delta_mean\'\n                             , data=graph_sp[""se_delta_mean""], dtype=\'float32\')\n    data_file.create_dataset(\'se_delta_std\'\n                             , data=graph_sp[""se_delta_std""], dtype=\'float32\')\n    data_file.create_dataset(\'se_delta_norm\'\n                             , data=graph_sp[""se_delta_norm""], dtype=\'float32\')\n    data_file.create_dataset(\'se_delta_centroid\'\n                             , data=graph_sp[""se_delta_centroid""], dtype=\'float32\')\n    data_file.create_dataset(\'se_length_ratio\'\n                             , data=graph_sp[""se_length_ratio""], dtype=\'float32\')\n    data_file.create_dataset(\'se_surface_ratio\'\n                             , data=graph_sp[""se_surface_ratio""], dtype=\'float32\')\n    data_file.create_dataset(\'se_volume_ratio\'\n                             , data=graph_sp[""se_volume_ratio""], dtype=\'float32\')\n    data_file.create_dataset(\'se_point_count_ratio\'\n                             , data=graph_sp[""se_point_count_ratio""], dtype=\'float32\')\n#-----------------------------------------------------------------------------\ndef read_spg(file_name):\n    """"""read the partition and spg information""""""\n    data_file = h5py.File(file_name, \'r\')\n    graph = dict([(""is_nn"", False)])\n    graph[""source""] = np.array(data_file[""source""], dtype=\'uint32\')\n    graph[""target""] = np.array(data_file[""target""], dtype=\'uint32\')\n    graph[""sp_centroids""] = np.array(data_file[""sp_centroids""], dtype=\'float32\')\n    graph[""sp_length""] = np.array(data_file[""sp_length""], dtype=\'float32\')\n    graph[""sp_surface""] = np.array(data_file[""sp_surface""], dtype=\'float32\')\n    graph[""sp_volume""] = np.array(data_file[""sp_volume""], dtype=\'float32\')\n    graph[""sp_point_count""] = np.array(data_file[""sp_point_count""], dtype=\'uint64\')\n    graph[""se_delta_mean""] = np.array(data_file[""se_delta_mean""], dtype=\'float32\')\n    graph[""se_delta_std""] = np.array(data_file[""se_delta_std""], dtype=\'float32\')\n    graph[""se_delta_norm""] = np.array(data_file[""se_delta_norm""], dtype=\'float32\')\n    graph[""se_delta_centroid""] = np.array(data_file[""se_delta_centroid""], dtype=\'float32\')\n    graph[""se_length_ratio""] = np.array(data_file[""se_length_ratio""], dtype=\'float32\')\n    graph[""se_surface_ratio""] = np.array(data_file[""se_surface_ratio""], dtype=\'float32\')\n    graph[""se_volume_ratio""] = np.array(data_file[""se_volume_ratio""], dtype=\'float32\')\n    graph[""se_point_count_ratio""] = np.array(data_file[""se_point_count_ratio""], dtype=\'float32\')\n    in_component = np.array(data_file[""in_component""], dtype=\'uint32\')\n    n_com = len(graph[""sp_length""])\n    graph[""sp_labels""] = np.array(data_file[""sp_labels""], dtype=\'uint32\')\n    grp = data_file[\'components\']\n    components = np.empty((n_com,), dtype=object)\n    for i_com in range(0, n_com):\n        components[i_com] = np.array(grp[str(i_com)], dtype=\'uint32\').tolist()\n    return graph, components, in_component\n#------------------------------------------------------------------------------\ndef reduced_labels2full(labels_red, components, n_ver):\n    """"""distribute the labels of superpoints to their repsective points""""""\n    labels_full = np.zeros((n_ver, ), dtype=\'uint8\')\n    for i_com in range(0, len(components)):\n        labels_full[components[i_com]] = labels_red[i_com]\n    return labels_full\n#------------------------------------------------------------------------------\ndef interpolate_labels_batch(data_file, xyz, labels, ver_batch):\n    """"""interpolate the labels of the pruned cloud to the full cloud""""""\n    if len(labels.shape) > 1 and labels.shape[1] > 1:\n        labels = np.argmax(labels, axis = 1)\n    i_rows = None\n    labels_f = np.zeros((0, ), dtype=\'uint8\')\n    #---the clouds can potentially be too big to parse directly---\n    #---they are cut in batches in the order they are stored---\n    nn = NearestNeighbors(n_neighbors=1, algorithm=\'kd_tree\').fit(xyz)\n    while True:\n        try:\n            if ver_batch>0:\n                if i_rows is None:\n                    print(""read lines %d to %d"" % (0, ver_batch))\n                else:\n                    print(""read lines %d to %d"" % (i_rows, i_rows + ver_batch))\n                #vertices = np.genfromtxt(data_file\n                #         , delimiter=\' \', max_rows=ver_batch\n                #        , skip_header=i_rows)\n                vertices = pd.read_csv(data_file\n                         , sep=\' \', nrows=ver_batch\n                         , header=i_rows).values\n            else:\n                #vertices = np.genfromtxt(data_file\n                 #        , delimiter=\' \')\n                vertices = pd.read_csv(data_file\n                         , delimiter=\' \').values\n                break\n        except (StopIteration, pd.errors.ParserError):\n            #end of file\n            break\n        if len(vertices)==0:\n            break\n        xyz_full = np.array(vertices[:, 0:3], dtype=\'float32\')\n        del vertices\n        distances, neighbor = nn.kneighbors(xyz_full)\n        del distances\n        labels_f = np.hstack((labels_f, labels[neighbor].flatten()))\n        if i_rows is None:\n            i_rows = ver_batch\n        else:\n            i_rows = i_rows + ver_batch\n    return labels_f\n#------------------------------------------------------------------------------\ndef interpolate_labels(xyz_up, xyz, labels, ver_batch):\n    """"""interpolate the labels of the pruned cloud to the full cloud""""""\n    if len(labels.shape) > 1 and labels.shape[1] > 1:\n        labels = np.argmax(labels, axis = 1)\n    nn = NearestNeighbors(n_neighbors=1, algorithm=\'kd_tree\').fit(xyz)\n    distances, neighbor = nn.kneighbors(xyz_up)\n    return labels[neighbor].flatten()\n#------------------------------------------------------------------------------\ndef perfect_prediction(components, labels):\n    """"""assign each superpoint with the majority label""""""\n    full_pred = np.zeros((labels.shape[0],),dtype=\'uint32\')\n    for i_com in range(len(components)):\n        label_com = labels[components[i_com],1:].sum(0).argmax()\n        full_pred[components[i_com]]=label_com\n    return full_pred\n#----------------------------------------------------\n#SEAL utilities\n\ndef compute_gt_connected_components(n_ver, edg_source, edg_target, is_transition, cutoff):\n    components, in_component = libcp.connected_comp(n_ver,\n                                                  edg_source.astype(\'uint32\'),\n                                                  edg_target.astype(\'uint32\'),\n                                                  is_transition.astype(\'uint8\'), 40) #rough guess\n    return components, in_component\n#----------------------\ndef write_gt_connected_components(file_name, components, in_component):\n    """"""save the label-based connected components of the ground truth""""""\n    if os.path.isfile(file_name):\n        os.remove(file_name)\n    data_file = h5py.File(file_name, \'w\')\n    grp = data_file.create_group(\'components\')\n    for i_com in range(len(components)):\n        grp.create_dataset(str(i_com), data=components[i_com], dtype=\'uint32\')\n    data_file.create_dataset(\'in_component\', data=in_component, dtype=\'uint32\')\n#-------------------------------------\n\ndef read_gt_connected_components(file_name):\n    """"""read the label-based connected components of the ground truth""""""\n    data_file = h5py.File(file_name, \'r\')\n    in_component = np.array(data_file[""in_component""], dtype=\'uint32\')\n    n_com = np.amax(in_component)\n    components = np.empty((n_com,), dtype=object)\n    for i_com in range(0, n_com):\n        components[i_com] = np.array(grp[str(i_com)], dtype=\'uint32\').tolist()\n    return components, in_component\n'"
partition/visualize.py,0,"b'""""""\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\n    http://arxiv.org/abs/1711.09869\n    2017 Loic Landrieu, Martin Simonovsky\n    \nthis functions outputs varied ply file to visualize the different steps\n""""""\nimport os.path\nimport numpy as np\nimport argparse\nimport sys\nsys.path.append(""./partition/"")\nfrom plyfile import PlyData, PlyElement\nfrom provider import *\nparser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\nparser.add_argument(\'--dataset\', default=\'s3dis\', help=\'dataset name: sema3d|s3dis\')\nparser.add_argument(\'--ROOT_PATH\', default=\'/mnt/bigdrive/loic/S3DIS\', help=\'folder containing the ./data folder\')\nparser.add_argument(\'--res_file\', default=\'../models/cv1/predictions_val\', help=\'folder containing the results\')\nparser.add_argument(\'--supervized_partition\',type=int,  default=0)\nparser.add_argument(\'--file_path\', default=\'Area_1/conferenceRoom_1\', help=\'file to output (must include the area / set in its path)\')\nparser.add_argument(\'--upsample\', default=0, type=int, help=\'if 1, upsample the prediction to the original cloud (if the files is huge it can take a very long and use a lot of memory - avoid on sema3d)\')\nparser.add_argument(\'--ver_batch\', default=0, type=int, help=\'Batch size for reading large files\')\nparser.add_argument(\'--output_type\', default=\'igfpres\', help=\'which cloud to output: i = input rgb pointcloud \\\n                    , g = ground truth, f = geometric features, p = partition, r = prediction result \\\n                    , e = error, s = SPG\')\nargs = parser.parse_args()\n#---path to data---------------------------------------------------------------\n#root of the data directory\nroot = args.ROOT_PATH+\'/\'\nrgb_out = \'i\' in args.output_type\ngt_out  = \'g\' in args.output_type\nfea_out = \'f\' in args.output_type\npar_out = \'p\' in args.output_type\nres_out = \'r\' in args.output_type\nerr_out = \'e\' in args.output_type\nspg_out = \'s\' in args.output_type\nfolder = os.path.split(args.file_path)[0] + \'/\'\nfile_name = os.path.split(args.file_path)[1]\n\nif args.dataset == \'s3dis\':\n    n_labels = 13\nif args.dataset == \'sema3d\':\n    n_labels = 8   \nif args.dataset == \'vkitti\':\n    n_labels = 13\nif args.dataset == \'custom_dataset\':\n    n_labels = 10    \n#---load the values------------------------------------------------------------\nfea_file   = root + ""features/""          + folder + file_name + \'.h5\'\nif not os.path.isfile(fea_file) or args.supervized_partition:\n    fea_file   = root + ""features_supervision/""          + folder + file_name + \'.h5\'\nspg_file   = root + ""superpoint_graphs/"" + folder + file_name + \'.h5\'\nply_folder = root + ""clouds/""            + folder \nply_file   = ply_folder                  + file_name\nres_file   = args.res_file + \'.h5\'\n\nif not os.path.isdir(root + ""clouds/""):\n    os.mkdir(root + ""clouds/"" )\nif not os.path.isdir(ply_folder ):\n    os.mkdir(ply_folder)\nif (not os.path.isfile(fea_file)) :\n    raise ValueError(""%s does not exist and is needed"" % fea_file)\n    \ngeof, xyz, rgb, graph_nn, labels = read_features(fea_file)\n\nif (par_out or res_out) and (not os.path.isfile(spg_file)):    \n    raise ValueError(""%s does not exist and is needed to output the partition  or result ply"" % spg_file) \nelse:\n    graph_spg, components, in_component = read_spg(spg_file)\nif res_out or err_out:\n    if not os.path.isfile(res_file):\n        raise ValueError(""%s does not exist and is needed to output the result ply"" % res_file) \n    try:\n        pred_red  = np.array(h5py.File(res_file, \'r\').get(folder + file_name))        \n        if (len(pred_red) != len(components)):\n            raise ValueError(""It looks like the spg is not adapted to the result file"") \n        pred_full = reduced_labels2full(pred_red, components, len(xyz))\n    except OSError:\n        raise ValueError(""%s does not exist in %s"" % (folder + file_name, res_file))\n#---write the output clouds----------------------------------------------------\nif rgb_out:\n    print(""writing the RGB file..."")\n    write_ply(ply_file + ""_rgb.ply"", xyz, rgb)\n    \nif gt_out: \n    print(""writing the GT file..."")\n    prediction2ply(ply_file + ""_GT.ply"", xyz, labels, n_labels, args.dataset)\n    \nif fea_out:\n    print(""writing the features file..."")\n    geof2ply(ply_file + ""_geof.ply"", xyz, geof)\n    \nif par_out:\n    print(""writing the partition file..."")\n    partition2ply(ply_file + ""_partition.ply"", xyz, components)\n    \nif res_out and not bool(args.upsample):\n    print(""writing the prediction file..."")\n    prediction2ply(ply_file + ""_pred.ply"", xyz, pred_full+1, n_labels,  args.dataset)\n    \nif err_out:\n    print(""writing the error file..."")\n    error2ply(ply_file + ""_err.ply"", xyz, rgb, labels, pred_full+1)\n    \nif spg_out:\n    print(""writing the SPG file..."")\n    spg2ply(ply_file + ""_spg.ply"", graph_spg)\n    \nif res_out and bool(args.upsample):\n    if args.dataset==\'s3dis\':\n        data_file   = root + \'data/\' + folder + file_name + \'/\' + file_name + "".txt""\n        xyz_up, rgb_up = read_s3dis_format(data_file, False)\n    elif args.dataset==\'sema3d\':#really not recommended unless you are very confident in your hardware\n        data_file  = data_folder + file_name + "".txt""\n        xyz_up, rgb_up = read_semantic3d_format(data_file, 0, \'\', 0, args.ver_batch)\n    elif args.dataset==\'custom_dataset\':\n        data_file  = data_folder + file_name + "".ply""\n        xyz_up, rgb_up = read_ply(data_file)\n    del rgb_up\n    pred_up = interpolate_labels(xyz_up, xyz, pred_full, args.ver_batch)\n    print(""writing the upsampled prediction file..."")\n    prediction2ply(ply_file + ""_pred_up.ply"", xyz_up, pred_up+1, n_labels, args.dataset)\n    \n'"
partition/write_Semantic3d.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\n    http://arxiv.org/abs/1711.09869\n    2017 Loic Landrieu, Martin Simonovsky\n    \ncall this function once the partition and inference was made to upsample\nthe prediction to the original point clouds\n""""""\nimport os.path\nimport glob\nimport numpy as np\nimport argparse\nfrom provider import *\nparser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\nparser.add_argument(\'--SEMA3D_PATH\', default=\'datasets/semantic3D\')\nparser.add_argument(\'--odir\', default=\'./results/semantic3d\', help=\'Directory to store results\')\nparser.add_argument(\'--ver_batch\', default=5000000, type=int, help=\'Batch size for reading large files\')\nparser.add_argument(\'--db_test_name\', default=\'testred\')\nargs = parser.parse_args()\n#---path to data---------------------------------------------------------------\n#root of the data directory\nroot = args.SEMA3D_PATH+\'/\'\n#list of subfolders to be processed\nif args.db_test_name == \'testred\':\n    area = \'test_reduced/\'\nelif args.db_test_name == \'testfull\':\n    area = \'test_full/\'\n#------------------------------------------------------------------------------\nprint(""=================\\n   "" + area + ""\\n================="")\ndata_folder = root + ""data/""               + area\nfea_folder  = root + ""features/""           + area\nspg_folder  = root + ""superpoint_graphs/""           + area\nres_folder  = \'./\' + args.odir + \'/\'\nlabels_folder =  root + ""labels/""          + area\nif not os.path.isdir(data_folder):\n    raise ValueError(""%s do not exists"" % data_folder)\nif not os.path.isdir(fea_folder):\n    raise ValueError(""%s do not exists"" % fea_folder)\nif not os.path.isdir(res_folder):\n    raise ValueError(""%s do not exists"" % res_folder)  \nif not os.path.isdir(root + ""labels/""):\n    os.mkdir(root + ""labels/"")   \nif not os.path.isdir(labels_folder):\n    os.mkdir(labels_folder)   \ntry:    \n    res_file = h5py.File(res_folder + \'predictions_\' + args.db_test_name + \'.h5\', \'r\')   \nexcept OSError:\n    raise ValueError(""%s do not exists"" % res_file) \n    \nfiles = glob.glob(data_folder+""*.txt"")    \nif (len(files) == 0):\n    raise ValueError(\'%s is empty\' % data_folder)\nn_files = len(files)\ni_file = 0\nfor file in files:\n    file_name = os.path.splitext(os.path.basename(file))[0]\n    file_name_short = \'_\'.join(file_name.split(\'_\')[:2])\n    data_file  = data_folder + file_name + "".txt""\n    fea_file   = fea_folder  + file_name_short + \'.h5\'\n    spg_file   = spg_folder  + file_name_short + \'.h5\' \n    label_file = labels_folder + file_name_short + "".labels""\n    i_file = i_file + 1\n    print(str(i_file) + "" / "" + str(n_files) + ""---> ""+file_name_short)\n    print(""    reading the subsampled file..."")\n    geof, xyz, rgb, graph_nn, l = read_features(fea_file)\n    graph_sp, components, in_component = read_spg(spg_file)\n    n_ver = xyz.shape[0]\n    del geof, rgb, graph_nn, l, graph_sp\n    labels_red = np.array(res_file.get(area + file_name_short))\n    print(""    upsampling..."")\n    labels_full = reduced_labels2full(labels_red, components, n_ver)\n    labels_ups = interpolate_labels_batch(data_file, xyz, labels_full, args.ver_batch)\n    np.savetxt(label_file, labels_ups, delimiter=\' \', fmt=\'%d\')   # X is an array\n'"
supervized_partition/__init__.py,0,b''
supervized_partition/evaluate_partition.py,0,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Thu Oct 11 10:12:49 2018\n\n@author: landrieuloic\n""""""\n\n""""""\n    Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\n    http://arxiv.org/abs/1711.09869\n    2017 Loic Landrieu, Martin Simonovsky\n""""""\nimport glob, os\nimport argparse\nimport numpy as np\nimport sys\nimport ast\nimport csv\nimport h5py\nsys.path.append(""./learning"")\nfrom metrics import *\n\nparser = argparse.ArgumentParser(description=\'Evaluation function for S3DIS\')\n\nparser.add_argument(\'--odir\', default=\'./results_partition/\', help=\'Directory to store results\')\nparser.add_argument(\'--folder\', default=\'\', help=\'Directory to store results\')\nparser.add_argument(\'--dataset\', default=\'s3dis\', help=\'Directory to store results\')\nparser.add_argument(\'--cvfold\', default=\'123456\', help=\'which fold to consider\')\n\nargs = parser.parse_args()\nargs.odir = args.odir + args.dataset + \'/\'\n\n\nroot = args.odir + args.folder + \'/\'\n\nif args.dataset == \'s3dis\':\n    fold_size = [44,40,23,49,68,48]\n    files = glob.glob(root + \'cv{}\'.format(args.cvfold[0]) + \'/res*.h5\')\n    n_classes=  13\nelif args.dataset == \'vkitti\':\n    fold_size = [15,15,15,15,15,15]\n    files = glob.glob(root + \'0{}\'.format(args.cvfold[0]) + \'/res*.h5\')\n    n_classes = 13\n\nfile_result_txt = open(args.odir + args.folder + \'/results\' + \'.txt\',""w"")\nfile_result_txt.write(""   N \\t ASA \\t BR \\t BP\\n"")\n    \n    \nC_classes = np.zeros((n_classes,n_classes))\nC_BR = np.zeros((2,2))\nC_BP = np.zeros((2,2))\nN_sp = 0\nN_pc = 0\n    \nfor i_fold in range(len(args.cvfold)):\n    fold = int(args.cvfold[i_fold])\n    if args.dataset == \'s3dis\':\n        base_name = root + \'cv{}\'.format(fold) \n    elif args.dataset == \'vkitti\':\n        base_name = root + \'0{}\'.format(fold) \n        \n    try:\n        file_name = base_name + \'/res.h5\'\n        res_file = h5py.File(file_name, \'r\')\n    except OSError:\n        raise NameError(\'Cant find pretrained model %s\' % file_name)\n            \n    c_classes = np.array(res_file[""confusion_matrix_classes""])\n    c_BP = np.array(res_file[""confusion_matrix_BP""])\n    c_BR = np.array(res_file[""confusion_matrix_BR""])\n    n_sp = np.array(res_file[""n_clusters""])\n    print(""Fold %d : \\t n_sp = %5.1f \\t ASA = %3.2f %% \\t BR = %3.2f %% \\t BP = %3.2f %%"" %  \\\n         (fold, n_sp, 100 * c_classes.trace() / c_classes.sum(), 100 * c_BR[1,1] / (c_BR[1,1] + c_BR[1,0]),100 * c_BP[1,1] / (c_BP[1,1] + c_BP[0,1]) ))\n    C_classes += c_classes\n    C_BR += c_BR\n    C_BP += c_BP\n    N_sp += n_sp * fold_size[i_fold]\n    N_pc += fold_size[i_fold]\n    \nif N_sp>0:\n    print(""\\nOverall : \\t n_sp = %5.1f  \\t ASA = %3.2f %% \\t BR = %3.2f %% \\t BP = %3.2f %%\\n"" %  \\\n         (N_sp/N_pc, 100 * C_classes.trace() / C_classes.sum(), 100 * C_BR[1,1] / (C_BR[1,1] + C_BR[1,0]),100 * C_BP[1,1] / (C_BP[1,1] + C_BP[0,1]) ))\n    file_result_txt.write(""%4.1f \\t %3.2f \\t %3.2f \\t %3.2f \\n"" % (N_sp/N_pc, 100 * C_classes.trace() / C_classes.sum(), 100 * C_BR[1,1] / (C_BR[1,1] + C_BR[1,0]),100 * C_BP[1,1] / (C_BP[1,1] + C_BP[0,1]) ))\n\nfile_result_txt.close()'"
supervized_partition/folderhierarchy.py,0,"b'import os\nimport sys\n\nDIR_PATH = os.path.dirname(os.path.realpath(__file__))\nsys.path.insert(0, os.path.join(DIR_PATH, \'..\'))\n\nclass FolderHierachy:\n    SPG_FOLDER = ""superpoint_graphs""\n    EMBEDDINGS_FOLDER = ""embeddings""\n    SCALAR_FOLDER = ""scalars""\n    MODEL_FILE = ""model.pth.tar""\n\n    def __init__(self,outputdir,dataset_name,root_dir,cv_fold):\n        self._root = root_dir\n        if dataset_name==\'s3dis\':\n            self._outputdir = os.path.join(outputdir,\'cv\' + str(cv_fold))\n            self._folders = [""Area_1/"", ""Area_2/"", ""Area_3/"", ""Area_4/"", ""Area_5/"", ""Area_6/""]\n        elif dataset_name==\'sema3d\':\n            self._outputdir = os.path.join(outputdir,\'best\')\n            self._folders  = [""train/"", ""test_reduced/"", ""test_full/""]\n        elif dataset_name==\'vkitti\':\n            self._outputdir = os.path.join(outputdir, \'cv\' + str(cv_fold))\n            self._folders  = [""01/"", ""02/"", ""03/"", ""04/"", ""05/"", ""06/""]\n        \n        if not os.path.exists(self._outputdir):\n            os.makedirs(self._outputdir)\n\n        self._spg_folder = self._create_folder(self.SPG_FOLDER)\n        self._emb_folder = self._create_folder(self.EMBEDDINGS_FOLDER)\n        self._scalars = self._create_folder(self.SCALAR_FOLDER)   \n\n    @property\n    def outputdir(self): return self._outputdir\n\n    @property\n    def emb_folder(self): return self._emb_folder\n    \n    @property\n    def spg_folder(self): return self._spg_folder\n\n    @property\n    def scalars(self): return self._scalars\n\n    @property\n    def model_path(self): return os.path.join(self._outputdir, self.MODEL_FILE)\n\n    def _create_folder(self,property_name):\n        folder = os.path.join(self._root , property_name )\n        if not os.path.isdir(folder):\n            os.mkdir(folder)\n        return folder'"
supervized_partition/generate_partition.py,3,"b'import logging\nimport argparse\nimport sys\nimport os\nimport torch\nimport glob\nimport torchnet as tnt\nimport functools\nimport tqdm\nfrom multiprocessing import Pool\n\nDIR_PATH = os.path.dirname(os.path.realpath(__file__))\nsys.path.insert(0, os.path.join(DIR_PATH, \'..\'))\n\nfrom supervized_partition import supervized_partition\nfrom supervized_partition import graph_processing\nfrom supervized_partition import losses\nfrom partition import provider\nfrom partition import graphs\nfrom learning import pointnet\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\'Partition large scale point clouds using cut-pursuit\')\n\n    parser.add_argument(\'--modeldir\', help=\'Folder where the saved model lies\', required=True)\n    parser.add_argument(\'--cuda\', default=0, type=int, help=\'Bool, use cuda\')\n    parser.add_argument(\'--input_folder\',  type=str,\n                        help=\'Folder containing preprocessed point clouds ready for segmentation\', required=True)\n    parser.add_argument(\'--output_folder\', default="""", type=str, help=\'Folder that will contain the output\')\n    parser.add_argument(\'--overwrite\', default=1, type=int, help=\'Overwrite existing partition\')\n    parser.add_argument(\'--nworkers\', default=5, type=int,\n                        help=\'Num subprocesses to use for generating the SPGs\')\n\n    args = parser.parse_args()\n    return args\n\n\ndef load_model(model_dir, cuda):\n    checkpoint = torch.load(os.path.join(model_dir, supervized_partition.FolderHierachy.MODEL_FILE))\n    training_args = checkpoint[\'args\']\n    training_args.cuda = cuda  # override cuda\n    model = supervized_partition.create_model(training_args)\n    model.load_state_dict(checkpoint[\'state_dict\'])\n    model.eval()\n    return model, training_args\n\n\ndef get_dataloader(input_folder, training_args):\n    file_list = glob.glob(os.path.join(input_folder, \'*.h5\'))\n    if not file_list:\n        raise ValueError(""Empty input folder: %s"" % input_folder)\n    dataset = tnt.dataset.ListDataset(file_list,\n                                      functools.partial(graph_processing.graph_loader, train=False, args=training_args, db_path=""""))\n    loader = torch.utils.data.DataLoader(dataset, batch_size=1,\n                                         collate_fn=graph_processing.graph_collate)\n    return loader\n\n\ndef get_embedder(args):\n    if args.learned_embeddings and args.ptn_embedding == \'ptn\':\n        ptnCloudEmbedder = pointnet.LocalCloudEmbedder(args)\n    elif \'geof\' in args.ver_value:\n        ptnCloudEmbedder = graph_processing.spatialEmbedder(args)\n    else:\n        raise NameError(\'Do not know model \' + args.learned_embeddings)\n    return ptnCloudEmbedder\n\n\ndef get_num_classes(args):\n    # Decide on the dataset\n    if args.dataset == \'s3dis\':\n        dbinfo = graph_processing.get_s3dis_info(args)\n    elif args.dataset == \'sema3d\':\n        dbinfo = graph_processing.get_sema3d_info(args)\n    elif args.dataset == \'vkitti\':\n        dbinfo = graph_processing.get_vkitti_info(args)\n    else:\n        raise NotImplementedError(\'Unknown dataset \' + args.dataset)\n    return dbinfo[""classes""]\n\n\ndef process(data_tuple, model, output_folder, training_args, overwrite):\n    fname, edg_source, edg_target, is_transition, labels, objects, clouds_data, xyz = data_tuple\n    spg_file = os.path.join(output_folder, fname[0])\n    logging.info(""\\nGenerating SPG file %s..."", spg_file)\n    if os.path.exists(os.path.dirname(spg_file)) and not overwrite:\n        logging.info(""Already exists, skipping"")\n        return\n    elif not os.path.exists(os.path.dirname(spg_file)):\n        os.makedirs(os.path.dirname(spg_file))\n\n    if training_args.cuda:\n        is_transition = is_transition.to(\'cuda\', non_blocking=True)\n        objects = objects.to(\'cuda\', non_blocking=True)\n        clouds, clouds_global, nei = clouds_data\n        clouds_data = (clouds.to(\'cuda\', non_blocking=True), clouds_global.to(\'cuda\', non_blocking=True), nei)\n\n    ptnCloudEmbedder = get_embedder(training_args)\n    num_classes = get_num_classes(training_args)\n\n    embeddings = ptnCloudEmbedder.run_batch(model, *clouds_data, xyz)\n\n    diff = losses.compute_dist(embeddings, edg_source, edg_target, training_args.dist_type)\n\n    pred_components, pred_in_component = losses.compute_partition(\n        training_args, embeddings, edg_source, edg_target, diff, xyz)\n\n    graph_sp = graphs.compute_sp_graph(xyz, 100, pred_in_component, pred_components, labels, num_classes)\n\n    provider.write_spg(spg_file, graph_sp, pred_components, pred_in_component)\n\n\ndef main():\n    logging.getLogger().setLevel(logging.INFO)  # set to logging.DEBUG to allow for more prints\n    args = parse_args()\n    model, training_args = load_model(args.modeldir, args.cuda)\n    dataloader = get_dataloader(args.input_folder, training_args)\n    workers = max(args.nworkers, 1)\n\n    output_folder = args.output_folder\n    if not output_folder:\n        # By default assumes that it follows the S3DIS folder structure\n        output_folder = os.path.join(args.input_folder, \'../..\', supervized_partition.FolderHierachy.SPG_FOLDER)\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    if logging.getLogger().getEffectiveLevel() > logging.DEBUG:\n        dataloader = tqdm.tqdm(dataloader, ncols=100)\n    with torch.no_grad():\n        processing_function = functools.partial(\n            process, model=model, output_folder=output_folder, training_args=training_args, overwrite=args.overwrite)\n        with Pool(workers) as p:\n            p.map(processing_function, dataloader)\n\n    logging.info(""DONE for %s"" % args.input_folder)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
supervized_partition/graph_processing.py,11,"b'import os\nimport sys\nimport glob\nimport numpy as np\nimport h5py\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport transforms3d\nimport math\nimport igraph\nimport argparse\nfrom timeit import default_timer as timer\nimport torchnet as tnt\nimport functools\nimport argparse\nfrom sklearn.linear_model import RANSACRegressor\nfrom plyfile import PlyData, PlyElement\n\nDIR_PATH = os.path.dirname(os.path.realpath(__file__))\nsys.path.insert(0, os.path.join(DIR_PATH, \'..\'))\nsys.path.insert(0, DIR_PATH)\nsys.path.append(os.path.join(DIR_PATH,""../partition/cut-pursuit/build/src""))\n\nfrom partition.ply_c import libply_c\nimport libcp\n\nfrom learning.spg import augment_cloud\nfrom partition.graphs import *\nfrom partition.provider import *\n\ndef main():\n    parser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\n    \n    parser.add_argument(\'--ROOT_PATH\', default=\'datasets/s3dis\')\n    parser.add_argument(\'--dataset\', default=\'s3dis\')\n    #parameters\n    parser.add_argument(\'--compute_geof\', default=1, type=int, help=\'compute hand-crafted features of the local geometry\')\n    parser.add_argument(\'--k_nn_local\', default=20, type=int, help=\'number of neighbors to describe the local geometry\')\n    parser.add_argument(\'--k_nn_adj\', default=5, type=int, help=\'number of neighbors for the adjacency graph\')\n    parser.add_argument(\'--voxel_width\', default=0.03, type=float, help=\'voxel size when subsampling (in m)\')\n    parser.add_argument(\'--plane_model\', default=1, type=int, help=\'uses a simple plane model to derive elevation\')\n    parser.add_argument(\'--use_voronoi\', default=0.0, type=float, help=\'uses the Voronoi graph in combination to knn to build the adjacency graph, useful for sparse aquisitions. If 0., do not use voronoi. If >0, then is the upper length limit for an edge to be kept. \')\n    parser.add_argument(\'--ver_batch\', default=5000000, type=int, help=\'batch size for reading large files\')\n    args = parser.parse_args()\n    \n    #path to data\n    if args.ROOT_PATH[-1]==\'/\':\n        root = args.ROOT_PATH\n    else:\n        root = args.ROOT_PATH+\'/\'\n        \n    if not os.path.exists(root + \'features_supervision\'):\n        os.makedirs(root + \'features_supervision\')\n    \n    #list of subfolders to be processed\n    if args.dataset == \'s3dis\':\n        folders = [""Area_1/"", ""Area_2/"", ""Area_3/"", ""Area_4/"", ""Area_5/"", ""Area_6/""]\n        n_labels = 13\n    elif args.dataset == \'sema3d\':\n        folders = [""train/"", ""test_reduced/"", ""test_full/""]\n        n_labels = 8\n    elif args.dataset == \'vkitti\':\n        folders = [""01/"", ""02/"",""03/"", ""04/"",""05/"", ""06/""]\n        n_labels = 13 #number of classes\n    elif args.dataset == \'custom_dataset\':\n        folders = [""train/"", ""test/""]\n        n_labels = 10 #number of classes\n    else:\n        raise ValueError(\'%s is an unknown data set\' % args.dataset)\n\n    pruning = args.voxel_width > 0\n    #------------------------------------------------------------------------------\n    for folder in folders:\n        print(""=================\\n   ""+folder+""\\n================="")\n        data_folder = root + ""data/""              + folder\n        str_folder  = root + ""features_supervision/""  + folder\n        \n        if not os.path.isdir(data_folder):\n            raise ValueError(""%s does not exist"" % data_folder)\n           # os.mkdir(data_folder)\n        if not os.path.isdir(str_folder):\n            os.mkdir(str_folder)\n            \n        if args.dataset == \'s3dis\':\n            files = [os.path.join(data_folder, o) for o in os.listdir(data_folder) \n                        if os.path.isdir(os.path.join(data_folder,o))]\n        elif args.dataset == \'sema3d\':\n            files = glob.glob(data_folder + ""*.txt"")\n        elif args.dataset == \'vkitti\':\n            files = glob.glob(data_folder + ""*.npy"")\n            \n        if (len(files) == 0):\n            continue\n            #raise ValueError(\'%s is empty\' % data_folder)\n        n_files = len(files)\n        i_file = 0\n        for file in files:\n            file_name = os.path.splitext(os.path.basename(file))[0]\n            if args.dataset==\'s3dis\':\n                data_file   = data_folder + file_name + \'/\' + file_name + "".txt""\n                str_file    = str_folder       + file_name + \'.h5\'\n            elif args.dataset==\'sema3d\':\n                file_name_short = \'_\'.join(file_name.split(\'_\')[:2])\n                data_file  = data_folder + file_name + "".txt""\n                label_file = data_folder + file_name + "".labels""\n                str_file    = str_folder + file_name_short + \'.h5\'\n            elif args.dataset==\'vkitti\':\n                data_file   = data_folder + file_name + "".npy""\n                str_file    = str_folder  + file_name + \'.h5\'\n            i_file = i_file + 1\n            print(str(i_file) + "" / "" + str(n_files) + ""---> ""+file_name)\n            if os.path.isfile(str_file):\n                print(""    graph structure already computed - delete for update..."")\n            else:\n                #--- build the geometric feature file h5 file ---\n                print(""    computing graph structure..."")\n                #--- read the data files and compute the labels---\n                if args.dataset == \'s3dis\':\n                    xyz, rgb, labels, objects = read_s3dis_format(data_file)\n                    if pruning:\n                        n_objects = int(objects.max()+1)\n                        xyz, rgb, labels, objects = libply_c.prune(xyz, args.voxel_width, rgb, labels, objects, n_labels, n_objects)\n                        #hard_labels = labels.argmax(axis=1)\n                        objects = objects[:,1:].argmax(axis=1)+1\n                    else: \n                    #hard_labels = labels\n                        objects = objects\n                elif args.dataset==\'sema3d\':\n                    has_labels = (os.path.isfile(label_file))\n                    if (has_labels):\n                        xyz, rgb, labels = read_semantic3d_format(data_file, n_labels, label_file, args.voxel_width, args.ver_batch)\n                    else:\n                        xyz, rgb = read_semantic3d_format(data_file, 0, \'\', args.voxel_width, args.ver_batch)\n                        labels = np.array([0])\n                        objects = np.array([0])\n                        is_transition = np.array(False)\n                elif args.dataset == \'vkitti\':\n                    xyz, rgb, labels = read_vkitti_format(data_file)\n                    if pruning:\n                        xyz, rgb, labels, o = libply_c.prune(xyz.astype(\'f4\'), args.voxel_width, rgb.astype(\'uint8\'), labels.astype(\'uint8\'), np.zeros(1, dtype=\'uint8\'), n_labels, 0)\n                    #---compute nn graph-------\n                n_ver = xyz.shape[0]    \n                print(""computing NN structure"")\n                graph_nn, local_neighbors = compute_graph_nn_2(xyz, args.k_nn_adj, args.k_nn_local, voronoi = args.use_voronoi)\n                \n                if args.dataset==\'s3dis\':\n                    is_transition = objects[graph_nn[""source""]]!=objects[graph_nn[""target""]]\n                elif args.dataset==\'sema3d\' and has_labels:\n                    #sema has no object, we make them ourselves with label inpainting\n                    hard_labels = np.argmax(labels[:,1:], 1)+1\n                    no_labels = (labels[:,1:].sum(1)==0).nonzero()\n                    hard_labels[no_labels] = 0\n                    is_transition = hard_labels[graph_nn[""source""]]!=hard_labels[graph_nn[""target""]] * (hard_labels[graph_nn[""source""]]!=0) \\\n                    * (hard_labels[graph_nn[""target""]]!=0)\n                   \n                    edg_source = graph_nn[""source""][(is_transition==0).nonzero()].astype(\'uint32\')\n                    edg_target = graph_nn[""target""][(is_transition==0).nonzero()].astype(\'uint32\')\n                    edge_weight = np.ones_like(edg_source).astype(\'f4\')\n                    node_weight = np.ones((n_ver,),dtype=\'f4\')\n                    node_weight[no_labels] = 0\n                    print(""Inpainting labels"")\n                    dump, objects = libcp.cutpursuit2(np.array(hard_labels).reshape((n_ver,1)).astype(\'f4\'), edg_source, edg_target, edge_weight, node_weight, 0.01)\n                    is_transition = objects[graph_nn[""source""]]!=objects[graph_nn[""target""]]\n                elif args.dataset==\'vkitti\':\n                    #we define the objects as the constant connected components of the labels\n                    hard_labels = np.argmax(labels, 1)\n                    is_transition = hard_labels[graph_nn[""source""]]!=hard_labels[graph_nn[""target""]]\n                    \n                    dump, objects = libply_c.connected_comp(n_ver \\\n                       , graph_nn[""source""].astype(\'uint32\'), graph_nn[""target""].astype(\'uint32\') \\\n                       , (is_transition==0).astype(\'uint8\'), 0)\n                    \n                if (args.compute_geof):\n                    geof = libply_c.compute_geof(xyz, local_neighbors, args.k_nn_local).astype(\'float32\')\n                    geof[:,3] = 2. * geof[:,3]\n                else:\n                    geof = 0\n                \n                if args.plane_model: #use a simple palne model to the compute elevation\n                    low_points = ((xyz[:,2]-xyz[:,2].min() < 0.5)).nonzero()[0]\n                    reg = RANSACRegressor(random_state=0).fit(xyz[low_points,:2], xyz[low_points,2])\n                    elevation = xyz[:,2]-reg.predict(xyz[:,:2])\n                else:\n                    elevation = xyz[:,2] - xyz[:,2].min()\n                \n                #compute the xy normalized position\n                ma, mi = np.max(xyz[:,:2],axis=0,keepdims=True), np.min(xyz[:,:2],axis=0,keepdims=True)\n                xyn = (xyz[:,:2] - mi) / (ma - mi + 1e-8) #global position\n                    \n                write_structure(str_file, xyz, rgb, graph_nn, local_neighbors.reshape([n_ver, args.k_nn_local]), \\\n                    is_transition, labels, objects, geof, elevation, xyn)\n                    \n#------------------------------------------------------------------------------\n\n#------------------------------------------------------------------------------\ndef write_structure(file_name, xyz, rgb, graph_nn, target_local_geometry, is_transition, labels, objects, geof, elevation, xyn):\n    """"""\n    save the input point cloud in a format ready for embedding    \n    """"""\n    #store transition and non-transition edges in two different contiguous memory blocks\n    #n_transition = np.count_nonzero(is_transition)\n    #blocks = np.hstack((np.where(is_transition),np.where(is_transition==False)))\n    \n    data_file = h5py.File(file_name, \'w\')\n    data_file.create_dataset(\'xyz\', data=xyz, dtype=\'float32\')\n    data_file.create_dataset(\'rgb\', data=rgb, dtype=\'float32\')\n    data_file.create_dataset(\'elevation\', data=elevation, dtype=\'float32\')\n    data_file.create_dataset(\'xyn\', data=xyn, dtype=\'float32\')\n    data_file.create_dataset(\'source\', data=graph_nn[""source""], dtype=\'int\')\n    data_file.create_dataset(\'target\', data=graph_nn[""target""], dtype=\'int\')\n    data_file.create_dataset(\'is_transition\', data=is_transition, dtype=\'uint8\')\n    data_file.create_dataset(\'target_local_geometry\', data=target_local_geometry, dtype=\'uint32\')\n    data_file.create_dataset(\'objects\', data=objects, dtype=\'uint32\')\n    if (len(geof)>0):        \n        data_file.create_dataset(\'geof\', data=geof, dtype=\'float32\')\n    if len(labels) > 0 and len(labels.shape)>1 and labels.shape[1]>1:\n        data_file.create_dataset(\'labels\', data=labels, dtype=\'int32\')\n    else:\n        data_file.create_dataset(\'labels\', data=labels, dtype=\'uint8\')\n\n#------------------------------------------------------------------------------\ndef read_structure(file_name, read_geof):\n    """"""\n    read the input point cloud in a format ready for embedding    \n    """"""\n    data_file = h5py.File(file_name, \'r\')\n    xyz = np.array(data_file[\'xyz\'], dtype=\'float32\')\n    rgb = np.array(data_file[\'rgb\'], dtype=\'float32\')\n    elevation = np.array(data_file[\'elevation\'], dtype=\'float32\')\n    xyn = np.array(data_file[\'xyn\'], dtype=\'float32\')\n    edg_source = np.array(data_file[\'source\'], dtype=\'int\').squeeze()\n    edg_target = np.array(data_file[\'target\'], dtype=\'int\').squeeze()\n    is_transition = np.array(data_file[\'is_transition\'])\n    objects = np.array(data_file[\'objects\'][()])\n    labels = np.array(data_file[\'labels\']).squeeze()\n    if len(labels.shape) == 0:#dirty fix\n        labels = np.array([0])\n    if len(is_transition.shape) == 0:#dirty fix\n        is_transition = np.array([0])\n    if read_geof: #geometry = geometric features\n        local_geometry = np.array(data_file[\'geof\'], dtype=\'float32\')\n    else: #geometry = neighborhood structure\n        local_geometry = np.array(data_file[\'target_local_geometry\'], dtype=\'uint32\')\n    \n    return xyz, rgb, edg_source, edg_target, is_transition, local_geometry, labels, objects, elevation, xyn\n#------------------------------------------------------------------------------\ndef get_s3dis_info(args):\n    #for now, no edge attributes\n    return {\n        \'classes\': 13,\n        \'inv_class_map\': {0:\'ceiling\', 1:\'floor\', 2:\'wall\', 3:\'column\', 4:\'beam\', 5:\'window\', 6:\'door\', 7:\'table\', 8:\'chair\', 9:\'bookcase\', 10:\'sofa\', 11:\'board\', 12:\'clutter\'},\n    }\n    \ndef get_sema3d_info(args):\n    #for now, no edge attributes\n    return {\n        \'classes\': 8,\n        \'inv_class_map\': {0:\'road\', 1:\'grass\', 2:\'tree\', 3:\'bush\', 4:\'building\', 5:\'hardscape\', 6:\'artifacts\', 7:\'car\', 8:\'chair\'},\n    }\n    \ndef get_vkitti_info(args):\n    #for now, no edge attributes\n    return {\n        \'classes\': 13,\n        \'inv_class_map\': {0:\'Terrain\', 1:\'Tree\', 2:\'Vegetation\', 3:\'Building\', 4:\'Road\', 5:\'GuardRail\', 6:\'TrafficSign\', 7:\'TrafficLight\', 8:\'Pole\', 9:\'Misc\', 10:\'Truck\', 11:\'Car\', 12:\'Van\', 13:\'None\'},\n    }\n    \n    \n                \ndef create_s3dis_datasets(args, test_seed_offset=0):\n    """""" Gets training and test datasets. """"""\n    # Load formatted clouds\n    testlist, trainlist = [], []\n    for n in range(1,7):\n        if n != args.cvfold:\n            path = \'{}/features_supervision/Area_{:d}/\'.format(args.ROOT_PATH, n)\n            for fname in sorted(os.listdir(path)):\n                if fname.endswith("".h5""):\n                    trainlist.append(path+fname)\n    path = \'{}/features_supervision/Area_{:d}/\'.format(args.ROOT_PATH, args.cvfold)\n    for fname in sorted(os.listdir(path)):\n        if fname.endswith("".h5""):\n            testlist.append(path+fname)\n           \n    return tnt.dataset.ListDataset(trainlist,\n                                   functools.partial(graph_loader, train=True, args=args, db_path=args.ROOT_PATH)), \\\n           tnt.dataset.ListDataset(testlist,\n                                   functools.partial(graph_loader, train=False, args=args, db_path=args.ROOT_PATH))\n\ndef create_vkitti_datasets(args, test_seed_offset=0):\n    """""" Gets training and test datasets. """"""\n    # Load formatted clouds\n    testlist, trainlist = [], []\n    for n in range(1,7):\n        if n != args.cvfold:\n            path = \'{}/features_supervision/0{:d}/\'.format(args.ROOT_PATH, n)\n            for fname in sorted(os.listdir(path)):\n                if fname.endswith("".h5""):\n                    trainlist.append(path+fname)\n    path = \'{}/features_supervision/0{:d}/\'.format(args.ROOT_PATH, args.cvfold)\n    for fname in sorted(os.listdir(path)):\n        if fname.endswith("".h5""):\n            testlist.append(path+fname)\n           \n    return tnt.dataset.ListDataset(trainlist,\n                                   functools.partial(graph_loader, train=True, args=args, db_path=args.ROOT_PATH)), \\\n           tnt.dataset.ListDataset(testlist,\n                                   functools.partial(graph_loader, train=False, args=args, db_path=args.ROOT_PATH))\n           \ndef create_sema3d_datasets(args, test_seed_offset=0):\n    """""" Gets training and test datasets. """"""\n    \n    train_names = [\'bildstein_station1\', \'bildstein_station5\', \'domfountain_station1\', \'domfountain_station3\', \'neugasse_station1\', \'sg27_station1\', \'sg27_station2\', \'sg27_station5\', \'sg27_station9\', \'sg28_station4\', \'untermaederbrunnen_station1\']\n    valid_names = [\'bildstein_station3\', \'domfountain_station2\', \'sg27_station4\', \'untermaederbrunnen_station3\']\n    #train_names = [\'bildstein_station1\', \'domfountain_station1\', \'untermaederbrunnen_station1\']\n    #valid_names = [\'domfountain_station2\', \'untermaederbrunnen_station3\']\n\n    path = \'{}/features_supervision/\'.format(args.ROOT_PATH)\n\n    if args.db_train_name == \'train\':\n        trainlist = [path + \'train/\' + f + \'.h5\' for f in train_names]\n    elif args.db_train_name == \'trainval\':\n        trainlist = [path + \'train/\' + f + \'.h5\' for f in train_names + valid_names]\n\n    testlist = []\n    if \'train\' in args.db_test_name:\n        testlist += [path + \'train/\' + f + \'.h5\' for f in train_names]\n    if \'val\' in args.db_test_name:\n        testlist += [path + \'train/\' + f + \'.h5\' for f in valid_names]\n    if \'testred\' in args.db_test_name:\n        testlist += [f for f in glob.glob(path + \'test_reduced/*.h5\')]\n    if \'testfull\' in args.db_test_name:\n        testlist += [f for f in glob.glob(path + \'test_full/*.h5\')]\n    \n    \n    return tnt.dataset.ListDataset(trainlist,\n                                   functools.partial(graph_loader, train=True, args=args, db_path=args.ROOT_PATH)), \\\n           tnt.dataset.ListDataset(testlist,\n                                   functools.partial(graph_loader, train=False, args=args, db_path=args.ROOT_PATH, full_cpu = True))\n\ndef subgraph_sampling(n_ver, edg_source, edg_target, max_ver):\n    """""" Select a subgraph of the input graph of max_ver verices""""""\n    return libply_c.random_subgraph(n_ver)\n\ndef graph_loader(entry, train, args, db_path, test_seed_offset=0, full_cpu = False):\n    """""" Load the point cloud and the graph structure """"""\n    xyz, rgb, edg_source, edg_target, is_transition, local_geometry\\\n        , labels, objects, elevation, xyn = read_structure(entry, \'geof\' in args.ver_value)\n    short_name= entry.split(os.sep)[-2]+\'/\'+entry.split(os.sep)[-1]\n\n    rgb = rgb/255\n\n    n_ver = np.shape(xyz)[0]\n    n_edg = np.shape(edg_source)[0]\n    \n    selected_ver = np.full((n_ver,), True, dtype=\'?\')\n    selected_edg = np.full((n_edg,), True, dtype=\'?\')\n    \n    if train:\n        xyz, rgb = augment_cloud_whole(args, xyz, rgb)\n        \n    subsample = False\n    new_ver_index = []\n\n    if train and (0<args.max_ver_train<n_ver):\n        \n        subsample = True\n            \n        selected_edg, selected_ver = libply_c.random_subgraph(n_ver, edg_source.astype(\'uint32\'), edg_target.astype(\'uint32\'), int(args.max_ver_train))\n        selected_edg = selected_edg.astype(\'?\')\n        selected_ver = selected_ver.astype(\'?\')\n            \n        new_ver_index = -np.ones((n_ver,), dtype = int)\n        new_ver_index[selected_ver.nonzero()] = range(selected_ver.sum())\n            \n        edg_source = new_ver_index[edg_source[selected_edg.astype(\'?\')]]\n        edg_target = new_ver_index[edg_target[selected_edg.astype(\'?\')]]\n            \n        is_transition = is_transition[selected_edg]\n        labels = labels[selected_ver,]\n        objects = objects[selected_ver,]\n        elevation = elevation[selected_ver]\n        xyn = xyn[selected_ver,]\n       \n    if args.learned_embeddings:\n        #we use point nets to embed the point clouds\n        nei = local_geometry[selected_ver,:args.k_nn_local].astype(\'int64\')\n        \n        clouds, clouds_global = [], [] #clouds_global is cloud global features. here, just the diameter + elevation\n        \n        clouds = xyz[nei,]\n        #diameters = np.max(np.max(clouds,axis=1) - np.min(clouds,axis=1), axis = 1)\n        diameters = np.sqrt(clouds.var(1).sum(1))\n        clouds = (clouds - xyz[selected_ver,np.newaxis,:]) / (diameters[:,np.newaxis,np.newaxis] + 1e-10)\n        \n        if args.use_rgb:\n            clouds = np.concatenate([clouds, rgb[nei,]],axis=2)\n        \n        clouds = clouds.transpose([0,2,1])\n        \n        clouds_global = diameters[:,None]\n        if \'e\' in args.global_feat:\n            clouds_global = np.hstack((clouds_global, elevation[:,None]))\n        if \'rgb\' in args.global_feat:\n            clouds_global = np.hstack((clouds_global, rgb[selected_ver,]))\n        if \'XY\' in args.global_feat:\n            clouds_global = np.hstack((clouds_global, xyn))\n        if \'xy\' in args.global_feat:\n            clouds_global = np.hstack((clouds_global, xyz[selected_ver,:2]))\n        #clouds_global = np.hstack((diameters[:,None], ((xyz[selected_ver,2] - min_z) / (max_z- min_z)-0.5)[:,None],np.zeros_like(rgb[selected_ver,])))\n\n        #clouds_global = np.vstack((diameters, xyz[selected_ver,2])).T\n    elif args.ver_value == \'geofrgb\':\n        #the embeddings are already computed\n        clouds = np.concatenate([local_geometry, rgb[selected_ver,]],axis=1)\n        clouds_global = np.array([0])\n        nei = np.array([0])\n    elif args.ver_value == \'geof\':\n        #the embeddings are already computed\n        clouds = local_geometry\n        clouds_global = np.array([0])\n        nei = np.array([0])\n    \n    n_edg_selected = selected_edg.sum()\n    \n    nei = np.array([0])\n    \n    xyz = xyz[selected_ver,]\n    is_transition = torch.from_numpy(is_transition)\n    #labels = torch.from_numpy(labels)\n    objects = torch.from_numpy(objects.astype(\'int64\'))\n    clouds = torch.from_numpy(clouds)\n    clouds_global = torch.from_numpy(clouds_global)\n    return short_name, edg_source, edg_target, is_transition, labels, objects, clouds, clouds_global, nei, xyz\n#------------------------------------------------------------------------------\n#------------------------------------------------------------------------------\ndef graph_collate(batch):\n    """""" Collates a list of dataset samples into a single batch\n    """"""\n    short_name, edg_source, edg_target, is_transition, labels, objects, clouds, clouds_global, nei, xyz = list(zip(*batch))\n\n    n_batch = len(short_name)\n    batch_ver_size_cumsum = np.array([c.shape[0] for c in labels]).cumsum()\n    batch_n_edg_cumsum = np.array([c.shape[0] for c in edg_source]).cumsum()\n    batch_n_objects_cumsum = np.array([c.max() for c in objects]).cumsum()\n    \n    \n    clouds = torch.cat(clouds, 0)\n    clouds_global = torch.cat(clouds_global, 0)\n    xyz = np.vstack(xyz)\n    #if len(is_transition[0])>1:\n    is_transition = torch.cat(is_transition, 0)\n    labels = np.vstack(labels)\n    \n    edg_source = np.hstack(edg_source)\n    edg_target = np.hstack(edg_target)\n    nei = np.vstack(nei)\n    #if len(is_transition[0]>1:\n    objects = torch.cat(objects, 0)\n    \n    for i_batch in range(1,n_batch):\n        edg_source[batch_n_edg_cumsum[i_batch-1]:batch_n_edg_cumsum[i_batch]] += int(batch_ver_size_cumsum[i_batch-1])\n        edg_target[batch_n_edg_cumsum[i_batch-1]:batch_n_edg_cumsum[i_batch]] += int(batch_ver_size_cumsum[i_batch-1])\n        #if len(objects)>1:\n        objects[batch_ver_size_cumsum[i_batch-1]:batch_ver_size_cumsum[i_batch],] += int(batch_n_objects_cumsum[i_batch-1])\n        non_valid = (nei[batch_ver_size_cumsum[i_batch-1]:batch_ver_size_cumsum[i_batch],]==-1).nonzero()\n        nei[batch_ver_size_cumsum[i_batch-1]:batch_ver_size_cumsum[i_batch],] += int(batch_ver_size_cumsum[i_batch-1])\n        nei[batch_ver_size_cumsum[i_batch-1]+non_valid[0],non_valid[1]] = -1\n\n    return short_name, edg_source, edg_target, is_transition, labels, objects, (clouds, clouds_global, nei), xyz\n#------------------------------------------------------------------------------\ndef show(clouds,k):\n    from mpl_toolkits.mplot3d import Axes3D    \n    import matplotlib.pyplot as plt    \n    fig = plt.figure()    \n    ax = fig.gca(projection=\'3d\') \n    ax.scatter(clouds[k,:,0], clouds[k,:,1], clouds[k,:,2])\n    plt.show()\n\n#------------------------------------------------------------------------------\ndef read_embeddings(file_name):\n    """"""\n    read the input point cloud in a format ready for embedding    \n    """"""\n    data_file = h5py.File(file_name, \'r\')\n    if \'embeddings\' in data_file:\n        embeddings = np.array(data_file[\'embeddings\'], dtype=\'float32\')\n    else:\n        embeddings = []\n    if \'edge_weight\' in data_file:\n        edge_weight = np.array(data_file[\'edge_weight\'], dtype=\'float32\')\n    else:\n        edge_weight = []\n    return embeddings, edge_weight\n#------------------------------------------------------------------------------\ndef write_embeddings(file_name, args, embeddings, edge_weight=[]):\n    """"""\n    save the embeddings and the edge weights \n    """"""\n    folder = args.ROOT_PATH + \'/embeddings\' + args.suffix + \'/\' +file_name.split(\'/\')[0]\n    if not os.path.isdir(folder):\n        os.mkdir(folder)\n    file_path = args.ROOT_PATH + \'/embeddings\' + args.suffix + \'/\' + file_name\n    if os.path.isfile(file_path):\n        data_file = h5py.File(file_path, \'r+\')\n    else:\n        data_file = h5py.File(file_path, \'w\')\n    if len(embeddings)>0  and not \'embeddings\' in data_file:\n        data_file.create_dataset(\'embeddings\'\n                                 , data=embeddings, dtype=\'float32\')\n    elif len(embeddings)>0:\n            data_file[\'embeddings\'][...] = embeddings\n            \n    if len(edge_weight)>0 and not \'edge_weight\' in data_file:\n        data_file.create_dataset(\'edge_weight\', data=edge_weight, dtype=\'float32\')\n    elif len(edge_weight)>0:\n            data_file[\'edge_weight\'][...] = edge_weight\n    data_file.close()\n#------------------------------------------------------------------------------\ndef augment_cloud_batch(clouds, args):\n    """""""" Augmentation on XYZ and jittering of everything """"""\n    if args.pc_augm_rot:\n        angle = np.random.uniform(0,2*math.pi, size=clouds.shape[0])\n        M = np.array([transforms3d.axangles.axangle2mat([0,0,1],t) for t in angle])\n        clouds[:,:,:3] = np.matmul(clouds[:,:,:3], M)\n\n    if args.pc_augm_jitter:\n        sigma, clip= 0.001, 0.003 # https://github.com/charlesq34/pointnet/blob/master/provider.py#L74\n        #clouds = clouds + np.clip(sigma * np.random.standard_normal(clouds.shape), -1*clip, clip).astype(np.float32)\n    return clouds\n#------------------------------------------------------------------------------\ndef augment_cloud_whole(args, xyz, rgb):\n    """""""" rotate the whole graph, add jitter """"""\n    if args.pc_augm_rot:\n        ref_point = xyz[np.random.randint(xyz.shape[0]),:3]\n        ref_point[2] = 0\n        M = transforms3d.axangles.axangle2mat([0,0,1],np.random.uniform(0,2*math.pi)).astype(\'f4\')\n        xyz = np.matmul(xyz[:,:3]-ref_point, M)+ref_point\n    if args.pc_augm_jitter: #add jitter\n        sigma, clip= 0.002, 0.005 # https://github.com/charlesq34/pointnet/blob/master/provider.py#L74\n        xyz = xyz + np.clip(sigma * np.random.standard_normal(xyz.shape), -1*clip, clip).astype(np.float32)\n        if args.use_rgb:\n            rgb = np.clip(rgb + np.clip(sigma * np.random.standard_normal(xyz.shape), -1*clip, clip).astype(np.float32),-1,1)\n    return xyz, rgb\n#------------------------------------------------------------------------------\nclass spatialEmbedder():\n    """""" \n    Hand-crafted embeding of point cloud\n    """"""\n    def __init__(self, args):\n        self.args = args\n\n    def run_batch(self, model, clouds, *excess):\n        """"""return clouds which should contain the embeddings""""""\n        if self.args.cuda:\n            return (clouds.cuda())\n        else:\n            return (clouds)\nif __name__ == ""__main__"": \n    main()\n'"
supervized_partition/losses.py,10,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n""""""\nCreated on Wed Sep 26 13:56:33 2018\n\n@author: landrieuloic\n\n""""""\nimport os\nimport sys\nimport math\nimport numpy as np\nimport torch\n\nDIR_PATH = os.path.dirname(os.path.realpath(__file__))\nsys.path.insert(0, os.path.join(DIR_PATH, \'..\'))\nsys.path.append(os.path.join(DIR_PATH,""../partition/cut-pursuit/src""))\n\nfrom partition.provider import *\nfrom partition.ply_c import libply_c \n\nimport libcp\n\ndef zhang(x, lam, dist_type):\n    if dist_type == \'euclidian\' or dist_type == \'scalar\':\n       beta = 1\n    elif dist_type == \'intrinsic\':\n        beta = 1.0471975512\n    return torch.clamp(-lam * x + lam * beta, min = 0)\n\ndef compute_dist(embeddings, edg_source, edg_target, dist_type):\n    if dist_type == \'euclidian\':\n        dist = ((embeddings[edg_source,:] - embeddings[edg_target,:])**2).sum(1)\n    elif dist_type == \'intrinsic\':\n        smoothness = 0.999\n        dist = (torch.acos((embeddings[edg_source,:] * embeddings[edg_target,:]).sum(1) * smoothness)-np.arccos(smoothness)) \\\n           / (np.arccos(-smoothness)-np.arccos(smoothness)) * 3.141592\n    elif dist_type == \'scalar\':\n        dist = (embeddings[edg_source,:] * embeddings[edg_target,:]).sum(1)-1\n    else:\n        raise ValueError("" %s is an unknown argument of parameter --dist_type"" % (dist_type))\n    return dist\n\ndef compute_loss(args, diff, is_transition, weights_loss):\n    intra_edg = is_transition==0\n    if \'tv\' in args.loss:\n        loss1 =  (weights_loss[intra_edg] * (torch.sqrt(diff[intra_edg]+1e-10))).sum()\n    elif \'laplacian\' in args.loss:\n        loss1 =  (weights_loss[intra_edg] * (diff[intra_edg])).sum()\n    elif \'TVH\' in args.loss:\n        delta = 0.2\n        loss1 =  delta * (weights_loss[intra_edg] * (torch.sqrt(1+diff[intra_edg]/delta**2)-1)).sum()\n    else:\n        raise ValueError("" %s is an unknown argument of parameter --loss"" % (args.loss))\n        \n    inter_edg = is_transition==1\n    \n    if \'zhang\' in args.loss:\n        loss2 = (zhang(torch.sqrt(diff[inter_edg]+1e-10), weights_loss[inter_edg], args.dist_type)).sum()\n    elif \'TVminus\' in args.loss:\n        loss2 = (torch.sqrt(diff[inter_edg]+1e-10) * weights_loss[inter_edg]).sum()\n \n    #return loss1/ weights_loss.sum(), loss2/ weights_loss.sum()\n    return loss1, loss2\n\n\ndef compute_partition(args, embeddings, edg_source, edg_target, diff, xyz=0):\n    edge_weight = np.ones_like(edg_source).astype(\'f4\')\n    if args.edge_weight_threshold>0:\n        edge_weight[diff>1]=args.edge_weight_threshold\n    if args.edge_weight_threshold<0:\n        edge_weight = torch.exp(diff * args.edge_weight_threshold).detach().cpu().numpy()/np.exp(args.edge_weight_threshold)\n\n    ver_value = np.zeros((embeddings.shape[0],0), dtype=\'f4\')\n    use_spatial = 0\n    ver_value = np.hstack((ver_value,embeddings.detach().cpu().numpy()))\n    if args.spatial_emb>0:\n        ver_value = np.hstack((ver_value, args.spatial_emb * xyz))# * math.sqrt(args.reg_strength)))\n        #ver_value = xyz * args.spatial_emb\n        use_spatial = 1#!!!\n        \n    pred_components, pred_in_component = libcp.cutpursuit(ver_value, \\\n        edg_source.astype(\'uint32\'), edg_target.astype(\'uint32\'), edge_weight, \\\n        args.reg_strength / (4 * args.k_nn_adj), cutoff=args.CP_cutoff, spatial = use_spatial, weight_decay = 0.7)\n    #emb2 = libcp.cutpursuit2(ver_value, edg_source.astype(\'uint32\'), edg_target.astype(\'uint32\'), edge_weight, args.reg_strength, cutoff=0, spatial =0)\n    #emb2 = emb2.reshape(ver_value.shape)\n    #((ver_value-emb2)**2).sum(0)\n    #cut = pred_in_component[edg_source]!=pred_in_component[edg_target]\n    return pred_components, pred_in_component\n\ndef compute_weight_loss(args, embeddings, objects, edg_source, edg_target, is_transition, diff, return_partition, xyz=0):\n    \n    if args.loss_weight == \'seal\' or args.loss_weight == \'crosspartition\' or return_partition:\n        pred_components, pred_in_component = compute_partition(args, embeddings, edg_source, edg_target, diff, xyz)\n\n    if args.loss_weight==\'none\':\n        weights_loss = np.ones_like(edg_target).astype(\'f4\')\n    elif args.loss_weight==\'proportional\':\n        weights_loss = np.ones_like(edg_target).astype(\'f4\') * float(len(is_transition)) / (1-is_transition).sum().float()\n        weights_loss[is_transition.nonzero()] = float(len(is_transition)) / float(is_transition.sum()) * args.transition_factor\n        weights_loss = weights_loss.cpu().numpy()\n    elif args.loss_weight==\'seal\':\n        weights_loss = compute_weights_SEAL(pred_components, pred_in_component, objects, edg_source, edg_target, is_transition, args.transition_factor)\n    elif args.loss_weight==\'crosspartition\':\n        weights_loss = compute_weights_XPART(pred_components, pred_in_component, objects.cpu().numpy(), edg_source, edg_target, is_transition.cpu().numpy(), args.transition_factor * 2 * args.k_nn_adj, xyz)\n    else:\n        raise ValueError("" %s is an unknown argument of parameter --loss"" % (args.loss_weight))       \n\n    if args.cuda:\n        weights_loss = torch.from_numpy(weights_loss).cuda()\n    else:\n        weights_loss = torch.from_numpy(weights_loss)\n    \n    if return_partition:\n        return weights_loss, pred_components, pred_in_component\n    else:\n        return weights_loss\n\ndef compute_weights_SEAL(pred_components, pred_in_component, objects, edg_source, edg_target, is_transition, transition_factor):\n    \n    SEAL_weights = np.ones((len(edg_source),), dtype=\'float32\')\n    w_per_component = np.empty((len(pred_components),), dtype=\'uint32\')\n    for i_com in range(len(pred_components)):\n        w_per_component[i_com] = len(pred_components[i_com]) - mode(objects[pred_components[i_com]], only_frequency=True)\n    SEAL_weights[is_transition.nonzero()] += np.stack(\\\n                (w_per_component[pred_in_component[edg_source[is_transition.nonzero()]]]\n            ,   w_per_component[pred_in_component[edg_target[is_transition.nonzero()]]])).max(0)  * transition_factor# 1 if not transition 1+w otherwise\n    return SEAL_weights\n\ndef compute_weights_XPART(pred_components, pred_in_component, objects, edg_source, edg_target, is_transition, transition_factor, xyz):\n\n    SEAGL_weights = np.ones((len(edg_source),), dtype=\'float32\')\n    pred_transition = pred_in_component[edg_source]!=pred_in_component[edg_target]\n    components_x, in_component_x = libply_c.connected_comp(pred_in_component.shape[0] \\\n           , edg_source.astype(\'uint32\'), edg_target.astype(\'uint32\') \\\n           , (is_transition+pred_transition==0).astype(\'uint8\'), 0)\n    \n    edg_transition = is_transition.nonzero()[0]\n    edg_source_trans = edg_source[edg_transition]\n    edg_target_trans = edg_target[edg_transition]\n    \n    comp_x_weight = [len(c) for c in components_x]\n    n_compx = len(components_x)\n    \n    edg_id = np.min((in_component_x[edg_source_trans],in_component_x[edg_target_trans]),0) * n_compx \\\n           + np.max((in_component_x[edg_source_trans],in_component_x[edg_target_trans]),0)\n    \n    edg_id_unique , in_edge_id, sedg_weight = np.unique(edg_id, return_index=True, return_counts=True)\n    \n    for i_edg in range(len(in_edge_id)):\n            i_com_1 = in_component_x[edg_source_trans[in_edge_id[i_edg]]]\n            i_com_2 = in_component_x[edg_target_trans[in_edge_id[i_edg]]]\n            weight = min(comp_x_weight[i_com_1], comp_x_weight[i_com_2]) \\\n                   / sedg_weight[i_edg] * transition_factor\n            corresponding_trans_edg = edg_transition[\\\n                ((in_component_x[edg_source_trans]==i_com_1) * (in_component_x[edg_target_trans]==i_com_2) \\\n              + (in_component_x[edg_target_trans]==i_com_1) * (in_component_x[edg_source_trans]==i_com_2))]\n            SEAGL_weights[corresponding_trans_edg] = SEAGL_weights[corresponding_trans_edg] + weight\n        \n    #missed_transition = ((is_transition==1)*(pred_transition==False)+(is_transition==0)*(pred_transition==True)).nonzero()[0]\n    #missed_transition = ((is_transition==1)*(pred_transition==False)).nonzero()[0]\n    #SEAGL_weights[missed_transition] = SEAGL_weights[missed_transition] * boosting_factor\n    #scalar2ply(\'full_par.ply\', xyz,pred_in_component)\n    #scalar2ply(\'full_parX.ply\', xyz,in_component_x)\n    #edge_weight2ply2(\'w.ply\', SEAGL_weights, xyz, edg_source, edg_target)\n    return SEAGL_weights\n\ndef mode(array, only_frequency=False):\n    """"""compute the mode and the corresponding frequency of a given distribution""""""\n    u, counts = np.unique(array, return_counts=True)\n    if only_frequency: return np.amax(counts)\n    else:\n        return u[np.argmax(counts)], np.amax(counts)\n    \ndef relax_edge_binary(edg_binary, edg_source, edg_target, n_ver, tolerance):\n    if torch.is_tensor(edg_binary):\n        relaxed_binary = edg_binary.cpu().numpy().copy()\n    else:\n        relaxed_binary = edg_binary.copy()\n    transition_vertex = np.full((n_ver,), 0, dtype = \'uint8\')\n    for i_tolerance in range(tolerance):\n        transition_vertex[edg_source[relaxed_binary.nonzero()]] = True\n        transition_vertex[edg_target[relaxed_binary.nonzero()]] = True\n        relaxed_binary[transition_vertex[edg_source]] = True\n        relaxed_binary[transition_vertex[edg_target]>0] = True\n    return relaxed_binary\n\n'"
supervized_partition/supervized_partition.py,16,"b'# -*- coding: utf-8 -*-\n""""""\nCreated on Tue Feb 27 10:26:49 2018\n@author: landrieuloic\n""""""\nimport os\nimport sys\nimport ast\nimport h5py\nimport numpy as np\nimport random\n\nimport time\nimport logging\nimport argparse   \nimport json\nimport math\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import MultiStepLR\nimport torchnet as tnt\n\nDIR_PATH = os.path.dirname(os.path.realpath(__file__))\nsys.path.insert(0, os.path.join(DIR_PATH, \'..\'))\n\nfrom partition.ply_c import libply_c\n\nfrom learning.pointnet import STNkD\nfrom learning.pointnet import LocalCloudEmbedder\nfrom learning.pointnet import PointNet\n\nfrom supervized_partition.graph_processing import *\nfrom partition.provider import embedding2ply\nfrom partition.provider import scalar2ply\nfrom partition.provider import edge_class2ply2\nfrom partition.provider import perfect_prediction\nfrom partition.provider import write_spg\n\nfrom learning.metrics import compute_OOA\nfrom learning.metrics import compute_boundary_precision\nfrom learning.metrics import compute_boundary_recall\n\nfrom supervized_partition.losses import compute_weight_loss\nfrom supervized_partition.losses import compute_partition\nfrom supervized_partition.losses import relax_edge_binary\nfrom supervized_partition.losses import compute_loss\nfrom supervized_partition.losses import compute_dist\n\nfrom learning import metrics\nfrom partition.graphs import compute_sp_graph\nfrom learning.main import create_optimizer\nfrom folderhierarchy import FolderHierachy\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\'Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs\')\n    # Dataset\n    parser.add_argument(\'--dataset\', default=\'s3dis\', help=\'Dataset name: sema3d|s3dis|vkitti\')\n    parser.add_argument(\'--cvfold\', default=1, type=int, help=\'Fold left-out for testing in leave-one-out setting (S3DIS)\')\n    parser.add_argument(\'--resume\', default=\'\', help=\'Loads a previously saved model.\')\n    parser.add_argument(\'--db_train_name\', default=\'trainval\', help=\'Training set (Sema3D)\')\n    parser.add_argument(\'--db_test_name\', default=\'testred\', help=\'Test set (Sema3D)\')\n    parser.add_argument(\'--ROOT_PATH\', default=\'datasets/s3dis\')\n    parser.add_argument(\'--odir\', default=\'results_emb/s3dis\', help=\'folder for saving the trained model\')\n    parser.add_argument(\'--spg_out\', default=1, type=int, help=\'wether to compute the SPG for linking with the SPG semantic segmentation method\')\n    \n    # Learning process arguments\n    parser.add_argument(\'--cuda\', default=1, type=int, help=\'Bool, use cuda\')\n    parser.add_argument(\'--nworkers\', default=0, type=int, help=\'Num subprocesses to use for data loading. 0 means that the data will be loaded in the main process\')\n    parser.add_argument(\'--test_nth_epoch\', default=10, type=int, help=\'Test each n-th epoch during training\')\n    parser.add_argument(\'--save_nth_epoch\', default=1, type=int, help=\'Save model each n-th epoch during training\')\n    parser.add_argument(\'--test_multisamp_n\', default=10, type=int, help=\'Average logits obtained over runs with different seeds\')\n    # Optimization arguments\n    parser.add_argument(\'--wd\', default=0, type=float, help=\'Weight decay\')\n    parser.add_argument(\'--lr\', default=1e-2, type=float, help=\'Initial learning rate\')\n    parser.add_argument(\'--lr_decay\', default=0.7, type=float, help=\'Multiplicative factor used on learning rate at `lr_steps`\')\n    parser.add_argument(\'--lr_steps\', default=\'[20,35,45]\', help=\'List of epochs where the learning rate is decreased by `lr_decay`\')\n    parser.add_argument(\'--momentum\', default=0.9, type=float, help=\'Momentum\')\n    parser.add_argument(\'--epochs\', default=20, type=int, help=\'Number of epochs to train. If <=0, only testing will be done.\')\n    parser.add_argument(\'--batch_size\', default=5, type=int, help=\'Batch size\')\n    parser.add_argument(\'--optim\', default=\'adam\', help=\'Optimizer: sgd|adam\')\n    parser.add_argument(\'--grad_clip\', default=1, type=float, help=\'Element-wise clipping of gradient. If 0, does not clip\')\n    # Point cloud processing\n    parser.add_argument(\'--pc_attribs\', default=\'\', help=\'Point attributes fed to PointNets, if empty then all possible.\')\n    parser.add_argument(\'--pc_augm_scale\', default=2, type=float, help=\'Training augmentation: Uniformly random scaling in [1/scale, scale]\')\n    parser.add_argument(\'--pc_augm_rot\', default=1, type=int, help=\'Training augmentation: Bool, random rotation around z-axis\')\n    parser.add_argument(\'--pc_augm_mirror_prob\', default=0, type=float, help=\'Training augmentation: Probability of mirroring about x or y axes\')\n    parser.add_argument(\'--pc_augm_jitter\', default=1, type=int, help=\'Training augmentation: Bool, Gaussian jittering of all attributes\')\n    # Point net\n    parser.add_argument(\'--ptn_embedding\', default=\'ptn\', help=\'configuration of the learned cloud emebdder (ptn): uses PointNets for vertices embeddings. no other options so far :)\')\n    parser.add_argument(\'--ptn_widths\', default=\'[[32,128], [34,32,32,4]]\', help=\'PointNet widths\')\n    parser.add_argument(\'--ptn_widths_stn\', default=\'[[16,64],[32,16]]\', help=\'PointNet\\\'s Transformer widths\')\n    parser.add_argument(\'--use_color\', default=\'rgb\', help=\'How to use color in the local cloud embedding : rgb, lab or no\')\n    parser.add_argument(\'--ptn_nfeat_stn\', default=2, type=int, help=\'PointNet\\\'s Transformer number of input features\')\n    parser.add_argument(\'--ptn_prelast_do\', default=0, type=float)\n    parser.add_argument(\'--ptn_norm\', default=\'batch\', help=\'Type of norm layers in PointNets, ""batch or ""layer"" or ""group""\')\n    parser.add_argument(\'--ptn_n_group\', default=2, type=int, help=\'Number of groups in groupnorm. Only compatible with ptn_norm=group\')\n    parser.add_argument(\'--stn_as_global\', default=1, type=int, help=\'Wether to use the STN output as a global variable\')\n    parser.add_argument(\'--global_feat\', default=\'eXYrgb\', help=\'Use rgb to embed points\')\n    parser.add_argument(\'--use_rgb\', default=1, type=int , help=\'Wether to use radiometry value to use for cloud embeding\')\n    parser.add_argument(\'--ptn_mem_monger\', default=0, type=int, help=\'Bool, save GPU memory by recomputing PointNets in back propagation.\')\n    #parser.add_argument(\'--cascade_color_neigh\', default=0, type=int, help=\'Wether to feed the color to the residual embeddings\')\n\n    #Loss\n    parser.add_argument(\'--loss_weight\', default=\'crosspartition\', help=\'[none, proportional, sqrt, seal, crosspartition] which loss weighting scheme to choose to train the model. unweighted: use classic cross_entropy loss, proportional: weight inversely by transition count,  SEAL: use SEAL loss as proposed in http://jankautz.com/publications/LearningSuperpixels_CVPR2018.pdf, crosspartition : our crosspartition weighting scheme\')\n    parser.add_argument(\'--loss\', default=\'TVH_zhang\', help=\'Structure of the loss : first term for intra edge (chose from : tv, laplacian, TVH (pseudo-huber)), second one for interedge (chose from: zhang, scad, tv)\')\n    parser.add_argument(\'--transition_factor\', default=5, type=float, help=\'Weight for transition edges in the graph structured contrastive loss\')\n    parser.add_argument(\'--dist_type\', default=\'euclidian\', help=\'[euclidian, intrisic, scalar] How to measure the distance between embeddings\')\n\n    #Graph-Clustering\n    parser.add_argument(\'--ver_value\', default=\'ptn\', help=\'what value to use for vertices (ptn): uses PointNets, (geof) : uses geometric features, (xyz) uses position, (rgb) uses color\')\n    parser.add_argument(\'--max_ver_train\', default=1e4, type=int, help=\'Size of the subgraph taken in each point cloud for the training\')\n    parser.add_argument(\'--k_nn_adj\', default=5, type=int, help=\'number of neighbors for the adjacency graph\')\n    parser.add_argument(\'--k_nn_local\', default=20, type=int, help=\'number of neighbors to describe the local geometry\')\n    parser.add_argument(\'--reg_strength\', default=1, type = float, help=\'Regularization strength or the generalized minimum partition problem.\')\n    parser.add_argument(\'--CP_cutoff\', default=10, type=int, help=\'Minimum accepted component size in cut pursuit. if negative, chose with respect tot his number and the reg_strength as explained in the paper\')\n    parser.add_argument(\'--spatial_emb\', default=0.2, type=float, help=\'Weight of xyz in the spatial embedding. When 0 : no xyz\')\n    parser.add_argument(\'--edge_weight_threshold\', default=-0.5, type=float, help=\'Edge weight value when diff>1. if negative, then switch to weight = exp(-diff * edge_weight_threshold)\')\n\n    #Metrics\n    parser.add_argument(\'--BR_tolerance\', default=1, type=int, help=\'How far an edge must be from an actual transition to be considered a true positive\')\n\n    args = parser.parse_args()\n\n    args.start_epoch = 0\n    args.lr_steps = ast.literal_eval(args.lr_steps)\n    args.ptn_widths = ast.literal_eval(args.ptn_widths)\n    args.ptn_widths_stn = ast.literal_eval(args.ptn_widths_stn)\n    args.learned_embeddings = (\'ptn\' in args.ver_value) or args.ver_value == \'xyz\' #wether we actually do some learning\n    if args.CP_cutoff<0: #adaptive cutoff: strong regularization will set a larger cutoff\n        args.CP_cutoff = int(max(-args.CP_cutoff/2, -args.CP_cutoff/2 * np.log(args.reg_strength) -args.CP_cutoff))\n\n    return args\n\ndef dataset(args):\n        # Decide on the dataset\n    if args.dataset==\'s3dis\':\n        dbinfo = get_s3dis_info(args)\n        create_dataset = create_s3dis_datasets\n    elif args.dataset==\'sema3d\':\n        dbinfo = get_sema3d_info(args)\n        create_dataset = create_sema3d_datasets\n    elif args.dataset==\'vkitti\':\n        dbinfo = get_vkitti_info(args)\n        create_dataset = create_vkitti_datasets\n    else:\n        raise NotImplementedError(\'Unknown dataset \' + args.dataset)\n    return dbinfo, create_dataset\n\ndef embed(args):\n    random.seed(0)  \n    root = args.ROOT_PATH+\'/\'\n    folder_hierarchy = FolderHierachy(args.odir, args.dataset, root, args.cvfold)\n\n    # Save command line arguments\n    with open(os.path.join(folder_hierarchy.outputdir, \'cmdline.txt\'), \'w\') as f:\n        f.write("" "".join([""\'""+a+""\'"" if (len(a)==0 or a[0]!=\'-\') else a for a in sys.argv]))\n    \n    if (args.dataset==\'sema3d\' and args.db_test_name.startswith(\'test\')) or (args.dataset.startswith(\'s3dis_02\') and args.cvfold==2):\n        # very large graphs\n        torch.backends.cudnn.enabled = False\n    \n    dbinfo, create_dataset = dataset(args) \n\n    # Create model and optimizer\n    if args.resume != \'\':\n        if args.resume==\'RESUME\': \n            if os.path.isfile(folder_hierarchy.model_path):\n                args.resume = folder_hierarchy.model_path\n            else:\n                raise NameError(\'Cant find pretrained model\')\n        model, optimizer, stats = resume(args)\n    else:\n        model = create_model(args)\n        optimizer = create_optimizer(args, model)\n            \n        stats = []\n                \n    train_dataset, test_dataset = create_dataset(args)\n    \n    if args.learned_embeddings and args.ptn_embedding == \'ptn\':\n        ptnCloudEmbedder = LocalCloudEmbedder(args)\n    elif \'geof\' in args.ver_value:\n        ptnCloudEmbedder = spatialEmbedder(args)\n    else:\n        raise NameError(\'Do not know model \' + args.learned_embeddings)\n        \n    scheduler = MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_decay, last_epoch=args.start_epoch-1)\n\n    def train(i_epoch):\n        """""" Trains for one epoch """"""\n        #return 0\n        model.train()\n        loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, collate_fn=graph_collate, num_workers=args.nworkers, shuffle=True, drop_last=True)\n        \n        if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=100)\n    \n        loss_meter = tnt.meter.AverageValueMeter()\n        n_clusters_meter = tnt.meter.AverageValueMeter()\n\n        t0 = time.time()\n    \n        for bidx, (fname, edg_source, edg_target, is_transition, labels, objects, clouds_data, xyz) in enumerate(loader):\n            \n            if args.cuda:\n                is_transition = is_transition.to(\'cuda\',non_blocking=True)\n                #labels = torch.from_numpy(labels).cuda()\n                objects = objects.to(\'cuda\',non_blocking=True)\n                clouds, clouds_global, nei = clouds_data\n                clouds_data = (clouds.to(\'cuda\',non_blocking=True),clouds_global.to(\'cuda\',non_blocking=True),nei) \n\n            t_loader = 1000*(time.time()-t0)\n            optimizer.zero_grad()\n            t0 = time.time()\n\n            embeddings = ptnCloudEmbedder.run_batch(model, *clouds_data, xyz)\n            \n            diff = compute_dist(embeddings, edg_source, edg_target, args.dist_type)\n            \n            weights_loss, pred_comp, in_comp = compute_weight_loss(args, embeddings, objects, edg_source, edg_target, is_transition, diff, True, xyz)\n            \n            loss1, loss2 = compute_loss(args, diff, is_transition, weights_loss)\n            \n            factor = 1000 #scaling for better usage of float precision\n            \n            loss = (loss1 + loss2) / weights_loss.shape[0]*factor\n            \n            loss.backward()\n            \n            if args.grad_clip>0:\n                for p in model.parameters():\n                    p.grad.data.clamp_(-args.grad_clip*factor, args.grad_clip*factor)\n                    \n            optimizer.step()\n\n            t_trainer = 1000*(time.time()-t0)\n            loss_meter.add(loss.item()/factor)#/weights_loss.mean().item())\n            n_clusters_meter.add(embeddings.shape[0] / len(pred_comp))\n            \n            logging.debug(\'Batch loss %f, Loader time %f ms, Trainer time %f ms.\', loss.item() / factor, t_loader, t_trainer)\n            t0 = time.time()\n            \n        #return 0,0,0\n        return loss_meter.value()[0], n_clusters_meter.value()[0]\n    \n    def evaluate(i_epoch):\n        """""" Evaluated model on test set """"""\n        model.eval()\n        \n        with torch.no_grad():\n            \n            loader = torch.utils.data.DataLoader(test_dataset , batch_size=1, collate_fn=graph_collate, num_workers=args.nworkers)\n            \n            if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=100)\n    \n            loss_meter = tnt.meter.AverageValueMeter()\n            n_clusters_meter = tnt.meter.AverageValueMeter()\n            BR_meter = tnt.meter.AverageValueMeter()\n            BP_meter = tnt.meter.AverageValueMeter()\n            CM_classes = metrics.ConfusionMatrix(dbinfo[\'classes\'])\n    \n            # iterate over dataset in batches\n            for bidx, (fname, edg_source, edg_target, is_transition, labels, objects, clouds_data, xyz) in enumerate(loader):\n                \n                if args.cuda:\n                    is_transition = is_transition.to(\'cuda\',non_blocking=True)\n                    #labels = torch.from_numpy(labels).cuda()\n                    objects = objects.to(\'cuda\',non_blocking=True)\n                    clouds, clouds_global, nei = clouds_data\n                    clouds_data = (clouds.to(\'cuda\',non_blocking=True),clouds_global.to(\'cuda\',non_blocking=True),nei) \n\n                embeddings = ptnCloudEmbedder.run_batch(model, *clouds_data, xyz)\n            \n                diff = compute_dist(embeddings, edg_source, edg_target, args.dist_type)\n                \n                if len(is_transition)>1:\n                    weights_loss, pred_components, pred_in_component = compute_weight_loss(args, embeddings, objects, edg_source, edg_target, is_transition, diff, True, xyz)\n                    loss1, loss2 = compute_loss(args, diff, is_transition, weights_loss)\n                    loss = (loss1 + loss2) / weights_loss.shape[0]\n                    pred_transition = pred_in_component[edg_source]!=pred_in_component[edg_target]\n                    per_pred = perfect_prediction(pred_components, labels)\n                    CM_classes.count_predicted_batch(labels[:,1:], per_pred)\n                else:\n                    loss = 0\n                    \n                if len(is_transition)>1:\n                    loss_meter.add(loss.item())#/weights_loss.sum().item())\n                    is_transition = is_transition.cpu().numpy()\n                    n_clusters_meter.add(len(pred_components))\n                    BR_meter.add((is_transition.sum())*compute_boundary_recall(is_transition, relax_edge_binary(pred_transition, edg_source, edg_target, xyz.shape[0], args.BR_tolerance)),n=is_transition.sum())\n                    BP_meter.add((pred_transition.sum())*compute_boundary_precision(relax_edge_binary(is_transition, edg_source, edg_target, xyz.shape[0], args.BR_tolerance), pred_transition),n=pred_transition.sum())\n        CM = CM_classes.confusion_matrix\n        return loss_meter.value()[0], n_clusters_meter.value()[0], 100*CM.trace() / CM.sum(), BR_meter.value()[0], BP_meter.value()[0]\n    \n    def evaluate_final():\n        """""" Evaluated model on test set """"""\n        \n        print(""Final evaluation"")\n        model.eval()\n        \n        loss_meter = tnt.meter.AverageValueMeter()\n        n_clusters_meter = tnt.meter.AverageValueMeter()\n        confusion_matrix_classes = metrics.ConfusionMatrix(dbinfo[\'classes\'])\n        confusion_matrix_BR = metrics.ConfusionMatrix(2)\n        confusion_matrix_BP = metrics.ConfusionMatrix(2)\n            \n        with torch.no_grad():\n            \n            loader = torch.utils.data.DataLoader(test_dataset , batch_size=1, collate_fn=graph_collate, num_workers=args.nworkers)\n                \n            if logging.getLogger().getEffectiveLevel() > logging.DEBUG: loader = tqdm(loader, ncols=100)\n    \n    # iterate over dataset in batches\n            for bidx, (fname, edg_source, edg_target, is_transition, labels, objects, clouds_data, xyz) in enumerate(loader):\n\n                if args.cuda:\n                    is_transition = is_transition.to(\'cuda\',non_blocking=True)\n                    #labels = torch.from_numpy(labels).cuda()\n                    objects = objects.to(\'cuda\',non_blocking=True)\n                    clouds, clouds_global, nei = clouds_data\n                    clouds_data = (clouds.to(\'cuda\',non_blocking=True),clouds_global.to(\'cuda\',non_blocking=True),nei) \n                \n                if args.dataset==\'sema3d\':\n                    embeddings = ptnCloudEmbedder.run_batch_cpu(model, *clouds_data, xyz)\n                else:\n                    embeddings = ptnCloudEmbedder.run_batch(model, *clouds_data, xyz)\n                \n                diff = compute_dist(embeddings, edg_source, edg_target, args.dist_type)\n                    \n                pred_components, pred_in_component = compute_partition(args, embeddings, edg_source, edg_target, diff, xyz)\n                    \n                if len(is_transition)>1:\n                    pred_transition = pred_in_component[edg_source]!=pred_in_component[edg_target]\n                    is_transition = is_transition.cpu().numpy()\n                        \n                    n_clusters_meter.add(len(pred_components))\n    \n                    per_pred = perfect_prediction(pred_components, labels)                    \n                    confusion_matrix_classes.count_predicted_batch(labels[:,1:], per_pred)\n                    confusion_matrix_BR.count_predicted_batch_hard(is_transition, relax_edge_binary(pred_transition, edg_source, edg_target, xyz.shape[0], args.BR_tolerance).astype(\'uint8\'))\n                    confusion_matrix_BP.count_predicted_batch_hard(relax_edge_binary(is_transition, edg_source, edg_target, xyz.shape[0], args.BR_tolerance),pred_transition.astype(\'uint8\'))\n              \n                if args.spg_out:\n                    graph_sp = compute_sp_graph(xyz, 100, pred_in_component, pred_components, labels, dbinfo[""classes""])\n                    spg_file = os.path.join(folder_hierarchy.spg_folder, fname[0])\n                    if not os.path.exists(os.path.dirname(spg_file)):\n                        os.makedirs(os.path.dirname(spg_file))\n                    try:\n                        os.remove(spg_file)\n                    except OSError:\n                        pass\n                    write_spg(spg_file, graph_sp, pred_components, pred_in_component)\n\n                    # Debugging purpose - write the embedding file and an exemple of scalar files\n                    # if bidx % 0 == 0:\n                    #     embedding2ply(os.path.join(folder_hierarchy.emb_folder , fname[0][:-3] + \'_emb.ply\'), xyz, embeddings.detach().cpu().numpy())\n                    #     scalar2ply(os.path.join(folder_hierarchy.scalars , fname[0][:-3] + \'_elevation.ply\') , xyz, clouds_data[1][:,1].cpu())\n                    #     edg_class = is_transition + 2*pred_transition\n                    #     edge_class2ply2(os.path.join(folder_hierarchy.emb_folder , fname[0][:-3] + \'_transition.ply\'), edg_class, xyz, edg_source, edg_target)\n            if len(is_transition)>1:\n                res_name = folder_hierarchy.outputdir+\'/res.h5\'\n                res_file = h5py.File(res_name, \'w\')\n                res_file.create_dataset(\'confusion_matrix_classes\'\n                                 , data=confusion_matrix_classes.confusion_matrix, dtype=\'uint64\')\n                res_file.create_dataset(\'confusion_matrix_BR\'\n                                 , data=confusion_matrix_BR.confusion_matrix, dtype=\'uint64\')\n                res_file.create_dataset(\'confusion_matrix_BP\'\n                                 , data=confusion_matrix_BP.confusion_matrix, dtype=\'uint64\')\n                res_file.create_dataset(\'n_clusters\'\n                                 , data=n_clusters_meter.value()[0], dtype=\'uint64\')\n                res_file.close()\n                \n        return\n    \n    # Training loop\n    #\n    for epoch in range(args.start_epoch, args.epochs):\n        if not args.learned_embeddings:\n            break\n        print(\'Epoch {}/{} ({}):\'.format(epoch, args.epochs, folder_hierarchy.outputdir))\n        scheduler.step()\n\n        loss, n_sp = train(epoch)\n\n        if (epoch+1) % args.test_nth_epoch == 0: #or epoch+1==args.epochs:\n            loss_test, n_clusters_test, ASA_test, BR_test, BP_test = evaluate(epoch)\n            print(\'-> Train loss: %1.5f - Test Loss: %1.5f  |  n_clusters:  %5.1f  |  ASA: %3.2f %%  |  Test BR: %3.2f %%  |  BP : %3.2f%%\' % (loss, loss_test, n_clusters_test, ASA_test, BR_test, BP_test))\n        else:\n            loss_test, n_clusters_test, ASA_test, BR_test, BP_test = 0,0,0,0,0\n            print(\'-> Train loss: %1.5f  superpoints size : %5.0f\' % (loss, n_sp))\n\n        stats.append({\'epoch\': epoch, \'loss\': loss, \'loss_test\': loss_test, \'n_clusters_test\': n_clusters_test, \'ASA_test\': ASA_test, \'BR_test\': BR_test, \'BP_test\': BP_test})\n\n        with open(os.path.join(folder_hierarchy.outputdir, \'trainlog.json\'), \'w\') as outfile:\n            json.dump(stats, outfile, indent=4)\n\n        if epoch % args.save_nth_epoch == 0 or epoch==args.epochs-1:            \n            model_name = \'model.pth.tar\'\n            print(""Saving model to "" + model_name)\n            model_name = \'model.pth.tar\'\n            torch.save({\'epoch\': epoch + 1, \'args\': args, \'state_dict\': model.state_dict(), \'optimizer\' : optimizer.state_dict()},\n                        os.path.join(folder_hierarchy.outputdir, model_name))\n\n        if math.isnan(loss): break\n\n    evaluate_final()\n\n\ndef create_model(args):\n    """""" Creates model """"""\n    model = nn.Module()\n    if args.learned_embeddings and \'ptn\' in args.ptn_embedding and args.ptn_nfeat_stn > 0:\n        model.stn = STNkD(args.ptn_nfeat_stn, args.ptn_widths_stn[0], args.ptn_widths_stn[1], norm=args.ptn_norm, n_group = args.ptn_n_group)\n    \n    if args.learned_embeddings and \'ptn\' in args.ptn_embedding:\n        n_embed = args.ptn_widths[1][-1]\n        n_feat = 3 + 3 * args.use_rgb\n        nfeats_global = len(args.global_feat) + 4 * args.stn_as_global + 1 #we always add the diameter\n        model.ptn = PointNet(args.ptn_widths[0], args.ptn_widths[1], [], [], n_feat, 0, prelast_do=args.ptn_prelast_do, nfeat_global=nfeats_global, norm=args.ptn_norm, is_res = False, last_bn = True)# = args.normalize_intermediary==0)\n\n    if args.ver_value  == \'geofrgb\':\n        n_embed = 7\n        model.placeholder = nn.Parameter(torch.tensor(0.0))\n    if args.ver_value  == \'geof\':\n        n_embed = 4\n        model.placeholder = nn.Parameter(torch.tensor(0.0))\n        \n    print(\'Total number of parameters: {}\'.format(sum([p.numel() for p in model.parameters()])))\n    print(model)    \n    if args.cuda: \n        model.cuda()\n    return model\n\ndef resume(args):\n    """""" Loads model and optimizer state from a previous checkpoint. """"""\n    print(""=> loading checkpoint \'{}\'"".format(args.resume))\n    checkpoint = torch.load(args.resume)\n    model = create_model(checkpoint[\'args\']) #use original arguments, architecture can\'t change\n    if not args.cuda:\n        model = model.cpu()\n    optimizer = create_optimizer(args, model)\n    \n    model.load_state_dict(checkpoint[\'state_dict\'])\n    if \'optimizer\' in checkpoint: optimizer.load_state_dict(checkpoint[\'optimizer\'])\n    for group in optimizer.param_groups: group[\'initial_lr\'] = args.lr\n    args.start_epoch = checkpoint[\'epoch\']\n    try:\n        stats = json.loads(open(os.path.join(os.path.dirname(args.resume), \'trainlog.json\')).read())\n    except:\n        stats = []\n    return model, optimizer, stats\n    \n    \nif __name__ == ""__main__"": \n    logging.getLogger().setLevel(logging.INFO)  #set to logging.DEBUG to allow for more prints\n    args = parse_args()\n    embed(args)\n'"
learning/ecc/GraphConvInfo.py,3,"b'""""""\r\n    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\r\n    https://github.com/mys007/ecc\r\n    https://arxiv.org/abs/1704.02901\r\n    2017 Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport igraph\r\nimport torch\r\nfrom collections import defaultdict\r\nimport numpy as np\r\n    \r\nclass GraphConvInfo(object):          \r\n    """""" Holds information about the structure of graph(s) in a vectorized form useful to `GraphConvModule`. \r\n    \r\n    We assume that the node feature tensor (given to `GraphConvModule` as input) is ordered by igraph vertex id, e.g. the fifth row corresponds to vertex with id=4. Batch processing is realized by concatenating all graphs into a large graph of disconnected components (and all node feature tensors into a large tensor).\r\n\r\n    The class requires problem-specific `edge_feat_func` function, which receives dict of edge attributes and returns Tensor of edge features and LongTensor of inverse indices if edge compaction was performed (less unique edge features than edges so some may be reused).\r\n    """"""\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        self._idxn = None           #indices into input tensor of convolution (node features)\r\n        self._idxe = None           #indices into edge features tensor (or None if it would be linear, i.e. no compaction)\r\n        self._degrees = None        #in-degrees of output nodes (slices _idxn and _idxe)\r\n        self._degrees_gpu = None\r\n        self._edgefeats = None      #edge features tensor (to be processed by feature-generating network)\r\n        if len(args)>0 or len(kwargs)>0:\r\n            self.set_batch(*args, **kwargs)\r\n      \r\n    def set_batch(self, graphs, edge_feat_func):\r\n        """""" Creates a representation of a given batch of graphs.\r\n        \r\n        Parameters:\r\n        graphs: single graph or a list/tuple of graphs.\r\n        edge_feat_func: see class description.\r\n        """"""\r\n        \r\n        graphs = graphs if isinstance(graphs,(list,tuple)) else [graphs]\r\n        p = 0\r\n        idxn = []\r\n        degrees = []\r\n        edge_indexes = []\r\n        edgeattrs = defaultdict(list)\r\n                \r\n        for G in graphs:\r\n            E = np.array(G.get_edgelist())\r\n            idx = E[:,1].argsort() # sort by target\r\n            \r\n            idxn.append(p + E[idx,0])\r\n            edgeseq = G.es[idx.tolist()]\r\n            for a in G.es.attributes():\r\n                edgeattrs[a] += edgeseq.get_attribute_values(a)\r\n            degrees += G.indegree(G.vs, loops=True)\r\n            edge_indexes.append(np.asarray(p + E[idx]))\r\n            p += G.vcount()\r\n              \r\n        self._edgefeats, self._idxe = edge_feat_func(edgeattrs)\r\n        \r\n        self._idxn = torch.LongTensor(np.concatenate(idxn))\r\n        if self._idxe is not None:\r\n            assert self._idxe.numel() == self._idxn.numel()\r\n            \r\n        self._degrees = torch.LongTensor(degrees)\r\n        self._degrees_gpu = None\r\n\r\n        self._edge_indexes = torch.LongTensor(np.concatenate(edge_indexes).T)\r\n        \r\n    def cuda(self):\r\n        self._idxn = self._idxn.cuda()\r\n        if self._idxe is not None: self._idxe = self._idxe.cuda()\r\n        self._degrees_gpu = self._degrees.cuda()\r\n        self._edgefeats = self._edgefeats.cuda()\r\n        self._edge_indexes = self._edge_indexes.cuda()\r\n        \r\n    def get_buffers(self):\r\n        """""" Provides data to `GraphConvModule`.\r\n        """"""\r\n        return self._idxn, self._idxe, self._degrees, self._degrees_gpu, self._edgefeats\r\n\r\n    def get_pyg_buffers(self):\r\n        """""" Provides data to `GraphConvModule`.\r\n        """"""\r\n        return self._edge_indexes'"
learning/ecc/GraphConvModule.py,15,"b'""""""\r\n    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\r\n    https://github.com/mys007/ecc\r\n    https://arxiv.org/abs/1704.02901\r\n    2017 Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable, Function\r\nfrom .GraphConvInfo import GraphConvInfo\r\nfrom . import cuda_kernels\r\nfrom . import utils\r\n\r\n\r\nclass GraphConvFunction(Function):\r\n    """"""Computes operations for each edge and averages the results over respective nodes.\r\n    The operation is either matrix-vector multiplication (for 3D weight tensors) or element-wise\r\n    vector-vector multiplication (for 2D weight tensors). The evaluation is computed in blocks of\r\n    size `edge_mem_limit` to reduce peak memory load. See `GraphConvInfo` for info on `idxn, idxe, degs`.\r\n    """"""\r\n    def init(self, in_channels, out_channels, idxn, idxe, degs, degs_gpu, edge_mem_limit=1e20):\r\n        self._in_channels = in_channels\r\n        self._out_channels = out_channels\r\n        self._idxn = idxn\r\n        self._idxe = idxe\r\n        self._degs = degs\r\n        self._degs_gpu = degs_gpu\r\n        self._shards = utils.get_edge_shards(degs, edge_mem_limit)\r\n\r\n    def _multiply(ctx, a, b, out, f_a=None, f_b=None):\r\n        """"""Performs operation on edge weights and node signal""""""\r\n        if ctx._full_weight_mat:\r\n            # weights are full in_channels x out_channels matrices -> mm\r\n            torch.bmm(f_a(a) if f_a else a, f_b(b) if f_b else b, out=out)\r\n        else:\r\n            # weights represent diagonal matrices -> mul\r\n            torch.mul(a, b.expand_as(a), out=out)\r\n\r\n    @staticmethod\r\n    def forward(ctx, input, weights, in_channels, out_channels, idxn, idxe, degs, degs_gpu, edge_mem_limit=1e20):\r\n\r\n        ctx.save_for_backward(input, weights)\r\n        ctx._in_channels = in_channels\r\n        ctx._out_channels = out_channels\r\n        ctx._idxn = idxn\r\n        ctx._idxe = idxe\r\n        ctx._degs = degs\r\n        ctx._degs_gpu = degs_gpu\r\n        ctx._shards = utils.get_edge_shards(degs, edge_mem_limit)\r\n\r\n        ctx._full_weight_mat = weights.dim() == 3\r\n        assert ctx._full_weight_mat or (\r\n                in_channels == out_channels and weights.size(1) == in_channels)\r\n\r\n        output = input.new(degs.numel(), out_channels)\r\n\r\n        # loop over blocks of output nodes\r\n        startd, starte = 0, 0\r\n        for numd, nume in ctx._shards:\r\n\r\n            # select sequence of matching pairs of node and edge weights\r\n            sel_input = torch.index_select(input, 0, idxn.narrow(0, starte, nume))\r\n\r\n            if ctx._idxe is not None:\r\n                sel_weights = torch.index_select(weights, 0, idxe.narrow(0, starte, nume))\r\n            else:\r\n                sel_weights = weights.narrow(0, starte, nume)\r\n\r\n            # compute matrix-vector products\r\n            products = input.new()\r\n            GraphConvFunction._multiply(ctx, sel_input, sel_weights, products, lambda a: a.unsqueeze(1))\r\n\r\n            # average over nodes\r\n            if ctx._idxn.is_cuda:\r\n                cuda_kernels.conv_aggregate_fw(output.narrow(0, startd, numd), products.view(-1, ctx._out_channels),\r\n                                               ctx._degs_gpu.narrow(0, startd, numd))\r\n            else:\r\n                k = 0\r\n                for i in range(startd, startd + numd):\r\n                    if ctx._degs[i] > 0:\r\n                        torch.mean(products.narrow(0, k, ctx._degs[i]), 0, out=output[i])\r\n                    else:\r\n                        output[i].fill_(0)\r\n                    k = k + ctx._degs[i]\r\n\r\n            startd += numd\r\n            starte += nume\r\n            del sel_input, sel_weights, products\r\n\r\n        return output\r\n\r\n    @staticmethod\r\n    def backward(ctx, grad_output):\r\n        input, weights = ctx.saved_tensors\r\n\r\n        grad_input = input.new(input.size()).fill_(0)\r\n        grad_weights = weights.new(weights.size())\r\n        if ctx._idxe is not None: grad_weights.fill_(0)\r\n\r\n        # loop over blocks of output nodes\r\n        startd, starte = 0, 0\r\n        for numd, nume in ctx._shards:\r\n\r\n            grad_products, tmp = input.new(nume, ctx._out_channels), input.new()\r\n\r\n            if ctx._idxn.is_cuda:\r\n                cuda_kernels.conv_aggregate_bw(grad_products, grad_output.narrow(0, startd, numd),\r\n                                               ctx._degs_gpu.narrow(0, startd, numd))\r\n            else:\r\n                k = 0\r\n                for i in range(startd, startd + numd):\r\n                    if ctx._degs[i] > 0:\r\n                        torch.div(grad_output[i], ctx._degs[i], out=grad_products[k])\r\n                        if ctx._degs[i] > 1:\r\n                            grad_products.narrow(0, k + 1, ctx._degs[i] - 1).copy_(\r\n                                grad_products[k].expand(ctx._degs[i] - 1, 1, ctx._out_channels).squeeze(1))\r\n                        k = k + ctx._degs[i]\r\n\r\n                        # grad wrt weights\r\n            sel_input = torch.index_select(input, 0, ctx._idxn.narrow(0, starte, nume))\r\n\r\n            if ctx._idxe is not None:\r\n                GraphConvFunction._multiply(ctx, sel_input, grad_products, tmp,\r\n                                            lambda a: a.unsqueeze(1).transpose_(2, 1),\r\n                                            lambda b: b.unsqueeze(1))\r\n                grad_weights.index_add_(0, ctx._idxe.narrow(0, starte, nume), tmp)\r\n            else:\r\n                GraphConvFunction._multiply(ctx, sel_input, grad_products, grad_weights.narrow(0, starte, nume),\r\n                                            lambda a: a.unsqueeze(1).transpose_(2, 1), lambda b: b.unsqueeze(1))\r\n\r\n            # grad wrt input\r\n            if ctx._idxe is not None:\r\n                torch.index_select(weights, 0, ctx._idxe.narrow(0, starte, nume), out=tmp)\r\n                GraphConvFunction._multiply(ctx, grad_products, tmp, sel_input, lambda a: a.unsqueeze(1),\r\n                                            lambda b: b.transpose_(2, 1))\r\n                del tmp\r\n            else:\r\n                GraphConvFunction._multiply(ctx, grad_products, weights.narrow(0, starte, nume), sel_input,\r\n                                            lambda a: a.unsqueeze(1),\r\n                                            lambda b: b.transpose_(2, 1))\r\n\r\n            grad_input.index_add_(0, ctx._idxn.narrow(0, starte, nume), sel_input)\r\n\r\n            startd += numd\r\n            starte += nume\r\n            del grad_products, sel_input\r\n\r\n        return grad_input, grad_weights, None, None, None, None, None, None, None\r\n\r\n\r\n\r\nclass GraphConvModule(nn.Module):\r\n    """""" Computes graph convolution using filter weights obtained from a filter generating network (`filter_net`).\r\n        The input should be a 2D tensor of size (# nodes, `in_channels`). Multiple graphs can be concatenated in the same tensor (minibatch).\r\n    \r\n    Parameters:\r\n    in_channels: number of input channels\r\n    out_channels: number of output channels\r\n    filter_net: filter-generating network transforming a 2D tensor (# edges, # edge features) to (# edges, in_channels*out_channels) or (# edges, in_channels)\r\n    gc_info: GraphConvInfo object containing graph(s) structure information, can be also set with `set_info()` method.\r\n    edge_mem_limit: block size (number of evaluated edges in parallel) for convolution evaluation, a low value reduces peak memory. \r\n    """"""\r\n\r\n    def __init__(self, in_channels, out_channels, filter_net, gc_info=None, edge_mem_limit=1e20):\r\n        super(GraphConvModule, self).__init__()\r\n        \r\n        self._in_channels = in_channels\r\n        self._out_channels = out_channels\r\n        self._fnet = filter_net\r\n        self._edge_mem_limit = edge_mem_limit\r\n        \r\n        self.set_info(gc_info)\r\n        \r\n    def set_info(self, gc_info):\r\n        self._gci = gc_info\r\n    \r\n    def forward(self, input):       \r\n        # get graph structure information tensors\r\n        idxn, idxe, degs, degs_gpu, edgefeats = self._gci.get_buffers()\r\n        edgefeats = Variable(edgefeats, requires_grad=False)\r\n        \r\n        # evalute and reshape filter weights\r\n        weights = self._fnet(edgefeats)\r\n        assert input.dim()==2 and weights.dim()==2 and (weights.size(1) == self._in_channels*self._out_channels or\r\n               (self._in_channels == self._out_channels and weights.size(1) == self._in_channels))\r\n        if weights.size(1) == self._in_channels*self._out_channels:\r\n            weights = weights.view(-1, self._in_channels, self._out_channels)\r\n\r\n        return GraphConvFunction(self._in_channels, self._out_channels, idxn, idxe, degs, degs_gpu, self._edge_mem_limit)(input, weights)\r\n        \r\n\r\n\r\n\r\n\r\n\r\nclass GraphConvModulePureAutograd(nn.Module):\r\n    """"""\r\n    Autograd-only equivalent of `GraphConvModule` + `GraphConvFunction`. Unfortunately, autograd needs to store intermediate products, which makes the module work only for very small graphs. The module is kept for didactic purposes only.\r\n    """"""\r\n\r\n    def __init__(self, in_channels, out_channels, filter_net, gc_info=None):\r\n        super(GraphConvModulePureAutograd, self).__init__()\r\n        \r\n        self._in_channels = in_channels\r\n        self._out_channels = out_channels\r\n        self._fnet = filter_net\r\n        \r\n        self.set_info(gc_info)\r\n        \r\n    def set_info(self, gc_info):\r\n        self._gci = gc_info\r\n\r\n    def forward(self, input):\r\n        # get graph structure information tensors\r\n        idxn, idxe, degs, edgefeats = self._gci.get_buffers()\r\n        idxn = Variable(idxn, requires_grad=False)\r\n        edgefeats = Variable(edgefeats, requires_grad=False)\r\n        \r\n        # evalute and reshape filter weights\r\n        weights = self._fnet(edgefeats)\r\n        assert input.dim()==2 and weights.dim()==2 and weights.size(1) == self._in_channels*self._out_channels\r\n        weights = weights.view(-1, self._in_channels, self._out_channels)\r\n            \r\n        # select sequence of matching pairs of node and edge weights            \r\n        if idxe is not None:\r\n            idxe = Variable(idxe, requires_grad=False)\r\n            weights = torch.index_select(weights, 0, idxe)        \r\n        \r\n        sel_input = torch.index_select(input, 0, idxn)\r\n\r\n        # compute matrix-vector products\r\n        products = torch.bmm(sel_input.view(-1,1,self._in_channels), weights)\r\n        \r\n        output = Variable(input.data.new(len(degs), self._out_channels))\r\n        \r\n        # average over nodes\r\n        k = 0\r\n        for i in range(len(degs)):\r\n            if degs[i]>0:\r\n                output.index_copy_(0, Variable(torch.Tensor([i]).type_as(idxn.data)), torch.mean(products.narrow(0,k,degs[i]), 0).view(1,-1))\r\n            else:\r\n                output.index_fill_(0, Variable(torch.Tensor([i]).type_as(idxn.data)), 0)\r\n            k = k + degs[i]\r\n\r\n        return output\r\n    \r\n'"
learning/ecc/GraphPoolInfo.py,2,"b'""""""\r\n    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\r\n    https://github.com/mys007/ecc\r\n    https://arxiv.org/abs/1704.02901\r\n    2017 Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport torch\r\n\r\n\r\nclass GraphPoolInfo(object):          \r\n    """""" Holds information about pooling in a vectorized form useful to `GraphPoolModule`. \r\n    \r\n    We assume that the node feature tensor (given to `GraphPoolModule` as input) is ordered by igraph vertex id, e.g. the fifth row corresponds to vertex with id=4. Batch processing is realized by concatenating all graphs into a large graph of disconnected components (and all node feature tensors into a large tensor).\r\n    """"""\r\n    \r\n    def __init__(self, *args, **kwargs):\r\n        self._idxn = None           #indices into input tensor of convolution (node features)\r\n        self._degrees = None        #in-degrees of output nodes (slices _idxn)\r\n        self._degrees_gpu = None\r\n        if len(args)>0 or len(kwargs)>0:\r\n            self.set_batch(*args, **kwargs)\r\n            \r\n    def set_batch(self, poolmaps, graphs_from, graphs_to):\r\n        """""" Creates a representation of a given batch of graph poolings.\r\n        \r\n        Parameters:\r\n        poolmaps: dict(s) mapping vertex id in coarsened graph to a list of vertex ids in input graph (defines pooling)\r\n        graphs_from: input graph(s)\r\n        graphs_to: coarsened graph(s)\r\n        """"""\r\n    \r\n        poolmaps = poolmaps if isinstance(poolmaps,(list,tuple)) else [poolmaps]\r\n        graphs_from = graphs_from if isinstance(graphs_from,(list,tuple)) else [graphs_from]\r\n        graphs_to = graphs_to if isinstance(graphs_to,(list,tuple)) else [graphs_to]\r\n        \r\n        idxn = []\r\n        degrees = []   \r\n        p = 0        \r\n              \r\n        for map, G_from, G_to in zip(poolmaps, graphs_from, graphs_to):\r\n            for v in range(G_to.vcount()):\r\n                nlist = map.get(v, [])\r\n                idxn.extend([n+p for n in nlist])\r\n                degrees.append(len(nlist))\r\n            p += G_from.vcount()\r\n         \r\n        self._idxn = torch.LongTensor(idxn)\r\n        self._degrees = torch.LongTensor(degrees)\r\n        self._degrees_gpu = None  \r\n        \r\n    def cuda(self):\r\n        self._idxn = self._idxn.cuda()\r\n        self._degrees_gpu = self._degrees.cuda()\r\n        \r\n    def get_buffers(self):\r\n        """""" Provides data to `GraphPoolModule`.\r\n        """"""    \r\n        return self._idxn, self._degrees, self._degrees_gpu\r\n '"
learning/ecc/GraphPoolModule.py,6,"b'""""""\r\n    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\r\n    https://github.com/mys007/ecc\r\n    https://arxiv.org/abs/1704.02901\r\n    2017 Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable, Function\r\nfrom .GraphPoolInfo import GraphPoolInfo\r\nfrom . import cuda_kernels\r\nfrom . import utils\r\n\r\nclass GraphPoolFunction(Function):\r\n    """""" Computes node feature aggregation for each node of the coarsened graph. The evaluation is computed in blocks of size `edge_mem_limit` to reduce peak memory load. See `GraphPoolInfo` for info on `idxn, degs`.\r\n    """"""\r\n\r\n    AGGR_MEAN = 0\r\n    AGGR_MAX = 1\r\n\r\n    def __init__(self, idxn, degs, degs_gpu, aggr, edge_mem_limit=1e20):\r\n        super(GraphPoolFunction, self).__init__()\r\n        self._idxn = idxn\r\n        self._degs = degs\r\n        self._degs_gpu = degs_gpu\r\n        self._aggr = aggr\r\n        self._shards = utils.get_edge_shards(degs, edge_mem_limit)\r\n                \r\n    def forward(self, input):\r\n        output = input.new(self._degs.numel(), input.size(1))\r\n        if self._aggr==GraphPoolFunction.AGGR_MAX:\r\n            self._max_indices = self._idxn.new(self._degs.numel(), input.size(1)).fill_(-1)\r\n        \r\n        self._input_size = input.size()\r\n        \r\n        # loop over blocks of output nodes\r\n        startd, starte = 0, 0\r\n        for numd, nume in self._shards: \r\n            \r\n            sel_input = torch.index_select(input, 0, self._idxn.narrow(0,starte,nume))\r\n            \r\n            # aggregate over nodes\r\n            if self._idxn.is_cuda:\r\n                if self._aggr==GraphPoolFunction.AGGR_MEAN:\r\n                    cuda_kernels.avgpool_fw(output.narrow(0,startd,numd), sel_input, self._degs_gpu.narrow(0,startd,numd))            \r\n                elif self._aggr==GraphPoolFunction.AGGR_MAX:\r\n                    cuda_kernels.maxpool_fw(output.narrow(0,startd,numd), self._max_indices.narrow(0,startd,numd), sel_input, self._degs_gpu.narrow(0,startd,numd))        \r\n            else:\r\n                k = 0\r\n                for i in range(startd, startd+numd):\r\n                    if self._degs[i]>0:\r\n                        if self._aggr==GraphPoolFunction.AGGR_MEAN:\r\n                            torch.mean(sel_input.narrow(0,k,self._degs[i]), 0, out=output[i])\r\n                        elif self._aggr==GraphPoolFunction.AGGR_MAX:\r\n                            torch.max(sel_input.narrow(0,k,self._degs[i]), 0, out=(output[i], self._max_indices[i]))\r\n                    else:\r\n                        output[i].fill_(0)\r\n                    k = k + self._degs[i]\r\n                    \r\n            startd += numd\r\n            starte += nume \r\n            del sel_input\r\n    \r\n        return output\r\n\r\n        \r\n    def backward(self, grad_output):\r\n        grad_input = grad_output.new(self._input_size).fill_(0)\r\n\r\n        # loop over blocks of output nodes\r\n        startd, starte = 0, 0\r\n        for numd, nume in self._shards:                  \r\n            \r\n            grad_sel_input = grad_output.new(nume, grad_output.size(1))\r\n\r\n            # grad wrt input\r\n            if self._idxn.is_cuda:\r\n                if self._aggr==GraphPoolFunction.AGGR_MEAN:\r\n                    cuda_kernels.avgpool_bw(grad_input, self._idxn.narrow(0,starte,nume), grad_output.narrow(0,startd,numd), self._degs_gpu.narrow(0,startd,numd))            \r\n                elif self._aggr==GraphPoolFunction.AGGR_MAX:\r\n                    cuda_kernels.maxpool_bw(grad_input, self._idxn.narrow(0,starte,nume), self._max_indices.narrow(0,startd,numd), grad_output.narrow(0,startd,numd), self._degs_gpu.narrow(0,startd,numd))  \r\n            else:\r\n                k = 0\r\n                for i in range(startd, startd+numd):\r\n                    if self._degs[i]>0:\r\n                        if self._aggr==GraphPoolFunction.AGGR_MEAN:\r\n                            torch.div(grad_output[i], self._degs[i], out=grad_sel_input[k])\r\n                            if self._degs[i]>1:\r\n                                grad_sel_input.narrow(0, k+1, self._degs[i]-1).copy_( grad_sel_input[k].expand(self._degs[i]-1,1,grad_output.size(1)) )\r\n                        elif self._aggr==GraphPoolFunction.AGGR_MAX:\r\n                            grad_sel_input.narrow(0, k, self._degs[i]).fill_(0).scatter_(0, self._max_indices[i].view(1,-1), grad_output[i].view(1,-1))\r\n                        k = k + self._degs[i]             \r\n\r\n                grad_input.index_add_(0, self._idxn.narrow(0,starte,nume), grad_sel_input)\r\n                    \r\n            startd += numd\r\n            starte += nume   \r\n            del grad_sel_input\r\n       \r\n        return grad_input\r\n        \r\n        \r\n        \r\nclass GraphPoolModule(nn.Module):\r\n    """""" Performs graph pooling.\r\n        The input should be a 2D tensor of size (# nodes, `in_channels`). Multiple graphs can be concatenated in the same tensor (minibatch).    \r\n    \r\n    Parameters:\r\n    aggr: aggregation type (GraphPoolFunction.AGGR_MEAN, GraphPoolFunction.AGGR_MAX)\r\n    gp_info: GraphPoolInfo object containing node mapping information, can be also set with `set_info()` method.\r\n    edge_mem_limit: block size (number of evaluated edges in parallel), a low value reduces peak memory.\r\n    """"""\r\n    \r\n    def __init__(self, aggr, gp_info=None, edge_mem_limit=1e20):\r\n        super(GraphPoolModule, self).__init__()\r\n        \r\n        self._aggr = aggr\r\n        self._edge_mem_limit = edge_mem_limit       \r\n        self.set_info(gp_info)\r\n        \r\n    def set_info(self, gp_info):\r\n        self._gpi = gp_info\r\n        \r\n    def forward(self, input):       \r\n        idxn, degs, degs_gpu = self._gpi.get_buffers()\r\n        return GraphPoolFunction(idxn, degs, degs_gpu, self._aggr, self._edge_mem_limit)(input)\r\n        \r\n        \r\nclass GraphAvgPoolModule(GraphPoolModule):\r\n    def __init__(self, gp_info=None, edge_mem_limit=1e20):\r\n        super(GraphAvgPoolModule, self).__init__(GraphPoolFunction.AGGR_MEAN, gp_info, edge_mem_limit)        \r\n        \r\nclass GraphMaxPoolModule(GraphPoolModule):\r\n    def __init__(self, gp_info=None, edge_mem_limit=1e20):\r\n        super(GraphMaxPoolModule, self).__init__(GraphPoolFunction.AGGR_MAX, gp_info, edge_mem_limit)                '"
learning/ecc/__init__.py,0,"b'from .GraphConvInfo import GraphConvInfo\r\nfrom .GraphConvModule import GraphConvModule, GraphConvFunction\r\n\r\nfrom .GraphPoolInfo import GraphPoolInfo\r\nfrom .GraphPoolModule import GraphAvgPoolModule, GraphMaxPoolModule\r\n\r\nfrom .utils import *\r\n'"
learning/ecc/cuda_kernels.py,10,"b'""""""\r\n    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\r\n    https://github.com/mys007/ecc\r\n    https://arxiv.org/abs/1704.02901\r\n    2017 Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport torch\r\ntry:\r\n    import cupy.cuda\r\n    from pynvrtc.compiler import Program\r\nexcept:\r\n    pass\r\nfrom collections import namedtuple\r\nimport numpy as np\r\n\r\nCUDA_NUM_THREADS = 1024\r\n\r\ndef GET_BLOCKS(N):\r\n  return (N + CUDA_NUM_THREADS - 1) // CUDA_NUM_THREADS;\r\n  \r\nmodules = {}\r\n\r\ndef get_dtype(t):\r\n    if isinstance(t, torch.cuda.FloatTensor):\r\n        return \'float\'\r\n    elif isinstance(t, torch.cuda.DoubleTensor):\r\n        return \'double\'\r\n   \r\ndef get_kernel_func(kname, ksrc, dtype):\r\n    if kname+dtype not in modules:\r\n        ksrc = ksrc.replace(\'DTYPE\', dtype)\r\n        #prog = Program(ksrc.encode(\'utf-8\'), (kname+dtype+\'.cu\').encode(\'utf-8\'))\r\n        #uncomment the line above and comment the line below if it causes the following error: AttributeError: \'Program\' object has no attribute \'_program\'\r\n        prog = Program(ksrc, kname+dtype+\'.cu\')        \r\n        ptx = prog.compile()\r\n        log = prog._interface.nvrtcGetProgramLog(prog._program)\r\n        if len(log.strip()) > 0: print(log)\r\n        module = cupy.cuda.function.Module()\r\n        module.load(bytes(ptx.encode()))\r\n        modules[kname+dtype] = module\r\n    else:\r\n        module = modules[kname+dtype]\r\n        \r\n    Stream = namedtuple(\'Stream\', [\'ptr\'])\r\n    s = Stream(ptr=torch.cuda.current_stream().cuda_stream)        \r\n        \r\n    return module.get_function(kname), s\r\n        \r\n####       \r\n       \r\ndef conv_aggregate_fw_kernel_v2(**kwargs):\r\n    kernel = r\'\'\'\r\nextern ""C""\r\n__global__ void conv_aggregate_fw_kernel_v2(DTYPE* dest, const DTYPE* src, const long long* lengths, const long long* cslengths, int width, int N, int dest_stridex, int src_stridex, int blockDimy) {\r\n\t\r\n    int x = blockIdx.x * blockDim.x + threadIdx.x; //one thread per feature channel, runs over all nodes\r\n    if (x >= width) return;\r\n    \r\n    int i = blockIdx.y * blockDimy;\r\n    int imax = min(N, i + blockDimy);\r\n    dest += dest_stridex * i + x;\r\n    src += src_stridex * (cslengths[i] - lengths[i]) + x;\r\n\r\n\tfor (; i<imax; ++i) {\t\r\n        int len = lengths[i];\r\n\t\tif (len > 0) {\r\n\t\t\tDTYPE sum = 0;\t\t\r\n            for (int j=0; j<len; j++, src += src_stridex) {\r\n                sum += *src;\r\n\t\t\t}\r\n\r\n            *dest = sum / len;\t\t\t\r\n\t\t}\r\n\t\telse {\r\n\t\t\t*dest = 0;\r\n\t\t}\r\n\t\t\r\n\t\tdest += dest_stridex;\r\n\t}\r\n}\r\n\'\'\'\r\n    return kernel   \r\n    \r\ndef conv_aggregate_bw_kernel_v2(**kwargs):\r\n    kernel = r\'\'\'\r\nextern ""C""\r\n__global__ void conv_aggregate_bw_kernel_v2(DTYPE* dest, const DTYPE* src, const long long* lengths, const long long* cslengths, int width, int N, int dest_stridex, int src_stridex, int blockDimy) {\r\n\t\r\n    int x = blockIdx.x * blockDim.x + threadIdx.x; //one thread per feature channel, runs over all nodes\r\n    if (x >= width) return;\r\n    \r\n    int i = blockIdx.y * blockDimy;\r\n    int imax = min(N, i + blockDimy);\r\n    dest += dest_stridex * (cslengths[i] - lengths[i]) + x;    \r\n    src += src_stridex * i + x;\r\n\t\r\n\tfor (; i<imax; ++i) {\t\r\n        int len = lengths[i];\r\n\t\tif (len > 0) {\r\n\t\t\tDTYPE val = *src / len;\r\n            for (int j=0; j<len; j++, dest += dest_stridex) {\r\n                *dest = val;\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tsrc += src_stridex;\r\n\t}\r\n}\r\n\'\'\'\r\n    return kernel   \r\n    \r\n\r\ndef conv_aggregate_fw(dest, src, degs):   \r\n    n = degs.numel()\r\n    w = src.size(1)\r\n    assert n == dest.size(0) and w == dest.size(1)\r\n    assert type(src)==type(dest) and isinstance(degs, torch.cuda.LongTensor)\r\n    \r\n    csdegs = torch.cumsum(degs,0)\r\n    blockDimY = n // (1024/(w//32+1)) +1 # try to occuppy 1024 threads by splitting also over nodes\r\n    function, stream = get_kernel_func(\'conv_aggregate_fw_kernel_v2\', conv_aggregate_fw_kernel_v2(), get_dtype(src))\r\n    function(args=[dest.data_ptr(), src.data_ptr(), degs.data_ptr(), csdegs.data_ptr(), np.int32(w), np.int32(n), np.int32(dest.stride(0)), np.int32(src.stride(0)), np.int32(blockDimY)], \r\n             block=(CUDA_NUM_THREADS,1,1), grid=(GET_BLOCKS(w),n//blockDimY+1,1), stream=stream)            \r\n                                         \r\ndef conv_aggregate_bw(dest, src, degs):\r\n    n = degs.numel()\r\n    w = src.size(1)\r\n    assert n == src.size(0) and w == dest.size(1)\r\n    assert type(src)==type(dest) and isinstance(degs, torch.cuda.LongTensor)\r\n    \r\n    csdegs = torch.cumsum(degs,0)\r\n    blockDimY = n // (1024/(w//32+1)) +1 # try to occuppy 1024 threads by splitting also over nodes\r\n    function, stream = get_kernel_func(\'conv_aggregate_bw_kernel_v2\', conv_aggregate_bw_kernel_v2(), get_dtype(src))\r\n    function(args=[dest.data_ptr(), src.data_ptr(), degs.data_ptr(), csdegs.data_ptr(), np.int32(w), np.int32(n), np.int32(dest.stride(0)), np.int32(src.stride(0)), np.int32(blockDimY)],\r\n             block=(CUDA_NUM_THREADS,1,1), grid=(GET_BLOCKS(w),n//blockDimY+1,1), stream=stream)\r\n                                         \r\n\r\n\r\ndef maxpool_fw_kernel(**kwargs):\r\n    kernel = r\'\'\'\r\nextern ""C""                                         \r\n__global__ void maxpool_fw_kernel(DTYPE* dest, long long* indices, const DTYPE* src, const long long* lengths, int width, int N, int dest_stridex, int src_stridex) {\r\n\t\r\n    int x = blockIdx.x * blockDim.x + threadIdx.x; //one thread per feature channel, runs over all points\r\n    if (x >= width) return;\r\n\t\r\n\tfor (int i=0; i<N; ++i) {\t\t\r\n\t\tif (lengths[i] > 0) {\r\n\t\t\tlong long src_step = lengths[i] * src_stridex;\r\n\t\t\tlong long bestjj = -1;\r\n\t\t\tDTYPE best = -1e10;\r\n\t\t\t\r\n\t\t\tfor (long long j = x, jj=0; j < src_step; j += src_stridex, ++jj) {\r\n\t\t\t\tif (src[j] > best) {\r\n\t\t\t\t\tbest = src[j];\r\n\t\t\t\t\tbestjj = jj;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tdest[x] = best;\r\n\t\t\tindices[x] = bestjj;\r\n\t\t\t\r\n\t\t\tsrc += src_step;\r\n\t\t}\r\n\t\telse {\r\n\t\t\tdest[x] = 0;\r\n\t\t\tindices[x] = -1;\r\n\t\t}\r\n\t\t\r\n\t\tdest += dest_stridex;\r\n\t\tindices += dest_stridex;\r\n\t}\r\n}\r\n\'\'\'\r\n    return kernel\r\n    \r\ndef maxpool_bw_kernel(**kwargs):\r\n    kernel = r\'\'\'\r\n//also directly scatters results by dest_indices (saves one sparse intermediate buffer)\r\nextern ""C""          \r\n__global__ void maxpool_bw_kernel(DTYPE* dest, const long long* dest_indices, const long long* max_indices, const DTYPE* src, const long long* lengths, int width, int N, int dest_stridex, int src_stridex) {\r\n\t\r\n    int x = blockIdx.x * blockDim.x + threadIdx.x; //one thread per feature channel, runs over all points\r\n    if (x >= width) return;\r\n\t\r\n\tfor (int i=0; i<N; ++i) {\r\n\t\tif (lengths[i] > 0) {\r\n\r\n            long long destidx = dest_indices[max_indices[x]];\r\n\t\t\tdest[x + destidx * dest_stridex] += src[x]; //no need for atomicadd, only one threads cares about each feat\r\n\t\t\t\r\n\t\t\tdest_indices += lengths[i];\r\n\t\t}\r\n\t\t\r\n\t\tsrc += src_stridex;\r\n\t\tmax_indices += src_stridex;\r\n\t}\r\n}\r\n\'\'\'\r\n    return kernel\r\n    \r\n    \r\ndef maxpool_fw(dest, indices, src, degs):   \r\n    n = degs.numel()\r\n    w = src.size(1)\r\n    assert n == dest.size(0) and w == dest.size(1)\r\n    assert type(src)==type(dest) and isinstance(degs, torch.cuda.LongTensor) and isinstance(indices, torch.cuda.LongTensor)\r\n    \r\n    function, stream = get_kernel_func(\'maxpool_fw_kernel\', maxpool_fw_kernel(), get_dtype(src))\r\n    function(args=[dest.data_ptr(), indices.data_ptr(), src.data_ptr(), degs.data_ptr(), np.int32(w), np.int32(n), np.int32(dest.stride(0)), np.int32(src.stride(0))],\r\n             block=(CUDA_NUM_THREADS,1,1), grid=(GET_BLOCKS(w),1,1), stream=stream)    \r\n    \r\ndef maxpool_bw(dest, idxn, indices, src, degs):   \r\n    n = degs.numel()\r\n    w = src.size(1)\r\n    assert n == src.size(0) and w == dest.size(1)\r\n    assert type(src)==type(dest) and isinstance(degs, torch.cuda.LongTensor) and isinstance(indices, torch.cuda.LongTensor) and isinstance(idxn, torch.cuda.LongTensor)\r\n    \r\n    function, stream = get_kernel_func(\'maxpool_bw_kernel\', maxpool_bw_kernel(), get_dtype(src))\r\n    function(args=[dest.data_ptr(), idxn.data_ptr(), indices.data_ptr(), src.data_ptr(), degs.data_ptr(), np.int32(w), np.int32(n), np.int32(dest.stride(0)), np.int32(src.stride(0))],\r\n             block=(CUDA_NUM_THREADS,1,1), grid=(GET_BLOCKS(w),1,1), stream=stream)    \r\n\r\n    \r\n\r\ndef avgpool_bw_kernel(**kwargs):\r\n    kernel = r\'\'\'\r\n//also directly scatters results by dest_indices (saves one intermediate buffer)\r\nextern ""C""     \r\n__global__ void avgpool_bw_kernel(DTYPE* dest, const long long* dest_indices, const DTYPE* src, const long long* lengths, int width, int N, int dest_stridex, int src_stridex) {\r\n\t\r\n    int x = blockIdx.x * blockDim.x + threadIdx.x; //one thread per feature channel, runs over all points\r\n    if (x >= width) return;\r\n\t\r\n\tfor (int i=0; i<N; ++i) {\r\n\t\tif (lengths[i] > 0) {\r\n\t\t\r\n\t\t\tDTYPE val = src[x] / lengths[i];\r\n\t\t\t\r\n\t\t\tfor (int j = 0; j < lengths[i]; ++j) {\r\n\t\t\t\tlong long destidx = dest_indices[j];\r\n\t\t\t\tdest[x + destidx * dest_stridex] += val; //no need for atomicadd, only one threads cares about each feat\r\n\t\t\t}\r\n\r\n\t\t\tdest_indices += lengths[i];\r\n\t\t}\r\n\t\t\r\n\t\tsrc += src_stridex;\r\n\t}\r\n}\r\n\'\'\'\r\n    return kernel\r\n\r\n\r\ndef avgpool_fw(dest, src, degs):   \r\n    conv_aggregate_fw(dest, src, degs)\r\n\r\ndef avgpool_bw(dest, idxn, src, degs):   \r\n    n = degs.numel()\r\n    w = src.size(1)\r\n    assert n == src.size(0) and w == dest.size(1)\r\n    assert type(src)==type(dest) and isinstance(degs, torch.cuda.LongTensor) and isinstance(idxn, torch.cuda.LongTensor)\r\n    \r\n    function, stream = get_kernel_func(\'avgpool_bw_kernel\', avgpool_bw_kernel(), get_dtype(src))\r\n    function(args=[dest.data_ptr(), idxn.data_ptr(), src.data_ptr(), degs.data_ptr(), np.int32(w), np.int32(n), np.int32(dest.stride(0)), np.int32(src.stride(0))],\r\n             block=(CUDA_NUM_THREADS,1,1), grid=(GET_BLOCKS(w),1,1), stream=stream)      \r\n'"
learning/ecc/test_GraphConvModule.py,14,"b'""""""\r\n    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\r\n    https://github.com/mys007/ecc\r\n    https://arxiv.org/abs/1704.02901\r\n    2017 Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport unittest\r\nimport numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable, gradcheck\r\n\r\nfrom .GraphConvModule import *\r\nfrom .GraphConvInfo import GraphConvInfo\r\n\r\n\r\nclass TestGraphConvModule(unittest.TestCase):\r\n\r\n    def test_gradcheck(self):\r\n    \r\n        torch.set_default_tensor_type(\'torch.DoubleTensor\') #necessary for proper numerical gradient    \r\n\r\n        for cuda in range(0,2):\r\n            # without idxe\r\n            n,e,in_channels, out_channels = 20,50,10, 15\r\n            input = torch.randn(n,in_channels)\r\n            weights = torch.randn(e,in_channels,out_channels)\r\n            idxn = torch.from_numpy(np.random.randint(n,size=e))\r\n            idxe = None\r\n            degs = torch.LongTensor([5, 0, 15, 20, 10])  #strided conv\r\n            degs_gpu = degs\r\n            edge_mem_limit = 30 # some nodes will be combined, some not\r\n            if cuda:\r\n                input = input.cuda(); weights = weights.cuda(); idxn = idxn.cuda(); degs_gpu = degs_gpu.cuda()\r\n            \r\n            func = GraphConvFunction(in_channels, out_channels, idxn, idxe, degs, degs_gpu, edge_mem_limit=edge_mem_limit)\r\n            data = (Variable(input, requires_grad=True), Variable(weights, requires_grad=True))\r\n\r\n            ok = gradcheck(func, data)\r\n            self.assertTrue(ok)\r\n            \r\n            # with idxe\r\n            weights = torch.randn(30,in_channels,out_channels)\r\n            idxe = torch.from_numpy(np.random.randint(30,size=e))\r\n            if cuda:\r\n                weights = weights.cuda(); idxe = idxe.cuda()\r\n\r\n            func = GraphConvFunction(in_channels, out_channels, idxn, idxe, degs, degs_gpu, edge_mem_limit=edge_mem_limit)\r\n\r\n            ok = gradcheck(func, data)\r\n            self.assertTrue(ok)\r\n\r\n        torch.set_default_tensor_type(\'torch.FloatTensor\')\r\n        \r\n    def test_batch_splitting(self):\r\n    \r\n        n,e,in_channels, out_channels = 20,50,10, 15\r\n        input = torch.randn(n,in_channels)\r\n        weights = torch.randn(e,in_channels,out_channels)\r\n        idxn = torch.from_numpy(np.random.randint(n,size=e))\r\n        idxe = None\r\n        degs = torch.LongTensor([5, 0, 15, 20, 10])  #strided conv\r\n        \r\n        func = GraphConvFunction(in_channels, out_channels, idxn, idxe, degs, degs, edge_mem_limit=1e10)\r\n        data = (Variable(input, requires_grad=True), Variable(weights, requires_grad=True))\r\n        output1 = func(*data)\r\n\r\n        func = GraphConvFunction(in_channels, out_channels, idxn, idxe, degs, degs, edge_mem_limit=1)\r\n        output2 = func(*data)\r\n\r\n        self.assertLess((output1-output2).norm().data[0], 1e-6)\r\n\r\n    \r\n        \r\nif __name__ == \'__main__\':\r\n    unittest.main()        '"
learning/ecc/test_GraphPoolModule.py,9,"b'""""""\r\n    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\r\n    https://github.com/mys007/ecc\r\n    https://arxiv.org/abs/1704.02901\r\n    2017 Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport unittest\r\nimport numpy as np\r\nimport torch\r\nfrom torch.autograd import Variable, gradcheck\r\n\r\nfrom .GraphPoolModule import *\r\nfrom .GraphPoolInfo import GraphPoolInfo\r\n\r\n\r\nclass TestGraphConvModule(unittest.TestCase):\r\n\r\n    def test_gradcheck(self):\r\n\r\n        torch.set_default_tensor_type(\'torch.DoubleTensor\') #necessary for proper numerical gradient\r\n        \r\n        for cuda in range(0,2):\r\n            for aggr in range(0,2):\r\n                n,in_channels = 20,10\r\n                input = torch.randn(n,in_channels)\r\n                idxn = torch.from_numpy(np.random.permutation(n))\r\n                degs = torch.LongTensor([2, 0, 3, 10, 5])\r\n                degs_gpu = degs\r\n                edge_mem_limit = 30 # some nodes will be combined, some not\r\n                if cuda:\r\n                    input = input.cuda(); idxn = idxn.cuda(); degs_gpu = degs_gpu.cuda()\r\n                \r\n                func = GraphPoolFunction(idxn, degs, degs_gpu, aggr=aggr, edge_mem_limit=edge_mem_limit)\r\n                data = (Variable(input, requires_grad=True),)\r\n\r\n                ok = gradcheck(func, data)\r\n                self.assertTrue(ok)\r\n        \r\n        torch.set_default_tensor_type(\'torch.FloatTensor\')\r\n        \r\n    def test_batch_splitting(self):\r\n        n,in_channels = 20,10\r\n        input = torch.randn(n,in_channels)\r\n        idxn = torch.from_numpy(np.random.permutation(n))\r\n        degs = torch.LongTensor([2, 0, 3, 10, 5])\r\n        \r\n        func = GraphPoolFunction(idxn, degs, degs, aggr=GraphPoolFunction.AGGR_MAX, edge_mem_limit=1e10)\r\n        data = (Variable(input, requires_grad=True),)\r\n        output1 = func(*data)\r\n\r\n        func = GraphPoolFunction(idxn, degs, degs, aggr=GraphPoolFunction.AGGR_MAX, edge_mem_limit=1)\r\n        output2 = func(*data)\r\n\r\n        self.assertLess((output1-output2).norm(), 1e-6)        \r\n          \r\nif __name__ == \'__main__\':\r\n    unittest.main()        '"
learning/ecc/utils.py,2,"b'""""""\r\n    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\r\n    https://github.com/mys007/ecc\r\n    https://arxiv.org/abs/1704.02901\r\n    2017 Martin Simonovsky\r\n""""""\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\nfrom builtins import range\r\n\r\nimport random\r\nimport numpy as np\r\nimport torch\r\n\r\nimport ecc\r\n\r\ndef graph_info_collate_classification(batch, edge_func):\r\n    """""" Collates a list of dataset samples into a single batch. We assume that all samples have the same number of resolutions.\r\n    \r\n    Each sample is a tuple of following elements:\r\n        features: 2D Tensor of node features\r\n        classes: LongTensor of class ids\r\n        graphs: list of graphs, each for one resolution\r\n        pooldata: list of triplets, each for one resolution: (pooling map, finer graph, coarser graph)   \r\n    """"""\r\n    features, classes, graphs, pooldata = list(zip(*batch))\r\n    graphs_by_layer = list(zip(*graphs))\r\n    pooldata_by_layer = list(zip(*pooldata))\r\n    \r\n    features = torch.cat([torch.from_numpy(f) for f in features])\r\n    if features.dim()==1: features = features.view(-1,1)\r\n    \r\n    classes = torch.LongTensor(classes)\r\n    \r\n    GIs, PIs = [], []    \r\n    for graphs in graphs_by_layer:\r\n        GIs.append( ecc.GraphConvInfo(graphs, edge_func) )\r\n    for pooldata in pooldata_by_layer:\r\n        PIs.append( ecc.GraphPoolInfo(*zip(*pooldata)) )  \r\n       \r\n    return features, classes, GIs, PIs\r\n    \r\n    \r\ndef unique_rows(data):\r\n    """""" Filters unique rows from a 2D np array and also returns inverse indices. Used for edge feature compaction. """"""\r\n    # https://stackoverflow.com/questions/16970982/find-unique-rows-in-numpy-array\r\n    uniq, indices = np.unique(data.view(data.dtype.descr * data.shape[1]), return_inverse=True)\r\n    return uniq.view(data.dtype).reshape(-1, data.shape[1]), indices\r\n    \r\ndef one_hot_discretization(feat, clip_min, clip_max, upweight):\r\n    indices = np.clip(np.round(feat), clip_min, clip_max).astype(int).reshape((-1,))\r\n    onehot = np.zeros((feat.shape[0], clip_max - clip_min + 1))\r\n    onehot[np.arange(onehot.shape[0]), indices] = onehot.shape[1] if upweight else 1\r\n    return onehot    \r\n    \r\ndef get_edge_shards(degs, edge_mem_limit):\r\n    """""" Splits iteration over nodes into shards, approximately limited by `edge_mem_limit` edges per shard. \r\n    Returns a list of pairs indicating how many output nodes and edges to process in each shard.""""""\r\n    d = degs if isinstance(degs, np.ndarray) else degs.numpy()\r\n    cs = np.cumsum(d)\r\n    cse = cs // edge_mem_limit\r\n    _, cse_i, cse_c = np.unique(cse, return_index=True, return_counts=True)\r\n    \r\n    shards = []\r\n    for b in range(len(cse_i)):\r\n        numd = cse_c[b]\r\n        nume = (cs[-1] if b==len(cse_i)-1 else cs[cse_i[b+1]-1]) - cs[cse_i[b]] + d[cse_i[b]]   \r\n        shards.append( (int(numd), int(nume)) )\r\n    return shards\r\n'"
partition/ply_c/__init__.py,0,b''
