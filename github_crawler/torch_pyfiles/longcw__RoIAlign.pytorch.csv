file_path,api_count,code
setup.py,2,"b""import torch\nfrom setuptools import setup, find_packages\nfrom torch.utils.cpp_extension import BuildExtension, CUDAExtension, CppExtension\n\nmodules = [\n    CppExtension(\n        'roi_align.crop_and_resize_cpu',\n        ['roi_align/src/crop_and_resize.cpp'],\n        extra_compile_args={'cxx': ['-g', '-fopenmp']}\n        )\n]\n\nif torch.cuda.is_available():\n    modules.append(\n        CUDAExtension(\n            'roi_align.crop_and_resize_gpu',\n            ['roi_align/src/crop_and_resize_gpu.cpp',\n             'roi_align/src/cuda/crop_and_resize_kernel.cu'],\n            extra_compile_args={'cxx': ['-g', '-fopenmp'],\n                                'nvcc': ['-O2']}\n        )\n    )\n\nsetup(\n    name='roi_align',\n    version='0.0.2',\n    description='PyTorch version of RoIAlign',\n    author='Long Chen',\n    author_email='longch1024@gmail.com',\n    url='https://github.com/longcw/RoIAlign.pytorch',\n    packages=find_packages(exclude=('tests',)),\n\n    ext_modules=modules,\n    cmdclass={'build_ext': BuildExtension},\n    install_requires=['torch>=1.2.0']\n)\n"""
roi_align/__init__.py,0,"b'from .roi_align import RoIAlign, CropAndResizeFunction, CropAndResize'"
roi_align/crop_and_resize.py,6,"b'import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Function\n\nimport roi_align.crop_and_resize_cpu as crop_and_resize_cpu\nif torch.cuda.is_available():\n    import roi_align.crop_and_resize_gpu as crop_and_resize_gpu\n\n\n\nclass CropAndResizeFunction(Function):\n\n    @staticmethod\n    def forward(ctx, image, boxes, box_ind, crop_height, crop_width, extrapolation_value=0):\n        ctx.crop_height = crop_height\n        ctx.crop_width = crop_width\n        ctx.extrapolation_value = extrapolation_value\n        crops = torch.zeros_like(image)\n\n        if image.is_cuda:\n            crop_and_resize_gpu.forward(\n                image, boxes, box_ind,\n                ctx.extrapolation_value, ctx.crop_height, ctx.crop_width, crops)\n        else:\n            crop_and_resize_cpu.forward(\n                image, boxes, box_ind,\n                ctx.extrapolation_value, ctx.crop_height, ctx.crop_width, crops)\n\n        # save for backward\n        ctx.im_size = image.size()\n        ctx.save_for_backward(boxes, box_ind)\n\n        return crops\n\n    @staticmethod\n    def backward(ctx, grad_outputs):\n        boxes, box_ind = ctx.saved_tensors\n\n        grad_outputs = grad_outputs.contiguous()\n        grad_image = torch.zeros_like(grad_outputs).resize_(*ctx.im_size)\n\n        if grad_outputs.is_cuda:\n            crop_and_resize_gpu.backward(\n                grad_outputs, boxes, box_ind, grad_image\n            )\n        else:\n            crop_and_resize_cpu.backward(\n                grad_outputs, boxes, box_ind, grad_image\n            )\n\n        return grad_image, None, None, None, None, None\n\n\nclass CropAndResize(nn.Module):\n    """"""\n    Crop and resize ported from tensorflow\n    See more details on https://www.tensorflow.org/api_docs/python/tf/image/crop_and_resize\n    """"""\n\n    def __init__(self, crop_height, crop_width, extrapolation_value=0):\n        super(CropAndResize, self).__init__()\n\n        self.crop_height = crop_height\n        self.crop_width = crop_width\n        self.extrapolation_value = extrapolation_value\n\n    def forward(self, image, boxes, box_ind):\n        return CropAndResizeFunction.apply(image, boxes, box_ind, self.crop_height, self.crop_width, self.extrapolation_value)\n'"
roi_align/roi_align.py,3,"b'import torch\nfrom torch import nn\n\nfrom .crop_and_resize import CropAndResizeFunction, CropAndResize\n\n\nclass RoIAlign(nn.Module):\n\n    def __init__(self, crop_height, crop_width, extrapolation_value=0, transform_fpcoor=True):\n        super(RoIAlign, self).__init__()\n\n        self.crop_height = crop_height\n        self.crop_width = crop_width\n        self.extrapolation_value = extrapolation_value\n        self.transform_fpcoor = transform_fpcoor\n\n    def forward(self, featuremap, boxes, box_ind):\n        """"""\n        RoIAlign based on crop_and_resize.\n        See more details on https://github.com/ppwwyyxx/tensorpack/blob/6d5ba6a970710eaaa14b89d24aace179eb8ee1af/examples/FasterRCNN/model.py#L301\n        :param featuremap: NxCxHxW\n        :param boxes: Mx4 float box with (x1, y1, x2, y2) **without normalization**\n        :param box_ind: M\n        :return: MxCxoHxoW\n        """"""\n        x1, y1, x2, y2 = torch.split(boxes, 1, dim=1)\n        image_height, image_width = featuremap.size()[2:4]\n\n        if self.transform_fpcoor:\n            spacing_w = (x2 - x1) / float(self.crop_width)\n            spacing_h = (y2 - y1) / float(self.crop_height)\n\n            nx0 = (x1 + spacing_w / 2 - 0.5) / float(image_width - 1)\n            ny0 = (y1 + spacing_h / 2 - 0.5) / float(image_height - 1)\n            nw = spacing_w * float(self.crop_width - 1) / float(image_width - 1)\n            nh = spacing_h * float(self.crop_height - 1) / float(image_height - 1)\n\n            boxes = torch.cat((ny0, nx0, ny0 + nh, nx0 + nw), 1)\n        else:\n            x1 = x1 / float(image_width - 1)\n            x2 = x2 / float(image_width - 1)\n            y1 = y1 / float(image_height - 1)\n            y2 = y2 / float(image_height - 1)\n            boxes = torch.cat((y1, x1, y2, x2), 1)\n\n        boxes = boxes.detach().contiguous()\n        box_ind = box_ind.detach()\n        return CropAndResizeFunction.apply(featuremap, boxes, box_ind, self.crop_height, self.crop_width, self.extrapolation_value)\n'"
tests/crop_and_resize_example.py,7,"b""import torch\nfrom torch import nn\nfrom torchvision import transforms, utils\nfrom torch.autograd import Variable, gradcheck\nfrom roi_align.crop_and_resize import CropAndResizeFunction\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n\ndef to_varabile(tensor, requires_grad=False, is_cuda=True):\n    if is_cuda:\n        tensor = tensor.cuda()\n    var = Variable(tensor, requires_grad=requires_grad)\n    return var\n\n\ncrop_height = 500\ncrop_width = 500\nis_cuda = torch.cuda.is_available()\n\n# In this simple example the number of images and boxes is 2\nimg_path1 = 'tests/images/choco.png'\nimg_path2 = 'tests/images/snow.png'\n\n# Define the boxes ( crops )\n# box = [y1/heigth , x1/width , y2/heigth , x2/width]\nboxes_data = torch.FloatTensor([[0, 0, 1, 1], [0, 0, 0.5, 0.5]])\n\n# Create an index to say which box crops which image\nbox_index_data = torch.IntTensor([0, 1])\n\n# Import the images from file\nimage_data1 = transforms.ToTensor()(imread(img_path1)).unsqueeze(0)\nimage_data2 = transforms.ToTensor()(imread(img_path2)).unsqueeze(0)\n\n# Create a batch of 2 images\nimage_data = torch.cat((image_data1, image_data2), 0)\n\n# Convert from numpy to Variables\nimage_torch = to_varabile(image_data, is_cuda=is_cuda)\nboxes = to_varabile(boxes_data, is_cuda=is_cuda)\nbox_index = to_varabile(box_index_data, is_cuda=is_cuda)\n\n# Crops and resize bbox1 from img1 and bbox2 from img2\ncrops_torch = CropAndResizeFunction.apply(image_torch, boxes, box_index, crop_height, crop_width, 0)\n\n# Visualize the crops\nprint(crops_torch.data.size())\ncrops_torch_data = crops_torch.data.cpu().numpy().transpose(0, 2, 3, 1)\nfig = plt.figure()\nplt.subplot(121)\nplt.imshow(crops_torch_data[0])\nplt.subplot(122)\nplt.imshow(crops_torch_data[1])\nplt.show()\n"""
tests/test.py,9,"b'import numpy as np\nimport torch\nimport sys\nfrom torch import nn\nfrom torch.autograd import Variable, gradcheck\ntry:\n    import tensorflow as tf\n    import tensorflow.contrib.slim as slim\nexcept:\n    print(""Unexpected error:"", sys.exc_info()[0])\n    tf = None\n\nfrom roi_align.crop_and_resize import CropAndResizeFunction\nfrom roi_align.roi_align import RoIAlign\n\n\ndef to_varabile(arr, requires_grad=False, is_cuda=True):\n    tensor = torch.from_numpy(arr)\n    if is_cuda:\n        tensor = tensor.cuda()\n    var = Variable(tensor, requires_grad=requires_grad)\n    return var\n\n\ndef generate_data(batch_size, depth, im_height, im_width, n_boxes, xyxy=False, box_normalize=True):\n\n    # random rois\n    xs = np.random.uniform(0, im_width, size=(n_boxes, 2))\n    ys = np.random.uniform(0, im_height, size=(n_boxes, 2))\n    if box_normalize:\n        xs /= (im_width - 1)\n        ys /= (im_height - 1)\n\n    xs.sort(axis=1)\n    ys.sort(axis=1)\n\n    if xyxy:\n        boxes_data = np.stack((xs[:, 0], ys[:, 0], xs[:, 1], ys[:, 1]), axis=-1).astype(np.float32)\n    else:\n        boxes_data = np.stack((ys[:, 0], xs[:, 0], ys[:, 1], xs[:, 1]), axis=-1).astype(np.float32)\n    box_index_data = np.random.randint(0, batch_size, size=n_boxes, dtype=np.int32)\n    image_data = np.random.randn(batch_size, depth, im_height, im_width).astype(np.float32)\n\n    return image_data, boxes_data, box_index_data\n\n\ndef compare_with_tf(crop_height, crop_width, is_cuda=True):\n    # generate data\n    image_data, boxes_data, box_index_data = generate_data(\n        batch_size=2,\n        depth=128,\n        im_height=200,\n        im_width=200,\n        n_boxes=10,\n        xyxy=False, box_normalize=True)\n    # boxes_tf_data = np.stack((boxes_data[:, 1], boxes_data[:, 0], boxes_data[:, 3], boxes_data[:, 2]), axis=1)\n    # boxes_tf_data[:, 0::2] /= (image_data.shape[2] - 1.)\n    # boxes_tf_data[:, 1::2] /= (image_data.shape[3] - 1.)\n\n    # rand conv layer\n    conv_torch = nn.Conv2d(image_data.shape[1], 64, 3, padding=1, bias=False)\n    if is_cuda:\n        conv_torch = conv_torch.cuda()\n\n    # pytorch forward\n    image_torch = to_varabile(image_data, requires_grad=True, is_cuda=is_cuda)\n    boxes = to_varabile(boxes_data, requires_grad=False, is_cuda=is_cuda)\n    box_index = to_varabile(box_index_data, requires_grad=False, is_cuda=is_cuda)\n\n    print(\'pytorch forward and backward start\')\n    crops_torch = CropAndResizeFunction.apply(image_torch, boxes, box_index, crop_height, crop_width, 0)\n    crops_torch = conv_torch(crops_torch)\n    crops_torch_data = crops_torch.data.cpu().numpy()\n\n    # pytorch backward\n    loss_torch = crops_torch.sum()\n    loss_torch.backward()\n    grad_torch_data = image_torch.grad.data.cpu().numpy()\n\n    print(\'pytorch forward and backward end\')\n\n    # tf forward & backward\n    image_tf = tf.placeholder(tf.float32, (None, None, None, None), name=\'image\')\n    boxes = tf.placeholder(tf.float32, (None, 4), name=\'boxes\')\n    box_index = tf.placeholder(tf.int32, (None,), name=\'box_index\')\n\n    image_t = tf.transpose(image_tf, (0, 2, 3, 1))\n    crops_tf = tf.image.crop_and_resize(image_t, boxes, box_index, (crop_height, crop_width))\n    conv_tf = tf.nn.conv2d(crops_tf, np.transpose(conv_torch.weight.data.cpu().numpy(), (2, 3, 1, 0)),\n                           [1, 1, 1, 1], padding=\'SAME\')\n\n    trans_tf = tf.transpose(conv_tf, (0, 3, 1, 2))\n    loss_tf = tf.reduce_sum(trans_tf)\n    grad_tf = tf.gradients(loss_tf, image_tf)[0]\n\n    with tf.Session() as sess:\n        crops_tf_data, grad_tf_data = sess.run(\n            (trans_tf, grad_tf), feed_dict={image_tf: image_data, boxes: boxes_data, box_index: box_index_data}\n        )\n\n    crops_diff = np.abs(crops_tf_data - crops_torch_data)\n    print(\'forward (maxval, min_err, max_err, mean_err):\',\n          crops_tf_data.max(), crops_diff.min(), crops_diff.max(), crops_diff.mean())\n\n    grad_diff = np.abs(grad_tf_data - grad_torch_data)\n    print(\'backward (maxval, min_err, max_err, mean_err):\',\n          grad_tf_data.max(), grad_diff.min(), grad_diff.max(), grad_diff.mean())\n\n\ndef test_roialign(is_cuda=True):\n    # generate data\n    crop_height = 3\n    crop_width = 3\n    image_data, boxes_data, box_index_data = generate_data(\n        batch_size=2,\n        depth=2,\n        im_height=10,\n        im_width=10,\n        n_boxes=2,\n        xyxy=True, box_normalize=False)\n    max_inp = np.abs(image_data).max()\n    print(\'max_input:\', max_inp)\n\n    image_torch = to_varabile(image_data, requires_grad=True, is_cuda=is_cuda)\n    boxes = to_varabile(boxes_data, requires_grad=False, is_cuda=is_cuda)\n    box_index = to_varabile(box_index_data, requires_grad=False, is_cuda=is_cuda)\n\n    roi_align = RoIAlign(crop_height, crop_width, transform_fpcoor=False)\n    gradcheck(roi_align, (image_torch, boxes, box_index), eps=max_inp/500)\n\n    print(\'test ok\')\n\n\nif __name__ == \'__main__\':\n    def main():\n        crop_height = 7\n        crop_width = 7\n        is_cuda = torch.cuda.is_available()\n\n        if tf is not None:\n            compare_with_tf(crop_height, crop_width, is_cuda=is_cuda)\n        else:\n            print(\'without tensorflow\')\n\n        test_roialign(is_cuda=is_cuda)\n\n    main()\n'"
tests/test2.py,2,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\n\nfrom roi_align.roi_align import RoIAlign\n\n\ndef to_varabile(arr, requires_grad=False, is_cuda=True):\n    tensor = torch.from_numpy(arr)\n    if is_cuda:\n        tensor = tensor.cuda()\n    var = Variable(tensor, requires_grad=requires_grad)\n    return var\n\n\n# the data you want\nis_cuda = False\nimage_data = np.tile(np.arange(7, dtype=np.float32), 7).reshape(7, 7)\nimage_data = image_data[np.newaxis, np.newaxis]\nboxes_data = np.asarray([[0, 0, 3, 3]], dtype=np.float32)\nbox_index_data = np.asarray([0], dtype=np.int32)\n\nimage_torch = to_varabile(image_data, requires_grad=True, is_cuda=is_cuda)\nboxes = to_varabile(boxes_data, requires_grad=False, is_cuda=is_cuda)\nbox_index = to_varabile(box_index_data, requires_grad=False, is_cuda=is_cuda)\n\n# set transform_fpcoor to False is the crop_and_resize\nprint(RoIAlign.apply(image_torch, boxes, box_index, 3, 3, transform_fpcoor=True))'"
