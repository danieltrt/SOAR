file_path,api_count,code
src/__init__.py,0,b''
src/deepSVDD.py,2,"b'import json\nimport torch\n\nfrom base.base_dataset import BaseADDataset\nfrom networks.main import build_network, build_autoencoder\nfrom optim.deepSVDD_trainer import DeepSVDDTrainer\nfrom optim.ae_trainer import AETrainer\n\n\nclass DeepSVDD(object):\n    """"""A class for the Deep SVDD method.\n\n    Attributes:\n        objective: A string specifying the Deep SVDD objective (either \'one-class\' or \'soft-boundary\').\n        nu: Deep SVDD hyperparameter nu (must be 0 < nu <= 1).\n        R: Hypersphere radius R.\n        c: Hypersphere center c.\n        net_name: A string indicating the name of the neural network to use.\n        net: The neural network \\phi.\n        ae_net: The autoencoder network corresponding to \\phi for network weights pretraining.\n        trainer: DeepSVDDTrainer to train a Deep SVDD model.\n        optimizer_name: A string indicating the optimizer to use for training the Deep SVDD network.\n        ae_trainer: AETrainer to train an autoencoder in pretraining.\n        ae_optimizer_name: A string indicating the optimizer to use for pretraining the autoencoder.\n        results: A dictionary to save the results.\n    """"""\n\n    def __init__(self, objective: str = \'one-class\', nu: float = 0.1):\n        """"""Inits DeepSVDD with one of the two objectives and hyperparameter nu.""""""\n\n        assert objective in (\'one-class\', \'soft-boundary\'), ""Objective must be either \'one-class\' or \'soft-boundary\'.""\n        self.objective = objective\n        assert (0 < nu) & (nu <= 1), ""For hyperparameter nu, it must hold: 0 < nu <= 1.""\n        self.nu = nu\n        self.R = 0.0  # hypersphere radius R\n        self.c = None  # hypersphere center c\n\n        self.net_name = None\n        self.net = None  # neural network \\phi\n\n        self.trainer = None\n        self.optimizer_name = None\n\n        self.ae_net = None  # autoencoder network for pretraining\n        self.ae_trainer = None\n        self.ae_optimizer_name = None\n\n        self.results = {\n            \'train_time\': None,\n            \'test_auc\': None,\n            \'test_time\': None,\n            \'test_scores\': None,\n        }\n\n    def set_network(self, net_name):\n        """"""Builds the neural network \\phi.""""""\n        self.net_name = net_name\n        self.net = build_network(net_name)\n\n    def train(self, dataset: BaseADDataset, optimizer_name: str = \'adam\', lr: float = 0.001, n_epochs: int = 50,\n              lr_milestones: tuple = (), batch_size: int = 128, weight_decay: float = 1e-6, device: str = \'cuda\',\n              n_jobs_dataloader: int = 0):\n        """"""Trains the Deep SVDD model on the training data.""""""\n\n        self.optimizer_name = optimizer_name\n        self.trainer = DeepSVDDTrainer(self.objective, self.R, self.c, self.nu, optimizer_name, lr=lr,\n                                       n_epochs=n_epochs, lr_milestones=lr_milestones, batch_size=batch_size,\n                                       weight_decay=weight_decay, device=device, n_jobs_dataloader=n_jobs_dataloader)\n        # Get the model\n        self.net = self.trainer.train(dataset, self.net)\n        self.R = float(self.trainer.R.cpu().data.numpy())  # get float\n        self.c = self.trainer.c.cpu().data.numpy().tolist()  # get list\n        self.results[\'train_time\'] = self.trainer.train_time\n\n    def test(self, dataset: BaseADDataset, device: str = \'cuda\', n_jobs_dataloader: int = 0):\n        """"""Tests the Deep SVDD model on the test data.""""""\n\n        if self.trainer is None:\n            self.trainer = DeepSVDDTrainer(self.objective, self.R, self.c, self.nu,\n                                           device=device, n_jobs_dataloader=n_jobs_dataloader)\n\n        self.trainer.test(dataset, self.net)\n        # Get results\n        self.results[\'test_auc\'] = self.trainer.test_auc\n        self.results[\'test_time\'] = self.trainer.test_time\n        self.results[\'test_scores\'] = self.trainer.test_scores\n\n    def pretrain(self, dataset: BaseADDataset, optimizer_name: str = \'adam\', lr: float = 0.001, n_epochs: int = 100,\n                 lr_milestones: tuple = (), batch_size: int = 128, weight_decay: float = 1e-6, device: str = \'cuda\',\n                 n_jobs_dataloader: int = 0):\n        """"""Pretrains the weights for the Deep SVDD network \\phi via autoencoder.""""""\n\n        self.ae_net = build_autoencoder(self.net_name)\n        self.ae_optimizer_name = optimizer_name\n        self.ae_trainer = AETrainer(optimizer_name, lr=lr, n_epochs=n_epochs, lr_milestones=lr_milestones,\n                                    batch_size=batch_size, weight_decay=weight_decay, device=device,\n                                    n_jobs_dataloader=n_jobs_dataloader)\n        self.ae_net = self.ae_trainer.train(dataset, self.ae_net)\n        self.ae_trainer.test(dataset, self.ae_net)\n        self.init_network_weights_from_pretraining()\n\n    def init_network_weights_from_pretraining(self):\n        """"""Initialize the Deep SVDD network weights from the encoder weights of the pretraining autoencoder.""""""\n\n        net_dict = self.net.state_dict()\n        ae_net_dict = self.ae_net.state_dict()\n\n        # Filter out decoder network keys\n        ae_net_dict = {k: v for k, v in ae_net_dict.items() if k in net_dict}\n        # Overwrite values in the existing state_dict\n        net_dict.update(ae_net_dict)\n        # Load the new state_dict\n        self.net.load_state_dict(net_dict)\n\n    def save_model(self, export_model, save_ae=True):\n        """"""Save Deep SVDD model to export_model.""""""\n\n        net_dict = self.net.state_dict()\n        ae_net_dict = self.ae_net.state_dict() if save_ae else None\n\n        torch.save({\'R\': self.R,\n                    \'c\': self.c,\n                    \'net_dict\': net_dict,\n                    \'ae_net_dict\': ae_net_dict}, export_model)\n\n    def load_model(self, model_path, load_ae=False):\n        """"""Load Deep SVDD model from model_path.""""""\n\n        model_dict = torch.load(model_path)\n\n        self.R = model_dict[\'R\']\n        self.c = model_dict[\'c\']\n        self.net.load_state_dict(model_dict[\'net_dict\'])\n        if load_ae:\n            if self.ae_net is None:\n                self.ae_net = build_autoencoder(self.net_name)\n            self.ae_net.load_state_dict(model_dict[\'ae_net_dict\'])\n\n    def save_results(self, export_json):\n        """"""Save results dict to a JSON-file.""""""\n        with open(export_json, \'w\') as fp:\n            json.dump(self.results, fp)\n'"
src/main.py,4,"b'import click\nimport torch\nimport logging\nimport random\nimport numpy as np\n\nfrom utils.config import Config\nfrom utils.visualization.plot_images_grid import plot_images_grid\nfrom deepSVDD import DeepSVDD\nfrom datasets.main import load_dataset\n\n\n################################################################################\n# Settings\n################################################################################\n@click.command()\n@click.argument(\'dataset_name\', type=click.Choice([\'mnist\', \'cifar10\']))\n@click.argument(\'net_name\', type=click.Choice([\'mnist_LeNet\', \'cifar10_LeNet\', \'cifar10_LeNet_ELU\']))\n@click.argument(\'xp_path\', type=click.Path(exists=True))\n@click.argument(\'data_path\', type=click.Path(exists=True))\n@click.option(\'--load_config\', type=click.Path(exists=True), default=None,\n              help=\'Config JSON-file path (default: None).\')\n@click.option(\'--load_model\', type=click.Path(exists=True), default=None,\n              help=\'Model file path (default: None).\')\n@click.option(\'--objective\', type=click.Choice([\'one-class\', \'soft-boundary\']), default=\'one-class\',\n              help=\'Specify Deep SVDD objective (""one-class"" or ""soft-boundary"").\')\n@click.option(\'--nu\', type=float, default=0.1, help=\'Deep SVDD hyperparameter nu (must be 0 < nu <= 1).\')\n@click.option(\'--device\', type=str, default=\'cuda\', help=\'Computation device to use (""cpu"", ""cuda"", ""cuda:2"", etc.).\')\n@click.option(\'--seed\', type=int, default=-1, help=\'Set seed. If -1, use randomization.\')\n@click.option(\'--optimizer_name\', type=click.Choice([\'adam\', \'amsgrad\']), default=\'adam\',\n              help=\'Name of the optimizer to use for Deep SVDD network training.\')\n@click.option(\'--lr\', type=float, default=0.001,\n              help=\'Initial learning rate for Deep SVDD network training. Default=0.001\')\n@click.option(\'--n_epochs\', type=int, default=50, help=\'Number of epochs to train.\')\n@click.option(\'--lr_milestone\', type=int, default=0, multiple=True,\n              help=\'Lr scheduler milestones at which lr is multiplied by 0.1. Can be multiple and must be increasing.\')\n@click.option(\'--batch_size\', type=int, default=128, help=\'Batch size for mini-batch training.\')\n@click.option(\'--weight_decay\', type=float, default=1e-6,\n              help=\'Weight decay (L2 penalty) hyperparameter for Deep SVDD objective.\')\n@click.option(\'--pretrain\', type=bool, default=True,\n              help=\'Pretrain neural network parameters via autoencoder.\')\n@click.option(\'--ae_optimizer_name\', type=click.Choice([\'adam\', \'amsgrad\']), default=\'adam\',\n              help=\'Name of the optimizer to use for autoencoder pretraining.\')\n@click.option(\'--ae_lr\', type=float, default=0.001,\n              help=\'Initial learning rate for autoencoder pretraining. Default=0.001\')\n@click.option(\'--ae_n_epochs\', type=int, default=100, help=\'Number of epochs to train autoencoder.\')\n@click.option(\'--ae_lr_milestone\', type=int, default=0, multiple=True,\n              help=\'Lr scheduler milestones at which lr is multiplied by 0.1. Can be multiple and must be increasing.\')\n@click.option(\'--ae_batch_size\', type=int, default=128, help=\'Batch size for mini-batch autoencoder training.\')\n@click.option(\'--ae_weight_decay\', type=float, default=1e-6,\n              help=\'Weight decay (L2 penalty) hyperparameter for autoencoder objective.\')\n@click.option(\'--n_jobs_dataloader\', type=int, default=0,\n              help=\'Number of workers for data loading. 0 means that the data will be loaded in the main process.\')\n@click.option(\'--normal_class\', type=int, default=0,\n              help=\'Specify the normal class of the dataset (all other classes are considered anomalous).\')\ndef main(dataset_name, net_name, xp_path, data_path, load_config, load_model, objective, nu, device, seed,\n         optimizer_name, lr, n_epochs, lr_milestone, batch_size, weight_decay, pretrain, ae_optimizer_name, ae_lr,\n         ae_n_epochs, ae_lr_milestone, ae_batch_size, ae_weight_decay, n_jobs_dataloader, normal_class):\n    """"""\n    Deep SVDD, a fully deep method for anomaly detection.\n\n    :arg DATASET_NAME: Name of the dataset to load.\n    :arg NET_NAME: Name of the neural network to use.\n    :arg XP_PATH: Export path for logging the experiment.\n    :arg DATA_PATH: Root path of data.\n    """"""\n\n    # Get configuration\n    cfg = Config(locals().copy())\n\n    # Set up logging\n    logging.basicConfig(level=logging.INFO)\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n    formatter = logging.Formatter(\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\')\n    log_file = xp_path + \'/log.txt\'\n    file_handler = logging.FileHandler(log_file)\n    file_handler.setLevel(logging.INFO)\n    file_handler.setFormatter(formatter)\n    logger.addHandler(file_handler)\n\n    # Print arguments\n    logger.info(\'Log file is %s.\' % log_file)\n    logger.info(\'Data path is %s.\' % data_path)\n    logger.info(\'Export path is %s.\' % xp_path)\n\n    logger.info(\'Dataset: %s\' % dataset_name)\n    logger.info(\'Normal class: %d\' % normal_class)\n    logger.info(\'Network: %s\' % net_name)\n\n    # If specified, load experiment config from JSON-file\n    if load_config:\n        cfg.load_config(import_json=load_config)\n        logger.info(\'Loaded configuration from %s.\' % load_config)\n\n    # Print configuration\n    logger.info(\'Deep SVDD objective: %s\' % cfg.settings[\'objective\'])\n    logger.info(\'Nu-paramerter: %.2f\' % cfg.settings[\'nu\'])\n\n    # Set seed\n    if cfg.settings[\'seed\'] != -1:\n        random.seed(cfg.settings[\'seed\'])\n        np.random.seed(cfg.settings[\'seed\'])\n        torch.manual_seed(cfg.settings[\'seed\'])\n        logger.info(\'Set seed to %d.\' % cfg.settings[\'seed\'])\n\n    # Default device to \'cpu\' if cuda is not available\n    if not torch.cuda.is_available():\n        device = \'cpu\'\n    logger.info(\'Computation device: %s\' % device)\n    logger.info(\'Number of dataloader workers: %d\' % n_jobs_dataloader)\n\n    # Load data\n    dataset = load_dataset(dataset_name, data_path, normal_class)\n\n    # Initialize DeepSVDD model and set neural network \\phi\n    deep_SVDD = DeepSVDD(cfg.settings[\'objective\'], cfg.settings[\'nu\'])\n    deep_SVDD.set_network(net_name)\n    # If specified, load Deep SVDD model (radius R, center c, network weights, and possibly autoencoder weights)\n    if load_model:\n        deep_SVDD.load_model(model_path=load_model, load_ae=True)\n        logger.info(\'Loading model from %s.\' % load_model)\n\n    logger.info(\'Pretraining: %s\' % pretrain)\n    if pretrain:\n        # Log pretraining details\n        logger.info(\'Pretraining optimizer: %s\' % cfg.settings[\'ae_optimizer_name\'])\n        logger.info(\'Pretraining learning rate: %g\' % cfg.settings[\'ae_lr\'])\n        logger.info(\'Pretraining epochs: %d\' % cfg.settings[\'ae_n_epochs\'])\n        logger.info(\'Pretraining learning rate scheduler milestones: %s\' % (cfg.settings[\'ae_lr_milestone\'],))\n        logger.info(\'Pretraining batch size: %d\' % cfg.settings[\'ae_batch_size\'])\n        logger.info(\'Pretraining weight decay: %g\' % cfg.settings[\'ae_weight_decay\'])\n\n        # Pretrain model on dataset (via autoencoder)\n        deep_SVDD.pretrain(dataset,\n                           optimizer_name=cfg.settings[\'ae_optimizer_name\'],\n                           lr=cfg.settings[\'ae_lr\'],\n                           n_epochs=cfg.settings[\'ae_n_epochs\'],\n                           lr_milestones=cfg.settings[\'ae_lr_milestone\'],\n                           batch_size=cfg.settings[\'ae_batch_size\'],\n                           weight_decay=cfg.settings[\'ae_weight_decay\'],\n                           device=device,\n                           n_jobs_dataloader=n_jobs_dataloader)\n\n    # Log training details\n    logger.info(\'Training optimizer: %s\' % cfg.settings[\'optimizer_name\'])\n    logger.info(\'Training learning rate: %g\' % cfg.settings[\'lr\'])\n    logger.info(\'Training epochs: %d\' % cfg.settings[\'n_epochs\'])\n    logger.info(\'Training learning rate scheduler milestones: %s\' % (cfg.settings[\'lr_milestone\'],))\n    logger.info(\'Training batch size: %d\' % cfg.settings[\'batch_size\'])\n    logger.info(\'Training weight decay: %g\' % cfg.settings[\'weight_decay\'])\n\n    # Train model on dataset\n    deep_SVDD.train(dataset,\n                    optimizer_name=cfg.settings[\'optimizer_name\'],\n                    lr=cfg.settings[\'lr\'],\n                    n_epochs=cfg.settings[\'n_epochs\'],\n                    lr_milestones=cfg.settings[\'lr_milestone\'],\n                    batch_size=cfg.settings[\'batch_size\'],\n                    weight_decay=cfg.settings[\'weight_decay\'],\n                    device=device,\n                    n_jobs_dataloader=n_jobs_dataloader)\n\n    # Test model\n    deep_SVDD.test(dataset, device=device, n_jobs_dataloader=n_jobs_dataloader)\n\n    # Plot most anomalous and most normal (within-class) test samples\n    indices, labels, scores = zip(*deep_SVDD.results[\'test_scores\'])\n    indices, labels, scores = np.array(indices), np.array(labels), np.array(scores)\n    idx_sorted = indices[labels == 0][np.argsort(scores[labels == 0])]  # sorted from lowest to highest anomaly score\n\n    if dataset_name in (\'mnist\', \'cifar10\'):\n\n        if dataset_name == \'mnist\':\n            X_normals = dataset.test_set.test_data[idx_sorted[:32], ...].unsqueeze(1)\n            X_outliers = dataset.test_set.test_data[idx_sorted[-32:], ...].unsqueeze(1)\n\n        if dataset_name == \'cifar10\':\n            X_normals = torch.tensor(np.transpose(dataset.test_set.test_data[idx_sorted[:32], ...], (0, 3, 1, 2)))\n            X_outliers = torch.tensor(np.transpose(dataset.test_set.test_data[idx_sorted[-32:], ...], (0, 3, 1, 2)))\n\n        plot_images_grid(X_normals, export_img=xp_path + \'/normals\', title=\'Most normal examples\', padding=2)\n        plot_images_grid(X_outliers, export_img=xp_path + \'/outliers\', title=\'Most anomalous examples\', padding=2)\n\n    # Save results, model, and configuration\n    deep_SVDD.save_results(export_json=xp_path + \'/results.json\')\n    deep_SVDD.save_model(export_model=xp_path + \'/model.tar\')\n    cfg.save_config(export_json=xp_path + \'/config.json\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
src/base/__init__.py,0,b'from .base_dataset import *\nfrom .torchvision_dataset import *\nfrom .base_net import *\nfrom .base_trainer import *\n'
src/base/base_dataset.py,4,"b'from abc import ABC, abstractmethod\nfrom torch.utils.data import DataLoader\n\n\nclass BaseADDataset(ABC):\n    """"""Anomaly detection dataset base class.""""""\n\n    def __init__(self, root: str):\n        super().__init__()\n        self.root = root  # root path to data\n\n        self.n_classes = 2  # 0: normal, 1: outlier\n        self.normal_classes = None  # tuple with original class labels that define the normal class\n        self.outlier_classes = None  # tuple with original class labels that define the outlier class\n\n        self.train_set = None  # must be of type torch.utils.data.Dataset\n        self.test_set = None  # must be of type torch.utils.data.Dataset\n\n    @abstractmethod\n    def loaders(self, batch_size: int, shuffle_train=True, shuffle_test=False, num_workers: int = 0) -> (\n            DataLoader, DataLoader):\n        """"""Implement data loaders of type torch.utils.data.DataLoader for train_set and test_set.""""""\n        pass\n\n    def __repr__(self):\n        return self.__class__.__name__\n'"
src/base/base_net.py,1,"b'import logging\nimport torch.nn as nn\nimport numpy as np\n\n\nclass BaseNet(nn.Module):\n    """"""Base class for all neural networks.""""""\n\n    def __init__(self):\n        super().__init__()\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.rep_dim = None  # representation dimensionality, i.e. dim of the last layer\n\n    def forward(self, *input):\n        """"""\n        Forward pass logic\n        :return: Network output\n        """"""\n        raise NotImplementedError\n\n    def summary(self):\n        """"""Network summary.""""""\n        net_parameters = filter(lambda p: p.requires_grad, self.parameters())\n        params = sum([np.prod(p.size()) for p in net_parameters])\n        self.logger.info(\'Trainable parameters: {}\'.format(params))\n        self.logger.info(self)\n'"
src/base/base_trainer.py,0,"b'from abc import ABC, abstractmethod\nfrom .base_dataset import BaseADDataset\nfrom .base_net import BaseNet\n\n\nclass BaseTrainer(ABC):\n    """"""Trainer base class.""""""\n\n    def __init__(self, optimizer_name: str, lr: float, n_epochs: int, lr_milestones: tuple, batch_size: int,\n                 weight_decay: float, device: str, n_jobs_dataloader: int):\n        super().__init__()\n        self.optimizer_name = optimizer_name\n        self.lr = lr\n        self.n_epochs = n_epochs\n        self.lr_milestones = lr_milestones\n        self.batch_size = batch_size\n        self.weight_decay = weight_decay\n        self.device = device\n        self.n_jobs_dataloader = n_jobs_dataloader\n\n    @abstractmethod\n    def train(self, dataset: BaseADDataset, net: BaseNet) -> BaseNet:\n        """"""\n        Implement train method that trains the given network using the train_set of dataset.\n        :return: Trained net\n        """"""\n        pass\n\n    @abstractmethod\n    def test(self, dataset: BaseADDataset, net: BaseNet):\n        """"""\n        Implement test method that evaluates the test_set of dataset on the given network.\n        """"""\n        pass\n'"
src/base/torchvision_dataset.py,1,"b'from .base_dataset import BaseADDataset\nfrom torch.utils.data import DataLoader\n\n\nclass TorchvisionDataset(BaseADDataset):\n    """"""TorchvisionDataset class for datasets already implemented in torchvision.datasets.""""""\n\n    def __init__(self, root: str):\n        super().__init__(root)\n\n    def loaders(self, batch_size: int, shuffle_train=True, shuffle_test=False, num_workers: int = 0) -> (\n            DataLoader, DataLoader):\n        train_loader = DataLoader(dataset=self.train_set, batch_size=batch_size, shuffle=shuffle_train,\n                                  num_workers=num_workers)\n        test_loader = DataLoader(dataset=self.test_set, batch_size=batch_size, shuffle=shuffle_test,\n                                 num_workers=num_workers)\n        return train_loader, test_loader\n'"
src/datasets/__init__.py,0,b'from .main import load_dataset\nfrom .mnist import MNIST_Dataset\nfrom .cifar10 import CIFAR10_Dataset\n'
src/datasets/cifar10.py,1,"b'from torch.utils.data import Subset\nfrom PIL import Image\nfrom torchvision.datasets import CIFAR10\nfrom base.torchvision_dataset import TorchvisionDataset\nfrom .preprocessing import get_target_label_idx, global_contrast_normalization\n\nimport torchvision.transforms as transforms\n\n\nclass CIFAR10_Dataset(TorchvisionDataset):\n\n    def __init__(self, root: str, normal_class=5):\n        super().__init__(root)\n\n        self.n_classes = 2  # 0: normal, 1: outlier\n        self.normal_classes = tuple([normal_class])\n        self.outlier_classes = list(range(0, 10))\n        self.outlier_classes.remove(normal_class)\n\n        # Pre-computed min and max values (after applying GCN) from train data per class\n        min_max = [(-28.94083453598571, 13.802961825439636),\n                   (-6.681770233365245, 9.158067708230273),\n                   (-34.924463588638204, 14.419298165027628),\n                   (-10.599172931391799, 11.093187820377565),\n                   (-11.945022995801637, 10.628045447867583),\n                   (-9.691969487694928, 8.948326776180823),\n                   (-9.174940012342555, 13.847014686472365),\n                   (-6.876682005899029, 12.282371383343161),\n                   (-15.603507135507172, 15.2464923804279),\n                   (-6.132882973622672, 8.046098172351265)]\n\n        # CIFAR-10 preprocessing: GCN (with L1 norm) and min-max feature scaling to [0,1]\n        transform = transforms.Compose([transforms.ToTensor(),\n                                        transforms.Lambda(lambda x: global_contrast_normalization(x, scale=\'l1\')),\n                                        transforms.Normalize([min_max[normal_class][0]] * 3,\n                                                             [min_max[normal_class][1] - min_max[normal_class][0]] * 3)])\n\n        target_transform = transforms.Lambda(lambda x: int(x in self.outlier_classes))\n\n        train_set = MyCIFAR10(root=self.root, train=True, download=True,\n                              transform=transform, target_transform=target_transform)\n        # Subset train set to normal class\n        train_idx_normal = get_target_label_idx(train_set.train_labels, self.normal_classes)\n        self.train_set = Subset(train_set, train_idx_normal)\n\n        self.test_set = MyCIFAR10(root=self.root, train=False, download=True,\n                                  transform=transform, target_transform=target_transform)\n\n\nclass MyCIFAR10(CIFAR10):\n    """"""Torchvision CIFAR10 class with patch of __getitem__ method to also return the index of a data sample.""""""\n\n    def __init__(self, *args, **kwargs):\n        super(MyCIFAR10, self).__init__(*args, **kwargs)\n\n    def __getitem__(self, index):\n        """"""Override the original method of the CIFAR10 class.\n        Args:\n            index (int): Index\n        Returns:\n            triple: (image, target, index) where target is index of the target class.\n        """"""\n        if self.train:\n            img, target = self.train_data[index], self.train_labels[index]\n        else:\n            img, target = self.test_data[index], self.test_labels[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(img)\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target, index  # only line changed\n'"
src/datasets/main.py,0,"b'from .mnist import MNIST_Dataset\nfrom .cifar10 import CIFAR10_Dataset\n\n\ndef load_dataset(dataset_name, data_path, normal_class):\n    """"""Loads the dataset.""""""\n\n    implemented_datasets = (\'mnist\', \'cifar10\')\n    assert dataset_name in implemented_datasets\n\n    dataset = None\n\n    if dataset_name == \'mnist\':\n        dataset = MNIST_Dataset(root=data_path, normal_class=normal_class)\n\n    if dataset_name == \'cifar10\':\n        dataset = CIFAR10_Dataset(root=data_path, normal_class=normal_class)\n\n    return dataset\n'"
src/datasets/mnist.py,1,"b'from torch.utils.data import Subset\nfrom PIL import Image\nfrom torchvision.datasets import MNIST\nfrom base.torchvision_dataset import TorchvisionDataset\nfrom .preprocessing import get_target_label_idx, global_contrast_normalization\n\nimport torchvision.transforms as transforms\n\n\nclass MNIST_Dataset(TorchvisionDataset):\n\n    def __init__(self, root: str, normal_class=0):\n        super().__init__(root)\n\n        self.n_classes = 2  # 0: normal, 1: outlier\n        self.normal_classes = tuple([normal_class])\n        self.outlier_classes = list(range(0, 10))\n        self.outlier_classes.remove(normal_class)\n\n        # Pre-computed min and max values (after applying GCN) from train data per class\n        min_max = [(-0.8826567065619495, 9.001545489292527),\n                   (-0.6661464580883915, 20.108062262467364),\n                   (-0.7820454743183202, 11.665100841080346),\n                   (-0.7645772083211267, 12.895051191467457),\n                   (-0.7253923114302238, 12.683235701611533),\n                   (-0.7698501867861425, 13.103278415430502),\n                   (-0.778418217980696, 10.457837397569108),\n                   (-0.7129780970522351, 12.057777597673047),\n                   (-0.8280402650205075, 10.581538445782988),\n                   (-0.7369959242164307, 10.697039838804978)]\n\n        # MNIST preprocessing: GCN (with L1 norm) and min-max feature scaling to [0,1]\n        transform = transforms.Compose([transforms.ToTensor(),\n                                        transforms.Lambda(lambda x: global_contrast_normalization(x, scale=\'l1\')),\n                                        transforms.Normalize([min_max[normal_class][0]],\n                                                             [min_max[normal_class][1] - min_max[normal_class][0]])])\n\n        target_transform = transforms.Lambda(lambda x: int(x in self.outlier_classes))\n\n        train_set = MyMNIST(root=self.root, train=True, download=True,\n                            transform=transform, target_transform=target_transform)\n        # Subset train_set to normal class\n        train_idx_normal = get_target_label_idx(train_set.train_labels.clone().data.cpu().numpy(), self.normal_classes)\n        self.train_set = Subset(train_set, train_idx_normal)\n\n        self.test_set = MyMNIST(root=self.root, train=False, download=True,\n                                transform=transform, target_transform=target_transform)\n\n\nclass MyMNIST(MNIST):\n    """"""Torchvision MNIST class with patch of __getitem__ method to also return the index of a data sample.""""""\n\n    def __init__(self, *args, **kwargs):\n        super(MyMNIST, self).__init__(*args, **kwargs)\n\n    def __getitem__(self, index):\n        """"""Override the original method of the MNIST class.\n        Args:\n            index (int): Index\n        Returns:\n            triple: (image, target, index) where target is index of the target class.\n        """"""\n        if self.train:\n            img, target = self.train_data[index], self.train_labels[index]\n        else:\n            img, target = self.test_data[index], self.test_labels[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(img.numpy(), mode=\'L\')\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target, index  # only line changed\n'"
src/datasets/preprocessing.py,4,"b'import torch\nimport numpy as np\n\n\ndef get_target_label_idx(labels, targets):\n    """"""\n    Get the indices of labels that are included in targets.\n    :param labels: array of labels\n    :param targets: list/tuple of target labels\n    :return: list with indices of target labels\n    """"""\n    return np.argwhere(np.isin(labels, targets)).flatten().tolist()\n\n\ndef global_contrast_normalization(x: torch.tensor, scale=\'l2\'):\n    """"""\n    Apply global contrast normalization to tensor, i.e. subtract mean across features (pixels) and normalize by scale,\n    which is either the standard deviation, L1- or L2-norm across features (pixels).\n    Note this is a *per sample* normalization globally across features (and not across the dataset).\n    """"""\n\n    assert scale in (\'l1\', \'l2\')\n\n    n_features = int(np.prod(x.shape))\n\n    mean = torch.mean(x)  # mean over all features (pixels) per sample\n    x -= mean\n\n    if scale == \'l1\':\n        x_scale = torch.mean(torch.abs(x))\n\n    if scale == \'l2\':\n        x_scale = torch.sqrt(torch.sum(x ** 2)) / n_features\n\n    x /= x_scale\n\n    return x\n'"
src/networks/__init__.py,0,"b'from .main import build_network, build_autoencoder\nfrom .mnist_LeNet import MNIST_LeNet, MNIST_LeNet_Autoencoder\nfrom .cifar10_LeNet import CIFAR10_LeNet, CIFAR10_LeNet_Autoencoder\nfrom .cifar10_LeNet_elu import CIFAR10_LeNet_ELU, CIFAR10_LeNet_ELU_Autoencoder\n'"
src/networks/cifar10_LeNet.py,3,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom base.base_net import BaseNet\n\n\nclass CIFAR10_LeNet(BaseNet):\n\n    def __init__(self):\n        super().__init__()\n\n        self.rep_dim = 128\n        self.pool = nn.MaxPool2d(2, 2)\n\n        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n        self.fc1 = nn.Linear(128 * 4 * 4, self.rep_dim, bias=False)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(F.leaky_relu(self.bn2d1(x)))\n        x = self.conv2(x)\n        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n        x = self.conv3(x)\n        x = self.pool(F.leaky_relu(self.bn2d3(x)))\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        return x\n\n\nclass CIFAR10_LeNet_Autoencoder(BaseNet):\n\n    def __init__(self):\n        super().__init__()\n\n        self.rep_dim = 128\n        self.pool = nn.MaxPool2d(2, 2)\n\n        # Encoder (must match the Deep SVDD network above)\n        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.conv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.conv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.conv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n        self.fc1 = nn.Linear(128 * 4 * 4, self.rep_dim, bias=False)\n        self.bn1d = nn.BatchNorm1d(self.rep_dim, eps=1e-04, affine=False)\n\n        # Decoder\n        self.deconv1 = nn.ConvTranspose2d(int(self.rep_dim / (4 * 4)), 128, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.deconv1.weight, gain=nn.init.calculate_gain('leaky_relu'))\n        self.bn2d4 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.deconv2.weight, gain=nn.init.calculate_gain('leaky_relu'))\n        self.bn2d5 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n        self.deconv3 = nn.ConvTranspose2d(64, 32, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.deconv3.weight, gain=nn.init.calculate_gain('leaky_relu'))\n        self.bn2d6 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n        self.deconv4 = nn.ConvTranspose2d(32, 3, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.deconv4.weight, gain=nn.init.calculate_gain('leaky_relu'))\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(F.leaky_relu(self.bn2d1(x)))\n        x = self.conv2(x)\n        x = self.pool(F.leaky_relu(self.bn2d2(x)))\n        x = self.conv3(x)\n        x = self.pool(F.leaky_relu(self.bn2d3(x)))\n        x = x.view(x.size(0), -1)\n        x = self.bn1d(self.fc1(x))\n        x = x.view(x.size(0), int(self.rep_dim / (4 * 4)), 4, 4)\n        x = F.leaky_relu(x)\n        x = self.deconv1(x)\n        x = F.interpolate(F.leaky_relu(self.bn2d4(x)), scale_factor=2)\n        x = self.deconv2(x)\n        x = F.interpolate(F.leaky_relu(self.bn2d5(x)), scale_factor=2)\n        x = self.deconv3(x)\n        x = F.interpolate(F.leaky_relu(self.bn2d6(x)), scale_factor=2)\n        x = self.deconv4(x)\n        x = torch.sigmoid(x)\n        return x\n"""
src/networks/cifar10_LeNet_elu.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom base.base_net import BaseNet\n\n\nclass CIFAR10_LeNet_ELU(BaseNet):\n\n    def __init__(self):\n        super().__init__()\n\n        self.rep_dim = 128\n        self.pool = nn.MaxPool2d(2, 2)\n\n        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n        self.fc1 = nn.Linear(128 * 4 * 4, self.rep_dim, bias=False)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(F.elu(self.bn2d1(x)))\n        x = self.conv2(x)\n        x = self.pool(F.elu(self.bn2d2(x)))\n        x = self.conv3(x)\n        x = self.pool(F.elu(self.bn2d3(x)))\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        return x\n\n\nclass CIFAR10_LeNet_ELU_Autoencoder(BaseNet):\n\n    def __init__(self):\n        super().__init__()\n\n        self.rep_dim = 128\n        self.pool = nn.MaxPool2d(2, 2)\n\n        # Encoder (must match the Deep SVDD network above)\n        self.conv1 = nn.Conv2d(3, 32, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.conv1.weight)\n        self.bn2d1 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n        self.conv2 = nn.Conv2d(32, 64, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.conv2.weight)\n        self.bn2d2 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n        self.conv3 = nn.Conv2d(64, 128, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.conv3.weight)\n        self.bn2d3 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n        self.fc1 = nn.Linear(128 * 4 * 4, self.rep_dim, bias=False)\n        self.bn1d = nn.BatchNorm1d(self.rep_dim, eps=1e-04, affine=False)\n\n        # Decoder\n        self.deconv1 = nn.ConvTranspose2d(int(self.rep_dim / (4 * 4)), 128, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.deconv1.weight)\n        self.bn2d4 = nn.BatchNorm2d(128, eps=1e-04, affine=False)\n        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.deconv2.weight)\n        self.bn2d5 = nn.BatchNorm2d(64, eps=1e-04, affine=False)\n        self.deconv3 = nn.ConvTranspose2d(64, 32, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.deconv3.weight)\n        self.bn2d6 = nn.BatchNorm2d(32, eps=1e-04, affine=False)\n        self.deconv4 = nn.ConvTranspose2d(32, 3, 5, bias=False, padding=2)\n        nn.init.xavier_uniform_(self.deconv4.weight)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(F.elu(self.bn2d1(x)))\n        x = self.conv2(x)\n        x = self.pool(F.elu(self.bn2d2(x)))\n        x = self.conv3(x)\n        x = self.pool(F.elu(self.bn2d3(x)))\n        x = x.view(x.size(0), -1)\n        x = self.bn1d(self.fc1(x))\n        x = x.view(x.size(0), int(self.rep_dim / (4 * 4)), 4, 4)\n        x = F.elu(x)\n        x = self.deconv1(x)\n        x = F.interpolate(F.elu(self.bn2d4(x)), scale_factor=2)\n        x = self.deconv2(x)\n        x = F.interpolate(F.elu(self.bn2d5(x)), scale_factor=2)\n        x = self.deconv3(x)\n        x = F.interpolate(F.elu(self.bn2d6(x)), scale_factor=2)\n        x = self.deconv4(x)\n        x = torch.sigmoid(x)\n        return x\n'"
src/networks/main.py,0,"b'from .mnist_LeNet import MNIST_LeNet, MNIST_LeNet_Autoencoder\nfrom .cifar10_LeNet import CIFAR10_LeNet, CIFAR10_LeNet_Autoencoder\nfrom .cifar10_LeNet_elu import CIFAR10_LeNet_ELU, CIFAR10_LeNet_ELU_Autoencoder\n\n\ndef build_network(net_name):\n    """"""Builds the neural network.""""""\n\n    implemented_networks = (\'mnist_LeNet\', \'cifar10_LeNet\', \'cifar10_LeNet_ELU\')\n    assert net_name in implemented_networks\n\n    net = None\n\n    if net_name == \'mnist_LeNet\':\n        net = MNIST_LeNet()\n\n    if net_name == \'cifar10_LeNet\':\n        net = CIFAR10_LeNet()\n\n    if net_name == \'cifar10_LeNet_ELU\':\n        net = CIFAR10_LeNet_ELU()\n\n    return net\n\n\ndef build_autoencoder(net_name):\n    """"""Builds the corresponding autoencoder network.""""""\n\n    implemented_networks = (\'mnist_LeNet\', \'cifar10_LeNet\', \'cifar10_LeNet_ELU\')\n    assert net_name in implemented_networks\n\n    ae_net = None\n\n    if net_name == \'mnist_LeNet\':\n        ae_net = MNIST_LeNet_Autoencoder()\n\n    if net_name == \'cifar10_LeNet\':\n        ae_net = CIFAR10_LeNet_Autoencoder()\n\n    if net_name == \'cifar10_LeNet_ELU\':\n        ae_net = CIFAR10_LeNet_ELU_Autoencoder()\n\n    return ae_net\n'"
src/networks/mnist_LeNet.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom base.base_net import BaseNet\n\n\nclass MNIST_LeNet(BaseNet):\n\n    def __init__(self):\n        super().__init__()\n\n        self.rep_dim = 32\n        self.pool = nn.MaxPool2d(2, 2)\n\n        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n        self.conv2 = nn.Conv2d(8, 4, 5, bias=False, padding=2)\n        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n        self.fc1 = nn.Linear(4 * 7 * 7, self.rep_dim, bias=False)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(F.leaky_relu(self.bn1(x)))\n        x = self.conv2(x)\n        x = self.pool(F.leaky_relu(self.bn2(x)))\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        return x\n\n\nclass MNIST_LeNet_Autoencoder(BaseNet):\n\n    def __init__(self):\n        super().__init__()\n\n        self.rep_dim = 32\n        self.pool = nn.MaxPool2d(2, 2)\n\n        # Encoder (must match the Deep SVDD network above)\n        self.conv1 = nn.Conv2d(1, 8, 5, bias=False, padding=2)\n        self.bn1 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n        self.conv2 = nn.Conv2d(8, 4, 5, bias=False, padding=2)\n        self.bn2 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n        self.fc1 = nn.Linear(4 * 7 * 7, self.rep_dim, bias=False)\n\n        # Decoder\n        self.deconv1 = nn.ConvTranspose2d(2, 4, 5, bias=False, padding=2)\n        self.bn3 = nn.BatchNorm2d(4, eps=1e-04, affine=False)\n        self.deconv2 = nn.ConvTranspose2d(4, 8, 5, bias=False, padding=3)\n        self.bn4 = nn.BatchNorm2d(8, eps=1e-04, affine=False)\n        self.deconv3 = nn.ConvTranspose2d(8, 1, 5, bias=False, padding=2)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(F.leaky_relu(self.bn1(x)))\n        x = self.conv2(x)\n        x = self.pool(F.leaky_relu(self.bn2(x)))\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = x.view(x.size(0), int(self.rep_dim / 16), 4, 4)\n        x = F.interpolate(F.leaky_relu(x), scale_factor=2)\n        x = self.deconv1(x)\n        x = F.interpolate(F.leaky_relu(self.bn3(x)), scale_factor=2)\n        x = self.deconv2(x)\n        x = F.interpolate(F.leaky_relu(self.bn4(x)), scale_factor=2)\n        x = self.deconv3(x)\n        x = torch.sigmoid(x)\n\n        return x\n'"
src/optim/__init__.py,0,b'from .deepSVDD_trainer import DeepSVDDTrainer\nfrom .ae_trainer import AETrainer\n'
src/optim/ae_trainer.py,6,"b""from base.base_trainer import BaseTrainer\nfrom base.base_dataset import BaseADDataset\nfrom base.base_net import BaseNet\nfrom sklearn.metrics import roc_auc_score\n\nimport logging\nimport time\nimport torch\nimport torch.optim as optim\nimport numpy as np\n\n\nclass AETrainer(BaseTrainer):\n\n    def __init__(self, optimizer_name: str = 'adam', lr: float = 0.001, n_epochs: int = 150, lr_milestones: tuple = (),\n                 batch_size: int = 128, weight_decay: float = 1e-6, device: str = 'cuda', n_jobs_dataloader: int = 0):\n        super().__init__(optimizer_name, lr, n_epochs, lr_milestones, batch_size, weight_decay, device,\n                         n_jobs_dataloader)\n\n    def train(self, dataset: BaseADDataset, ae_net: BaseNet):\n        logger = logging.getLogger()\n\n        # Set device for network\n        ae_net = ae_net.to(self.device)\n\n        # Get train data loader\n        train_loader, _ = dataset.loaders(batch_size=self.batch_size, num_workers=self.n_jobs_dataloader)\n\n        # Set optimizer (Adam optimizer for now)\n        optimizer = optim.Adam(ae_net.parameters(), lr=self.lr, weight_decay=self.weight_decay,\n                               amsgrad=self.optimizer_name == 'amsgrad')\n\n        # Set learning rate scheduler\n        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.lr_milestones, gamma=0.1)\n\n        # Training\n        logger.info('Starting pretraining...')\n        start_time = time.time()\n        ae_net.train()\n        for epoch in range(self.n_epochs):\n\n            scheduler.step()\n            if epoch in self.lr_milestones:\n                logger.info('  LR scheduler: new learning rate is %g' % float(scheduler.get_lr()[0]))\n\n            loss_epoch = 0.0\n            n_batches = 0\n            epoch_start_time = time.time()\n            for data in train_loader:\n                inputs, _, _ = data\n                inputs = inputs.to(self.device)\n\n                # Zero the network parameter gradients\n                optimizer.zero_grad()\n\n                # Update network parameters via backpropagation: forward + backward + optimize\n                outputs = ae_net(inputs)\n                scores = torch.sum((outputs - inputs) ** 2, dim=tuple(range(1, outputs.dim())))\n                loss = torch.mean(scores)\n                loss.backward()\n                optimizer.step()\n\n                loss_epoch += loss.item()\n                n_batches += 1\n\n            # log epoch statistics\n            epoch_train_time = time.time() - epoch_start_time\n            logger.info('  Epoch {}/{}\\t Time: {:.3f}\\t Loss: {:.8f}'\n                        .format(epoch + 1, self.n_epochs, epoch_train_time, loss_epoch / n_batches))\n\n        pretrain_time = time.time() - start_time\n        logger.info('Pretraining time: %.3f' % pretrain_time)\n        logger.info('Finished pretraining.')\n\n        return ae_net\n\n    def test(self, dataset: BaseADDataset, ae_net: BaseNet):\n        logger = logging.getLogger()\n\n        # Set device for network\n        ae_net = ae_net.to(self.device)\n\n        # Get test data loader\n        _, test_loader = dataset.loaders(batch_size=self.batch_size, num_workers=self.n_jobs_dataloader)\n\n        # Testing\n        logger.info('Testing autoencoder...')\n        loss_epoch = 0.0\n        n_batches = 0\n        start_time = time.time()\n        idx_label_score = []\n        ae_net.eval()\n        with torch.no_grad():\n            for data in test_loader:\n                inputs, labels, idx = data\n                inputs = inputs.to(self.device)\n                outputs = ae_net(inputs)\n                scores = torch.sum((outputs - inputs) ** 2, dim=tuple(range(1, outputs.dim())))\n                loss = torch.mean(scores)\n\n                # Save triple of (idx, label, score) in a list\n                idx_label_score += list(zip(idx.cpu().data.numpy().tolist(),\n                                            labels.cpu().data.numpy().tolist(),\n                                            scores.cpu().data.numpy().tolist()))\n\n                loss_epoch += loss.item()\n                n_batches += 1\n\n        logger.info('Test set Loss: {:.8f}'.format(loss_epoch / n_batches))\n\n        _, labels, scores = zip(*idx_label_score)\n        labels = np.array(labels)\n        scores = np.array(scores)\n\n        auc = roc_auc_score(labels, scores)\n        logger.info('Test set AUC: {:.2f}%'.format(100. * auc))\n\n        test_time = time.time() - start_time\n        logger.info('Autoencoder testing time: %.3f' % test_time)\n        logger.info('Finished testing autoencoder.')\n"""
src/optim/deepSVDD_trainer.py,14,"b'from base.base_trainer import BaseTrainer\nfrom base.base_dataset import BaseADDataset\nfrom base.base_net import BaseNet\nfrom torch.utils.data.dataloader import DataLoader\nfrom sklearn.metrics import roc_auc_score\n\nimport logging\nimport time\nimport torch\nimport torch.optim as optim\nimport numpy as np\n\n\nclass DeepSVDDTrainer(BaseTrainer):\n\n    def __init__(self, objective, R, c, nu: float, optimizer_name: str = \'adam\', lr: float = 0.001, n_epochs: int = 150,\n                 lr_milestones: tuple = (), batch_size: int = 128, weight_decay: float = 1e-6, device: str = \'cuda\',\n                 n_jobs_dataloader: int = 0):\n        super().__init__(optimizer_name, lr, n_epochs, lr_milestones, batch_size, weight_decay, device,\n                         n_jobs_dataloader)\n\n        assert objective in (\'one-class\', \'soft-boundary\'), ""Objective must be either \'one-class\' or \'soft-boundary\'.""\n        self.objective = objective\n\n        # Deep SVDD parameters\n        self.R = torch.tensor(R, device=self.device)  # radius R initialized with 0 by default.\n        self.c = torch.tensor(c, device=self.device) if c is not None else None\n        self.nu = nu\n\n        # Optimization parameters\n        self.warm_up_n_epochs = 10  # number of training epochs for soft-boundary Deep SVDD before radius R gets updated\n\n        # Results\n        self.train_time = None\n        self.test_auc = None\n        self.test_time = None\n        self.test_scores = None\n\n    def train(self, dataset: BaseADDataset, net: BaseNet):\n        logger = logging.getLogger()\n\n        # Set device for network\n        net = net.to(self.device)\n\n        # Get train data loader\n        train_loader, _ = dataset.loaders(batch_size=self.batch_size, num_workers=self.n_jobs_dataloader)\n\n        # Set optimizer (Adam optimizer for now)\n        optimizer = optim.Adam(net.parameters(), lr=self.lr, weight_decay=self.weight_decay,\n                               amsgrad=self.optimizer_name == \'amsgrad\')\n\n        # Set learning rate scheduler\n        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.lr_milestones, gamma=0.1)\n\n        # Initialize hypersphere center c (if c not loaded)\n        if self.c is None:\n            logger.info(\'Initializing center c...\')\n            self.c = self.init_center_c(train_loader, net)\n            logger.info(\'Center c initialized.\')\n\n        # Training\n        logger.info(\'Starting training...\')\n        start_time = time.time()\n        net.train()\n        for epoch in range(self.n_epochs):\n\n            scheduler.step()\n            if epoch in self.lr_milestones:\n                logger.info(\'  LR scheduler: new learning rate is %g\' % float(scheduler.get_lr()[0]))\n\n            loss_epoch = 0.0\n            n_batches = 0\n            epoch_start_time = time.time()\n            for data in train_loader:\n                inputs, _, _ = data\n                inputs = inputs.to(self.device)\n\n                # Zero the network parameter gradients\n                optimizer.zero_grad()\n\n                # Update network parameters via backpropagation: forward + backward + optimize\n                outputs = net(inputs)\n                dist = torch.sum((outputs - self.c) ** 2, dim=1)\n                if self.objective == \'soft-boundary\':\n                    scores = dist - self.R ** 2\n                    loss = self.R ** 2 + (1 / self.nu) * torch.mean(torch.max(torch.zeros_like(scores), scores))\n                else:\n                    loss = torch.mean(dist)\n                loss.backward()\n                optimizer.step()\n\n                # Update hypersphere radius R on mini-batch distances\n                if (self.objective == \'soft-boundary\') and (epoch >= self.warm_up_n_epochs):\n                    self.R.data = torch.tensor(get_radius(dist, self.nu), device=self.device)\n\n                loss_epoch += loss.item()\n                n_batches += 1\n\n            # log epoch statistics\n            epoch_train_time = time.time() - epoch_start_time\n            logger.info(\'  Epoch {}/{}\\t Time: {:.3f}\\t Loss: {:.8f}\'\n                        .format(epoch + 1, self.n_epochs, epoch_train_time, loss_epoch / n_batches))\n\n        self.train_time = time.time() - start_time\n        logger.info(\'Training time: %.3f\' % self.train_time)\n\n        logger.info(\'Finished training.\')\n\n        return net\n\n    def test(self, dataset: BaseADDataset, net: BaseNet):\n        logger = logging.getLogger()\n\n        # Set device for network\n        net = net.to(self.device)\n\n        # Get test data loader\n        _, test_loader = dataset.loaders(batch_size=self.batch_size, num_workers=self.n_jobs_dataloader)\n\n        # Testing\n        logger.info(\'Starting testing...\')\n        start_time = time.time()\n        idx_label_score = []\n        net.eval()\n        with torch.no_grad():\n            for data in test_loader:\n                inputs, labels, idx = data\n                inputs = inputs.to(self.device)\n                outputs = net(inputs)\n                dist = torch.sum((outputs - self.c) ** 2, dim=1)\n                if self.objective == \'soft-boundary\':\n                    scores = dist - self.R ** 2\n                else:\n                    scores = dist\n\n                # Save triples of (idx, label, score) in a list\n                idx_label_score += list(zip(idx.cpu().data.numpy().tolist(),\n                                            labels.cpu().data.numpy().tolist(),\n                                            scores.cpu().data.numpy().tolist()))\n\n        self.test_time = time.time() - start_time\n        logger.info(\'Testing time: %.3f\' % self.test_time)\n\n        self.test_scores = idx_label_score\n\n        # Compute AUC\n        _, labels, scores = zip(*idx_label_score)\n        labels = np.array(labels)\n        scores = np.array(scores)\n\n        self.test_auc = roc_auc_score(labels, scores)\n        logger.info(\'Test set AUC: {:.2f}%\'.format(100. * self.test_auc))\n\n        logger.info(\'Finished testing.\')\n\n    def init_center_c(self, train_loader: DataLoader, net: BaseNet, eps=0.1):\n        """"""Initialize hypersphere center c as the mean from an initial forward pass on the data.""""""\n        n_samples = 0\n        c = torch.zeros(net.rep_dim, device=self.device)\n\n        net.eval()\n        with torch.no_grad():\n            for data in train_loader:\n                # get the inputs of the batch\n                inputs, _, _ = data\n                inputs = inputs.to(self.device)\n                outputs = net(inputs)\n                n_samples += outputs.shape[0]\n                c += torch.sum(outputs, dim=0)\n\n        c /= n_samples\n\n        # If c_i is too close to 0, set to +-eps. Reason: a zero unit can be trivially matched with zero weights.\n        c[(abs(c) < eps) & (c < 0)] = -eps\n        c[(abs(c) < eps) & (c > 0)] = eps\n\n        return c\n\n\ndef get_radius(dist: torch.Tensor, nu: float):\n    """"""Optimally solve for radius R via the (1-nu)-quantile of distances.""""""\n    return np.quantile(np.sqrt(dist.clone().data.cpu().numpy()), 1 - nu)\n'"
src/utils/__init__.py,0,b'from .config import Config\n'
src/utils/collect_results.py,0,"b""import json\nimport numpy as np\n\n\nbase_path = '/Users/lukasruff/Repos/Deep-SVDD-PyTorch/log/mnist/test/mnist/soft_deepSVDD'\nn_exps = 3\nn_seeds = 3\n\nexps = range(n_exps)\nseeds = range(1, n_seeds)\n\nfor exp in exps:\n\n    exp_folder = str(exp) + 'vsall'\n    aucs = np.zeros(n_seeds, dtype=np.float32)\n\n    for seed in seeds:\n\n        seed_folder = 'seed_' + str(seed)\n        file_name = 'results.json'\n        file_path = base_path + '/' + exp_folder + '/' + seed_folder + '/' + file_name\n\n        with open(file_path, 'r') as fp:\n            results = json.load(fp)\n\n        aucs[seed - 1] = results['test_auc']\n\n    mean = np.mean(aucs[aucs > 0])\n    std = np.std(aucs[aucs > 0])\n\n    # Write results\n    log_file = '{}/result.txt'.format(base_path)\n    log = open(log_file, 'a')\n    log.write('Experiment: {}\\n'.format(exp_folder))\n    log.write('Test Set AUC [mean]: {} %\\n'.format(round(float(mean * 100), 4)))\n    log.write('Test Set AUC [std]: {} %\\n'.format(round(float(std * 100), 4)))\n    log.write('\\n')\n\nlog.write('\\n')\nlog.close()\n"""
src/utils/config.py,0,"b'import json\n\n\nclass Config(object):\n    """"""Base class for experimental setting/configuration.""""""\n\n    def __init__(self, settings):\n        self.settings = settings\n\n    def load_config(self, import_json):\n        """"""Load settings dict from import_json (path/filename.json) JSON-file.""""""\n\n        with open(import_json, \'r\') as fp:\n            settings = json.load(fp)\n\n        for key, value in settings.items():\n            self.settings[key] = value\n\n    def save_config(self, export_json):\n        """"""Save settings dict to export_json (path/filename.json) JSON-file.""""""\n\n        with open(export_json, \'w\') as fp:\n            json.dump(self.settings, fp)\n'"
src/utils/visualization/plot_images_grid.py,1,"b'import torch\n# import matplotlib\n# matplotlib.use(\'Agg\')  # or \'PS\', \'PDF\', \'SVG\'\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.utils import make_grid\n\n\ndef plot_images_grid(x: torch.tensor, export_img, title: str = \'\', nrow=8, padding=2, normalize=False, pad_value=0):\n    """"""Plot 4D Tensor of images of shape (B x C x H x W) as a grid.""""""\n\n    grid = make_grid(x, nrow=nrow, padding=padding, normalize=normalize, pad_value=pad_value)\n    npgrid = grid.cpu().numpy()\n\n    plt.imshow(np.transpose(npgrid, (1, 2, 0)), interpolation=\'nearest\')\n\n    ax = plt.gca()\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n\n    if not (title == \'\'):\n        plt.title(title)\n\n    plt.savefig(export_img, bbox_inches=\'tight\', pad_inches=0.1)\n    plt.clf()\n'"
