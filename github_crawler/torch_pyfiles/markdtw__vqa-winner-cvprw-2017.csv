file_path,api_count,code
data_loader.py,3,"b'from __future__ import division, print_function, absolute_import\n\nimport os\nimport pdb\nimport pickle\n\nimport torch\nfrom torch.utils.data import Dataset\nimport numpy as np\nfrom tqdm import tqdm\n\nclass VQAv2(Dataset):\n\n    def __init__(self, root, train, seqlen=14):\n        """"""\n        root (str): path to data directory\n        train (bool): training or validation\n        seqlen (int): maximum words in a question\n        """"""\n        if train:\n            prefix = \'train\'\n        else:\n            prefix = \'val\'\n        print(""Loading preprocessed files... ({})"".format(prefix))\n        qas = pickle.load(open(os.path.join(root, prefix + \'_qa.pkl\'), \'rb\'))\n        idx2word, word2idx = pickle.load(open(os.path.join(root, \'dict_q.pkl\'), \'rb\'))\n        idx2ans, ans2idx = pickle.load(open(os.path.join(root, \'dict_ans.pkl\'), \'rb\'))\n        vfeats = pickle.load(open(os.path.join(root, prefix + \'_vfeats.pkl\'), \'rb\'))\n\n        print(""Setting up everything... ({})"".format(prefix))\n        self.vqas = []\n        for qa in tqdm(qas):\n            que = np.ones(seqlen, dtype=np.int64) * len(word2idx)\n            for i, word in enumerate(qa[\'question_toked\']):\n                if word in word2idx:\n                    que[i] = word2idx[word]\n\n            ans = np.zeros(len(idx2ans), dtype=np.float32)\n            for a, s in qa[\'answer\']:\n                ans[ans2idx[a]] = s\n\n            self.vqas.append({\n                \'v\': vfeats[qa[\'image_id\']],\n                \'q\': que,\n                \'a\': ans,\n                \'q_txt\': qa[\'question\'],\n                \'a_txt\': qa[\'answer\']\n            })\n\n    def __len__(self):\n        return len(self.vqas)\n\n    def __getitem__(self, idx):\n        return self.vqas[idx][\'v\'], self.vqas[idx][\'q\'], self.vqas[idx][\'a\'], self.vqas[idx][\'q_txt\'], self.vqas[idx][\'a_txt\']\n\n    @staticmethod\n    def get_n_classes(fpath=os.path.join(\'data\', \'dict_ans.pkl\')):\n        idx2ans, _ = pickle.load(open(fpath, \'rb\'))\n        return len(idx2ans)\n\n    @staticmethod\n    def get_vocab_size(fpath=os.path.join(\'data\', \'dict_q.pkl\')):\n        idx2word, _ = pickle.load(open(fpath, \'rb\'))\n        return len(idx2word)\n\n\ndef prepare_data(args):\n\n    train_loader = torch.utils.data.DataLoader(\n        VQAv2(root=args.data_root, train=True),\n        batch_size=args.batch_size, shuffle=True, num_workers=args.n_workers, pin_memory=args.pin_mem)\n\n    val_loader = torch.utils.data.DataLoader(\n        VQAv2(root=args.data_root, train=False),\n        batch_size=args.vbatch_size, shuffle=False, num_workers=args.n_workers, pin_memory=args.pin_mem)\n\n    vocab_size = VQAv2.get_vocab_size()\n    num_classes = VQAv2.get_n_classes()\n    return train_loader, val_loader, vocab_size, num_classes\n'"
main.py,11,"b'from __future__ import division, print_function, absolute_import\n\nimport os\nimport pdb\nimport time\nimport random\nimport argparse\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom model import Model\nfrom utils import GOATLogger, save_ckpt, compute_score\nfrom data_loader import prepare_data\n\nFLAGS = argparse.ArgumentParser()\nFLAGS.add_argument(\'--mode\', choices=[\'train\', \'eval\'])\n# Hyper-parameters\nFLAGS.add_argument(\'--hid-dim\', type=int,\n                   help=""Hidden dimension for GRU"")\nFLAGS.add_argument(\'--batch-size\', type=int,\n                   help=""Batch size"")\nFLAGS.add_argument(\'--vbatch-size\', type=int,\n                   help=""Batch size for validation"")\nFLAGS.add_argument(\'--epoch\', type=int,\n                   help=""Epochs to train"")\n# Paths\nFLAGS.add_argument(\'--data-root\', type=str,\n                   help=""Location of data"")\nFLAGS.add_argument(\'--resume\', type=str,\n                   help=""Location to resume model"")\nFLAGS.add_argument(\'--save\', type=str,\n                   help=""Location to save model"")\nFLAGS.add_argument(\'--wemb-init\', type=str,\n                   help=""Location to pretrained wemb"")\n# Others\nFLAGS.add_argument(\'--cpu\', action=\'store_true\',\n                   help=""Set this to use CPU, default use CUDA"")\nFLAGS.add_argument(\'--n-workers\', type=int, default=2,\n                   help=""How many processes for preprocessing"")\nFLAGS.add_argument(\'--pin-mem\', type=bool, default=False,\n                   help=""DataLoader pin memory or not"")\nFLAGS.add_argument(\'--log-freq\', type=int, default=100,\n                   help=""Logging frequency"")\nFLAGS.add_argument(\'--seed\', type=int, default=420,\n                   help=""Random seed"")\n\n\ndef evaluate(val_loader, model, epoch, device, logger):\n    model.eval()\n\n    batches = len(val_loader)\n    for step, (v, q, a, _, _) in enumerate(tqdm(val_loader, ascii=True)):\n        v = v.to(device)\n        q = q.to(device)\n        a = a.to(device)\n\n        logits = model(v, q)\n        loss = F.binary_cross_entropy_with_logits(logits, a) * a.size(1)\n        score = compute_score(logits, a)\n\n        logger.batch_info_eval(epoch, step, batches, loss.item(), score)\n\n    score = logger.batch_info_eval(epoch, -1, batches)\n    return score\n\n\ndef train(train_loader, model, optim, epoch, device, logger):\n    model.train()\n\n    batches = len(train_loader)\n    start = time.time()\n    for step, (v, q, a, _, _) in enumerate(train_loader):\n        data_time = time.time() - start\n\n        v = v.to(device)\n        q = q.to(device)\n        a = a.to(device)\n\n        logits = model(v, q)\n        loss = F.binary_cross_entropy_with_logits(logits, a) * a.size(1)\n\n        optim.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n        optim.step()\n\n        batch_time = time.time() - start\n        score = compute_score(logits, a)\n        logger.batch_info(epoch, step, batches, data_time, loss.item(), score, batch_time)\n        start = time.time()\n\n\ndef main():\n\n    args, unparsed = FLAGS.parse_known_args()\n    if len(unparsed) != 0:\n        raise NameError(""Argument {} not recognized"".format(unparsed))\n\n    logger = GOATLogger(args.mode, args.save, args.log_freq)\n    random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    if args.cpu:\n        device = torch.device(\'cpu\')\n    else:\n        if not torch.cuda.is_available():\n            raise RuntimeError(""GPU unavailable."")\n\n        args.devices = torch.cuda.device_count()\n        args.batch_size *= args.devices\n        torch.backends.cudnn.benchmark = True\n        device = torch.device(\'cuda\')\n        torch.cuda.manual_seed(args.seed)\n\n    # Get data\n    train_loader, val_loader, vocab_size, num_classes = prepare_data(args)\n\n    # Set up model\n    model = Model(vocab_size, args.wemb_init, args.hid_dim, num_classes)\n    model = nn.DataParallel(model).to(device)\n    logger.loginfo(""Parameters: {:.3f}M"".format(sum(p.numel() for p in model.parameters()) / 1e6))\n\n    # Set up optimizer\n    optim = torch.optim.Adamax(model.parameters())\n\n    last_epoch = 0\n    bscore = 0.0\n\n    if args.resume:\n        logger.loginfo(""Initialized from ckpt: "" + args.resume)\n        ckpt = torch.load(args.resume, map_location=device)\n        last_epoch = ckpt[\'epoch\']\n        model.load_state_dict(ckpt[\'state_dict\'])\n        optim.load_state_dict(ckpt[\'optim_state_dict\'])\n\n    if args.mode == \'eval\':\n        _ = evaluate(val_loader, model, last_epoch, device, logger)\n        return\n\n    # Train\n    for epoch in range(last_epoch, args.epoch):\n        train(train_loader, model, optim, epoch, device, logger)\n        score = evaluate(val_loader, model, epoch, device, logger)\n        bscore = save_ckpt(score, bscore, epoch, model, optim, args.save, logger)\n\n    logger.loginfo(""Done"")\n\n\nif __name__ == \'__main__\':\n    main()\n'"
model.py,10,"b'from __future__ import division\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport pdb\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\nclass Model(nn.Module):\n\n    def __init__(self, vocab_size, wemb_init, hid_dim, num_classes):\n        super(Model, self).__init__()\n        """"""\n            vocab_size (int): how many vocabs\n            wemb_init (str): path to pretrained wemb weights\n            hid_dim (int): for GRU -> 512\n            num_classes (int): output classes -> 3129\n        """"""\n        emb_dim = int(wemb_init.split(\'_\')[-1].split(\'.\')[0])\n        self.hid_dim = hid_dim\n\n        # question encoding\n        self.wembed = nn.Embedding(vocab_size + 1, emb_dim)\n        self.gru = nn.GRU(emb_dim, hid_dim)\n\n        # image attention\n        self.att = nn.Linear(hid_dim, 1)\n\n        # output classifier\n        self.clf = nn.Linear(hid_dim, num_classes)\n        self.clf_do = nn.Dropout(0.5, inplace=True)\n\n        # initialize word embedding layer weight\n        pretrained_wemb = np.zeros((vocab_size + 1, emb_dim), dtype=np.float32)\n        pretrained_wemb[:vocab_size] = np.load(wemb_init)\n        self.wembed.weight.data.copy_(torch.from_numpy(pretrained_wemb))\n\n        # gated tanh activation\n        self.gth_iatt = nn.Linear(2048 + hid_dim, hid_dim)\n        self.gthp_iatt = nn.Linear(2048 + hid_dim, hid_dim)\n        self.gth_q = nn.Linear(hid_dim, hid_dim)\n        self.gthp_q = nn.Linear(hid_dim, hid_dim)\n        self.gth_i = nn.Linear(2048, hid_dim)\n        self.gthp_i = nn.Linear(2048, hid_dim)\n        self.gth_clf = nn.Linear(hid_dim, hid_dim)\n        self.gthp_clf = nn.Linear(hid_dim, hid_dim)\n\n\n    def forward(self, image, question):\n        """"""\n        question -> shape (batch, 14)\n        image -> shape (batch, 36, 2048)\n        """"""\n        # question encoding\n        emb = self.wembed(question)                 # (batch, seqlen, emb_dim)\n        enc, hid = self.gru(emb.permute(1, 0, 2))   # (seqlen, batch, hid_dim)\n        qenc = enc[-1]                              # (batch, hid_dim)\n        \n        # image attention\n        qenc_reshape = qenc.repeat(1, 36).view(-1, 36, self.hid_dim)    # (batch, 36, hid_dim)\n        image = F.normalize(image, -1)                                  # (batch, 36, 2048)\n        concated = torch.cat((image, qenc_reshape), -1)                 # (batch, 36, 2048 + hid_dim)\n        concated = torch.mul(torch.tanh(self.gth_iatt(concated)), torch.sigmoid(self.gthp_iatt(concated)))\n        a = self.att(concated)                              # (batch, 36, 1)\n        a = F.softmax(a.squeeze(), dim=1)                   # (batch, 36)\n        v_head = torch.bmm(a.unsqueeze(1), image).squeeze() # (batch, 2048)\n\n        # element-wise (question + image) multiplication\n        q = torch.mul(torch.tanh(self.gth_q(qenc)), torch.sigmoid(self.gthp_q(qenc)))\n        v = torch.mul(torch.tanh(self.gth_i(v_head)), torch.sigmoid(self.gthp_i(v_head)))\n        h = torch.mul(q, v) # (batch, hid_dim)\n\n        # output classifier\n        s_head = self.clf(torch.mul(torch.tanh(self.gth_clf(h)), torch.sigmoid(self.gthp_clf(h))))\n        s_head = self.clf_do(s_head)\n        return s_head\n'"
utils.py,3,"b'from __future__ import division, print_function, absolute_import\n\nimport os\nimport pdb\nimport time\nimport logging\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nclass GOATLogger:\n\n    def __init__(self, mode, save, log_freq=100):\n        self.save_root = save\n        self.log_freq = log_freq\n        self.stats = {\n            \'train\': {\'iter\': [], \'loss\': [], \'score\': []},\n            \'eval\': {\'epoch\': [], \'loss\': [], \'score\': []},\n            \'xaxis\': {\'train\': \'iter\', \'eval\': \'epoch\'}\n        }\n\n        if mode == \'train\':\n            if not os.path.exists(self.save_root):\n                os.mkdir(self.save_root)\n            filename = os.path.join(self.save_root, \'console.log\')\n            logging.basicConfig(level=logging.DEBUG,\n                format=\'%(asctime)s.%(msecs)03d - %(message)s\',\n                datefmt=\'%b-%d %H:%M:%S\',\n                filename=filename,\n                filemode=\'w\')\n            console = logging.StreamHandler()\n            console.setLevel(logging.INFO)\n            console.setFormatter(logging.Formatter(\'%(message)s\'))\n            logging.getLogger(\'\').addHandler(console)\n            logging.info(""Logger created at {}"".format(filename))\n        else:\n            logging.basicConfig(level=logging.INFO,\n                format=\'%(asctime)s.%(msecs)03d - %(message)s\',\n                datefmt=\'%b-%d %H:%M:%S\')\n\n    def batch_info(self, epoch, step, batches, data_time, loss, score, batch_time):\n        if (step+1) % self.log_freq == 0 or (step+1) == batches:\n            strout = ""[{:3d}][{:4d}/{:4d}] "".format(epoch+1, step+1, batches) + \\\n                ""time for data/train: {:6.4f}/{:6.4f}, loss: {:6.4f}, score: {:6.3f}"".format(\\\n                    data_time, batch_time, loss, score)\n            self.loginfo(strout)\n            self.save_stats(\'train\')\n\n        g_step = step + batches * epoch\n        self.stats[\'train\'][\'iter\'].append(g_step)\n        self.stats[\'train\'][\'loss\'].append(loss)\n        self.stats[\'train\'][\'score\'].append(score)\n\n    def batch_info_eval(self, epoch, step, batches, loss=0, score=0):\n        if step == -1:\n            score_mean = np.mean(self.stats[\'eval\'][\'score\'][-batches:])\n            strout = ""[{:3d}]* Evaluation - score: {:.3f} *"".format(epoch+1, score_mean)\n            self.loginfo(strout)\n            self.save_stats(\'eval\')\n            return score_mean\n\n        self.stats[\'eval\'][\'epoch\'].append(epoch)\n        self.stats[\'eval\'][\'loss\'].append(loss)\n        self.stats[\'eval\'][\'score\'].append(score)\n\n\n    def save_stats(self, phase=\'train\'):\n        data = pd.DataFrame(self.stats[phase])\n        data.to_csv(os.path.join(self.save_root, \'stats_{}.csv\'.format(phase)))\n        xaxis = self.stats[\'xaxis\'][phase]\n\n        plt.style.use(\'seaborn-darkgrid\')\n        # plot accuracy\n        plt.plot(xaxis, \'score\', data=data)\n        plt.title(\'Classification Accuracy ({}, {})\'.format(phase, self.stats[phase][xaxis][-1]))\n        plt.legend()\n        plt.savefig(os.path.join(self.save_root, \'accuracy_{}.png\'.format(phase)))\n        plt.clf()\n        # plot loss\n        plt.plot(xaxis, \'loss\', data=data)\n        plt.title(\'Cross-entropy Loss ({}, {})\'.format(phase, self.stats[phase][xaxis][-1]))\n        plt.savefig(os.path.join(self.save_root, \'loss_{}.png\'.format(phase)))\n        plt.clf()\n\n    def logdebug(self, strout):\n        logging.debug(strout)\n    def loginfo(self, strout):\n        logging.info(strout)\n    def logbreak(self):\n        logging.info(""="" * 80)\n\n\ndef compute_score(logits, labels):\n    logits = torch.max(logits, 1)[1].data\n    one_hots = torch.zeros(*labels.size()).cuda()\n    one_hots.scatter_(1, logits.view(-1, 1), 1)\n    score = (one_hots * labels)\n    return score.cpu().numpy().sum() / logits.shape[0]\n\n\ndef save_ckpt(score, bscore, epoch, model, optim, save, logger):\n    if not os.path.exists(os.path.join(save, \'ckpts\')):\n        os.mkdir(os.path.join(save, \'ckpts\'))\n\n    torch.save({\n        \'epoch\': epoch+1,\n        \'state_dict\': model.state_dict(),\n        \'optim_state_dict\': optim.state_dict(),\n        \'score\': score}, os.path.join(save, \'ckpts\', \'model_{}.pth.tar\'.format(epoch)))\n\n    if score > bscore:\n        if os.path.exists(os.path.join(save, \'best.pth.tar\')):\n            os.unlink(os.path.join(save, \'best.pth.tar\'))\n        os.symlink(os.path.join(\'ckpts\', \'model_{}.pth.tar\'.format(epoch)),\n                   os.path.join(save, \'best.pth.tar\'))\n        logger.loginfo(""* This is the best score so far. *\\n"")\n    return max(score, bscore)\n'"
scripts/preproc.py,0,"b'from __future__ import division, print_function, absolute_import\n\nimport os\nimport re\nimport pdb\nimport sys\nimport csv\nimport json\ncsv.field_size_limit(sys.maxsize)\n\nimport base64\nimport pickle\n\nimport numpy as np\nimport nltk\nnltk.data.path.append(\'data\')\nnltk.download(\'punkt\', download_dir=\'data\')\nfrom nltk.tokenize import word_tokenize\nfrom tqdm import tqdm\n\nta_path = os.path.join(\'data\', \'v2_mscoco_train2014_annotations.json\')\nva_path = os.path.join(\'data\', \'v2_mscoco_val2014_annotations.json\')\ntq_path = os.path.join(\'data\', \'v2_OpenEnded_mscoco_train2014_questions.json\')\nvq_path = os.path.join(\'data\', \'v2_OpenEnded_mscoco_val2014_questions.json\')\nglove_path = os.path.join(\'data\', \'glove\', \'glove.6B.300d.txt\')\nvfeats_path = os.path.join(\'data\', \'trainval_resnet101_faster_rcnn_genome_36.tsv\')\n\ncontractions = {\n    ""aint"": ""ain\'t"", ""arent"": ""aren\'t"", ""cant"": ""can\'t"", ""couldve"":\n    ""could\'ve"", ""couldnt"": ""couldn\'t"", ""couldn\'tve"": ""couldn\'t\'ve"",\n    ""couldnt\'ve"": ""couldn\'t\'ve"", ""didnt"": ""didn\'t"", ""doesnt"":\n    ""doesn\'t"", ""dont"": ""don\'t"", ""hadnt"": ""hadn\'t"", ""hadnt\'ve"":\n    ""hadn\'t\'ve"", ""hadn\'tve"": ""hadn\'t\'ve"", ""hasnt"": ""hasn\'t"", ""havent"":\n    ""haven\'t"", ""hed"": ""he\'d"", ""hed\'ve"": ""he\'d\'ve"", ""he\'dve"":\n    ""he\'d\'ve"", ""hes"": ""he\'s"", ""howd"": ""how\'d"", ""howll"": ""how\'ll"",\n    ""hows"": ""how\'s"", ""Id\'ve"": ""I\'d\'ve"", ""I\'dve"": ""I\'d\'ve"", ""Im"":\n    ""I\'m"", ""Ive"": ""I\'ve"", ""isnt"": ""isn\'t"", ""itd"": ""it\'d"", ""itd\'ve"":\n    ""it\'d\'ve"", ""it\'dve"": ""it\'d\'ve"", ""itll"": ""it\'ll"", ""let\'s"": ""let\'s"",\n    ""maam"": ""ma\'am"", ""mightnt"": ""mightn\'t"", ""mightnt\'ve"":\n    ""mightn\'t\'ve"", ""mightn\'tve"": ""mightn\'t\'ve"", ""mightve"": ""might\'ve"",\n    ""mustnt"": ""mustn\'t"", ""mustve"": ""must\'ve"", ""neednt"": ""needn\'t"",\n    ""notve"": ""not\'ve"", ""oclock"": ""o\'clock"", ""oughtnt"": ""oughtn\'t"",\n    ""ow\'s\'at"": ""\'ow\'s\'at"", ""\'ows\'at"": ""\'ow\'s\'at"", ""\'ow\'sat"":\n    ""\'ow\'s\'at"", ""shant"": ""shan\'t"", ""shed\'ve"": ""she\'d\'ve"", ""she\'dve"":\n    ""she\'d\'ve"", ""she\'s"": ""she\'s"", ""shouldve"": ""should\'ve"", ""shouldnt"":\n    ""shouldn\'t"", ""shouldnt\'ve"": ""shouldn\'t\'ve"", ""shouldn\'tve"":\n    ""shouldn\'t\'ve"", ""somebody\'d"": ""somebodyd"", ""somebodyd\'ve"":\n    ""somebody\'d\'ve"", ""somebody\'dve"": ""somebody\'d\'ve"", ""somebodyll"":\n    ""somebody\'ll"", ""somebodys"": ""somebody\'s"", ""someoned"": ""someone\'d"",\n    ""someoned\'ve"": ""someone\'d\'ve"", ""someone\'dve"": ""someone\'d\'ve"",\n    ""someonell"": ""someone\'ll"", ""someones"": ""someone\'s"", ""somethingd"":\n    ""something\'d"", ""somethingd\'ve"": ""something\'d\'ve"", ""something\'dve"":\n    ""something\'d\'ve"", ""somethingll"": ""something\'ll"", ""thats"":\n    ""that\'s"", ""thered"": ""there\'d"", ""thered\'ve"": ""there\'d\'ve"",\n    ""there\'dve"": ""there\'d\'ve"", ""therere"": ""there\'re"", ""theres"":\n    ""there\'s"", ""theyd"": ""they\'d"", ""theyd\'ve"": ""they\'d\'ve"", ""they\'dve"":\n    ""they\'d\'ve"", ""theyll"": ""they\'ll"", ""theyre"": ""they\'re"", ""theyve"":\n    ""they\'ve"", ""twas"": ""\'twas"", ""wasnt"": ""wasn\'t"", ""wed\'ve"":\n    ""we\'d\'ve"", ""we\'dve"": ""we\'d\'ve"", ""weve"": ""we\'ve"", ""werent"":\n    ""weren\'t"", ""whatll"": ""what\'ll"", ""whatre"": ""what\'re"", ""whats"":\n    ""what\'s"", ""whatve"": ""what\'ve"", ""whens"": ""when\'s"", ""whered"":\n    ""where\'d"", ""wheres"": ""where\'s"", ""whereve"": ""where\'ve"", ""whod"":\n    ""who\'d"", ""whod\'ve"": ""who\'d\'ve"", ""who\'dve"": ""who\'d\'ve"", ""wholl"":\n    ""who\'ll"", ""whos"": ""who\'s"", ""whove"": ""who\'ve"", ""whyll"": ""why\'ll"",\n    ""whyre"": ""why\'re"", ""whys"": ""why\'s"", ""wont"": ""won\'t"", ""wouldve"":\n    ""would\'ve"", ""wouldnt"": ""wouldn\'t"", ""wouldnt\'ve"": ""wouldn\'t\'ve"",\n    ""wouldn\'tve"": ""wouldn\'t\'ve"", ""yall"": ""y\'all"", ""yall\'ll"":\n    ""y\'all\'ll"", ""y\'allll"": ""y\'all\'ll"", ""yall\'d\'ve"": ""y\'all\'d\'ve"",\n    ""y\'alld\'ve"": ""y\'all\'d\'ve"", ""y\'all\'dve"": ""y\'all\'d\'ve"", ""youd"":\n    ""you\'d"", ""youd\'ve"": ""you\'d\'ve"", ""you\'dve"": ""you\'d\'ve"", ""youll"":\n    ""you\'ll"", ""youre"": ""you\'re"", ""youve"": ""you\'ve""\n}\n\nmanual_map = {\n    \'none\': \'0\',\n    \'zero\': \'0\',\n    \'one\': \'1\',\n    \'two\': \'2\',\n    \'three\': \'3\',\n    \'four\': \'4\',\n    \'five\': \'5\',\n    \'six\': \'6\',\n    \'seven\': \'7\',\n    \'eight\': \'8\',\n    \'nine\': \'9\',\n    \'ten\': \'10\'\n}\n\narticles = [\'a\', \'an\', \'the\']\nperiod_strip = re.compile(""(?!<=\\d)(\\.)(?!\\d)"")\ncomma_strip = re.compile(""(\\d)(\\,)(\\d)"")\npunct = [\n    \';\', r""/"", \'[\', \']\', \'""\', \'{\', \'}\',\n    \'(\', \')\', \'=\', \'+\', \'\\\\\', \'_\', \'-\',\n    \'>\', \'<\', \'@\', \'`\', \',\', \'?\', \'!\'\n]\n\n\ndef _process_punctuation(inText):\n    outText = inText\n    for p in punct:\n        if (p + \' \' in inText or \' \' + p in inText) \\\n        or (re.search(comma_strip, inText) != None):\n            outText = outText.replace(p, \'\')\n        else:\n            outText = outText.replace(p, \' \')\n    outText = period_strip.sub("""", outText, re.UNICODE)\n    return outText\n\n\ndef _process_digit_article(inText):\n    outText = []\n    tempText = inText.lower().split()\n    for word in tempText:\n        word = manual_map.setdefault(word, word)\n        if word not in articles:\n            outText.append(word)\n        else:\n            pass\n    for wordId, word in enumerate(outText):\n        if word in contractions:\n            outText[wordId] = contractions[word]\n    outText = \' \'.join(outText)\n    return outText\n\n\ndef process_a(freq_thr=9):\n\n    ta = json.load(open(ta_path))[\'annotations\']\n    va = json.load(open(va_path))[\'annotations\']\n    annos = ta + va\n\n    print(""Calculating the frequency of each multiple choice answer..."")\n    mca_freqs = {}\n    for anno in tqdm(annos):\n        mca = _process_digit_article(_process_punctuation(anno[\'multiple_choice_answer\']))\n        mca = mca.replace(\',\', \'\')\n        mca_freqs[mca] = mca_freqs.get(mca, 0) + 1\n\n    # filter out rare answers\n    for a, freq in list(mca_freqs.items()):\n        if freq < freq_thr:\n            mca_freqs.pop(a)\n\n    print(""Number of answers appear more than {} times: {}"".format(freq_thr - 1, len(mca_freqs)))\n\n    # generate answer dictionary\n    idx2ans = []\n    ans2idx = {}\n    for i, a in enumerate(mca_freqs):\n        idx2ans.append(a)\n        ans2idx[a] = i\n\n    print(""Generating soft scores..."")\n    targets = []\n    for anno in tqdm(annos):\n        anss = anno[\'answers\']\n\n        # calculate individual answer\'s frequency\n        ans_freqs = {}\n        for a in anss:\n            ans_freqs[a[\'answer\']] = ans_freqs.get(a[\'answer\'], 0) + 1\n\n        soft_score = []\n        for a, freq in ans_freqs.items():\n            if a in ans2idx:\n                soft_score.append((a, min(1, freq / 3)))\n\n        targets.append({\n            \'question_id\': anno[\'question_id\'],\n            \'image_id\': anno[\'image_id\'],\n            \'answer\': soft_score    # [(ans1, score1), (ans2, score2), ...]\n        })\n\n    pickle.dump([idx2ans, ans2idx], open(os.path.join(\'data\', \'dict_ans.pkl\'), \'wb\'))\n    return targets\n\n\ndef _tokenize(tbt):\n    tbt = tbt.lower().replace(\',\', \'\').replace(\'?\', \'\')\n    return word_tokenize(tbt)\n\n\ndef process_qa(targets, max_words=14):\n\n    print(""Merging QAs..."")\n    idx2word = []\n    word2idx = {}\n\n    tq = json.load(open(tq_path))[\'questions\']\n    vq = json.load(open(vq_path))[\'questions\']\n    qs = tq + vq\n    qas = []\n    for i, q in enumerate(tqdm(qs)):\n        tokens = _tokenize(q[\'question\'])\n        for t in tokens:\n            if not t in word2idx:\n                idx2word.append(t)\n                word2idx[t] = len(idx2word) - 1\n\n        assert q[\'question_id\'] == targets[i][\'question_id\'],\\\n                ""Question ID doesn\'t match ({}: {})"".format(q[\'question_id\'], targets[i][\'question_id\'])\n\n        qas.append({\n            \'image_id\': q[\'image_id\'],\n            \'question\': q[\'question\'],\n            \'question_id\': q[\'question_id\'],\n            \'question_toked\': tokens,\n            \'answer\': targets[i][\'answer\']\n        })\n\n    pickle.dump([idx2word, word2idx], open(os.path.join(\'data\', \'dict_q.pkl\'), \'wb\'))\n    pickle.dump(qas[:len(tq)], open(os.path.join(\'data\', \'train_qa.pkl\'), \'wb\'))\n    pickle.dump(qas[len(tq):], open(os.path.join(\'data\', \'val_qa.pkl\'), \'wb\'))\n    return idx2word\n\n\ndef process_wemb(idx2word):\n    print(""Generating pretrained word embedding weights..."")\n    word2emb = {}\n    emb_dim = int(glove_path.split(\'.\')[-2].split(\'d\')[0])\n    with open(glove_path) as f:\n        for entry in f:\n            vals = entry.split(\' \')\n            word = vals[0]\n            word2emb[word] = np.asarray(vals[1:], dtype=np.float32)\n\n    pretrained_weights = np.zeros((len(idx2word), emb_dim), dtype=np.float32)\n    for idx, word in enumerate(idx2word):\n        if word not in word2emb:\n            continue\n        pretrained_weights[idx] = word2emb[word]\n\n    np.save(os.path.join(\'data\', \'glove_pretrained_{}.npy\'.format(emb_dim)), pretrained_weights)\n\n\ndef process_vfeats():\n    FIELDNAMES = [\'image_id\', \'image_w\', \'image_h\', \'num_boxes\', \'boxes\', \'features\']\n    tq = json.load(open(tq_path))[\'questions\']\n    vq = json.load(open(vq_path))[\'questions\']\n    tids = set([q[\'image_id\'] for q in tq])\n    vids = set([q[\'image_id\'] for q in vq])\n\n    print(""Reading tsv, total iterations: {}"".format(len(tids)+len(vids)))\n    tvfeats = {}\n    vvfeats = {}\n    with open(vfeats_path) as tsv_in_file:\n        reader = csv.DictReader(tsv_in_file, delimiter=\'\\t\', fieldnames=FIELDNAMES)\n        for i, item in enumerate(tqdm(reader)):\n            image_id = int(item[\'image_id\'])\n            feats = np.frombuffer(base64.b64decode(item[\'features\']), \n                dtype=np.float32).reshape((int(item[\'num_boxes\']), -1))\n\n            if image_id in tids:\n                tvfeats[image_id] = feats\n            elif image_id in vids:\n                vvfeats[image_id] = feats\n            else:\n                raise ValueError(""Image_id: {} not in training or validation set"".format(image_id))\n\n    print(""Converting tsv to pickle... This will take a while"")\n    pickle.dump(tvfeats, open(os.path.join(\'data\', \'train_vfeats.pkl\'), \'wb\'))\n    pickle.dump(vvfeats, open(os.path.join(\'data\', \'val_vfeats.pkl\'), \'wb\'))\n\n\nif __name__ == \'__main__\':\n    targets = process_a()\n    idx2word = process_qa(targets)\n    process_wemb(idx2word)\n    #process_vfeats()\n    print(""Done"")\n'"
