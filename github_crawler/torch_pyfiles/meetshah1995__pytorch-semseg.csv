file_path,api_count,code
test.py,3,"b'import os\nimport torch\nimport argparse\nimport numpy as np\nimport scipy.misc as misc\n\n\nfrom ptsemseg.models import get_model\nfrom ptsemseg.loader import get_loader\nfrom ptsemseg.utils import convert_state_dict\n\ntry:\n    import pydensecrf.densecrf as dcrf\nexcept:\n    print(\n        ""Failed to import pydensecrf,\\\n           CRF post-processing will not work""\n    )\n\n\ndef test(args):\n\n    device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\n    model_file_name = os.path.split(args.model_path)[1]\n    model_name = model_file_name[: model_file_name.find(""_"")]\n\n    # Setup image\n    print(""Read Input Image from : {}"".format(args.img_path))\n    img = misc.imread(args.img_path)\n\n    data_loader = get_loader(args.dataset)\n    loader = data_loader(root=None, is_transform=True, img_norm=args.img_norm, test_mode=True)\n    n_classes = loader.n_classes\n\n    resized_img = misc.imresize(img, (loader.img_size[0], loader.img_size[1]), interp=""bicubic"")\n\n    orig_size = img.shape[:-1]\n    if model_name in [""pspnet"", ""icnet"", ""icnetBN""]:\n        # uint8 with RGB mode, resize width and height which are odd numbers\n        img = misc.imresize(img, (orig_size[0] // 2 * 2 + 1, orig_size[1] // 2 * 2 + 1))\n    else:\n        img = misc.imresize(img, (loader.img_size[0], loader.img_size[1]))\n\n    img = img[:, :, ::-1]\n    img = img.astype(np.float64)\n    img -= loader.mean\n    if args.img_norm:\n        img = img.astype(float) / 255.0\n\n    # NHWC -> NCHW\n    img = img.transpose(2, 0, 1)\n    img = np.expand_dims(img, 0)\n    img = torch.from_numpy(img).float()\n\n    # Setup Model\n    model_dict = {""arch"": model_name}\n    model = get_model(model_dict, n_classes, version=args.dataset)\n    state = convert_state_dict(torch.load(args.model_path)[""model_state""])\n    model.load_state_dict(state)\n    model.eval()\n    model.to(device)\n\n    images = img.to(device)\n    outputs = model(images)\n\n    if args.dcrf:\n        unary = outputs.data.cpu().numpy()\n        unary = np.squeeze(unary, 0)\n        unary = -np.log(unary)\n        unary = unary.transpose(2, 1, 0)\n        w, h, c = unary.shape\n        unary = unary.transpose(2, 0, 1).reshape(loader.n_classes, -1)\n        unary = np.ascontiguousarray(unary)\n\n        resized_img = np.ascontiguousarray(resized_img)\n\n        d = dcrf.DenseCRF2D(w, h, loader.n_classes)\n        d.setUnaryEnergy(unary)\n        d.addPairwiseBilateral(sxy=5, srgb=3, rgbim=resized_img, compat=1)\n\n        q = d.inference(50)\n        mask = np.argmax(q, axis=0).reshape(w, h).transpose(1, 0)\n        decoded_crf = loader.decode_segmap(np.array(mask, dtype=np.uint8))\n        dcrf_path = args.out_path[:-4] + ""_drf.png""\n        misc.imsave(dcrf_path, decoded_crf)\n        print(""Dense CRF Processed Mask Saved at: {}"".format(dcrf_path))\n\n    pred = np.squeeze(outputs.data.max(1)[1].cpu().numpy(), axis=0)\n    if model_name in [""pspnet"", ""icnet"", ""icnetBN""]:\n        pred = pred.astype(np.float32)\n        # float32 with F mode, resize back to orig_size\n        pred = misc.imresize(pred, orig_size, ""nearest"", mode=""F"")\n\n    decoded = loader.decode_segmap(pred)\n    print(""Classes found: "", np.unique(pred))\n    misc.imsave(args.out_path, decoded)\n    print(""Segmentation Mask Saved at: {}"".format(args.out_path))\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=""Params"")\n    parser.add_argument(\n        ""--model_path"",\n        nargs=""?"",\n        type=str,\n        default=""fcn8s_pascal_1_26.pkl"",\n        help=""Path to the saved model"",\n    )\n    parser.add_argument(\n        ""--dataset"",\n        nargs=""?"",\n        type=str,\n        default=""pascal"",\n        help=""Dataset to use [\'pascal, camvid, ade20k etc\']"",\n    )\n\n    parser.add_argument(\n        ""--img_norm"",\n        dest=""img_norm"",\n        action=""store_true"",\n        help=""Enable input image scales normalization [0, 1] \\\n                              | True by default"",\n    )\n    parser.add_argument(\n        ""--no-img_norm"",\n        dest=""img_norm"",\n        action=""store_false"",\n        help=""Disable input image scales normalization [0, 1] |\\\n                              True by default"",\n    )\n    parser.set_defaults(img_norm=True)\n\n    parser.add_argument(\n        ""--dcrf"",\n        dest=""dcrf"",\n        action=""store_true"",\n        help=""Enable DenseCRF based post-processing | \\\n                              False by default"",\n    )\n    parser.add_argument(\n        ""--no-dcrf"",\n        dest=""dcrf"",\n        action=""store_false"",\n        help=""Disable DenseCRF based post-processing | \\\n                              False by default"",\n    )\n    parser.set_defaults(dcrf=False)\n\n    parser.add_argument(\n        ""--img_path"", nargs=""?"", type=str, default=None, help=""Path of the input image""\n    )\n    parser.add_argument(\n        ""--out_path"", nargs=""?"", type=str, default=None, help=""Path of the output segmap""\n    )\n    args = parser.parse_args()\n    test(args)\n'"
train.py,8,"b'import os\nimport yaml\nimport time\nimport shutil\nimport torch\nimport random\nimport argparse\nimport numpy as np\n\nfrom torch.utils import data\nfrom tqdm import tqdm\n\nfrom ptsemseg.models import get_model\nfrom ptsemseg.loss import get_loss_function\nfrom ptsemseg.loader import get_loader\nfrom ptsemseg.utils import get_logger\nfrom ptsemseg.metrics import runningScore, averageMeter\nfrom ptsemseg.augmentations import get_composed_augmentations\nfrom ptsemseg.schedulers import get_scheduler\nfrom ptsemseg.optimizers import get_optimizer\n\nfrom tensorboardX import SummaryWriter\n\n\ndef train(cfg, writer, logger):\n\n    # Setup seeds\n    torch.manual_seed(cfg.get(""seed"", 1337))\n    torch.cuda.manual_seed(cfg.get(""seed"", 1337))\n    np.random.seed(cfg.get(""seed"", 1337))\n    random.seed(cfg.get(""seed"", 1337))\n\n    # Setup device\n    device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\n    # Setup Augmentations\n    augmentations = cfg[""training""].get(""augmentations"", None)\n    data_aug = get_composed_augmentations(augmentations)\n\n    # Setup Dataloader\n    data_loader = get_loader(cfg[""data""][""dataset""])\n    data_path = cfg[""data""][""path""]\n\n    t_loader = data_loader(\n        data_path,\n        is_transform=True,\n        split=cfg[""data""][""train_split""],\n        img_size=(cfg[""data""][""img_rows""], cfg[""data""][""img_cols""]),\n        augmentations=data_aug,\n    )\n\n    v_loader = data_loader(\n        data_path,\n        is_transform=True,\n        split=cfg[""data""][""val_split""],\n        img_size=(cfg[""data""][""img_rows""], cfg[""data""][""img_cols""]),\n    )\n\n    n_classes = t_loader.n_classes\n    trainloader = data.DataLoader(\n        t_loader,\n        batch_size=cfg[""training""][""batch_size""],\n        num_workers=cfg[""training""][""n_workers""],\n        shuffle=True,\n    )\n\n    valloader = data.DataLoader(\n        v_loader, batch_size=cfg[""training""][""batch_size""], num_workers=cfg[""training""][""n_workers""]\n    )\n\n    # Setup Metrics\n    running_metrics_val = runningScore(n_classes)\n\n    # Setup Model\n    model = get_model(cfg[""model""], n_classes).to(device)\n\n    model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n\n    # Setup optimizer, lr_scheduler and loss function\n    optimizer_cls = get_optimizer(cfg)\n    optimizer_params = {k: v for k, v in cfg[""training""][""optimizer""].items() if k != ""name""}\n\n    optimizer = optimizer_cls(model.parameters(), **optimizer_params)\n    logger.info(""Using optimizer {}"".format(optimizer))\n\n    scheduler = get_scheduler(optimizer, cfg[""training""][""lr_schedule""])\n\n    loss_fn = get_loss_function(cfg)\n    logger.info(""Using loss {}"".format(loss_fn))\n\n    start_iter = 0\n    if cfg[""training""][""resume""] is not None:\n        if os.path.isfile(cfg[""training""][""resume""]):\n            logger.info(\n                ""Loading model and optimizer from checkpoint \'{}\'"".format(cfg[""training""][""resume""])\n            )\n            checkpoint = torch.load(cfg[""training""][""resume""])\n            model.load_state_dict(checkpoint[""model_state""])\n            optimizer.load_state_dict(checkpoint[""optimizer_state""])\n            scheduler.load_state_dict(checkpoint[""scheduler_state""])\n            start_iter = checkpoint[""epoch""]\n            logger.info(\n                ""Loaded checkpoint \'{}\' (iter {})"".format(\n                    cfg[""training""][""resume""], checkpoint[""epoch""]\n                )\n            )\n        else:\n            logger.info(""No checkpoint found at \'{}\'"".format(cfg[""training""][""resume""]))\n\n    val_loss_meter = averageMeter()\n    time_meter = averageMeter()\n\n    best_iou = -100.0\n    i = start_iter\n    flag = True\n\n    while i <= cfg[""training""][""train_iters""] and flag:\n        for (images, labels) in trainloader:\n            i += 1\n            start_ts = time.time()\n            scheduler.step()\n            model.train()\n            images = images.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n\n            loss = loss_fn(input=outputs, target=labels)\n\n            loss.backward()\n            optimizer.step()\n\n            time_meter.update(time.time() - start_ts)\n\n            if (i + 1) % cfg[""training""][""print_interval""] == 0:\n                fmt_str = ""Iter [{:d}/{:d}]  Loss: {:.4f}  Time/Image: {:.4f}""\n                print_str = fmt_str.format(\n                    i + 1,\n                    cfg[""training""][""train_iters""],\n                    loss.item(),\n                    time_meter.avg / cfg[""training""][""batch_size""],\n                )\n\n                print(print_str)\n                logger.info(print_str)\n                writer.add_scalar(""loss/train_loss"", loss.item(), i + 1)\n                time_meter.reset()\n\n            if (i + 1) % cfg[""training""][""val_interval""] == 0 or (i + 1) == cfg[""training""][\n                ""train_iters""\n            ]:\n                model.eval()\n                with torch.no_grad():\n                    for i_val, (images_val, labels_val) in tqdm(enumerate(valloader)):\n                        images_val = images_val.to(device)\n                        labels_val = labels_val.to(device)\n\n                        outputs = model(images_val)\n                        val_loss = loss_fn(input=outputs, target=labels_val)\n\n                        pred = outputs.data.max(1)[1].cpu().numpy()\n                        gt = labels_val.data.cpu().numpy()\n\n                        running_metrics_val.update(gt, pred)\n                        val_loss_meter.update(val_loss.item())\n\n                writer.add_scalar(""loss/val_loss"", val_loss_meter.avg, i + 1)\n                logger.info(""Iter %d Loss: %.4f"" % (i + 1, val_loss_meter.avg))\n\n                score, class_iou = running_metrics_val.get_scores()\n                for k, v in score.items():\n                    print(k, v)\n                    logger.info(""{}: {}"".format(k, v))\n                    writer.add_scalar(""val_metrics/{}"".format(k), v, i + 1)\n\n                for k, v in class_iou.items():\n                    logger.info(""{}: {}"".format(k, v))\n                    writer.add_scalar(""val_metrics/cls_{}"".format(k), v, i + 1)\n\n                val_loss_meter.reset()\n                running_metrics_val.reset()\n\n                if score[""Mean IoU : \\t""] >= best_iou:\n                    best_iou = score[""Mean IoU : \\t""]\n                    state = {\n                        ""epoch"": i + 1,\n                        ""model_state"": model.state_dict(),\n                        ""optimizer_state"": optimizer.state_dict(),\n                        ""scheduler_state"": scheduler.state_dict(),\n                        ""best_iou"": best_iou,\n                    }\n                    save_path = os.path.join(\n                        writer.file_writer.get_logdir(),\n                        ""{}_{}_best_model.pkl"".format(cfg[""model""][""arch""], cfg[""data""][""dataset""]),\n                    )\n                    torch.save(state, save_path)\n\n            if (i + 1) == cfg[""training""][""train_iters""]:\n                flag = False\n                break\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=""config"")\n    parser.add_argument(\n        ""--config"",\n        nargs=""?"",\n        type=str,\n        default=""configs/fcn8s_pascal.yml"",\n        help=""Configuration file to use"",\n    )\n\n    args = parser.parse_args()\n\n    with open(args.config) as fp:\n        cfg = yaml.load(fp)\n\n    run_id = random.randint(1, 100000)\n    logdir = os.path.join(""runs"", os.path.basename(args.config)[:-4], str(run_id))\n    writer = SummaryWriter(log_dir=logdir)\n\n    print(""RUNDIR: {}"".format(logdir))\n    shutil.copy(args.config, logdir)\n\n    logger = get_logger(logdir)\n    logger.info(""Let the games begin"")\n\n    train(cfg, writer, logger)\n'"
validate.py,5,"b'import yaml\nimport torch\nimport argparse\nimport timeit\nimport numpy as np\n\nfrom torch.utils import data\n\n\nfrom ptsemseg.models import get_model\nfrom ptsemseg.loader import get_loader\nfrom ptsemseg.metrics import runningScore\nfrom ptsemseg.utils import convert_state_dict\n\ntorch.backends.cudnn.benchmark = True\n\n\ndef validate(cfg, args):\n\n    device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\n    # Setup Dataloader\n    data_loader = get_loader(cfg[""data""][""dataset""])\n    data_path = cfg[""data""][""path""]\n\n    loader = data_loader(\n        data_path,\n        split=cfg[""data""][""val_split""],\n        is_transform=True,\n        img_size=(cfg[""data""][""img_rows""], cfg[""data""][""img_cols""]),\n    )\n\n    n_classes = loader.n_classes\n\n    valloader = data.DataLoader(loader, batch_size=cfg[""training""][""batch_size""], num_workers=8)\n    running_metrics = runningScore(n_classes)\n\n    # Setup Model\n\n    model = get_model(cfg[""model""], n_classes).to(device)\n    state = convert_state_dict(torch.load(args.model_path)[""model_state""])\n    model.load_state_dict(state)\n    model.eval()\n    model.to(device)\n\n    for i, (images, labels) in enumerate(valloader):\n        start_time = timeit.default_timer()\n\n        images = images.to(device)\n\n        if args.eval_flip:\n            outputs = model(images)\n\n            # Flip images in numpy (not support in tensor)\n            outputs = outputs.data.cpu().numpy()\n            flipped_images = np.copy(images.data.cpu().numpy()[:, :, :, ::-1])\n            flipped_images = torch.from_numpy(flipped_images).float().to(device)\n            outputs_flipped = model(flipped_images)\n            outputs_flipped = outputs_flipped.data.cpu().numpy()\n            outputs = (outputs + outputs_flipped[:, :, :, ::-1]) / 2.0\n\n            pred = np.argmax(outputs, axis=1)\n        else:\n            outputs = model(images)\n            pred = outputs.data.max(1)[1].cpu().numpy()\n\n        gt = labels.numpy()\n\n        if args.measure_time:\n            elapsed_time = timeit.default_timer() - start_time\n            print(\n                ""Inference time \\\n                  (iter {0:5d}): {1:3.5f} fps"".format(\n                    i + 1, pred.shape[0] / elapsed_time\n                )\n            )\n        running_metrics.update(gt, pred)\n\n    score, class_iou = running_metrics.get_scores()\n\n    for k, v in score.items():\n        print(k, v)\n\n    for i in range(n_classes):\n        print(i, class_iou[i])\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=""Hyperparams"")\n    parser.add_argument(\n        ""--config"",\n        nargs=""?"",\n        type=str,\n        default=""configs/fcn8s_pascal.yml"",\n        help=""Config file to be used"",\n    )\n    parser.add_argument(\n        ""--model_path"",\n        nargs=""?"",\n        type=str,\n        default=""fcn8s_pascal_1_26.pkl"",\n        help=""Path to the saved model"",\n    )\n    parser.add_argument(\n        ""--eval_flip"",\n        dest=""eval_flip"",\n        action=""store_true"",\n        help=""Enable evaluation with flipped image |\\\n                              True by default"",\n    )\n    parser.add_argument(\n        ""--no-eval_flip"",\n        dest=""eval_flip"",\n        action=""store_false"",\n        help=""Disable evaluation with flipped image |\\\n                              True by default"",\n    )\n    parser.set_defaults(eval_flip=True)\n\n    parser.add_argument(\n        ""--measure_time"",\n        dest=""measure_time"",\n        action=""store_true"",\n        help=""Enable evaluation with time (fps) measurement |\\\n                              True by default"",\n    )\n    parser.add_argument(\n        ""--no-measure_time"",\n        dest=""measure_time"",\n        action=""store_false"",\n        help=""Disable evaluation with time (fps) measurement |\\\n                              True by default"",\n    )\n    parser.set_defaults(measure_time=True)\n\n    args = parser.parse_args()\n\n    with open(args.config) as fp:\n        cfg = yaml.load(fp)\n\n    validate(cfg, args)\n'"
ptsemseg/__init__.py,0,b''
ptsemseg/caffe_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: caffe.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'caffe.proto\',\n  package=\'caffe\',\n  syntax=\'proto2\',\n  serialized_pb=_b(\'\\n\\x0b\\x63\\x61\\x66\\x66\\x65.proto\\x12\\x05\\x63\\x61\\x66\\x66\\x65\\""\\x1c\\n\\tBlobShape\\x12\\x0f\\n\\x03\\x64im\\x18\\x01 \\x03(\\x03\\x42\\x02\\x10\\x01\\""\\xcc\\x01\\n\\tBlobProto\\x12\\x1f\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x05 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04\\x64iff\\x18\\x06 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_data\\x18\\x08 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_diff\\x18\\t \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x0e\\n\\x03num\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x13\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x11\\n\\x06height\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""2\\n\\x0f\\x42lobProtoVector\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\""\\x81\\x01\\n\\x05\\x44\\x61tum\\x12\\x10\\n\\x08\\x63hannels\\x18\\x01 \\x01(\\x05\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\x05\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\x05\\x12\\x0c\\n\\x04\\x64\\x61ta\\x18\\x04 \\x01(\\x0c\\x12\\r\\n\\x05label\\x18\\x05 \\x01(\\x05\\x12\\x12\\n\\nfloat_data\\x18\\x06 \\x03(\\x02\\x12\\x16\\n\\x07\\x65ncoded\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x8a\\x02\\n\\x0f\\x46illerParameter\\x12\\x16\\n\\x04type\\x18\\x01 \\x01(\\t:\\x08\\x63onstant\\x12\\x10\\n\\x05value\\x18\\x02 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03min\\x18\\x03 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03max\\x18\\x04 \\x01(\\x02:\\x01\\x31\\x12\\x0f\\n\\x04mean\\x18\\x05 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03std\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x06sparse\\x18\\x07 \\x01(\\x05:\\x02-1\\x12\\x42\\n\\rvariance_norm\\x18\\x08 \\x01(\\x0e\\x32#.caffe.FillerParameter.VarianceNorm:\\x06\\x46\\x41N_IN\\""4\\n\\x0cVarianceNorm\\x12\\n\\n\\x06\\x46\\x41N_IN\\x10\\x00\\x12\\x0b\\n\\x07\\x46\\x41N_OUT\\x10\\x01\\x12\\x0b\\n\\x07\\x41VERAGE\\x10\\x02\\""\\x8e\\x02\\n\\x0cNetParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12%\\n\\x0binput_shape\\x18\\x08 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x11\\n\\tinput_dim\\x18\\x04 \\x03(\\x05\\x12\\x1d\\n\\x0e\\x66orce_backward\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1e\\n\\x05state\\x18\\x06 \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x19\\n\\ndebug_info\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12$\\n\\x05layer\\x18\\x64 \\x03(\\x0b\\x32\\x15.caffe.LayerParameter\\x12\\\'\\n\\x06layers\\x18\\x02 \\x03(\\x0b\\x32\\x17.caffe.V1LayerParameter\\""\\x9c\\n\\n\\x0fSolverParameter\\x12\\x0b\\n\\x03net\\x18\\x18 \\x01(\\t\\x12&\\n\\tnet_param\\x18\\x19 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12\\x11\\n\\ttrain_net\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x08test_net\\x18\\x02 \\x03(\\t\\x12,\\n\\x0ftrain_net_param\\x18\\x15 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12+\\n\\x0etest_net_param\\x18\\x16 \\x03(\\x0b\\x32\\x13.caffe.NetParameter\\x12$\\n\\x0btrain_state\\x18\\x1a \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12#\\n\\ntest_state\\x18\\x1b \\x03(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x11\\n\\ttest_iter\\x18\\x03 \\x03(\\x05\\x12\\x18\\n\\rtest_interval\\x18\\x04 \\x01(\\x05:\\x01\\x30\\x12 \\n\\x11test_compute_loss\\x18\\x13 \\x01(\\x08:\\x05\\x66\\x61lse\\x12!\\n\\x13test_initialization\\x18  \\x01(\\x08:\\x04true\\x12\\x0f\\n\\x07\\x62\\x61se_lr\\x18\\x05 \\x01(\\x02\\x12\\x0f\\n\\x07\\x64isplay\\x18\\x06 \\x01(\\x05\\x12\\x17\\n\\x0c\\x61verage_loss\\x18! \\x01(\\x05:\\x01\\x31\\x12\\x10\\n\\x08max_iter\\x18\\x07 \\x01(\\x05\\x12\\x14\\n\\titer_size\\x18$ \\x01(\\x05:\\x01\\x31\\x12\\x11\\n\\tlr_policy\\x18\\x08 \\x01(\\t\\x12\\r\\n\\x05gamma\\x18\\t \\x01(\\x02\\x12\\r\\n\\x05power\\x18\\n \\x01(\\x02\\x12\\x10\\n\\x08momentum\\x18\\x0b \\x01(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x0c \\x01(\\x02\\x12\\x1f\\n\\x13regularization_type\\x18\\x1d \\x01(\\t:\\x02L2\\x12\\x10\\n\\x08stepsize\\x18\\r \\x01(\\x05\\x12\\x11\\n\\tstepvalue\\x18\\"" \\x03(\\x05\\x12\\x1a\\n\\x0e\\x63lip_gradients\\x18# \\x01(\\x02:\\x02-1\\x12\\x13\\n\\x08snapshot\\x18\\x0e \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0fsnapshot_prefix\\x18\\x0f \\x01(\\t\\x12\\x1c\\n\\rsnapshot_diff\\x18\\x10 \\x01(\\x08:\\x05\\x66\\x61lse\\x12K\\n\\x0fsnapshot_format\\x18% \\x01(\\x0e\\x32%.caffe.SolverParameter.SnapshotFormat:\\x0b\\x42INARYPROTO\\x12;\\n\\x0bsolver_mode\\x18\\x11 \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverMode:\\x03GPU\\x12\\x14\\n\\tdevice_id\\x18\\x12 \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0brandom_seed\\x18\\x14 \\x01(\\x03:\\x02-1\\x12\\x11\\n\\x04type\\x18( \\x01(\\t:\\x03SGD\\x12\\x14\\n\\x05\\x64\\x65lta\\x18\\x1f \\x01(\\x02:\\x05\\x31\\x65-08\\x12\\x18\\n\\tmomentum2\\x18\\\' \\x01(\\x02:\\x05\\x30.999\\x12\\x11\\n\\trms_decay\\x18& \\x01(\\x02\\x12\\x19\\n\\ndebug_info\\x18\\x17 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x14snapshot_after_train\\x18\\x1c \\x01(\\x08:\\x04true\\x12;\\n\\x0bsolver_type\\x18\\x1e \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverType:\\x03SGD\\""+\\n\\x0eSnapshotFormat\\x12\\x08\\n\\x04HDF5\\x10\\x00\\x12\\x0f\\n\\x0b\\x42INARYPROTO\\x10\\x01\\""\\x1e\\n\\nSolverMode\\x12\\x07\\n\\x03\\x43PU\\x10\\x00\\x12\\x07\\n\\x03GPU\\x10\\x01\\""U\\n\\nSolverType\\x12\\x07\\n\\x03SGD\\x10\\x00\\x12\\x0c\\n\\x08NESTEROV\\x10\\x01\\x12\\x0b\\n\\x07\\x41\\x44\\x41GRAD\\x10\\x02\\x12\\x0b\\n\\x07RMSPROP\\x10\\x03\\x12\\x0c\\n\\x08\\x41\\x44\\x41\\x44\\x45LTA\\x10\\x04\\x12\\x08\\n\\x04\\x41\\x44\\x41M\\x10\\x05\\""l\\n\\x0bSolverState\\x12\\x0c\\n\\x04iter\\x18\\x01 \\x01(\\x05\\x12\\x13\\n\\x0blearned_net\\x18\\x02 \\x01(\\t\\x12!\\n\\x07history\\x18\\x03 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x17\\n\\x0c\\x63urrent_step\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""N\\n\\x08NetState\\x12!\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase:\\x04TEST\\x12\\x10\\n\\x05level\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\r\\n\\x05stage\\x18\\x03 \\x03(\\t\\""s\\n\\x0cNetStateRule\\x12\\x1b\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x11\\n\\tmin_level\\x18\\x02 \\x01(\\x05\\x12\\x11\\n\\tmax_level\\x18\\x03 \\x01(\\x05\\x12\\r\\n\\x05stage\\x18\\x04 \\x03(\\t\\x12\\x11\\n\\tnot_stage\\x18\\x05 \\x03(\\t\\""\\xa3\\x01\\n\\tParamSpec\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\nshare_mode\\x18\\x02 \\x01(\\x0e\\x32\\x1d.caffe.ParamSpec.DimCheckMode\\x12\\x12\\n\\x07lr_mult\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ndecay_mult\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\xeb\\x16\\n\\x0eLayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x03 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x04 \\x03(\\t\\x12\\x1b\\n\\x05phase\\x18\\n \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x13\\n\\x0bloss_weight\\x18\\x05 \\x03(\\x02\\x12\\x1f\\n\\x05param\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.ParamSpec\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x07 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x16\\n\\x0epropagate_down\\x18\\x0b \\x03(\\x08\\x12$\\n\\x07include\\x18\\x08 \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18\\t \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12\\x37\\n\\x0ftransform_param\\x18\\x64 \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18\\x65 \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x66 \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12I\\n\\x1b\\x61\\x64\\x61ptive_bias_channel_param\\x18\\x94\\x01 \\x01(\\x0b\\x32#.caffe.AdaptiveBiasChannelParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18g \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12\\x34\\n\\x10\\x62\\x61tch_norm_param\\x18\\x8b\\x01 \\x01(\\x0b\\x32\\x19.caffe.BatchNormParameter\\x12%\\n\\x08\\x62n_param\\x18\\x98\\x01 \\x01(\\x0b\\x32\\x12.caffe.BNParameter\\x12)\\n\\nbias_param\\x18\\x8d\\x01 \\x01(\\x0b\\x32\\x14.caffe.BiasParameter\\x12\\x38\\n\\x12\\x62ias_channel_param\\x18\\x95\\x01 \\x01(\\x0b\\x32\\x1b.caffe.BiasChannelParameter\\x12,\\n\\x0c\\x63oncat_param\\x18h \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18i \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18j \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18k \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12\\x32\\n\\x0f\\x64\\x65nse_crf_param\\x18\\x92\\x01 \\x01(\\x0b\\x32\\x18.caffe.DenseCRFParameter\\x12@\\n\\x16\\x64omain_transform_param\\x18\\x93\\x01 \\x01(\\x0b\\x32\\x1f.caffe.DomainTransformParameter\\x12.\\n\\rdropout_param\\x18l \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18m \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18n \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12\\\'\\n\\telu_param\\x18\\x8c\\x01 \\x01(\\x0b\\x32\\x13.caffe.ELUParameter\\x12+\\n\\x0b\\x65mbed_param\\x18\\x89\\x01 \\x01(\\x0b\\x32\\x15.caffe.EmbedParameter\\x12&\\n\\texp_param\\x18o \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12/\\n\\rflatten_param\\x18\\x87\\x01 \\x01(\\x0b\\x32\\x17.caffe.FlattenParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18p \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18q \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18r \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18s \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18t \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18u \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12-\\n\\x0cinterp_param\\x18\\x8f\\x01 \\x01(\\x0b\\x32\\x16.caffe.InterpParameter\\x12\\\'\\n\\tlog_param\\x18\\x86\\x01 \\x01(\\x0b\\x32\\x13.caffe.LogParameter\\x12&\\n\\tlrn_param\\x18v \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x30\\n\\x0emat_read_param\\x18\\x97\\x01 \\x01(\\x0b\\x32\\x17.caffe.MatReadParameter\\x12\\x32\\n\\x0fmat_write_param\\x18\\x91\\x01 \\x01(\\x0b\\x32\\x18.caffe.MatWriteParameter\\x12\\x35\\n\\x11memory_data_param\\x18w \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18x \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18y \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18z \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12+\\n\\x0bprelu_param\\x18\\x83\\x01 \\x01(\\x0b\\x32\\x15.caffe.PReLUParameter\\x12-\\n\\x0cpython_param\\x18\\x82\\x01 \\x01(\\x0b\\x32\\x16.caffe.PythonParameter\\x12\\x33\\n\\x0freduction_param\\x18\\x88\\x01 \\x01(\\x0b\\x32\\x19.caffe.ReductionParameter\\x12(\\n\\nrelu_param\\x18{ \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12/\\n\\rreshape_param\\x18\\x85\\x01 \\x01(\\x0b\\x32\\x17.caffe.ReshapeParameter\\x12+\\n\\x0bscale_param\\x18\\x8e\\x01 \\x01(\\x0b\\x32\\x15.caffe.ScaleParameter\\x12\\x38\\n\\x12seg_accuracy_param\\x18\\x90\\x01 \\x01(\\x0b\\x32\\x1b.caffe.SegAccuracyParameter\\x12.\\n\\rsigmoid_param\\x18| \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18} \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12\\\'\\n\\tspp_param\\x18\\x84\\x01 \\x01(\\x0b\\x32\\x13.caffe.SPPParameter\\x12*\\n\\x0bslice_param\\x18~ \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18\\x7f \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x33\\n\\x0fthreshold_param\\x18\\x80\\x01 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12)\\n\\ntile_param\\x18\\x8a\\x01 \\x01(\\x0b\\x32\\x14.caffe.TileParameter\\x12\\x38\\n\\x12unique_label_param\\x18\\x96\\x01 \\x01(\\x0b\\x32\\x1b.caffe.UniqueLabelParameter\\x12\\x36\\n\\x11window_data_param\\x18\\x81\\x01 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\""\\xfc\\x01\\n\\x17TransformationParameter\\x12\\x10\\n\\x05scale\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\x06mirror\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x14\\n\\tcrop_size\\x18\\x03 \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\tmean_file\\x18\\x04 \\x01(\\t\\x12\\x12\\n\\nmean_value\\x18\\x05 \\x03(\\x02\\x12\\x1a\\n\\x0b\\x66orce_color\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\nforce_gray\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\rscale_factors\\x18\\x08 \\x03(\\x02\\x12\\x15\\n\\ncrop_width\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x0b\\x63rop_height\\x18\\n \\x01(\\r:\\x01\\x30\\""\\xc2\\x01\\n\\rLossParameter\\x12\\x14\\n\\x0cignore_label\\x18\\x01 \\x01(\\x05\\x12\\x44\\n\\rnormalization\\x18\\x03 \\x01(\\x0e\\x32&.caffe.LossParameter.NormalizationMode:\\x05VALID\\x12\\x11\\n\\tnormalize\\x18\\x02 \\x01(\\x08\\""B\\n\\x11NormalizationMode\\x12\\x08\\n\\x04\\x46ULL\\x10\\x00\\x12\\t\\n\\x05VALID\\x10\\x01\\x12\\x0e\\n\\nBATCH_SIZE\\x10\\x02\\x12\\x08\\n\\x04NONE\\x10\\x03\\""L\\n\\x11\\x41\\x63\\x63uracyParameter\\x12\\x10\\n\\x05top_k\\x18\\x01 \\x01(\\r:\\x01\\x31\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x0cignore_label\\x18\\x03 \\x01(\\x05\\""\\xa2\\x01\\n\\x1c\\x41\\x64\\x61ptiveBiasChannelParameter\\x12\\x13\\n\\x08num_iter\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x17\\n\\nbg_portion\\x18\\x02 \\x01(\\x02:\\x03\\x30.2\\x12\\x17\\n\\nfg_portion\\x18\\x03 \\x01(\\x02:\\x03\\x30.2\\x12\\x1d\\n\\x0fsuppress_others\\x18\\x04 \\x01(\\x08:\\x04true\\x12\\x1c\\n\\rmargin_others\\x18\\x05 \\x01(\\x02:\\x05\\x31\\x65-05\\""M\\n\\x0f\\x41rgMaxParameter\\x12\\x1a\\n\\x0bout_max_val\\x18\\x01 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x05top_k\\x18\\x02 \\x01(\\r:\\x01\\x31\\x12\\x0c\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05\\""\\xd6\\x01\\n\\x14\\x42iasChannelParameter\\x12\\x12\\n\\x07\\x62g_bias\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x07\\x66g_bias\\x18\\x02 \\x01(\\x02:\\x01\\x32\\x12\\x14\\n\\x0cignore_label\\x18\\x03 \\x03(\\x05\\x12@\\n\\nlabel_type\\x18\\x04 \\x01(\\x0e\\x32%.caffe.BiasChannelParameter.LabelType:\\x05IMAGE\\x12\\x1b\\n\\x10\\x62\\x61\\x63kground_label\\x18\\x06 \\x01(\\x05:\\x01\\x30\\""!\\n\\tLabelType\\x12\\t\\n\\x05IMAGE\\x10\\x01\\x12\\t\\n\\x05PIXEL\\x10\\x02\\""9\\n\\x0f\\x43oncatParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x15\\n\\nconcat_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""\\x8e\\x01\\n\\x12\\x42\\x61tchNormParameter\\x12\\x18\\n\\x10use_global_stats\\x18\\x01 \\x01(\\x08\\x12&\\n\\x17moving_average_fraction\\x18\\x02 \\x01(\\x02:\\x05\\x30.999\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-05\\x12\\""\\n\\x13update_global_stats\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x8b\\x02\\n\\x0b\\x42NParameter\\x12,\\n\\x0cslope_filler\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x02 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x15\\n\\x08momentum\\x18\\x03 \\x01(\\x02:\\x03\\x30.9\\x12\\x12\\n\\x03\\x65ps\\x18\\x04 \\x01(\\x02:\\x05\\x31\\x65-05\\x12\\x15\\n\\x06\\x66rozen\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x32\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x19.caffe.BNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""]\\n\\rBiasParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""L\\n\\x18\\x43ontrastiveLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x1d\\n\\x0elegacy_version\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xfc\\x03\\n\\x14\\x43onvolutionParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x0b\\n\\x03pad\\x18\\x03 \\x03(\\r\\x12\\x13\\n\\x0bkernel_size\\x18\\x04 \\x03(\\r\\x12\\x0e\\n\\x06stride\\x18\\x06 \\x03(\\r\\x12\\x10\\n\\x08\\x64ilation\\x18\\x12 \\x03(\\r\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x08kernel_h\\x18\\x0b \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x0c \\x01(\\r\\x12\\x10\\n\\x08stride_h\\x18\\r \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x0e \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\x05 \\x01(\\r:\\x01\\x31\\x12-\\n\\rweight_filler\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12;\\n\\x06\\x65ngine\\x18\\x0f \\x01(\\x0e\\x32\\"".caffe.ConvolutionParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x10 \\x01(\\x05:\\x01\\x31\\x12\\x1e\\n\\x0f\\x66orce_nd_im2col\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xa4\\x02\\n\\rDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x31\\n\\x07\\x62\\x61\\x63kend\\x18\\x08 \\x01(\\x0e\\x32\\x17.caffe.DataParameter.DB:\\x07LEVELDB\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x13\\x66orce_encoded_color\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x13\\n\\x08prefetch\\x18\\n \\x01(\\r:\\x01\\x34\\""\\x1b\\n\\x02\\x44\\x42\\x12\\x0b\\n\\x07LEVELDB\\x10\\x00\\x12\\x08\\n\\x04LMDB\\x10\\x01\\""\\xa3\\x01\\n\\x11\\x44\\x65nseCRFParameter\\x12\\x14\\n\\x08max_iter\\x18\\x01 \\x01(\\x05:\\x02\\x31\\x30\\x12\\x12\\n\\npos_xy_std\\x18\\x02 \\x03(\\x02\\x12\\r\\n\\x05pos_w\\x18\\x03 \\x03(\\x02\\x12\\x11\\n\\tbi_xy_std\\x18\\x04 \\x03(\\x02\\x12\\x12\\n\\nbi_rgb_std\\x18\\x05 \\x03(\\x02\\x12\\x0c\\n\\x04\\x62i_w\\x18\\x06 \\x03(\\x02\\x12 \\n\\x12output_probability\\x18\\x07 \\x01(\\x08:\\x04true\\""y\\n\\x18\\x44omainTransformParameter\\x12\\x13\\n\\x08num_iter\\x18\\x01 \\x01(\\x05:\\x01\\x33\\x12\\x19\\n\\rspatial_sigma\\x18\\x02 \\x01(\\x02:\\x02\\x35\\x30\\x12\\x16\\n\\x0brange_sigma\\x18\\x03 \\x01(\\x02:\\x01\\x35\\x12\\x15\\n\\nmin_weight\\x18\\x04 \\x01(\\x02:\\x01\\x30\\"".\\n\\x10\\x44ropoutParameter\\x12\\x1a\\n\\rdropout_ratio\\x18\\x01 \\x01(\\x02:\\x03\\x30.5\\""\\xa0\\x01\\n\\x12\\x44ummyDataParameter\\x12+\\n\\x0b\\x64\\x61ta_filler\\x18\\x01 \\x03(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1f\\n\\x05shape\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0b\\n\\x03num\\x18\\x02 \\x03(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x03 \\x03(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x03(\\r\\x12\\r\\n\\x05width\\x18\\x05 \\x03(\\r\\""\\xa5\\x01\\n\\x10\\x45ltwiseParameter\\x12\\x39\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32!.caffe.EltwiseParameter.EltwiseOp:\\x03SUM\\x12\\r\\n\\x05\\x63oeff\\x18\\x02 \\x03(\\x02\\x12\\x1e\\n\\x10stable_prod_grad\\x18\\x03 \\x01(\\x08:\\x04true\\""\\\'\\n\\tEltwiseOp\\x12\\x08\\n\\x04PROD\\x10\\x00\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x07\\n\\x03MAX\\x10\\x02\\"" \\n\\x0c\\x45LUParameter\\x12\\x10\\n\\x05\\x61lpha\\x18\\x01 \\x01(\\x02:\\x01\\x31\\""\\xac\\x01\\n\\x0e\\x45mbedParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x11\\n\\tinput_dim\\x18\\x02 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x03 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""D\\n\\x0c\\x45xpParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""9\\n\\x10\\x46lattenParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x08\\x65nd_axis\\x18\\x02 \\x01(\\x05:\\x02-1\\""O\\n\\x11HDF5DataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x02 \\x01(\\r\\x12\\x16\\n\\x07shuffle\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\""(\\n\\x13HDF5OutputParameter\\x12\\x11\\n\\tfile_name\\x18\\x01 \\x01(\\t\\""^\\n\\x12HingeLossParameter\\x12\\x30\\n\\x04norm\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.HingeLossParameter.Norm:\\x02L1\\""\\x16\\n\\x04Norm\\x12\\x06\\n\\x02L1\\x10\\x01\\x12\\x06\\n\\x02L2\\x10\\x02\\""\\x9f\\x03\\n\\x12ImageDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\nbatch_size\\x18\\x04 \\x01(\\r:\\x01\\x31\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x07shuffle\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nnew_height\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x08is_color\\x18\\x0b \\x01(\\x08:\\x04true\\x12\\x19\\n\\x0cignore_label\\x18\\x0f \\x01(\\x05:\\x03\\x32\\x35\\x35\\x12>\\n\\nlabel_type\\x18\\x10 \\x01(\\x0e\\x32#.caffe.ImageDataParameter.LabelType:\\x05IMAGE\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\x0c \\x01(\\t:\\x00\\""+\\n\\tLabelType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\t\\n\\x05IMAGE\\x10\\x01\\x12\\t\\n\\x05PIXEL\\x10\\x02\\""\\\'\\n\\x15InfogainLossParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\""\\xcb\\x01\\n\\x15InnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x05 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\ttranspose\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x90\\x01\\n\\x0fInterpParameter\\x12\\x11\\n\\x06height\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x16\\n\\x0bzoom_factor\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\rshrink_factor\\x18\\x04 \\x01(\\x05:\\x01\\x31\\x12\\x12\\n\\x07pad_beg\\x18\\x05 \\x01(\\x05:\\x01\\x30\\x12\\x12\\n\\x07pad_end\\x18\\x06 \\x01(\\x05:\\x01\\x30\\""D\\n\\x0cLogParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""\\xb8\\x02\\n\\x0cLRNParameter\\x12\\x15\\n\\nlocal_size\\x18\\x01 \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x03 \\x01(\\x02:\\x04\\x30.75\\x12\\x44\\n\\x0bnorm_region\\x18\\x04 \\x01(\\x0e\\x32\\x1e.caffe.LRNParameter.NormRegion:\\x0f\\x41\\x43ROSS_CHANNELS\\x12\\x0c\\n\\x01k\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.LRNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""5\\n\\nNormRegion\\x12\\x13\\n\\x0f\\x41\\x43ROSS_CHANNELS\\x10\\x00\\x12\\x12\\n\\x0eWITHIN_CHANNEL\\x10\\x01\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""]\\n\\x10MatReadParameter\\x12\\x0e\\n\\x06prefix\\x18\\x01 \\x02(\\t\\x12\\x10\\n\\x06source\\x18\\x02 \\x01(\\t:\\x00\\x12\\x10\\n\\x05strip\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nbatch_size\\x18\\x04 \\x01(\\x05:\\x01\\x31\\""Z\\n\\x11MatWriteParameter\\x12\\x0e\\n\\x06prefix\\x18\\x01 \\x02(\\t\\x12\\x10\\n\\x06source\\x18\\x02 \\x01(\\t:\\x00\\x12\\x10\\n\\x05strip\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x11\\n\\x06period\\x18\\x04 \\x01(\\x05:\\x01\\x31\\""Z\\n\\x13MemoryDataParameter\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\""d\\n\\x0cMVNParameter\\x12 \\n\\x12normalize_variance\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x0f\\x61\\x63ross_channels\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-09\\""\\xa2\\x03\\n\\x10PoolingParameter\\x12\\x35\\n\\x04pool\\x18\\x01 \\x01(\\x0e\\x32\\"".caffe.PoolingParameter.PoolMethod:\\x03MAX\\x12\\x0e\\n\\x03pad\\x18\\x04 \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x0bkernel_size\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08kernel_h\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x06 \\x01(\\r\\x12\\x11\\n\\x06stride\\x18\\x03 \\x01(\\r:\\x01\\x31\\x12\\x10\\n\\x08stride_h\\x18\\x07 \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x08 \\x01(\\r\\x12\\x37\\n\\x06\\x65ngine\\x18\\x0b \\x01(\\x0e\\x32\\x1e.caffe.PoolingParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x1d\\n\\x0eglobal_pooling\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""F\\n\\x0ePowerParameter\\x12\\x10\\n\\x05power\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""g\\n\\x0fPythonParameter\\x12\\x0e\\n\\x06module\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05layer\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\tparam_str\\x18\\x03 \\x01(\\t:\\x00\\x12 \\n\\x11share_in_parallel\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xad\\x01\\n\\x12ReductionParameter\\x12=\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32%.caffe.ReductionParameter.ReductionOp:\\x03SUM\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05\\x63oeff\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""5\\n\\x0bReductionOp\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x08\\n\\x04\\x41SUM\\x10\\x02\\x12\\t\\n\\x05SUMSQ\\x10\\x03\\x12\\x08\\n\\x04MEAN\\x10\\x04\\""\\x8d\\x01\\n\\rReLUParameter\\x12\\x19\\n\\x0enegative_slope\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x34\\n\\x06\\x65ngine\\x18\\x02 \\x01(\\x0e\\x32\\x1b.caffe.ReLUParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x10ReshapeParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\x08num_axes\\x18\\x03 \\x01(\\x05:\\x02-1\\""\\xa5\\x01\\n\\x0eScaleParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x18\\n\\tbias_term\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""\\xd2\\x01\\n\\x14SegAccuracyParameter\\x12I\\n\\x06metric\\x18\\x01 \\x01(\\x0e\\x32*.caffe.SegAccuracyParameter.AccuracyMetric:\\rPixelAccuracy\\x12\\x14\\n\\x0cignore_label\\x18\\x02 \\x03(\\x05\\x12\\x13\\n\\x05reset\\x18\\x03 \\x01(\\x08:\\x04true\\""D\\n\\x0e\\x41\\x63\\x63uracyMetric\\x12\\x11\\n\\rPixelAccuracy\\x10\\x00\\x12\\x11\\n\\rClassAccuracy\\x10\\x01\\x12\\x0c\\n\\x08PixelIOU\\x10\\x02\\""x\\n\\x10SigmoidParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SigmoidParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""L\\n\\x0eSliceParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x0bslice_point\\x18\\x02 \\x03(\\r\\x12\\x14\\n\\tslice_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""\\x89\\x01\\n\\x10SoftmaxParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SoftmaxParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""r\\n\\rTanHParameter\\x12\\x34\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1b.caffe.TanHParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""/\\n\\rTileParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\r\\n\\x05tiles\\x18\\x02 \\x01(\\x05\\""*\\n\\x12ThresholdParameter\\x12\\x14\\n\\tthreshold\\x18\\x01 \\x01(\\x02:\\x01\\x30\\""U\\n\\x14UniqueLabelParameter\\x12\\x12\\n\\nmax_labels\\x18\\x01 \\x02(\\x05\\x12\\x14\\n\\x0cignore_label\\x18\\x02 \\x03(\\x05\\x12\\x13\\n\\x0b\\x66orce_label\\x18\\x03 \\x03(\\x02\\""\\xc1\\x02\\n\\x13WindowDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\x0c\\x66g_threshold\\x18\\x07 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0c\\x62g_threshold\\x18\\x08 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0b\\x66g_fraction\\x18\\t \\x01(\\x02:\\x04\\x30.25\\x12\\x16\\n\\x0b\\x63ontext_pad\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\tcrop_mode\\x18\\x0b \\x01(\\t:\\x04warp\\x12\\x1b\\n\\x0c\\x63\\x61\\x63he_images\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\r \\x01(\\t:\\x00\\""\\xeb\\x01\\n\\x0cSPPParameter\\x12\\x16\\n\\x0epyramid_height\\x18\\x01 \\x01(\\r\\x12\\x31\\n\\x04pool\\x18\\x02 \\x01(\\x0e\\x32\\x1e.caffe.SPPParameter.PoolMethod:\\x03MAX\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.SPPParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xe0\\x13\\n\\x10V1LayerParameter\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x02 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x03 \\x03(\\t\\x12\\x0c\\n\\x04name\\x18\\x04 \\x01(\\t\\x12$\\n\\x07include\\x18  \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18! \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12/\\n\\x04type\\x18\\x05 \\x01(\\x0e\\x32!.caffe.V1LayerParameter.LayerType\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x0e\\n\\x05param\\x18\\xe9\\x07 \\x03(\\t\\x12>\\n\\x0f\\x62lob_share_mode\\x18\\xea\\x07 \\x03(\\x0e\\x32$.caffe.V1LayerParameter.DimCheckMode\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x07 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x08 \\x03(\\x02\\x12\\x13\\n\\x0bloss_weight\\x18# \\x03(\\x02\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x1b \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18\\x17 \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12,\\n\\x0c\\x63oncat_param\\x18\\t \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18( \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18\\n \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18\\x0b \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18\\x0c \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18\\x1a \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18\\x18 \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12&\\n\\texp_param\\x18) \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18\\r \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18\\x0e \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18\\x1d \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18\\x0f \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18\\x10 \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18\\x11 \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12&\\n\\tlrn_param\\x18\\x12 \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18\\x16 \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18\\"" \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18\\x13 \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18\\x15 \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12(\\n\\nrelu_param\\x18\\x1e \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12.\\n\\rsigmoid_param\\x18& \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18\\\' \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12*\\n\\x0bslice_param\\x18\\x1f \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18% \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x32\\n\\x0fthreshold_param\\x18\\x19 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12\\x35\\n\\x11window_data_param\\x18\\x14 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\x12\\x37\\n\\x0ftransform_param\\x18$ \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18* \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12&\\n\\x05layer\\x18\\x01 \\x01(\\x0b\\x32\\x17.caffe.V0LayerParameter\\""\\xd8\\x04\\n\\tLayerType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\n\\n\\x06\\x41\\x42SVAL\\x10#\\x12\\x0c\\n\\x08\\x41\\x43\\x43URACY\\x10\\x01\\x12\\n\\n\\x06\\x41RGMAX\\x10\\x1e\\x12\\x08\\n\\x04\\x42NLL\\x10\\x02\\x12\\n\\n\\x06\\x43ONCAT\\x10\\x03\\x12\\x14\\n\\x10\\x43ONTRASTIVE_LOSS\\x10%\\x12\\x0f\\n\\x0b\\x43ONVOLUTION\\x10\\x04\\x12\\x08\\n\\x04\\x44\\x41TA\\x10\\x05\\x12\\x11\\n\\rDECONVOLUTION\\x10\\\'\\x12\\x0b\\n\\x07\\x44ROPOUT\\x10\\x06\\x12\\x0e\\n\\nDUMMY_DATA\\x10 \\x12\\x12\\n\\x0e\\x45UCLIDEAN_LOSS\\x10\\x07\\x12\\x0b\\n\\x07\\x45LTWISE\\x10\\x19\\x12\\x07\\n\\x03\\x45XP\\x10&\\x12\\x0b\\n\\x07\\x46LATTEN\\x10\\x08\\x12\\r\\n\\tHDF5_DATA\\x10\\t\\x12\\x0f\\n\\x0bHDF5_OUTPUT\\x10\\n\\x12\\x0e\\n\\nHINGE_LOSS\\x10\\x1c\\x12\\n\\n\\x06IM2COL\\x10\\x0b\\x12\\x0e\\n\\nIMAGE_DATA\\x10\\x0c\\x12\\x11\\n\\rINFOGAIN_LOSS\\x10\\r\\x12\\x11\\n\\rINNER_PRODUCT\\x10\\x0e\\x12\\x07\\n\\x03LRN\\x10\\x0f\\x12\\x0f\\n\\x0bMEMORY_DATA\\x10\\x1d\\x12\\x1d\\n\\x19MULTINOMIAL_LOGISTIC_LOSS\\x10\\x10\\x12\\x07\\n\\x03MVN\\x10\\""\\x12\\x0b\\n\\x07POOLING\\x10\\x11\\x12\\t\\n\\x05POWER\\x10\\x1a\\x12\\x08\\n\\x04RELU\\x10\\x12\\x12\\x0b\\n\\x07SIGMOID\\x10\\x13\\x12\\x1e\\n\\x1aSIGMOID_CROSS_ENTROPY_LOSS\\x10\\x1b\\x12\\x0b\\n\\x07SILENCE\\x10$\\x12\\x0b\\n\\x07SOFTMAX\\x10\\x14\\x12\\x10\\n\\x0cSOFTMAX_LOSS\\x10\\x15\\x12\\t\\n\\x05SPLIT\\x10\\x16\\x12\\t\\n\\x05SLICE\\x10!\\x12\\x08\\n\\x04TANH\\x10\\x17\\x12\\x0f\\n\\x0bWINDOW_DATA\\x10\\x18\\x12\\r\\n\\tTHRESHOLD\\x10\\x1f\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\xfd\\x07\\n\\x10V0LayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x12\\n\\nnum_output\\x18\\x03 \\x01(\\r\\x12\\x16\\n\\x08\\x62iasterm\\x18\\x04 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x06 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0e\\n\\x03pad\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x12\\n\\nkernelsize\\x18\\x08 \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\t \\x01(\\r:\\x01\\x31\\x12\\x11\\n\\x06stride\\x18\\n \\x01(\\r:\\x01\\x31\\x12\\x35\\n\\x04pool\\x18\\x0b \\x01(\\x0e\\x32\\"".caffe.V0LayerParameter.PoolMethod:\\x03MAX\\x12\\x1a\\n\\rdropout_ratio\\x18\\x0c \\x01(\\x02:\\x03\\x30.5\\x12\\x15\\n\\nlocal_size\\x18\\r \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x0e \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x0f \\x01(\\x02:\\x04\\x30.75\\x12\\x0c\\n\\x01k\\x18\\x16 \\x01(\\x02:\\x01\\x31\\x12\\x0e\\n\\x06source\\x18\\x10 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x11 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x08meanfile\\x18\\x12 \\x01(\\t\\x12\\x11\\n\\tbatchsize\\x18\\x13 \\x01(\\r\\x12\\x13\\n\\x08\\x63ropsize\\x18\\x14 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x15 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x32 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x33 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x34 \\x03(\\x02\\x12\\x14\\n\\trand_skip\\x18\\x35 \\x01(\\r:\\x01\\x30\\x12\\x1d\\n\\x10\\x64\\x65t_fg_threshold\\x18\\x36 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x10\\x64\\x65t_bg_threshold\\x18\\x37 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x0f\\x64\\x65t_fg_fraction\\x18\\x38 \\x01(\\x02:\\x04\\x30.25\\x12\\x1a\\n\\x0f\\x64\\x65t_context_pad\\x18: \\x01(\\r:\\x01\\x30\\x12\\x1b\\n\\rdet_crop_mode\\x18; \\x01(\\t:\\x04warp\\x12\\x12\\n\\x07new_num\\x18< \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0cnew_channels\\x18= \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nnew_height\\x18> \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18? \\x01(\\x05:\\x01\\x30\\x12\\x1d\\n\\x0eshuffle_images\\x18@ \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nconcat_dim\\x18\\x41 \\x01(\\r:\\x01\\x31\\x12\\x36\\n\\x11hdf5_output_param\\x18\\xe9\\x07 \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""W\\n\\x0ePReLUParameter\\x12&\\n\\x06\\x66iller\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1d\\n\\x0e\\x63hannel_shared\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse*\\x1c\\n\\x05Phase\\x12\\t\\n\\x05TRAIN\\x10\\x00\\x12\\x08\\n\\x04TEST\\x10\\x01\')\n)\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\n_PHASE = _descriptor.EnumDescriptor(\n  name=\'Phase\',\n  full_name=\'caffe.Phase\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TRAIN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TEST\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=17175,\n  serialized_end=17203,\n)\n_sym_db.RegisterEnumDescriptor(_PHASE)\n\nPhase = enum_type_wrapper.EnumTypeWrapper(_PHASE)\nTRAIN = 0\nTEST = 1\n\n\n_FILLERPARAMETER_VARIANCENORM = _descriptor.EnumDescriptor(\n  name=\'VarianceNorm\',\n  full_name=\'caffe.FillerParameter.VarianceNorm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_IN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_OUT\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVERAGE\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=658,\n  serialized_end=710,\n)\n_sym_db.RegisterEnumDescriptor(_FILLERPARAMETER_VARIANCENORM)\n\n_SOLVERPARAMETER_SNAPSHOTFORMAT = _descriptor.EnumDescriptor(\n  name=\'SnapshotFormat\',\n  full_name=\'caffe.SolverParameter.SnapshotFormat\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BINARYPROTO\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2132,\n  serialized_end=2175,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SNAPSHOTFORMAT)\n\n_SOLVERPARAMETER_SOLVERMODE = _descriptor.EnumDescriptor(\n  name=\'SolverMode\',\n  full_name=\'caffe.SolverParameter.SolverMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CPU\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'GPU\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2177,\n  serialized_end=2207,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SOLVERMODE)\n\n_SOLVERPARAMETER_SOLVERTYPE = _descriptor.EnumDescriptor(\n  name=\'SolverType\',\n  full_name=\'caffe.SolverParameter.SolverType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SGD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NESTEROV\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAGRAD\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RMSPROP\', index=3, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADADELTA\', index=4, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAM\', index=5, number=5,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2209,\n  serialized_end=2294,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SOLVERTYPE)\n\n_PARAMSPEC_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.ParamSpec.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n_sym_db.RegisterEnumDescriptor(_PARAMSPEC_DIMCHECKMODE)\n\n_LOSSPARAMETER_NORMALIZATIONMODE = _descriptor.EnumDescriptor(\n  name=\'NormalizationMode\',\n  full_name=\'caffe.LossParameter.NormalizationMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FULL\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VALID\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BATCH_SIZE\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=3, number=3,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6079,\n  serialized_end=6145,\n)\n_sym_db.RegisterEnumDescriptor(_LOSSPARAMETER_NORMALIZATIONMODE)\n\n_BIASCHANNELPARAMETER_LABELTYPE = _descriptor.EnumDescriptor(\n  name=\'LabelType\',\n  full_name=\'caffe.BiasChannelParameter.LabelType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PIXEL\', index=1, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6651,\n  serialized_end=6684,\n)\n_sym_db.RegisterEnumDescriptor(_BIASCHANNELPARAMETER_LABELTYPE)\n\n_BNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.BNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_BNPARAMETER_ENGINE)\n\n_CONVOLUTIONPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ConvolutionParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_CONVOLUTIONPARAMETER_ENGINE)\n\n_DATAPARAMETER_DB = _descriptor.EnumDescriptor(\n  name=\'DB\',\n  full_name=\'caffe.DataParameter.DB\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVELDB\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LMDB\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=8110,\n  serialized_end=8137,\n)\n_sym_db.RegisterEnumDescriptor(_DATAPARAMETER_DB)\n\n_ELTWISEPARAMETER_ELTWISEOP = _descriptor.EnumDescriptor(\n  name=\'EltwiseOp\',\n  full_name=\'caffe.EltwiseParameter.EltwiseOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'PROD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=8766,\n  serialized_end=8805,\n)\n_sym_db.RegisterEnumDescriptor(_ELTWISEPARAMETER_ELTWISEOP)\n\n_HINGELOSSPARAMETER_NORM = _descriptor.EnumDescriptor(\n  name=\'Norm\',\n  full_name=\'caffe.HingeLossParameter.Norm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'L1\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'L2\', index=1, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9340,\n  serialized_end=9362,\n)\n_sym_db.RegisterEnumDescriptor(_HINGELOSSPARAMETER_NORM)\n\n_IMAGEDATAPARAMETER_LABELTYPE = _descriptor.EnumDescriptor(\n  name=\'LabelType\',\n  full_name=\'caffe.ImageDataParameter.LabelType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PIXEL\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9737,\n  serialized_end=9780,\n)\n_sym_db.RegisterEnumDescriptor(_IMAGEDATAPARAMETER_LABELTYPE)\n\n_LRNPARAMETER_NORMREGION = _descriptor.EnumDescriptor(\n  name=\'NormRegion\',\n  full_name=\'caffe.LRNParameter.NormRegion\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ACROSS_CHANNELS\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WITHIN_CHANNEL\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=10461,\n  serialized_end=10514,\n)\n_sym_db.RegisterEnumDescriptor(_LRNPARAMETER_NORMREGION)\n\n_LRNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.LRNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_LRNPARAMETER_ENGINE)\n\n_POOLINGPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.PoolingParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=11270,\n  serialized_end=11316,\n)\n_sym_db.RegisterEnumDescriptor(_POOLINGPARAMETER_POOLMETHOD)\n\n_POOLINGPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.PoolingParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_POOLINGPARAMETER_ENGINE)\n\n_REDUCTIONPARAMETER_REDUCTIONOP = _descriptor.EnumDescriptor(\n  name=\'ReductionOp\',\n  full_name=\'caffe.ReductionParameter.ReductionOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ASUM\', index=1, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUMSQ\', index=2, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEAN\', index=3, number=4,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=11661,\n  serialized_end=11714,\n)\n_sym_db.RegisterEnumDescriptor(_REDUCTIONPARAMETER_REDUCTIONOP)\n\n_RELUPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ReLUParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_RELUPARAMETER_ENGINE)\n\n_SEGACCURACYPARAMETER_ACCURACYMETRIC = _descriptor.EnumDescriptor(\n  name=\'AccuracyMetric\',\n  full_name=\'caffe.SegAccuracyParameter.AccuracyMetric\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'PixelAccuracy\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ClassAccuracy\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PixelIOU\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=12263,\n  serialized_end=12331,\n)\n_sym_db.RegisterEnumDescriptor(_SEGACCURACYPARAMETER_ACCURACYMETRIC)\n\n_SIGMOIDPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SigmoidParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_SIGMOIDPARAMETER_ENGINE)\n\n_SOFTMAXPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SoftmaxParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_SOFTMAXPARAMETER_ENGINE)\n\n_TANHPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.TanHParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_TANHPARAMETER_ENGINE)\n\n_SPPPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.SPPParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=11270,\n  serialized_end=11316,\n)\n_sym_db.RegisterEnumDescriptor(_SPPPARAMETER_POOLMETHOD)\n\n_SPPPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SPPParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7115,\n  serialized_end=7158,\n)\n_sym_db.RegisterEnumDescriptor(_SPPPARAMETER_ENGINE)\n\n_V1LAYERPARAMETER_LAYERTYPE = _descriptor.EnumDescriptor(\n  name=\'LayerType\',\n  full_name=\'caffe.V1LayerParameter.LayerType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ABSVAL\', index=1, number=35,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ACCURACY\', index=2, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ARGMAX\', index=3, number=30,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BNLL\', index=4, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONCAT\', index=5, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONTRASTIVE_LOSS\', index=6, number=37,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONVOLUTION\', index=7, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA\', index=8, number=5,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DECONVOLUTION\', index=9, number=39,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DROPOUT\', index=10, number=6,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DUMMY_DATA\', index=11, number=32,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EUCLIDEAN_LOSS\', index=12, number=7,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ELTWISE\', index=13, number=25,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EXP\', index=14, number=38,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FLATTEN\', index=15, number=8,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_DATA\', index=16, number=9,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_OUTPUT\', index=17, number=10,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HINGE_LOSS\', index=18, number=28,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IM2COL\', index=19, number=11,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE_DATA\', index=20, number=12,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INFOGAIN_LOSS\', index=21, number=13,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INNER_PRODUCT\', index=22, number=14,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LRN\', index=23, number=15,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEMORY_DATA\', index=24, number=29,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MULTINOMIAL_LOGISTIC_LOSS\', index=25, number=16,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MVN\', index=26, number=34,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POOLING\', index=27, number=17,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POWER\', index=28, number=26,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RELU\', index=29, number=18,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID\', index=30, number=19,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID_CROSS_ENTROPY_LOSS\', index=31, number=27,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SILENCE\', index=32, number=36,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX\', index=33, number=20,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX_LOSS\', index=34, number=21,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SPLIT\', index=35, number=22,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SLICE\', index=36, number=33,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TANH\', index=37, number=23,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WINDOW_DATA\', index=38, number=24,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'THRESHOLD\', index=39, number=31,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=15416,\n  serialized_end=16016,\n)\n_sym_db.RegisterEnumDescriptor(_V1LAYERPARAMETER_LAYERTYPE)\n\n_V1LAYERPARAMETER_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.V1LayerParameter.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2725,\n  serialized_end=2767,\n)\n_sym_db.RegisterEnumDescriptor(_V1LAYERPARAMETER_DIMCHECKMODE)\n\n_V0LAYERPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.V0LayerParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=11270,\n  serialized_end=11316,\n)\n_sym_db.RegisterEnumDescriptor(_V0LAYERPARAMETER_POOLMETHOD)\n\n\n_BLOBSHAPE = _descriptor.Descriptor(\n  name=\'BlobShape\',\n  full_name=\'caffe.BlobShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'caffe.BlobShape.dim\', index=0,\n      number=1, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22,\n  serialized_end=50,\n)\n\n\n_BLOBPROTO = _descriptor.Descriptor(\n  name=\'BlobProto\',\n  full_name=\'caffe.BlobProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.BlobProto.shape\', index=0,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.BlobProto.data\', index=1,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'diff\', full_name=\'caffe.BlobProto.diff\', index=2,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'double_data\', full_name=\'caffe.BlobProto.double_data\', index=3,\n      number=8, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'double_diff\', full_name=\'caffe.BlobProto.double_diff\', index=4,\n      number=9, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.BlobProto.num\', index=5,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.BlobProto.channels\', index=6,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.BlobProto.height\', index=7,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.BlobProto.width\', index=8,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=53,\n  serialized_end=257,\n)\n\n\n_BLOBPROTOVECTOR = _descriptor.Descriptor(\n  name=\'BlobProtoVector\',\n  full_name=\'caffe.BlobProtoVector\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.BlobProtoVector.blobs\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=259,\n  serialized_end=309,\n)\n\n\n_DATUM = _descriptor.Descriptor(\n  name=\'Datum\',\n  full_name=\'caffe.Datum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.Datum.channels\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.Datum.height\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.Datum.width\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.Datum.data\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.Datum.label\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'float_data\', full_name=\'caffe.Datum.float_data\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'encoded\', full_name=\'caffe.Datum.encoded\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=312,\n  serialized_end=441,\n)\n\n\n_FILLERPARAMETER = _descriptor.Descriptor(\n  name=\'FillerParameter\',\n  full_name=\'caffe.FillerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.FillerParameter.type\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""constant"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'caffe.FillerParameter.value\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min\', full_name=\'caffe.FillerParameter.min\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max\', full_name=\'caffe.FillerParameter.max\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean\', full_name=\'caffe.FillerParameter.mean\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'std\', full_name=\'caffe.FillerParameter.std\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sparse\', full_name=\'caffe.FillerParameter.sparse\', index=6,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'variance_norm\', full_name=\'caffe.FillerParameter.variance_norm\', index=7,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _FILLERPARAMETER_VARIANCENORM,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=444,\n  serialized_end=710,\n)\n\n\n_NETPARAMETER = _descriptor.Descriptor(\n  name=\'NetParameter\',\n  full_name=\'caffe.NetParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.NetParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'caffe.NetParameter.input\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_shape\', full_name=\'caffe.NetParameter.input_shape\', index=2,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.NetParameter.input_dim\', index=3,\n      number=4, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_backward\', full_name=\'caffe.NetParameter.force_backward\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'caffe.NetParameter.state\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.NetParameter.debug_info\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.NetParameter.layer\', index=7,\n      number=100, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layers\', full_name=\'caffe.NetParameter.layers\', index=8,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=713,\n  serialized_end=983,\n)\n\n\n_SOLVERPARAMETER = _descriptor.Descriptor(\n  name=\'SolverParameter\',\n  full_name=\'caffe.SolverParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'net\', full_name=\'caffe.SolverParameter.net\', index=0,\n      number=24, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'net_param\', full_name=\'caffe.SolverParameter.net_param\', index=1,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net\', full_name=\'caffe.SolverParameter.train_net\', index=2,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net\', full_name=\'caffe.SolverParameter.test_net\', index=3,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net_param\', full_name=\'caffe.SolverParameter.train_net_param\', index=4,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net_param\', full_name=\'caffe.SolverParameter.test_net_param\', index=5,\n      number=22, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_state\', full_name=\'caffe.SolverParameter.train_state\', index=6,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_state\', full_name=\'caffe.SolverParameter.test_state\', index=7,\n      number=27, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_iter\', full_name=\'caffe.SolverParameter.test_iter\', index=8,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_interval\', full_name=\'caffe.SolverParameter.test_interval\', index=9,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_compute_loss\', full_name=\'caffe.SolverParameter.test_compute_loss\', index=10,\n      number=19, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_initialization\', full_name=\'caffe.SolverParameter.test_initialization\', index=11,\n      number=32, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'base_lr\', full_name=\'caffe.SolverParameter.base_lr\', index=12,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'display\', full_name=\'caffe.SolverParameter.display\', index=13,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'average_loss\', full_name=\'caffe.SolverParameter.average_loss\', index=14,\n      number=33, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_iter\', full_name=\'caffe.SolverParameter.max_iter\', index=15,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'iter_size\', full_name=\'caffe.SolverParameter.iter_size\', index=16,\n      number=36, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_policy\', full_name=\'caffe.SolverParameter.lr_policy\', index=17,\n      number=8, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.SolverParameter.gamma\', index=18,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.SolverParameter.power\', index=19,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.SolverParameter.momentum\', index=20,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.SolverParameter.weight_decay\', index=21,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'regularization_type\', full_name=\'caffe.SolverParameter.regularization_type\', index=22,\n      number=29, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""L2"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepsize\', full_name=\'caffe.SolverParameter.stepsize\', index=23,\n      number=13, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepvalue\', full_name=\'caffe.SolverParameter.stepvalue\', index=24,\n      number=34, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'clip_gradients\', full_name=\'caffe.SolverParameter.clip_gradients\', index=25,\n      number=35, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot\', full_name=\'caffe.SolverParameter.snapshot\', index=26,\n      number=14, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_prefix\', full_name=\'caffe.SolverParameter.snapshot_prefix\', index=27,\n      number=15, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_diff\', full_name=\'caffe.SolverParameter.snapshot_diff\', index=28,\n      number=16, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_format\', full_name=\'caffe.SolverParameter.snapshot_format\', index=29,\n      number=37, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_mode\', full_name=\'caffe.SolverParameter.solver_mode\', index=30,\n      number=17, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'device_id\', full_name=\'caffe.SolverParameter.device_id\', index=31,\n      number=18, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'random_seed\', full_name=\'caffe.SolverParameter.random_seed\', index=32,\n      number=20, type=3, cpp_type=2, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.SolverParameter.type\', index=33,\n      number=40, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""SGD"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'delta\', full_name=\'caffe.SolverParameter.delta\', index=34,\n      number=31, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-08),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum2\', full_name=\'caffe.SolverParameter.momentum2\', index=35,\n      number=39, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.999),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rms_decay\', full_name=\'caffe.SolverParameter.rms_decay\', index=36,\n      number=38, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.SolverParameter.debug_info\', index=37,\n      number=23, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_after_train\', full_name=\'caffe.SolverParameter.snapshot_after_train\', index=38,\n      number=28, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_type\', full_name=\'caffe.SolverParameter.solver_type\', index=39,\n      number=30, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOLVERPARAMETER_SNAPSHOTFORMAT,\n    _SOLVERPARAMETER_SOLVERMODE,\n    _SOLVERPARAMETER_SOLVERTYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=986,\n  serialized_end=2294,\n)\n\n\n_SOLVERSTATE = _descriptor.Descriptor(\n  name=\'SolverState\',\n  full_name=\'caffe.SolverState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'iter\', full_name=\'caffe.SolverState.iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'learned_net\', full_name=\'caffe.SolverState.learned_net\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'history\', full_name=\'caffe.SolverState.history\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'current_step\', full_name=\'caffe.SolverState.current_step\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2296,\n  serialized_end=2404,\n)\n\n\n_NETSTATE = _descriptor.Descriptor(\n  name=\'NetState\',\n  full_name=\'caffe.NetState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetState.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'level\', full_name=\'caffe.NetState.level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetState.stage\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2406,\n  serialized_end=2484,\n)\n\n\n_NETSTATERULE = _descriptor.Descriptor(\n  name=\'NetStateRule\',\n  full_name=\'caffe.NetStateRule\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetStateRule.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min_level\', full_name=\'caffe.NetStateRule.min_level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_level\', full_name=\'caffe.NetStateRule.max_level\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetStateRule.stage\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'not_stage\', full_name=\'caffe.NetStateRule.not_stage\', index=4,\n      number=5, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2486,\n  serialized_end=2601,\n)\n\n\n_PARAMSPEC = _descriptor.Descriptor(\n  name=\'ParamSpec\',\n  full_name=\'caffe.ParamSpec\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.ParamSpec.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_mode\', full_name=\'caffe.ParamSpec.share_mode\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_mult\', full_name=\'caffe.ParamSpec.lr_mult\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'decay_mult\', full_name=\'caffe.ParamSpec.decay_mult\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _PARAMSPEC_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2604,\n  serialized_end=2767,\n)\n\n\n_LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'LayerParameter\',\n  full_name=\'caffe.LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.LayerParameter.bottom\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.LayerParameter.top\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.LayerParameter.phase\', index=4,\n      number=10, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.LayerParameter.loss_weight\', index=5,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.LayerParameter.param\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.LayerParameter.blobs\', index=7,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'propagate_down\', full_name=\'caffe.LayerParameter.propagate_down\', index=8,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.LayerParameter.include\', index=9,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.LayerParameter.exclude\', index=10,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.LayerParameter.transform_param\', index=11,\n      number=100, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.LayerParameter.loss_param\', index=12,\n      number=101, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.LayerParameter.accuracy_param\', index=13,\n      number=102, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'adaptive_bias_channel_param\', full_name=\'caffe.LayerParameter.adaptive_bias_channel_param\', index=14,\n      number=148, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.LayerParameter.argmax_param\', index=15,\n      number=103, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_norm_param\', full_name=\'caffe.LayerParameter.batch_norm_param\', index=16,\n      number=139, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bn_param\', full_name=\'caffe.LayerParameter.bn_param\', index=17,\n      number=152, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_param\', full_name=\'caffe.LayerParameter.bias_param\', index=18,\n      number=141, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_channel_param\', full_name=\'caffe.LayerParameter.bias_channel_param\', index=19,\n      number=149, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.LayerParameter.concat_param\', index=20,\n      number=104, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.LayerParameter.contrastive_loss_param\', index=21,\n      number=105, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.LayerParameter.convolution_param\', index=22,\n      number=106, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.LayerParameter.data_param\', index=23,\n      number=107, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dense_crf_param\', full_name=\'caffe.LayerParameter.dense_crf_param\', index=24,\n      number=146, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'domain_transform_param\', full_name=\'caffe.LayerParameter.domain_transform_param\', index=25,\n      number=147, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.LayerParameter.dropout_param\', index=26,\n      number=108, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.LayerParameter.dummy_data_param\', index=27,\n      number=109, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.LayerParameter.eltwise_param\', index=28,\n      number=110, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'elu_param\', full_name=\'caffe.LayerParameter.elu_param\', index=29,\n      number=140, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'embed_param\', full_name=\'caffe.LayerParameter.embed_param\', index=30,\n      number=137, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.LayerParameter.exp_param\', index=31,\n      number=111, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'flatten_param\', full_name=\'caffe.LayerParameter.flatten_param\', index=32,\n      number=135, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.LayerParameter.hdf5_data_param\', index=33,\n      number=112, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.LayerParameter.hdf5_output_param\', index=34,\n      number=113, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.LayerParameter.hinge_loss_param\', index=35,\n      number=114, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.LayerParameter.image_data_param\', index=36,\n      number=115, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.LayerParameter.infogain_loss_param\', index=37,\n      number=116, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.LayerParameter.inner_product_param\', index=38,\n      number=117, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'interp_param\', full_name=\'caffe.LayerParameter.interp_param\', index=39,\n      number=143, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'log_param\', full_name=\'caffe.LayerParameter.log_param\', index=40,\n      number=134, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.LayerParameter.lrn_param\', index=41,\n      number=118, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mat_read_param\', full_name=\'caffe.LayerParameter.mat_read_param\', index=42,\n      number=151, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mat_write_param\', full_name=\'caffe.LayerParameter.mat_write_param\', index=43,\n      number=145, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.LayerParameter.memory_data_param\', index=44,\n      number=119, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.LayerParameter.mvn_param\', index=45,\n      number=120, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.LayerParameter.pooling_param\', index=46,\n      number=121, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.LayerParameter.power_param\', index=47,\n      number=122, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prelu_param\', full_name=\'caffe.LayerParameter.prelu_param\', index=48,\n      number=131, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'python_param\', full_name=\'caffe.LayerParameter.python_param\', index=49,\n      number=130, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reduction_param\', full_name=\'caffe.LayerParameter.reduction_param\', index=50,\n      number=136, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.LayerParameter.relu_param\', index=51,\n      number=123, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reshape_param\', full_name=\'caffe.LayerParameter.reshape_param\', index=52,\n      number=133, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale_param\', full_name=\'caffe.LayerParameter.scale_param\', index=53,\n      number=142, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'seg_accuracy_param\', full_name=\'caffe.LayerParameter.seg_accuracy_param\', index=54,\n      number=144, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.LayerParameter.sigmoid_param\', index=55,\n      number=124, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.LayerParameter.softmax_param\', index=56,\n      number=125, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'spp_param\', full_name=\'caffe.LayerParameter.spp_param\', index=57,\n      number=132, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.LayerParameter.slice_param\', index=58,\n      number=126, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.LayerParameter.tanh_param\', index=59,\n      number=127, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.LayerParameter.threshold_param\', index=60,\n      number=128, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tile_param\', full_name=\'caffe.LayerParameter.tile_param\', index=61,\n      number=138, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'unique_label_param\', full_name=\'caffe.LayerParameter.unique_label_param\', index=62,\n      number=150, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.LayerParameter.window_data_param\', index=63,\n      number=129, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2770,\n  serialized_end=5693,\n)\n\n\n_TRANSFORMATIONPARAMETER = _descriptor.Descriptor(\n  name=\'TransformationParameter\',\n  full_name=\'caffe.TransformationParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.TransformationParameter.scale\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.TransformationParameter.mirror\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.TransformationParameter.crop_size\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.TransformationParameter.mean_file\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_value\', full_name=\'caffe.TransformationParameter.mean_value\', index=4,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_color\', full_name=\'caffe.TransformationParameter.force_color\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_gray\', full_name=\'caffe.TransformationParameter.force_gray\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale_factors\', full_name=\'caffe.TransformationParameter.scale_factors\', index=7,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_width\', full_name=\'caffe.TransformationParameter.crop_width\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_height\', full_name=\'caffe.TransformationParameter.crop_height\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=5696,\n  serialized_end=5948,\n)\n\n\n_LOSSPARAMETER = _descriptor.Descriptor(\n  name=\'LossParameter\',\n  full_name=\'caffe.LossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.LossParameter.ignore_label\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalization\', full_name=\'caffe.LossParameter.normalization\', index=1,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalize\', full_name=\'caffe.LossParameter.normalize\', index=2,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LOSSPARAMETER_NORMALIZATIONMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=5951,\n  serialized_end=6145,\n)\n\n\n_ACCURACYPARAMETER = _descriptor.Descriptor(\n  name=\'AccuracyParameter\',\n  full_name=\'caffe.AccuracyParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.AccuracyParameter.top_k\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.AccuracyParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.AccuracyParameter.ignore_label\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6147,\n  serialized_end=6223,\n)\n\n\n_ADAPTIVEBIASCHANNELPARAMETER = _descriptor.Descriptor(\n  name=\'AdaptiveBiasChannelParameter\',\n  full_name=\'caffe.AdaptiveBiasChannelParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_iter\', full_name=\'caffe.AdaptiveBiasChannelParameter.num_iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bg_portion\', full_name=\'caffe.AdaptiveBiasChannelParameter.bg_portion\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.2),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_portion\', full_name=\'caffe.AdaptiveBiasChannelParameter.fg_portion\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.2),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'suppress_others\', full_name=\'caffe.AdaptiveBiasChannelParameter.suppress_others\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'margin_others\', full_name=\'caffe.AdaptiveBiasChannelParameter.margin_others\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-05),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6226,\n  serialized_end=6388,\n)\n\n\n_ARGMAXPARAMETER = _descriptor.Descriptor(\n  name=\'ArgMaxParameter\',\n  full_name=\'caffe.ArgMaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'out_max_val\', full_name=\'caffe.ArgMaxParameter.out_max_val\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.ArgMaxParameter.top_k\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ArgMaxParameter.axis\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6390,\n  serialized_end=6467,\n)\n\n\n_BIASCHANNELPARAMETER = _descriptor.Descriptor(\n  name=\'BiasChannelParameter\',\n  full_name=\'caffe.BiasChannelParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bg_bias\', full_name=\'caffe.BiasChannelParameter.bg_bias\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_bias\', full_name=\'caffe.BiasChannelParameter.fg_bias\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(2),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.BiasChannelParameter.ignore_label\', index=2,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'label_type\', full_name=\'caffe.BiasChannelParameter.label_type\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'background_label\', full_name=\'caffe.BiasChannelParameter.background_label\', index=4,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _BIASCHANNELPARAMETER_LABELTYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6470,\n  serialized_end=6684,\n)\n\n\n_CONCATPARAMETER = _descriptor.Descriptor(\n  name=\'ConcatParameter\',\n  full_name=\'caffe.ConcatParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConcatParameter.axis\', index=0,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.ConcatParameter.concat_dim\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6686,\n  serialized_end=6743,\n)\n\n\n_BATCHNORMPARAMETER = _descriptor.Descriptor(\n  name=\'BatchNormParameter\',\n  full_name=\'caffe.BatchNormParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'use_global_stats\', full_name=\'caffe.BatchNormParameter.use_global_stats\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'moving_average_fraction\', full_name=\'caffe.BatchNormParameter.moving_average_fraction\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.999),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BatchNormParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-05),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'update_global_stats\', full_name=\'caffe.BatchNormParameter.update_global_stats\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6746,\n  serialized_end=6888,\n)\n\n\n_BNPARAMETER = _descriptor.Descriptor(\n  name=\'BNParameter\',\n  full_name=\'caffe.BNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'slope_filler\', full_name=\'caffe.BNParameter.slope_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.BNParameter.bias_filler\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.BNParameter.momentum\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.9),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BNParameter.eps\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-05),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'frozen\', full_name=\'caffe.BNParameter.frozen\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.BNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _BNPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6891,\n  serialized_end=7158,\n)\n\n\n_BIASPARAMETER = _descriptor.Descriptor(\n  name=\'BiasParameter\',\n  full_name=\'caffe.BiasParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.BiasParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.BiasParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.BiasParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7160,\n  serialized_end=7253,\n)\n\n\n_CONTRASTIVELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'ContrastiveLossParameter\',\n  full_name=\'caffe.ContrastiveLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.ContrastiveLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'legacy_version\', full_name=\'caffe.ContrastiveLossParameter.legacy_version\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7255,\n  serialized_end=7331,\n)\n\n\n_CONVOLUTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ConvolutionParameter\',\n  full_name=\'caffe.ConvolutionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.ConvolutionParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ConvolutionParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.ConvolutionParameter.pad\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.ConvolutionParameter.kernel_size\', index=3,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.ConvolutionParameter.stride\', index=4,\n      number=6, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dilation\', full_name=\'caffe.ConvolutionParameter.dilation\', index=5,\n      number=18, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.ConvolutionParameter.pad_h\', index=6,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.ConvolutionParameter.pad_w\', index=7,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.ConvolutionParameter.kernel_h\', index=8,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.ConvolutionParameter.kernel_w\', index=9,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.ConvolutionParameter.stride_h\', index=10,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.ConvolutionParameter.stride_w\', index=11,\n      number=14, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.ConvolutionParameter.group\', index=12,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.ConvolutionParameter.weight_filler\', index=13,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ConvolutionParameter.bias_filler\', index=14,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ConvolutionParameter.engine\', index=15,\n      number=15, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConvolutionParameter.axis\', index=16,\n      number=16, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_nd_im2col\', full_name=\'caffe.ConvolutionParameter.force_nd_im2col\', index=17,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CONVOLUTIONPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7334,\n  serialized_end=7842,\n)\n\n\n_DATAPARAMETER = _descriptor.Descriptor(\n  name=\'DataParameter\',\n  full_name=\'caffe.DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.DataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.DataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'backend\', full_name=\'caffe.DataParameter.backend\', index=3,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.DataParameter.scale\', index=4,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.DataParameter.mean_file\', index=5,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.DataParameter.crop_size\', index=6,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.DataParameter.mirror\', index=7,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_encoded_color\', full_name=\'caffe.DataParameter.force_encoded_color\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prefetch\', full_name=\'caffe.DataParameter.prefetch\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _DATAPARAMETER_DB,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7845,\n  serialized_end=8137,\n)\n\n\n_DENSECRFPARAMETER = _descriptor.Descriptor(\n  name=\'DenseCRFParameter\',\n  full_name=\'caffe.DenseCRFParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'max_iter\', full_name=\'caffe.DenseCRFParameter.max_iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=10,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pos_xy_std\', full_name=\'caffe.DenseCRFParameter.pos_xy_std\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pos_w\', full_name=\'caffe.DenseCRFParameter.pos_w\', index=2,\n      number=3, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bi_xy_std\', full_name=\'caffe.DenseCRFParameter.bi_xy_std\', index=3,\n      number=4, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bi_rgb_std\', full_name=\'caffe.DenseCRFParameter.bi_rgb_std\', index=4,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bi_w\', full_name=\'caffe.DenseCRFParameter.bi_w\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'output_probability\', full_name=\'caffe.DenseCRFParameter.output_probability\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8140,\n  serialized_end=8303,\n)\n\n\n_DOMAINTRANSFORMPARAMETER = _descriptor.Descriptor(\n  name=\'DomainTransformParameter\',\n  full_name=\'caffe.DomainTransformParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_iter\', full_name=\'caffe.DomainTransformParameter.num_iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=3,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'spatial_sigma\', full_name=\'caffe.DomainTransformParameter.spatial_sigma\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(50),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'range_sigma\', full_name=\'caffe.DomainTransformParameter.range_sigma\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min_weight\', full_name=\'caffe.DomainTransformParameter.min_weight\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8305,\n  serialized_end=8426,\n)\n\n\n_DROPOUTPARAMETER = _descriptor.Descriptor(\n  name=\'DropoutParameter\',\n  full_name=\'caffe.DropoutParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.DropoutParameter.dropout_ratio\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8428,\n  serialized_end=8474,\n)\n\n\n_DUMMYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'DummyDataParameter\',\n  full_name=\'caffe.DummyDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data_filler\', full_name=\'caffe.DummyDataParameter.data_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.DummyDataParameter.shape\', index=1,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.DummyDataParameter.num\', index=2,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.DummyDataParameter.channels\', index=3,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.DummyDataParameter.height\', index=4,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.DummyDataParameter.width\', index=5,\n      number=5, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8477,\n  serialized_end=8637,\n)\n\n\n_ELTWISEPARAMETER = _descriptor.Descriptor(\n  name=\'EltwiseParameter\',\n  full_name=\'caffe.EltwiseParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.EltwiseParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.EltwiseParameter.coeff\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stable_prod_grad\', full_name=\'caffe.EltwiseParameter.stable_prod_grad\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _ELTWISEPARAMETER_ELTWISEOP,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8640,\n  serialized_end=8805,\n)\n\n\n_ELUPARAMETER = _descriptor.Descriptor(\n  name=\'ELUParameter\',\n  full_name=\'caffe.ELUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.ELUParameter.alpha\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8807,\n  serialized_end=8839,\n)\n\n\n_EMBEDPARAMETER = _descriptor.Descriptor(\n  name=\'EmbedParameter\',\n  full_name=\'caffe.EmbedParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.EmbedParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.EmbedParameter.input_dim\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.EmbedParameter.bias_term\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.EmbedParameter.weight_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.EmbedParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8842,\n  serialized_end=9014,\n)\n\n\n_EXPPARAMETER = _descriptor.Descriptor(\n  name=\'ExpParameter\',\n  full_name=\'caffe.ExpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.ExpParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ExpParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.ExpParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9016,\n  serialized_end=9084,\n)\n\n\n_FLATTENPARAMETER = _descriptor.Descriptor(\n  name=\'FlattenParameter\',\n  full_name=\'caffe.FlattenParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.FlattenParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'end_axis\', full_name=\'caffe.FlattenParameter.end_axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9086,\n  serialized_end=9143,\n)\n\n\n_HDF5DATAPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5DataParameter\',\n  full_name=\'caffe.HDF5DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.HDF5DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.HDF5DataParameter.batch_size\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.HDF5DataParameter.shuffle\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9145,\n  serialized_end=9224,\n)\n\n\n_HDF5OUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5OutputParameter\',\n  full_name=\'caffe.HDF5OutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'file_name\', full_name=\'caffe.HDF5OutputParameter.file_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9226,\n  serialized_end=9266,\n)\n\n\n_HINGELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'HingeLossParameter\',\n  full_name=\'caffe.HingeLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'norm\', full_name=\'caffe.HingeLossParameter.norm\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _HINGELOSSPARAMETER_NORM,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9268,\n  serialized_end=9362,\n)\n\n\n_IMAGEDATAPARAMETER = _descriptor.Descriptor(\n  name=\'ImageDataParameter\',\n  full_name=\'caffe.ImageDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.ImageDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.ImageDataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.ImageDataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.ImageDataParameter.shuffle\', index=3,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.ImageDataParameter.new_height\', index=4,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.ImageDataParameter.new_width\', index=5,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'is_color\', full_name=\'caffe.ImageDataParameter.is_color\', index=6,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.ImageDataParameter.ignore_label\', index=7,\n      number=15, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=255,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'label_type\', full_name=\'caffe.ImageDataParameter.label_type\', index=8,\n      number=16, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ImageDataParameter.scale\', index=9,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.ImageDataParameter.mean_file\', index=10,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.ImageDataParameter.crop_size\', index=11,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.ImageDataParameter.mirror\', index=12,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.ImageDataParameter.root_folder\', index=13,\n      number=12, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _IMAGEDATAPARAMETER_LABELTYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9365,\n  serialized_end=9780,\n)\n\n\n_INFOGAINLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'InfogainLossParameter\',\n  full_name=\'caffe.InfogainLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.InfogainLossParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9782,\n  serialized_end=9821,\n)\n\n\n_INNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'InnerProductParameter\',\n  full_name=\'caffe.InnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.InnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.InnerProductParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.InnerProductParameter.weight_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.InnerProductParameter.bias_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.InnerProductParameter.axis\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transpose\', full_name=\'caffe.InnerProductParameter.transpose\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9824,\n  serialized_end=10027,\n)\n\n\n_INTERPPARAMETER = _descriptor.Descriptor(\n  name=\'InterpParameter\',\n  full_name=\'caffe.InterpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.InterpParameter.height\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.InterpParameter.width\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'zoom_factor\', full_name=\'caffe.InterpParameter.zoom_factor\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shrink_factor\', full_name=\'caffe.InterpParameter.shrink_factor\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_beg\', full_name=\'caffe.InterpParameter.pad_beg\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_end\', full_name=\'caffe.InterpParameter.pad_end\', index=5,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10030,\n  serialized_end=10174,\n)\n\n\n_LOGPARAMETER = _descriptor.Descriptor(\n  name=\'LogParameter\',\n  full_name=\'caffe.LogParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.LogParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.LogParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.LogParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10176,\n  serialized_end=10244,\n)\n\n\n_LRNPARAMETER = _descriptor.Descriptor(\n  name=\'LRNParameter\',\n  full_name=\'caffe.LRNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.LRNParameter.local_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.LRNParameter.alpha\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.LRNParameter.beta\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.75),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'norm_region\', full_name=\'caffe.LRNParameter.norm_region\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.LRNParameter.k\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.LRNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LRNPARAMETER_NORMREGION,\n    _LRNPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10247,\n  serialized_end=10559,\n)\n\n\n_MATREADPARAMETER = _descriptor.Descriptor(\n  name=\'MatReadParameter\',\n  full_name=\'caffe.MatReadParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'prefix\', full_name=\'caffe.MatReadParameter.prefix\', index=0,\n      number=1, type=9, cpp_type=9, label=2,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.MatReadParameter.source\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'strip\', full_name=\'caffe.MatReadParameter.strip\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.MatReadParameter.batch_size\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10561,\n  serialized_end=10654,\n)\n\n\n_MATWRITEPARAMETER = _descriptor.Descriptor(\n  name=\'MatWriteParameter\',\n  full_name=\'caffe.MatWriteParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'prefix\', full_name=\'caffe.MatWriteParameter.prefix\', index=0,\n      number=1, type=9, cpp_type=9, label=2,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.MatWriteParameter.source\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'strip\', full_name=\'caffe.MatWriteParameter.strip\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'period\', full_name=\'caffe.MatWriteParameter.period\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10656,\n  serialized_end=10746,\n)\n\n\n_MEMORYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'MemoryDataParameter\',\n  full_name=\'caffe.MemoryDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.MemoryDataParameter.batch_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.MemoryDataParameter.channels\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.MemoryDataParameter.height\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.MemoryDataParameter.width\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10748,\n  serialized_end=10838,\n)\n\n\n_MVNPARAMETER = _descriptor.Descriptor(\n  name=\'MVNParameter\',\n  full_name=\'caffe.MVNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'normalize_variance\', full_name=\'caffe.MVNParameter.normalize_variance\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'across_channels\', full_name=\'caffe.MVNParameter.across_channels\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.MVNParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-09),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10840,\n  serialized_end=10940,\n)\n\n\n_POOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'PoolingParameter\',\n  full_name=\'caffe.PoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.PoolingParameter.pool\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.PoolingParameter.pad\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.PoolingParameter.pad_h\', index=2,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.PoolingParameter.pad_w\', index=3,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.PoolingParameter.kernel_size\', index=4,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.PoolingParameter.kernel_h\', index=5,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.PoolingParameter.kernel_w\', index=6,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.PoolingParameter.stride\', index=7,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.PoolingParameter.stride_h\', index=8,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.PoolingParameter.stride_w\', index=9,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.PoolingParameter.engine\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'global_pooling\', full_name=\'caffe.PoolingParameter.global_pooling\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _POOLINGPARAMETER_POOLMETHOD,\n    _POOLINGPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10943,\n  serialized_end=11361,\n)\n\n\n_POWERPARAMETER = _descriptor.Descriptor(\n  name=\'PowerParameter\',\n  full_name=\'caffe.PowerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.PowerParameter.power\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.PowerParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.PowerParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11363,\n  serialized_end=11433,\n)\n\n\n_PYTHONPARAMETER = _descriptor.Descriptor(\n  name=\'PythonParameter\',\n  full_name=\'caffe.PythonParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'module\', full_name=\'caffe.PythonParameter.module\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.PythonParameter.layer\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param_str\', full_name=\'caffe.PythonParameter.param_str\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_in_parallel\', full_name=\'caffe.PythonParameter.share_in_parallel\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11435,\n  serialized_end=11538,\n)\n\n\n_REDUCTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ReductionParameter\',\n  full_name=\'caffe.ReductionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.ReductionParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReductionParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.ReductionParameter.coeff\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _REDUCTIONPARAMETER_REDUCTIONOP,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11541,\n  serialized_end=11714,\n)\n\n\n_RELUPARAMETER = _descriptor.Descriptor(\n  name=\'ReLUParameter\',\n  full_name=\'caffe.ReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'negative_slope\', full_name=\'caffe.ReLUParameter.negative_slope\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ReLUParameter.engine\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _RELUPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11717,\n  serialized_end=11858,\n)\n\n\n_RESHAPEPARAMETER = _descriptor.Descriptor(\n  name=\'ReshapeParameter\',\n  full_name=\'caffe.ReshapeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ReshapeParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReshapeParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ReshapeParameter.num_axes\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11860,\n  serialized_end=11950,\n)\n\n\n_SCALEPARAMETER = _descriptor.Descriptor(\n  name=\'ScaleParameter\',\n  full_name=\'caffe.ScaleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ScaleParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ScaleParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.ScaleParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ScaleParameter.bias_term\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ScaleParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11953,\n  serialized_end=12118,\n)\n\n\n_SEGACCURACYPARAMETER = _descriptor.Descriptor(\n  name=\'SegAccuracyParameter\',\n  full_name=\'caffe.SegAccuracyParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'metric\', full_name=\'caffe.SegAccuracyParameter.metric\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.SegAccuracyParameter.ignore_label\', index=1,\n      number=2, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reset\', full_name=\'caffe.SegAccuracyParameter.reset\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SEGACCURACYPARAMETER_ACCURACYMETRIC,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12121,\n  serialized_end=12331,\n)\n\n\n_SIGMOIDPARAMETER = _descriptor.Descriptor(\n  name=\'SigmoidParameter\',\n  full_name=\'caffe.SigmoidParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SigmoidParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SIGMOIDPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12333,\n  serialized_end=12453,\n)\n\n\n_SLICEPARAMETER = _descriptor.Descriptor(\n  name=\'SliceParameter\',\n  full_name=\'caffe.SliceParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SliceParameter.axis\', index=0,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_point\', full_name=\'caffe.SliceParameter.slice_point\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_dim\', full_name=\'caffe.SliceParameter.slice_dim\', index=2,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12455,\n  serialized_end=12531,\n)\n\n\n_SOFTMAXPARAMETER = _descriptor.Descriptor(\n  name=\'SoftmaxParameter\',\n  full_name=\'caffe.SoftmaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SoftmaxParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SoftmaxParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOFTMAXPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12534,\n  serialized_end=12671,\n)\n\n\n_TANHPARAMETER = _descriptor.Descriptor(\n  name=\'TanHParameter\',\n  full_name=\'caffe.TanHParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.TanHParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TANHPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12673,\n  serialized_end=12787,\n)\n\n\n_TILEPARAMETER = _descriptor.Descriptor(\n  name=\'TileParameter\',\n  full_name=\'caffe.TileParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.TileParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tiles\', full_name=\'caffe.TileParameter.tiles\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12789,\n  serialized_end=12836,\n)\n\n\n_THRESHOLDPARAMETER = _descriptor.Descriptor(\n  name=\'ThresholdParameter\',\n  full_name=\'caffe.ThresholdParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'threshold\', full_name=\'caffe.ThresholdParameter.threshold\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12838,\n  serialized_end=12880,\n)\n\n\n_UNIQUELABELPARAMETER = _descriptor.Descriptor(\n  name=\'UniqueLabelParameter\',\n  full_name=\'caffe.UniqueLabelParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'max_labels\', full_name=\'caffe.UniqueLabelParameter.max_labels\', index=0,\n      number=1, type=5, cpp_type=1, label=2,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.UniqueLabelParameter.ignore_label\', index=1,\n      number=2, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_label\', full_name=\'caffe.UniqueLabelParameter.force_label\', index=2,\n      number=3, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12882,\n  serialized_end=12967,\n)\n\n\n_WINDOWDATAPARAMETER = _descriptor.Descriptor(\n  name=\'WindowDataParameter\',\n  full_name=\'caffe.WindowDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.WindowDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.WindowDataParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.WindowDataParameter.mean_file\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.WindowDataParameter.batch_size\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.WindowDataParameter.crop_size\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.WindowDataParameter.mirror\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_threshold\', full_name=\'caffe.WindowDataParameter.fg_threshold\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bg_threshold\', full_name=\'caffe.WindowDataParameter.bg_threshold\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_fraction\', full_name=\'caffe.WindowDataParameter.fg_fraction\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.25),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'context_pad\', full_name=\'caffe.WindowDataParameter.context_pad\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_mode\', full_name=\'caffe.WindowDataParameter.crop_mode\', index=10,\n      number=11, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""warp"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cache_images\', full_name=\'caffe.WindowDataParameter.cache_images\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.WindowDataParameter.root_folder\', index=12,\n      number=13, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=12970,\n  serialized_end=13291,\n)\n\n\n_SPPPARAMETER = _descriptor.Descriptor(\n  name=\'SPPParameter\',\n  full_name=\'caffe.SPPParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pyramid_height\', full_name=\'caffe.SPPParameter.pyramid_height\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.SPPParameter.pool\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SPPParameter.engine\', index=2,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SPPPARAMETER_POOLMETHOD,\n    _SPPPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13294,\n  serialized_end=13529,\n)\n\n\n_V1LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V1LayerParameter\',\n  full_name=\'caffe.V1LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.V1LayerParameter.bottom\', index=0,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.V1LayerParameter.top\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V1LayerParameter.name\', index=2,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.V1LayerParameter.include\', index=3,\n      number=32, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.V1LayerParameter.exclude\', index=4,\n      number=33, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V1LayerParameter.type\', index=5,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V1LayerParameter.blobs\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.V1LayerParameter.param\', index=7,\n      number=1001, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blob_share_mode\', full_name=\'caffe.V1LayerParameter.blob_share_mode\', index=8,\n      number=1002, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V1LayerParameter.blobs_lr\', index=9,\n      number=7, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V1LayerParameter.weight_decay\', index=10,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.V1LayerParameter.loss_weight\', index=11,\n      number=35, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.V1LayerParameter.accuracy_param\', index=12,\n      number=27, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.V1LayerParameter.argmax_param\', index=13,\n      number=23, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.V1LayerParameter.concat_param\', index=14,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.V1LayerParameter.contrastive_loss_param\', index=15,\n      number=40, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.V1LayerParameter.convolution_param\', index=16,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.V1LayerParameter.data_param\', index=17,\n      number=11, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.V1LayerParameter.dropout_param\', index=18,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.V1LayerParameter.dummy_data_param\', index=19,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.V1LayerParameter.eltwise_param\', index=20,\n      number=24, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.V1LayerParameter.exp_param\', index=21,\n      number=41, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.V1LayerParameter.hdf5_data_param\', index=22,\n      number=13, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V1LayerParameter.hdf5_output_param\', index=23,\n      number=14, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.V1LayerParameter.hinge_loss_param\', index=24,\n      number=29, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.V1LayerParameter.image_data_param\', index=25,\n      number=15, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.V1LayerParameter.infogain_loss_param\', index=26,\n      number=16, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.V1LayerParameter.inner_product_param\', index=27,\n      number=17, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.V1LayerParameter.lrn_param\', index=28,\n      number=18, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.V1LayerParameter.memory_data_param\', index=29,\n      number=22, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.V1LayerParameter.mvn_param\', index=30,\n      number=34, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.V1LayerParameter.pooling_param\', index=31,\n      number=19, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.V1LayerParameter.power_param\', index=32,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.V1LayerParameter.relu_param\', index=33,\n      number=30, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.V1LayerParameter.sigmoid_param\', index=34,\n      number=38, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.V1LayerParameter.softmax_param\', index=35,\n      number=39, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.V1LayerParameter.slice_param\', index=36,\n      number=31, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.V1LayerParameter.tanh_param\', index=37,\n      number=37, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.V1LayerParameter.threshold_param\', index=38,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.V1LayerParameter.window_data_param\', index=39,\n      number=20, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.V1LayerParameter.transform_param\', index=40,\n      number=36, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.V1LayerParameter.loss_param\', index=41,\n      number=42, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.V1LayerParameter.layer\', index=42,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V1LAYERPARAMETER_LAYERTYPE,\n    _V1LAYERPARAMETER_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=13532,\n  serialized_end=16060,\n)\n\n\n_V0LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V0LayerParameter\',\n  full_name=\'caffe.V0LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V0LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V0LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.V0LayerParameter.num_output\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'biasterm\', full_name=\'caffe.V0LayerParameter.biasterm\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.V0LayerParameter.weight_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.V0LayerParameter.bias_filler\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.V0LayerParameter.pad\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernelsize\', full_name=\'caffe.V0LayerParameter.kernelsize\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.V0LayerParameter.group\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.V0LayerParameter.stride\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.V0LayerParameter.pool\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.V0LayerParameter.dropout_ratio\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.V0LayerParameter.local_size\', index=12,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.V0LayerParameter.alpha\', index=13,\n      number=14, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.V0LayerParameter.beta\', index=14,\n      number=15, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.75),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.V0LayerParameter.k\', index=15,\n      number=22, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.V0LayerParameter.source\', index=16,\n      number=16, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.V0LayerParameter.scale\', index=17,\n      number=17, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'meanfile\', full_name=\'caffe.V0LayerParameter.meanfile\', index=18,\n      number=18, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batchsize\', full_name=\'caffe.V0LayerParameter.batchsize\', index=19,\n      number=19, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cropsize\', full_name=\'caffe.V0LayerParameter.cropsize\', index=20,\n      number=20, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.V0LayerParameter.mirror\', index=21,\n      number=21, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V0LayerParameter.blobs\', index=22,\n      number=50, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V0LayerParameter.blobs_lr\', index=23,\n      number=51, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V0LayerParameter.weight_decay\', index=24,\n      number=52, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.V0LayerParameter.rand_skip\', index=25,\n      number=53, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_threshold\', full_name=\'caffe.V0LayerParameter.det_fg_threshold\', index=26,\n      number=54, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_bg_threshold\', full_name=\'caffe.V0LayerParameter.det_bg_threshold\', index=27,\n      number=55, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_fraction\', full_name=\'caffe.V0LayerParameter.det_fg_fraction\', index=28,\n      number=56, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.25),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_context_pad\', full_name=\'caffe.V0LayerParameter.det_context_pad\', index=29,\n      number=58, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_crop_mode\', full_name=\'caffe.V0LayerParameter.det_crop_mode\', index=30,\n      number=59, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""warp"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_num\', full_name=\'caffe.V0LayerParameter.new_num\', index=31,\n      number=60, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_channels\', full_name=\'caffe.V0LayerParameter.new_channels\', index=32,\n      number=61, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.V0LayerParameter.new_height\', index=33,\n      number=62, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.V0LayerParameter.new_width\', index=34,\n      number=63, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle_images\', full_name=\'caffe.V0LayerParameter.shuffle_images\', index=35,\n      number=64, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.V0LayerParameter.concat_dim\', index=36,\n      number=65, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V0LayerParameter.hdf5_output_param\', index=37,\n      number=1001, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V0LAYERPARAMETER_POOLMETHOD,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=16063,\n  serialized_end=17084,\n)\n\n\n_PRELUPARAMETER = _descriptor.Descriptor(\n  name=\'PReLUParameter\',\n  full_name=\'caffe.PReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.PReLUParameter.filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channel_shared\', full_name=\'caffe.PReLUParameter.channel_shared\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=17086,\n  serialized_end=17173,\n)\n\n_BLOBPROTO.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_BLOBPROTOVECTOR.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_FILLERPARAMETER.fields_by_name[\'variance_norm\'].enum_type = _FILLERPARAMETER_VARIANCENORM\n_FILLERPARAMETER_VARIANCENORM.containing_type = _FILLERPARAMETER\n_NETPARAMETER.fields_by_name[\'input_shape\'].message_type = _BLOBSHAPE\n_NETPARAMETER.fields_by_name[\'state\'].message_type = _NETSTATE\n_NETPARAMETER.fields_by_name[\'layer\'].message_type = _LAYERPARAMETER\n_NETPARAMETER.fields_by_name[\'layers\'].message_type = _V1LAYERPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'test_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'test_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'snapshot_format\'].enum_type = _SOLVERPARAMETER_SNAPSHOTFORMAT\n_SOLVERPARAMETER.fields_by_name[\'solver_mode\'].enum_type = _SOLVERPARAMETER_SOLVERMODE\n_SOLVERPARAMETER.fields_by_name[\'solver_type\'].enum_type = _SOLVERPARAMETER_SOLVERTYPE\n_SOLVERPARAMETER_SNAPSHOTFORMAT.containing_type = _SOLVERPARAMETER\n_SOLVERPARAMETER_SOLVERMODE.containing_type = _SOLVERPARAMETER\n_SOLVERPARAMETER_SOLVERTYPE.containing_type = _SOLVERPARAMETER\n_SOLVERSTATE.fields_by_name[\'history\'].message_type = _BLOBPROTO\n_NETSTATE.fields_by_name[\'phase\'].enum_type = _PHASE\n_NETSTATERULE.fields_by_name[\'phase\'].enum_type = _PHASE\n_PARAMSPEC.fields_by_name[\'share_mode\'].enum_type = _PARAMSPEC_DIMCHECKMODE\n_PARAMSPEC_DIMCHECKMODE.containing_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'phase\'].enum_type = _PHASE\n_LAYERPARAMETER.fields_by_name[\'param\'].message_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_LAYERPARAMETER.fields_by_name[\'adaptive_bias_channel_param\'].message_type = _ADAPTIVEBIASCHANNELPARAMETER\n_LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'batch_norm_param\'].message_type = _BATCHNORMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bn_param\'].message_type = _BNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bias_param\'].message_type = _BIASPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bias_channel_param\'].message_type = _BIASCHANNELPARAMETER\n_LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dense_crf_param\'].message_type = _DENSECRFPARAMETER\n_LAYERPARAMETER.fields_by_name[\'domain_transform_param\'].message_type = _DOMAINTRANSFORMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'elu_param\'].message_type = _ELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'embed_param\'].message_type = _EMBEDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'flatten_param\'].message_type = _FLATTENPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'interp_param\'].message_type = _INTERPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'log_param\'].message_type = _LOGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mat_read_param\'].message_type = _MATREADPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mat_write_param\'].message_type = _MATWRITEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'prelu_param\'].message_type = _PRELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'python_param\'].message_type = _PYTHONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reduction_param\'].message_type = _REDUCTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reshape_param\'].message_type = _RESHAPEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'scale_param\'].message_type = _SCALEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'seg_accuracy_param\'].message_type = _SEGACCURACYPARAMETER\n_LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'spp_param\'].message_type = _SPPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tile_param\'].message_type = _TILEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'unique_label_param\'].message_type = _UNIQUELABELPARAMETER\n_LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_LOSSPARAMETER.fields_by_name[\'normalization\'].enum_type = _LOSSPARAMETER_NORMALIZATIONMODE\n_LOSSPARAMETER_NORMALIZATIONMODE.containing_type = _LOSSPARAMETER\n_BIASCHANNELPARAMETER.fields_by_name[\'label_type\'].enum_type = _BIASCHANNELPARAMETER_LABELTYPE\n_BIASCHANNELPARAMETER_LABELTYPE.containing_type = _BIASCHANNELPARAMETER\n_BNPARAMETER.fields_by_name[\'slope_filler\'].message_type = _FILLERPARAMETER\n_BNPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_BNPARAMETER.fields_by_name[\'engine\'].enum_type = _BNPARAMETER_ENGINE\n_BNPARAMETER_ENGINE.containing_type = _BNPARAMETER\n_BIASPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'engine\'].enum_type = _CONVOLUTIONPARAMETER_ENGINE\n_CONVOLUTIONPARAMETER_ENGINE.containing_type = _CONVOLUTIONPARAMETER\n_DATAPARAMETER.fields_by_name[\'backend\'].enum_type = _DATAPARAMETER_DB\n_DATAPARAMETER_DB.containing_type = _DATAPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'data_filler\'].message_type = _FILLERPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_ELTWISEPARAMETER.fields_by_name[\'operation\'].enum_type = _ELTWISEPARAMETER_ELTWISEOP\n_ELTWISEPARAMETER_ELTWISEOP.containing_type = _ELTWISEPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_HINGELOSSPARAMETER.fields_by_name[\'norm\'].enum_type = _HINGELOSSPARAMETER_NORM\n_HINGELOSSPARAMETER_NORM.containing_type = _HINGELOSSPARAMETER\n_IMAGEDATAPARAMETER.fields_by_name[\'label_type\'].enum_type = _IMAGEDATAPARAMETER_LABELTYPE\n_IMAGEDATAPARAMETER_LABELTYPE.containing_type = _IMAGEDATAPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_LRNPARAMETER.fields_by_name[\'norm_region\'].enum_type = _LRNPARAMETER_NORMREGION\n_LRNPARAMETER.fields_by_name[\'engine\'].enum_type = _LRNPARAMETER_ENGINE\n_LRNPARAMETER_NORMREGION.containing_type = _LRNPARAMETER\n_LRNPARAMETER_ENGINE.containing_type = _LRNPARAMETER\n_POOLINGPARAMETER.fields_by_name[\'pool\'].enum_type = _POOLINGPARAMETER_POOLMETHOD\n_POOLINGPARAMETER.fields_by_name[\'engine\'].enum_type = _POOLINGPARAMETER_ENGINE\n_POOLINGPARAMETER_POOLMETHOD.containing_type = _POOLINGPARAMETER\n_POOLINGPARAMETER_ENGINE.containing_type = _POOLINGPARAMETER\n_REDUCTIONPARAMETER.fields_by_name[\'operation\'].enum_type = _REDUCTIONPARAMETER_REDUCTIONOP\n_REDUCTIONPARAMETER_REDUCTIONOP.containing_type = _REDUCTIONPARAMETER\n_RELUPARAMETER.fields_by_name[\'engine\'].enum_type = _RELUPARAMETER_ENGINE\n_RELUPARAMETER_ENGINE.containing_type = _RELUPARAMETER\n_RESHAPEPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_SCALEPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_SCALEPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_SEGACCURACYPARAMETER.fields_by_name[\'metric\'].enum_type = _SEGACCURACYPARAMETER_ACCURACYMETRIC\n_SEGACCURACYPARAMETER_ACCURACYMETRIC.containing_type = _SEGACCURACYPARAMETER\n_SIGMOIDPARAMETER.fields_by_name[\'engine\'].enum_type = _SIGMOIDPARAMETER_ENGINE\n_SIGMOIDPARAMETER_ENGINE.containing_type = _SIGMOIDPARAMETER\n_SOFTMAXPARAMETER.fields_by_name[\'engine\'].enum_type = _SOFTMAXPARAMETER_ENGINE\n_SOFTMAXPARAMETER_ENGINE.containing_type = _SOFTMAXPARAMETER\n_TANHPARAMETER.fields_by_name[\'engine\'].enum_type = _TANHPARAMETER_ENGINE\n_TANHPARAMETER_ENGINE.containing_type = _TANHPARAMETER\n_SPPPARAMETER.fields_by_name[\'pool\'].enum_type = _SPPPARAMETER_POOLMETHOD\n_SPPPARAMETER.fields_by_name[\'engine\'].enum_type = _SPPPARAMETER_ENGINE\n_SPPPARAMETER_POOLMETHOD.containing_type = _SPPPARAMETER\n_SPPPARAMETER_ENGINE.containing_type = _SPPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'type\'].enum_type = _V1LAYERPARAMETER_LAYERTYPE\n_V1LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V1LAYERPARAMETER.fields_by_name[\'blob_share_mode\'].enum_type = _V1LAYERPARAMETER_DIMCHECKMODE\n_V1LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'layer\'].message_type = _V0LAYERPARAMETER\n_V1LAYERPARAMETER_LAYERTYPE.containing_type = _V1LAYERPARAMETER\n_V1LAYERPARAMETER_DIMCHECKMODE.containing_type = _V1LAYERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'pool\'].enum_type = _V0LAYERPARAMETER_POOLMETHOD\n_V0LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V0LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V0LAYERPARAMETER_POOLMETHOD.containing_type = _V0LAYERPARAMETER\n_PRELUPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'BlobShape\'] = _BLOBSHAPE\nDESCRIPTOR.message_types_by_name[\'BlobProto\'] = _BLOBPROTO\nDESCRIPTOR.message_types_by_name[\'BlobProtoVector\'] = _BLOBPROTOVECTOR\nDESCRIPTOR.message_types_by_name[\'Datum\'] = _DATUM\nDESCRIPTOR.message_types_by_name[\'FillerParameter\'] = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'NetParameter\'] = _NETPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverParameter\'] = _SOLVERPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverState\'] = _SOLVERSTATE\nDESCRIPTOR.message_types_by_name[\'NetState\'] = _NETSTATE\nDESCRIPTOR.message_types_by_name[\'NetStateRule\'] = _NETSTATERULE\nDESCRIPTOR.message_types_by_name[\'ParamSpec\'] = _PARAMSPEC\nDESCRIPTOR.message_types_by_name[\'LayerParameter\'] = _LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'TransformationParameter\'] = _TRANSFORMATIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'LossParameter\'] = _LOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'AccuracyParameter\'] = _ACCURACYPARAMETER\nDESCRIPTOR.message_types_by_name[\'AdaptiveBiasChannelParameter\'] = _ADAPTIVEBIASCHANNELPARAMETER\nDESCRIPTOR.message_types_by_name[\'ArgMaxParameter\'] = _ARGMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'BiasChannelParameter\'] = _BIASCHANNELPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConcatParameter\'] = _CONCATPARAMETER\nDESCRIPTOR.message_types_by_name[\'BatchNormParameter\'] = _BATCHNORMPARAMETER\nDESCRIPTOR.message_types_by_name[\'BNParameter\'] = _BNPARAMETER\nDESCRIPTOR.message_types_by_name[\'BiasParameter\'] = _BIASPARAMETER\nDESCRIPTOR.message_types_by_name[\'ContrastiveLossParameter\'] = _CONTRASTIVELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConvolutionParameter\'] = _CONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'DataParameter\'] = _DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'DenseCRFParameter\'] = _DENSECRFPARAMETER\nDESCRIPTOR.message_types_by_name[\'DomainTransformParameter\'] = _DOMAINTRANSFORMPARAMETER\nDESCRIPTOR.message_types_by_name[\'DropoutParameter\'] = _DROPOUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DummyDataParameter\'] = _DUMMYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'EltwiseParameter\'] = _ELTWISEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ELUParameter\'] = _ELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'EmbedParameter\'] = _EMBEDPARAMETER\nDESCRIPTOR.message_types_by_name[\'ExpParameter\'] = _EXPPARAMETER\nDESCRIPTOR.message_types_by_name[\'FlattenParameter\'] = _FLATTENPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5DataParameter\'] = _HDF5DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5OutputParameter\'] = _HDF5OUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'HingeLossParameter\'] = _HINGELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ImageDataParameter\'] = _IMAGEDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'InfogainLossParameter\'] = _INFOGAINLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'InnerProductParameter\'] = _INNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'InterpParameter\'] = _INTERPPARAMETER\nDESCRIPTOR.message_types_by_name[\'LogParameter\'] = _LOGPARAMETER\nDESCRIPTOR.message_types_by_name[\'LRNParameter\'] = _LRNPARAMETER\nDESCRIPTOR.message_types_by_name[\'MatReadParameter\'] = _MATREADPARAMETER\nDESCRIPTOR.message_types_by_name[\'MatWriteParameter\'] = _MATWRITEPARAMETER\nDESCRIPTOR.message_types_by_name[\'MemoryDataParameter\'] = _MEMORYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'MVNParameter\'] = _MVNPARAMETER\nDESCRIPTOR.message_types_by_name[\'PoolingParameter\'] = _POOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'PowerParameter\'] = _POWERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PythonParameter\'] = _PYTHONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReductionParameter\'] = _REDUCTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReLUParameter\'] = _RELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReshapeParameter\'] = _RESHAPEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ScaleParameter\'] = _SCALEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SegAccuracyParameter\'] = _SEGACCURACYPARAMETER\nDESCRIPTOR.message_types_by_name[\'SigmoidParameter\'] = _SIGMOIDPARAMETER\nDESCRIPTOR.message_types_by_name[\'SliceParameter\'] = _SLICEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SoftmaxParameter\'] = _SOFTMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'TanHParameter\'] = _TANHPARAMETER\nDESCRIPTOR.message_types_by_name[\'TileParameter\'] = _TILEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ThresholdParameter\'] = _THRESHOLDPARAMETER\nDESCRIPTOR.message_types_by_name[\'UniqueLabelParameter\'] = _UNIQUELABELPARAMETER\nDESCRIPTOR.message_types_by_name[\'WindowDataParameter\'] = _WINDOWDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'SPPParameter\'] = _SPPPARAMETER\nDESCRIPTOR.message_types_by_name[\'V1LayerParameter\'] = _V1LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'V0LayerParameter\'] = _V0LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PReLUParameter\'] = _PRELUPARAMETER\nDESCRIPTOR.enum_types_by_name[\'Phase\'] = _PHASE\n\nBlobShape = _reflection.GeneratedProtocolMessageType(\'BlobShape\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBSHAPE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobShape)\n  ))\n_sym_db.RegisterMessage(BlobShape)\n\nBlobProto = _reflection.GeneratedProtocolMessageType(\'BlobProto\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBPROTO,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobProto)\n  ))\n_sym_db.RegisterMessage(BlobProto)\n\nBlobProtoVector = _reflection.GeneratedProtocolMessageType(\'BlobProtoVector\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBPROTOVECTOR,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobProtoVector)\n  ))\n_sym_db.RegisterMessage(BlobProtoVector)\n\nDatum = _reflection.GeneratedProtocolMessageType(\'Datum\', (_message.Message,), dict(\n  DESCRIPTOR = _DATUM,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.Datum)\n  ))\n_sym_db.RegisterMessage(Datum)\n\nFillerParameter = _reflection.GeneratedProtocolMessageType(\'FillerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _FILLERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.FillerParameter)\n  ))\n_sym_db.RegisterMessage(FillerParameter)\n\nNetParameter = _reflection.GeneratedProtocolMessageType(\'NetParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _NETPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetParameter)\n  ))\n_sym_db.RegisterMessage(NetParameter)\n\nSolverParameter = _reflection.GeneratedProtocolMessageType(\'SolverParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SOLVERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SolverParameter)\n  ))\n_sym_db.RegisterMessage(SolverParameter)\n\nSolverState = _reflection.GeneratedProtocolMessageType(\'SolverState\', (_message.Message,), dict(\n  DESCRIPTOR = _SOLVERSTATE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SolverState)\n  ))\n_sym_db.RegisterMessage(SolverState)\n\nNetState = _reflection.GeneratedProtocolMessageType(\'NetState\', (_message.Message,), dict(\n  DESCRIPTOR = _NETSTATE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetState)\n  ))\n_sym_db.RegisterMessage(NetState)\n\nNetStateRule = _reflection.GeneratedProtocolMessageType(\'NetStateRule\', (_message.Message,), dict(\n  DESCRIPTOR = _NETSTATERULE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetStateRule)\n  ))\n_sym_db.RegisterMessage(NetStateRule)\n\nParamSpec = _reflection.GeneratedProtocolMessageType(\'ParamSpec\', (_message.Message,), dict(\n  DESCRIPTOR = _PARAMSPEC,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ParamSpec)\n  ))\n_sym_db.RegisterMessage(ParamSpec)\n\nLayerParameter = _reflection.GeneratedProtocolMessageType(\'LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LayerParameter)\n  ))\n_sym_db.RegisterMessage(LayerParameter)\n\nTransformationParameter = _reflection.GeneratedProtocolMessageType(\'TransformationParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TRANSFORMATIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TransformationParameter)\n  ))\n_sym_db.RegisterMessage(TransformationParameter)\n\nLossParameter = _reflection.GeneratedProtocolMessageType(\'LossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LossParameter)\n  ))\n_sym_db.RegisterMessage(LossParameter)\n\nAccuracyParameter = _reflection.GeneratedProtocolMessageType(\'AccuracyParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ACCURACYPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AccuracyParameter)\n  ))\n_sym_db.RegisterMessage(AccuracyParameter)\n\nAdaptiveBiasChannelParameter = _reflection.GeneratedProtocolMessageType(\'AdaptiveBiasChannelParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ADAPTIVEBIASCHANNELPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AdaptiveBiasChannelParameter)\n  ))\n_sym_db.RegisterMessage(AdaptiveBiasChannelParameter)\n\nArgMaxParameter = _reflection.GeneratedProtocolMessageType(\'ArgMaxParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ARGMAXPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ArgMaxParameter)\n  ))\n_sym_db.RegisterMessage(ArgMaxParameter)\n\nBiasChannelParameter = _reflection.GeneratedProtocolMessageType(\'BiasChannelParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BIASCHANNELPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BiasChannelParameter)\n  ))\n_sym_db.RegisterMessage(BiasChannelParameter)\n\nConcatParameter = _reflection.GeneratedProtocolMessageType(\'ConcatParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONCATPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ConcatParameter)\n  ))\n_sym_db.RegisterMessage(ConcatParameter)\n\nBatchNormParameter = _reflection.GeneratedProtocolMessageType(\'BatchNormParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BATCHNORMPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BatchNormParameter)\n  ))\n_sym_db.RegisterMessage(BatchNormParameter)\n\nBNParameter = _reflection.GeneratedProtocolMessageType(\'BNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BNParameter)\n  ))\n_sym_db.RegisterMessage(BNParameter)\n\nBiasParameter = _reflection.GeneratedProtocolMessageType(\'BiasParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BIASPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BiasParameter)\n  ))\n_sym_db.RegisterMessage(BiasParameter)\n\nContrastiveLossParameter = _reflection.GeneratedProtocolMessageType(\'ContrastiveLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONTRASTIVELOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ContrastiveLossParameter)\n  ))\n_sym_db.RegisterMessage(ContrastiveLossParameter)\n\nConvolutionParameter = _reflection.GeneratedProtocolMessageType(\'ConvolutionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONVOLUTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ConvolutionParameter)\n  ))\n_sym_db.RegisterMessage(ConvolutionParameter)\n\nDataParameter = _reflection.GeneratedProtocolMessageType(\'DataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DataParameter)\n  ))\n_sym_db.RegisterMessage(DataParameter)\n\nDenseCRFParameter = _reflection.GeneratedProtocolMessageType(\'DenseCRFParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DENSECRFPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DenseCRFParameter)\n  ))\n_sym_db.RegisterMessage(DenseCRFParameter)\n\nDomainTransformParameter = _reflection.GeneratedProtocolMessageType(\'DomainTransformParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DOMAINTRANSFORMPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DomainTransformParameter)\n  ))\n_sym_db.RegisterMessage(DomainTransformParameter)\n\nDropoutParameter = _reflection.GeneratedProtocolMessageType(\'DropoutParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DROPOUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DropoutParameter)\n  ))\n_sym_db.RegisterMessage(DropoutParameter)\n\nDummyDataParameter = _reflection.GeneratedProtocolMessageType(\'DummyDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DUMMYDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DummyDataParameter)\n  ))\n_sym_db.RegisterMessage(DummyDataParameter)\n\nEltwiseParameter = _reflection.GeneratedProtocolMessageType(\'EltwiseParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ELTWISEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.EltwiseParameter)\n  ))\n_sym_db.RegisterMessage(EltwiseParameter)\n\nELUParameter = _reflection.GeneratedProtocolMessageType(\'ELUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ELUParameter)\n  ))\n_sym_db.RegisterMessage(ELUParameter)\n\nEmbedParameter = _reflection.GeneratedProtocolMessageType(\'EmbedParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _EMBEDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.EmbedParameter)\n  ))\n_sym_db.RegisterMessage(EmbedParameter)\n\nExpParameter = _reflection.GeneratedProtocolMessageType(\'ExpParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _EXPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ExpParameter)\n  ))\n_sym_db.RegisterMessage(ExpParameter)\n\nFlattenParameter = _reflection.GeneratedProtocolMessageType(\'FlattenParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _FLATTENPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.FlattenParameter)\n  ))\n_sym_db.RegisterMessage(FlattenParameter)\n\nHDF5DataParameter = _reflection.GeneratedProtocolMessageType(\'HDF5DataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HDF5DATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HDF5DataParameter)\n  ))\n_sym_db.RegisterMessage(HDF5DataParameter)\n\nHDF5OutputParameter = _reflection.GeneratedProtocolMessageType(\'HDF5OutputParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HDF5OUTPUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HDF5OutputParameter)\n  ))\n_sym_db.RegisterMessage(HDF5OutputParameter)\n\nHingeLossParameter = _reflection.GeneratedProtocolMessageType(\'HingeLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HINGELOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HingeLossParameter)\n  ))\n_sym_db.RegisterMessage(HingeLossParameter)\n\nImageDataParameter = _reflection.GeneratedProtocolMessageType(\'ImageDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _IMAGEDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ImageDataParameter)\n  ))\n_sym_db.RegisterMessage(ImageDataParameter)\n\nInfogainLossParameter = _reflection.GeneratedProtocolMessageType(\'InfogainLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INFOGAINLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InfogainLossParameter)\n  ))\n_sym_db.RegisterMessage(InfogainLossParameter)\n\nInnerProductParameter = _reflection.GeneratedProtocolMessageType(\'InnerProductParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INNERPRODUCTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InnerProductParameter)\n  ))\n_sym_db.RegisterMessage(InnerProductParameter)\n\nInterpParameter = _reflection.GeneratedProtocolMessageType(\'InterpParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INTERPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InterpParameter)\n  ))\n_sym_db.RegisterMessage(InterpParameter)\n\nLogParameter = _reflection.GeneratedProtocolMessageType(\'LogParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LOGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LogParameter)\n  ))\n_sym_db.RegisterMessage(LogParameter)\n\nLRNParameter = _reflection.GeneratedProtocolMessageType(\'LRNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LRNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LRNParameter)\n  ))\n_sym_db.RegisterMessage(LRNParameter)\n\nMatReadParameter = _reflection.GeneratedProtocolMessageType(\'MatReadParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MATREADPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MatReadParameter)\n  ))\n_sym_db.RegisterMessage(MatReadParameter)\n\nMatWriteParameter = _reflection.GeneratedProtocolMessageType(\'MatWriteParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MATWRITEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MatWriteParameter)\n  ))\n_sym_db.RegisterMessage(MatWriteParameter)\n\nMemoryDataParameter = _reflection.GeneratedProtocolMessageType(\'MemoryDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MEMORYDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MemoryDataParameter)\n  ))\n_sym_db.RegisterMessage(MemoryDataParameter)\n\nMVNParameter = _reflection.GeneratedProtocolMessageType(\'MVNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MVNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MVNParameter)\n  ))\n_sym_db.RegisterMessage(MVNParameter)\n\nPoolingParameter = _reflection.GeneratedProtocolMessageType(\'PoolingParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _POOLINGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PoolingParameter)\n  ))\n_sym_db.RegisterMessage(PoolingParameter)\n\nPowerParameter = _reflection.GeneratedProtocolMessageType(\'PowerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _POWERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PowerParameter)\n  ))\n_sym_db.RegisterMessage(PowerParameter)\n\nPythonParameter = _reflection.GeneratedProtocolMessageType(\'PythonParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PYTHONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PythonParameter)\n  ))\n_sym_db.RegisterMessage(PythonParameter)\n\nReductionParameter = _reflection.GeneratedProtocolMessageType(\'ReductionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _REDUCTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReductionParameter)\n  ))\n_sym_db.RegisterMessage(ReductionParameter)\n\nReLUParameter = _reflection.GeneratedProtocolMessageType(\'ReLUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReLUParameter)\n  ))\n_sym_db.RegisterMessage(ReLUParameter)\n\nReshapeParameter = _reflection.GeneratedProtocolMessageType(\'ReshapeParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RESHAPEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReshapeParameter)\n  ))\n_sym_db.RegisterMessage(ReshapeParameter)\n\nScaleParameter = _reflection.GeneratedProtocolMessageType(\'ScaleParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SCALEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ScaleParameter)\n  ))\n_sym_db.RegisterMessage(ScaleParameter)\n\nSegAccuracyParameter = _reflection.GeneratedProtocolMessageType(\'SegAccuracyParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SEGACCURACYPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SegAccuracyParameter)\n  ))\n_sym_db.RegisterMessage(SegAccuracyParameter)\n\nSigmoidParameter = _reflection.GeneratedProtocolMessageType(\'SigmoidParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SIGMOIDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SigmoidParameter)\n  ))\n_sym_db.RegisterMessage(SigmoidParameter)\n\nSliceParameter = _reflection.GeneratedProtocolMessageType(\'SliceParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SLICEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SliceParameter)\n  ))\n_sym_db.RegisterMessage(SliceParameter)\n\nSoftmaxParameter = _reflection.GeneratedProtocolMessageType(\'SoftmaxParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SOFTMAXPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SoftmaxParameter)\n  ))\n_sym_db.RegisterMessage(SoftmaxParameter)\n\nTanHParameter = _reflection.GeneratedProtocolMessageType(\'TanHParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TANHPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TanHParameter)\n  ))\n_sym_db.RegisterMessage(TanHParameter)\n\nTileParameter = _reflection.GeneratedProtocolMessageType(\'TileParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TILEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TileParameter)\n  ))\n_sym_db.RegisterMessage(TileParameter)\n\nThresholdParameter = _reflection.GeneratedProtocolMessageType(\'ThresholdParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _THRESHOLDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ThresholdParameter)\n  ))\n_sym_db.RegisterMessage(ThresholdParameter)\n\nUniqueLabelParameter = _reflection.GeneratedProtocolMessageType(\'UniqueLabelParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _UNIQUELABELPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.UniqueLabelParameter)\n  ))\n_sym_db.RegisterMessage(UniqueLabelParameter)\n\nWindowDataParameter = _reflection.GeneratedProtocolMessageType(\'WindowDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _WINDOWDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.WindowDataParameter)\n  ))\n_sym_db.RegisterMessage(WindowDataParameter)\n\nSPPParameter = _reflection.GeneratedProtocolMessageType(\'SPPParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SPPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SPPParameter)\n  ))\n_sym_db.RegisterMessage(SPPParameter)\n\nV1LayerParameter = _reflection.GeneratedProtocolMessageType(\'V1LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _V1LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.V1LayerParameter)\n  ))\n_sym_db.RegisterMessage(V1LayerParameter)\n\nV0LayerParameter = _reflection.GeneratedProtocolMessageType(\'V0LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _V0LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.V0LayerParameter)\n  ))\n_sym_db.RegisterMessage(V0LayerParameter)\n\nPReLUParameter = _reflection.GeneratedProtocolMessageType(\'PReLUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PRELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PReLUParameter)\n  ))\n_sym_db.RegisterMessage(PReLUParameter)\n\n\n_BLOBSHAPE.fields_by_name[\'dim\'].has_options = True\n_BLOBSHAPE.fields_by_name[\'dim\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_BLOBPROTO.fields_by_name[\'data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_BLOBPROTO.fields_by_name[\'diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_BLOBPROTO.fields_by_name[\'double_data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_BLOBPROTO.fields_by_name[\'double_diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n# @@protoc_insertion_point(module_scope)\n'"
ptsemseg/metrics.py,0,"b'# Adapted from score written by wkentaro\n# https://github.com/wkentaro/pytorch-fcn/blob/master/torchfcn/utils.py\n\nimport numpy as np\n\n\nclass runningScore(object):\n    def __init__(self, n_classes):\n        self.n_classes = n_classes\n        self.confusion_matrix = np.zeros((n_classes, n_classes))\n\n    def _fast_hist(self, label_true, label_pred, n_class):\n        mask = (label_true >= 0) & (label_true < n_class)\n        hist = np.bincount(\n            n_class * label_true[mask].astype(int) + label_pred[mask], minlength=n_class ** 2\n        ).reshape(n_class, n_class)\n        return hist\n\n    def update(self, label_trues, label_preds):\n        for lt, lp in zip(label_trues, label_preds):\n            self.confusion_matrix += self._fast_hist(lt.flatten(), lp.flatten(), self.n_classes)\n\n    def get_scores(self):\n        """"""Returns accuracy score evaluation result.\n            - overall accuracy\n            - mean accuracy\n            - mean IU\n            - fwavacc\n        """"""\n        hist = self.confusion_matrix\n        acc = np.diag(hist).sum() / hist.sum()\n        acc_cls = np.diag(hist) / hist.sum(axis=1)\n        acc_cls = np.nanmean(acc_cls)\n        iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n        mean_iu = np.nanmean(iu)\n        freq = hist.sum(axis=1) / hist.sum()\n        fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n        cls_iu = dict(zip(range(self.n_classes), iu))\n\n        return (\n            {\n                ""Overall Acc: \\t"": acc,\n                ""Mean Acc : \\t"": acc_cls,\n                ""FreqW Acc : \\t"": fwavacc,\n                ""Mean IoU : \\t"": mean_iu,\n            },\n            cls_iu,\n        )\n\n    def reset(self):\n        self.confusion_matrix = np.zeros((self.n_classes, self.n_classes))\n\n\nclass averageMeter(object):\n    """"""Computes and stores the average and current value""""""\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n'"
ptsemseg/utils.py,0,"b'""""""\nMisc Utility functions\n""""""\nimport os\nimport logging\nimport datetime\nimport numpy as np\n\nfrom collections import OrderedDict\n\n\ndef recursive_glob(rootdir=""."", suffix=""""):\n    """"""Performs recursive glob with given suffix and rootdir\n        :param rootdir is the root directory\n        :param suffix is the suffix to be searched\n    """"""\n    return [\n        os.path.join(looproot, filename)\n        for looproot, _, filenames in os.walk(rootdir)\n        for filename in filenames\n        if filename.endswith(suffix)\n    ]\n\n\ndef alpha_blend(input_image, segmentation_mask, alpha=0.5):\n    """"""Alpha Blending utility to overlay RGB masks on RBG images\n        :param input_image is a np.ndarray with 3 channels\n        :param segmentation_mask is a np.ndarray with 3 channels\n        :param alpha is a float value\n    """"""\n    blended = np.zeros(input_image.size, dtype=np.float32)\n    blended = input_image * alpha + segmentation_mask * (1 - alpha)\n    return blended\n\n\ndef convert_state_dict(state_dict):\n    """"""Converts a state dict saved from a dataParallel module to normal\n       module state_dict inplace\n       :param state_dict is the loaded DataParallel model_state\n    """"""\n    if not next(iter(state_dict)).startswith(""module.""):\n        return state_dict  # abort if dict is not a DataParallel model_state\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k[7:]  # remove `module.`\n        new_state_dict[name] = v\n    return new_state_dict\n\n\ndef get_logger(logdir):\n    logger = logging.getLogger(""ptsemseg"")\n    ts = str(datetime.datetime.now()).split(""."")[0].replace("" "", ""_"")\n    ts = ts.replace("":"", ""_"").replace(""-"", ""_"")\n    file_path = os.path.join(logdir, ""run_{}.log"".format(ts))\n    hdlr = logging.FileHandler(file_path)\n    formatter = logging.Formatter(""%(asctime)s %(levelname)s %(message)s"")\n    hdlr.setFormatter(formatter)\n    logger.addHandler(hdlr)\n    logger.setLevel(logging.INFO)\n    return logger\n'"
ptsemseg/augmentations/__init__.py,0,"b'import logging\nfrom ptsemseg.augmentations.augmentations import (\n    AdjustContrast,\n    AdjustGamma,\n    AdjustBrightness,\n    AdjustSaturation,\n    AdjustHue,\n    RandomCrop,\n    RandomHorizontallyFlip,\n    RandomVerticallyFlip,\n    Scale,\n    RandomSized,\n    RandomSizedCrop,\n    RandomRotate,\n    RandomTranslate,\n    CenterCrop,\n    Compose,\n)\n\nlogger = logging.getLogger(""ptsemseg"")\n\nkey2aug = {\n    ""gamma"": AdjustGamma,\n    ""hue"": AdjustHue,\n    ""brightness"": AdjustBrightness,\n    ""saturation"": AdjustSaturation,\n    ""contrast"": AdjustContrast,\n    ""rcrop"": RandomCrop,\n    ""hflip"": RandomHorizontallyFlip,\n    ""vflip"": RandomVerticallyFlip,\n    ""scale"": Scale,\n    ""rsize"": RandomSized,\n    ""rsizecrop"": RandomSizedCrop,\n    ""rotate"": RandomRotate,\n    ""translate"": RandomTranslate,\n    ""ccrop"": CenterCrop,\n}\n\n\ndef get_composed_augmentations(aug_dict):\n    if aug_dict is None:\n        logger.info(""Using No Augmentations"")\n        return None\n\n    augmentations = []\n    for aug_key, aug_param in aug_dict.items():\n        augmentations.append(key2aug[aug_key](aug_param))\n        logger.info(""Using {} aug with params {}"".format(aug_key, aug_param))\n    return Compose(augmentations)\n'"
ptsemseg/augmentations/augmentations.py,0,"b'import math\nimport numbers\nimport random\nimport numpy as np\nimport torchvision.transforms.functional as tf\n\nfrom PIL import Image, ImageOps\n\n\nclass Compose(object):\n    def __init__(self, augmentations):\n        self.augmentations = augmentations\n        self.PIL2Numpy = False\n\n    def __call__(self, img, mask):\n        if isinstance(img, np.ndarray):\n            img = Image.fromarray(img, mode=""RGB"")\n            mask = Image.fromarray(mask, mode=""L"")\n            self.PIL2Numpy = True\n\n        assert img.size == mask.size\n        for a in self.augmentations:\n            img, mask = a(img, mask)\n\n        if self.PIL2Numpy:\n            img, mask = np.array(img), np.array(mask, dtype=np.uint8)\n\n        return img, mask\n\n\nclass RandomCrop(object):\n    def __init__(self, size, padding=0):\n        if isinstance(size, numbers.Number):\n            self.size = (int(size), int(size))\n        else:\n            self.size = size\n        self.padding = padding\n\n    def __call__(self, img, mask):\n        if self.padding > 0:\n            img = ImageOps.expand(img, border=self.padding, fill=0)\n            mask = ImageOps.expand(mask, border=self.padding, fill=0)\n\n        assert img.size == mask.size\n        w, h = img.size\n        th, tw = self.size\n        if w == tw and h == th:\n            return img, mask\n        if w < tw or h < th:\n            return (img.resize((tw, th), Image.BILINEAR), mask.resize((tw, th), Image.NEAREST))\n\n        x1 = random.randint(0, w - tw)\n        y1 = random.randint(0, h - th)\n        return (img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th)))\n\n\nclass AdjustGamma(object):\n    def __init__(self, gamma):\n        self.gamma = gamma\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        return tf.adjust_gamma(img, random.uniform(1, 1 + self.gamma)), mask\n\n\nclass AdjustSaturation(object):\n    def __init__(self, saturation):\n        self.saturation = saturation\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        return (\n            tf.adjust_saturation(img, random.uniform(1 - self.saturation, 1 + self.saturation)),\n            mask,\n        )\n\n\nclass AdjustHue(object):\n    def __init__(self, hue):\n        self.hue = hue\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        return tf.adjust_hue(img, random.uniform(-self.hue, self.hue)), mask\n\n\nclass AdjustBrightness(object):\n    def __init__(self, bf):\n        self.bf = bf\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        return tf.adjust_brightness(img, random.uniform(1 - self.bf, 1 + self.bf)), mask\n\n\nclass AdjustContrast(object):\n    def __init__(self, cf):\n        self.cf = cf\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        return tf.adjust_contrast(img, random.uniform(1 - self.cf, 1 + self.cf)), mask\n\n\nclass CenterCrop(object):\n    def __init__(self, size):\n        if isinstance(size, numbers.Number):\n            self.size = (int(size), int(size))\n        else:\n            self.size = size\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        w, h = img.size\n        th, tw = self.size\n        x1 = int(round((w - tw) / 2.0))\n        y1 = int(round((h - th) / 2.0))\n        return (img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th)))\n\n\nclass RandomHorizontallyFlip(object):\n    def __init__(self, p):\n        self.p = p\n\n    def __call__(self, img, mask):\n        if random.random() < self.p:\n            return (img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT))\n        return img, mask\n\n\nclass RandomVerticallyFlip(object):\n    def __init__(self, p):\n        self.p = p\n\n    def __call__(self, img, mask):\n        if random.random() < self.p:\n            return (img.transpose(Image.FLIP_TOP_BOTTOM), mask.transpose(Image.FLIP_TOP_BOTTOM))\n        return img, mask\n\n\nclass FreeScale(object):\n    def __init__(self, size):\n        self.size = tuple(reversed(size))  # size: (h, w)\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        return (img.resize(self.size, Image.BILINEAR), mask.resize(self.size, Image.NEAREST))\n\n\nclass RandomTranslate(object):\n    def __init__(self, offset):\n        # tuple (delta_x, delta_y)\n        self.offset = offset\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        x_offset = int(2 * (random.random() - 0.5) * self.offset[0])\n        y_offset = int(2 * (random.random() - 0.5) * self.offset[1])\n\n        x_crop_offset = x_offset\n        y_crop_offset = y_offset\n        if x_offset < 0:\n            x_crop_offset = 0\n        if y_offset < 0:\n            y_crop_offset = 0\n\n        cropped_img = tf.crop(\n            img,\n            y_crop_offset,\n            x_crop_offset,\n            img.size[1] - abs(y_offset),\n            img.size[0] - abs(x_offset),\n        )\n\n        if x_offset >= 0 and y_offset >= 0:\n            padding_tuple = (0, 0, x_offset, y_offset)\n\n        elif x_offset >= 0 and y_offset < 0:\n            padding_tuple = (0, abs(y_offset), x_offset, 0)\n\n        elif x_offset < 0 and y_offset >= 0:\n            padding_tuple = (abs(x_offset), 0, 0, y_offset)\n\n        elif x_offset < 0 and y_offset < 0:\n            padding_tuple = (abs(x_offset), abs(y_offset), 0, 0)\n\n        return (\n            tf.pad(cropped_img, padding_tuple, padding_mode=""reflect""),\n            tf.affine(\n                mask,\n                translate=(-x_offset, -y_offset),\n                scale=1.0,\n                angle=0.0,\n                shear=0.0,\n                fillcolor=250,\n            ),\n        )\n\n\nclass RandomRotate(object):\n    def __init__(self, degree):\n        self.degree = degree\n\n    def __call__(self, img, mask):\n        rotate_degree = random.random() * 2 * self.degree - self.degree\n        return (\n            tf.affine(\n                img,\n                translate=(0, 0),\n                scale=1.0,\n                angle=rotate_degree,\n                resample=Image.BILINEAR,\n                fillcolor=(0, 0, 0),\n                shear=0.0,\n            ),\n            tf.affine(\n                mask,\n                translate=(0, 0),\n                scale=1.0,\n                angle=rotate_degree,\n                resample=Image.NEAREST,\n                fillcolor=250,\n                shear=0.0,\n            ),\n        )\n\n\nclass Scale(object):\n    def __init__(self, size):\n        self.size = size\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        w, h = img.size\n        if (w >= h and w == self.size) or (h >= w and h == self.size):\n            return img, mask\n        if w > h:\n            ow = self.size\n            oh = int(self.size * h / w)\n            return (img.resize((ow, oh), Image.BILINEAR), mask.resize((ow, oh), Image.NEAREST))\n        else:\n            oh = self.size\n            ow = int(self.size * w / h)\n            return (img.resize((ow, oh), Image.BILINEAR), mask.resize((ow, oh), Image.NEAREST))\n\n\nclass RandomSizedCrop(object):\n    def __init__(self, size):\n        self.size = size\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n        for attempt in range(10):\n            area = img.size[0] * img.size[1]\n            target_area = random.uniform(0.45, 1.0) * area\n            aspect_ratio = random.uniform(0.5, 2)\n\n            w = int(round(math.sqrt(target_area * aspect_ratio)))\n            h = int(round(math.sqrt(target_area / aspect_ratio)))\n\n            if random.random() < 0.5:\n                w, h = h, w\n\n            if w <= img.size[0] and h <= img.size[1]:\n                x1 = random.randint(0, img.size[0] - w)\n                y1 = random.randint(0, img.size[1] - h)\n\n                img = img.crop((x1, y1, x1 + w, y1 + h))\n                mask = mask.crop((x1, y1, x1 + w, y1 + h))\n                assert img.size == (w, h)\n\n                return (\n                    img.resize((self.size, self.size), Image.BILINEAR),\n                    mask.resize((self.size, self.size), Image.NEAREST),\n                )\n\n        # Fallback\n        scale = Scale(self.size)\n        crop = CenterCrop(self.size)\n        return crop(*scale(img, mask))\n\n\nclass RandomSized(object):\n    def __init__(self, size):\n        self.size = size\n        self.scale = Scale(self.size)\n        self.crop = RandomCrop(self.size)\n\n    def __call__(self, img, mask):\n        assert img.size == mask.size\n\n        w = int(random.uniform(0.5, 2) * img.size[0])\n        h = int(random.uniform(0.5, 2) * img.size[1])\n\n        img, mask = (img.resize((w, h), Image.BILINEAR), mask.resize((w, h), Image.NEAREST))\n\n        return self.crop(*self.scale(img, mask))\n'"
ptsemseg/loader/__init__.py,0,"b'import json\n\nfrom ptsemseg.loader.pascal_voc_loader import pascalVOCLoader\nfrom ptsemseg.loader.camvid_loader import camvidLoader\nfrom ptsemseg.loader.ade20k_loader import ADE20KLoader\nfrom ptsemseg.loader.mit_sceneparsing_benchmark_loader import MITSceneParsingBenchmarkLoader\nfrom ptsemseg.loader.cityscapes_loader import cityscapesLoader\nfrom ptsemseg.loader.nyuv2_loader import NYUv2Loader\nfrom ptsemseg.loader.sunrgbd_loader import SUNRGBDLoader\nfrom ptsemseg.loader.mapillary_vistas_loader import mapillaryVistasLoader\n\n\ndef get_loader(name):\n    """"""get_loader\n\n    :param name:\n    """"""\n    return {\n        ""pascal"": pascalVOCLoader,\n        ""camvid"": camvidLoader,\n        ""ade20k"": ADE20KLoader,\n        ""mit_sceneparsing_benchmark"": MITSceneParsingBenchmarkLoader,\n        ""cityscapes"": cityscapesLoader,\n        ""nyuv2"": NYUv2Loader,\n        ""sunrgbd"": SUNRGBDLoader,\n        ""vistas"": mapillaryVistasLoader,\n    }[name]\n'"
ptsemseg/loader/ade20k_loader.py,3,"b'import collections\nimport torch\nimport torchvision\nimport numpy as np\nimport scipy.misc as m\nimport matplotlib.pyplot as plt\n\nfrom torch.utils import data\n\nfrom ptsemseg.utils import recursive_glob\n\n\nclass ADE20KLoader(data.Dataset):\n    def __init__(\n        self,\n        root,\n        split=""training"",\n        is_transform=False,\n        img_size=512,\n        augmentations=None,\n        img_norm=True,\n        test_mode=False,\n    ):\n        self.root = root\n        self.split = split\n        self.is_transform = is_transform\n        self.augmentations = augmentations\n        self.img_norm = img_norm\n        self.test_mode = test_mode\n        self.n_classes = 150\n        self.img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n        self.mean = np.array([104.00699, 116.66877, 122.67892])\n        self.files = collections.defaultdict(list)\n\n        if not self.test_mode:\n            for split in [""training"", ""validation""]:\n                file_list = recursive_glob(\n                    rootdir=self.root + ""images/"" + self.split + ""/"", suffix="".jpg""\n                )\n                self.files[split] = file_list\n\n    def __len__(self):\n        return len(self.files[self.split])\n\n    def __getitem__(self, index):\n        img_path = self.files[self.split][index].rstrip()\n        lbl_path = img_path[:-4] + ""_seg.png""\n\n        img = m.imread(img_path)\n        img = np.array(img, dtype=np.uint8)\n\n        lbl = m.imread(lbl_path)\n        lbl = np.array(lbl, dtype=np.int32)\n\n        if self.augmentations is not None:\n            img, lbl = self.augmentations(img, lbl)\n\n        if self.is_transform:\n            img, lbl = self.transform(img, lbl)\n\n        return img, lbl\n\n    def transform(self, img, lbl):\n        img = m.imresize(img, (self.img_size[0], self.img_size[1]))  # uint8 with RGB mode\n        img = img[:, :, ::-1]  # RGB -> BGR\n        img = img.astype(np.float64)\n        img -= self.mean\n        if self.img_norm:\n            # Resize scales images from 0 to 255, thus we need\n            # to divide by 255.0\n            img = img.astype(float) / 255.0\n        # NHWC -> NCHW\n        img = img.transpose(2, 0, 1)\n\n        lbl = self.encode_segmap(lbl)\n        classes = np.unique(lbl)\n        lbl = lbl.astype(float)\n        lbl = m.imresize(lbl, (self.img_size[0], self.img_size[1]), ""nearest"", mode=""F"")\n        lbl = lbl.astype(int)\n        assert np.all(classes == np.unique(lbl))\n\n        img = torch.from_numpy(img).float()\n        lbl = torch.from_numpy(lbl).long()\n        return img, lbl\n\n    def encode_segmap(self, mask):\n        # Refer : http://groups.csail.mit.edu/vision/datasets/ADE20K/code/loadAde20K.m\n        mask = mask.astype(int)\n        label_mask = np.zeros((mask.shape[0], mask.shape[1]))\n        label_mask = (mask[:, :, 0] / 10.0) * 256 + mask[:, :, 1]\n        return np.array(label_mask, dtype=np.uint8)\n\n    def decode_segmap(self, temp, plot=False):\n        # TODO:(@meetshah1995)\n        # Verify that the color mapping is 1-to-1\n        r = temp.copy()\n        g = temp.copy()\n        b = temp.copy()\n        for l in range(0, self.n_classes):\n            r[temp == l] = 10 * (l % 10)\n            g[temp == l] = l\n            b[temp == l] = 0\n\n        rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n        rgb[:, :, 0] = r / 255.0\n        rgb[:, :, 1] = g / 255.0\n        rgb[:, :, 2] = b / 255.0\n        if plot:\n            plt.imshow(rgb)\n            plt.show()\n        else:\n            return rgb\n\n\nif __name__ == ""__main__"":\n    local_path = ""/Users/meet/data/ADE20K_2016_07_26/""\n    dst = ADE20KLoader(local_path, is_transform=True)\n    trainloader = data.DataLoader(dst, batch_size=4)\n    for i, data_samples in enumerate(trainloader):\n        imgs, labels = data_samples\n        if i == 0:\n            img = torchvision.utils.make_grid(imgs).numpy()\n            img = np.transpose(img, (1, 2, 0))\n            img = img[:, :, ::-1]\n            plt.imshow(img)\n            plt.show()\n            for j in range(4):\n                plt.imshow(dst.decode_segmap(labels.numpy()[j]))\n                plt.show()\n'"
ptsemseg/loader/camvid_loader.py,3,"b'import os\nimport collections\nimport torch\nimport numpy as np\nimport scipy.misc as m\nimport matplotlib.pyplot as plt\n\nfrom torch.utils import data\nfrom ptsemseg.augmentations import Compose, RandomHorizontallyFlip, RandomRotate\n\n\nclass camvidLoader(data.Dataset):\n    def __init__(\n        self,\n        root,\n        split=""train"",\n        is_transform=False,\n        img_size=None,\n        augmentations=None,\n        img_norm=True,\n        test_mode=False,\n    ):\n        self.root = root\n        self.split = split\n        self.img_size = [360, 480]\n        self.is_transform = is_transform\n        self.augmentations = augmentations\n        self.img_norm = img_norm\n        self.test_mode = test_mode\n        self.mean = np.array([104.00699, 116.66877, 122.67892])\n        self.n_classes = 12\n        self.files = collections.defaultdict(list)\n\n        if not self.test_mode:\n            for split in [""train"", ""test"", ""val""]:\n                file_list = os.listdir(root + ""/"" + split)\n                self.files[split] = file_list\n\n    def __len__(self):\n        return len(self.files[self.split])\n\n    def __getitem__(self, index):\n        img_name = self.files[self.split][index]\n        img_path = self.root + ""/"" + self.split + ""/"" + img_name\n        lbl_path = self.root + ""/"" + self.split + ""annot/"" + img_name\n\n        img = m.imread(img_path)\n        img = np.array(img, dtype=np.uint8)\n\n        lbl = m.imread(lbl_path)\n        lbl = np.array(lbl, dtype=np.int8)\n\n        if self.augmentations is not None:\n            img, lbl = self.augmentations(img, lbl)\n\n        if self.is_transform:\n            img, lbl = self.transform(img, lbl)\n\n        return img, lbl\n\n    def transform(self, img, lbl):\n        img = m.imresize(img, (self.img_size[0], self.img_size[1]))  # uint8 with RGB mode\n        img = img[:, :, ::-1]  # RGB -> BGR\n        img = img.astype(np.float64)\n        img -= self.mean\n        if self.img_norm:\n            # Resize scales images from 0 to 255, thus we need\n            # to divide by 255.0\n            img = img.astype(float) / 255.0\n        # NHWC -> NCHW\n        img = img.transpose(2, 0, 1)\n\n        img = torch.from_numpy(img).float()\n        lbl = torch.from_numpy(lbl).long()\n        return img, lbl\n\n    def decode_segmap(self, temp, plot=False):\n        Sky = [128, 128, 128]\n        Building = [128, 0, 0]\n        Pole = [192, 192, 128]\n        Road = [128, 64, 128]\n        Pavement = [60, 40, 222]\n        Tree = [128, 128, 0]\n        SignSymbol = [192, 128, 128]\n        Fence = [64, 64, 128]\n        Car = [64, 0, 128]\n        Pedestrian = [64, 64, 0]\n        Bicyclist = [0, 128, 192]\n        Unlabelled = [0, 0, 0]\n\n        label_colours = np.array(\n            [\n                Sky,\n                Building,\n                Pole,\n                Road,\n                Pavement,\n                Tree,\n                SignSymbol,\n                Fence,\n                Car,\n                Pedestrian,\n                Bicyclist,\n                Unlabelled,\n            ]\n        )\n        r = temp.copy()\n        g = temp.copy()\n        b = temp.copy()\n        for l in range(0, self.n_classes):\n            r[temp == l] = label_colours[l, 0]\n            g[temp == l] = label_colours[l, 1]\n            b[temp == l] = label_colours[l, 2]\n\n        rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n        rgb[:, :, 0] = r / 255.0\n        rgb[:, :, 1] = g / 255.0\n        rgb[:, :, 2] = b / 255.0\n        return rgb\n\n\nif __name__ == ""__main__"":\n    local_path = ""/home/meetshah1995/datasets/segnet/CamVid""\n    augmentations = Compose([RandomRotate(10), RandomHorizontallyFlip()])\n\n    dst = camvidLoader(local_path, is_transform=True, augmentations=augmentations)\n    bs = 4\n    trainloader = data.DataLoader(dst, batch_size=bs)\n    for i, data_samples in enumerate(trainloader):\n        imgs, labels = data_samples\n        imgs = imgs.numpy()[:, ::-1, :, :]\n        imgs = np.transpose(imgs, [0, 2, 3, 1])\n        f, axarr = plt.subplots(bs, 2)\n        for j in range(bs):\n            axarr[j][0].imshow(imgs[j])\n            axarr[j][1].imshow(dst.decode_segmap(labels.numpy()[j]))\n        plt.show()\n        a = input()\n        if a == ""ex"":\n            break\n        else:\n            plt.close()\n'"
ptsemseg/loader/cityscapes_loader.py,3,"b'import os\nimport torch\nimport numpy as np\nimport scipy.misc as m\n\nfrom torch.utils import data\n\nfrom ptsemseg.utils import recursive_glob\nfrom ptsemseg.augmentations import Compose, RandomHorizontallyFlip, RandomRotate, Scale\n\n\nclass cityscapesLoader(data.Dataset):\n    """"""cityscapesLoader\n\n    https://www.cityscapes-dataset.com\n\n    Data is derived from CityScapes, and can be downloaded from here:\n    https://www.cityscapes-dataset.com/downloads/\n\n    Many Thanks to @fvisin for the loader repo:\n    https://github.com/fvisin/dataset_loaders/blob/master/dataset_loaders/images/cityscapes.py\n    """"""\n\n    colors = [  # [  0,   0,   0],\n        [128, 64, 128],\n        [244, 35, 232],\n        [70, 70, 70],\n        [102, 102, 156],\n        [190, 153, 153],\n        [153, 153, 153],\n        [250, 170, 30],\n        [220, 220, 0],\n        [107, 142, 35],\n        [152, 251, 152],\n        [0, 130, 180],\n        [220, 20, 60],\n        [255, 0, 0],\n        [0, 0, 142],\n        [0, 0, 70],\n        [0, 60, 100],\n        [0, 80, 100],\n        [0, 0, 230],\n        [119, 11, 32],\n    ]\n\n    label_colours = dict(zip(range(19), colors))\n\n    mean_rgb = {\n        ""pascal"": [103.939, 116.779, 123.68],\n        ""cityscapes"": [0.0, 0.0, 0.0],\n    }  # pascal mean for PSPNet and ICNet pre-trained model\n\n    def __init__(\n        self,\n        root,\n        split=""train"",\n        is_transform=False,\n        img_size=(512, 1024),\n        augmentations=None,\n        img_norm=True,\n        version=""cityscapes"",\n        test_mode=False,\n    ):\n        """"""__init__\n\n        :param root:\n        :param split:\n        :param is_transform:\n        :param img_size:\n        :param augmentations\n        """"""\n        self.root = root\n        self.split = split\n        self.is_transform = is_transform\n        self.augmentations = augmentations\n        self.img_norm = img_norm\n        self.n_classes = 19\n        self.img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n        self.mean = np.array(self.mean_rgb[version])\n        self.files = {}\n\n        self.images_base = os.path.join(self.root, ""leftImg8bit"", self.split)\n        self.annotations_base = os.path.join(self.root, ""gtFine"", self.split)\n\n        self.files[split] = recursive_glob(rootdir=self.images_base, suffix="".png"")\n\n        self.void_classes = [0, 1, 2, 3, 4, 5, 6, 9, 10, 14, 15, 16, 18, 29, 30, -1]\n        self.valid_classes = [\n            7,\n            8,\n            11,\n            12,\n            13,\n            17,\n            19,\n            20,\n            21,\n            22,\n            23,\n            24,\n            25,\n            26,\n            27,\n            28,\n            31,\n            32,\n            33,\n        ]\n        self.class_names = [\n            ""unlabelled"",\n            ""road"",\n            ""sidewalk"",\n            ""building"",\n            ""wall"",\n            ""fence"",\n            ""pole"",\n            ""traffic_light"",\n            ""traffic_sign"",\n            ""vegetation"",\n            ""terrain"",\n            ""sky"",\n            ""person"",\n            ""rider"",\n            ""car"",\n            ""truck"",\n            ""bus"",\n            ""train"",\n            ""motorcycle"",\n            ""bicycle"",\n        ]\n\n        self.ignore_index = 250\n        self.class_map = dict(zip(self.valid_classes, range(19)))\n\n        if not self.files[split]:\n            raise Exception(""No files for split=[%s] found in %s"" % (split, self.images_base))\n\n        print(""Found %d %s images"" % (len(self.files[split]), split))\n\n    def __len__(self):\n        """"""__len__""""""\n        return len(self.files[self.split])\n\n    def __getitem__(self, index):\n        """"""__getitem__\n\n        :param index:\n        """"""\n        img_path = self.files[self.split][index].rstrip()\n        lbl_path = os.path.join(\n            self.annotations_base,\n            img_path.split(os.sep)[-2],\n            os.path.basename(img_path)[:-15] + ""gtFine_labelIds.png"",\n        )\n\n        img = m.imread(img_path)\n        img = np.array(img, dtype=np.uint8)\n\n        lbl = m.imread(lbl_path)\n        lbl = self.encode_segmap(np.array(lbl, dtype=np.uint8))\n\n        if self.augmentations is not None:\n            img, lbl = self.augmentations(img, lbl)\n\n        if self.is_transform:\n            img, lbl = self.transform(img, lbl)\n\n        return img, lbl\n\n    def transform(self, img, lbl):\n        """"""transform\n\n        :param img:\n        :param lbl:\n        """"""\n        img = m.imresize(img, (self.img_size[0], self.img_size[1]))  # uint8 with RGB mode\n        img = img[:, :, ::-1]  # RGB -> BGR\n        img = img.astype(np.float64)\n        img -= self.mean\n        if self.img_norm:\n            # Resize scales images from 0 to 255, thus we need\n            # to divide by 255.0\n            img = img.astype(float) / 255.0\n        # NHWC -> NCHW\n        img = img.transpose(2, 0, 1)\n\n        classes = np.unique(lbl)\n        lbl = lbl.astype(float)\n        lbl = m.imresize(lbl, (self.img_size[0], self.img_size[1]), ""nearest"", mode=""F"")\n        lbl = lbl.astype(int)\n\n        if not np.all(classes == np.unique(lbl)):\n            print(""WARN: resizing labels yielded fewer classes"")\n\n        if not np.all(np.unique(lbl[lbl != self.ignore_index]) < self.n_classes):\n            print(""after det"", classes, np.unique(lbl))\n            raise ValueError(""Segmentation map contained invalid class values"")\n\n        img = torch.from_numpy(img).float()\n        lbl = torch.from_numpy(lbl).long()\n\n        return img, lbl\n\n    def decode_segmap(self, temp):\n        r = temp.copy()\n        g = temp.copy()\n        b = temp.copy()\n        for l in range(0, self.n_classes):\n            r[temp == l] = self.label_colours[l][0]\n            g[temp == l] = self.label_colours[l][1]\n            b[temp == l] = self.label_colours[l][2]\n\n        rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n        rgb[:, :, 0] = r / 255.0\n        rgb[:, :, 1] = g / 255.0\n        rgb[:, :, 2] = b / 255.0\n        return rgb\n\n    def encode_segmap(self, mask):\n        # Put all void classes to zero\n        for _voidc in self.void_classes:\n            mask[mask == _voidc] = self.ignore_index\n        for _validc in self.valid_classes:\n            mask[mask == _validc] = self.class_map[_validc]\n        return mask\n\n\nif __name__ == ""__main__"":\n    import matplotlib.pyplot as plt\n\n    augmentations = Compose([Scale(2048), RandomRotate(10), RandomHorizontallyFlip(0.5)])\n\n    local_path = ""/datasets01/cityscapes/112817/""\n    dst = cityscapesLoader(local_path, is_transform=True, augmentations=augmentations)\n    bs = 4\n    trainloader = data.DataLoader(dst, batch_size=bs, num_workers=0)\n    for i, data_samples in enumerate(trainloader):\n        imgs, labels = data_samples\n        import pdb\n\n        pdb.set_trace()\n        imgs = imgs.numpy()[:, ::-1, :, :]\n        imgs = np.transpose(imgs, [0, 2, 3, 1])\n        f, axarr = plt.subplots(bs, 2)\n        for j in range(bs):\n            axarr[j][0].imshow(imgs[j])\n            axarr[j][1].imshow(dst.decode_segmap(labels.numpy()[j]))\n        plt.show()\n        a = input()\n        if a == ""ex"":\n            break\n        else:\n            plt.close()\n'"
ptsemseg/loader/mapillary_vistas_loader.py,3,"b'import os\nimport json\nimport torch\nimport numpy as np\n\nfrom torch.utils import data\nfrom PIL import Image\n\nfrom ptsemseg.utils import recursive_glob\nfrom ptsemseg.augmentations import Compose, RandomHorizontallyFlip, RandomRotate\n\n\nclass mapillaryVistasLoader(data.Dataset):\n    def __init__(\n        self,\n        root,\n        split=""training"",\n        img_size=(640, 1280),\n        is_transform=True,\n        augmentations=None,\n        test_mode=False,\n    ):\n        self.root = root\n        self.split = split\n        self.is_transform = is_transform\n        self.augmentations = augmentations\n        self.n_classes = 65\n\n        self.img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n        self.mean = np.array([80.5423, 91.3162, 81.4312])\n        self.files = {}\n\n        self.images_base = os.path.join(self.root, self.split, ""images"")\n        self.annotations_base = os.path.join(self.root, self.split, ""labels"")\n\n        self.files[split] = recursive_glob(rootdir=self.images_base, suffix="".jpg"")\n\n        self.class_ids, self.class_names, self.class_colors = self.parse_config()\n\n        self.ignore_id = 250\n\n        if not self.files[split]:\n            raise Exception(""No files for split=[%s] found in %s"" % (split, self.images_base))\n\n        print(""Found %d %s images"" % (len(self.files[split]), split))\n\n    def parse_config(self):\n        with open(os.path.join(self.root, ""config.json"")) as config_file:\n            config = json.load(config_file)\n\n        labels = config[""labels""]\n\n        class_names = []\n        class_ids = []\n        class_colors = []\n        print(""There are {} labels in the config file"".format(len(labels)))\n        for label_id, label in enumerate(labels):\n            class_names.append(label[""readable""])\n            class_ids.append(label_id)\n            class_colors.append(label[""color""])\n\n        return class_names, class_ids, class_colors\n\n    def __len__(self):\n        """"""__len__""""""\n        return len(self.files[self.split])\n\n    def __getitem__(self, index):\n        """"""__getitem__\n        :param index:\n        """"""\n        img_path = self.files[self.split][index].rstrip()\n        lbl_path = os.path.join(\n            self.annotations_base, os.path.basename(img_path).replace("".jpg"", "".png"")\n        )\n\n        img = Image.open(img_path)\n        lbl = Image.open(lbl_path)\n\n        if self.augmentations is not None:\n            img, lbl = self.augmentations(img, lbl)\n\n        if self.is_transform:\n            img, lbl = self.transform(img, lbl)\n\n        return img, lbl\n\n    def transform(self, img, lbl):\n        if self.img_size == (""same"", ""same""):\n            pass\n        else:\n            img = img.resize(\n                (self.img_size[0], self.img_size[1]), resample=Image.LANCZOS\n            )  # uint8 with RGB mode\n            lbl = lbl.resize((self.img_size[0], self.img_size[1]))\n        img = np.array(img).astype(np.float64) / 255.0\n        img = torch.from_numpy(img.transpose(2, 0, 1)).float()  # From HWC to CHW\n        lbl = torch.from_numpy(np.array(lbl)).long()\n        lbl[lbl == 65] = self.ignore_id\n        return img, lbl\n\n    def decode_segmap(self, temp):\n        r = temp.copy()\n        g = temp.copy()\n        b = temp.copy()\n        for l in range(0, self.n_classes):\n            r[temp == l] = self.class_colors[l][0]\n            g[temp == l] = self.class_colors[l][1]\n            b[temp == l] = self.class_colors[l][2]\n\n        rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n        rgb[:, :, 0] = r / 255.0\n        rgb[:, :, 1] = g / 255.0\n        rgb[:, :, 2] = b / 255.0\n        return rgb\n\n\nif __name__ == ""__main__"":\n    augment = Compose([RandomHorizontallyFlip(), RandomRotate(6)])\n\n    local_path = ""/private/home/meetshah/datasets/seg/vistas/""\n    dst = mapillaryVistasLoader(\n        local_path, img_size=(512, 1024), is_transform=True, augmentations=augment\n    )\n    bs = 8\n    trainloader = data.DataLoader(dst, batch_size=bs, num_workers=4, shuffle=True)\n    for i, data_samples in enumerate(trainloader):\n        x = dst.decode_segmap(data_samples[1][0].numpy())\n        print(""batch :"", i)\n'"
ptsemseg/loader/mit_sceneparsing_benchmark_loader.py,3,"b'import os\nimport torch\nimport numpy as np\nimport scipy.misc as m\n\nfrom torch.utils import data\n\nfrom ptsemseg.utils import recursive_glob\n\n\nclass MITSceneParsingBenchmarkLoader(data.Dataset):\n    """"""MITSceneParsingBenchmarkLoader\n\n    http://sceneparsing.csail.mit.edu/\n\n    Data is derived from ADE20k, and can be downloaded from here:\n    http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip\n\n    NOTE: this loader is not designed to work with the original ADE20k dataset;\n    for that you will need the ADE20kLoader\n\n    This class can also be extended to load data for places challenge:\n    https://github.com/CSAILVision/placeschallenge/tree/master/sceneparsing\n\n    """"""\n\n    def __init__(\n        self,\n        root,\n        split=""training"",\n        is_transform=False,\n        img_size=512,\n        augmentations=None,\n        img_norm=True,\n        test_mode=False,\n    ):\n        """"""__init__\n\n        :param root:\n        :param split:\n        :param is_transform:\n        :param img_size:\n        """"""\n        self.root = root\n        self.split = split\n        self.is_transform = is_transform\n        self.augmentations = augmentations\n        self.img_norm = img_norm\n        self.n_classes = 151  # 0 is reserved for ""other""\n        self.img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n        self.mean = np.array([104.00699, 116.66877, 122.67892])\n        self.files = {}\n\n        self.images_base = os.path.join(self.root, ""images"", self.split)\n        self.annotations_base = os.path.join(self.root, ""annotations"", self.split)\n\n        self.files[split] = recursive_glob(rootdir=self.images_base, suffix="".jpg"")\n\n        if not self.files[split]:\n            raise Exception(""No files for split=[%s] found in %s"" % (split, self.images_base))\n\n        print(""Found %d %s images"" % (len(self.files[split]), split))\n\n    def __len__(self):\n        """"""__len__""""""\n        return len(self.files[self.split])\n\n    def __getitem__(self, index):\n        """"""__getitem__\n\n        :param index:\n        """"""\n        img_path = self.files[self.split][index].rstrip()\n        lbl_path = os.path.join(self.annotations_base, os.path.basename(img_path)[:-4] + "".png"")\n\n        img = m.imread(img_path, mode=""RGB"")\n        img = np.array(img, dtype=np.uint8)\n\n        lbl = m.imread(lbl_path)\n        lbl = np.array(lbl, dtype=np.uint8)\n\n        if self.augmentations is not None:\n            img, lbl = self.augmentations(img, lbl)\n\n        if self.is_transform:\n            img, lbl = self.transform(img, lbl)\n\n        return img, lbl\n\n    def transform(self, img, lbl):\n        """"""transform\n\n        :param img:\n        :param lbl:\n        """"""\n        if self.img_size == (""same"", ""same""):\n            pass\n        else:\n            img = m.imresize(img, (self.img_size[0], self.img_size[1]))  # uint8 with RGB mode\n        img = img[:, :, ::-1]  # RGB -> BGR\n        img = img.astype(np.float64)\n        img -= self.mean\n        if self.img_norm:\n            # Resize scales images from 0 to 255, thus we need\n            # to divide by 255.0\n            img = img.astype(float) / 255.0\n        # NHWC -> NCHW\n        img = img.transpose(2, 0, 1)\n\n        classes = np.unique(lbl)\n        lbl = lbl.astype(float)\n        if self.img_size == (""same"", ""same""):\n            pass\n        else:\n            lbl = m.imresize(lbl, (self.img_size[0], self.img_size[1]), ""nearest"", mode=""F"")\n        lbl = lbl.astype(int)\n\n        if not np.all(classes == np.unique(lbl)):\n            print(""WARN: resizing labels yielded fewer classes"")\n\n        if not np.all(np.unique(lbl) < self.n_classes):\n            raise ValueError(""Segmentation map contained invalid class values"")\n\n        img = torch.from_numpy(img).float()\n        lbl = torch.from_numpy(lbl).long()\n\n        return img, lbl\n'"
ptsemseg/loader/nyuv2_loader.py,3,"b'import os\nimport collections\nimport torch\nimport numpy as np\nimport scipy.misc as m\n\nfrom torch.utils import data\n\nfrom ptsemseg.utils import recursive_glob\nfrom ptsemseg.augmentations import Compose, RandomHorizontallyFlip, RandomRotate, Scale\n\n\nclass NYUv2Loader(data.Dataset):\n    """"""\n    NYUv2 loader\n    Download From (only 13 classes):\n    test source: http://www.doc.ic.ac.uk/~ahanda/nyu_test_rgb.tgz\n    train source: http://www.doc.ic.ac.uk/~ahanda/nyu_train_rgb.tgz\n    test_labels source:\n      https://github.com/ankurhanda/nyuv2-meta-data/raw/master/test_labels_13/nyuv2_test_class13.tgz\n    train_labels source:\n      https://github.com/ankurhanda/nyuv2-meta-data/raw/master/train_labels_13/nyuv2_train_class13.tgz\n\n    """"""\n\n    def __init__(\n        self,\n        root,\n        split=""training"",\n        is_transform=False,\n        img_size=(480, 640),\n        augmentations=None,\n        img_norm=True,\n        test_mode=False,\n    ):\n        self.root = root\n        self.is_transform = is_transform\n        self.n_classes = 14\n        self.augmentations = augmentations\n        self.img_norm = img_norm\n        self.test_mode = test_mode\n        self.img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n        self.mean = np.array([104.00699, 116.66877, 122.67892])\n        self.files = collections.defaultdict(list)\n        self.cmap = self.color_map(normalized=False)\n\n        split_map = {""training"": ""train"", ""val"": ""test""}\n        self.split = split_map[split]\n\n        for split in [""train"", ""test""]:\n            file_list = recursive_glob(rootdir=self.root + split + ""/"", suffix=""png"")\n            self.files[split] = file_list\n\n    def __len__(self):\n        return len(self.files[self.split])\n\n    def __getitem__(self, index):\n        img_path = self.files[self.split][index].rstrip()\n        img_number = img_path.split(""_"")[-1][:4]\n        lbl_path = os.path.join(\n            self.root, self.split + ""_annot"", ""new_nyu_class13_"" + img_number + "".png""\n        )\n\n        img = m.imread(img_path)\n        img = np.array(img, dtype=np.uint8)\n\n        lbl = m.imread(lbl_path)\n        lbl = np.array(lbl, dtype=np.uint8)\n\n        if not (len(img.shape) == 3 and len(lbl.shape) == 2):\n            return self.__getitem__(np.random.randint(0, self.__len__()))\n\n        if self.augmentations is not None:\n            img, lbl = self.augmentations(img, lbl)\n\n        if self.is_transform:\n            img, lbl = self.transform(img, lbl)\n\n        return img, lbl\n\n    def transform(self, img, lbl):\n        img = m.imresize(img, (self.img_size[0], self.img_size[1]))  # uint8 with RGB mode\n        img = img[:, :, ::-1]  # RGB -> BGR\n        img = img.astype(np.float64)\n        img -= self.mean\n        if self.img_norm:\n            # Resize scales images from 0 to 255, thus we need\n            # to divide by 255.0\n            img = img.astype(float) / 255.0\n        # NHWC -> NCHW\n        img = img.transpose(2, 0, 1)\n\n        classes = np.unique(lbl)\n        lbl = lbl.astype(float)\n        lbl = m.imresize(lbl, (self.img_size[0], self.img_size[1]), ""nearest"", mode=""F"")\n        lbl = lbl.astype(int)\n        assert np.all(classes == np.unique(lbl))\n\n        img = torch.from_numpy(img).float()\n        lbl = torch.from_numpy(lbl).long()\n        return img, lbl\n\n    def color_map(self, N=256, normalized=False):\n        """"""\n        Return Color Map in PASCAL VOC format\n        """"""\n\n        def bitget(byteval, idx):\n            return (byteval & (1 << idx)) != 0\n\n        dtype = ""float32"" if normalized else ""uint8""\n        cmap = np.zeros((N, 3), dtype=dtype)\n        for i in range(N):\n            r = g = b = 0\n            c = i\n            for j in range(8):\n                r = r | (bitget(c, 0) << 7 - j)\n                g = g | (bitget(c, 1) << 7 - j)\n                b = b | (bitget(c, 2) << 7 - j)\n                c = c >> 3\n\n            cmap[i] = np.array([r, g, b])\n\n        cmap = cmap / 255.0 if normalized else cmap\n        return cmap\n\n    def decode_segmap(self, temp):\n        r = temp.copy()\n        g = temp.copy()\n        b = temp.copy()\n        for l in range(0, self.n_classes):\n            r[temp == l] = self.cmap[l, 0]\n            g[temp == l] = self.cmap[l, 1]\n            b[temp == l] = self.cmap[l, 2]\n\n        rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n        rgb[:, :, 0] = r / 255.0\n        rgb[:, :, 1] = g / 255.0\n        rgb[:, :, 2] = b / 255.0\n        return rgb\n\n\nif __name__ == ""__main__"":\n    import matplotlib.pyplot as plt\n\n    augmentations = Compose([Scale(512), RandomRotate(10), RandomHorizontallyFlip()])\n\n    local_path = ""/home/meet/datasets/NYUv2/""\n    dst = NYUv2Loader(local_path, is_transform=True, augmentations=augmentations)\n    bs = 4\n    trainloader = data.DataLoader(dst, batch_size=bs, num_workers=0)\n    for i, datas in enumerate(trainloader):\n        imgs, labels = datas\n        imgs = imgs.numpy()[:, ::-1, :, :]\n        imgs = np.transpose(imgs, [0, 2, 3, 1])\n        f, axarr = plt.subplots(bs, 2)\n        for j in range(bs):\n            axarr[j][0].imshow(imgs[j])\n            axarr[j][1].imshow(dst.decode_segmap(labels.numpy()[j]))\n        plt.show()\n        a = input()\n        if a == ""ex"":\n            break\n        else:\n            plt.close()\n'"
ptsemseg/loader/pascal_voc_loader.py,2,"b'import os\nfrom os.path import join as pjoin\nimport collections\nimport json\nimport torch\nimport numpy as np\nimport scipy.misc as m\nimport scipy.io as io\nimport matplotlib.pyplot as plt\nimport glob\n\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.utils import data\nfrom torchvision import transforms\n\n\nclass pascalVOCLoader(data.Dataset):\n    """"""Data loader for the Pascal VOC semantic segmentation dataset.\n\n    Annotations from both the original VOC data (which consist of RGB images\n    in which colours map to specific classes) and the SBD (Berkely) dataset\n    (where annotations are stored as .mat files) are converted into a common\n    `label_mask` format.  Under this format, each mask is an (M,N) array of\n    integer values from 0 to 21, where 0 represents the background class.\n\n    The label masks are stored in a new folder, called `pre_encoded`, which\n    is added as a subdirectory of the `SegmentationClass` folder in the\n    original Pascal VOC data layout.\n\n    A total of five data splits are provided for working with the VOC data:\n        train: The original VOC 2012 training data - 1464 images\n        val: The original VOC 2012 validation data - 1449 images\n        trainval: The combination of `train` and `val` - 2913 images\n        train_aug: The unique images present in both the train split and\n                   training images from SBD: - 8829 images (the unique members\n                   of the result of combining lists of length 1464 and 8498)\n        train_aug_val: The original VOC 2012 validation data minus the images\n                   present in `train_aug` (This is done with the same logic as\n                   the validation set used in FCN PAMI paper, but with VOC 2012\n                   rather than VOC 2011) - 904 images\n    """"""\n\n    def __init__(\n        self,\n        root,\n        sbd_path=None,\n        split=""train_aug"",\n        is_transform=False,\n        img_size=512,\n        augmentations=None,\n        img_norm=True,\n        test_mode=False,\n    ):\n        self.root = root\n        self.sbd_path = sbd_path\n        self.split = split\n        self.is_transform = is_transform\n        self.augmentations = augmentations\n        self.img_norm = img_norm\n        self.test_mode = test_mode\n        self.n_classes = 21\n        self.mean = np.array([104.00699, 116.66877, 122.67892])\n        self.files = collections.defaultdict(list)\n        self.img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n\n        if not self.test_mode:\n            for split in [""train"", ""val"", ""trainval""]:\n                path = pjoin(self.root, ""ImageSets/Segmentation"", split + "".txt"")\n                file_list = tuple(open(path, ""r""))\n                file_list = [id_.rstrip() for id_ in file_list]\n                self.files[split] = file_list\n            self.setup_annotations()\n\n        self.tf = transforms.Compose(\n            [\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n            ]\n        )\n\n    def __len__(self):\n        return len(self.files[self.split])\n\n    def __getitem__(self, index):\n        im_name = self.files[self.split][index]\n        im_path = pjoin(self.root, ""JPEGImages"", im_name + "".jpg"")\n        lbl_path = pjoin(self.root, ""SegmentationClass/pre_encoded"", im_name + "".png"")\n        im = Image.open(im_path)\n        lbl = Image.open(lbl_path)\n        if self.augmentations is not None:\n            im, lbl = self.augmentations(im, lbl)\n        if self.is_transform:\n            im, lbl = self.transform(im, lbl)\n        return im, lbl\n\n    def transform(self, img, lbl):\n        if self.img_size == (""same"", ""same""):\n            pass\n        else:\n            img = img.resize((self.img_size[0], self.img_size[1]))  # uint8 with RGB mode\n            lbl = lbl.resize((self.img_size[0], self.img_size[1]))\n        img = self.tf(img)\n        lbl = torch.from_numpy(np.array(lbl)).long()\n        lbl[lbl == 255] = 0\n        return img, lbl\n\n    def get_pascal_labels(self):\n        """"""Load the mapping that associates pascal classes with label colors\n\n        Returns:\n            np.ndarray with dimensions (21, 3)\n        """"""\n        return np.asarray(\n            [\n                [0, 0, 0],\n                [128, 0, 0],\n                [0, 128, 0],\n                [128, 128, 0],\n                [0, 0, 128],\n                [128, 0, 128],\n                [0, 128, 128],\n                [128, 128, 128],\n                [64, 0, 0],\n                [192, 0, 0],\n                [64, 128, 0],\n                [192, 128, 0],\n                [64, 0, 128],\n                [192, 0, 128],\n                [64, 128, 128],\n                [192, 128, 128],\n                [0, 64, 0],\n                [128, 64, 0],\n                [0, 192, 0],\n                [128, 192, 0],\n                [0, 64, 128],\n            ]\n        )\n\n    def encode_segmap(self, mask):\n        """"""Encode segmentation label images as pascal classes\n\n        Args:\n            mask (np.ndarray): raw segmentation label image of dimension\n              (M, N, 3), in which the Pascal classes are encoded as colours.\n\n        Returns:\n            (np.ndarray): class map with dimensions (M,N), where the value at\n            a given location is the integer denoting the class index.\n        """"""\n        mask = mask.astype(int)\n        label_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int16)\n        for ii, label in enumerate(self.get_pascal_labels()):\n            label_mask[np.where(np.all(mask == label, axis=-1))[:2]] = ii\n        label_mask = label_mask.astype(int)\n        return label_mask\n\n    def decode_segmap(self, label_mask, plot=False):\n        """"""Decode segmentation class labels into a color image\n\n        Args:\n            label_mask (np.ndarray): an (M,N) array of integer values denoting\n              the class label at each spatial location.\n            plot (bool, optional): whether to show the resulting color image\n              in a figure.\n\n        Returns:\n            (np.ndarray, optional): the resulting decoded color image.\n        """"""\n        label_colours = self.get_pascal_labels()\n        r = label_mask.copy()\n        g = label_mask.copy()\n        b = label_mask.copy()\n        for ll in range(0, self.n_classes):\n            r[label_mask == ll] = label_colours[ll, 0]\n            g[label_mask == ll] = label_colours[ll, 1]\n            b[label_mask == ll] = label_colours[ll, 2]\n        rgb = np.zeros((label_mask.shape[0], label_mask.shape[1], 3))\n        rgb[:, :, 0] = r / 255.0\n        rgb[:, :, 1] = g / 255.0\n        rgb[:, :, 2] = b / 255.0\n        if plot:\n            plt.imshow(rgb)\n            plt.show()\n        else:\n            return rgb\n\n    def setup_annotations(self):\n        """"""Sets up Berkley annotations by adding image indices to the\n        `train_aug` split and pre-encode all segmentation labels into the\n        common label_mask format (if this has not already been done). This\n        function also defines the `train_aug` and `train_aug_val` data splits\n        according to the description in the class docstring\n        """"""\n        sbd_path = self.sbd_path\n        target_path = pjoin(self.root, ""SegmentationClass/pre_encoded"")\n        if not os.path.exists(target_path):\n            os.makedirs(target_path)\n        path = pjoin(sbd_path, ""dataset/train.txt"")\n        sbd_train_list = tuple(open(path, ""r""))\n        sbd_train_list = [id_.rstrip() for id_ in sbd_train_list]\n        train_aug = self.files[""train""] + sbd_train_list\n\n        # keep unique elements (stable)\n        train_aug = [train_aug[i] for i in sorted(np.unique(train_aug, return_index=True)[1])]\n        self.files[""train_aug""] = train_aug\n        set_diff = set(self.files[""val""]) - set(train_aug)  # remove overlap\n        self.files[""train_aug_val""] = list(set_diff)\n\n        pre_encoded = glob.glob(pjoin(target_path, ""*.png""))\n        expected = np.unique(self.files[""train_aug""] + self.files[""val""]).size\n\n        if len(pre_encoded) != expected:\n            print(""Pre-encoding segmentation masks..."")\n            for ii in tqdm(sbd_train_list):\n                lbl_path = pjoin(sbd_path, ""dataset/cls"", ii + "".mat"")\n                data = io.loadmat(lbl_path)\n                lbl = data[""GTcls""][0][""Segmentation""][0].astype(np.int32)\n                lbl = m.toimage(lbl, high=lbl.max(), low=lbl.min())\n                m.imsave(pjoin(target_path, ii + "".png""), lbl)\n\n            for ii in tqdm(self.files[""trainval""]):\n                fname = ii + "".png""\n                lbl_path = pjoin(self.root, ""SegmentationClass"", fname)\n                lbl = self.encode_segmap(m.imread(lbl_path))\n                lbl = m.toimage(lbl, high=lbl.max(), low=lbl.min())\n                m.imsave(pjoin(target_path, fname), lbl)\n\n        assert expected == 9733, ""unexpected dataset sizes""\n\n\n# Leave code for debugging purposes\n# import ptsemseg.augmentations as aug\n# if __name__ == \'__main__\':\n# # local_path = \'/home/meetshah1995/datasets/VOCdevkit/VOC2012/\'\n# bs = 4\n# augs = aug.Compose([aug.RandomRotate(10), aug.RandomHorizontallyFlip()])\n# dst = pascalVOCLoader(root=local_path, is_transform=True, augmentations=augs)\n# trainloader = data.DataLoader(dst, batch_size=bs)\n# for i, data in enumerate(trainloader):\n# imgs, labels = data\n# imgs = imgs.numpy()[:, ::-1, :, :]\n# imgs = np.transpose(imgs, [0,2,3,1])\n# f, axarr = plt.subplots(bs, 2)\n# for j in range(bs):\n# axarr[j][0].imshow(imgs[j])\n# axarr[j][1].imshow(dst.decode_segmap(labels.numpy()[j]))\n# plt.show()\n# a = raw_input()\n# if a == \'ex\':\n# break\n# else:\n# plt.close()\n'"
ptsemseg/loader/sunrgbd_loader.py,3,"b'import collections\nimport torch\nimport numpy as np\nimport scipy.misc as m\n\nfrom torch.utils import data\n\nfrom ptsemseg.utils import recursive_glob\nfrom ptsemseg.augmentations import Compose, RandomHorizontallyFlip, RandomRotate, Scale\n\n\nclass SUNRGBDLoader(data.Dataset):\n    """"""SUNRGBD loader\n\n    Download From:\n    http://www.doc.ic.ac.uk/~ahanda/SUNRGBD-test_images.tgz\n        test source: http://www.doc.ic.ac.uk/~ahanda/SUNRGBD-test_images.tgz\n        train source: http://www.doc.ic.ac.uk/~ahanda/SUNRGBD-train_images.tgz\n\n        first 5050 in this is test, later 5051 is train\n        test and train labels source:\n        https://github.com/ankurhanda/sunrgbd-meta-data/raw/master/sunrgbd_train_test_labels.tar.gz\n    """"""\n\n    def __init__(\n        self,\n        root,\n        split=""training"",\n        is_transform=False,\n        img_size=(480, 640),\n        augmentations=None,\n        img_norm=True,\n        test_mode=False,\n    ):\n        self.root = root\n        self.is_transform = is_transform\n        self.n_classes = 38\n        self.augmentations = augmentations\n        self.img_norm = img_norm\n        self.test_mode = test_mode\n        self.img_size = img_size if isinstance(img_size, tuple) else (img_size, img_size)\n        self.mean = np.array([104.00699, 116.66877, 122.67892])\n        self.files = collections.defaultdict(list)\n        self.anno_files = collections.defaultdict(list)\n        self.cmap = self.color_map(normalized=False)\n\n        split_map = {""training"": ""train"", ""val"": ""test""}\n        self.split = split_map[split]\n\n        for split in [""train"", ""test""]:\n            file_list = sorted(recursive_glob(rootdir=self.root + split + ""/"", suffix=""jpg""))\n            self.files[split] = file_list\n\n        for split in [""train"", ""test""]:\n            file_list = sorted(\n                recursive_glob(rootdir=self.root + ""annotations/"" + split + ""/"", suffix=""png"")\n            )\n            self.anno_files[split] = file_list\n\n    def __len__(self):\n        return len(self.files[self.split])\n\n    def __getitem__(self, index):\n        img_path = self.files[self.split][index].rstrip()\n        lbl_path = self.anno_files[self.split][index].rstrip()\n        # img_number = img_path.split(\'/\')[-1]\n        # lbl_path = os.path.join(self.root, \'annotations\', img_number).replace(\'jpg\', \'png\')\n\n        img = m.imread(img_path)\n        img = np.array(img, dtype=np.uint8)\n\n        lbl = m.imread(lbl_path)\n        lbl = np.array(lbl, dtype=np.uint8)\n\n        if not (len(img.shape) == 3 and len(lbl.shape) == 2):\n            return self.__getitem__(np.random.randint(0, self.__len__()))\n\n        if self.augmentations is not None:\n            img, lbl = self.augmentations(img, lbl)\n\n        if self.is_transform:\n            img, lbl = self.transform(img, lbl)\n\n        return img, lbl\n\n    def transform(self, img, lbl):\n        img = m.imresize(img, (self.img_size[0], self.img_size[1]))  # uint8 with RGB mode\n        img = img[:, :, ::-1]  # RGB -> BGR\n        img = img.astype(np.float64)\n        img -= self.mean\n        if self.img_norm:\n            # Resize scales images from 0 to 255, thus we need\n            # to divide by 255.0\n            img = img.astype(float) / 255.0\n        # NHWC -> NCHW\n        img = img.transpose(2, 0, 1)\n\n        classes = np.unique(lbl)\n        lbl = lbl.astype(float)\n        lbl = m.imresize(lbl, (self.img_size[0], self.img_size[1]), ""nearest"", mode=""F"")\n        lbl = lbl.astype(int)\n        assert np.all(classes == np.unique(lbl))\n\n        img = torch.from_numpy(img).float()\n        lbl = torch.from_numpy(lbl).long()\n        return img, lbl\n\n    def color_map(self, N=256, normalized=False):\n        """"""\n        Return Color Map in PASCAL VOC format\n        """"""\n\n        def bitget(byteval, idx):\n            return (byteval & (1 << idx)) != 0\n\n        dtype = ""float32"" if normalized else ""uint8""\n        cmap = np.zeros((N, 3), dtype=dtype)\n        for i in range(N):\n            r = g = b = 0\n            c = i\n            for j in range(8):\n                r = r | (bitget(c, 0) << 7 - j)\n                g = g | (bitget(c, 1) << 7 - j)\n                b = b | (bitget(c, 2) << 7 - j)\n                c = c >> 3\n\n            cmap[i] = np.array([r, g, b])\n\n        cmap = cmap / 255.0 if normalized else cmap\n        return cmap\n\n    def decode_segmap(self, temp):\n        r = temp.copy()\n        g = temp.copy()\n        b = temp.copy()\n        for l in range(0, self.n_classes):\n            r[temp == l] = self.cmap[l, 0]\n            g[temp == l] = self.cmap[l, 1]\n            b[temp == l] = self.cmap[l, 2]\n\n        rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n        rgb[:, :, 0] = r / 255.0\n        rgb[:, :, 1] = g / 255.0\n        rgb[:, :, 2] = b / 255.0\n        return rgb\n\n\nif __name__ == ""__main__"":\n    import matplotlib.pyplot as plt\n\n    augmentations = Compose([Scale(512), RandomRotate(10), RandomHorizontallyFlip()])\n\n    local_path = ""/home/meet/datasets/SUNRGBD/""\n    dst = SUNRGBDLoader(local_path, is_transform=True, augmentations=augmentations)\n    bs = 4\n    trainloader = data.DataLoader(dst, batch_size=bs, num_workers=0)\n    for i, data_samples in enumerate(trainloader):\n        imgs, labels = data_samples\n        imgs = imgs.numpy()[:, ::-1, :, :]\n        imgs = np.transpose(imgs, [0, 2, 3, 1])\n        f, axarr = plt.subplots(bs, 2)\n        for j in range(bs):\n            axarr[j][0].imshow(imgs[j])\n            axarr[j][1].imshow(dst.decode_segmap(labels.numpy()[j]))\n        plt.show()\n        a = input()\n        if a == ""ex"":\n            break\n        else:\n            plt.close()\n'"
ptsemseg/loss/__init__.py,0,"b'import logging\nimport functools\n\nfrom ptsemseg.loss.loss import (\n    cross_entropy2d,\n    bootstrapped_cross_entropy2d,\n    multi_scale_cross_entropy2d,\n)\n\n\nlogger = logging.getLogger(""ptsemseg"")\n\nkey2loss = {\n    ""cross_entropy"": cross_entropy2d,\n    ""bootstrapped_cross_entropy"": bootstrapped_cross_entropy2d,\n    ""multi_scale_cross_entropy"": multi_scale_cross_entropy2d,\n}\n\n\ndef get_loss_function(cfg):\n    if cfg[""training""][""loss""] is None:\n        logger.info(""Using default cross entropy loss"")\n        return cross_entropy2d\n\n    else:\n        loss_dict = cfg[""training""][""loss""]\n        loss_name = loss_dict[""name""]\n        loss_params = {k: v for k, v in loss_dict.items() if k != ""name""}\n\n        if loss_name not in key2loss:\n            raise NotImplementedError(""Loss {} not implemented"".format(loss_name))\n\n        logger.info(""Using {} with {} params"".format(loss_name, loss_params))\n        return functools.partial(key2loss[loss_name], **loss_params)\n'"
ptsemseg/loss/loss.py,4,"b'import torch\nimport torch.nn.functional as F\n\n\ndef cross_entropy2d(input, target, weight=None, size_average=True):\n    n, c, h, w = input.size()\n    nt, ht, wt = target.size()\n\n    # Handle inconsistent size between input and target\n    if h != ht and w != wt:  # upsample labels\n        input = F.interpolate(input, size=(ht, wt), mode=""bilinear"", align_corners=True)\n\n    input = input.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n    target = target.view(-1)\n    loss = F.cross_entropy(\n        input, target, weight=weight, size_average=size_average, ignore_index=250\n    )\n    return loss\n\n\ndef multi_scale_cross_entropy2d(input, target, weight=None, size_average=True, scale_weight=None):\n    if not isinstance(input, tuple):\n        return cross_entropy2d(input=input, target=target, weight=weight, size_average=size_average)\n\n    # Auxiliary training for PSPNet [1.0, 0.4] and ICNet [1.0, 0.4, 0.16]\n    if scale_weight is None:  # scale_weight: torch tensor type\n        n_inp = len(input)\n        scale = 0.4\n        scale_weight = torch.pow(scale * torch.ones(n_inp), torch.arange(n_inp).float()).to(\n            target.device\n        )\n\n    loss = 0.0\n    for i, inp in enumerate(input):\n        loss = loss + scale_weight[i] * cross_entropy2d(\n            input=inp, target=target, weight=weight, size_average=size_average\n        )\n\n    return loss\n\n\ndef bootstrapped_cross_entropy2d(input, target, K, weight=None, size_average=True):\n\n    batch_size = input.size()[0]\n\n    def _bootstrap_xentropy_single(input, target, K, weight=None, size_average=True):\n\n        n, c, h, w = input.size()\n        input = input.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n        target = target.view(-1)\n        loss = F.cross_entropy(\n            input, target, weight=weight, reduce=False, size_average=False, ignore_index=250\n        )\n\n        topk_loss, _ = loss.topk(K)\n        reduced_topk_loss = topk_loss.sum() / K\n\n        return reduced_topk_loss\n\n    loss = 0.0\n    # Bootstrap from each image not entire batch\n    for i in range(batch_size):\n        loss += _bootstrap_xentropy_single(\n            input=torch.unsqueeze(input[i], 0),\n            target=torch.unsqueeze(target[i], 0),\n            K=K,\n            weight=weight,\n            size_average=size_average,\n        )\n    return loss / float(batch_size)\n'"
ptsemseg/models/__init__.py,0,"b'import copy\nimport torchvision.models as models\n\nfrom ptsemseg.models.fcn import fcn8s, fcn16s, fcn32s\nfrom ptsemseg.models.segnet import segnet\nfrom ptsemseg.models.unet import unet\nfrom ptsemseg.models.pspnet import pspnet\nfrom ptsemseg.models.icnet import icnet\nfrom ptsemseg.models.linknet import linknet\nfrom ptsemseg.models.frrn import frrn\n\n\ndef get_model(model_dict, n_classes, version=None):\n    name = model_dict[""arch""]\n    model = _get_model_instance(name)\n    param_dict = copy.deepcopy(model_dict)\n    param_dict.pop(""arch"")\n\n    if name in [""frrnA"", ""frrnB""]:\n        model = model(n_classes, **param_dict)\n\n    elif name in [""fcn32s"", ""fcn16s"", ""fcn8s""]:\n        model = model(n_classes=n_classes, **param_dict)\n        vgg16 = models.vgg16(pretrained=True)\n        model.init_vgg16_params(vgg16)\n\n    elif name == ""segnet"":\n        model = model(n_classes=n_classes, **param_dict)\n        vgg16 = models.vgg16(pretrained=True)\n        model.init_vgg16_params(vgg16)\n\n    elif name == ""unet"":\n        model = model(n_classes=n_classes, **param_dict)\n\n    elif name == ""pspnet"":\n        model = model(n_classes=n_classes, **param_dict)\n\n    elif name == ""icnet"":\n        model = model(n_classes=n_classes, **param_dict)\n\n    elif name == ""icnetBN"":\n        model = model(n_classes=n_classes, **param_dict)\n\n    else:\n        model = model(n_classes=n_classes, **param_dict)\n\n    return model\n\n\ndef _get_model_instance(name):\n    try:\n        return {\n            ""fcn32s"": fcn32s,\n            ""fcn8s"": fcn8s,\n            ""fcn16s"": fcn16s,\n            ""unet"": unet,\n            ""segnet"": segnet,\n            ""pspnet"": pspnet,\n            ""icnet"": icnet,\n            ""icnetBN"": icnet,\n            ""linknet"": linknet,\n            ""frrnA"": frrn,\n            ""frrnB"": frrn,\n        }[name]\n    except:\n        raise (""Model {} not available"".format(name))\n'"
ptsemseg/models/fcn.py,2,"b'import functools\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom ptsemseg.models.utils import get_upsampling_weight\nfrom ptsemseg.loss import cross_entropy2d\n\n\n# FCN32s\nclass fcn32s(nn.Module):\n    def __init__(self, n_classes=21, learned_billinear=False):\n        super(fcn32s, self).__init__()\n        self.learned_billinear = learned_billinear\n        self.n_classes = n_classes\n        self.loss = functools.partial(cross_entropy2d, size_average=False)\n\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=100),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(256, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block5 = nn.Sequential(\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Conv2d(512, 4096, 7),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(),\n            nn.Conv2d(4096, 4096, 1),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(),\n            nn.Conv2d(4096, self.n_classes, 1),\n        )\n\n        if self.learned_billinear:\n            raise NotImplementedError\n\n    def forward(self, x):\n        conv1 = self.conv_block1(x)\n        conv2 = self.conv_block2(conv1)\n        conv3 = self.conv_block3(conv2)\n        conv4 = self.conv_block4(conv3)\n        conv5 = self.conv_block5(conv4)\n\n        score = self.classifier(conv5)\n\n        out = F.upsample(score, x.size()[2:])\n\n        return out\n\n    def init_vgg16_params(self, vgg16, copy_fc8=True):\n        blocks = [\n            self.conv_block1,\n            self.conv_block2,\n            self.conv_block3,\n            self.conv_block4,\n            self.conv_block5,\n        ]\n\n        ranges = [[0, 4], [5, 9], [10, 16], [17, 23], [24, 29]]\n        features = list(vgg16.features.children())\n\n        for idx, conv_block in enumerate(blocks):\n            for l1, l2 in zip(features[ranges[idx][0] : ranges[idx][1]], conv_block):\n                if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n                    assert l1.weight.size() == l2.weight.size()\n                    assert l1.bias.size() == l2.bias.size()\n                    l2.weight.data = l1.weight.data\n                    l2.bias.data = l1.bias.data\n        for i1, i2 in zip([0, 3], [0, 3]):\n            l1 = vgg16.classifier[i1]\n            l2 = self.classifier[i2]\n            l2.weight.data = l1.weight.data.view(l2.weight.size())\n            l2.bias.data = l1.bias.data.view(l2.bias.size())\n        n_class = self.classifier[6].weight.size()[0]\n        if copy_fc8:\n            l1 = vgg16.classifier[6]\n            l2 = self.classifier[6]\n            l2.weight.data = l1.weight.data[:n_class, :].view(l2.weight.size())\n            l2.bias.data = l1.bias.data[:n_class]\n\n\nclass fcn16s(nn.Module):\n    def __init__(self, n_classes=21, learned_billinear=False):\n        super(fcn16s, self).__init__()\n        self.learned_billinear = learned_billinear\n        self.n_classes = n_classes\n        self.loss = functools.partial(cross_entropy2d, size_average=False)\n\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=100),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(256, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block5 = nn.Sequential(\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Conv2d(512, 4096, 7),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(),\n            nn.Conv2d(4096, 4096, 1),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(),\n            nn.Conv2d(4096, self.n_classes, 1),\n        )\n\n        self.score_pool4 = nn.Conv2d(512, self.n_classes, 1)\n\n        # TODO: Add support for learned upsampling\n        if self.learned_billinear:\n            raise NotImplementedError\n\n    def forward(self, x):\n        conv1 = self.conv_block1(x)\n        conv2 = self.conv_block2(conv1)\n        conv3 = self.conv_block3(conv2)\n        conv4 = self.conv_block4(conv3)\n        conv5 = self.conv_block5(conv4)\n\n        score = self.classifier(conv5)\n        score_pool4 = self.score_pool4(conv4)\n\n        score = F.upsample(score, score_pool4.size()[2:])\n        score += score_pool4\n        out = F.upsample(score, x.size()[2:])\n\n        return out\n\n    def init_vgg16_params(self, vgg16, copy_fc8=True):\n        blocks = [\n            self.conv_block1,\n            self.conv_block2,\n            self.conv_block3,\n            self.conv_block4,\n            self.conv_block5,\n        ]\n\n        ranges = [[0, 4], [5, 9], [10, 16], [17, 23], [24, 29]]\n        features = list(vgg16.features.children())\n\n        for idx, conv_block in enumerate(blocks):\n            for l1, l2 in zip(features[ranges[idx][0] : ranges[idx][1]], conv_block):\n                if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n                    # print(idx, l1, l2)\n                    assert l1.weight.size() == l2.weight.size()\n                    assert l1.bias.size() == l2.bias.size()\n                    l2.weight.data = l1.weight.data\n                    l2.bias.data = l1.bias.data\n        for i1, i2 in zip([0, 3], [0, 3]):\n            l1 = vgg16.classifier[i1]\n            l2 = self.classifier[i2]\n            l2.weight.data = l1.weight.data.view(l2.weight.size())\n            l2.bias.data = l1.bias.data.view(l2.bias.size())\n        n_class = self.classifier[6].weight.size()[0]\n        if copy_fc8:\n            l1 = vgg16.classifier[6]\n            l2 = self.classifier[6]\n            l2.weight.data = l1.weight.data[:n_class, :].view(l2.weight.size())\n            l2.bias.data = l1.bias.data[:n_class]\n\n\n# FCN 8s\nclass fcn8s(nn.Module):\n    def __init__(self, n_classes=21, learned_billinear=True):\n        super(fcn8s, self).__init__()\n        self.learned_billinear = learned_billinear\n        self.n_classes = n_classes\n        self.loss = functools.partial(cross_entropy2d, size_average=False)\n\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(3, 64, 3, padding=100),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(128, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block4 = nn.Sequential(\n            nn.Conv2d(256, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.conv_block5 = nn.Sequential(\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Conv2d(512, 4096, 7),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(),\n            nn.Conv2d(4096, 4096, 1),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(),\n            nn.Conv2d(4096, self.n_classes, 1),\n        )\n\n        self.score_pool4 = nn.Conv2d(512, self.n_classes, 1)\n        self.score_pool3 = nn.Conv2d(256, self.n_classes, 1)\n\n        if self.learned_billinear:\n            self.upscore2 = nn.ConvTranspose2d(\n                self.n_classes, self.n_classes, 4, stride=2, bias=False\n            )\n            self.upscore4 = nn.ConvTranspose2d(\n                self.n_classes, self.n_classes, 4, stride=2, bias=False\n            )\n            self.upscore8 = nn.ConvTranspose2d(\n                self.n_classes, self.n_classes, 16, stride=8, bias=False\n            )\n\n        for m in self.modules():\n            if isinstance(m, nn.ConvTranspose2d):\n                m.weight.data.copy_(\n                    get_upsampling_weight(m.in_channels, m.out_channels, m.kernel_size[0])\n                )\n\n    def forward(self, x):\n        conv1 = self.conv_block1(x)\n        conv2 = self.conv_block2(conv1)\n        conv3 = self.conv_block3(conv2)\n        conv4 = self.conv_block4(conv3)\n        conv5 = self.conv_block5(conv4)\n\n        score = self.classifier(conv5)\n\n        if self.learned_billinear:\n            upscore2 = self.upscore2(score)\n            score_pool4c = self.score_pool4(conv4)[\n                :, :, 5 : 5 + upscore2.size()[2], 5 : 5 + upscore2.size()[3]\n            ]\n            upscore_pool4 = self.upscore4(upscore2 + score_pool4c)\n\n            score_pool3c = self.score_pool3(conv3)[\n                :, :, 9 : 9 + upscore_pool4.size()[2], 9 : 9 + upscore_pool4.size()[3]\n            ]\n\n            out = self.upscore8(score_pool3c + upscore_pool4)[\n                :, :, 31 : 31 + x.size()[2], 31 : 31 + x.size()[3]\n            ]\n            return out.contiguous()\n\n        else:\n            score_pool4 = self.score_pool4(conv4)\n            score_pool3 = self.score_pool3(conv3)\n            score = F.upsample(score, score_pool4.size()[2:])\n            score += score_pool4\n            score = F.upsample(score, score_pool3.size()[2:])\n            score += score_pool3\n            out = F.upsample(score, x.size()[2:])\n\n        return out\n\n    def init_vgg16_params(self, vgg16, copy_fc8=True):\n        blocks = [\n            self.conv_block1,\n            self.conv_block2,\n            self.conv_block3,\n            self.conv_block4,\n            self.conv_block5,\n        ]\n\n        ranges = [[0, 4], [5, 9], [10, 16], [17, 23], [24, 29]]\n        features = list(vgg16.features.children())\n\n        for idx, conv_block in enumerate(blocks):\n            for l1, l2 in zip(features[ranges[idx][0] : ranges[idx][1]], conv_block):\n                if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n                    assert l1.weight.size() == l2.weight.size()\n                    assert l1.bias.size() == l2.bias.size()\n                    l2.weight.data = l1.weight.data\n                    l2.bias.data = l1.bias.data\n        for i1, i2 in zip([0, 3], [0, 3]):\n            l1 = vgg16.classifier[i1]\n            l2 = self.classifier[i2]\n            l2.weight.data = l1.weight.data.view(l2.weight.size())\n            l2.bias.data = l1.bias.data.view(l2.bias.size())\n        n_class = self.classifier[6].weight.size()[0]\n        if copy_fc8:\n            l1 = vgg16.classifier[6]\n            l2 = self.classifier[6]\n            l2.weight.data = l1.weight.data[:n_class, :].view(l2.weight.size())\n            l2.bias.data = l1.bias.data[:n_class]\n'"
ptsemseg/models/frrn.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom ptsemseg.models.utils import FRRU, RU, conv2DBatchNormRelu, conv2DGroupNormRelu\n\nfrrn_specs_dic = {\n    ""A"": {\n        ""encoder"": [[3, 96, 2], [4, 192, 4], [2, 384, 8], [2, 384, 16]],\n        ""decoder"": [[2, 192, 8], [2, 192, 4], [2, 48, 2]],\n    },\n    ""B"": {\n        ""encoder"": [[3, 96, 2], [4, 192, 4], [2, 384, 8], [2, 384, 16], [2, 384, 32]],\n        ""decoder"": [[2, 192, 16], [2, 192, 8], [2, 192, 4], [2, 48, 2]],\n    },\n}\n\n\nclass frrn(nn.Module):\n    """"""\n    Full Resolution Residual Networks for Semantic Segmentation\n    URL: https://arxiv.org/abs/1611.08323\n\n    References:\n    1) Original Author\'s code: https://github.com/TobyPDE/FRRN\n    2) TF implementation by @kiwonjoon: https://github.com/hiwonjoon/tf-frrn\n    """"""\n\n    def __init__(self, n_classes=21, model_type=""B"", group_norm=False, n_groups=16):\n        super(frrn, self).__init__()\n        self.n_classes = n_classes\n        self.model_type = model_type\n        self.group_norm = group_norm\n        self.n_groups = n_groups\n\n        if self.group_norm:\n            self.conv1 = conv2DGroupNormRelu(3, 48, 5, 1, 2)\n        else:\n            self.conv1 = conv2DBatchNormRelu(3, 48, 5, 1, 2)\n\n        self.up_residual_units = []\n        self.down_residual_units = []\n        for i in range(3):\n            self.up_residual_units.append(\n                RU(\n                    channels=48,\n                    kernel_size=3,\n                    strides=1,\n                    group_norm=self.group_norm,\n                    n_groups=self.n_groups,\n                )\n            )\n            self.down_residual_units.append(\n                RU(\n                    channels=48,\n                    kernel_size=3,\n                    strides=1,\n                    group_norm=self.group_norm,\n                    n_groups=self.n_groups,\n                )\n            )\n\n        self.up_residual_units = nn.ModuleList(self.up_residual_units)\n        self.down_residual_units = nn.ModuleList(self.down_residual_units)\n\n        self.split_conv = nn.Conv2d(48, 32, kernel_size=1, padding=0, stride=1, bias=False)\n\n        # each spec is as (n_blocks, channels, scale)\n        self.encoder_frru_specs = frrn_specs_dic[self.model_type][""encoder""]\n\n        self.decoder_frru_specs = frrn_specs_dic[self.model_type][""decoder""]\n\n        # encoding\n        prev_channels = 48\n        self.encoding_frrus = {}\n        for n_blocks, channels, scale in self.encoder_frru_specs:\n            for block in range(n_blocks):\n                key = ""_"".join(map(str, [""encoding_frru"", n_blocks, channels, scale, block]))\n                setattr(\n                    self,\n                    key,\n                    FRRU(\n                        prev_channels=prev_channels,\n                        out_channels=channels,\n                        scale=scale,\n                        group_norm=self.group_norm,\n                        n_groups=self.n_groups,\n                    ),\n                )\n            prev_channels = channels\n\n        # decoding\n        self.decoding_frrus = {}\n        for n_blocks, channels, scale in self.decoder_frru_specs:\n            # pass through decoding FRRUs\n            for block in range(n_blocks):\n                key = ""_"".join(map(str, [""decoding_frru"", n_blocks, channels, scale, block]))\n                setattr(\n                    self,\n                    key,\n                    FRRU(\n                        prev_channels=prev_channels,\n                        out_channels=channels,\n                        scale=scale,\n                        group_norm=self.group_norm,\n                        n_groups=self.n_groups,\n                    ),\n                )\n            prev_channels = channels\n\n        self.merge_conv = nn.Conv2d(\n            prev_channels + 32, 48, kernel_size=1, padding=0, stride=1, bias=False\n        )\n\n        self.classif_conv = nn.Conv2d(\n            48, self.n_classes, kernel_size=1, padding=0, stride=1, bias=True\n        )\n\n    def forward(self, x):\n\n        # pass to initial conv\n        x = self.conv1(x)\n\n        # pass through residual units\n        for i in range(3):\n            x = self.up_residual_units[i](x)\n\n        # divide stream\n        y = x\n        z = self.split_conv(x)\n\n        prev_channels = 48\n        # encoding\n        for n_blocks, channels, scale in self.encoder_frru_specs:\n            # maxpool bigger feature map\n            y_pooled = F.max_pool2d(y, stride=2, kernel_size=2, padding=0)\n            # pass through encoding FRRUs\n            for block in range(n_blocks):\n                key = ""_"".join(map(str, [""encoding_frru"", n_blocks, channels, scale, block]))\n                y, z = getattr(self, key)(y_pooled, z)\n            prev_channels = channels\n\n        # decoding\n        for n_blocks, channels, scale in self.decoder_frru_specs:\n            # bilinear upsample smaller feature map\n            upsample_size = torch.Size([_s * 2 for _s in y.size()[-2:]])\n            y_upsampled = F.upsample(y, size=upsample_size, mode=""bilinear"", align_corners=True)\n            # pass through decoding FRRUs\n            for block in range(n_blocks):\n                key = ""_"".join(map(str, [""decoding_frru"", n_blocks, channels, scale, block]))\n                # print(""Incoming FRRU Size: "", key, y_upsampled.shape, z.shape)\n                y, z = getattr(self, key)(y_upsampled, z)\n                # print(""Outgoing FRRU Size: "", key, y.shape, z.shape)\n            prev_channels = channels\n\n        # merge streams\n        x = torch.cat(\n            [F.upsample(y, scale_factor=2, mode=""bilinear"", align_corners=True), z], dim=1\n        )\n        x = self.merge_conv(x)\n\n        # pass through residual units\n        for i in range(3):\n            x = self.down_residual_units[i](x)\n\n        # final 1x1 conv to get classification\n        x = self.classif_conv(x)\n\n        return x\n'"
ptsemseg/models/icnet.py,18,"b'import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\nfrom ptsemseg import caffe_pb2\nfrom ptsemseg.models.utils import (\n    get_interp_size,\n    cascadeFeatureFusion,\n    conv2DBatchNormRelu,\n    residualBlockPSP,\n    pyramidPooling,\n)\nfrom ptsemseg.loss.loss import multi_scale_cross_entropy2d\n\nicnet_specs = {\n    ""cityscapes"": {""n_classes"": 19, ""input_size"": (1025, 2049), ""block_config"": [3, 4, 6, 3]}\n}\n\n\nclass icnet(nn.Module):\n\n    """"""\n    Image Cascade Network\n    URL: https://arxiv.org/abs/1704.08545\n\n    References:\n    1) Original Author\'s code: https://github.com/hszhao/ICNet\n    2) Chainer implementation by @mitmul: https://github.com/mitmul/chainer-pspnet\n    3) TensorFlow implementation by @hellochick: https://github.com/hellochick/ICNet-tensorflow\n\n    """"""\n\n    def __init__(\n        self,\n        n_classes=19,\n        block_config=[3, 4, 6, 3],\n        input_size=(1025, 2049),\n        version=None,\n        is_batchnorm=True,\n    ):\n\n        super(icnet, self).__init__()\n\n        bias = not is_batchnorm\n\n        self.block_config = (\n            icnet_specs[version][""block_config""] if version is not None else block_config\n        )\n        self.n_classes = icnet_specs[version][""n_classes""] if version is not None else n_classes\n        self.input_size = icnet_specs[version][""input_size""] if version is not None else input_size\n\n        # Encoder\n        self.convbnrelu1_1 = conv2DBatchNormRelu(\n            in_channels=3,\n            k_size=3,\n            n_filters=32,\n            padding=1,\n            stride=2,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n        self.convbnrelu1_2 = conv2DBatchNormRelu(\n            in_channels=32,\n            k_size=3,\n            n_filters=32,\n            padding=1,\n            stride=1,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n        self.convbnrelu1_3 = conv2DBatchNormRelu(\n            in_channels=32,\n            k_size=3,\n            n_filters=64,\n            padding=1,\n            stride=1,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n\n        # Vanilla Residual Blocks\n        self.res_block2 = residualBlockPSP(\n            self.block_config[0], 64, 32, 128, 1, 1, is_batchnorm=is_batchnorm\n        )\n        self.res_block3_conv = residualBlockPSP(\n            self.block_config[1],\n            128,\n            64,\n            256,\n            2,\n            1,\n            include_range=""conv"",\n            is_batchnorm=is_batchnorm,\n        )\n        self.res_block3_identity = residualBlockPSP(\n            self.block_config[1],\n            128,\n            64,\n            256,\n            2,\n            1,\n            include_range=""identity"",\n            is_batchnorm=is_batchnorm,\n        )\n\n        # Dilated Residual Blocks\n        self.res_block4 = residualBlockPSP(\n            self.block_config[2], 256, 128, 512, 1, 2, is_batchnorm=is_batchnorm\n        )\n        self.res_block5 = residualBlockPSP(\n            self.block_config[3], 512, 256, 1024, 1, 4, is_batchnorm=is_batchnorm\n        )\n\n        # Pyramid Pooling Module\n        self.pyramid_pooling = pyramidPooling(\n            1024, [6, 3, 2, 1], model_name=""icnet"", fusion_mode=""sum"", is_batchnorm=is_batchnorm\n        )\n\n        # Final conv layer with kernel 1 in sub4 branch\n        self.conv5_4_k1 = conv2DBatchNormRelu(\n            in_channels=1024,\n            k_size=1,\n            n_filters=256,\n            padding=0,\n            stride=1,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n\n        # High-resolution (sub1) branch\n        self.convbnrelu1_sub1 = conv2DBatchNormRelu(\n            in_channels=3,\n            k_size=3,\n            n_filters=32,\n            padding=1,\n            stride=2,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n        self.convbnrelu2_sub1 = conv2DBatchNormRelu(\n            in_channels=32,\n            k_size=3,\n            n_filters=32,\n            padding=1,\n            stride=2,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n        self.convbnrelu3_sub1 = conv2DBatchNormRelu(\n            in_channels=32,\n            k_size=3,\n            n_filters=64,\n            padding=1,\n            stride=2,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n        self.classification = nn.Conv2d(128, self.n_classes, 1, 1, 0)\n\n        # Cascade Feature Fusion Units\n        self.cff_sub24 = cascadeFeatureFusion(\n            self.n_classes, 256, 256, 128, is_batchnorm=is_batchnorm\n        )\n        self.cff_sub12 = cascadeFeatureFusion(\n            self.n_classes, 128, 64, 128, is_batchnorm=is_batchnorm\n        )\n\n        # Define auxiliary loss function\n        self.loss = multi_scale_cross_entropy2d\n\n    def forward(self, x):\n        h, w = x.shape[2:]\n\n        # H, W -> H/2, W/2\n        x_sub2 = F.interpolate(\n            x, size=get_interp_size(x, s_factor=2), mode=""bilinear"", align_corners=True\n        )\n\n        # H/2, W/2 -> H/4, W/4\n        x_sub2 = self.convbnrelu1_1(x_sub2)\n        x_sub2 = self.convbnrelu1_2(x_sub2)\n        x_sub2 = self.convbnrelu1_3(x_sub2)\n\n        # H/4, W/4 -> H/8, W/8\n        x_sub2 = F.max_pool2d(x_sub2, 3, 2, 1)\n\n        # H/8, W/8 -> H/16, W/16\n        x_sub2 = self.res_block2(x_sub2)\n        x_sub2 = self.res_block3_conv(x_sub2)\n        # H/16, W/16 -> H/32, W/32\n        x_sub4 = F.interpolate(\n            x_sub2, size=get_interp_size(x_sub2, s_factor=2), mode=""bilinear"", align_corners=True\n        )\n        x_sub4 = self.res_block3_identity(x_sub4)\n\n        x_sub4 = self.res_block4(x_sub4)\n        x_sub4 = self.res_block5(x_sub4)\n\n        x_sub4 = self.pyramid_pooling(x_sub4)\n        x_sub4 = self.conv5_4_k1(x_sub4)\n\n        x_sub1 = self.convbnrelu1_sub1(x)\n        x_sub1 = self.convbnrelu2_sub1(x_sub1)\n        x_sub1 = self.convbnrelu3_sub1(x_sub1)\n\n        x_sub24, sub4_cls = self.cff_sub24(x_sub4, x_sub2)\n        x_sub12, sub24_cls = self.cff_sub12(x_sub24, x_sub1)\n\n        x_sub12 = F.interpolate(\n            x_sub12, size=get_interp_size(x_sub12, z_factor=2), mode=""bilinear"", align_corners=True\n        )\n        x_sub4 = self.res_block3_identity(x_sub4)\n        sub124_cls = self.classification(x_sub12)\n\n        if self.training:\n            return (sub124_cls, sub24_cls, sub4_cls)\n        else:\n            sub124_cls = F.interpolate(\n                sub124_cls,\n                size=get_interp_size(sub124_cls, z_factor=4),\n                mode=""bilinear"",\n                align_corners=True,\n            )\n            return sub124_cls\n\n    def load_pretrained_model(self, model_path):\n        """"""\n        Load weights from caffemodel w/o caffe dependency\n        and plug them in corresponding modules\n        """"""\n        # My eyes and my heart both hurt when writing this method\n\n        # Only care about layer_types that have trainable parameters\n        ltypes = [\n            ""BNData"",\n            ""ConvolutionData"",\n            ""HoleConvolutionData"",\n            ""Convolution"",\n        ]  # Convolution type for conv3_sub1_proj\n\n        def _get_layer_params(layer, ltype):\n\n            if ltype == ""BNData"":\n                gamma = np.array(layer.blobs[0].data)\n                beta = np.array(layer.blobs[1].data)\n                mean = np.array(layer.blobs[2].data)\n                var = np.array(layer.blobs[3].data)\n                return [mean, var, gamma, beta]\n\n            elif ltype in [""ConvolutionData"", ""HoleConvolutionData"", ""Convolution""]:\n                is_bias = layer.convolution_param.bias_term\n                weights = np.array(layer.blobs[0].data)\n                bias = []\n                if is_bias:\n                    bias = np.array(layer.blobs[1].data)\n                return [weights, bias]\n\n            elif ltype == ""InnerProduct"":\n                raise Exception(""Fully connected layers {}, not supported"".format(ltype))\n\n            else:\n                raise Exception(""Unkown layer type {}"".format(ltype))\n\n        net = caffe_pb2.NetParameter()\n        with open(model_path, ""rb"") as model_file:\n            net.MergeFromString(model_file.read())\n\n        # dict formatted as ->  key:<layer_name> :: value:<layer_type>\n        layer_types = {}\n        # dict formatted as ->  key:<layer_name> :: value:[<list_of_params>]\n        layer_params = {}\n\n        for l in net.layer:\n            lname = l.name\n            ltype = l.type\n            lbottom = l.bottom\n            ltop = l.top\n            if ltype in ltypes:\n                print(""Processing layer {} | {}, {}"".format(lname, lbottom, ltop))\n                layer_types[lname] = ltype\n                layer_params[lname] = _get_layer_params(l, ltype)\n            # if len(l.blobs) > 0:\n            #    print(lname, ltype, lbottom, ltop, len(l.blobs))\n\n        # Set affine=False for all batchnorm modules\n        def _no_affine_bn(module=None):\n            if isinstance(module, nn.BatchNorm2d):\n                module.affine = False\n\n            if len([m for m in module.children()]) > 0:\n                for child in module.children():\n                    _no_affine_bn(child)\n\n        # _no_affine_bn(self)\n\n        def _transfer_conv(layer_name, module):\n            weights, bias = layer_params[layer_name]\n            w_shape = np.array(module.weight.size())\n\n            print(\n                ""CONV {}: Original {} and trans weights {}"".format(\n                    layer_name, w_shape, weights.shape\n                )\n            )\n\n            module.weight.data.copy_(torch.from_numpy(weights).view_as(module.weight))\n\n            if len(bias) != 0:\n                b_shape = np.array(module.bias.size())\n                print(\n                    ""CONV {}: Original {} and trans bias {}"".format(layer_name, b_shape, bias.shape)\n                )\n                module.bias.data.copy_(torch.from_numpy(bias).view_as(module.bias))\n\n        def _transfer_bn(conv_layer_name, bn_module):\n            mean, var, gamma, beta = layer_params[conv_layer_name + ""/bn""]\n            print(\n                ""BN {}: Original {} and trans weights {}"".format(\n                    conv_layer_name, bn_module.running_mean.size(), mean.shape\n                )\n            )\n            bn_module.running_mean.copy_(torch.from_numpy(mean).view_as(bn_module.running_mean))\n            bn_module.running_var.copy_(torch.from_numpy(var).view_as(bn_module.running_var))\n            bn_module.weight.data.copy_(torch.from_numpy(gamma).view_as(bn_module.weight))\n            bn_module.bias.data.copy_(torch.from_numpy(beta).view_as(bn_module.bias))\n\n        def _transfer_conv_bn(conv_layer_name, mother_module):\n            conv_module = mother_module[0]\n            _transfer_conv(conv_layer_name, conv_module)\n\n            if conv_layer_name + ""/bn"" in layer_params.keys():\n                bn_module = mother_module[1]\n                _transfer_bn(conv_layer_name, bn_module)\n\n        def _transfer_residual(block_name, block):\n            block_module, n_layers = block[0], block[1]\n            prefix = block_name[:5]\n\n            if (""bottleneck"" in block_name) or (""identity"" not in block_name):  # Conv block\n                bottleneck = block_module.layers[0]\n                bottleneck_conv_bn_dic = {\n                    prefix + ""_1_1x1_reduce"": bottleneck.cbr1.cbr_unit,\n                    prefix + ""_1_3x3"": bottleneck.cbr2.cbr_unit,\n                    prefix + ""_1_1x1_proj"": bottleneck.cb4.cb_unit,\n                    prefix + ""_1_1x1_increase"": bottleneck.cb3.cb_unit,\n                }\n\n                for k, v in bottleneck_conv_bn_dic.items():\n                    _transfer_conv_bn(k, v)\n\n            if (""identity"" in block_name) or (""bottleneck"" not in block_name):  # Identity blocks\n                base_idx = 2 if ""identity"" in block_name else 1\n\n                for layer_idx in range(2, n_layers + 1):\n                    residual_layer = block_module.layers[layer_idx - base_idx]\n                    residual_conv_bn_dic = {\n                        ""_"".join(\n                            map(str, [prefix, layer_idx, ""1x1_reduce""])\n                        ): residual_layer.cbr1.cbr_unit,\n                        ""_"".join(\n                            map(str, [prefix, layer_idx, ""3x3""])\n                        ): residual_layer.cbr2.cbr_unit,\n                        ""_"".join(\n                            map(str, [prefix, layer_idx, ""1x1_increase""])\n                        ): residual_layer.cb3.cb_unit,\n                    }\n\n                    for k, v in residual_conv_bn_dic.items():\n                        _transfer_conv_bn(k, v)\n\n        convbn_layer_mapping = {\n            ""conv1_1_3x3_s2"": self.convbnrelu1_1.cbr_unit,\n            ""conv1_2_3x3"": self.convbnrelu1_2.cbr_unit,\n            ""conv1_3_3x3"": self.convbnrelu1_3.cbr_unit,\n            ""conv1_sub1"": self.convbnrelu1_sub1.cbr_unit,\n            ""conv2_sub1"": self.convbnrelu2_sub1.cbr_unit,\n            ""conv3_sub1"": self.convbnrelu3_sub1.cbr_unit,\n            # \'conv5_3_pool6_conv\': self.pyramid_pooling.paths[0].cbr_unit,\n            # \'conv5_3_pool3_conv\': self.pyramid_pooling.paths[1].cbr_unit,\n            # \'conv5_3_pool2_conv\': self.pyramid_pooling.paths[2].cbr_unit,\n            # \'conv5_3_pool1_conv\': self.pyramid_pooling.paths[3].cbr_unit,\n            ""conv5_4_k1"": self.conv5_4_k1.cbr_unit,\n            ""conv_sub4"": self.cff_sub24.low_dilated_conv_bn.cb_unit,\n            ""conv3_1_sub2_proj"": self.cff_sub24.high_proj_conv_bn.cb_unit,\n            ""conv_sub2"": self.cff_sub12.low_dilated_conv_bn.cb_unit,\n            ""conv3_sub1_proj"": self.cff_sub12.high_proj_conv_bn.cb_unit,\n        }\n\n        residual_layers = {\n            ""conv2"": [self.res_block2, self.block_config[0]],\n            ""conv3_bottleneck"": [self.res_block3_conv, self.block_config[1]],\n            ""conv3_identity"": [self.res_block3_identity, self.block_config[1]],\n            ""conv4"": [self.res_block4, self.block_config[2]],\n            ""conv5"": [self.res_block5, self.block_config[3]],\n        }\n\n        # Transfer weights for all non-residual conv+bn layers\n        for k, v in convbn_layer_mapping.items():\n            _transfer_conv_bn(k, v)\n\n        # Transfer weights for final non-bn conv layer\n        _transfer_conv(""conv6_cls"", self.classification)\n        _transfer_conv(""conv6_sub4"", self.cff_sub24.low_classifier_conv)\n        _transfer_conv(""conv6_sub2"", self.cff_sub12.low_classifier_conv)\n\n        # Transfer weights for all residual layers\n        for k, v in residual_layers.items():\n            _transfer_residual(k, v)\n\n    def tile_predict(self, imgs, include_flip_mode=True):\n        """"""\n        Predict by takin overlapping tiles from the image.\n\n        Strides are adaptively computed from the imgs shape\n        and input size\n\n        :param imgs: torch.Tensor with shape [N, C, H, W] in BGR format\n        :param side: int with side length of model input\n        :param n_classes: int with number of classes in seg output.\n        """"""\n\n        side_x, side_y = self.input_size\n        n_classes = self.n_classes\n        n_samples, c, h, w = imgs.shape\n        # n = int(max(h,w) / float(side) + 1)\n        n_x = int(h / float(side_x) + 1)\n        n_y = int(w / float(side_y) + 1)\n        stride_x = (h - side_x) / float(n_x)\n        stride_y = (w - side_y) / float(n_y)\n\n        x_ends = [[int(i * stride_x), int(i * stride_x) + side_x] for i in range(n_x + 1)]\n        y_ends = [[int(i * stride_y), int(i * stride_y) + side_y] for i in range(n_y + 1)]\n\n        pred = np.zeros([n_samples, n_classes, h, w])\n        count = np.zeros([h, w])\n\n        slice_count = 0\n        for sx, ex in x_ends:\n            for sy, ey in y_ends:\n                slice_count += 1\n\n                imgs_slice = imgs[:, :, sx:ex, sy:ey]\n                if include_flip_mode:\n                    imgs_slice_flip = torch.from_numpy(\n                        np.copy(imgs_slice.cpu().numpy()[:, :, :, ::-1])\n                    ).float()\n\n                is_model_on_cuda = next(self.parameters()).is_cuda\n\n                inp = Variable(imgs_slice, volatile=True)\n                if include_flip_mode:\n                    flp = Variable(imgs_slice_flip, volatile=True)\n\n                if is_model_on_cuda:\n                    inp = inp.cuda()\n                    if include_flip_mode:\n                        flp = flp.cuda()\n\n                psub1 = F.softmax(self.forward(inp), dim=1).data.cpu().numpy()\n                if include_flip_mode:\n                    psub2 = F.softmax(self.forward(flp), dim=1).data.cpu().numpy()\n                    psub = (psub1 + psub2[:, :, :, ::-1]) / 2.0\n                else:\n                    psub = psub1\n\n                pred[:, :, sx:ex, sy:ey] = psub\n                count[sx:ex, sy:ey] += 1.0\n\n        score = (pred / count[None, None, ...]).astype(np.float32)\n        return score / np.expand_dims(score.sum(axis=1), axis=1)\n\n\n# For Testing Purposes only\nif __name__ == ""__main__"":\n    cd = 0\n    import os\n    import scipy.misc as m\n    from ptsemseg.loader.cityscapes_loader import cityscapesLoader as cl\n\n    ic = icnet(version=""cityscapes"", is_batchnorm=False)\n\n    # Just need to do this one time\n    caffemodel_dir_path = ""PATH_TO_ICNET_DIR/evaluation/model""\n    ic.load_pretrained_model(\n        model_path=os.path.join(caffemodel_dir_path, ""icnet_cityscapes_train_30k.caffemodel"")\n    )\n    # ic.load_pretrained_model(model_path=os.path.join(caffemodel_dir_path,\n    #                           \'icnet_cityscapes_train_30k_bnnomerge.caffemodel\'))\n    # ic.load_pretrained_model(model_path=os.path.join(caffemodel_dir_path,\n    #                           \'icnet_cityscapes_trainval_90k.caffemodel\'))\n    # ic.load_pretrained_model(model_path=os.path.join(caffemodel_dir_path,\n    #                           \'icnet_cityscapes_trainval_90k_bnnomerge.caffemodel\'))\n\n    # ic.load_state_dict(torch.load(\'ic.pth\'))\n\n    ic.float()\n    ic.cuda(cd)\n    ic.eval()\n\n    dataset_root_dir = ""PATH_TO_CITYSCAPES_DIR""\n    dst = cl(root=dataset_root_dir)\n    img = m.imread(\n        os.path.join(\n            dataset_root_dir,\n            ""leftImg8bit/demoVideo/stuttgart_00/stuttgart_00_000000_000010_leftImg8bit.png"",\n        )\n    )\n    m.imsave(""test_input.png"", img)\n    orig_size = img.shape[:-1]\n    img = m.imresize(img, ic.input_size)  # uint8 with RGB mode\n    img = img.transpose(2, 0, 1)\n    img = img.astype(np.float64)\n    img -= np.array([123.68, 116.779, 103.939])[:, None, None]\n    img = np.copy(img[::-1, :, :])\n    img = torch.from_numpy(img).float()\n    img = img.unsqueeze(0)\n\n    out = ic.tile_predict(img)\n    pred = np.argmax(out, axis=1)[0]\n    pred = pred.astype(np.float32)\n    pred = m.imresize(pred, orig_size, ""nearest"", mode=""F"")  # float32 with F mode\n    decoded = dst.decode_segmap(pred)\n    m.imsave(""test_output.png"", decoded)\n    # m.imsave(\'test_output.png\', pred)\n\n    checkpoints_dir_path = ""checkpoints""\n    if not os.path.exists(checkpoints_dir_path):\n        os.mkdir(checkpoints_dir_path)\n    ic = torch.nn.DataParallel(ic, device_ids=range(torch.cuda.device_count()))\n    state = {""model_state"": ic.state_dict()}\n    torch.save(state, os.path.join(checkpoints_dir_path, ""icnet_cityscapes_train_30k.pth""))\n    # torch.save(state, os.path.join(checkpoints_dir_path, ""icnetBN_cityscapes_train_30k.pth""))\n    # torch.save(state, os.path.join(checkpoints_dir_path, ""icnet_cityscapes_trainval_90k.pth""))\n    # torch.save(state, os.path.join(checkpoints_dir_path, ""icnetBN_cityscapes_trainval_90k.pth""))\n    print(""Output Shape {} \\t Input Shape {}"".format(out.shape, img.shape))\n'"
ptsemseg/models/linknet.py,1,"b'import torch.nn as nn\n\nfrom ptsemseg.models.utils import conv2DBatchNormRelu, linknetUp, residualBlock\n\n\nclass linknet(nn.Module):\n    def __init__(\n        self, feature_scale=4, n_classes=21, is_deconv=True, in_channels=3, is_batchnorm=True\n    ):\n        super(linknet, self).__init__()\n        self.is_deconv = is_deconv\n        self.in_channels = in_channels\n        self.is_batchnorm = is_batchnorm\n        self.feature_scale = feature_scale\n        self.layers = [2, 2, 2, 2]  # Currently hardcoded for ResNet-18\n\n        filters = [64, 128, 256, 512]\n        filters = [x / self.feature_scale for x in filters]\n\n        self.inplanes = filters[0]\n\n        # Encoder\n        self.convbnrelu1 = conv2DBatchNormRelu(\n            in_channels=3, k_size=7, n_filters=64, padding=3, stride=2, bias=False\n        )\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        block = residualBlock\n        self.encoder1 = self._make_layer(block, filters[0], self.layers[0])\n        self.encoder2 = self._make_layer(block, filters[1], self.layers[1], stride=2)\n        self.encoder3 = self._make_layer(block, filters[2], self.layers[2], stride=2)\n        self.encoder4 = self._make_layer(block, filters[3], self.layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7)\n\n        # Decoder\n        self.decoder4 = linknetUp(filters[3], filters[2])\n        self.decoder4 = linknetUp(filters[2], filters[1])\n        self.decoder4 = linknetUp(filters[1], filters[0])\n        self.decoder4 = linknetUp(filters[0], filters[0])\n\n        # Final Classifier\n        self.finaldeconvbnrelu1 = nn.Sequential(\n            nn.ConvTranspose2d(filters[0], 32 / feature_scale, 3, 2, 1),\n            nn.BatchNorm2d(32 / feature_scale),\n            nn.ReLU(inplace=True),\n        )\n        self.finalconvbnrelu2 = conv2DBatchNormRelu(\n            in_channels=32 / feature_scale,\n            k_size=3,\n            n_filters=32 / feature_scale,\n            padding=1,\n            stride=1,\n        )\n        self.finalconv3 = nn.Conv2d(32 / feature_scale, n_classes, 2, 2, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.inplanes,\n                    planes * block.expansion,\n                    kernel_size=1,\n                    stride=stride,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        # Encoder\n        x = self.convbnrelu1(x)\n        x = self.maxpool(x)\n\n        e1 = self.encoder1(x)\n        e2 = self.encoder2(e1)\n        e3 = self.encoder3(e2)\n        e4 = self.encoder4(e3)\n\n        # Decoder with Skip Connections\n        d4 = self.decoder4(e4)\n        d4 += e3\n        d3 = self.decoder3(d4)\n        d3 += e2\n        d2 = self.decoder2(d3)\n        d2 += e1\n        d1 = self.decoder1(d2)\n\n        # Final Classification\n        f1 = self.finaldeconvbnrelu1(d1)\n        f2 = self.finalconvbnrelu2(f1)\n        f3 = self.finalconv3(f2)\n\n        return f3\n'"
ptsemseg/models/pspnet.py,18,"b'import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\nfrom ptsemseg import caffe_pb2\nfrom ptsemseg.models.utils import conv2DBatchNormRelu, residualBlockPSP, pyramidPooling\nfrom ptsemseg.loss.loss import multi_scale_cross_entropy2d\n\npspnet_specs = {\n    ""pascal"": {""n_classes"": 21, ""input_size"": (473, 473), ""block_config"": [3, 4, 23, 3]},\n    ""cityscapes"": {""n_classes"": 19, ""input_size"": (713, 713), ""block_config"": [3, 4, 23, 3]},\n    ""ade20k"": {""n_classes"": 150, ""input_size"": (473, 473), ""block_config"": [3, 4, 6, 3]},\n}\n\n\nclass pspnet(nn.Module):\n\n    """"""\n    Pyramid Scene Parsing Network\n    URL: https://arxiv.org/abs/1612.01105\n\n    References:\n    1) Original Author\'s code: https://github.com/hszhao/PSPNet\n    2) Chainer implementation by @mitmul: https://github.com/mitmul/chainer-pspnet\n    3) TensorFlow implementation by @hellochick: https://github.com/hellochick/PSPNet-tensorflow\n\n    Visualization:\n    http://dgschwend.github.io/netscope/#/gist/6bfb59e6a3cfcb4e2bb8d47f827c2928\n\n    """"""\n\n    def __init__(\n        self, n_classes=21, block_config=[3, 4, 23, 3], input_size=(473, 473), version=None\n    ):\n\n        super(pspnet, self).__init__()\n\n        self.block_config = (\n            pspnet_specs[version][""block_config""] if version is not None else block_config\n        )\n        self.n_classes = pspnet_specs[version][""n_classes""] if version is not None else n_classes\n        self.input_size = pspnet_specs[version][""input_size""] if version is not None else input_size\n\n        # Encoder\n        self.convbnrelu1_1 = conv2DBatchNormRelu(\n            in_channels=3, k_size=3, n_filters=64, padding=1, stride=2, bias=False\n        )\n        self.convbnrelu1_2 = conv2DBatchNormRelu(\n            in_channels=64, k_size=3, n_filters=64, padding=1, stride=1, bias=False\n        )\n        self.convbnrelu1_3 = conv2DBatchNormRelu(\n            in_channels=64, k_size=3, n_filters=128, padding=1, stride=1, bias=False\n        )\n\n        # Vanilla Residual Blocks\n        self.res_block2 = residualBlockPSP(self.block_config[0], 128, 64, 256, 1, 1)\n        self.res_block3 = residualBlockPSP(self.block_config[1], 256, 128, 512, 2, 1)\n\n        # Dilated Residual Blocks\n        self.res_block4 = residualBlockPSP(self.block_config[2], 512, 256, 1024, 1, 2)\n        self.res_block5 = residualBlockPSP(self.block_config[3], 1024, 512, 2048, 1, 4)\n\n        # Pyramid Pooling Module\n        self.pyramid_pooling = pyramidPooling(2048, [6, 3, 2, 1])\n\n        # Final conv layers\n        self.cbr_final = conv2DBatchNormRelu(4096, 512, 3, 1, 1, False)\n        self.dropout = nn.Dropout2d(p=0.1, inplace=False)\n        self.classification = nn.Conv2d(512, self.n_classes, 1, 1, 0)\n\n        # Auxiliary layers for training\n        self.convbnrelu4_aux = conv2DBatchNormRelu(\n            in_channels=1024, k_size=3, n_filters=256, padding=1, stride=1, bias=False\n        )\n        self.aux_cls = nn.Conv2d(256, self.n_classes, 1, 1, 0)\n\n        # Define auxiliary loss function\n        self.loss = multi_scale_cross_entropy2d\n\n    def forward(self, x):\n        inp_shape = x.shape[2:]\n\n        # H, W -> H/2, W/2\n        x = self.convbnrelu1_1(x)\n        x = self.convbnrelu1_2(x)\n        x = self.convbnrelu1_3(x)\n\n        # H/2, W/2 -> H/4, W/4\n        x = F.max_pool2d(x, 3, 2, 1)\n\n        # H/4, W/4 -> H/8, W/8\n        x = self.res_block2(x)\n        x = self.res_block3(x)\n        x = self.res_block4(x)\n\n        # Auxiliary layers for training\n        if self.training:\n            x_aux = self.convbnrelu4_aux(x)\n            x_aux = self.dropout(x_aux)\n            x_aux = self.aux_cls(x_aux)\n\n        x = self.res_block5(x)\n\n        x = self.pyramid_pooling(x)\n\n        x = self.cbr_final(x)\n        x = self.dropout(x)\n\n        x = self.classification(x)\n        x = F.interpolate(x, size=inp_shape, mode=""bilinear"", align_corners=True)\n\n        if self.training:\n            return (x, x_aux)\n        else:  # eval mode\n            return x\n\n    def load_pretrained_model(self, model_path):\n        """"""\n        Load weights from caffemodel w/o caffe dependency\n        and plug them in corresponding modules\n        """"""\n        # My eyes and my heart both hurt when writing this method\n\n        # Only care about layer_types that have trainable parameters\n        ltypes = [""BNData"", ""ConvolutionData"", ""HoleConvolutionData""]\n\n        def _get_layer_params(layer, ltype):\n\n            if ltype == ""BNData"":\n                gamma = np.array(layer.blobs[0].data)\n                beta = np.array(layer.blobs[1].data)\n                mean = np.array(layer.blobs[2].data)\n                var = np.array(layer.blobs[3].data)\n                return [mean, var, gamma, beta]\n\n            elif ltype in [""ConvolutionData"", ""HoleConvolutionData""]:\n                is_bias = layer.convolution_param.bias_term\n                weights = np.array(layer.blobs[0].data)\n                bias = []\n                if is_bias:\n                    bias = np.array(layer.blobs[1].data)\n                return [weights, bias]\n\n            elif ltype == ""InnerProduct"":\n                raise Exception(""Fully connected layers {}, not supported"".format(ltype))\n\n            else:\n                raise Exception(""Unkown layer type {}"".format(ltype))\n\n        net = caffe_pb2.NetParameter()\n        with open(model_path, ""rb"") as model_file:\n            net.MergeFromString(model_file.read())\n\n        # dict formatted as ->  key:<layer_name> :: value:<layer_type>\n        layer_types = {}\n        # dict formatted as ->  key:<layer_name> :: value:[<list_of_params>]\n        layer_params = {}\n\n        for l in net.layer:\n            lname = l.name\n            ltype = l.type\n            if ltype in ltypes:\n                print(""Processing layer {}"".format(lname))\n                layer_types[lname] = ltype\n                layer_params[lname] = _get_layer_params(l, ltype)\n\n        # Set affine=False for all batchnorm modules\n        def _no_affine_bn(module=None):\n            if isinstance(module, nn.BatchNorm2d):\n                module.affine = False\n\n            if len([m for m in module.children()]) > 0:\n                for child in module.children():\n                    _no_affine_bn(child)\n\n        # _no_affine_bn(self)\n\n        def _transfer_conv(layer_name, module):\n            weights, bias = layer_params[layer_name]\n            w_shape = np.array(module.weight.size())\n\n            print(\n                ""CONV {}: Original {} and trans weights {}"".format(\n                    layer_name, w_shape, weights.shape\n                )\n            )\n\n            module.weight.data.copy_(torch.from_numpy(weights).view_as(module.weight))\n\n            if len(bias) != 0:\n                b_shape = np.array(module.bias.size())\n                print(\n                    ""CONV {}: Original {} and trans bias {}"".format(layer_name, b_shape, bias.shape)\n                )\n                module.bias.data.copy_(torch.from_numpy(bias).view_as(module.bias))\n\n        def _transfer_conv_bn(conv_layer_name, mother_module):\n            conv_module = mother_module[0]\n            bn_module = mother_module[1]\n\n            _transfer_conv(conv_layer_name, conv_module)\n\n            mean, var, gamma, beta = layer_params[conv_layer_name + ""/bn""]\n            print(\n                ""BN {}: Original {} and trans weights {}"".format(\n                    conv_layer_name, bn_module.running_mean.size(), mean.shape\n                )\n            )\n            bn_module.running_mean.copy_(torch.from_numpy(mean).view_as(bn_module.running_mean))\n            bn_module.running_var.copy_(torch.from_numpy(var).view_as(bn_module.running_var))\n            bn_module.weight.data.copy_(torch.from_numpy(gamma).view_as(bn_module.weight))\n            bn_module.bias.data.copy_(torch.from_numpy(beta).view_as(bn_module.bias))\n\n        def _transfer_residual(prefix, block):\n            block_module, n_layers = block[0], block[1]\n\n            bottleneck = block_module.layers[0]\n            bottleneck_conv_bn_dic = {\n                prefix + ""_1_1x1_reduce"": bottleneck.cbr1.cbr_unit,\n                prefix + ""_1_3x3"": bottleneck.cbr2.cbr_unit,\n                prefix + ""_1_1x1_proj"": bottleneck.cb4.cb_unit,\n                prefix + ""_1_1x1_increase"": bottleneck.cb3.cb_unit,\n            }\n\n            for k, v in bottleneck_conv_bn_dic.items():\n                _transfer_conv_bn(k, v)\n\n            for layer_idx in range(2, n_layers + 1):\n                residual_layer = block_module.layers[layer_idx - 1]\n                residual_conv_bn_dic = {\n                    ""_"".join(\n                        map(str, [prefix, layer_idx, ""1x1_reduce""])\n                    ): residual_layer.cbr1.cbr_unit,\n                    ""_"".join(map(str, [prefix, layer_idx, ""3x3""])): residual_layer.cbr2.cbr_unit,\n                    ""_"".join(\n                        map(str, [prefix, layer_idx, ""1x1_increase""])\n                    ): residual_layer.cb3.cb_unit,\n                }\n\n                for k, v in residual_conv_bn_dic.items():\n                    _transfer_conv_bn(k, v)\n\n        convbn_layer_mapping = {\n            ""conv1_1_3x3_s2"": self.convbnrelu1_1.cbr_unit,\n            ""conv1_2_3x3"": self.convbnrelu1_2.cbr_unit,\n            ""conv1_3_3x3"": self.convbnrelu1_3.cbr_unit,\n            ""conv5_3_pool6_conv"": self.pyramid_pooling.paths[0].cbr_unit,\n            ""conv5_3_pool3_conv"": self.pyramid_pooling.paths[1].cbr_unit,\n            ""conv5_3_pool2_conv"": self.pyramid_pooling.paths[2].cbr_unit,\n            ""conv5_3_pool1_conv"": self.pyramid_pooling.paths[3].cbr_unit,\n            ""conv5_4"": self.cbr_final.cbr_unit,\n            ""conv4_"" + str(self.block_config[2] + 1): self.convbnrelu4_aux.cbr_unit,\n        }  # Auxiliary layers for training\n\n        residual_layers = {\n            ""conv2"": [self.res_block2, self.block_config[0]],\n            ""conv3"": [self.res_block3, self.block_config[1]],\n            ""conv4"": [self.res_block4, self.block_config[2]],\n            ""conv5"": [self.res_block5, self.block_config[3]],\n        }\n\n        # Transfer weights for all non-residual conv+bn layers\n        for k, v in convbn_layer_mapping.items():\n            _transfer_conv_bn(k, v)\n\n        # Transfer weights for final non-bn conv layer\n        _transfer_conv(""conv6"", self.classification)\n        _transfer_conv(""conv6_1"", self.aux_cls)\n\n        # Transfer weights for all residual layers\n        for k, v in residual_layers.items():\n            _transfer_residual(k, v)\n\n    def tile_predict(self, imgs, include_flip_mode=True):\n        """"""\n        Predict by takin overlapping tiles from the image.\n\n        Strides are adaptively computed from the imgs shape\n        and input size\n\n        :param imgs: torch.Tensor with shape [N, C, H, W] in BGR format\n        :param side: int with side length of model input\n        :param n_classes: int with number of classes in seg output.\n        """"""\n\n        side_x, side_y = self.input_size\n        n_classes = self.n_classes\n        n_samples, c, h, w = imgs.shape\n        # n = int(max(h,w) / float(side) + 1)\n        n_x = int(h / float(side_x) + 1)\n        n_y = int(w / float(side_y) + 1)\n        stride_x = (h - side_x) / float(n_x)\n        stride_y = (w - side_y) / float(n_y)\n\n        x_ends = [[int(i * stride_x), int(i * stride_x) + side_x] for i in range(n_x + 1)]\n        y_ends = [[int(i * stride_y), int(i * stride_y) + side_y] for i in range(n_y + 1)]\n\n        pred = np.zeros([n_samples, n_classes, h, w])\n        count = np.zeros([h, w])\n\n        slice_count = 0\n        for sx, ex in x_ends:\n            for sy, ey in y_ends:\n                slice_count += 1\n\n                imgs_slice = imgs[:, :, sx:ex, sy:ey]\n                if include_flip_mode:\n                    imgs_slice_flip = torch.from_numpy(\n                        np.copy(imgs_slice.cpu().numpy()[:, :, :, ::-1])\n                    ).float()\n\n                is_model_on_cuda = next(self.parameters()).is_cuda\n\n                inp = Variable(imgs_slice, volatile=True)\n                if include_flip_mode:\n                    flp = Variable(imgs_slice_flip, volatile=True)\n\n                if is_model_on_cuda:\n                    inp = inp.cuda()\n                    if include_flip_mode:\n                        flp = flp.cuda()\n\n                psub1 = F.softmax(self.forward(inp), dim=1).data.cpu().numpy()\n                if include_flip_mode:\n                    psub2 = F.softmax(self.forward(flp), dim=1).data.cpu().numpy()\n                    psub = (psub1 + psub2[:, :, :, ::-1]) / 2.0\n                else:\n                    psub = psub1\n\n                pred[:, :, sx:ex, sy:ey] = psub\n                count[sx:ex, sy:ey] += 1.0\n\n        score = (pred / count[None, None, ...]).astype(np.float32)\n        return score / np.expand_dims(score.sum(axis=1), axis=1)\n\n\n# For Testing Purposes only\nif __name__ == ""__main__"":\n    cd = 0\n    import os\n    import scipy.misc as m\n    from ptsemseg.loader.cityscapes_loader import cityscapesLoader as cl\n\n    psp = pspnet(version=""cityscapes"")\n\n    # Just need to do this one time\n    caffemodel_dir_path = ""PATH_TO_PSPNET_DIR/evaluation/model""\n    psp.load_pretrained_model(\n        model_path=os.path.join(caffemodel_dir_path, ""pspnet101_cityscapes.caffemodel"")\n    )\n    # psp.load_pretrained_model(model_path=os.path.join(caffemodel_dir_path,\n    #                            \'pspnet50_ADE20K.caffemodel\'))\n    # psp.load_pretrained_model(model_path=os.path.join(caffemodel_dir_path,\n    #                           \'pspnet101_VOC2012.caffemodel\'))\n    #\n    # psp.load_state_dict(torch.load(\'psp.pth\'))\n\n    psp.float()\n    psp.cuda(cd)\n    psp.eval()\n\n    dataset_root_dir = ""PATH_TO_CITYSCAPES_DIR""\n    dst = cl(root=dataset_root_dir)\n    img = m.imread(\n        os.path.join(\n            dataset_root_dir,\n            ""leftImg8bit/demoVideo/stuttgart_00/stuttgart_00_000000_000010_leftImg8bit.png"",\n        )\n    )\n    m.imsave(""cropped.png"", img)\n    orig_size = img.shape[:-1]\n    img = img.transpose(2, 0, 1)\n    img = img.astype(np.float64)\n    img -= np.array([123.68, 116.779, 103.939])[:, None, None]\n    img = np.copy(img[::-1, :, :])\n    img = torch.from_numpy(img).float()  # convert to torch tensor\n    img = img.unsqueeze(0)\n\n    out = psp.tile_predict(img)\n    pred = np.argmax(out, axis=1)[0]\n    decoded = dst.decode_segmap(pred)\n    m.imsave(""cityscapes_sttutgart_tiled.png"", decoded)\n    # m.imsave(\'cityscapes_sttutgart_tiled.png\', pred)\n\n    checkpoints_dir_path = ""checkpoints""\n    if not os.path.exists(checkpoints_dir_path):\n        os.mkdir(checkpoints_dir_path)\n    psp = torch.nn.DataParallel(\n        psp, device_ids=range(torch.cuda.device_count())\n    )  # append `module.`\n    state = {""model_state"": psp.state_dict()}\n    torch.save(state, os.path.join(checkpoints_dir_path, ""pspnet_101_cityscapes.pth""))\n    # torch.save(state, os.path.join(checkpoints_dir_path, ""pspnet_50_ade20k.pth""))\n    # torch.save(state, os.path.join(checkpoints_dir_path, ""pspnet_101_pascalvoc.pth""))\n    print(""Output Shape {} \\t Input Shape {}"".format(out.shape, img.shape))\n'"
ptsemseg/models/refinenet.py,1,"b'import torch.nn as nn\n\n\nclass refinenet(nn.Module):\n    """"""\n    RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation\n    URL: https://arxiv.org/abs/1611.06612\n\n    References:\n    1) Original Author\'s MATLAB code: https://github.com/guosheng/refinenet\n    2) TF implementation by @eragonruan: https://github.com/eragonruan/refinenet-image-segmentation\n    """"""\n\n    def __init__(self, n_classes=21):\n        super(refinenet, self).__init__()\n        self.n_classes = n_classes\n\n    def forward(self, x):\n        pass\n'"
ptsemseg/models/segnet.py,1,"b'import torch.nn as nn\n\nfrom ptsemseg.models.utils import segnetDown2, segnetDown3, segnetUp2, segnetUp3\n\n\nclass segnet(nn.Module):\n    def __init__(self, n_classes=21, in_channels=3, is_unpooling=True):\n        super(segnet, self).__init__()\n\n        self.in_channels = in_channels\n        self.is_unpooling = is_unpooling\n\n        self.down1 = segnetDown2(self.in_channels, 64)\n        self.down2 = segnetDown2(64, 128)\n        self.down3 = segnetDown3(128, 256)\n        self.down4 = segnetDown3(256, 512)\n        self.down5 = segnetDown3(512, 512)\n\n        self.up5 = segnetUp3(512, 512)\n        self.up4 = segnetUp3(512, 256)\n        self.up3 = segnetUp3(256, 128)\n        self.up2 = segnetUp2(128, 64)\n        self.up1 = segnetUp2(64, n_classes)\n\n    def forward(self, inputs):\n\n        down1, indices_1, unpool_shape1 = self.down1(inputs)\n        down2, indices_2, unpool_shape2 = self.down2(down1)\n        down3, indices_3, unpool_shape3 = self.down3(down2)\n        down4, indices_4, unpool_shape4 = self.down4(down3)\n        down5, indices_5, unpool_shape5 = self.down5(down4)\n\n        up5 = self.up5(down5, indices_5, unpool_shape5)\n        up4 = self.up4(up5, indices_4, unpool_shape4)\n        up3 = self.up3(up4, indices_3, unpool_shape3)\n        up2 = self.up2(up3, indices_2, unpool_shape2)\n        up1 = self.up1(up2, indices_1, unpool_shape1)\n\n        return up1\n\n    def init_vgg16_params(self, vgg16):\n        blocks = [self.down1, self.down2, self.down3, self.down4, self.down5]\n\n        features = list(vgg16.features.children())\n\n        vgg_layers = []\n        for _layer in features:\n            if isinstance(_layer, nn.Conv2d):\n                vgg_layers.append(_layer)\n\n        merged_layers = []\n        for idx, conv_block in enumerate(blocks):\n            if idx < 2:\n                units = [conv_block.conv1.cbr_unit, conv_block.conv2.cbr_unit]\n            else:\n                units = [\n                    conv_block.conv1.cbr_unit,\n                    conv_block.conv2.cbr_unit,\n                    conv_block.conv3.cbr_unit,\n                ]\n            for _unit in units:\n                for _layer in _unit:\n                    if isinstance(_layer, nn.Conv2d):\n                        merged_layers.append(_layer)\n\n        assert len(vgg_layers) == len(merged_layers)\n\n        for l1, l2 in zip(vgg_layers, merged_layers):\n            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n                assert l1.weight.size() == l2.weight.size()\n                assert l1.bias.size() == l2.bias.size()\n                l2.weight.data = l1.weight.data\n                l2.bias.data = l1.bias.data\n'"
ptsemseg/models/unet.py,1,"b'import torch.nn as nn\n\nfrom ptsemseg.models.utils import unetConv2, unetUp\n\n\nclass unet(nn.Module):\n    def __init__(\n        self, feature_scale=4, n_classes=21, is_deconv=True, in_channels=3, is_batchnorm=True\n    ):\n        super(unet, self).__init__()\n        self.is_deconv = is_deconv\n        self.in_channels = in_channels\n        self.is_batchnorm = is_batchnorm\n        self.feature_scale = feature_scale\n\n        filters = [64, 128, 256, 512, 1024]\n        filters = [int(x / self.feature_scale) for x in filters]\n\n        # downsampling\n        self.conv1 = unetConv2(self.in_channels, filters[0], self.is_batchnorm)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n\n        self.conv2 = unetConv2(filters[0], filters[1], self.is_batchnorm)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n\n        self.conv3 = unetConv2(filters[1], filters[2], self.is_batchnorm)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n\n        self.conv4 = unetConv2(filters[2], filters[3], self.is_batchnorm)\n        self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n\n        self.center = unetConv2(filters[3], filters[4], self.is_batchnorm)\n\n        # upsampling\n        self.up_concat4 = unetUp(filters[4], filters[3], self.is_deconv)\n        self.up_concat3 = unetUp(filters[3], filters[2], self.is_deconv)\n        self.up_concat2 = unetUp(filters[2], filters[1], self.is_deconv)\n        self.up_concat1 = unetUp(filters[1], filters[0], self.is_deconv)\n\n        # final conv (without any concat)\n        self.final = nn.Conv2d(filters[0], n_classes, 1)\n\n    def forward(self, inputs):\n        conv1 = self.conv1(inputs)\n        maxpool1 = self.maxpool1(conv1)\n\n        conv2 = self.conv2(maxpool1)\n        maxpool2 = self.maxpool2(conv2)\n\n        conv3 = self.conv3(maxpool2)\n        maxpool3 = self.maxpool3(conv3)\n\n        conv4 = self.conv4(maxpool3)\n        maxpool4 = self.maxpool4(conv4)\n\n        center = self.center(maxpool4)\n        up4 = self.up_concat4(conv4, center)\n        up3 = self.up_concat3(conv3, up4)\n        up2 = self.up_concat2(conv2, up3)\n        up1 = self.up_concat1(conv1, up2)\n\n        final = self.final(up1)\n\n        return final\n'"
ptsemseg/models/utils.py,11,"b'import torch\nimport torch.nn as nn\nimport numpy as np\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass conv2DBatchNorm(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        n_filters,\n        k_size,\n        stride,\n        padding,\n        bias=True,\n        dilation=1,\n        is_batchnorm=True,\n    ):\n        super(conv2DBatchNorm, self).__init__()\n\n        conv_mod = nn.Conv2d(\n            int(in_channels),\n            int(n_filters),\n            kernel_size=k_size,\n            padding=padding,\n            stride=stride,\n            bias=bias,\n            dilation=dilation,\n        )\n\n        if is_batchnorm:\n            self.cb_unit = nn.Sequential(conv_mod, nn.BatchNorm2d(int(n_filters)))\n        else:\n            self.cb_unit = nn.Sequential(conv_mod)\n\n    def forward(self, inputs):\n        outputs = self.cb_unit(inputs)\n        return outputs\n\n\nclass conv2DGroupNorm(nn.Module):\n    def __init__(\n        self, in_channels, n_filters, k_size, stride, padding, bias=True, dilation=1, n_groups=16\n    ):\n        super(conv2DGroupNorm, self).__init__()\n\n        conv_mod = nn.Conv2d(\n            int(in_channels),\n            int(n_filters),\n            kernel_size=k_size,\n            padding=padding,\n            stride=stride,\n            bias=bias,\n            dilation=dilation,\n        )\n\n        self.cg_unit = nn.Sequential(conv_mod, nn.GroupNorm(n_groups, int(n_filters)))\n\n    def forward(self, inputs):\n        outputs = self.cg_unit(inputs)\n        return outputs\n\n\nclass deconv2DBatchNorm(nn.Module):\n    def __init__(self, in_channels, n_filters, k_size, stride, padding, bias=True):\n        super(deconv2DBatchNorm, self).__init__()\n\n        self.dcb_unit = nn.Sequential(\n            nn.ConvTranspose2d(\n                int(in_channels),\n                int(n_filters),\n                kernel_size=k_size,\n                padding=padding,\n                stride=stride,\n                bias=bias,\n            ),\n            nn.BatchNorm2d(int(n_filters)),\n        )\n\n    def forward(self, inputs):\n        outputs = self.dcb_unit(inputs)\n        return outputs\n\n\nclass conv2DBatchNormRelu(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        n_filters,\n        k_size,\n        stride,\n        padding,\n        bias=True,\n        dilation=1,\n        is_batchnorm=True,\n    ):\n        super(conv2DBatchNormRelu, self).__init__()\n\n        conv_mod = nn.Conv2d(\n            int(in_channels),\n            int(n_filters),\n            kernel_size=k_size,\n            padding=padding,\n            stride=stride,\n            bias=bias,\n            dilation=dilation,\n        )\n\n        if is_batchnorm:\n            self.cbr_unit = nn.Sequential(\n                conv_mod, nn.BatchNorm2d(int(n_filters)), nn.ReLU(inplace=True)\n            )\n        else:\n            self.cbr_unit = nn.Sequential(conv_mod, nn.ReLU(inplace=True))\n\n    def forward(self, inputs):\n        outputs = self.cbr_unit(inputs)\n        return outputs\n\n\nclass conv2DGroupNormRelu(nn.Module):\n    def __init__(\n        self, in_channels, n_filters, k_size, stride, padding, bias=True, dilation=1, n_groups=16\n    ):\n        super(conv2DGroupNormRelu, self).__init__()\n\n        conv_mod = nn.Conv2d(\n            int(in_channels),\n            int(n_filters),\n            kernel_size=k_size,\n            padding=padding,\n            stride=stride,\n            bias=bias,\n            dilation=dilation,\n        )\n\n        self.cgr_unit = nn.Sequential(\n            conv_mod, nn.GroupNorm(n_groups, int(n_filters)), nn.ReLU(inplace=True)\n        )\n\n    def forward(self, inputs):\n        outputs = self.cgr_unit(inputs)\n        return outputs\n\n\nclass deconv2DBatchNormRelu(nn.Module):\n    def __init__(self, in_channels, n_filters, k_size, stride, padding, bias=True):\n        super(deconv2DBatchNormRelu, self).__init__()\n\n        self.dcbr_unit = nn.Sequential(\n            nn.ConvTranspose2d(\n                int(in_channels),\n                int(n_filters),\n                kernel_size=k_size,\n                padding=padding,\n                stride=stride,\n                bias=bias,\n            ),\n            nn.BatchNorm2d(int(n_filters)),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, inputs):\n        outputs = self.dcbr_unit(inputs)\n        return outputs\n\n\nclass unetConv2(nn.Module):\n    def __init__(self, in_size, out_size, is_batchnorm):\n        super(unetConv2, self).__init__()\n\n        if is_batchnorm:\n            self.conv1 = nn.Sequential(\n                nn.Conv2d(in_size, out_size, 3, 1, 0), nn.BatchNorm2d(out_size), nn.ReLU()\n            )\n            self.conv2 = nn.Sequential(\n                nn.Conv2d(out_size, out_size, 3, 1, 0), nn.BatchNorm2d(out_size), nn.ReLU()\n            )\n        else:\n            self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, 3, 1, 0), nn.ReLU())\n            self.conv2 = nn.Sequential(nn.Conv2d(out_size, out_size, 3, 1, 0), nn.ReLU())\n\n    def forward(self, inputs):\n        outputs = self.conv1(inputs)\n        outputs = self.conv2(outputs)\n        return outputs\n\n\nclass unetUp(nn.Module):\n    def __init__(self, in_size, out_size, is_deconv):\n        super(unetUp, self).__init__()\n        self.conv = unetConv2(in_size, out_size, False)\n        if is_deconv:\n            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n        else:\n            self.up = nn.UpsamplingBilinear2d(scale_factor=2)\n\n    def forward(self, inputs1, inputs2):\n        outputs2 = self.up(inputs2)\n        offset = outputs2.size()[2] - inputs1.size()[2]\n        padding = 2 * [offset // 2, offset // 2]\n        outputs1 = F.pad(inputs1, padding)\n        return self.conv(torch.cat([outputs1, outputs2], 1))\n\n\nclass segnetDown2(nn.Module):\n    def __init__(self, in_size, out_size):\n        super(segnetDown2, self).__init__()\n        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n\n    def forward(self, inputs):\n        outputs = self.conv1(inputs)\n        outputs = self.conv2(outputs)\n        unpooled_shape = outputs.size()\n        outputs, indices = self.maxpool_with_argmax(outputs)\n        return outputs, indices, unpooled_shape\n\n\nclass segnetDown3(nn.Module):\n    def __init__(self, in_size, out_size):\n        super(segnetDown3, self).__init__()\n        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n        self.conv3 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n\n    def forward(self, inputs):\n        outputs = self.conv1(inputs)\n        outputs = self.conv2(outputs)\n        outputs = self.conv3(outputs)\n        unpooled_shape = outputs.size()\n        outputs, indices = self.maxpool_with_argmax(outputs)\n        return outputs, indices, unpooled_shape\n\n\nclass segnetUp2(nn.Module):\n    def __init__(self, in_size, out_size):\n        super(segnetUp2, self).__init__()\n        self.unpool = nn.MaxUnpool2d(2, 2)\n        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n        self.conv2 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n\n    def forward(self, inputs, indices, output_shape):\n        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n        outputs = self.conv1(outputs)\n        outputs = self.conv2(outputs)\n        return outputs\n\n\nclass segnetUp3(nn.Module):\n    def __init__(self, in_size, out_size):\n        super(segnetUp3, self).__init__()\n        self.unpool = nn.MaxUnpool2d(2, 2)\n        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n        self.conv2 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n        self.conv3 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n\n    def forward(self, inputs, indices, output_shape):\n        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n        outputs = self.conv1(outputs)\n        outputs = self.conv2(outputs)\n        outputs = self.conv3(outputs)\n        return outputs\n\n\nclass residualBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_channels, n_filters, stride=1, downsample=None):\n        super(residualBlock, self).__init__()\n\n        self.convbnrelu1 = conv2DBatchNormRelu(in_channels, n_filters, 3, stride, 1, bias=False)\n        self.convbn2 = conv2DBatchNorm(n_filters, n_filters, 3, 1, 1, bias=False)\n        self.downsample = downsample\n        self.stride = stride\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        residual = x\n\n        out = self.convbnrelu1(x)\n        out = self.convbn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass residualBottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_channels, n_filters, stride=1, downsample=None):\n        super(residualBottleneck, self).__init__()\n        self.convbn1 = nn.Conv2DBatchNorm(in_channels, n_filters, k_size=1, bias=False)\n        self.convbn2 = nn.Conv2DBatchNorm(\n            n_filters, n_filters, k_size=3, padding=1, stride=stride, bias=False\n        )\n        self.convbn3 = nn.Conv2DBatchNorm(n_filters, n_filters * 4, k_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.convbn1(x)\n        out = self.convbn2(out)\n        out = self.convbn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass linknetUp(nn.Module):\n    def __init__(self, in_channels, n_filters):\n        super(linknetUp, self).__init__()\n\n        # B, 2C, H, W -> B, C/2, H, W\n        self.convbnrelu1 = conv2DBatchNormRelu(\n            in_channels, n_filters / 2, k_size=1, stride=1, padding=1\n        )\n\n        # B, C/2, H, W -> B, C/2, H, W\n        self.deconvbnrelu2 = nn.deconv2DBatchNormRelu(\n            n_filters / 2, n_filters / 2, k_size=3, stride=2, padding=0\n        )\n\n        # B, C/2, H, W -> B, C, H, W\n        self.convbnrelu3 = conv2DBatchNormRelu(\n            n_filters / 2, n_filters, k_size=1, stride=1, padding=1\n        )\n\n    def forward(self, x):\n        x = self.convbnrelu1(x)\n        x = self.deconvbnrelu2(x)\n        x = self.convbnrelu3(x)\n        return x\n\n\nclass FRRU(nn.Module):\n    """"""\n    Full Resolution Residual Unit for FRRN\n    """"""\n\n    def __init__(self, prev_channels, out_channels, scale, group_norm=False, n_groups=None):\n        super(FRRU, self).__init__()\n        self.scale = scale\n        self.prev_channels = prev_channels\n        self.out_channels = out_channels\n        self.group_norm = group_norm\n        self.n_groups = n_groups\n\n        if self.group_norm:\n            conv_unit = conv2DGroupNormRelu\n            self.conv1 = conv_unit(\n                prev_channels + 32,\n                out_channels,\n                k_size=3,\n                stride=1,\n                padding=1,\n                bias=False,\n                n_groups=self.n_groups,\n            )\n            self.conv2 = conv_unit(\n                out_channels,\n                out_channels,\n                k_size=3,\n                stride=1,\n                padding=1,\n                bias=False,\n                n_groups=self.n_groups,\n            )\n\n        else:\n            conv_unit = conv2DBatchNormRelu\n            self.conv1 = conv_unit(\n                prev_channels + 32, out_channels, k_size=3, stride=1, padding=1, bias=False\n            )\n            self.conv2 = conv_unit(\n                out_channels, out_channels, k_size=3, stride=1, padding=1, bias=False\n            )\n\n        self.conv_res = nn.Conv2d(out_channels, 32, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, y, z):\n        x = torch.cat([y, nn.MaxPool2d(self.scale, self.scale)(z)], dim=1)\n        y_prime = self.conv1(x)\n        y_prime = self.conv2(y_prime)\n\n        x = self.conv_res(y_prime)\n        upsample_size = torch.Size([_s * self.scale for _s in y_prime.shape[-2:]])\n        x = F.upsample(x, size=upsample_size, mode=""nearest"")\n        z_prime = z + x\n\n        return y_prime, z_prime\n\n\nclass RU(nn.Module):\n    """"""\n    Residual Unit for FRRN\n    """"""\n\n    def __init__(self, channels, kernel_size=3, strides=1, group_norm=False, n_groups=None):\n        super(RU, self).__init__()\n        self.group_norm = group_norm\n        self.n_groups = n_groups\n\n        if self.group_norm:\n            self.conv1 = conv2DGroupNormRelu(\n                channels,\n                channels,\n                k_size=kernel_size,\n                stride=strides,\n                padding=1,\n                bias=False,\n                n_groups=self.n_groups,\n            )\n            self.conv2 = conv2DGroupNorm(\n                channels,\n                channels,\n                k_size=kernel_size,\n                stride=strides,\n                padding=1,\n                bias=False,\n                n_groups=self.n_groups,\n            )\n\n        else:\n            self.conv1 = conv2DBatchNormRelu(\n                channels, channels, k_size=kernel_size, stride=strides, padding=1, bias=False\n            )\n            self.conv2 = conv2DBatchNorm(\n                channels, channels, k_size=kernel_size, stride=strides, padding=1, bias=False\n            )\n\n    def forward(self, x):\n        incoming = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return x + incoming\n\n\nclass residualConvUnit(nn.Module):\n    def __init__(self, channels, kernel_size=3):\n        super(residualConvUnit, self).__init__()\n\n        self.residual_conv_unit = nn.Sequential(\n            nn.ReLU(inplace=True),\n            nn.Conv2d(channels, channels, kernel_size=kernel_size),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(channels, channels, kernel_size=kernel_size),\n        )\n\n    def forward(self, x):\n        input = x\n        x = self.residual_conv_unit(x)\n        return x + input\n\n\nclass multiResolutionFusion(nn.Module):\n    def __init__(self, channels, up_scale_high, up_scale_low, high_shape, low_shape):\n        super(multiResolutionFusion, self).__init__()\n\n        self.up_scale_high = up_scale_high\n        self.up_scale_low = up_scale_low\n\n        self.conv_high = nn.Conv2d(high_shape[1], channels, kernel_size=3)\n\n        if low_shape is not None:\n            self.conv_low = nn.Conv2d(low_shape[1], channels, kernel_size=3)\n\n    def forward(self, x_high, x_low):\n        high_upsampled = F.upsample(\n            self.conv_high(x_high), scale_factor=self.up_scale_high, mode=""bilinear""\n        )\n\n        if x_low is None:\n            return high_upsampled\n\n        low_upsampled = F.upsample(\n            self.conv_low(x_low), scale_factor=self.up_scale_low, mode=""bilinear""\n        )\n\n        return low_upsampled + high_upsampled\n\n\nclass chainedResidualPooling(nn.Module):\n    def __init__(self, channels, input_shape):\n        super(chainedResidualPooling, self).__init__()\n\n        self.chained_residual_pooling = nn.Sequential(\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(5, 1, 2),\n            nn.Conv2d(input_shape[1], channels, kernel_size=3),\n        )\n\n    def forward(self, x):\n        input = x\n        x = self.chained_residual_pooling(x)\n        return x + input\n\n\nclass pyramidPooling(nn.Module):\n    def __init__(\n        self, in_channels, pool_sizes, model_name=""pspnet"", fusion_mode=""cat"", is_batchnorm=True\n    ):\n        super(pyramidPooling, self).__init__()\n\n        bias = not is_batchnorm\n\n        self.paths = []\n        for i in range(len(pool_sizes)):\n            self.paths.append(\n                conv2DBatchNormRelu(\n                    in_channels,\n                    int(in_channels / len(pool_sizes)),\n                    1,\n                    1,\n                    0,\n                    bias=bias,\n                    is_batchnorm=is_batchnorm,\n                )\n            )\n\n        self.path_module_list = nn.ModuleList(self.paths)\n        self.pool_sizes = pool_sizes\n        self.model_name = model_name\n        self.fusion_mode = fusion_mode\n\n    def forward(self, x):\n        h, w = x.shape[2:]\n\n        if self.training or self.model_name != ""icnet"":  # general settings or pspnet\n            k_sizes = []\n            strides = []\n            for pool_size in self.pool_sizes:\n                k_sizes.append((int(h / pool_size), int(w / pool_size)))\n                strides.append((int(h / pool_size), int(w / pool_size)))\n        else:  # eval mode and icnet: pre-trained for 1025 x 2049\n            k_sizes = [(8, 15), (13, 25), (17, 33), (33, 65)]\n            strides = [(5, 10), (10, 20), (16, 32), (33, 65)]\n\n        if self.fusion_mode == ""cat"":  # pspnet: concat (including x)\n            output_slices = [x]\n\n            for i, (module, pool_size) in enumerate(zip(self.path_module_list, self.pool_sizes)):\n                out = F.avg_pool2d(x, k_sizes[i], stride=strides[i], padding=0)\n                # out = F.adaptive_avg_pool2d(x, output_size=(pool_size, pool_size))\n                if self.model_name != ""icnet"":\n                    out = module(out)\n                out = F.interpolate(out, size=(h, w), mode=""bilinear"", align_corners=True)\n                output_slices.append(out)\n\n            return torch.cat(output_slices, dim=1)\n        else:  # icnet: element-wise sum (including x)\n            pp_sum = x\n\n            for i, (module, pool_size) in enumerate(zip(self.path_module_list, self.pool_sizes)):\n                out = F.avg_pool2d(x, k_sizes[i], stride=strides[i], padding=0)\n                # out = F.adaptive_avg_pool2d(x, output_size=(pool_size, pool_size))\n                if self.model_name != ""icnet"":\n                    out = module(out)\n                out = F.interpolate(out, size=(h, w), mode=""bilinear"", align_corners=True)\n                pp_sum = pp_sum + out\n\n            return pp_sum\n\n\nclass bottleNeckPSP(nn.Module):\n    def __init__(\n        self, in_channels, mid_channels, out_channels, stride, dilation=1, is_batchnorm=True\n    ):\n        super(bottleNeckPSP, self).__init__()\n\n        bias = not is_batchnorm\n\n        self.cbr1 = conv2DBatchNormRelu(\n            in_channels, mid_channels, 1, stride=1, padding=0, bias=bias, is_batchnorm=is_batchnorm\n        )\n        if dilation > 1:\n            self.cbr2 = conv2DBatchNormRelu(\n                mid_channels,\n                mid_channels,\n                3,\n                stride=stride,\n                padding=dilation,\n                bias=bias,\n                dilation=dilation,\n                is_batchnorm=is_batchnorm,\n            )\n        else:\n            self.cbr2 = conv2DBatchNormRelu(\n                mid_channels,\n                mid_channels,\n                3,\n                stride=stride,\n                padding=1,\n                bias=bias,\n                dilation=1,\n                is_batchnorm=is_batchnorm,\n            )\n        self.cb3 = conv2DBatchNorm(\n            mid_channels, out_channels, 1, stride=1, padding=0, bias=bias, is_batchnorm=is_batchnorm\n        )\n        self.cb4 = conv2DBatchNorm(\n            in_channels,\n            out_channels,\n            1,\n            stride=stride,\n            padding=0,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n\n    def forward(self, x):\n        conv = self.cb3(self.cbr2(self.cbr1(x)))\n        residual = self.cb4(x)\n        return F.relu(conv + residual, inplace=True)\n\n\nclass bottleNeckIdentifyPSP(nn.Module):\n    def __init__(self, in_channels, mid_channels, stride, dilation=1, is_batchnorm=True):\n        super(bottleNeckIdentifyPSP, self).__init__()\n\n        bias = not is_batchnorm\n\n        self.cbr1 = conv2DBatchNormRelu(\n            in_channels, mid_channels, 1, stride=1, padding=0, bias=bias, is_batchnorm=is_batchnorm\n        )\n        if dilation > 1:\n            self.cbr2 = conv2DBatchNormRelu(\n                mid_channels,\n                mid_channels,\n                3,\n                stride=1,\n                padding=dilation,\n                bias=bias,\n                dilation=dilation,\n                is_batchnorm=is_batchnorm,\n            )\n        else:\n            self.cbr2 = conv2DBatchNormRelu(\n                mid_channels,\n                mid_channels,\n                3,\n                stride=1,\n                padding=1,\n                bias=bias,\n                dilation=1,\n                is_batchnorm=is_batchnorm,\n            )\n        self.cb3 = conv2DBatchNorm(\n            mid_channels, in_channels, 1, stride=1, padding=0, bias=bias, is_batchnorm=is_batchnorm\n        )\n\n    def forward(self, x):\n        residual = x\n        x = self.cb3(self.cbr2(self.cbr1(x)))\n        return F.relu(x + residual, inplace=True)\n\n\nclass residualBlockPSP(nn.Module):\n    def __init__(\n        self,\n        n_blocks,\n        in_channels,\n        mid_channels,\n        out_channels,\n        stride,\n        dilation=1,\n        include_range=""all"",\n        is_batchnorm=True,\n    ):\n        super(residualBlockPSP, self).__init__()\n\n        if dilation > 1:\n            stride = 1\n\n        # residualBlockPSP = convBlockPSP + identityBlockPSPs\n        layers = []\n        if include_range in [""all"", ""conv""]:\n            layers.append(\n                bottleNeckPSP(\n                    in_channels,\n                    mid_channels,\n                    out_channels,\n                    stride,\n                    dilation,\n                    is_batchnorm=is_batchnorm,\n                )\n            )\n        if include_range in [""all"", ""identity""]:\n            for i in range(n_blocks - 1):\n                layers.append(\n                    bottleNeckIdentifyPSP(\n                        out_channels, mid_channels, stride, dilation, is_batchnorm=is_batchnorm\n                    )\n                )\n\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.layers(x)\n\n\nclass cascadeFeatureFusion(nn.Module):\n    def __init__(\n        self, n_classes, low_in_channels, high_in_channels, out_channels, is_batchnorm=True\n    ):\n        super(cascadeFeatureFusion, self).__init__()\n\n        bias = not is_batchnorm\n\n        self.low_dilated_conv_bn = conv2DBatchNorm(\n            low_in_channels,\n            out_channels,\n            3,\n            stride=1,\n            padding=2,\n            bias=bias,\n            dilation=2,\n            is_batchnorm=is_batchnorm,\n        )\n        self.low_classifier_conv = nn.Conv2d(\n            int(low_in_channels),\n            int(n_classes),\n            kernel_size=1,\n            padding=0,\n            stride=1,\n            bias=True,\n            dilation=1,\n        )  # Train only\n        self.high_proj_conv_bn = conv2DBatchNorm(\n            high_in_channels,\n            out_channels,\n            1,\n            stride=1,\n            padding=0,\n            bias=bias,\n            is_batchnorm=is_batchnorm,\n        )\n\n    def forward(self, x_low, x_high):\n        x_low_upsampled = F.interpolate(\n            x_low, size=get_interp_size(x_low, z_factor=2), mode=""bilinear"", align_corners=True\n        )\n\n        low_cls = self.low_classifier_conv(x_low_upsampled)\n\n        low_fm = self.low_dilated_conv_bn(x_low_upsampled)\n        high_fm = self.high_proj_conv_bn(x_high)\n        high_fused_fm = F.relu(low_fm + high_fm, inplace=True)\n\n        return high_fused_fm, low_cls\n\n\ndef get_interp_size(input, s_factor=1, z_factor=1):  # for caffe\n    ori_h, ori_w = input.shape[2:]\n\n    # shrink (s_factor >= 1)\n    ori_h = (ori_h - 1) / s_factor + 1\n    ori_w = (ori_w - 1) / s_factor + 1\n\n    # zoom (z_factor >= 1)\n    ori_h = ori_h + (ori_h - 1) * (z_factor - 1)\n    ori_w = ori_w + (ori_w - 1) * (z_factor - 1)\n\n    resize_shape = (int(ori_h), int(ori_w))\n    return resize_shape\n\n\ndef interp(input, output_size, mode=""bilinear""):\n    n, c, ih, iw = input.shape\n    oh, ow = output_size\n\n    # normalize to [-1, 1]\n    h = torch.arange(0, oh, dtype=torch.float, device=input.device) / (oh - 1) * 2 - 1\n    w = torch.arange(0, ow, dtype=torch.float, device=input.device) / (ow - 1) * 2 - 1\n\n    grid = torch.zeros(oh, ow, 2, dtype=torch.float, device=input.device)\n    grid[:, :, 0] = w.unsqueeze(0).repeat(oh, 1)\n    grid[:, :, 1] = h.unsqueeze(0).repeat(ow, 1).transpose(0, 1)\n    grid = grid.unsqueeze(0).repeat(n, 1, 1, 1)  # grid.shape: [n, oh, ow, 2]\n    grid = Variable(grid)\n    if input.is_cuda:\n        grid = grid.cuda()\n\n    return F.grid_sample(input, grid, mode=mode)\n\n\ndef get_upsampling_weight(in_channels, out_channels, kernel_size):\n    """"""Make a 2D bilinear kernel suitable for upsampling""""""\n    factor = (kernel_size + 1) // 2\n    if kernel_size % 2 == 1:\n        center = factor - 1\n    else:\n        center = factor - 0.5\n    og = np.ogrid[:kernel_size, :kernel_size]\n    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float64)\n    weight[range(in_channels), range(out_channels), :, :] = filt\n    return torch.from_numpy(weight).float()\n'"
ptsemseg/optimizers/__init__.py,1,"b'import logging\n\nfrom torch.optim import SGD, Adam, ASGD, Adamax, Adadelta, Adagrad, RMSprop\n\nlogger = logging.getLogger(""ptsemseg"")\n\nkey2opt = {\n    ""sgd"": SGD,\n    ""adam"": Adam,\n    ""asgd"": ASGD,\n    ""adamax"": Adamax,\n    ""adadelta"": Adadelta,\n    ""adagrad"": Adagrad,\n    ""rmsprop"": RMSprop,\n}\n\n\ndef get_optimizer(cfg):\n    if cfg[""training""][""optimizer""] is None:\n        logger.info(""Using SGD optimizer"")\n        return SGD\n\n    else:\n        opt_name = cfg[""training""][""optimizer""][""name""]\n        if opt_name not in key2opt:\n            raise NotImplementedError(""Optimizer {} not implemented"".format(opt_name))\n\n        logger.info(""Using {} optimizer"".format(opt_name))\n        return key2opt[opt_name]\n'"
ptsemseg/schedulers/__init__.py,1,"b'import logging\n\nfrom torch.optim.lr_scheduler import MultiStepLR, ExponentialLR, CosineAnnealingLR\n\nfrom ptsemseg.schedulers.schedulers import WarmUpLR, ConstantLR, PolynomialLR\n\nlogger = logging.getLogger(""ptsemseg"")\n\nkey2scheduler = {\n    ""constant_lr"": ConstantLR,\n    ""poly_lr"": PolynomialLR,\n    ""multi_step"": MultiStepLR,\n    ""cosine_annealing"": CosineAnnealingLR,\n    ""exp_lr"": ExponentialLR,\n}\n\n\ndef get_scheduler(optimizer, scheduler_dict):\n    if scheduler_dict is None:\n        logger.info(""Using No LR Scheduling"")\n        return ConstantLR(optimizer)\n\n    s_type = scheduler_dict[""name""]\n    scheduler_dict.pop(""name"")\n\n    logging.info(""Using {} scheduler with {} params"".format(s_type, scheduler_dict))\n\n    warmup_dict = {}\n    if ""warmup_iters"" in scheduler_dict:\n        # This can be done in a more pythonic way...\n        warmup_dict[""warmup_iters""] = scheduler_dict.get(""warmup_iters"", 100)\n        warmup_dict[""mode""] = scheduler_dict.get(""warmup_mode"", ""linear"")\n        warmup_dict[""gamma""] = scheduler_dict.get(""warmup_factor"", 0.2)\n\n        logger.info(\n            ""Using Warmup with {} iters {} gamma and {} mode"".format(\n                warmup_dict[""warmup_iters""], warmup_dict[""gamma""], warmup_dict[""mode""]\n            )\n        )\n\n        scheduler_dict.pop(""warmup_iters"", None)\n        scheduler_dict.pop(""warmup_mode"", None)\n        scheduler_dict.pop(""warmup_factor"", None)\n\n        base_scheduler = key2scheduler[s_type](optimizer, **scheduler_dict)\n        return WarmUpLR(optimizer, base_scheduler, **warmup_dict)\n\n    return key2scheduler[s_type](optimizer, **scheduler_dict)\n'"
ptsemseg/schedulers/schedulers.py,1,"b'from torch.optim.lr_scheduler import _LRScheduler\n\n\nclass ConstantLR(_LRScheduler):\n    def __init__(self, optimizer, last_epoch=-1):\n        super(ConstantLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        return [base_lr for base_lr in self.base_lrs]\n\n\nclass PolynomialLR(_LRScheduler):\n    def __init__(self, optimizer, max_iter, decay_iter=1, gamma=0.9, last_epoch=-1):\n        self.decay_iter = decay_iter\n        self.max_iter = max_iter\n        self.gamma = gamma\n        super(PolynomialLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        if self.last_epoch % self.decay_iter or self.last_epoch % self.max_iter:\n            return [base_lr for base_lr in self.base_lrs]\n        else:\n            factor = (1 - self.last_epoch / float(self.max_iter)) ** self.gamma\n            return [base_lr * factor for base_lr in self.base_lrs]\n\n\nclass WarmUpLR(_LRScheduler):\n    def __init__(\n        self, optimizer, scheduler, mode=""linear"", warmup_iters=100, gamma=0.2, last_epoch=-1\n    ):\n        self.mode = mode\n        self.scheduler = scheduler\n        self.warmup_iters = warmup_iters\n        self.gamma = gamma\n        super(WarmUpLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        cold_lrs = self.scheduler.get_lr()\n\n        if self.last_epoch < self.warmup_iters:\n            if self.mode == ""linear"":\n                alpha = self.last_epoch / float(self.warmup_iters)\n                factor = self.gamma * (1 - alpha) + alpha\n\n            elif self.mode == ""constant"":\n                factor = self.gamma\n            else:\n                raise KeyError(""WarmUp type {} not implemented"".format(self.mode))\n\n            return [factor * base_lr for base_lr in cold_lrs]\n\n        return cold_lrs\n'"
