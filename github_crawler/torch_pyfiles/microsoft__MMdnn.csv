file_path,api_count,code
setup.py,0,"b'from __future__ import absolute_import\nfrom setuptools import setup, find_packages\nfrom io import open\n\n# Get the long description from the README file\nwith open(\'README.md\', encoding=\'utf-8\') as f:\n    long_description = f.read()\n\nsetup(\n    name=\'mmdnn\',\n\n    # Versions should comply with PEP440.  For a discussion on single-sourcing\n    # the version across setup.py and the project code, see\n    # https://packaging.python.org/en/latest/single_source_version.html\n    version=\'0.3.0\',\n\n    description=\'Deep learning model converter, visualization and editor.\',\n    long_description=long_description,\n    long_description_content_type=\'text/markdown\',\n\n    # The project\'s main homepage.\n    url=\'https://github.com/Microsoft/MMdnn\',\n\n    # Author details\n    author = \'System Research Group, Microsoft Research Asia\',\n    author_email=\'mmdnn_feedback@microsoft.com\',\n\n    # Choose your license\n    license=\'MIT\',\n\n    # See https://pypi.python.org/pypi?%3Aaction=list_classifiers\n    classifiers=[\n        # How mature is this project? Common values are\n        #   3 - Alpha\n        #   4 - Beta\n        #   5 - Production/Stable\n        \'Development Status :: 3 - Alpha\',\n\n        # Indicate who your project is intended for\n        \'Intended Audience :: Developers\',\n        \'Intended Audience :: Education\',\n        \'Intended Audience :: Science/Research\',\n        \'Topic :: Scientific/Engineering :: Mathematics\',\n        \'Topic :: Software Development :: Libraries :: Python Modules\',\n        \'Topic :: Software Development :: Libraries\',\n\n        # Pick your license as you wish (should match ""license"" above)\n        \'License :: OSI Approved :: MIT License\',\n\n        # Specify the Python versions you support here. In particular, ensure\n        # that you indicate whether you support Python 2, Python 3 or both.\n        \'Programming Language :: Python :: 2\',\n        \'Programming Language :: Python :: 3\'\n    ],\n\n    # What does your project relate to?\n    keywords=\'deep learning model converter visualization\',\n\n    # You can just specify the packages manually here if your project is\n    # simple. Or you can use find_packages().\n    packages=find_packages(),\n\n    package_data={\n        \'mmdnn\':[\'visualization/public/*\',\n                \'visualization/*.json\',\n                \'visualization/*.js\',\n                \'visualization/*.html\',\n                \'visualization/*.css\']\n    },\n\n    # Alternatively, if you want to distribute just a my_module.py, uncomment\n    # this:\n    #   py_modules=[""my_module""],\n\n    # List run-time dependencies here.  These will be installed by pip when\n    # your project is installed. For an analysis of ""install_requires"" vs pip\'s\n    # requirements files see:\n    # https://packaging.python.org/en/latest/requirements.html\n    install_requires=[\n        \'numpy >= 1.15.0\',\n        \'protobuf >= 3.6.0\',\n        \'six >= 1.10.0\',\n        \'pillow >= 6.2.1\',\n    ],\n\n    # To provide executable scripts, use entry points in preference to the\n    # ""scripts"" keyword. Entry points provide cross-platform support and allow\n    # pip to create the appropriate form of executable for the target platform.\n    entry_points={\n        \'console_scripts\': [\n            \'mmconvert  = mmdnn.conversion._script.convert:_main\',\n            \'mmdownload = mmdnn.conversion._script.extractModel:_main\',\n            \'mmvismeta  = mmdnn.conversion.examples.tensorflow.vis_meta:_main\',\n            \'mmtoir     = mmdnn.conversion._script.convertToIR:_main\',\n            \'mmtocode   = mmdnn.conversion._script.IRToCode:_main\',\n            \'mmtomodel  = mmdnn.conversion._script.dump_code:_main\',\n        ],\n    },\n)\n'"
docs/client.py,0,"b""'''\nSend JPEG image to tensorflow_model_server loaded with GAN model.\n\nHint: the code has been compiled together with TensorFlow serving\nand not locally. The client is called in the TensorFlow Docker container\n'''\n\nfrom __future__ import print_function\n\n# Communication to TensorFlow server via gRPC\nfrom grpc.beta import implementations\nimport tensorflow as tf\n\n# TensorFlow serving stuff to send messages\nfrom tensorflow_serving.apis import predict_pb2\nfrom tensorflow_serving.apis import prediction_service_pb2\n\n\n# Command line arguments\ntf.app.flags.DEFINE_string('server', 'localhost:9000',\n                           'PredictionService host:port')\ntf.app.flags.DEFINE_string('image', '', 'path to image in JPEG format')\nFLAGS = tf.app.flags.FLAGS\n\n\ndef main(_):\n    host, port = FLAGS.server.split(':')\n    channel = implementations.insecure_channel(host, int(port))\n    stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n    # Send request\n    image = tf.gfile.FastGFile(FLAGS.image, 'rb').read()\n    request = predict_pb2.PredictRequest()\n    request.model_spec.name = 'tensorflow-serving'\n    request.model_spec.signature_name = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n    request.inputs['image'].CopyFrom(tf.contrib.util.make_tensor_proto(image))\n    #request.inputs['input'].CopyFrom()\n\n    result = stub.Predict(request, 10.0)  # 10 secs timeout\n    print(result)\n\n\nif __name__ == '__main__':\n    tf.app.run()\n"""
mmdnn/__init__.py,0,b''
requirements/select_requirements.py,0,"b'#!/usr/bin/python\n""""""\nTo have a single pip command that uses the specific requirements file use this\nin a shell script for posix OS::\n\n  pip install -r $(select_requirements.py)\n\nOn windows, create a bat of cmd file that loads the windows-specific\nrequirements directly::\n\n  for /f %%i in (\'python select_requirements.py\') do (set req_file=""%%i"")\n  pip install -r %req_file%\n""""""\n\nfrom __future__ import print_function\n\nimport os\nimport platform\nimport struct\nimport sys\n\n# major python major_python_versions as python2 and python3\nmajor_python_versions = tuple(map(str, platform.python_version_tuple()))\npython2 = major_python_versions[0] == \'2\'\npython3 = major_python_versions[0] == \'3\'\n\n\n# operating system\nsys_platform = str(sys.platform).lower()\nlinux = \'linux\' in sys_platform\nwindows = \'win32\' in sys_platform\ncygwin = \'cygwin\' in sys_platform\nsolaris = \'sunos\' in sys_platform\nmacosx = \'darwin\' in sys_platform\nposix = \'posix\' in os.name.lower()\n\ndef select_requirements_file():\n    """"""\n    Print the path to a requirements file based on some os/arch condition.\n    """"""\n    if windows:\n        print(\'requirements/win.txt\')\n    elif macosx:\n        print(\'requirements/mac.txt\')\n    elif linux:\n        if python2:\n            print(\'requirements/linux-py2.txt\')\n        elif python3:\n            print(\'requirements/linux-py3.txt\')\n    elif cygwin:\n        print(\'requirements/cygwin.txt\')\n    else:\n        raise Exception(\'Unsupported OS/platform\')\n\nif __name__ == \'__main__\':\n    select_requirements_file()'"
tests/conversion_imagenet.py,7,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nTEST_ONNX = os.environ.get(\'TEST_ONNX\')\nimport sys\nimport imp\nimport numpy as np\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nimport utils\nfrom utils import *\nfrom datetime import datetime\n\n\ndef is_paddle_supported():\n    if (sys.version_info > (2, 7)):\n        print(\'PaddlePaddle does not support Python {0}\'.format(sys.version), file=sys.stderr)\n        return False\n\n    return True\n\n\ndef is_coreml_supported():\n    import sys\n    if sys.platform == \'darwin\':\n        import platform\n        ver_str = platform.mac_ver()[0]\n        if (tuple([int(v) for v in ver_str.split(\'.\')]) >= (10, 13)):\n            return True\n\n    print(\'CoreML is not supported on your platform.\', file=sys.stderr)\n    return False\n\n\ndef check_env(source_framework, target_framework, model_name):\n    if ((source_framework == \'paddle\') or (target_framework == \'paddle\')):\n        if not is_paddle_supported():\n            return False\n\n    if ((source_framework == \'coreml\') or (target_framework == \'coreml\')):\n        if not is_coreml_supported():\n            return False\n\n    return True\n\n\nclass TestModels(CorrectnessTest):\n\n    image_path = ""mmdnn/conversion/examples/data/seagull.jpg""\n    cachedir = ""tests/cache/""\n    tmpdir = ""tests/tmp/""\n    sentence_path = ""mmdnn/conversion/examples/data/one_imdb.npy""\n    vocab_size = 30000\n\n    def __init__(self, test_table=None, methodName=\'test_nothing\'):\n        super(TestModels, self).__init__(methodName)\n        if test_table:\n            print (""Reset the test_table!"", file=sys.stderr)\n            self.test_table = test_table\n\n\n    @staticmethod\n    def tensorflow_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.tensorflow.extractor import tensorflow_extractor\n        from mmdnn.conversion.tensorflow.tensorflow_parser import TensorflowParser\n\n        # get original model prediction result\n        original_predict = tensorflow_extractor.inference(architecture_name, None, TestModels.cachedir, test_input_path)\n        del tensorflow_extractor\n\n        # original to IR\n        IR_file = TestModels.tmpdir + \'tensorflow_\' + architecture_name + ""_converted""\n        parser = TensorflowParser(\n            TestModels.cachedir + ""imagenet_"" + architecture_name + "".ckpt.meta"",\n            TestModels.cachedir + ""imagenet_"" + architecture_name + "".ckpt"",\n            [""MMdnn_Output""])\n        parser.run(IR_file)\n        del parser\n        del TensorflowParser\n\n        return original_predict\n\n\n    @staticmethod\n    def tensorflow_frozen_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.tensorflow.extractor import tensorflow_extractor\n        from mmdnn.conversion.tensorflow.tensorflow_frozenparser import TensorflowParser2\n\n        # get original model prediction result\n        original_predict = tensorflow_extractor.inference(architecture_name, None, TestModels.cachedir, test_input_path, is_frozen = True)\n        para = tensorflow_extractor.get_frozen_para(architecture_name)\n        del tensorflow_extractor\n\n        # original to IR\n        IR_file = TestModels.tmpdir + \'tensorflow_frozen_\' + architecture_name + ""_converted""\n        parser = TensorflowParser2(\n            TestModels.cachedir + para[0], para[1], para[2], para[3])\n        parser.run(IR_file)\n        del parser\n        del TensorflowParser2\n\n        return original_predict\n\n\n    @staticmethod\n    def keras_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.keras.extractor import keras_extractor\n        from mmdnn.conversion.keras.keras2_parser import Keras2Parser\n\n        # download model\n        model_filename = keras_extractor.download(architecture_name, TestModels.cachedir)\n\n        # get original model prediction result\n        original_predict = keras_extractor.inference(architecture_name, model_filename, TestModels.cachedir, test_input_path)\n        # print(original_predict)\n        del keras_extractor\n\n        # original to IR\n        IR_file = TestModels.tmpdir + \'keras_\' + architecture_name + ""_converted""\n        parser = Keras2Parser(model_filename)\n        parser.run(IR_file)\n        del parser\n        del Keras2Parser\n        return original_predict\n\n\n    @staticmethod\n    def mxnet_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.mxnet.extractor import mxnet_extractor\n        from mmdnn.conversion.mxnet.mxnet_parser import MXNetParser\n\n        # download model\n        architecture_file, weight_file = mxnet_extractor.download(architecture_name, TestModels.cachedir)\n\n        # get original model prediction result\n        original_predict = mxnet_extractor.inference(architecture_name, None, TestModels.cachedir, test_input_path)\n        del mxnet_extractor\n\n        # original to IR\n        import re\n        if re.search(\'.\', weight_file):\n            weight_file = weight_file[:-7]\n        prefix, epoch = weight_file.rsplit(\'-\', 1)\n        model = (architecture_file, prefix, epoch, [3, 224, 224])\n\n        IR_file = TestModels.tmpdir + \'mxnet_\' + architecture_name + ""_converted""\n        parser = MXNetParser(model)\n        parser.run(IR_file)\n        del parser\n        del MXNetParser\n\n        return original_predict\n\n\n    @staticmethod\n    def caffe_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.caffe.extractor import caffe_extractor\n\n        # download model\n        architecture_file, weight_file = caffe_extractor.download(architecture_name, TestModels.cachedir)\n\n        # get original model prediction result\n        original_predict = caffe_extractor.inference(architecture_name, (architecture_file, weight_file), TestModels.cachedir, test_input_path)\n        del caffe_extractor\n\n        # original to IR\n        from mmdnn.conversion.caffe.transformer import CaffeTransformer\n        transformer = CaffeTransformer(architecture_file, weight_file, ""tensorflow"", None, phase = \'TEST\')\n        graph = transformer.transform_graph()\n        data = transformer.transform_data()\n        del CaffeTransformer\n\n        from mmdnn.conversion.caffe.writer import ModelSaver, PyWriter\n\n        prototxt = graph.as_graph_def().SerializeToString()\n        IR_file = TestModels.tmpdir + \'caffe_\' + architecture_name + ""_converted""\n        pb_path = IR_file + \'.pb\'\n        with open(pb_path, \'wb\') as of:\n            of.write(prototxt)\n        print (""IR network structure is saved as [{}]."".format(pb_path))\n\n        import numpy as np\n        npy_path = IR_file + \'.npy\'\n        with open(npy_path, \'wb\') as of:\n            np.save(of, data)\n        print (""IR weights are saved as [{}]."".format(npy_path))\n\n        if original_predict.ndim == 3:\n            original_predict = np.transpose(original_predict, (1, 2, 0))\n\n        return original_predict\n\n\n    @staticmethod\n    def cntk_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.cntk.extractor import cntk_extractor\n        from mmdnn.conversion.cntk.cntk_parser import CntkParser\n        # download model\n        architecture_file = cntk_extractor.download(architecture_name, TestModels.cachedir)\n\n        # get original model prediction result\n        original_predict = cntk_extractor.inference(architecture_name, architecture_file, test_input_path)\n        del cntk_extractor\n\n        # original to IR\n        IR_file = TestModels.tmpdir + \'cntk_\' + architecture_name + ""_converted""\n        parser = CntkParser(architecture_file)\n        parser.run(IR_file)\n        del parser\n        del CntkParser\n        return original_predict\n\n\n    @staticmethod\n    def coreml_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.coreml.extractor import coreml_extractor\n        from mmdnn.conversion.coreml.coreml_parser import CoremlParser\n\n        # download model\n        architecture_file = coreml_extractor.download(architecture_name, TestModels.cachedir)\n\n        # get original model prediction result\n        original_predict = coreml_extractor.inference(architecture_name, architecture_file, test_input_path)\n        del coreml_extractor\n\n         # original to IR\n        IR_file = TestModels.tmpdir + \'coreml_\' + architecture_name + ""_converted""\n        parser = CoremlParser(architecture_file)\n        parser.run(IR_file)\n        del parser\n        del CoremlParser\n        return original_predict\n\n    @staticmethod\n    def paddle_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.paddle.extractor import paddle_extractor\n        from mmdnn.conversion.paddle.paddle_parser import PaddleParser\n\n        # download model\n        model_filename = paddle_extractor.download(architecture_name, TestModels.cachedir)\n\n        # get original model prediction result\n        original_predict = paddle_extractor.inference(architecture_name, model_filename, TestModels.cachedir, test_input_path)\n        del paddle_extractor\n\n        # original to IR\n        IR_file = TestModels.tmpdir + \'paddle_\' + architecture_name + ""_converted""\n\n        parser = PaddleParser(model_filename)\n        parser.run(IR_file)\n        del parser\n        del PaddleParser\n        return original_predict\n\n    @staticmethod\n    def pytorch_parse(architecture_name, test_input_path):\n        from mmdnn.conversion.examples.pytorch.extractor import pytorch_extractor\n        from mmdnn.conversion.pytorch.pytorch_parser import PytorchParser\n\n        # download model\n        architecture_file = pytorch_extractor.download(architecture_name, TestModels.cachedir)\n\n\n        # get original model prediction result\n        original_predict = pytorch_extractor.inference(architecture_name, architecture_file, test_input_path)\n        del pytorch_extractor\n\n        # get shape\n        func = TestKit.preprocess_func[\'pytorch\'][architecture_name]\n\n        import inspect\n        funcstr = inspect.getsource(func)\n\n        pytorch_pre = funcstr.split(\'(\')[0].split(\'.\')[-1]\n\n        if len(funcstr.split(\',\')) == 3:\n            size = int(funcstr.split(\'path,\')[1].split(\')\')[0])\n\n        elif  len(funcstr.split(\',\')) == 4:\n            size = int(funcstr.split(\'path,\')[1].split(\',\')[0])\n\n        elif len(funcstr.split(\',\')) == 11:\n            size = int(funcstr.split(\'path,\')[1].split(\',\')[0])\n\n\n         # original to IR\n        IR_file = TestModels.tmpdir + \'pytorch_\' + architecture_name + ""_converted""\n        parser = PytorchParser(architecture_file, [3, size, size])\n        parser.run(IR_file)\n        del parser\n        del PytorchParser\n        return original_predict\n\n\n    @staticmethod\n    def darknet_parse(architecture_name, test_input_path):\n        ensure_dir(""./data/"")\n        from mmdnn.conversion.examples.darknet.extractor import darknet_extractor\n        from mmdnn.conversion.darknet.darknet_parser import DarknetParser\n        # download model\n        architecture_file = darknet_extractor.download(architecture_name, TestModels.cachedir)\n\n        # get original model prediction result\n        original_predict = darknet_extractor.inference(architecture_name, architecture_file, TestModels.cachedir, test_input_path)\n        del darknet_extractor\n\n        # original to IR\n        IR_file = TestModels.tmpdir + \'darknet_\' + architecture_name + ""_converted""\n\n        if architecture_name == ""yolov3"":\n            start = ""1""\n        else:\n            start = ""0""\n\n        parser = DarknetParser(architecture_file[0], architecture_file[1], start)\n        parser.run(IR_file)\n        del parser\n        del DarknetParser\n        return original_predict\n\n\n    @staticmethod\n    def cntk_emit(original_framework, architecture_name, architecture_path, weight_path, test_input_path):\n        from mmdnn.conversion.cntk.cntk_emitter import CntkEmitter\n\n        # IR to code\n        converted_file = TestModels.tmpdir + original_framework + \'_cntk_\' + architecture_name + ""_converted""\n        converted_file = converted_file.replace(\'.\', \'_\')\n        emitter = CntkEmitter((architecture_path, weight_path))\n        emitter.run(converted_file + \'.py\', None, \'test\')\n        del emitter\n        del CntkEmitter\n\n        model_converted = imp.load_source(\'CntkModel\', converted_file + \'.py\').KitModel(weight_path)\n\n        if \'rnn\' not in architecture_name:\n            func = TestKit.preprocess_func[original_framework][architecture_name]\n            img = func(test_input_path)\n            input_data = img\n        else:\n            sentence = np.load(test_input_path)\n            from keras.utils import to_categorical\n            input_data = to_categorical(sentence, 30000)[0]\n\n\n        predict = model_converted.eval({model_converted.arguments[0]:[input_data]})\n        converted_predict = np.squeeze(predict)\n        del model_converted\n        del sys.modules[\'CntkModel\']\n        os.remove(converted_file + \'.py\')\n\n        return converted_predict\n\n\n    @staticmethod\n    def tensorflow_emit(original_framework, architecture_name, architecture_path, weight_path, test_input_path):\n        import tensorflow as tf\n        from mmdnn.conversion.tensorflow.tensorflow_emitter import TensorflowEmitter\n        # IR to code\n        converted_file = TestModels.tmpdir + original_framework + \'_tensorflow_\' + architecture_name + ""_converted""\n        converted_file = converted_file.replace(\'.\', \'_\')\n\n        emitter = TensorflowEmitter((architecture_path, weight_path))\n        emitter.run(converted_file + \'.py\', None, \'test\')\n        del emitter\n        del TensorflowEmitter\n\n        # import converted model\n        model_converted = imp.load_source(\'TFModel\', converted_file + \'.py\').KitModel(weight_path)\n\n        input_tf, model_tf = model_converted\n\n        original_framework = checkfrozen(original_framework)\n\n        if \'rnn\' not in architecture_name:\n            func = TestKit.preprocess_func[original_framework][architecture_name]\n            img = func(test_input_path)\n            input_data = np.expand_dims(img, 0)\n        else:\n            input_data = np.load(test_input_path)\n\n        with tf.Session() as sess:\n            init = tf.global_variables_initializer()\n            sess.run(init)\n            predict = sess.run(model_tf, feed_dict = {input_tf : input_data})\n        del model_converted\n        del sys.modules[\'TFModel\']\n        os.remove(converted_file + \'.py\')\n        converted_predict = np.squeeze(predict)\n\n        del tf\n\n        return converted_predict\n\n\n    @staticmethod\n    def pytorch_emit(original_framework, architecture_name, architecture_path, weight_path, test_input_path):\n        from mmdnn.conversion.pytorch.pytorch_emitter import PytorchEmitter\n\n        # IR to code\n        converted_file = TestModels.tmpdir + original_framework + \'_pytorch_\' + architecture_name + ""_converted""\n        converted_file = converted_file.replace(\'.\', \'_\')\n        emitter = PytorchEmitter((architecture_path, weight_path))\n        emitter.run(converted_file + \'.py\', converted_file + \'.npy\', \'test\')\n        del emitter\n        del PytorchEmitter\n\n        # import converted model\n        import torch\n        model_converted = imp.load_source(\'PytorchModel\', converted_file + \'.py\').KitModel(converted_file + \'.npy\')\n\n        model_converted.eval()\n\n        original_framework = checkfrozen(original_framework)\n        if \'rnn\' not in architecture_name:\n            func = TestKit.preprocess_func[original_framework][architecture_name]\n            img = func(test_input_path)\n            img = np.transpose(img, (2, 0, 1))\n            img = np.expand_dims(img, 0).copy()\n            input_data = torch.from_numpy(img)\n            input_data = torch.autograd.Variable(input_data, requires_grad = False)\n        else:\n            sentence = np.load(test_input_path)\n            input_data = torch.from_numpy(sentence)\n            input_data = torch.autograd.Variable(input_data, requires_grad = False)\n\n        predict = model_converted(input_data)\n        predict = predict.data.numpy()\n        converted_predict = np.squeeze(predict)\n\n        del model_converted\n        del sys.modules[\'PytorchModel\']\n        del torch\n        os.remove(converted_file + \'.py\')\n        os.remove(converted_file + \'.npy\')\n\n        return converted_predict\n\n\n    @staticmethod\n    def keras_emit(original_framework, architecture_name, architecture_path, weight_path, test_input_path):\n        from mmdnn.conversion.keras.keras2_emitter import Keras2Emitter\n\n        # IR to code\n        converted_file = TestModels.tmpdir + original_framework + \'_keras_\' + architecture_name + ""_converted""\n        converted_file = converted_file.replace(\'.\', \'_\')\n        emitter = Keras2Emitter((architecture_path, weight_path))\n        emitter.run(converted_file + \'.py\', None, \'test\')\n        del emitter\n        del Keras2Emitter\n\n\n        # import converted model\n        model_converted = imp.load_source(\'KerasModel\', converted_file + \'.py\').KitModel(weight_path)\n\n        original_framework = checkfrozen(original_framework)\n        if \'rnn\' not in architecture_name:\n            func = TestKit.preprocess_func[original_framework][architecture_name]\n            img = func(test_input_path)\n            input_data = np.expand_dims(img, 0)\n        else:\n            input_data = np.load(test_input_path)\n\n        predict = model_converted.predict(input_data)\n\n        if original_framework == ""darknet"":\n            converted_predict = None\n        else:\n            converted_predict = np.squeeze(predict)\n\n        del model_converted\n        del sys.modules[\'KerasModel\']\n\n        import keras.backend as K\n        K.clear_session()\n\n        os.remove(converted_file + \'.py\')\n\n        return converted_predict\n\n\n    @staticmethod\n    def mxnet_emit(original_framework, architecture_name, architecture_path, weight_path, test_input_path):\n        from mmdnn.conversion.mxnet.mxnet_emitter import MXNetEmitter\n        from collections import namedtuple\n        Batch = namedtuple(\'Batch\', [\'data\'])\n\n        import mxnet\n\n        # IR to code\n        converted_file = TestModels.tmpdir + original_framework + \'_mxnet_\' + architecture_name + ""_converted""\n        converted_file = converted_file.replace(\'.\', \'_\')\n        output_weights_file = converted_file + ""-0000.params""\n        emitter = MXNetEmitter((architecture_path, weight_path, output_weights_file))\n        emitter.run(converted_file + \'.py\', None, \'test\')\n        del emitter\n        del MXNetEmitter\n\n        # import converted model\n        imported = imp.load_source(\'MXNetModel\', converted_file + \'.py\')\n\n        model_converted = imported.RefactorModel()\n        model_converted = imported.deploy_weight(model_converted, output_weights_file)\n\n        original_framework = checkfrozen(original_framework)\n        if \'rnn\' not in architecture_name:\n            func = TestKit.preprocess_func[original_framework][architecture_name]\n            img = func(test_input_path)\n            img = np.transpose(img, (2, 0, 1))\n            input_data = np.expand_dims(img, 0)\n        else:\n            input_data = np.load(test_input_path)\n\n        model_converted.forward(Batch([mxnet.nd.array(input_data)]))\n        predict = model_converted.get_outputs()[0].asnumpy()\n        converted_predict = np.squeeze(predict)\n\n        del model_converted\n        del sys.modules[\'MXNetModel\']\n        del mxnet\n\n        os.remove(converted_file + \'.py\')\n        os.remove(output_weights_file)\n\n        return converted_predict\n\n\n    @staticmethod\n    def caffe_emit(original_framework, architecture_name, architecture_path, weight_path, test_input_path):\n        try:\n            import caffe\n            from mmdnn.conversion.caffe.caffe_emitter import CaffeEmitter\n\n            # IR to code\n            converted_file = TestModels.tmpdir + original_framework + \'_caffe_\' + architecture_name + ""_converted""\n            converted_file = converted_file.replace(\'.\', \'_\')\n            emitter = CaffeEmitter((architecture_path, weight_path))\n            emitter.run(converted_file + \'.py\', converted_file + \'.npy\', \'test\')\n            del emitter\n            del CaffeEmitter\n\n            # import converted model\n            imported = imp.load_source(\'CaffeModel\', converted_file + \'.py\')\n\n            imported.make_net(converted_file + \'.prototxt\')\n            imported.gen_weight(converted_file + \'.npy\', converted_file + \'.caffemodel\', converted_file + \'.prototxt\')\n            model_converted = caffe.Net(converted_file + \'.prototxt\', converted_file + \'.caffemodel\', caffe.TEST)\n\n            original_framework = checkfrozen(original_framework)\n            func = TestKit.preprocess_func[original_framework][architecture_name]\n            img = func(test_input_path)\n            img = np.transpose(img, [2, 0, 1])\n            input_data = np.expand_dims(img, 0)\n\n            model_converted.blobs[model_converted.inputs[0]].data[...] = input_data\n            predict = model_converted.forward()[model_converted.outputs[-1]]\n            converted_predict = np.squeeze(predict)\n\n            del model_converted\n            del sys.modules[\'CaffeModel\']\n            del caffe\n            os.remove(converted_file + \'.py\')\n            os.remove(converted_file + \'.npy\')\n            os.remove(converted_file + \'.prototxt\')\n            os.remove(converted_file + \'.caffemodel\')\n\n            return converted_predict\n\n        except ImportError:\n            print (""Cannot import Caffe. Caffe Emit is not tested."")\n            return None\n\n\n    @staticmethod\n    def coreml_emit(original_framework, architecture_name, architecture_path, weight_path, test_input_path):\n        from mmdnn.conversion.coreml.coreml_emitter import CoreMLEmitter\n        from coremltools.models import MLModel\n        import coremltools\n        from PIL import Image\n\n        def prep_for_coreml(prename, BGRTranspose):\n            # The list is in RGB oder\n            if prename == \'Standard\':\n                return 0.00784313725490196,-1, -1, -1\n            elif prename == \'ZeroCenter\' :\n                return 1, -123.68, -116.779, -103.939\n            elif prename == \'Identity\':\n                return 1, 1, 1, 1\n            else:\n                raise ValueError()\n\n        # IR to Model\n        # converted_file = original_framework + \'_coreml_\' + architecture_name + ""_converted""\n        # converted_file = converted_file.replace(\'.\', \'_\')\n\n        original_framework = checkfrozen(original_framework)\n        func = TestKit.preprocess_func[original_framework][architecture_name]\n\n        import inspect\n        funcstr = inspect.getsource(func)\n\n        coreml_pre = funcstr.split(\'(\')[0].split(\'.\')[-1]\n\n        if len(funcstr.split(\',\')) == 3:\n            BGRTranspose = bool(0)\n            size = int(funcstr.split(\'path,\')[1].split(\')\')[0])\n            prep_list = prep_for_coreml(coreml_pre, BGRTranspose)\n        elif  len(funcstr.split(\',\')) == 4:\n            BGRTranspose = funcstr.split(\',\')[-2].split(\')\')[0].strip() == str(True)\n            size = int(funcstr.split(\'path,\')[1].split(\',\')[0])\n            prep_list = prep_for_coreml(coreml_pre, BGRTranspose)\n\n        elif len(funcstr.split(\',\')) == 11:\n            BGRTranspose = funcstr.split(\',\')[-2].split(\')\')[0].strip() == str(True)\n\n            size = int(funcstr.split(\'path,\')[1].split(\',\')[0])\n            prep_list = (   float(funcstr.split(\',\')[2]),\n                            float(funcstr.split(\',\')[3].split(\'[\')[-1]),\n                            float(funcstr.split(\',\')[4]),\n                            float(funcstr.split(\',\')[5].split(\']\')[0])\n                        )\n\n        emitter = CoreMLEmitter(architecture_path, weight_path)\n\n\n        model, input_name, output_name = emitter.gen_model(\n                input_names=None,\n                output_names=None,\n                image_input_names=test_input_path,\n                is_bgr=BGRTranspose,\n                red_bias=prep_list[1],\n                green_bias=prep_list[2],\n                blue_bias=prep_list[3],\n                gray_bias=0.0,\n                image_scale=prep_list[0],\n                class_labels=None,\n                predicted_feature_name=None,\n                predicted_probabilities_output=\'\'\n            )\n\n        input_name = str(input_name[0][0])\n        output_name = str(output_name[0][0])\n\n        # load model\n        model = MLModel(model)\n\n\n        # save model\n        # coremltools.utils.save_spec(model.get_spec(), converted_file)\n\n        if not is_coreml_supported():\n            return None\n        else:\n\n            from PIL import Image as pil_image\n            img = pil_image.open(test_input_path)\n            img = img.resize((size, size))\n\n            # inference\n\n            coreml_input = {input_name: img}\n            coreml_output = model.predict(coreml_input)\n            prob = coreml_output[output_name]\n            prob = np.array(prob).squeeze()\n\n            return prob\n\n\n    @staticmethod\n    def onnx_emit(original_framework, architecture_name, architecture_path, weight_path, test_input_path):\n        from mmdnn.conversion.onnx.onnx_emitter import OnnxEmitter\n\n        # IR to code\n        converted_file = TestModels.tmpdir + original_framework + \'_onnx_\' + architecture_name + ""_converted""\n        converted_file = converted_file.replace(\'.\', \'_\')\n        emitter = OnnxEmitter(architecture_path, weight_path)\n        emitter.run(converted_file + \'.py\', converted_file + \'.npy\', \'test\')\n        del emitter\n        del OnnxEmitter\n\n        # import converted model\n        from onnx_tf.backend import prepare\n        model_converted = imp.load_source(\'OnnxModel\', converted_file + \'.py\').KitModel(converted_file + \'.npy\')\n\n        tf_rep = prepare(model_converted)\n\n        original_framework = checkfrozen(original_framework)\n        func = TestKit.preprocess_func[original_framework][architecture_name]\n        img = func(test_input_path)\n        input_data = np.expand_dims(img, 0)\n\n        predict = tf_rep.run(input_data)[0]\n\n        del prepare\n        del model_converted\n        del tf_rep\n        del sys.modules[\'OnnxModel\']\n\n        os.remove(converted_file + \'.py\')\n        os.remove(converted_file + \'.npy\')\n\n        return predict\n\n\n    # In case of odd number add the extra padding at the end for SAME_UPPER(eg. pads:[0, 2, 2, 0, 0, 3, 3, 0]) and at the beginning for SAME_LOWER(eg. pads:[0, 3, 3, 0, 0, 2, 2, 0])\n\n    exception_tabel = {\n        \'cntk_keras_resnet18\',                      # Cntk Padding is SAME_LOWER, but Keras Padding is SAME_UPPER, in first convolution layer.\n        \'cntk_keras_resnet152\',                     # Cntk Padding is SAME_LOWER, but Keras Padding is SAME_UPPER, in first convolution layer.\n        \'cntk_tensorflow_resnet18\',                 # Cntk Padding is SAME_LOWER, but Keras Padding is SAME_UPPER, in first convolution layer.\n        \'cntk_tensorflow_resnet152\',                # Cntk Padding is SAME_LOWER, but Keras Padding is SAME_UPPER, in first convolution layer.\n        \'tensorflow_cntk_inception_v1\',             # Cntk Padding is SAME_LOWER, but Tensorflow Padding is SAME_UPPER, in first convolution layer.\n        \'tensorflow_cntk_resnet_v1_50\',             # Cntk Padding is SAME_LOWER, but Tensorflow Padding is SAME_UPPER, in first convolution layer.\n        \'tensorflow_cntk_resnet_v2_50\',             # Cntk Padding is SAME_LOWER, but Tensorflow Padding is SAME_UPPER, in first convolution layer.\n        \'tensorflow_cntk_resnet_v1_152\',            # Cntk Padding is SAME_LOWER, but Tensorflow Padding is SAME_UPPER, in first convolution layer.\n        \'tensorflow_cntk_resnet_v2_152\',            # Cntk Padding is SAME_LOWER, but Tensorflow Padding is SAME_UPPER, in first convolution layer.\n        \'tensorflow_cntk_mobilenet_v1_1.0\',         # Cntk Padding is SAME_LOWER, but Tensorflow Padding is SAME_UPPER, in first convolution layer.\n        \'tensorflow_cntk_mobilenet_v2_1.0_224\',     # Cntk Padding is SAME_LOWER, but Tensorflow Padding is SAME_UPPER, in first convolution layer.\n        \'tensorflow_caffe_mobilenet_v1_1.0\',        # Caffe No Relu6\n        \'tensorflow_caffe_mobilenet_v2_1.0_224\',    # Caffe No Relu6\n        \'tensorflow_frozen_mxnet_inception_v1\',     # different after AvgPool. AVG POOL padding difference between these two framework. MXNet AVGPooling Padding is SAME_LOWER, Tensorflow AVGPooling Padding is SAME_UPPER\n        \'tensorflow_mxnet_inception_v3\',            # different after ""InceptionV3/InceptionV3/Mixed_5b/Branch_3/AvgPool_0a_3x3/AvgPool"". AVG POOL padding difference between these two framework.\n        \'darknet_keras_yolov2\',                     # accumulation of small difference\n        \'darknet_keras_yolov3\',                     # accumulation of small difference\n    }\n\n    if TEST_ONNX and TEST_ONNX.lower() == \'true\':\n        test_table = {\n            \'cntk\' : {\n                \'inception_v3\'  : [onnx_emit],\n                \'resnet18\'      : [onnx_emit],\n                \'resnet152\'     : [onnx_emit],\n            },\n\n            \'keras\' : {\n                \'vgg16\'        : [onnx_emit],\n                \'vgg19\'        : [onnx_emit],\n                \'inception_v3\' : [onnx_emit],\n                \'resnet50\'     : [onnx_emit],\n                \'densenet\'     : [onnx_emit],\n                # \'xception\'     : [onnx_emit],\n                \'mobilenet\'    : [onnx_emit],\n                # \'nasnet\'       : [onnx_emit],\n                #Temporarily disable \'yolo2\'        : [onnx_emit],\n            },\n\n            \'mxnet\' : {\n                \'vgg19\'                        : [onnx_emit],\n                \'imagenet1k-inception-bn\'      : [onnx_emit],\n                \'imagenet1k-resnet-18\'         : [onnx_emit],\n                \'imagenet1k-resnet-152\'        : [onnx_emit],\n                \'squeezenet_v1.1\'              : [onnx_emit],\n                \'imagenet1k-resnext-101-64x4d\' : [onnx_emit],\n                \'imagenet1k-resnext-50\'        : [onnx_emit],\n            },\n\n            \'caffe\' : {\n                \'alexnet\'       : [onnx_emit],\n                \'inception_v1\'  : [onnx_emit],\n                #Temporarily disable \'inception_v4\'  : [onnx_emit],\n                \'resnet152\'     : [onnx_emit],\n                \'squeezenet\'    : [onnx_emit],\n                \'vgg19\'         : [onnx_emit],\n                # \'voc-fcn8s\'     : [onnx_emit], # TODO: ConvTranspose, Crop\n                # \'voc-fcn16s\'    : [onnx_emit], # TODO: ConvTranspose, Crop\n                # \'voc-fcn32s\'    : [onnx_emit], # TODO: ConvTranspose, Crop\n                #Temporarily disable \'xception\'      : [onnx_emit],\n            },\n\n            \'tensorflow\' : {\n                #Temporarily disable \'facenet\'               : [onnx_emit],\n                \'vgg19\'                 : [onnx_emit],\n                \'inception_v1\'          : [onnx_emit],\n                \'inception_v3\'          : [onnx_emit],\n                # \'resnet_v1_50\'          : [onnx_emit], # POOL: strides > window_shape not supported due to inconsistency between CPU and GPU implementations\n                # \'resnet_v1_152\'         : [onnx_emit], # POOL: strides > window_shape not supported due to inconsistency between CPU and GPU implementations\n                # \'resnet_v2_50\'          : [onnx_emit], # POOL: strides > window_shape not supported due to inconsistency between CPU and GPU implementations\n                # \'resnet_v2_152\'         : [onnx_emit], # POOL: strides > window_shape not supported due to inconsistency between CPU and GPU implementations\n                \'mobilenet_v1_1.0\'      : [onnx_emit],\n                \'mobilenet_v2_1.0_224\'  : [onnx_emit],\n                # \'nasnet-a_large\'        : [onnx_emit], # POOL: strides > window_shape not supported due to inconsistency between CPU and GPU implementations\n                \'inception_resnet_v2\'   : [onnx_emit],\n            },\n\n            \'tensorflow_frozen\' : {\n                \'inception_v1\'      : [onnx_emit],\n                \'inception_v3\'      : [onnx_emit],\n                \'mobilenet_v1_1.0\'  : [onnx_emit],\n                #Temporarily disable \'facenet\'           : [onnx_emit],\n            },\n\n            \'coreml\' : {\n                \'inception_v3\' : [onnx_emit],\n                \'mobilenet\'    : [onnx_emit],\n                \'resnet50\'     : [onnx_emit],\n                \'tinyyolo\'     : [onnx_emit],\n                \'vgg16\'        : [onnx_emit],\n            },\n\n            \'darknet\' : {\n            },\n\n            \'paddle\'  : {\n                \'resnet50\'     : [onnx_emit],\n                \'vgg16\'        : [onnx_emit],      # First 1000 exactly the same, the last one is different\n            },\n\n            \'pytorch\' : {\n                # TODO: coredump\n            },\n\n\n        }\n\n    else:\n        test_table = {\n            \'cntk\' : {\n                # \'alexnet\'       : [cntk_emit, keras_emit, tensorflow_emit],\n                \'inception_v3\'  : [cntk_emit, pytorch_emit, tensorflow_emit], #TODO: Caffe, Keras, and MXNet no constant layer\n                \'resnet18\'      : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'resnet152\'     : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n            },\n\n            \'keras\' : {\n                \'vgg19\'        : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'inception_v3\' : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'resnet50\'     : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'densenet\'     : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'xception\'     : [tensorflow_emit, keras_emit, coreml_emit],\n                \'mobilenet\'    : [coreml_emit, keras_emit, tensorflow_emit], # TODO: mxnet_emit\n                # \'nasnet\'       : [tensorflow_emit, keras_emit, coreml_emit],\n                #Temporarily disable \'yolo2\'        : [keras_emit],\n                # \'facenet\'      : [tensorflow_emit, coreml_emit,mxnet_emit,keras_emit]  # TODO\n            },\n\n            \'mxnet\' : {\n                \'vgg19\'                        : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'imagenet1k-inception-bn\'      : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'imagenet1k-resnet-18\'         : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'imagenet1k-resnet-152\'        : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'squeezenet_v1.1\'              : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'imagenet1k-resnext-101-64x4d\' : [caffe_emit, cntk_emit, coreml_emit, mxnet_emit, pytorch_emit, tensorflow_emit], # Keras is ok but too slow\n                \'imagenet1k-resnext-50\'        : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n            },\n\n            \'caffe\' : {\n                \'alexnet\'       : [caffe_emit, cntk_emit, coreml_emit, mxnet_emit, pytorch_emit, tensorflow_emit], # TODO: keras_emit(\'Tensor\' object has no attribute \'_keras_history\')\n                \'inception_v1\'  : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                #Temporarily disable \'inception_v4\'  : [cntk_emit, coreml_emit, keras_emit, pytorch_emit, tensorflow_emit], # TODO mxnet_emit(Small error), caffe_emit(Crash for shape)\n                \'resnet152\'     : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'squeezenet\'    : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'vgg19\'         : [caffe_emit, cntk_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'voc-fcn8s\'     : [cntk_emit, coreml_emit, tensorflow_emit],\n                \'voc-fcn16s\'    : [cntk_emit, coreml_emit, tensorflow_emit],\n                \'voc-fcn32s\'    : [cntk_emit, coreml_emit, tensorflow_emit],\n                #Temporarily disable \'xception\'      : [coreml_emit, cntk_emit, mxnet_emit, pytorch_emit, tensorflow_emit], #  TODO: Caffe(Crash) keras_emit(too slow)\n            },\n\n            \'tensorflow\' : {\n                \'vgg19\'                 : [caffe_emit, coreml_emit, cntk_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'inception_v1\'          : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit], # TODO: cntk_emit\n                \'inception_v3\'          : [caffe_emit, coreml_emit, cntk_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'resnet_v1_152\'         : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit], # TODO: cntk_emit\n                \'resnet_v2_152\'         : [caffe_emit, coreml_emit, cntk_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'mobilenet_v1_1.0\'      : [caffe_emit, coreml_emit, cntk_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'mobilenet_v2_1.0_224\'  : [caffe_emit, coreml_emit, cntk_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'nasnet-a_large\'        : [mxnet_emit, pytorch_emit, tensorflow_emit], # TODO: keras_emit(Slice Layer: https://blog.csdn.net/lujiandong1/article/details/54936185)\n                \'inception_resnet_v2\'   : [caffe_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit], #  CoremlEmit worked once, then always\n                #Temporarily disable \'facenet\'               : [mxnet_emit, tensorflow_emit, keras_emit, pytorch_emit, caffe_emit], # TODO: coreml_emit\n                #Temporarily disable \'rnn_lstm_gru_stacked\'  : [tensorflow_emit, keras_emit, pytorch_emit, mxnet_emit] #TODO cntk_emit\n            },\n\n            \'tensorflow_frozen\' : {\n                \'inception_v1\'      : [tensorflow_emit, keras_emit, mxnet_emit, coreml_emit], # TODO: cntk_emit\n                \'inception_v3\'      : [tensorflow_emit, keras_emit, mxnet_emit, coreml_emit], # TODO: cntk_emit\n                \'mobilenet_v1_1.0\'  : [tensorflow_emit, keras_emit, mxnet_emit, coreml_emit],\n                #Temporarily disable \'facenet\'           : [mxnet_emit, tensorflow_emit, keras_emit, caffe_emit] # TODO: coreml_emit\n            },\n\n            \'coreml\' : {\n                \'inception_v3\' : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'mobilenet\'    : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'resnet50\'     : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                # \'tinyyolo\'     : [coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'vgg16\'        : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n            },\n\n            \'darknet\' : {\n                \'yolov2\': [keras_emit],\n                \'yolov3\': [keras_emit],\n            },\n\n            \'paddle\' : {\n                \'resnet50\': [coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit], # caffe_emit crash, due to gflags_reporting.cc\n                \'resnet101\': [coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit], # caffe_emit crash\n                # \'vgg16\': [tensorflow_emit],\n                # \'alexnet\': [tensorflow_emit]\n            },\n\n            \'pytorch\' : {\n                \'alexnet\'     : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'densenet201\' : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'inception_v3\': [caffe_emit, coreml_emit, keras_emit, pytorch_emit, tensorflow_emit],  # Mxnet broken https://github.com/apache/incubator-mxnet/issues/10194\n                \'vgg19\'       : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'vgg19_bn\'    : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n                \'resnet152\'   : [caffe_emit, coreml_emit, keras_emit, mxnet_emit, pytorch_emit, tensorflow_emit],\n            }\n        }\n\n\n    def _get_test_input(self, architecture_name):\n        if \'rnn\' in architecture_name:\n            return self.sentence_path\n        else:\n            return self.image_path\n\n\n    @classmethod\n    def _need_assert(cls, original_framework, target_framework, network_name, original_prediction, converted_prediction):\n        test_name = original_framework + \'_\' + target_framework + \'_\' + network_name\n        if test_name in cls.exception_tabel:\n            return False\n\n        if target_framework == \'coreml\':\n            if not is_coreml_supported():\n                return False\n\n        if target_framework == \'onnx\' or target_framework == \'caffe\':\n            if converted_prediction is None:\n                return False\n\n        return True\n\n\n    def _test_function(self, original_framework, parser):\n        print(""[{}] Testing {} models starts."".format(datetime.now(), original_framework), file=sys.stderr)\n        \n        ensure_dir(self.cachedir)\n        ensure_dir(self.tmpdir)\n\n        for network_name in self.test_table[original_framework].keys():\n            print(""[{}] Testing {} {} starts."".format(datetime.now(), original_framework, network_name), file=sys.stderr)\n\n            # get test input path\n            test_input = self._get_test_input(network_name)\n\n            # get original model prediction result\n            original_predict = parser(network_name, test_input)\n\n\n            IR_file = TestModels.tmpdir + original_framework + \'_\' + network_name + ""_converted""\n            for emit in self.test_table[original_framework][network_name]:\n                if isinstance(emit, staticmethod):\n                    emit = emit.__func__\n                target_framework = emit.__name__[:-5]\n\n                if (target_framework == \'coreml\'):\n                    if not is_coreml_supported():\n                        continue\n\n                print(\'[{}] Converting {} from {} to {} starts.\'.format(datetime.now(), network_name, original_framework, target_framework), file=sys.stderr)\n                converted_predict = emit(\n                    original_framework,\n                    network_name,\n                    IR_file + "".pb"",\n                    IR_file + "".npy"",\n                    test_input)\n\n\n                self._compare_outputs(\n                    original_framework,\n                    target_framework,\n                    network_name,\n                    original_predict,\n                    converted_predict,\n                    self._need_assert(original_framework, target_framework, network_name, original_predict, converted_predict)\n                )\n                print(\'[{}] Converting {} from {} to {} passed.\'.format(datetime.now(), network_name, original_framework, target_framework), file=sys.stderr)\n\n            try:\n                os.remove(IR_file + "".json"")\n            except OSError:\n                pass\n\n            os.remove(IR_file + "".pb"")\n            os.remove(IR_file + "".npy"")\n            print(""[{}] Testing {} {} passed."".format(datetime.now(), original_framework, network_name), file=sys.stderr)\n\n        print(""[{}] Testing {} models passed."".format(datetime.now(), original_framework), file=sys.stderr)\n\n\n    def test_nothing(self):\n        pass\n\n    # def test_caffe(self):\n    #     try:\n    #         import caffe\n    #         self._test_function(\'caffe\', self.caffe_parse)\n    #     except ImportError:\n    #         print(\'Please install caffe! Or caffe is not supported in your platform.\', file=sys.stderr)\n\n\n    # def test_cntk(self):\n    #     try:\n    #         import cntk\n    #         self._test_function(\'cntk\', self.cntk_parse)\n    #     except ImportError:\n    #         print(\'Please install cntk! Or cntk is not supported in your platform.\', file=sys.stderr)\n\n\n    # def test_coreml(self):\n    #     from coremltools.models.utils import macos_version\n    #     if macos_version() < (10, 13):\n    #         print(\'Coreml is not supported in your platform.\', file=sys.stderr)\n    #     else:\n    #         self._test_function(\'coreml\', self.coreml_parse)\n\n\n    # def test_keras(self):\n    #     self._test_function(\'keras\', self.keras_parse)\n\n\n    # def test_mxnet(self):\n    #     self._test_function(\'mxnet\', self.mxnet_parse)\n\n\n    # def test_darknet(self):\n    #     self._test_function(\'darknet\', self.darknet_parse)\n\n\n    # def test_paddle(self):\n    #     # omit tensorflow lead to crash\n    #     import tensorflow as tf\n    #     try:\n    #         import paddle.v2 as paddle\n    #         self._test_function(\'paddle\', self.paddle_parse)\n    #     except ImportError:\n    #         print(\'Please install Paddlepaddle! Or Paddlepaddle is not supported in your platform.\', file=sys.stderr)\n\n\n    # def test_pytorch(self):\n    #     self._test_function(\'pytorch\', self.pytorch_parse)\n\n\n    # def test_tensorflow(self):\n    #     self._test_function(\'tensorflow\', self.tensorflow_parse)\n\n\n    # def test_tensorflow_frozen(self):\n    #     self._test_function(\'tensorflow_frozen\', self.tensorflow_frozen_parse)\n'"
tests/gen_test.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\nimport io\nimport os\nimport argparse\nimport yaml\n\nmodel_template_str = \'\'\'\nmodels:\n  - model:\n      name: \'vgg19\'\n      source: \'tensorflow\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'inception_v1\'\n      source: \'tensorflow\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'inception_v3\'\n      source: \'tensorflow\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'resnet_v1_152\'\n      source: \'tensorflow\'\n      targets: [\'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'resnet_v2_152\'\n      source: \'tensorflow\'\n      targets: [\'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'mobilenet_v1_1.0\'\n      source: \'tensorflow\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'mobilenet_v2_1.0_224\'\n      source: \'tensorflow\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'nasnet-a_large\'\n      source: \'tensorflow\'\n      targets: [\'tensorflow\', \'mxnet\', \'pytorch\']\n  - model:\n      name: \'inception_resnet_v2\'\n      source: \'tensorflow\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'pytorch\', \'keras\', \'caffe\']\n  - model:\n      name: \'facenet\'\n      source: \'tensorflow\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'pytorch\', \'keras\', \'caffe\']\n  - model:\n      name: \'rnn_embedding\'\n      source: \'tensorflow\'\n      targets: [\'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'keras\']\n\n  - model:\n      name: \'inception_v1\'\n      source: \'tensorflow_frozen\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'coreml\', \'keras\']\n  - model:\n      name: \'inception_v3\'\n      source: \'tensorflow_frozen\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'coreml\', \'keras\']\n  - model:\n      name: \'mobilenet_v1_1.0\'\n      source: \'tensorflow_frozen\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'coreml\', \'keras\']\n  - model:\n      name: \'facenet\'\n      source: \'tensorflow_frozen\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'keras\']\n\n  - model:\n      name: \'inception_v3\'\n      source: \'cntk\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\']\n  - model:\n      name: \'resnet18\'\n      source: \'cntk\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'resnet152\'\n      source: \'cntk\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n\n  - model:\n      name: \'vgg19\'\n      source: \'mxnet\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'imagenet1k-inception-bn\'\n      source: \'mxnet\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'imagenet1k-resnet-18\'\n      source: \'mxnet\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'imagenet1k-resnet-152\'\n      source: \'mxnet\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'squeezenet_v1.1\'\n      source: \'mxnet\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'imagenet1k-resnext-101-64x4d\'\n      source: \'mxnet\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'imagenet1k-resnext-50\'\n      source: \'mxnet\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n\n  - model:\n      name: \'alexnet\'\n      source: \'pytorch\'\n      targets: [\'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'densenet201\'\n      source: \'pytorch\'\n      targets: [\'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'inception_v3\'\n      source: \'pytorch\'\n      targets: [\'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'vgg19\'\n      source: \'pytorch\'\n      targets: [\'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'vgg19_bn\'\n      source: \'pytorch\'\n      targets: [\'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'resnet152\'\n      source: \'pytorch\'\n      targets: [\'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n\n  - model:\n      name: \'inception_v3\'\n      source: \'coreml\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'mobilenet\'\n      source: \'coreml\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'resnet50\'\n      source: \'coreml\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'tinyyolo\'\n      source: \'coreml\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\']\n  - model:\n      name: \'vgg16\'\n      source: \'coreml\'\n      targets: [\'onnx\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n\n  - model:\n      name: \'vgg19\'\n      source: \'keras\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'inception_v3\'\n      source: \'keras\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'resnet50\'\n      source: \'keras\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'densenet\'\n      source: \'keras\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'xception\'\n      source: \'keras\'\n      targets: [\'tensorflow\', \'coreml\', \'keras\']\n  - model:\n      name: \'mobilenet\'\n      source: \'keras\'\n      targets: [\'onnx\', \'tensorflow\', \'coreml\', \'keras\']\n  - model:\n      name: \'yolo2\'\n      source: \'keras\'\n      targets: [\'onnx\', \'keras\']\n\n  - model:\n      name: \'alexnet\'\n      source: \'caffe\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'caffe\']\n  - model:\n      name: \'inception_v1\'\n      source: \'caffe\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'inception_v4\'\n      source: \'caffe\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'pytorch\', \'coreml\', \'keras\']\n  - model:\n      name: \'resnet152\'\n      source: \'caffe\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'squeezenet\'\n      source: \'caffe\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'vgg19\'\n      source: \'caffe\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\', \'keras\', \'caffe\']\n  - model:\n      name: \'voc-fcn8s\'\n      source: \'caffe\'\n      targets: [\'cntk\', \'tensorflow\', \'coreml\']\n  - model:\n      name: \'voc-fcn16s\'\n      source: \'caffe\'\n      targets: [\'cntk\', \'tensorflow\', \'coreml\']\n  - model:\n      name: \'voc-fcn32s\'\n      source: \'caffe\'\n      targets: [\'cntk\', \'tensorflow\', \'coreml\']\n  - model:\n      name: \'xception\'\n      source: \'caffe\'\n      targets: [\'onnx\', \'cntk\', \'tensorflow\', \'mxnet\', \'pytorch\', \'coreml\']\n\n  - model:\n      name: \'resnet50\'\n      source: \'paddle\'\n      targets: [\'onnx\']\n  - model:\n      name: \'vgg16\'\n      source: \'paddle\'\n      targets: [\'onnx\']\n\n\'\'\'\n\ncode_template_str = \'\'\'\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nfrom conversion_imagenet import TestModels\nfrom conversion_imagenet import check_env\n\ndef get_test_table():\n    return {{ \'{1}\' :\n    {{\n        \'{0}\'                : [TestModels.{2}_emit]\n    }}}}\n\n\n\ndef test_{1}_{2}_{3}():\n    if not check_env(\'{1}\', \'{2}\', \'{0}\'):\n        return\n\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function(\'{1}\', tester.{1}_parse)\n\n\nif __name__ == \'__main__\':\n    test_{1}_{2}_{3}()\n\n\'\'\'\n\ntravis_template_str = \'\'\'\nsudo: required\ndist: xenial\n\nos:\n  - linux\n\nlanguage: python\npython:\n  - ""2.7""\n  - ""3.5""\n\nenv:\n{0}\n\ncache:\n  directories:\n    - $HOME/.cache/pip\n\naddons:\n  apt:\n    update: true\n\nbefore_install:\n  - sudo apt-get install -y openmpi-bin\n  - sudo apt-get install -y libprotobuf-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\n  - sudo apt-get install -y libatlas-base-dev\n  - sudo apt-get install -y libgflags-dev libgoogle-glog-dev\n  - if [ ""$TEST_SOURCE_FRAMEWORK"" = ""caffe"" ] || [ ""$TEST_TARGET_FRAMEWORK"" = ""caffe"" ]; then sudo apt-get install -y --no-install-recommends libboost-all-dev; fi\n\ninstall:\n  - pip install -q -r $(python requirements/select_requirements.py)\n  - pip install wget\n\nbefore_script:\n  - export LD_LIBRARY_PATH=$(python -c ""import os; print(os.path.dirname(os.__file__) + \'/site-packages/caffe/libs\')""):${{LD_LIBRARY_PATH}}\n\nafter_failure: true\n\nafter_success: true\n\nafter_script: true\n\nscript: bash test.sh $TEST_SOURCE_FRAMEWORK $TEST_TARGET_FRAMEWORK $TEST_MODEL\n\nmatrix:\n  fast_finish: true\n\n  allow_failures:\n    - env: TEST_SOURCE_FRAMEWORK=paddle TEST_MODEL=resnet50\n    - env: TEST_SOURCE_FRAMEWORK=paddle TEST_MODEL=vgg16\n\nnotifications:\n  email:\n    on_success: never\n    on_failure: never\n\n\'\'\'\n\n\ndef gen_test(output_dir, model):\n    model_name = model[\'name\']\n    normalized_model_name = model_name.replace(\'.\', \'_\')\n    normalized_model_name2 = normalized_model_name.replace(\'-\', \'_\')\n    length = len(model[\'targets\'])\n    for i in range(length):\n        test_file = os.path.join(output_dir, \'test_{0}_{1}_{2}.py\'\n                    .format(model[\'source\'], model[\'targets\'][i], normalized_model_name))\n        with open(test_file, ""w+"") as f:\n            code = code_template_str.format(model_name, model[\'source\'], model[\'targets\'][i], normalized_model_name2)\n            f.write(code)\n\n\ndef gen_tests(output_dir):\n    y = yaml.load(model_template_str)\n    length = len(y[\'models\'])\n    for i in range(length):\n        gen_test(output_dir, y[\'models\'][i][\'model\'])\n\n\ndef gen_travis(output_dir):\n    y = yaml.load(model_template_str)\n    travis_file = os.path.join(output_dir, \'travis.yml\')\n\n    env_str = \'\'\n    length = len(y[\'models\'])\n    for i in range(length):\n        model = y[\'models\'][i][\'model\']\n        model_name = model[\'name\']\n        normalized_model_name = model_name.replace(\'.\', \'_\')\n        source_framework = model[\'source\']\n        if False:\n            env_str += \'  - TEST_SOURCE_FRAMEWORK={0} TEST_MODEL={1}\\n\'.format(source_framework, normalized_model_name)\n        else:\n            length2 = len(model[\'targets\'])\n            for j in range(length2):\n                target_framework = model[\'targets\'][j]\n                env_str += \'  - TEST_SOURCE_FRAMEWORK={0} TEST_TARGET_FRAMEWORK={1} TEST_MODEL={2}\\n\'.format(source_framework, target_framework, normalized_model_name)\n\n    with open(travis_file, ""w+"") as f:\n        code = travis_template_str.format(env_str)\n        f.write(code)\n\n    return\n\n\ndef prepare_env(FLAGS):\n    output_dir = FLAGS.output_dir\n    if (not os.path.exists(output_dir)):\n        os.mkdir(output_dir)\n    if ((not os.path.isdir(output_dir)) or (not os.path.exists(output_dir))):\n        print(\'Cannot create target output directory: ""{0}""\'.format(output_dir))\n        return False\n    return True\n\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-o\', \'--output_dir\', help=\'The output directory.\', required=True)\n    FLAGS, unparsed = parser.parse_known_args()\n    if (not prepare_env(FLAGS)):\n        return\n\n    output_dir = FLAGS.output_dir\n    gen_travis(output_dir)\n    gen_tests(output_dir)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
tests/test_caffe.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'caffe' :\n        {\n            'alexnet'       : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'inception_v1'  : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            #Temporarily disable 'xception'      : [TestModels.coreml_emit, TestModels.cntk_emit, TestModels.tensorflow_emit],\n        }\n    }\n\ndef test_caffe():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('caffe', tester.caffe_parse)\n\n\nif __name__ == '__main__':\n    test_caffe()"""
tests/test_caffe_2.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'caffe' :\n        {\n            'resnet152'     : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'squeezenet'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n            ],\n        }\n    }\n\ndef test_caffe():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('caffe', tester.caffe_parse)\n\n\nif __name__ == '__main__':\n    test_caffe()"""
tests/test_caffe_3.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'caffe' :\n        {\n            'vgg19'         : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_caffe():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('caffe', tester.caffe_parse)\n\n\nif __name__ == '__main__':\n    test_caffe()"""
tests/test_caffe_4.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'caffe' :\n        {\n            # Cannot run on Travis since it seems to consume too much memory.\n            'voc-fcn8s'     : [\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.tensorflow_emit\n                ],\n            'voc-fcn16s'     : [\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.tensorflow_emit\n                ],\n            'voc-fcn32s'     : [\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.tensorflow_emit\n                ],\n            #Temporarily disable 'xception'      : [TestModels.mxnet_emit, TestModels.pytorch_emit],\n            #Temporarily disable 'inception_v4'  : [TestModels.cntk_emit, TestModels.coreml_emit, TestModels.keras_emit, TestModels.pytorch_emit, TestModels.tensorflow_emit],\n        }\n    }\n\ndef test_caffe():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('caffe', tester.caffe_parse)\n\n\nif __name__ == '__main__':\n    test_caffe()"""
tests/test_cntk.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'cntk' :\n        {\n            'inception_v3'     : [\n                TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                #TestModels.coreml_emit,\n                #TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'resnet18'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_cntk():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('cntk', tester.cntk_parse)\n\n\nif __name__ == '__main__':\n    test_cntk()\n"""
tests/test_cntk_2.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'cntk' :\n        {\n            'resnet152'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_cntk():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('cntk', tester.cntk_parse)\n\n\nif __name__ == '__main__':\n    test_cntk()\n"""
tests/test_coreml.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\nfrom conversion_imagenet import is_coreml_supported\n\ndef get_test_table():\n    return { 'coreml' :\n        {\n            'inception_v3'       : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'mobilenet'  : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n        }\n    }\n\n\ndef test_coreml():\n    if is_coreml_supported():\n        test_table = get_test_table()\n        tester = TestModels(test_table)\n        tester._test_function('coreml', tester.coreml_parse)\n\n\nif __name__ == '__main__':\n    test_coreml()\n"""
tests/test_coreml_2.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\nfrom conversion_imagenet import is_coreml_supported\n\ndef get_test_table():\n    return { 'coreml' :\n        {\n            'resnet50'       : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'vgg16'  : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'tinyyolo'  : [\n                TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                #TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                #TestModels.tensorflow_emit\n                ]\n        }\n    }\n\n\ndef test_coreml():\n    if is_coreml_supported():\n        test_table = get_test_table()\n        tester = TestModels(test_table)\n        tester._test_function('coreml', tester.coreml_parse)\n\n\nif __name__ == '__main__':\n    test_coreml()\n"""
tests/test_darknet.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'darknet' :\n        {\n            'yolov2'     : [\n                #TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                #TestModels.coreml_emit,\n                TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                #TestModels.tensorflow_emit\n                ],\n            'yolov3'     : [\n                #TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                #TestModels.coreml_emit,\n                TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                #TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_darknet():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('darknet', tester.darknet_parse)\n\n\nif __name__ == '__main__':\n    test_darknet()\n"""
tests/test_keras.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return {\n        'keras' : {\n            'vgg16'        : [\n                TestModels.onnx_emit\n                ],\n            'vgg19'        : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n    }}\n\n\ndef test_keras():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('keras', tester.keras_parse)\n\n\nif __name__ == '__main__':\n    test_keras()\n"""
tests/test_keras_2.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return {\n        'keras' : {\n            'resnet50'     : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n    }}\n\n\ndef test_keras():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('keras', tester.keras_parse)\n\n\nif __name__ == '__main__':\n    test_keras()\n"""
tests/test_keras_3.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return {\n        'keras' : {\n            'densenet'     : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n    }}\n\n\ndef test_keras():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('keras', tester.keras_parse)\n\n\nif __name__ == '__main__':\n    test_keras()\n"""
tests/test_keras_4.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return {\n        'keras' : {\n            'inception_v3' : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n    }}\n\n\ndef test_keras():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('keras', tester.keras_parse)\n\n\nif __name__ == '__main__':\n    test_keras()\n"""
tests/test_keras_5.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return {\n        'keras' : {\n            'mobilenet'     : [\n                TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'xception'     : [\n                #TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n    }}\n\n\ndef test_keras():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('keras', tester.keras_parse)\n\n\nif __name__ == '__main__':\n    test_keras()\n"""
tests/test_mxnet.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'mxnet' : {\n        'vgg19'      : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n        'squeezenet_v1.1'              : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n        'imagenet1k-inception-bn'        : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n        }\n    }\n\n\ndef test_mxnet():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('mxnet', tester.mxnet_parse)\n\n\nif __name__ == '__main__':\n    test_mxnet()\n\n"""
tests/test_mxnet_2.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'mxnet' : {\n        'imagenet1k-resnet-18'      : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n        'imagenet1k-resnet-152'              : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                #TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n    }}\n\n\ndef test_mxnet():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('mxnet', tester.mxnet_parse)\n\n\nif __name__ == '__main__':\n    test_mxnet()\n\n"""
tests/test_mxnet_3.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'mxnet' : {\n        'imagenet1k-resnet-152'              : [\n                #TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                #TestModels.coreml_emit,\n                TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                #TestModels.tensorflow_emit\n                ]\n    }}\n\n\ndef test_mxnet():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('mxnet', tester.mxnet_parse)\n\n\nif __name__ == '__main__':\n    test_mxnet()\n\n"""
tests/test_mxnet_4.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return {\n        'mxnet' : {\n            # Run too slow on Travis.\n            'imagenet1k-resnext-101-64x4d'      : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                # cntk_emit OOM on Travis\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n    }}\n\n\ndef test_mxnet():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('mxnet', tester.mxnet_parse)\n\n\nif __name__ == '__main__':\n    test_mxnet()\n\n"""
tests/test_mxnet_5.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport six\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'mxnet' : {        \n        'imagenet1k-resnext-50'              : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n    }}\n\n\ndef test_mxnet():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('mxnet', tester.mxnet_parse)\n\n\nif __name__ == '__main__':\n    test_mxnet()\n\n"""
tests/test_paddle.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\nfrom conversion_imagenet import is_paddle_supported\n\ndef get_test_table():\n    return { 'paddle' : {\n        'resnet50'      : [\n                TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n        'resnet101'              : [\n                #TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n        'vgg16'        : [\n                TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                #TestModels.coreml_emit,\n                #TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                #TestModels.tensorflow_emit\n                ],\n    }}\n\ndef test_paddle():\n    if not is_paddle_supported():\n        return\n    # omit tensorflow lead to crash\n    import tensorflow as tf\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('paddle', tester.paddle_parse)\n\n\nif __name__ == '__main__':\n    test_paddle()\n"""
tests/test_pytorch.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'pytorch' :\n        {\n            'densenet201'    : [\n                #TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_pytorch():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('pytorch', tester.pytorch_parse)\n\n\nif __name__ == '__main__':\n    test_pytorch()\n"""
tests/test_pytorch_2.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'pytorch' :\n        {\n            'inception_v3'    : [\n                #TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                #TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_pytorch():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('pytorch', tester.pytorch_parse)\n\n\nif __name__ == '__main__':\n    test_pytorch()\n"""
tests/test_pytorch_3.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'pytorch' :\n        {\n            'alexnet'    : [\n                #TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_pytorch():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('pytorch', tester.pytorch_parse)\n\n\nif __name__ == '__main__':\n    test_pytorch()\n"""
tests/test_pytorch_4.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'pytorch' :\n        {\n            'resnet152'    : [\n                #TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_pytorch():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('pytorch', tester.pytorch_parse)\n\n\nif __name__ == '__main__':\n    test_pytorch()\n"""
tests/test_pytorch_5.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'pytorch' :\n        {\n            'vgg19'    : [\n                #TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'vgg19_bn'    : [\n                #TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_pytorch():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function('pytorch', tester.pytorch_parse)\n\n\nif __name__ == '__main__':\n    test_pytorch()\n"""
tests/test_tensorflow.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { \'tensorflow\' :\n        {\n            \'vgg19\'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_tensorflow():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function(\'tensorflow\', tester.tensorflow_parse)\n\n\nif __name__ == ""__main__"":\n    test_tensorflow()\n'"
tests/test_tensorflow_2.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { \'tensorflow\' :\n        {\n            \'inception_v1\'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            \'inception_v3\'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_tensorflow():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function(\'tensorflow\', tester.tensorflow_parse)\n\n\nif __name__ == ""__main__"":\n    test_tensorflow()\n'"
tests/test_tensorflow_3.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { \'tensorflow\' :\n        {\n            \'mobilenet_v1_1.0\'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            \'mobilenet_v2_1.0_224\'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_tensorflow():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function(\'tensorflow\', tester.tensorflow_parse)\n\n\nif __name__ == ""__main__"":\n    test_tensorflow()\n'"
tests/test_tensorflow_4.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { \'tensorflow\' :\n        {\n            \'resnet_v1_152\'    : [\n                #TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_tensorflow():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function(\'tensorflow\', tester.tensorflow_parse)\n\n\nif __name__ == ""__main__"":\n    test_tensorflow()\n'"
tests/test_tensorflow_5.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { \'tensorflow\' :\n        {\n            \'resnet_v2_152\'    : [\n                #TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_tensorflow():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function(\'tensorflow\', tester.tensorflow_parse)\n\n\nif __name__ == ""__main__"":\n    test_tensorflow()\n'"
tests/test_tensorflow_6.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { \'tensorflow\' :\n        {\n            \'inception_resnet_v2\'    : [\n                TestModels.onnx_emit,\n                TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                #TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_tensorflow():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function(\'tensorflow\', tester.tensorflow_parse)\n\n\nif __name__ == ""__main__"":\n    test_tensorflow()\n'"
tests/test_tensorflow_7.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { \'tensorflow\' :\n        {\n            # Cannot run on Travis since it seems to consume too much memory.\n            \'nasnet-a_large\'    : [\n                #TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                #TestModels.coreml_emit,\n                #TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\ndef test_tensorflow():\n    test_table = get_test_table()\n    tester = TestModels(test_table)\n    tester._test_function(\'tensorflow\', tester.tensorflow_parse)\n\n\nif __name__ == ""__main__"":\n    test_tensorflow()\n'"
tests/test_tensorflow_frozen.py,0,"b""from __future__ import absolute_import\nfrom __future__ import print_function\n\nimport os\nimport sys\nfrom conversion_imagenet import TestModels\n\ndef get_test_table():\n    return { 'tensorflow_frozen' :\n        {\n            'inception_v1'    : [\n                TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'inception_v3'    : [\n                TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ],\n            'mobilenet_v1_1.0'    : [\n                TestModels.onnx_emit,\n                #TestModels.caffe_emit,\n                #TestModels.cntk_emit,\n                TestModels.coreml_emit,\n                TestModels.keras_emit,\n                TestModels.mxnet_emit,\n                #TestModels.pytorch_emit,\n                TestModels.tensorflow_emit\n                ]\n        }\n    }\n\n\ndef test_tensorflow_frozen():\n    tester = TestModels()\n    tester._test_function('tensorflow_frozen', tester.tensorflow_frozen_parse)\n\n\nif __name__ == '__main__':\n    test_tensorflow_frozen()\n"""
tests/utils.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\n__all__ = [\'ensure_dir\', \'checkfrozen\', \'CorrectnessTest\']\n\nimport os\nimport unittest\nimport numpy as np\n\ndef _compute_SNR(x,y):\n    noise = x - y\n    noise_var = np.sum(noise ** 2) / len(noise) + 1e-7\n    signal_energy = np.sum(y ** 2) / len(y)\n    max_signal_energy = np.amax(y ** 2)\n    SNR = 10 * np.log10(signal_energy / noise_var)\n    PSNR = 10 * np.log10(max_signal_energy / noise_var)\n    return SNR, PSNR\n\n\ndef _compute_max_relative_error(x, y):\n    from six.moves import xrange\n    rerror = 0\n    index = 0\n    for i in xrange(len(x)):\n        den = max(1.0, np.abs(x[i]), np.abs(y[i]))\n        if np.abs(x[i]/den - y[i] / den) > rerror:\n            rerror = np.abs(x[i] / den - y[i] / den)\n            index = i\n    return rerror, index\n\n\ndef _compute_L1_error(x, y):\n    return np.linalg.norm(x - y, ord=1)\n\n\ndef ensure_dir(f):\n    d = os.path.dirname(f)\n    if not os.path.exists(d):\n        os.makedirs(d)\n\ndef checkfrozen(f):\n    if f == \'tensorflow_frozen\':\n        return \'tensorflow\'\n    else:\n        return f\n\n\nclass CorrectnessTest(unittest.TestCase):\n\n    err_thresh = 0.15\n    snr_thresh = 12\n    psnr_thresh = 30\n\n    @classmethod\n    def setUpClass(cls):\n        """""" Set up the unit test by loading common utilities.\n        """"""\n        pass\n\n\n    def _compare_outputs(self, original_framework, target_framework, network_name, original_predict, converted_predict, need_assert=True):\n        # Function self.assertEquals has deprecated, change to assertEqual\n        if (converted_predict is None or original_predict is None) and not need_assert:\n            return\n\n        # self.assertEqual(original_predict.shape, converted_predict.shape)\n        original_predict = original_predict.flatten()\n        converted_predict = converted_predict.flatten()\n        len1 = original_predict.shape[0]\n        len2 = converted_predict.shape[0]\n        length = min(len1, len2)\n        original_predict = np.sort(original_predict)[::-1]\n        converted_predict = np.sort(converted_predict)[::-1]\n        original_predict = original_predict[0:length]\n        converted_predict = converted_predict[0:length]\n        error, ind = _compute_max_relative_error(converted_predict, original_predict)\n        L1_error = _compute_L1_error(converted_predict, original_predict)\n        SNR, PSNR = _compute_SNR(converted_predict, original_predict)\n        print(""error:"", error)\n        print(""L1 error:"", L1_error)\n        print(""SNR:"", SNR)\n        print(""PSNR:"", PSNR)\n\n        if need_assert:\n            self.assertGreater(SNR, self.snr_thresh, ""Error in converting {} from {} to {}"".format(network_name, original_framework, target_framework))\n            self.assertGreater(PSNR, self.psnr_thresh, ""Error in converting {} from {} to {}"".format(network_name, original_framework, target_framework))\n            self.assertLess(error, self.err_thresh, ""Error in converting {} from {} to {}"".format(network_name, original_framework, target_framework))\n'"
mmdnn/conversion/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/models/GenerateMdByDataset.py,0,"b'import json\nimport os\nimport argparse\n\nmarkdown_code = str()\n\nframework_list = [\'caffe\', \'cntk\', \'coreml\', \'darknet\', \'mxnet\', \'pytorch\', \'tensorflow\']  # Haven\'t added \'keras\' yet\nframe_model_map = {\n     \'caffe\': {\'architecture\':\'prototxt\', \'weights\':\'caffemodel\'},\n     \'cntk\': {\'architecture\':\'model\'},\n     \'coreml\': {\'architecture\':\'mlmodel\'},\n     \'darknet\': {\'architecture\':\'cfg\', \'weights\':\'weights\'},\n     \'mxnet\': {\'architecture\':\'json\', \'weights\':\'params\'},\n     \'pytorch\': {\'architecture\':\'pth\'},\n     \'tensorflow\': {\'architecture\':\'tgz\'}\n}  # Haven\'t add \'keras\' yet\ndataset_list = [\'imagenet\', \'imagenet11k\', \'Pascal VOC\', \'grocery100\']\n\ndef add_code(code):\n    global markdown_code\n    markdown_code += code\n\ndef add_header(level, code):\n    add_code(""#"" * level + "" "" + code + \'\\n\\n\')\n\ndef draw_line(num):\n    add_code(""| "" * num + ""|\\n"")\n    add_code((""|-"" * num + ""|\\n""))\n\ndef save_code(filepath):\n    with open(filepath, \'w\') as f:\n        f.write(markdown_code)\n    print(""Markdown generate succeeded!"")\n\ndef LoadJson(json_path):\n    with open(json_path, encoding=\'utf-8\') as f:\n        data = json.load(f)\n    return data\n\ndef RegenerateJsonByDataset(data):\n    new_data = {}\n    new_data[\'dataset\'] = {}\n    for i in range(len(dataset_list)):\n        new_data[\'dataset\'][dataset_list[i]] = []\n    for mo in data[\'models\']:\n        ds = mo[\'dataset\']\n        item = {}\n        item[\'name\'] = mo[\'name\']\n        item[\'framework\'] = mo[\'framework\']\n        item[\'source\'] = mo[\'source\']\n        item[\'link\'] = mo[\'link\']\n        item[\'version\'] = """"\n        new_data[\'dataset\'][ds].append(item)\n\n    # with open(\'modelmapbydataset.json\', \'w\') as outfile:\n    #     json.dump(new_data, outfile)\n    return new_data\n\ndef GenerateModelBlock_v2(model):\n    link = model[\'link\']\n    framework = model[\'framework\']\n\n    # generate makedown script\n    add_code(\'\'\'|<b>{}</b><br />Framework: {}<br />Download: \'\'\'.format(\n        model[\'name\'],\n        model[\'framework\']\n    ))\n    for k in link.keys():\n        if link[k]:\n            add_code(""[{}]({}) "".format(\n                frame_model_map[framework][k],\n                link[k]\n            ))\n    add_code(""<br />Source: "")\n    if (model[\'source\']!=""""):\n        add_code(""[Link]({})"".format(model[\'source\']))\n    add_code(""<br />"")\n\ndef DrawTableBlock(data, dataset_name):\n    colnum = 3\n    add_header(3, dataset_name)\n    draw_line(colnum)\n    models = data[\'dataset\'][dataset_name]\n    num = 0\n    for i in range(len(models)):\n        if ((models[i][\'framework\']!=\'keras\') and (models[i][\'link\'][\'architecture\']!="""")):\n            GenerateModelBlock_v2(models[i])\n            num += 1\n            if num % colnum == 0:\n                add_code(""\\n"")\n    add_code(""\\n"")\n\ndef GenerateModelsList_v2(data):\n\n    add_header(1, ""Model Collection"")\n\n    # add Image Classification\n    add_header(2, ""Image Classification"")\n    for ds_name in [\'imagenet\', \'imagenet11k\']:\n        DrawTableBlock(data, ds_name)\n\n    # add Object Detection\n    add_header(2, ""Object Detection"")\n    for ds_name in [\'Pascal VOC\', \'grocery100\']:\n        DrawTableBlock(data, ds_name)\n\n    add_code(""\\n"")\n\ndef GenerateIntroductionAndTutorial():\n    # MMdnn introduction\n    add_header(1, ""Introduction"")\n    text_intro=\'\'\'This is a collection of pre-trained models in different deep learning frameworks.\\n\nYou can download the model you want by simply click the download link.\\n\nWith the download model, you can convert them to different frameworks.\\n\nNext session show an example to show you how to convert pre-trained model between frameworks.\\n\\n\'\'\'\n    add_code(text_intro)\n\n    # steps for model conversion\n    add_header(2, ""Steps to Convert Model"")\n    text_example=\'\'\'**Example: Convert vgg19 model from Tensorflow to CNTK**\\n\n1. Install the stable version of MMdnn\n    ```bash\n    pip install mmdnn\n    ```\n2. Download Tensorflow pre-trained model\n    - [x] **Method 1:** Directly download from below model collection\n    - [x] **Method 2:** Use command line\n    ```bash\n        $ mmdownload -f tensorflow -n vgg19\n\n        Downloading file [./vgg_19_2016_08_28.tar.gz] from [http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz]\n        progress: 520592.0 KB downloaded, 100%\n        Model saved in file: ./imagenet_vgg19.ckpt\n    ```\n    **NOTICE:** _the model name after the **\'-n\'** argument must be the models appearence in the below model collection._\n\n3. Convert model architecture(*.ckpt.meta) and weights(.ckpt) from Tensorflow to IR\n    ```bash\n    $ mmtoir -f tensorflow -d vgg19 -n imagenet_vgg19.ckpt.meta -w imagenet_vgg19.ckpt  --dstNodeName MMdnn_Output\n\n    Parse file [imagenet_vgg19.ckpt.meta] with binary format successfully.\n    Tensorflow model file [imagenet_vgg19.ckpt.meta] loaded successfully.\n    Tensorflow checkpoint file [imagenet_vgg19.ckpt] loaded successfully. [38] variables loaded.\n    IR network structure is saved as [vgg19.json].\n    IR network structure is saved as [vgg19.pb].\n    IR weights are saved as [vgg19.npy].\n    ```\n4. Convert models from IR to PyTorch code snippet and weights\n    ```bash\n    $ mmtocode -f pytorch -n vgg19.pb --IRWeightPath vgg19.npy --dstModelPath pytorch_vgg19.py -dw pytorch_vgg19.npy\n\n    Parse file [vgg19.pb] with binary format successfully.\n    Target network code snippet is saved as [pytorch_vgg19.py].\n    Target weights are saved as [pytorch_vgg19.npy].\n    ```\n5. Generate PyTorch model from code snippet file and weight file\n    ```bash\n    $ mmtomodel -f pytorch -in pytorch_vgg19.py -iw pytorch_vgg19.npy --o pytorch_vgg19.pth\n\n    PyTorch model file is saved as [pytorch_vgg19.pth], generated by [pytorch_vgg19.py] and [pytorch_vgg19.npy].\n    Notice that you may need [pytorch_vgg19.py] to load the model back.\n    ```\n\'\'\'\n    add_code(text_example)\n    add_code(""\\n\\n"")\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-f\', \'--file\', type=str, default=""modelmap2.json"", help=""the path of json file"")\n    parser.add_argument(\'-d\', \'--distFile\', type=str, default=""Collection_v2.md"", help=""the path of the readme file"")\n    args = parser.parse_args()\n\n    # Generate model converter description\n    GenerateIntroductionAndTutorial()\n\n    # Generate models list\n    data = LoadJson(args.file)\n    new_data = RegenerateJsonByDataset(data)\n    GenerateModelsList_v2(new_data)\n    save_code(args.distFile)\n\nif __name__ == ""__main__"":\n    main()\n'"
mmdnn/models/GenerateMdFromJson.py,0,"b'import json\nimport os\nimport argparse\n\nmarkdown_code = str()\n\nframework_list = [\'caffe\', \'cntk\', \'coreml\', \'darknet\', \'mxnet\', \'pytorch\', \'tensorflow\']  # Haven\'t add \'keras\' yet\nframe_model_map = {\n     \'caffe\': {\'architecture\':\'prototxt\', \'weights\':\'caffemodel\'},\n     \'cntk\': {\'architecture\':\'model\'},\n     \'coreml\': {\'architecture\':\'mlmodel\'},\n     \'darknet\': {\'architecture\':\'cfg\', \'weights\':\'weights\'},\n     \'mxnet\': {\'architecture\':\'json\', \'weights\':\'params\'},\n     \'pytorch\': {\'architecture\':\'pth\'},\n     \'tensorflow\': {\'architecture\':\'tgz\'}\n}  # Haven\'t add \'keras\' yet\ndataset_list = [\'imagenet\', \'imagenet11k\', \'Pascal VOC\', \'grocery100\']\n\ndef add_code(code):\n    global markdown_code\n    markdown_code += code\n\ndef add_header(level, code):\n    add_code(""#"" * level + "" "" + code + \'\\n\\n\')\n\ndef draw_line(num):\n    add_code(""| "" * num + ""|\\n"")\n    add_code((""|-"" * num + ""|\\n""))\n\ndef save_code(filepath):\n    with open(filepath, \'w\') as f:\n        f.write(markdown_code)\n    print(""Markdown generate succeeded!"")\n\ndef LoadJson(json_path):\n    with open(json_path, encoding=\'utf-8\') as f:\n        data = json.load(f)\n    return data\n\ndef GenerateModelBlock(model):\n    link = model[""link""]\n    framework = model[""framework""]\n\n    # generate makedown script\n    add_code(\'\'\'|<b>{}</b><br />Framework: {}<br />Dataset: _{}_ <br />Download: \'\'\'.format(\n        model[""name""],\n        model[""framework""],\n        model[""dataset""],\n    ))\n    for k in link.keys():\n        if link[k]:\n            add_code(""[{}]({}) "".format(frame_model_map[framework][k], link[k]))\n    add_code(""<br />Source: "")\n    if (model[""source""]!=""""):\n        add_code(""[Link]({})"".format(model[""source""]))\n    add_code(""<br />"")\n\ndef GenerateModelsList(data):\n    colnum = 3\n    add_header(1, ""Model Collection"")\n    draw_line(colnum)\n    models = data[""models""]\n    num = 0\n    for i in range(len(data[""models""])):\n        if ((models[i][""framework""]!=""keras"") and (models[i][""link""][""architecture""]!="""")):\n            GenerateModelBlock(models[i])\n            num += 1\n            if num % colnum == 0:\n                add_code(""\\n"")\n    add_code(""\\n"")\n\ndef GenerateIntroductionAndTutorial():\n    # MMdnn introduction\n    add_header(1, ""Introduction"")\n    text_intro=\'\'\'This is a collection of pre-trained models in different deep learning frameworks.\\n\nYou can download the model you want by simply click the download link.\\n\nWith the download model, you can convert them to different frameworks.\\n\nNext session show an example to show you how to convert pre-trained model between frameworks.\\n\\n\'\'\'\n    add_code(text_intro)\n\n    # steps for model conversion\n    add_header(2, ""Steps to Convert Model"")\n    text_example=\'\'\'**Example: Convert vgg19 model from Tensorflow to CNTK**\\n\n1. Install the stable version of MMdnn\n    ```bash\n    pip install mmdnn\n    ```\n2. Download Tensorflow pre-trained model\n    - [x] **Method 1:** Directly download from below model collection\n    - [x] **Method 2:** Use command line\n    ```bash\n        $ mmdownload -f tensorflow -n vgg19\n\n        Downloading file [./vgg_19_2016_08_28.tar.gz] from [http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz]\n        progress: 520592.0 KB downloaded, 100%\n        Model saved in file: ./imagenet_vgg19.ckpt\n    ```\n    **NOTICE:** _the model name after the **\'-n\'** argument must be the models appearence in the below model collection._\n\n3. Convert model architecture(*.ckpt.meta) and weights(.ckpt) from Tensorflow to IR\n    ```bash\n    $ mmtoir -f tensorflow -d vgg19 -n imagenet_vgg19.ckpt.meta -w imagenet_vgg19.ckpt  --dstNodeName MMdnn_Output\n\n    Parse file [imagenet_vgg19.ckpt.meta] with binary format successfully.\n    Tensorflow model file [imagenet_vgg19.ckpt.meta] loaded successfully.\n    Tensorflow checkpoint file [imagenet_vgg19.ckpt] loaded successfully. [38] variables loaded.\n    IR network structure is saved as [vgg19.json].\n    IR network structure is saved as [vgg19.pb].\n    IR weights are saved as [vgg19.npy].\n    ```\n4. Convert models from IR to PyTorch code snippet and weights\n    ```bash\n    $ mmtocode -f pytorch -n vgg19.pb --IRWeightPath vgg19.npy --dstModelPath pytorch_vgg19.py -dw pytorch_vgg19.npy\n\n    Parse file [vgg19.pb] with binary format successfully.\n    Target network code snippet is saved as [pytorch_vgg19.py].\n    Target weights are saved as [pytorch_vgg19.npy].\n    ```\n5. Generate PyTorch model from code snippet file and weight file\n    ```bash\n    $ mmtomodel -f pytorch -in pytorch_vgg19.py -iw pytorch_vgg19.npy --o pytorch_vgg19.pth\n\n    PyTorch model file is saved as [pytorch_vgg19.pth], generated by [pytorch_vgg19.py] and [pytorch_vgg19.npy].\n    Notice that you may need [pytorch_vgg19.py] to load the model back.\n    ```\n\'\'\'\n    add_code(text_example)\n    add_code(""\\n\\n"")\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-f\', \'--file\', type=str, default=""modelmap2.json"", help=""the path of json file"")\n    parser.add_argument(\'-d\', \'--distFile\', type=str, default=""README.md"", help=""the path of the readme file"")\n    args = parser.parse_args()\n\n    # Generate model converter description\n    GenerateIntroductionAndTutorial()\n\n    # Generate models list\n    data = LoadJson(args.file)\n    GenerateModelsList(data)\n    save_code(args.distFile)\n\nif __name__ == ""__main__"":\n    main()'"
mmdnn/conversion/_script/IRToCode.py,1,"b'import sys as _sys\nimport google.protobuf.text_format as text_format\nfrom six import text_type as _text_type\n\n\n\ndef _convert(args):\n    if args.dstFramework == \'caffe\':\n        from mmdnn.conversion.caffe.caffe_emitter import CaffeEmitter\n        if args.IRWeightPath is None:\n            emitter = CaffeEmitter(args.IRModelPath)\n        else:\n            assert args.dstWeightPath\n            emitter = CaffeEmitter((args.IRModelPath, args.IRWeightPath))\n\n    elif args.dstFramework == \'keras\':\n        from mmdnn.conversion.keras.keras2_emitter import Keras2Emitter\n        emitter = Keras2Emitter((args.IRModelPath, args.IRWeightPath))\n\n    elif args.dstFramework == \'tensorflow\':\n        from mmdnn.conversion.tensorflow.tensorflow_emitter import TensorflowEmitter\n        if args.IRWeightPath is None:\n            # Convert network architecture only\n            emitter = TensorflowEmitter(args.IRModelPath)\n        else:\n            emitter = TensorflowEmitter((args.IRModelPath, args.IRWeightPath))\n\n    elif args.dstFramework == \'cntk\':\n        from mmdnn.conversion.cntk.cntk_emitter import CntkEmitter\n        if args.IRWeightPath is None:\n            emitter = CntkEmitter(args.IRModelPath)\n        else:\n            emitter = CntkEmitter((args.IRModelPath, args.IRWeightPath))\n\n    elif args.dstFramework == \'coreml\':\n        raise NotImplementedError(""CoreML emitter is not finished yet."")\n\n    elif args.dstFramework == \'pytorch\':\n        if not args.dstWeightPath or not args.IRWeightPath:\n            raise ValueError(""Need to set a target weight filename."")\n        from mmdnn.conversion.pytorch.pytorch_emitter import PytorchEmitter\n        emitter = PytorchEmitter((args.IRModelPath, args.IRWeightPath))\n\n    elif args.dstFramework == \'mxnet\':\n        from mmdnn.conversion.mxnet.mxnet_emitter import MXNetEmitter\n        if args.IRWeightPath is None:\n            emitter = MXNetEmitter(args.IRModelPath)\n        else:\n            if args.dstWeightPath is None:\n                raise ValueError(""MXNet emitter needs argument [dstWeightPath(dw)], like -dw mxnet_converted-0000.param"")\n            emitter = MXNetEmitter((args.IRModelPath, args.IRWeightPath, args.dstWeightPath))\n    elif args.dstFramework == \'onnx\':\n        from mmdnn.conversion.onnx.onnx_emitter import OnnxEmitter\n        if args.IRWeightPath is None:\n            raise NotImplementedError(""ONNX emitter needs IR weight file"")\n        else:\n            emitter = OnnxEmitter(args.IRModelPath, args.IRWeightPath)\n    else:\n        assert False\n\n    emitter.run(args.dstModelPath, args.dstWeightPath, args.phase)\n\n    return 0\n\n\ndef _get_parser():\n    import argparse\n\n    parser = argparse.ArgumentParser(description = \'Convert IR model file formats to other format.\')\n\n    parser.add_argument(\n        \'--phase\',\n        type=_text_type,\n        choices=[\'train\', \'test\'],\n        default=\'test\',\n        help=\'Convert phase (train/test) for destination toolkits.\'\n    )\n\n    parser.add_argument(\n        \'--dstFramework\', \'-f\',\n        type=_text_type,\n        choices=[\'caffe\', \'caffe2\', \'cntk\', \'mxnet\', \'keras\', \'tensorflow\', \'coreml\', \'pytorch\', \'onnx\'],\n        required=True,\n        help=\'Format of model at srcModelPath (default is to auto-detect).\')\n\n    parser.add_argument(\n        \'--IRModelPath\', \'-n\', \'-in\',\n        type=_text_type,\n        required=True,\n        help=\'Path to the IR network structure file.\')\n\n    parser.add_argument(\n        \'--IRWeightPath\', \'-w\', \'-iw\',\n        type=_text_type,\n        required=False,\n        default=None,\n        help = \'Path to the IR network structure file.\')\n\n    parser.add_argument(\n        \'--dstModelPath\', \'-d\', \'-o\',\n        type = _text_type,\n        required = True,\n        help = \'Path to save the destination model\')\n\n    # MXNet\n    parser.add_argument(\n        \'--dstWeightPath\', \'-dw\', \'-ow\',\n        type=_text_type,\n        default=None,\n        help=\'[MXNet] Path to save the destination weight.\')\n    return parser\n\n\ndef _main():\n    parser=_get_parser()\n    args = parser.parse_args()\n    ret = _convert(args)\n    _sys.exit(int(ret)) # cast to int or else the exit code is always 1\n\n\nif __name__ == \'__main__\':\n    _main()'"
mmdnn/conversion/_script/IRToModel.py,1,"b'import sys as _sys\nimport google.protobuf.text_format as text_format\nfrom six import text_type as _text_type\n\n\n\ndef _convert(args):\n    if args.framework == \'caffe\':\n        raise NotImplementedError(""Destination [Caffe] is not implemented yet."")\n\n    elif args.framework == \'keras\':\n        raise NotImplementedError(""Destination [Keras] is not implemented yet."")\n\n    elif args.framework == \'tensorflow\':\n        raise NotImplementedError(""Destination [Tensorflow] is not implemented yet."")\n\n    elif args.framework == \'cntk\':\n        raise NotImplementedError(""Destination [CNTK] is not implemented yet."")\n\n    elif args.framework == \'coreml\':\n        from mmdnn.conversion.coreml.coreml_emitter import CoreMLEmitter\n        assert args.inputNetwork is not None\n        assert args.inputWeight is not None\n        emitter = CoreMLEmitter(args.inputNetwork, args.inputWeight)\n        model, in_, out_ = emitter.gen_model(\n            args.inputNames,\n            args.outputNames,\n            image_input_names = set(args.imageInputNames) if args.imageInputNames else None,\n            is_bgr = args.isBGR,\n            red_bias = args.redBias,\n            blue_bias = args.blueBias,\n            green_bias = args.greenBias,\n            gray_bias = args.grayBias,\n            image_scale = args.scale,\n            class_labels = args.classInputPath if args.classInputPath else None,\n            predicted_feature_name = args.predictedFeatureName)\n\n        """"""\n        from google.protobuf import text_format\n        with open(args.output+\'.txt\', \'w\') as f:\n            f.write(text_format.MessageToString(model))\n        """"""\n\n        with open(args.output, \'wb\') as f:\n            model = model.SerializeToString()\n            f.write(model)\n\n\n        return 0\n\n    elif args.framework == \'pytorch\':\n        if not args.dstWeightPath or not args.IRWeightPath:\n            raise ValueError(""Need to set a target weight filename."")\n        from mmdnn.conversion.pytorch.pytorch_emitter import PytorchEmitter\n        emitter = PytorchEmitter((args.IRModelPath, args.IRWeightPath))\n\n    elif args.framework == \'mxnet\':\n        from mmdnn.conversion.mxnet.mxnet_emitter import MXNetEmitter\n        if args.IRWeightPath == None:\n            emitter = MXNetEmitter(args.IRModelPath)\n        else:\n            emitter = MXNetEmitter((args.IRModelPath, args.IRWeightPath, args.inputShape, args.dstWeightPath))\n\n    else:\n        assert False\n\n    emitter.run(args.output)\n\n    return 0\n\n\ndef _get_parser():\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\'Convert IR model file formats to other format.\')\n\n    parser.add_argument(\n        \'-f\', \'--framework\', type=_text_type, choices=[\'coreml\'], required=True,\n        help=\'Format of model at srcModelPath (default is to auto-detect).\'\n    )\n\n    parser.add_argument(\n        \'-in\', \'--inputNetwork\',\n        type=_text_type,\n        required=True,\n        help=\'Path of the IR network architecture file.\')\n\n    parser.add_argument(\n        \'-iw\', \'--inputWeight\',\n        type=_text_type,\n        required=True,\n        help=\'Path to the IR network weight file.\')\n\n    parser.add_argument(\n        \'-o\', \'--output\',\n        type=_text_type,\n        required=True,\n        help=\'Path to save the destination model\')\n\n    # Caffe\n    parser.add_argument(\n        \'--phase\', type=_text_type, choices=[\'train\', \'test\'], default=\'test\',\n        help=\'[Caffe] Convert phase (train/test) for destination toolkits.\'\n    )\n\n    # For CoreML\n    parser.add_argument(\'--inputNames\', type=_text_type, nargs=\'*\', help=\'Names of the feature (input) columns, in order (required for keras models).\')\n    parser.add_argument(\'--outputNames\', type=_text_type, nargs=\'*\', help=\'Names of the target (output) columns, in order (required for keras models).\')\n    parser.add_argument(\'--imageInputNames\', type=_text_type, default=[], action=\'append\', help=\'Label the named input as an image. Can be specified more than once for multiple image inputs.\')\n    parser.add_argument(\'--isBGR\', action=\'store_true\', default=False, help=\'True if the image data in BGR order (RGB default)\')\n    parser.add_argument(\'--redBias\', type=float, default=0.0, help=\'Bias value to be added to the red channel (optional, default 0.0)\')\n    parser.add_argument(\'--blueBias\', type=float, default=0.0, help=\'Bias value to be added to the blue channel (optional, default 0.0)\')\n    parser.add_argument(\'--greenBias\', type=float, default=0.0, help=\'Bias value to be added to the green channel (optional, default 0.0)\')\n    parser.add_argument(\'--grayBias\', type=float, default=0.0, help=\'Bias value to be added to the gray channel for Grayscale images (optional, default 0.0)\')\n    parser.add_argument(\'--scale\', type=float, default=1.0, help=\'Value by which the image data must be scaled (optional, default 1.0)\')\n    parser.add_argument(\'--classInputPath\', type=_text_type, default=\'\', help=\'Path to class labels (ordered new line separated) for treating the neural network as a classifier\')\n    parser.add_argument(\'--predictedFeatureName\', type=_text_type, default=\'class_output\', help=\'Name of the output feature that captures the class name (for classifiers models).\')\n    return parser\n\n\ndef _main():\n    parser=_get_parser()\n    args = parser.parse_args()\n    ret = _convert(args)\n    _sys.exit(int(ret)) # cast to int or else the exit code is always 1\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/_script/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function'
mmdnn/conversion/_script/convert.py,0,"b'import sys as _sys\nimport argparse\nimport mmdnn.conversion._script.convertToIR as convertToIR\nimport mmdnn.conversion._script.IRToCode as IRToCode\nimport mmdnn.conversion._script.IRToModel as IRToModel\nfrom six import text_type as _text_type\nimport uuid\nimport os\n\n\ndef _get_parser():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        \'--srcFramework\', \'-sf\',\n        type=_text_type,\n        choices=[""caffe"", ""caffe2"", ""cntk"", ""mxnet"", ""keras"", ""tensorflow"", \'tf\', \'pytorch\'],\n        help=""Source toolkit name of the model to be converted."")\n    parser.add_argument(\n        \'--inputWeight\', \'-iw\',\n        type=_text_type,\n        default=None,\n        help=\'Path to the model weights file of the external tool (e.g caffe weights proto binary, keras h5 binary\')\n    parser.add_argument(\n        \'--inputNetwork\', \'-in\',\n        type=_text_type,\n        default=None,\n        help=\'Path to the model network file of the external tool (e.g caffe prototxt, keras json\')\n    parser.add_argument(\n        \'--dstFramework\', \'-df\',\n        type=_text_type,\n        choices=[\'caffe\', \'caffe2\', \'cntk\', \'mxnet\', \'keras\', \'tensorflow\', \'coreml\', \'pytorch\', \'onnx\'],\n        required=True,\n        help=\'Format of model at srcModelPath (default is to auto-detect).\')\n    parser.add_argument(\n        \'--outputModel\', \'-om\',\n        type=_text_type,\n        required=True,\n        help=\'Path to save the destination model\')\n    parser.add_argument(\n        \'--dump_tag\',\n        type=_text_type,\n        default=None,\n        help=\'Tensorflow model dump type\',\n        choices=[\'SERVING\', \'TRAINING\'])\n\n    return parser\n\n\ndef _extract_ir_args(args, unknown_args, temp_filename):\n    unknown_args.extend([\'--srcFramework\', args.srcFramework])\n    if args.inputWeight is not None:\n        unknown_args.extend([\'--weights\', args.inputWeight])\n    if args.inputNetwork is not None:\n        unknown_args.extend([\'--network\', args.inputNetwork])\n    unknown_args.extend([\'--dstPath\', temp_filename])\n\n    ir_parser = convertToIR._get_parser()\n    return ir_parser.parse_known_args(unknown_args)\n\n\ndef _extract_code_args(args, unknown_args, temp_filename,network_filename):\n    unknown_args.extend([\'--dstFramework\', args.dstFramework])\n    unknown_args.extend([\'--IRModelPath\', temp_filename + \'.pb\'])\n    unknown_args.extend([\'--IRWeightPath\', temp_filename + \'.npy\'])\n    unknown_args.extend([\'--dstModelPath\', network_filename + \'.py\'])\n    unknown_args.extend([\'--dstWeightPath\', temp_filename + \'.npy\'])\n    code_parser = IRToCode._get_parser()\n    return code_parser.parse_known_args(unknown_args)\n\n\ndef _extract_model_args(args, unknown_args, temp_filename):\n    unknown_args.extend([\'--framework\', args.dstFramework])\n    unknown_args.extend([\'--inputNetwork\', temp_filename + \'.pb\'])\n    unknown_args.extend([\'--inputWeight\', temp_filename + \'.npy\'])\n    unknown_args.extend([\'--output\', args.outputModel])\n    model_parser = IRToModel._get_parser()\n    return model_parser.parse_known_args(unknown_args)\n\n\ndef remove_temp_files(temp_filename, verbose=False):\n    exts = [\'.json\', \'.pb\', \'.npy\', \'.py\']\n    # exts = [\'.pb\', \'.npy\', \'.py\']\n    for ext in exts:\n        temp_file = temp_filename + ext\n        if os.path.isfile(temp_file):\n            os.remove(temp_file)\n            if verbose:\n                print(\'temporary file [{}] has been removed.\'.format(temp_file))\n\ndef get_network_filename(framework, temp_filename, output_model_filename):\n    if framework in [\'pytorch\']:\n        return os.path.join(os.path.dirname(output_model_filename), os.path.basename(output_model_filename).split(\'.\')[0])\n    return temp_filename\n\n\ndef _main():\n    parser = _get_parser()\n    args, unknown_args = parser.parse_known_args()\n    temp_filename = uuid.uuid4().hex\n    ir_args, unknown_args = _extract_ir_args(args, unknown_args, temp_filename)\n    ret = convertToIR._convert(ir_args)\n    if int(ret) != 0:\n        _sys.exit(int(ret))\n    if args.dstFramework != \'coreml\':\n        network_filename = get_network_filename(args.dstFramework, temp_filename, args.outputModel)\n        code_args, unknown_args = _extract_code_args(args, unknown_args, temp_filename, network_filename)\n        ret = IRToCode._convert(code_args)\n        if int(ret) != 0:\n            _sys.exit(int(ret))\n        from mmdnn.conversion._script.dump_code import dump_code\n        dump_code(args.dstFramework, network_filename + \'.py\', temp_filename + \'.npy\', args.outputModel, args.dump_tag)\n        remove_temp_files(temp_filename)\n\n    else:\n        model_args, unknown_args = _extract_model_args(args, unknown_args, temp_filename)\n        ret = IRToModel._convert(model_args)\n        remove_temp_files(temp_filename)\n        _sys.exit(int(ret))\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/_script/convertToIR.py,2,"b'import sys as _sys\nimport google.protobuf.text_format as text_format\nfrom six import text_type as _text_type\n\n\ndef _convert(args):\n    if args.inputShape != None:\n        inputshape = []\n        for x in args.inputShape:\n            shape = x.split(\',\')\n            inputshape.append([int(x) for x in shape])\n    else:\n        inputshape = [None]\n    if args.srcFramework == \'caffe\':\n        from mmdnn.conversion.caffe.transformer import CaffeTransformer\n        transformer = CaffeTransformer(args.network, args.weights, ""tensorflow"", inputshape[0], phase = args.caffePhase)\n        graph = transformer.transform_graph()\n        data = transformer.transform_data()\n\n        from mmdnn.conversion.caffe.writer import JsonFormatter, ModelSaver, PyWriter\n        JsonFormatter(graph).dump(args.dstPath + "".json"")\n        print (""IR network structure is saved as [{}.json]."".format(args.dstPath))\n\n        prototxt = graph.as_graph_def().SerializeToString()\n        with open(args.dstPath + "".pb"", \'wb\') as of:\n            of.write(prototxt)\n        print (""IR network structure is saved as [{}.pb]."".format(args.dstPath))\n\n        import numpy as np\n        with open(args.dstPath + "".npy"", \'wb\') as of:\n            np.save(of, data)\n        print (""IR weights are saved as [{}.npy]."".format(args.dstPath))\n\n        return 0\n\n    elif args.srcFramework == \'caffe2\':\n        raise NotImplementedError(""Caffe2 is not supported yet."")\n\n    elif args.srcFramework == \'keras\':\n        if args.network != None:\n            model = (args.network, args.weights)\n        else:\n            model = args.weights\n\n        from mmdnn.conversion.keras.keras2_parser import Keras2Parser\n        parser = Keras2Parser(model)\n\n    elif args.srcFramework == \'tensorflow\' or args.srcFramework == \'tf\':\n        assert args.network or args.weights\n        if not args.network:\n            if args.dstNodeName is None:\n                raise ValueError(""Need to provide the output node of Tensorflow model."")\n            if args.inNodeName is None:\n                raise ValueError(""Need to provide the input node of Tensorflow model."")\n            if inputshape is None:\n                raise ValueError(""Need to provide the input node shape of Tensorflow model."")\n            assert len(args.inNodeName) == len(inputshape)\n            from mmdnn.conversion.tensorflow.tensorflow_frozenparser import TensorflowParser2\n            parser = TensorflowParser2(args.weights, inputshape, args.inNodeName, args.dstNodeName)\n\n        else:\n            from mmdnn.conversion.tensorflow.tensorflow_parser import TensorflowParser\n            if args.inNodeName and inputshape[0]:\n                parser = TensorflowParser(args.network, args.weights, args.dstNodeName, inputshape[0], args.inNodeName)\n            else:\n                parser = TensorflowParser(args.network, args.weights, args.dstNodeName)\n\n    elif args.srcFramework == \'mxnet\':\n        assert inputshape != None\n        if args.weights == None:\n            model = (args.network, inputshape[0])\n        else:\n            import re\n            if re.search(\'.\', args.weights):\n                args.weights = args.weights[:-7]\n            prefix, epoch = args.weights.rsplit(\'-\', 1)\n            model = (args.network, prefix, epoch, inputshape[0])\n\n        from mmdnn.conversion.mxnet.mxnet_parser import MXNetParser\n        parser = MXNetParser(model)\n\n    elif args.srcFramework == \'cntk\':\n        from mmdnn.conversion.cntk.cntk_parser import CntkParser\n        model = args.network or args.weights\n        parser = CntkParser(model)\n\n    elif args.srcFramework == \'pytorch\':\n        assert inputshape != None\n        from mmdnn.conversion.pytorch.pytorch_parser import PytorchParser\n        model = args.network or args.weights\n        assert model != None\n        parser = PytorchParser(model, inputshape[0])\n\n    elif args.srcFramework == \'torch\' or args.srcFramework == \'torch7\':\n        from mmdnn.conversion.torch.torch_parser import TorchParser\n        model = args.network or args.weights\n        assert model != None\n        parser = TorchParser(model, inputshape[0])\n\n    elif args.srcFramework == \'onnx\':\n        from mmdnn.conversion.onnx.onnx_parser import ONNXParser\n        parser = ONNXParser(args.network)\n\n    elif args.srcFramework == \'darknet\':\n        from mmdnn.conversion.darknet.darknet_parser import DarknetParser\n        parser = DarknetParser(args.network, args.weights, args.darknetStart)\n\n    elif args.srcFramework == \'coreml\':\n        from mmdnn.conversion.coreml.coreml_parser import CoremlParser\n        parser = CoremlParser(args.network)\n\n    else:\n        raise ValueError(""Unknown framework [{}]."".format(args.srcFramework))\n\n    parser.run(args.dstPath)\n\n    return 0\n\n\ndef _get_parser():\n    import argparse\n\n    parser = argparse.ArgumentParser(description = \'Convert other model file formats to IR format.\')\n\n    parser.add_argument(\n        \'--srcFramework\', \'-f\',\n        type=_text_type,\n        choices=[""caffe"", ""caffe2"", ""cntk"", ""mxnet"", ""keras"", ""tensorflow"", \'tf\', \'torch\', \'torch7\', \'onnx\', \'darknet\', \'coreml\', \'pytorch\'],\n        help=""Source toolkit name of the model to be converted."")\n\n    parser.add_argument(\n        \'--weights\', \'-w\', \'-iw\',\n        type=_text_type,\n        default=None,\n        help=\'Path to the model weights file of the external tool (e.g caffe weights proto binary, keras h5 binary\')\n\n    parser.add_argument(\n        \'--network\', \'-n\', \'-in\',\n        type=_text_type,\n        default=None,\n        help=\'Path to the model network file of the external tool (e.g caffe prototxt, keras json\')\n\n    parser.add_argument(\n        \'--dstPath\', \'-d\', \'-o\',\n        type=_text_type,\n        required=True,\n        help=\'Path to save the IR model.\')\n\n    parser.add_argument(\n        \'--inNodeName\', \'-inode\',\n        nargs=\'+\',\n        type=_text_type,\n        default=None,\n        help=""[Tensorflow] Input nodes\' name of the graph."")\n\n    parser.add_argument(\n        \'--dstNodeName\', \'-node\',\n        nargs=\'+\',\n        type=_text_type,\n        default=None,\n        help=""[Tensorflow] Output nodes\' name of the graph."")\n\n    parser.add_argument(\n        \'--inputShape\',\n        nargs=\'+\',\n        type=_text_type,\n        default=None,\n        help=\'[Tensorflow/MXNet/Caffe2/Torch7] Input shape of model (channel, height, width)\')\n\n\n    # Caffe\n    parser.add_argument(\n        \'--caffePhase\',\n        type=_text_type,\n        default=\'TRAIN\',\n        help=\'[Caffe] Convert the specific phase of caffe model.\')\n\n\n    # Darknet\n    parser.add_argument(\n        \'--darknetStart\',\n        type=_text_type,\n        choices=[""0"", ""1""],\n        help=\'[Darknet] Parse the darknet model weight file from the start.\')\n\n    return parser\n\n\ndef _main():\n    parser = _get_parser()\n    args = parser.parse_args()\n    ret = _convert(args)\n    _sys.exit(int(ret)) # cast to int or else the exit code is always 1\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/_script/dump_code.py,1,"b'import sys as _sys\nfrom six import text_type as _text_type\nimport sys\nimport imp\nimport os.path\n\n\ndef dump_code(framework, network_filepath, weight_filepath, dump_filepath, dump_tag):\n    if network_filepath.endswith(\'.py\'):\n        network_filepath = network_filepath[:-3]\n    sys.path.insert(0, os.path.dirname(os.path.abspath(network_filepath)))\n    MainModel = imp.load_source(\'MainModel\', network_filepath + \'.py\')\n    if framework == \'caffe\':\n        from mmdnn.conversion.caffe.saver import save_model\n    elif framework == \'cntk\':\n        from mmdnn.conversion.cntk.saver import save_model\n    elif framework == \'keras\':\n        from mmdnn.conversion.keras.saver import save_model\n    elif framework == \'mxnet\':\n        from mmdnn.conversion.mxnet.saver import save_model\n    elif framework == \'pytorch\':\n        from mmdnn.conversion.pytorch.saver import save_model\n    elif framework == \'tensorflow\':\n        from mmdnn.conversion.tensorflow.saver import save_model\n        save_model(MainModel, network_filepath, weight_filepath, dump_filepath, dump_tag)\n        return 0\n\n    elif framework == \'onnx\':\n        from mmdnn.conversion.onnx.saver import save_model\n    else:\n        raise NotImplementedError(""{} saver is not finished yet."".format(framework))\n    save_model(MainModel, network_filepath, weight_filepath, dump_filepath)\n\n    return 0\n\n\ndef _get_parser():\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\'Dump the model code into target model.\')\n\n    parser.add_argument(\n        \'-f\', \'--framework\', type=_text_type, choices=[""caffe"", ""cntk"", ""mxnet"", ""keras"", ""tensorflow"", \'pytorch\', \'onnx\'],\n        required=True,\n        help=\'Format of model at srcModelPath (default is to auto-detect).\'\n    )\n\n    parser.add_argument(\n        \'-in\', \'--inputNetwork\',\n        type=_text_type,\n        required=True,\n        help=\'Path to the model network architecture file.\')\n\n    parser.add_argument(\n        \'-iw\', \'--inputWeight\',\n        type=_text_type,\n        required=True,\n        help=\'Path to the model network weight file.\')\n\n    parser.add_argument(\n        \'-o\', \'-om\', \'--outputModel\',\n        type=_text_type,\n        required=True,\n        help=\'Path to save the target model\')\n\n    parser.add_argument(\n        \'--dump_tag\',\n        type=_text_type,\n        default=None,\n        help=\'Tensorflow model dump type\',\n        choices=[\'SERVING\', \'TRAINING\'])\n\n    return parser\n\n\ndef _main():\n    parser = _get_parser()\n    args = parser.parse_args()\n    ret = dump_code(args.framework, args.inputNetwork, args.inputWeight, args.outputModel, args.dump_tag)\n    _sys.exit(int(ret))\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/_script/extractModel.py,1,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom six import text_type as _text_type\n\n\ndef generate_label(predict, label_file, offset):\n    import os\n\n    if not os.path.exists(label_file):\n        return predict\n\n    with open(label_file, \'r\') as f:\n        labels = [l.rstrip() for l in f]\n\n    ret = []\n    for i, j in predict:\n        ret.append((labels[i - offset], i, j))\n\n    return ret\n\ndef extract_model(args):\n    if args.framework == \'caffe\':\n        from mmdnn.conversion.examples.caffe.extractor import caffe_extractor\n        extractor = caffe_extractor()\n\n    elif args.framework == \'keras\':\n        from mmdnn.conversion.examples.keras.extractor import keras_extractor\n        extractor = keras_extractor()\n\n    elif args.framework == \'tensorflow\' or args.framework == \'tf\':\n        from mmdnn.conversion.examples.tensorflow.extractor import tensorflow_extractor\n        extractor = tensorflow_extractor()\n\n    elif args.framework == \'mxnet\':\n        from mmdnn.conversion.examples.mxnet.extractor import mxnet_extractor\n        extractor = mxnet_extractor()\n\n    elif args.framework == \'cntk\':\n        from mmdnn.conversion.examples.cntk.extractor import cntk_extractor\n        extractor = cntk_extractor()\n\n    elif args.framework == \'pytorch\':\n        from mmdnn.conversion.examples.pytorch.extractor import pytorch_extractor\n        extractor = pytorch_extractor()\n\n    elif args.framework == \'darknet\':\n        from mmdnn.conversion.examples.darknet.extractor import darknet_extractor\n        extractor = darknet_extractor()\n\n    elif args.framework == \'coreml\':\n        from mmdnn.conversion.examples.coreml.extractor import coreml_extractor\n        extractor = coreml_extractor()\n\n    else:\n        raise ValueError(""Unknown framework [{}]."".format(args.framework))\n\n    files = extractor.download(args.network, args.path)\n\n    if files and args.image:\n        predict = extractor.inference(args.network, files, args.path, args.image)\n        if type(predict) == list:\n            print(predict)\n\n        else:\n            if predict.ndim == 1:\n                if predict.shape[0] == 1001:\n                    offset = 1\n                else:\n                    offset = 0\n                top_indices = predict.argsort()[-5:][::-1]\n                predict = [(i, predict[i]) for i in top_indices]\n                predict = generate_label(predict, args.label, offset)\n\n                for line in predict:\n                    print (line)\n\n            else:\n                print (predict.shape)\n                print (predict)\n\n\n\ndef _main():\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\'Extract pre-trained models for frameworks.\')\n\n    parser.add_argument(\n        \'--framework\', \'-f\',\n        type=_text_type,\n        required=True,\n        choices=[""caffe"", ""cntk"", ""mxnet"", ""keras"", ""tensorflow"", \'tf\', \'pytorch\', \'darknet\', \'coreml\'],\n        help=""Framework name"")\n\n    parser.add_argument(\n        \'--network\', \'-n\',\n        type=_text_type,\n        default=None,\n        help=\'Path to the model network file of the external tool (e.g caffe prototxt, keras json\')\n\n    parser.add_argument(\n        \'-i\', \'--image\',\n        type=_text_type, help=\'Test Image Path\')\n\n    parser.add_argument(\n        \'--path\', \'-p\', \'-o\',\n        type=_text_type,\n        default=\'./\',\n        help=\'Path to save the pre-trained model files (e.g keras h5)\')\n\n\n    parser.add_argument(\n        \'-l\', \'--label\',\n        type=_text_type,\n        default=\'mmdnn/conversion/examples/data/imagenet_1000.txt\',\n        help=\'Path of label.\')\n\n    args = parser.parse_args()\n    extract_model(args)\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/caffe/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function'
mmdnn/conversion/caffe/caffe_emitter.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import division\n\nimport os\nimport sys\nimport math\nimport numpy as np\n\nimport caffe\nfrom caffe import layers as L\nfrom caffe import params as P\nfrom mmdnn.conversion.common.IR.IR_graph import IRGraph, IRGraphNode\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.emitter import Emitter\nfrom mmdnn.conversion.common.utils import *\n\n\nclass CaffeEmitter(Emitter):\n\n    def __init__(self, model):\n        from six import string_types as _string_types\n        super(CaffeEmitter, self).__init__()\n        if isinstance(model, _string_types):\n            network_path = model\n        else:\n            network_path = model[0]\n            self._load_weights(model[1])\n\n        self.IR_graph = IRGraph(network_path)\n        super(CaffeEmitter, self)._build()\n\n\n    @property\n    def header_code(self):\n        return """"""from __future__ import print_function\nimport numpy as np\nimport sys, argparse\nimport caffe\nfrom caffe import layers as L\nfrom caffe import params as P\nfrom caffe import to_proto\nfrom six import text_type as _text_type\n\n\n__weights_dict = dict()\n\ndef load_weights(weight_file):\n    if weight_file == None:\n        return\n\n    try:\n        weights_dict = np.load(weight_file, allow_pickle=True).item()\n    except:\n        weights_dict = np.load(weight_file, allow_pickle=True, encoding=\'bytes\').item()\n\n    return weights_dict\n\n\ndef KitModel(weight_file = None):\n    n = caffe.NetSpec()\n""""""\n\n    @property\n    def end_code(self):\n        return """"""    return n\n\ndef make_net(prototxt):\n    n = KitModel()\n    with open(prototxt, \'w\') as fpb:\n        print(n.to_proto(), file=fpb)\n\ndef gen_weight(weight_file, model, prototxt):\n    global __weights_dict\n    __weights_dict = load_weights(weight_file)\n\n    net = caffe.Net(prototxt, caffe.TRAIN)\n\n    for key in __weights_dict:\n        if \'weights\' in __weights_dict[key]:\n            net.params[key][0].data.flat = __weights_dict[key][\'weights\']\n        elif \'mean\' in __weights_dict[key]:\n            net.params[key][0].data.flat = __weights_dict[key][\'mean\']\n            net.params[key][1].data.flat = __weights_dict[key][\'var\']\n            if \'scale\' in __weights_dict[key]:\n                net.params[key][2].data.flat = __weights_dict[key][\'scale\']\n        elif \'scale\' in __weights_dict[key]:\n            net.params[key][0].data.flat = __weights_dict[key][\'scale\']\n        if \'bias\' in __weights_dict[key]:\n            net.params[key][1].data.flat = __weights_dict[key][\'bias\']\n        if \'gamma\' in __weights_dict[key]: # used for prelu, not sure if other layers use this too\n            net.params[key][0].data.flat = __weights_dict[key][\'gamma\']\n    net.save(model)\n    return net\n\n\n\nif __name__==\'__main__\':\n    parser = argparse.ArgumentParser(description=\'Generate caffe model and prototxt\')\n    parser.add_argument(\'--weight_file\', \'-w\', type=_text_type, default=\'IR weight file\')\n    parser.add_argument(\'--prototxt\', \'-p\', type=_text_type, default=\'caffe_converted.prototxt\')\n    parser.add_argument(\'--model\', \'-m\', type=_text_type, default=\'caffe_converted.caffemodel\')\n    args = parser.parse_args()\n    # For some reason argparser gives us unicode, so we need to conver to str first\n    make_net(str(args.prototxt))\n    gen_weight(str(args.weight_file), str(args.model), str(args.prototxt))\n\n""""""\n\n    def gen_code(self, phase = \'test\'):\n        self.phase = phase\n        self.add_body(0, self.header_code)\n\n        #for test\n        # with open(""graph.txt"", \'w\') as f:\n        #     for layer in self.IR_graph.topological_sort:\n        #         current_node = self.IR_graph.get_node(layer)\n        #         print(""========current_node=========\\n{}"".format(current_node.layer), file=f)\n        #test end\n\n        for layer in self.IR_graph.topological_sort:\n            current_node = self.IR_graph.get_node(layer)\n            node_type = current_node.type\n            #print(""========current_node={}"".format(current_node.layer))\n\n            if hasattr(self, ""emit_"" + node_type):\n                func = getattr(self, ""emit_"" + node_type)\n                func(current_node)\n            else:\n                print(""CaffeEmitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(current_node)\n\n        self.add_body(0, """")\n        self.add_body(0,self.end_code)\n\n        return self.body_code\n\n\n    def run(self, dstNetworkPath, dstWeightPath = None, phase = \'test\'):\n        super(CaffeEmitter, self).run(dstNetworkPath, dstWeightPath, phase)\n        if self.weight_loaded:\n            self.save_weights(self.weights_dict, dstWeightPath)\n\n\n    @staticmethod\n    def _shapeToStr(shapes):\n        return [dim.size if dim.size > 0 else 1 for dim in shapes.dim]\n\n\n    def _get_symmetric_padding(self, IR_node):\n        stride_h = IR_node.get_attr(\'strides\')[1]\n        stride_w = IR_node.get_attr(\'strides\')[2]\n\n        # check if have pad layer\n        IR_parent_node = self.IR_graph.get_parent(IR_node.name, [0])\n        if IR_parent_node.type == \'Pad\':\n            pads = IR_parent_node.get_attr(\'pads\')\n        else:\n            pads = IR_node.get_attr(\'pads\')\n\n        # Pad_h < kernel_h (vgg19 caffe2caffe)\n        if IR_node.type == ""Pool"":\n            if pads[1]:\n                pad_h = pads[1] + (0 if pads[1] == pads[5] else stride_h)\n            else:\n                pad_h = 0\n            if pads[2]:\n                pad_w = pads[2] + (0 if pads[2] == pads[6] else stride_w)\n            else:\n                pad_w = 0\n        elif IR_node.type == ""Unpool"":\n            pad_h = 0\n            pad_w = 0\n        else:\n            pad_h = pads[1] + (0 if pads[1] == pads[5] else stride_h)\n            pad_w = pads[2] + (0 if pads[2] == pads[6] else stride_w)\n\n        return pad_h, pad_w\n\n\n    def check_if_need_transpose(self, IR_node):\n        parent = self.IR_graph.get_parent(IR_node.name, [0])\n        while parent.type == \'Flatten\' or parent.type == \'Dropout\' or parent.type == \'Reshape\':\n            parent = self.IR_graph.get_parent(parent.name, [0])\n        dim = len(parent.layer.attr[\'_output_shapes\'].list.shape[0].dim)\n        if dim > 2:\n            original_dims = self.weights_dict[IR_node.name][\'weights\'].shape\n            dims = [i.size for i in parent.layer.attr[\'_output_shapes\'].list.shape[0].dim[1:]] + [-1]\n            self.weights_dict[IR_node.name][\'weights\'] = np.reshape(self.weights_dict[IR_node.name][\'weights\'], dims)\n            self.weights_dict[IR_node.name][\'weights\'] = np.transpose(self.weights_dict[IR_node.name][\'weights\'], [dim - 2] + list(range(0, dim - 2)) + [dim - 1])\n            self.weights_dict[IR_node.name][\'weights\'] = np.reshape(self.weights_dict[IR_node.name][\'weights\'], original_dims)\n\n\n    def emit_Conv(self, IR_node):\n        # implement asymmetric paddings by applying symmetric padding then cropping\n        pad_h, pad_w = self._get_symmetric_padding(IR_node)\n\n        num_output = IR_node.get_attr(\'kernel_shape\')[-1]\n        if IR_node.type == ""DepthwiseConv"":\n            num_group = IR_node.get_attr(""kernel_shape"")[-2]\n            # num_output = IR_node.get_attr(\'kernel_shape\')[-2]\n            num_output = IR_node.get_attr(""_output_shapes"")[0].dim[3].size\n        else:\n            num_group = IR_node.get_attr(""group"", 1)\n\n        self.add_body(1, ""n.{:<15} = L.Convolution(n.{}, kernel_h={}, kernel_w={}, stride={}, num_output={}, pad_h={}, pad_w={}, group={}, \\\n            bias_term={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'kernel_shape\')[0],\n            IR_node.get_attr(\'kernel_shape\')[1],\n            IR_node.get_attr(\'strides\')[1],\n            num_output,\n            pad_h,\n            pad_w,\n            num_group,\n            IR_node.get_attr(\'use_bias\', False)))\n\n        dim = len(IR_node.get_attr(\'strides\')) - 2\n        if self.weight_loaded:\n            if IR_node.type == ""DepthwiseConv"":\n                self.weights_dict[IR_node.name][\'weights\'] = np.swapaxes(self.weights_dict[IR_node.name][\'weights\'], -1, -2)\n            self.weights_dict[IR_node.name][\'weights\'] = np.transpose(self.weights_dict[IR_node.name][\'weights\'], [dim + 1, dim] + list(range(0, dim)))\n            self.weights_dict[IR_node.variable_name] = self.weights_dict.pop(IR_node.name)\n\n        self.check_if_need_crop(IR_node)\n        # keys = []\n        # for key in self.weights_dict[IR_node.name].keys():\n        #     keys.append(key)\n        # print(""=======Layer: {}, keys: {}"".format(IR_node.name, keys))\n\n    def compute_output_shape(self, IR_node, kernel_h, kernel_w):\n        parent_node = self.IR_graph.get_parent(IR_node.name, [0])\n\n        if parent_node.get_attr(\'_output_shapes\'):\n            shape = parent_node.get_attr(\'_output_shapes\')[0]\n            shape = shape_to_list(shape)\n            h_i = shape[1]\n            w_i = shape[2]\n            pad_h, pad_w = self._get_symmetric_padding(IR_node)\n            stride_h = IR_node.get_attr(\'strides\')[1]\n            stride_w = IR_node.get_attr(\'strides\')[2]\n\n            if IR_node.type == \'Pool\':\n                h_o = (h_i + 2 * pad_h - kernel_h + stride_h - 1) // stride_h + 1\n                w_o = (w_i + 2 * pad_w - kernel_w + stride_w - 1) // stride_w + 1\n            elif IR_node.type == \'Unpool\':\n                h_o = (h_i - 2 * pad_h - kernel_h + stride_h) * stride_h\n                w_o = (w_i - 2 * pad_w - kernel_w + stride_w) * stride_w\n            else:\n                h_o = (h_i + 2 * pad_h - kernel_h) // stride_h + 1\n                w_o = (w_i + 2 * pad_w - kernel_w) // stride_w + 1\n            return h_o, w_o\n        else:\n            assert False\n\n\n    def check_if_need_crop(self, IR_node):\n        shape = IR_node.get_attr(\'_output_shapes\')[0]\n        shape = shape_to_list(shape)\n        ir_ho = shape[1]\n        ir_wo = shape[2]\n        if ir_ho <0 or ir_wo<0:\n            return\n        if IR_node.type == \'Pool\' or IR_node.type == \'Unpool\':\n            k_h = IR_node.get_attr(\'kernel_shape\')[1]\n            k_w = IR_node.get_attr(\'kernel_shape\')[2]\n        else:\n            k_h = IR_node.get_attr(\'kernel_shape\')[0]\n            k_w = IR_node.get_attr(\'kernel_shape\')[1]\n\n        caffe_ho, caffe_wo = self.compute_output_shape(IR_node, k_h, k_w)\n\n        # if asymmetric padding, set offset to 1\n        pads = IR_node.get_attr(\'pads\')\n        offset = [0 if pads[1] == pads[5] else 1,\n                  0 if pads[2] == pads[6] else 1]\n        if caffe_ho > ir_ho or caffe_wo > ir_wo:\n            crop_layer_variable_name = IR_node.variable_name + ""_crop""\n            self.add_body(1, ""n.{:<15} = L.Crop(n.{}, L.DummyData(shape=[dict(dim=[1, {}, {}, {}])], \\\n                ntop=1), ntop=1, offset={})"".format(\n                crop_layer_variable_name,\n                IR_node.variable_name,\n                shape[3],\n                ir_ho,\n                ir_wo,\n                offset\n            ))\n            # Change the layer name\n            IR_node.real_name = IR_node.real_name + ""_crop""\n\n\n    def emit_Pool(self, IR_node):\n        pooling_type = IR_node.get_attr(\'pooling_type\')\n        if pooling_type == \'MAX\':\n            pooling_type = P.Pooling.MAX\n        elif pooling_type == \'AVG\':\n            pooling_type = P.Pooling.AVE\n        elif pooling_type == \'STOCHASTIC\':\n            pooling_type = P.Pooling.STOCHASTIC\n        else:\n            raise ValueError()\n\n        if IR_node.layer.attr[\'global_pooling\'].b:\n            self.add_body(1, ""n.{:<15} = L.Pooling(n.{}, pool={}, stride={}, global_pooling=True, ntop=1)"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                pooling_type,\n                IR_node.get_attr(\'strides\')[1]))\n        else:\n            pad_h, pad_w = self._get_symmetric_padding(IR_node)\n            pool_size = IR_node.get_attr(\'kernel_shape\')[1:3]\n            if pool_size[0] != pool_size[1]:\n                self.add_body(1, ""n.{:<15} = L.Pooling(n.{}, pool={}, kernel_h={}, kernel_w={}, pad_h={}, pad_w={}, stride={}, ntop=1)"".format(\n                    IR_node.variable_name,\n                    self.parent_variable_name(IR_node),\n                    pooling_type,\n                    pool_size[0],\n                    pool_size[1],\n                    pad_h,\n                    pad_w,\n                    IR_node.get_attr(\'strides\')[1]))\n            else:\n                self.add_body(1, ""n.{:<15} = L.Pooling(n.{}, pool={}, kernel_size={}, pad_h={}, pad_w={}, stride={}, ntop=1)"".format(\n                    IR_node.variable_name,\n                    self.parent_variable_name(IR_node),\n                    pooling_type,\n                    pool_size[0],\n                    pad_h,\n                    pad_w,\n                    IR_node.get_attr(\'strides\')[1]))\n\n            # check if need crop output shape\n            self.check_if_need_crop(IR_node)\n\n    def emit_Unpool(self, IR_node):\n        pad_h, pad_w = self._get_symmetric_padding(IR_node)\n        pool_size = IR_node.get_attr(\'kernel_shape\')[1:3]\n        if pool_size[0] != pool_size[1]:\n            self.add_body(1, ""n.{:<15} = L.Unpooling(n.{}, kernel_h={}, kernel_w={}, stride={}, ntop=1)"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                pool_size[0],\n                pool_size[1],\n                IR_node.get_attr(\'strides\')[1]))\n        else:\n            self.add_body(1, ""n.{:<15} = L.Unpooling(n.{}, kernel_size={}, stride={}, ntop=1)"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                pool_size[0],\n                IR_node.get_attr(\'strides\')[1]))\n\n        # check if need crop output shape\n        self.check_if_need_crop(IR_node)\n\n    def emit_ResizeBilinear(self, IR_node):\n        shape = IR_node.get_attr(""_output_shapes"")[0]\n        shape = shape_to_list(shape)\n        self.add_body(1, ""n.{:<15} = L.ResizeBilinear(n.{}, height={}, width={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            shape[1],\n            shape[2]))\n\n    def emit_UNKNOWN(self, IR_node):\n        print(IR_node.IR_layer.name)\n\n\n    def emit_DataInput(self, IR_node):\n        shape = self._shapeToStr(IR_node.get_attr(\'shape\'))\n        shape = [shape[0], shape[-1]] + shape[1:-1]\n        self.add_body(1, ""n.{:<15} = L.Input(shape=[dict(dim={})], ntop=1)"".format(\n            IR_node.variable_name,\n            shape))\n\n\n    def emit_Dropout(self, IR_node):\n        in_place = True\n        self.add_body(1, ""n.{:<15} = L.Dropout(n.{}, dropout_ratio={} , in_place={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            1 - IR_node.get_attr(\'keep_prob\'),\n            in_place))\n\n\n    def emit_FullyConnected(self, IR_node):\n        self.add_body(1, ""n.{:<15} = L.InnerProduct(n.{}, num_output={}, bias_term={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.layer.attr[""units""].i,\n            IR_node.get_attr(\'use_bias\', False)))\n        if self.weight_loaded:\n            self.check_if_need_transpose(IR_node)\n            self.weights_dict[IR_node.name][\'weights\'] = np.transpose(self.weights_dict[IR_node.name][\'weights\'], (1, 0))\n            self.weights_dict[IR_node.variable_name] = self.weights_dict.pop(IR_node.name)\n\n\n    def emit_BatchNorm(self, IR_node):\n\n        self.add_body(1, ""n.{:<15} = L.BatchNorm(n.{}, eps={}, use_global_stats={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'epsilon\'),\n            self.phase == \'test\'\n        ))\n\n        scale_layer_var_name = IR_node.variable_name + ""_scale""\n        self.add_body(1, ""n.{:<15} = L.Scale(n.{}, bias_term={}, in_place=True, ntop=1)"".format(\n            scale_layer_var_name,\n            IR_node.variable_name,\n            IR_node.get_attr(\'bias\', False)\n        ))\n\n        if self.weight_loaded:\n            self.weights_dict[scale_layer_var_name] = dict()\n            if \'scale\' in self.weights_dict[IR_node.name]:\n                self.weights_dict[scale_layer_var_name][\'scale\'] = self.weights_dict[IR_node.name][\'scale\']\n            else:\n                self.weights_dict[scale_layer_var_name][\'scale\'] = 1\n\n            self.weights_dict[IR_node.name][\'scale\'] = 1\n\n            if \'bias\' in self.weights_dict[IR_node.name]:\n                self.weights_dict[scale_layer_var_name][\'bias\'] = self.weights_dict[IR_node.name][\'bias\']\n                self.weights_dict[IR_node.name].pop(\'bias\', None)\n                # change the key ""name"" to ""variable_name"", in case of the layer name has invalid characters\n\n            self.weights_dict[IR_node.variable_name] = self.weights_dict.pop(IR_node.name)\n\n        IR_node.real_name = IR_node.name + ""_scale""\n\n\n    def emit_Scale(self, IR_node):\n        self.add_body(1, ""n.{:<15} = L.Scale(n.{}, bias_term={}, in_place=True, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'use_bias\', False)\n        ))\n        if self.weight_loaded:\n            self.weights_dict[IR_node.variable_name] = self.weights_dict.pop(IR_node.name)\n\n\n    def emit_Constant(self, IR_node):\n        if IR_node.get_attr(\'value\'):\n            value = IR_node.get_attr(\'value\')\n        else:\n            value = self.weights_dict[IR_node.name][\'value\'][0]\n        IR_node_after = self.IR_graph.get_son(IR_node.name, [0])\n        shape = IR_node_after.get_attr(""_output_shapes"")[0]\n        shape = shape_to_list(shape)\n        if len(shape) == 4:\n            shape[1], shape[3] = shape[3], shape[1]\n            shape[0] = 1\n        shape = list(map(lambda x:str(x), shape))\n\n        self.add_body(1, ""n.{:<15} = L.DummyData(shape=[dict(dim=[{}])], data_filler=dict(type=\'constant\', value={}), ntop=1)"".format(\n            IR_node.variable_name,\n            \', \'.join(shape),\n            value\n        ))\n\n\n    def emit_LRN(self, IR_node):\n        output_name = IR_node.variable_name\n        input_name = self.parent_variable_name(IR_node)\n        size = IR_node.get_attr(\'size\')\n        alpha = IR_node.get_attr(\'alpha\')\n        beta = IR_node.get_attr(\'beta\')\n        bias = IR_node.get_attr(\'bias\')\n\n        self.add_body(1, ""n.{:<15} = L.LRN(n.{}, local_size={}, alpha={}, beta={}, k={})"".format(\n            output_name,\n            input_name,\n            size,\n            alpha,\n            beta,\n            bias\n        ))\n\n\n    def emit_Add(self, IR_node):\n        input_layers = \', \'.join((\'n.\' + self.IR_graph.get_parent(IR_node.name, [num]).real_variable_name) for num in range(0, len(IR_node.in_edges)))\n        self.add_body(1, ""n.{:<15} = L.Eltwise({}, operation=1, ntop=1)"".format(\n            IR_node.variable_name,\n            input_layers,\n        ))\n\n    def emit_Flatten(self, IR_node):\n        self.add_body(1, ""n.{:<15} = L.Flatten(n.{})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            ))\n\n\n    def emit_Squeeze(self, IR_node):\n        shape = IR_node.get_attr(""_output_shapes"")[0]\n        shape = shape_to_list(shape)\n        if shape:\n            dim_str = ""\'dim\': {}"".format(shape)\n            dim_str = "" reshape_param={\'shape\': { "" + dim_str + \'} }\'\n            self.add_body(1, ""n.{:<15} = L.Reshape(n.{}, {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                dim_str\n                ))\n        else:\n            IR_node.real_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n\n\n    def emit_Concat(self, IR_node):\n        axis_array = (2, 3, 1, 0)\n        axis = axis_array.index(IR_node.get_attr(\'axis\'))\n        input_layers = \', \'.join((\'n.\' + self.IR_graph.get_node(edge).real_variable_name) for edge in IR_node.in_edges)\n        self.add_body(1, ""n.{:<15} = L.Concat({}, axis={})"".format(\n            IR_node.variable_name,\n            input_layers,\n            axis\n        ))\n\n    def emit_Sigmoid(self, IR_node):\n        self.add_body(1, ""n.{:<15} = L.Sigmoid(n.{}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)))\n\n\n    def emit_Relu(self, IR_node):\n        in_place = True\n        self.add_body(1, ""n.{:<15} = L.ReLU(n.{}, in_place={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            in_place))\n\n\n    def emit_Elu(self, IR_node):\n        in_place = True\n        self.add_body(1, ""n.{:<15} = L.ELU(n.{}, in_place={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            in_place))\n\n\n    def emit_LeakyRelu(self, IR_node):\n        in_place = True\n        self.add_body(1, ""n.{:<15} = L.ReLU(n.{}, in_place={}, negative_slope={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            in_place,\n            IR_node.IR_layer.attr[\'alpha\'].f))\n\n\n\n    def emit_PRelu(self, IR_node):\n        in_place = True\n        self.add_body(1, ""n.{:<15} = L.PReLU(n.{}, in_place={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            in_place))\n\n    def emit_Tanh(self, IR_node):\n        self.add_body(1, ""n.{:<15} = L.TanH(n.{}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)))\n\n    def emit_Softmax(self, IR_node):\n        self.add_body(1, ""n.{:<15} = L.Softmax(n.{}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)))\n\n\n    def emit_Pad(self, IR_node):\n        IR_node.real_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n\n    def reduction(self, IR_node, op, axes):\n        # Convert NHWC (IR) to NCHW (Caffe): [0,1,2,3]->[0,3,1,2]\n        if len(axes) == 1:\n            assert (axes[0] == 2)\n        elif len(axes) == 2:\n            assert ((axes[0] == 1) and (axes[1] == 2))\n\n        self.add_body(1, ""n.{:<15} = L.Reduction(n.{}, operation={} , axis={} ,ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            op,\n            len(axes)))\n\n        if IR_node.get_attr(\'keepdims\') == True:\n            shape = IR_node.get_attr(""_output_shapes"")[0]\n            shape = shape_to_list(shape)\n            shape = [1] + [shape[-1]] + shape[1:-1]\n            dim_str = ""\'dim\': {}"".format(shape)\n            dim_str = ""{\'shape\': { "" + dim_str + \'} }\'\n            self.add_body(1, ""n.{:<15} = L.Reshape(n.{}, reshape_param={}) "".format(\n                IR_node.variable_name + ""_reshape"",\n                IR_node.real_variable_name,\n                dim_str))\n            IR_node.real_name = IR_node.real_name + \'_reshape\'\n\n\n    def emit_ReduceMean(self, IR_node):\n        self.reduction(IR_node, 4, IR_node.get_attr(\'axes\'))\n\n    def emit_ReduceSum(self, IR_node):\n        self.reduction(IR_node, 1, IR_node.get_attr(\'axes\'))\n\n    def emit_Relu6(self, IR_node):\n        in_place = True\n        self.add_body(1, ""n.{:<15} = L.Clip(n.{}, min=0, max=6, in_place={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            in_place))\n\n    def emit_DepthwiseConv(self, IR_node):\n        self.emit_Conv(IR_node)\n\n    def emit_Const(self, IR_node):\n        pass\n    def emit_Shape(self, IR_node):\n        pass\n    def emit_Reshape(self, IR_node):\n        shape = IR_node.get_attr(""_output_shapes"")[0]\n        shape = shape_to_list(shape)\n        if shape:\n            dim_str = ""\'dim\': {}"".format(shape)\n            dim_str = "" reshape_param={\'shape\': { "" + dim_str + \'} }\'\n            self.add_body(1, ""n.{:<15} = L.Reshape(n.{}, {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                dim_str\n                ))\n        else:\n            IR_node.real_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n\n    def emit_Slice(self, IR_node):\n        pass\n\n    def emit_Pack(self, IR_node):\n        pass\n\n    def emit_Abs(self, IR_node):\n        self.add_body(1, ""n.{:<15} = L.AbsVal(n.{}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)))\n\n    def emit_Sub(self, IR_node):\n        input_layers = \', \'.join((\'n.\' + self.IR_graph.get_node(edge).real_variable_name) for edge in IR_node.in_edges)\n        self.add_body(1, ""n.{:<15} = L.Eltwise({}, coeff = [1, -1], ntop=1)"".format(\n            IR_node.variable_name,\n            input_layers))\n\n    def emit_Mul(self, IR_node):\n        if len(IR_node.in_edges) == 2:\n            input_layers = \', \'.join((\'n.\' + self.IR_graph.get_node(edge).real_variable_name) for edge in IR_node.in_edges)\n            self.add_body(1, ""n.{:<15} = L.Eltwise({}, operation=0, ntop=1)"".format(\n            IR_node.variable_name,\n            input_layers))\n        elif len(IR_node.in_edges) == 1:\n            self.emit_Scale(IR_node)\n        else:\n            assert False\n\n    def emit_UpSampling2D(self, IR_node):\n        scales = IR_node.get_attr(\'scales\')\n        scale = tuple(scales)[0]\n\n        shape = IR_node.get_attr(\'_output_shapes\')[0]\n        shape = shape_to_list(shape)\n\n        self.add_body(1, ""n.{:<15} = L.Deconvolution(n.{}, convolution_param=dict(kernel_size={}, stride={}, pad={}, num_output={}, group={}, bias_term={}), param=[dict(lr_mult=0)], ntop=1)"".format(\n            IR_node.variable_name,\n            IR_node.in_edges[0],\n            2 * scale - scale % 2,\n            scale,\n            int(math.ceil((scale - 1) / 2)),\n            shape[-1],\n            shape[-1],\n            False))\n\n    # def emit_Square(self, IR_node):\n    #     input_layers = \', \'.join((\'n.\' + self.IR_graph.get_node(edge).real_variable_name) for edge in IR_node.in_edges)\n    #     self.add_body(1, ""n.{:<15} = L.Square({}, ntop=1)"".format(\n    #         IR_node.variable_name,\n    #         input_layers))\n\n\n    def emit_Elu(self, IR_node):\n        in_place = True\n        self.add_body(1, ""n.{:<15} = L.ELU(n.{}, in_place={}, ntop=1)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            in_place))\n\n    def emit_SpaceToDepth(self, IR_node):\n        self.add_body(1, """")\n'"
mmdnn/conversion/caffe/caffe_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: caffe.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'caffe.proto\',\n  package=\'caffe\',\n  syntax=\'proto2\',\n  serialized_pb=_b(\'\\n\\x0b\\x63\\x61\\x66\\x66\\x65.proto\\x12\\x05\\x63\\x61\\x66\\x66\\x65\\""\\x1c\\n\\tBlobShape\\x12\\x0f\\n\\x03\\x64im\\x18\\x01 \\x03(\\x03\\x42\\x02\\x10\\x01\\""\\xcc\\x01\\n\\tBlobProto\\x12\\x1f\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x10\\n\\x04\\x64\\x61ta\\x18\\x05 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x10\\n\\x04\\x64iff\\x18\\x06 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_data\\x18\\x08 \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x17\\n\\x0b\\x64ouble_diff\\x18\\t \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x0e\\n\\x03num\\x18\\x01 \\x01(\\x05:\\x01\\x30\\x12\\x13\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x11\\n\\x06height\\x18\\x03 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05width\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""2\\n\\x0f\\x42lobProtoVector\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\""\\x81\\x01\\n\\x05\\x44\\x61tum\\x12\\x10\\n\\x08\\x63hannels\\x18\\x01 \\x01(\\x05\\x12\\x0e\\n\\x06height\\x18\\x02 \\x01(\\x05\\x12\\r\\n\\x05width\\x18\\x03 \\x01(\\x05\\x12\\x0c\\n\\x04\\x64\\x61ta\\x18\\x04 \\x01(\\x0c\\x12\\r\\n\\x05label\\x18\\x05 \\x01(\\x05\\x12\\x12\\n\\nfloat_data\\x18\\x06 \\x03(\\x02\\x12\\x16\\n\\x07\\x65ncoded\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\x8a\\x02\\n\\x0f\\x46illerParameter\\x12\\x16\\n\\x04type\\x18\\x01 \\x01(\\t:\\x08\\x63onstant\\x12\\x10\\n\\x05value\\x18\\x02 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03min\\x18\\x03 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03max\\x18\\x04 \\x01(\\x02:\\x01\\x31\\x12\\x0f\\n\\x04mean\\x18\\x05 \\x01(\\x02:\\x01\\x30\\x12\\x0e\\n\\x03std\\x18\\x06 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x06sparse\\x18\\x07 \\x01(\\x05:\\x02-1\\x12\\x42\\n\\rvariance_norm\\x18\\x08 \\x01(\\x0e\\x32#.caffe.FillerParameter.VarianceNorm:\\x06\\x46\\x41N_IN\\""4\\n\\x0cVarianceNorm\\x12\\n\\n\\x06\\x46\\x41N_IN\\x10\\x00\\x12\\x0b\\n\\x07\\x46\\x41N_OUT\\x10\\x01\\x12\\x0b\\n\\x07\\x41VERAGE\\x10\\x02\\""\\x8e\\x02\\n\\x0cNetParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12%\\n\\x0binput_shape\\x18\\x08 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x11\\n\\tinput_dim\\x18\\x04 \\x03(\\x05\\x12\\x1d\\n\\x0e\\x66orce_backward\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1e\\n\\x05state\\x18\\x06 \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x19\\n\\ndebug_info\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\x12$\\n\\x05layer\\x18\\x64 \\x03(\\x0b\\x32\\x15.caffe.LayerParameter\\x12\\\'\\n\\x06layers\\x18\\x02 \\x03(\\x0b\\x32\\x17.caffe.V1LayerParameter\\""\\xc3\\n\\n\\x0fSolverParameter\\x12\\x0b\\n\\x03net\\x18\\x18 \\x01(\\t\\x12&\\n\\tnet_param\\x18\\x19 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12\\x11\\n\\ttrain_net\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x08test_net\\x18\\x02 \\x03(\\t\\x12,\\n\\x0ftrain_net_param\\x18\\x15 \\x01(\\x0b\\x32\\x13.caffe.NetParameter\\x12+\\n\\x0etest_net_param\\x18\\x16 \\x03(\\x0b\\x32\\x13.caffe.NetParameter\\x12$\\n\\x0btrain_state\\x18\\x1a \\x01(\\x0b\\x32\\x0f.caffe.NetState\\x12#\\n\\ntest_state\\x18\\x1b \\x03(\\x0b\\x32\\x0f.caffe.NetState\\x12\\x11\\n\\ttest_iter\\x18\\x03 \\x03(\\x05\\x12\\x18\\n\\rtest_interval\\x18\\x04 \\x01(\\x05:\\x01\\x30\\x12 \\n\\x11test_compute_loss\\x18\\x13 \\x01(\\x08:\\x05\\x66\\x61lse\\x12!\\n\\x13test_initialization\\x18  \\x01(\\x08:\\x04true\\x12\\x0f\\n\\x07\\x62\\x61se_lr\\x18\\x05 \\x01(\\x02\\x12\\x0f\\n\\x07\\x64isplay\\x18\\x06 \\x01(\\x05\\x12\\x17\\n\\x0c\\x61verage_loss\\x18! \\x01(\\x05:\\x01\\x31\\x12\\x10\\n\\x08max_iter\\x18\\x07 \\x01(\\x05\\x12\\x14\\n\\titer_size\\x18$ \\x01(\\x05:\\x01\\x31\\x12\\x11\\n\\tlr_policy\\x18\\x08 \\x01(\\t\\x12\\r\\n\\x05gamma\\x18\\t \\x01(\\x02\\x12\\r\\n\\x05power\\x18\\n \\x01(\\x02\\x12\\x10\\n\\x08momentum\\x18\\x0b \\x01(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x0c \\x01(\\x02\\x12\\x1f\\n\\x13regularization_type\\x18\\x1d \\x01(\\t:\\x02L2\\x12\\x10\\n\\x08stepsize\\x18\\r \\x01(\\x05\\x12\\x11\\n\\tstepvalue\\x18\\"" \\x03(\\x05\\x12\\x1a\\n\\x0e\\x63lip_gradients\\x18# \\x01(\\x02:\\x02-1\\x12\\x13\\n\\x08snapshot\\x18\\x0e \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0fsnapshot_prefix\\x18\\x0f \\x01(\\t\\x12\\x1c\\n\\rsnapshot_diff\\x18\\x10 \\x01(\\x08:\\x05\\x66\\x61lse\\x12K\\n\\x0fsnapshot_format\\x18% \\x01(\\x0e\\x32%.caffe.SolverParameter.SnapshotFormat:\\x0b\\x42INARYPROTO\\x12;\\n\\x0bsolver_mode\\x18\\x11 \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverMode:\\x03GPU\\x12\\x14\\n\\tdevice_id\\x18\\x12 \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0brandom_seed\\x18\\x14 \\x01(\\x03:\\x02-1\\x12\\x11\\n\\x04type\\x18( \\x01(\\t:\\x03SGD\\x12\\x14\\n\\x05\\x64\\x65lta\\x18\\x1f \\x01(\\x02:\\x05\\x31\\x65-08\\x12\\x18\\n\\tmomentum2\\x18\\\' \\x01(\\x02:\\x05\\x30.999\\x12\\x17\\n\\trms_decay\\x18& \\x01(\\x02:\\x04\\x30.99\\x12\\x19\\n\\ndebug_info\\x18\\x17 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x14snapshot_after_train\\x18\\x1c \\x01(\\x08:\\x04true\\x12;\\n\\x0bsolver_type\\x18\\x1e \\x01(\\x0e\\x32!.caffe.SolverParameter.SolverType:\\x03SGD\\x12\\x1f\\n\\x11layer_wise_reduce\\x18) \\x01(\\x08:\\x04true\\""+\\n\\x0eSnapshotFormat\\x12\\x08\\n\\x04HDF5\\x10\\x00\\x12\\x0f\\n\\x0b\\x42INARYPROTO\\x10\\x01\\""\\x1e\\n\\nSolverMode\\x12\\x07\\n\\x03\\x43PU\\x10\\x00\\x12\\x07\\n\\x03GPU\\x10\\x01\\""U\\n\\nSolverType\\x12\\x07\\n\\x03SGD\\x10\\x00\\x12\\x0c\\n\\x08NESTEROV\\x10\\x01\\x12\\x0b\\n\\x07\\x41\\x44\\x41GRAD\\x10\\x02\\x12\\x0b\\n\\x07RMSPROP\\x10\\x03\\x12\\x0c\\n\\x08\\x41\\x44\\x41\\x44\\x45LTA\\x10\\x04\\x12\\x08\\n\\x04\\x41\\x44\\x41M\\x10\\x05\\""l\\n\\x0bSolverState\\x12\\x0c\\n\\x04iter\\x18\\x01 \\x01(\\x05\\x12\\x13\\n\\x0blearned_net\\x18\\x02 \\x01(\\t\\x12!\\n\\x07history\\x18\\x03 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x17\\n\\x0c\\x63urrent_step\\x18\\x04 \\x01(\\x05:\\x01\\x30\\""N\\n\\x08NetState\\x12!\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase:\\x04TEST\\x12\\x10\\n\\x05level\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\r\\n\\x05stage\\x18\\x03 \\x03(\\t\\""s\\n\\x0cNetStateRule\\x12\\x1b\\n\\x05phase\\x18\\x01 \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x11\\n\\tmin_level\\x18\\x02 \\x01(\\x05\\x12\\x11\\n\\tmax_level\\x18\\x03 \\x01(\\x05\\x12\\r\\n\\x05stage\\x18\\x04 \\x03(\\t\\x12\\x11\\n\\tnot_stage\\x18\\x05 \\x03(\\t\\""\\xa3\\x01\\n\\tParamSpec\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x31\\n\\nshare_mode\\x18\\x02 \\x01(\\x0e\\x32\\x1d.caffe.ParamSpec.DimCheckMode\\x12\\x12\\n\\x07lr_mult\\x18\\x03 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\ndecay_mult\\x18\\x04 \\x01(\\x02:\\x01\\x31\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\x82\\x14\\n\\x0eLayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x03 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x04 \\x03(\\t\\x12\\x1b\\n\\x05phase\\x18\\n \\x01(\\x0e\\x32\\x0c.caffe.Phase\\x12\\x13\\n\\x0bloss_weight\\x18\\x05 \\x03(\\x02\\x12\\x1f\\n\\x05param\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.ParamSpec\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x07 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x16\\n\\x0epropagate_down\\x18\\x0b \\x03(\\x08\\x12$\\n\\x07include\\x18\\x08 \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18\\t \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12\\x37\\n\\x0ftransform_param\\x18\\x64 \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18\\x65 \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x66 \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18g \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12\\x34\\n\\x10\\x62\\x61tch_norm_param\\x18\\x8b\\x01 \\x01(\\x0b\\x32\\x19.caffe.BatchNormParameter\\x12)\\n\\nbias_param\\x18\\x8d\\x01 \\x01(\\x0b\\x32\\x14.caffe.BiasParameter\\x12,\\n\\x0c\\x63oncat_param\\x18h \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18i \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18j \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12)\\n\\ncrop_param\\x18\\x90\\x01 \\x01(\\x0b\\x32\\x14.caffe.CropParameter\\x12(\\n\\ndata_param\\x18k \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18l \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18m \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18n \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12\\\'\\n\\telu_param\\x18\\x8c\\x01 \\x01(\\x0b\\x32\\x13.caffe.ELUParameter\\x12+\\n\\x0b\\x65mbed_param\\x18\\x89\\x01 \\x01(\\x0b\\x32\\x15.caffe.EmbedParameter\\x12&\\n\\texp_param\\x18o \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12/\\n\\rflatten_param\\x18\\x87\\x01 \\x01(\\x0b\\x32\\x17.caffe.FlattenParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18p \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18q \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18r \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18s \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18t \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18u \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12+\\n\\x0binput_param\\x18\\x8f\\x01 \\x01(\\x0b\\x32\\x15.caffe.InputParameter\\x12\\\'\\n\\tlog_param\\x18\\x86\\x01 \\x01(\\x0b\\x32\\x13.caffe.LogParameter\\x12&\\n\\tlrn_param\\x18v \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18w \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18x \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12\\x33\\n\\x0fparameter_param\\x18\\x91\\x01 \\x01(\\x0b\\x32\\x19.caffe.ParameterParameter\\x12.\\n\\rpooling_param\\x18y \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18z \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12+\\n\\x0bprelu_param\\x18\\x83\\x01 \\x01(\\x0b\\x32\\x15.caffe.PReLUParameter\\x12-\\n\\x0cpython_param\\x18\\x82\\x01 \\x01(\\x0b\\x32\\x16.caffe.PythonParameter\\x12\\x33\\n\\x0frecurrent_param\\x18\\x92\\x01 \\x01(\\x0b\\x32\\x19.caffe.RecurrentParameter\\x12\\x33\\n\\x0freduction_param\\x18\\x88\\x01 \\x01(\\x0b\\x32\\x19.caffe.ReductionParameter\\x12(\\n\\nrelu_param\\x18{ \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12/\\n\\rreshape_param\\x18\\x85\\x01 \\x01(\\x0b\\x32\\x17.caffe.ReshapeParameter\\x12+\\n\\x0bscale_param\\x18\\x8e\\x01 \\x01(\\x0b\\x32\\x15.caffe.ScaleParameter\\x12.\\n\\rsigmoid_param\\x18| \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18} \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12\\\'\\n\\tspp_param\\x18\\x84\\x01 \\x01(\\x0b\\x32\\x13.caffe.SPPParameter\\x12*\\n\\x0bslice_param\\x18~ \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18\\x7f \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x33\\n\\x0fthreshold_param\\x18\\x80\\x01 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12)\\n\\ntile_param\\x18\\x8a\\x01 \\x01(\\x0b\\x32\\x14.caffe.TileParameter\\x12\\x36\\n\\x11window_data_param\\x18\\x81\\x01 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\""\\xb6\\x01\\n\\x17TransformationParameter\\x12\\x10\\n\\x05scale\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x15\\n\\x06mirror\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x14\\n\\tcrop_size\\x18\\x03 \\x01(\\r:\\x01\\x30\\x12\\x11\\n\\tmean_file\\x18\\x04 \\x01(\\t\\x12\\x12\\n\\nmean_value\\x18\\x05 \\x03(\\x02\\x12\\x1a\\n\\x0b\\x66orce_color\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\nforce_gray\\x18\\x07 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xc2\\x01\\n\\rLossParameter\\x12\\x14\\n\\x0cignore_label\\x18\\x01 \\x01(\\x05\\x12\\x44\\n\\rnormalization\\x18\\x03 \\x01(\\x0e\\x32&.caffe.LossParameter.NormalizationMode:\\x05VALID\\x12\\x11\\n\\tnormalize\\x18\\x02 \\x01(\\x08\\""B\\n\\x11NormalizationMode\\x12\\x08\\n\\x04\\x46ULL\\x10\\x00\\x12\\t\\n\\x05VALID\\x10\\x01\\x12\\x0e\\n\\nBATCH_SIZE\\x10\\x02\\x12\\x08\\n\\x04NONE\\x10\\x03\\""L\\n\\x11\\x41\\x63\\x63uracyParameter\\x12\\x10\\n\\x05top_k\\x18\\x01 \\x01(\\r:\\x01\\x31\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x0cignore_label\\x18\\x03 \\x01(\\x05\\""M\\n\\x0f\\x41rgMaxParameter\\x12\\x1a\\n\\x0bout_max_val\\x18\\x01 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x10\\n\\x05top_k\\x18\\x02 \\x01(\\r:\\x01\\x31\\x12\\x0c\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05\\""9\\n\\x0f\\x43oncatParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12\\x15\\n\\nconcat_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""j\\n\\x12\\x42\\x61tchNormParameter\\x12\\x18\\n\\x10use_global_stats\\x18\\x01 \\x01(\\x08\\x12&\\n\\x17moving_average_fraction\\x18\\x02 \\x01(\\x02:\\x05\\x30.999\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-05\\""]\\n\\rBiasParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""L\\n\\x18\\x43ontrastiveLossParameter\\x12\\x11\\n\\x06margin\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x1d\\n\\x0elegacy_version\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xfc\\x03\\n\\x14\\x43onvolutionParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12\\x0b\\n\\x03pad\\x18\\x03 \\x03(\\r\\x12\\x13\\n\\x0bkernel_size\\x18\\x04 \\x03(\\r\\x12\\x0e\\n\\x06stride\\x18\\x06 \\x03(\\r\\x12\\x10\\n\\x08\\x64ilation\\x18\\x12 \\x03(\\r\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x08kernel_h\\x18\\x0b \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x0c \\x01(\\r\\x12\\x10\\n\\x08stride_h\\x18\\r \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x0e \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\x05 \\x01(\\r:\\x01\\x31\\x12-\\n\\rweight_filler\\x18\\x07 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x08 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12;\\n\\x06\\x65ngine\\x18\\x0f \\x01(\\x0e\\x32\\"".caffe.ConvolutionParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x10 \\x01(\\x05:\\x01\\x31\\x12\\x1e\\n\\x0f\\x66orce_nd_im2col\\x18\\x11 \\x01(\\x08:\\x05\\x66\\x61lse\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""0\\n\\rCropParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x32\\x12\\x0e\\n\\x06offset\\x18\\x02 \\x03(\\r\\""\\xa4\\x02\\n\\rDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x31\\n\\x07\\x62\\x61\\x63kend\\x18\\x08 \\x01(\\x0e\\x32\\x17.caffe.DataParameter.DB:\\x07LEVELDB\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\""\\n\\x13\\x66orce_encoded_color\\x18\\t \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x13\\n\\x08prefetch\\x18\\n \\x01(\\r:\\x01\\x34\\""\\x1b\\n\\x02\\x44\\x42\\x12\\x0b\\n\\x07LEVELDB\\x10\\x00\\x12\\x08\\n\\x04LMDB\\x10\\x01\\"".\\n\\x10\\x44ropoutParameter\\x12\\x1a\\n\\rdropout_ratio\\x18\\x01 \\x01(\\x02:\\x03\\x30.5\\""\\xa0\\x01\\n\\x12\\x44ummyDataParameter\\x12+\\n\\x0b\\x64\\x61ta_filler\\x18\\x01 \\x03(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1f\\n\\x05shape\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0b\\n\\x03num\\x18\\x02 \\x03(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x03 \\x03(\\r\\x12\\x0e\\n\\x06height\\x18\\x04 \\x03(\\r\\x12\\r\\n\\x05width\\x18\\x05 \\x03(\\r\\""\\xa5\\x01\\n\\x10\\x45ltwiseParameter\\x12\\x39\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32!.caffe.EltwiseParameter.EltwiseOp:\\x03SUM\\x12\\r\\n\\x05\\x63oeff\\x18\\x02 \\x03(\\x02\\x12\\x1e\\n\\x10stable_prod_grad\\x18\\x03 \\x01(\\x08:\\x04true\\""\\\'\\n\\tEltwiseOp\\x12\\x08\\n\\x04PROD\\x10\\x00\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x07\\n\\x03MAX\\x10\\x02\\"" \\n\\x0c\\x45LUParameter\\x12\\x10\\n\\x05\\x61lpha\\x18\\x01 \\x01(\\x02:\\x01\\x31\\""\\xac\\x01\\n\\x0e\\x45mbedParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x11\\n\\tinput_dim\\x18\\x02 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x03 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""D\\n\\x0c\\x45xpParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""9\\n\\x10\\x46lattenParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x14\\n\\x08\\x65nd_axis\\x18\\x02 \\x01(\\x05:\\x02-1\\""O\\n\\x11HDF5DataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x02 \\x01(\\r\\x12\\x16\\n\\x07shuffle\\x18\\x03 \\x01(\\x08:\\x05\\x66\\x61lse\\""(\\n\\x13HDF5OutputParameter\\x12\\x11\\n\\tfile_name\\x18\\x01 \\x01(\\t\\""^\\n\\x12HingeLossParameter\\x12\\x30\\n\\x04norm\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.HingeLossParameter.Norm:\\x02L1\\""\\x16\\n\\x04Norm\\x12\\x06\\n\\x02L1\\x10\\x01\\x12\\x06\\n\\x02L2\\x10\\x02\\""\\x97\\x02\\n\\x12ImageDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x15\\n\\nbatch_size\\x18\\x04 \\x01(\\r:\\x01\\x31\\x12\\x14\\n\\trand_skip\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x07shuffle\\x18\\x08 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nnew_height\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x16\\n\\x08is_color\\x18\\x0b \\x01(\\x08:\\x04true\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\x0c \\x01(\\t:\\x00\\""8\\n\\x15InfogainLossParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\""\\xcb\\x01\\n\\x15InnerProductParameter\\x12\\x12\\n\\nnum_output\\x18\\x01 \\x01(\\r\\x12\\x17\\n\\tbias_term\\x18\\x02 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x04 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x05 \\x01(\\x05:\\x01\\x31\\x12\\x18\\n\\ttranspose\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\""1\\n\\x0eInputParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x03(\\x0b\\x32\\x10.caffe.BlobShape\\""D\\n\\x0cLogParameter\\x12\\x10\\n\\x04\\x62\\x61se\\x18\\x01 \\x01(\\x02:\\x02-1\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""\\xb8\\x02\\n\\x0cLRNParameter\\x12\\x15\\n\\nlocal_size\\x18\\x01 \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x03 \\x01(\\x02:\\x04\\x30.75\\x12\\x44\\n\\x0bnorm_region\\x18\\x04 \\x01(\\x0e\\x32\\x1e.caffe.LRNParameter.NormRegion:\\x0f\\x41\\x43ROSS_CHANNELS\\x12\\x0c\\n\\x01k\\x18\\x05 \\x01(\\x02:\\x01\\x31\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.LRNParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""5\\n\\nNormRegion\\x12\\x13\\n\\x0f\\x41\\x43ROSS_CHANNELS\\x10\\x00\\x12\\x12\\n\\x0eWITHIN_CHANNEL\\x10\\x01\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x13MemoryDataParameter\\x12\\x12\\n\\nbatch_size\\x18\\x01 \\x01(\\r\\x12\\x10\\n\\x08\\x63hannels\\x18\\x02 \\x01(\\r\\x12\\x0e\\n\\x06height\\x18\\x03 \\x01(\\r\\x12\\r\\n\\x05width\\x18\\x04 \\x01(\\r\\""d\\n\\x0cMVNParameter\\x12 \\n\\x12normalize_variance\\x18\\x01 \\x01(\\x08:\\x04true\\x12\\x1e\\n\\x0f\\x61\\x63ross_channels\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x12\\n\\x03\\x65ps\\x18\\x03 \\x01(\\x02:\\x05\\x31\\x65-09\\""5\\n\\x12ParameterParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\""\\xa2\\x03\\n\\x10PoolingParameter\\x12\\x35\\n\\x04pool\\x18\\x01 \\x01(\\x0e\\x32\\"".caffe.PoolingParameter.PoolMethod:\\x03MAX\\x12\\x0e\\n\\x03pad\\x18\\x04 \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_h\\x18\\t \\x01(\\r:\\x01\\x30\\x12\\x10\\n\\x05pad_w\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x13\\n\\x0bkernel_size\\x18\\x02 \\x01(\\r\\x12\\x10\\n\\x08kernel_h\\x18\\x05 \\x01(\\r\\x12\\x10\\n\\x08kernel_w\\x18\\x06 \\x01(\\r\\x12\\x11\\n\\x06stride\\x18\\x03 \\x01(\\r:\\x01\\x31\\x12\\x10\\n\\x08stride_h\\x18\\x07 \\x01(\\r\\x12\\x10\\n\\x08stride_w\\x18\\x08 \\x01(\\r\\x12\\x37\\n\\x06\\x65ngine\\x18\\x0b \\x01(\\x0e\\x32\\x1e.caffe.PoolingParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x1d\\n\\x0eglobal_pooling\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""F\\n\\x0ePowerParameter\\x12\\x10\\n\\x05power\\x18\\x01 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x05shift\\x18\\x03 \\x01(\\x02:\\x01\\x30\\""g\\n\\x0fPythonParameter\\x12\\x0e\\n\\x06module\\x18\\x01 \\x01(\\t\\x12\\r\\n\\x05layer\\x18\\x02 \\x01(\\t\\x12\\x13\\n\\tparam_str\\x18\\x03 \\x01(\\t:\\x00\\x12 \\n\\x11share_in_parallel\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xc0\\x01\\n\\x12RecurrentParameter\\x12\\x15\\n\\nnum_output\\x18\\x01 \\x01(\\r:\\x01\\x30\\x12-\\n\\rweight_filler\\x18\\x02 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x19\\n\\ndebug_info\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1c\\n\\rexpose_hidden\\x18\\x05 \\x01(\\x08:\\x05\\x66\\x61lse\\""\\xad\\x01\\n\\x12ReductionParameter\\x12=\\n\\toperation\\x18\\x01 \\x01(\\x0e\\x32%.caffe.ReductionParameter.ReductionOp:\\x03SUM\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x10\\n\\x05\\x63oeff\\x18\\x03 \\x01(\\x02:\\x01\\x31\\""5\\n\\x0bReductionOp\\x12\\x07\\n\\x03SUM\\x10\\x01\\x12\\x08\\n\\x04\\x41SUM\\x10\\x02\\x12\\t\\n\\x05SUMSQ\\x10\\x03\\x12\\x08\\n\\x04MEAN\\x10\\x04\\""\\x8d\\x01\\n\\rReLUParameter\\x12\\x19\\n\\x0enegative_slope\\x18\\x01 \\x01(\\x02:\\x01\\x30\\x12\\x34\\n\\x06\\x65ngine\\x18\\x02 \\x01(\\x0e\\x32\\x1b.caffe.ReLUParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""Z\\n\\x10ReshapeParameter\\x12\\x1f\\n\\x05shape\\x18\\x01 \\x01(\\x0b\\x32\\x10.caffe.BlobShape\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\x08num_axes\\x18\\x03 \\x01(\\x05:\\x02-1\\""\\xa5\\x01\\n\\x0eScaleParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x08num_axes\\x18\\x02 \\x01(\\x05:\\x01\\x31\\x12&\\n\\x06\\x66iller\\x18\\x03 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x18\\n\\tbias_term\\x18\\x04 \\x01(\\x08:\\x05\\x66\\x61lse\\x12+\\n\\x0b\\x62ias_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\""x\\n\\x10SigmoidParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SigmoidParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""L\\n\\x0eSliceParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x03 \\x01(\\x05:\\x01\\x31\\x12\\x13\\n\\x0bslice_point\\x18\\x02 \\x03(\\r\\x12\\x14\\n\\tslice_dim\\x18\\x01 \\x01(\\r:\\x01\\x31\\""\\x89\\x01\\n\\x10SoftmaxParameter\\x12\\x37\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1e.caffe.SoftmaxParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\x12\\x0f\\n\\x04\\x61xis\\x18\\x02 \\x01(\\x05:\\x01\\x31\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""r\\n\\rTanHParameter\\x12\\x34\\n\\x06\\x65ngine\\x18\\x01 \\x01(\\x0e\\x32\\x1b.caffe.TanHParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""/\\n\\rTileParameter\\x12\\x0f\\n\\x04\\x61xis\\x18\\x01 \\x01(\\x05:\\x01\\x31\\x12\\r\\n\\x05tiles\\x18\\x02 \\x01(\\x05\\""*\\n\\x12ThresholdParameter\\x12\\x14\\n\\tthreshold\\x18\\x01 \\x01(\\x02:\\x01\\x30\\""\\xc1\\x02\\n\\x13WindowDataParameter\\x12\\x0e\\n\\x06source\\x18\\x01 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x02 \\x01(\\x02:\\x01\\x31\\x12\\x11\\n\\tmean_file\\x18\\x03 \\x01(\\t\\x12\\x12\\n\\nbatch_size\\x18\\x04 \\x01(\\r\\x12\\x14\\n\\tcrop_size\\x18\\x05 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x06 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x19\\n\\x0c\\x66g_threshold\\x18\\x07 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0c\\x62g_threshold\\x18\\x08 \\x01(\\x02:\\x03\\x30.5\\x12\\x19\\n\\x0b\\x66g_fraction\\x18\\t \\x01(\\x02:\\x04\\x30.25\\x12\\x16\\n\\x0b\\x63ontext_pad\\x18\\n \\x01(\\r:\\x01\\x30\\x12\\x17\\n\\tcrop_mode\\x18\\x0b \\x01(\\t:\\x04warp\\x12\\x1b\\n\\x0c\\x63\\x61\\x63he_images\\x18\\x0c \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\x0broot_folder\\x18\\r \\x01(\\t:\\x00\\""\\xeb\\x01\\n\\x0cSPPParameter\\x12\\x16\\n\\x0epyramid_height\\x18\\x01 \\x01(\\r\\x12\\x31\\n\\x04pool\\x18\\x02 \\x01(\\x0e\\x32\\x1e.caffe.SPPParameter.PoolMethod:\\x03MAX\\x12\\x33\\n\\x06\\x65ngine\\x18\\x06 \\x01(\\x0e\\x32\\x1a.caffe.SPPParameter.Engine:\\x07\\x44\\x45\\x46\\x41ULT\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""+\\n\\x06\\x45ngine\\x12\\x0b\\n\\x07\\x44\\x45\\x46\\x41ULT\\x10\\x00\\x12\\t\\n\\x05\\x43\\x41\\x46\\x46\\x45\\x10\\x01\\x12\\t\\n\\x05\\x43UDNN\\x10\\x02\\""\\xe0\\x13\\n\\x10V1LayerParameter\\x12\\x0e\\n\\x06\\x62ottom\\x18\\x02 \\x03(\\t\\x12\\x0b\\n\\x03top\\x18\\x03 \\x03(\\t\\x12\\x0c\\n\\x04name\\x18\\x04 \\x01(\\t\\x12$\\n\\x07include\\x18  \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12$\\n\\x07\\x65xclude\\x18! \\x03(\\x0b\\x32\\x13.caffe.NetStateRule\\x12/\\n\\x04type\\x18\\x05 \\x01(\\x0e\\x32!.caffe.V1LayerParameter.LayerType\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x06 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x0e\\n\\x05param\\x18\\xe9\\x07 \\x03(\\t\\x12>\\n\\x0f\\x62lob_share_mode\\x18\\xea\\x07 \\x03(\\x0e\\x32$.caffe.V1LayerParameter.DimCheckMode\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x07 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x08 \\x03(\\x02\\x12\\x13\\n\\x0bloss_weight\\x18# \\x03(\\x02\\x12\\x30\\n\\x0e\\x61\\x63\\x63uracy_param\\x18\\x1b \\x01(\\x0b\\x32\\x18.caffe.AccuracyParameter\\x12,\\n\\x0c\\x61rgmax_param\\x18\\x17 \\x01(\\x0b\\x32\\x16.caffe.ArgMaxParameter\\x12,\\n\\x0c\\x63oncat_param\\x18\\t \\x01(\\x0b\\x32\\x16.caffe.ConcatParameter\\x12?\\n\\x16\\x63ontrastive_loss_param\\x18( \\x01(\\x0b\\x32\\x1f.caffe.ContrastiveLossParameter\\x12\\x36\\n\\x11\\x63onvolution_param\\x18\\n \\x01(\\x0b\\x32\\x1b.caffe.ConvolutionParameter\\x12(\\n\\ndata_param\\x18\\x0b \\x01(\\x0b\\x32\\x14.caffe.DataParameter\\x12.\\n\\rdropout_param\\x18\\x0c \\x01(\\x0b\\x32\\x17.caffe.DropoutParameter\\x12\\x33\\n\\x10\\x64ummy_data_param\\x18\\x1a \\x01(\\x0b\\x32\\x19.caffe.DummyDataParameter\\x12.\\n\\reltwise_param\\x18\\x18 \\x01(\\x0b\\x32\\x17.caffe.EltwiseParameter\\x12&\\n\\texp_param\\x18) \\x01(\\x0b\\x32\\x13.caffe.ExpParameter\\x12\\x31\\n\\x0fhdf5_data_param\\x18\\r \\x01(\\x0b\\x32\\x18.caffe.HDF5DataParameter\\x12\\x35\\n\\x11hdf5_output_param\\x18\\x0e \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\x12\\x33\\n\\x10hinge_loss_param\\x18\\x1d \\x01(\\x0b\\x32\\x19.caffe.HingeLossParameter\\x12\\x33\\n\\x10image_data_param\\x18\\x0f \\x01(\\x0b\\x32\\x19.caffe.ImageDataParameter\\x12\\x39\\n\\x13infogain_loss_param\\x18\\x10 \\x01(\\x0b\\x32\\x1c.caffe.InfogainLossParameter\\x12\\x39\\n\\x13inner_product_param\\x18\\x11 \\x01(\\x0b\\x32\\x1c.caffe.InnerProductParameter\\x12&\\n\\tlrn_param\\x18\\x12 \\x01(\\x0b\\x32\\x13.caffe.LRNParameter\\x12\\x35\\n\\x11memory_data_param\\x18\\x16 \\x01(\\x0b\\x32\\x1a.caffe.MemoryDataParameter\\x12&\\n\\tmvn_param\\x18\\"" \\x01(\\x0b\\x32\\x13.caffe.MVNParameter\\x12.\\n\\rpooling_param\\x18\\x13 \\x01(\\x0b\\x32\\x17.caffe.PoolingParameter\\x12*\\n\\x0bpower_param\\x18\\x15 \\x01(\\x0b\\x32\\x15.caffe.PowerParameter\\x12(\\n\\nrelu_param\\x18\\x1e \\x01(\\x0b\\x32\\x14.caffe.ReLUParameter\\x12.\\n\\rsigmoid_param\\x18& \\x01(\\x0b\\x32\\x17.caffe.SigmoidParameter\\x12.\\n\\rsoftmax_param\\x18\\\' \\x01(\\x0b\\x32\\x17.caffe.SoftmaxParameter\\x12*\\n\\x0bslice_param\\x18\\x1f \\x01(\\x0b\\x32\\x15.caffe.SliceParameter\\x12(\\n\\ntanh_param\\x18% \\x01(\\x0b\\x32\\x14.caffe.TanHParameter\\x12\\x32\\n\\x0fthreshold_param\\x18\\x19 \\x01(\\x0b\\x32\\x19.caffe.ThresholdParameter\\x12\\x35\\n\\x11window_data_param\\x18\\x14 \\x01(\\x0b\\x32\\x1a.caffe.WindowDataParameter\\x12\\x37\\n\\x0ftransform_param\\x18$ \\x01(\\x0b\\x32\\x1e.caffe.TransformationParameter\\x12(\\n\\nloss_param\\x18* \\x01(\\x0b\\x32\\x14.caffe.LossParameter\\x12&\\n\\x05layer\\x18\\x01 \\x01(\\x0b\\x32\\x17.caffe.V0LayerParameter\\""\\xd8\\x04\\n\\tLayerType\\x12\\x08\\n\\x04NONE\\x10\\x00\\x12\\n\\n\\x06\\x41\\x42SVAL\\x10#\\x12\\x0c\\n\\x08\\x41\\x43\\x43URACY\\x10\\x01\\x12\\n\\n\\x06\\x41RGMAX\\x10\\x1e\\x12\\x08\\n\\x04\\x42NLL\\x10\\x02\\x12\\n\\n\\x06\\x43ONCAT\\x10\\x03\\x12\\x14\\n\\x10\\x43ONTRASTIVE_LOSS\\x10%\\x12\\x0f\\n\\x0b\\x43ONVOLUTION\\x10\\x04\\x12\\x08\\n\\x04\\x44\\x41TA\\x10\\x05\\x12\\x11\\n\\rDECONVOLUTION\\x10\\\'\\x12\\x0b\\n\\x07\\x44ROPOUT\\x10\\x06\\x12\\x0e\\n\\nDUMMY_DATA\\x10 \\x12\\x12\\n\\x0e\\x45UCLIDEAN_LOSS\\x10\\x07\\x12\\x0b\\n\\x07\\x45LTWISE\\x10\\x19\\x12\\x07\\n\\x03\\x45XP\\x10&\\x12\\x0b\\n\\x07\\x46LATTEN\\x10\\x08\\x12\\r\\n\\tHDF5_DATA\\x10\\t\\x12\\x0f\\n\\x0bHDF5_OUTPUT\\x10\\n\\x12\\x0e\\n\\nHINGE_LOSS\\x10\\x1c\\x12\\n\\n\\x06IM2COL\\x10\\x0b\\x12\\x0e\\n\\nIMAGE_DATA\\x10\\x0c\\x12\\x11\\n\\rINFOGAIN_LOSS\\x10\\r\\x12\\x11\\n\\rINNER_PRODUCT\\x10\\x0e\\x12\\x07\\n\\x03LRN\\x10\\x0f\\x12\\x0f\\n\\x0bMEMORY_DATA\\x10\\x1d\\x12\\x1d\\n\\x19MULTINOMIAL_LOGISTIC_LOSS\\x10\\x10\\x12\\x07\\n\\x03MVN\\x10\\""\\x12\\x0b\\n\\x07POOLING\\x10\\x11\\x12\\t\\n\\x05POWER\\x10\\x1a\\x12\\x08\\n\\x04RELU\\x10\\x12\\x12\\x0b\\n\\x07SIGMOID\\x10\\x13\\x12\\x1e\\n\\x1aSIGMOID_CROSS_ENTROPY_LOSS\\x10\\x1b\\x12\\x0b\\n\\x07SILENCE\\x10$\\x12\\x0b\\n\\x07SOFTMAX\\x10\\x14\\x12\\x10\\n\\x0cSOFTMAX_LOSS\\x10\\x15\\x12\\t\\n\\x05SPLIT\\x10\\x16\\x12\\t\\n\\x05SLICE\\x10!\\x12\\x08\\n\\x04TANH\\x10\\x17\\x12\\x0f\\n\\x0bWINDOW_DATA\\x10\\x18\\x12\\r\\n\\tTHRESHOLD\\x10\\x1f\\""*\\n\\x0c\\x44imCheckMode\\x12\\n\\n\\x06STRICT\\x10\\x00\\x12\\x0e\\n\\nPERMISSIVE\\x10\\x01\\""\\xfd\\x07\\n\\x10V0LayerParameter\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\x0c\\n\\x04type\\x18\\x02 \\x01(\\t\\x12\\x12\\n\\nnum_output\\x18\\x03 \\x01(\\r\\x12\\x16\\n\\x08\\x62iasterm\\x18\\x04 \\x01(\\x08:\\x04true\\x12-\\n\\rweight_filler\\x18\\x05 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12+\\n\\x0b\\x62ias_filler\\x18\\x06 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x0e\\n\\x03pad\\x18\\x07 \\x01(\\r:\\x01\\x30\\x12\\x12\\n\\nkernelsize\\x18\\x08 \\x01(\\r\\x12\\x10\\n\\x05group\\x18\\t \\x01(\\r:\\x01\\x31\\x12\\x11\\n\\x06stride\\x18\\n \\x01(\\r:\\x01\\x31\\x12\\x35\\n\\x04pool\\x18\\x0b \\x01(\\x0e\\x32\\"".caffe.V0LayerParameter.PoolMethod:\\x03MAX\\x12\\x1a\\n\\rdropout_ratio\\x18\\x0c \\x01(\\x02:\\x03\\x30.5\\x12\\x15\\n\\nlocal_size\\x18\\r \\x01(\\r:\\x01\\x35\\x12\\x10\\n\\x05\\x61lpha\\x18\\x0e \\x01(\\x02:\\x01\\x31\\x12\\x12\\n\\x04\\x62\\x65ta\\x18\\x0f \\x01(\\x02:\\x04\\x30.75\\x12\\x0c\\n\\x01k\\x18\\x16 \\x01(\\x02:\\x01\\x31\\x12\\x0e\\n\\x06source\\x18\\x10 \\x01(\\t\\x12\\x10\\n\\x05scale\\x18\\x11 \\x01(\\x02:\\x01\\x31\\x12\\x10\\n\\x08meanfile\\x18\\x12 \\x01(\\t\\x12\\x11\\n\\tbatchsize\\x18\\x13 \\x01(\\r\\x12\\x13\\n\\x08\\x63ropsize\\x18\\x14 \\x01(\\r:\\x01\\x30\\x12\\x15\\n\\x06mirror\\x18\\x15 \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x1f\\n\\x05\\x62lobs\\x18\\x32 \\x03(\\x0b\\x32\\x10.caffe.BlobProto\\x12\\x10\\n\\x08\\x62lobs_lr\\x18\\x33 \\x03(\\x02\\x12\\x14\\n\\x0cweight_decay\\x18\\x34 \\x03(\\x02\\x12\\x14\\n\\trand_skip\\x18\\x35 \\x01(\\r:\\x01\\x30\\x12\\x1d\\n\\x10\\x64\\x65t_fg_threshold\\x18\\x36 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x10\\x64\\x65t_bg_threshold\\x18\\x37 \\x01(\\x02:\\x03\\x30.5\\x12\\x1d\\n\\x0f\\x64\\x65t_fg_fraction\\x18\\x38 \\x01(\\x02:\\x04\\x30.25\\x12\\x1a\\n\\x0f\\x64\\x65t_context_pad\\x18: \\x01(\\r:\\x01\\x30\\x12\\x1b\\n\\rdet_crop_mode\\x18; \\x01(\\t:\\x04warp\\x12\\x12\\n\\x07new_num\\x18< \\x01(\\x05:\\x01\\x30\\x12\\x17\\n\\x0cnew_channels\\x18= \\x01(\\x05:\\x01\\x30\\x12\\x15\\n\\nnew_height\\x18> \\x01(\\x05:\\x01\\x30\\x12\\x14\\n\\tnew_width\\x18? \\x01(\\x05:\\x01\\x30\\x12\\x1d\\n\\x0eshuffle_images\\x18@ \\x01(\\x08:\\x05\\x66\\x61lse\\x12\\x15\\n\\nconcat_dim\\x18\\x41 \\x01(\\r:\\x01\\x31\\x12\\x36\\n\\x11hdf5_output_param\\x18\\xe9\\x07 \\x01(\\x0b\\x32\\x1a.caffe.HDF5OutputParameter\\"".\\n\\nPoolMethod\\x12\\x07\\n\\x03MAX\\x10\\x00\\x12\\x07\\n\\x03\\x41VE\\x10\\x01\\x12\\x0e\\n\\nSTOCHASTIC\\x10\\x02\\""W\\n\\x0ePReLUParameter\\x12&\\n\\x06\\x66iller\\x18\\x01 \\x01(\\x0b\\x32\\x16.caffe.FillerParameter\\x12\\x1d\\n\\x0e\\x63hannel_shared\\x18\\x02 \\x01(\\x08:\\x05\\x66\\x61lse*\\x1c\\n\\x05Phase\\x12\\t\\n\\x05TRAIN\\x10\\x00\\x12\\x08\\n\\x04TEST\\x10\\x01\')\n)\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\n_PHASE = _descriptor.EnumDescriptor(\n  name=\'Phase\',\n  full_name=\'caffe.Phase\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'TRAIN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TEST\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=15403,\n  serialized_end=15431,\n)\n_sym_db.RegisterEnumDescriptor(_PHASE)\n\nPhase = enum_type_wrapper.EnumTypeWrapper(_PHASE)\nTRAIN = 0\nTEST = 1\n\n\n_FILLERPARAMETER_VARIANCENORM = _descriptor.EnumDescriptor(\n  name=\'VarianceNorm\',\n  full_name=\'caffe.FillerParameter.VarianceNorm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_IN\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FAN_OUT\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVERAGE\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=658,\n  serialized_end=710,\n)\n_sym_db.RegisterEnumDescriptor(_FILLERPARAMETER_VARIANCENORM)\n\n_SOLVERPARAMETER_SNAPSHOTFORMAT = _descriptor.EnumDescriptor(\n  name=\'SnapshotFormat\',\n  full_name=\'caffe.SolverParameter.SnapshotFormat\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BINARYPROTO\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2171,\n  serialized_end=2214,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SNAPSHOTFORMAT)\n\n_SOLVERPARAMETER_SOLVERMODE = _descriptor.EnumDescriptor(\n  name=\'SolverMode\',\n  full_name=\'caffe.SolverParameter.SolverMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'CPU\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'GPU\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2216,\n  serialized_end=2246,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SOLVERMODE)\n\n_SOLVERPARAMETER_SOLVERTYPE = _descriptor.EnumDescriptor(\n  name=\'SolverType\',\n  full_name=\'caffe.SolverParameter.SolverType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SGD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NESTEROV\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAGRAD\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RMSPROP\', index=3, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADADELTA\', index=4, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ADAM\', index=5, number=5,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2248,\n  serialized_end=2333,\n)\n_sym_db.RegisterEnumDescriptor(_SOLVERPARAMETER_SOLVERTYPE)\n\n_PARAMSPEC_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.ParamSpec.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2764,\n  serialized_end=2806,\n)\n_sym_db.RegisterEnumDescriptor(_PARAMSPEC_DIMCHECKMODE)\n\n_LOSSPARAMETER_NORMALIZATIONMODE = _descriptor.EnumDescriptor(\n  name=\'NormalizationMode\',\n  full_name=\'caffe.LossParameter.NormalizationMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'FULL\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'VALID\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BATCH_SIZE\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=3, number=3,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=5687,\n  serialized_end=5753,\n)\n_sym_db.RegisterEnumDescriptor(_LOSSPARAMETER_NORMALIZATIONMODE)\n\n_CONVOLUTIONPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ConvolutionParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6718,\n  serialized_end=6761,\n)\n_sym_db.RegisterEnumDescriptor(_CONVOLUTIONPARAMETER_ENGINE)\n\n_DATAPARAMETER_DB = _descriptor.EnumDescriptor(\n  name=\'DB\',\n  full_name=\'caffe.DataParameter.DB\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'LEVELDB\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LMDB\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7079,\n  serialized_end=7106,\n)\n_sym_db.RegisterEnumDescriptor(_DATAPARAMETER_DB)\n\n_ELTWISEPARAMETER_ELTWISEOP = _descriptor.EnumDescriptor(\n  name=\'EltwiseOp\',\n  full_name=\'caffe.EltwiseParameter.EltwiseOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'PROD\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=7446,\n  serialized_end=7485,\n)\n_sym_db.RegisterEnumDescriptor(_ELTWISEPARAMETER_ELTWISEOP)\n\n_HINGELOSSPARAMETER_NORM = _descriptor.EnumDescriptor(\n  name=\'Norm\',\n  full_name=\'caffe.HingeLossParameter.Norm\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'L1\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'L2\', index=1, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=8020,\n  serialized_end=8042,\n)\n_sym_db.RegisterEnumDescriptor(_HINGELOSSPARAMETER_NORM)\n\n_LRNPARAMETER_NORMREGION = _descriptor.EnumDescriptor(\n  name=\'NormRegion\',\n  full_name=\'caffe.LRNParameter.NormRegion\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'ACROSS_CHANNELS\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WITHIN_CHANNEL\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=8926,\n  serialized_end=8979,\n)\n_sym_db.RegisterEnumDescriptor(_LRNPARAMETER_NORMREGION)\n\n_LRNPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.LRNParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6718,\n  serialized_end=6761,\n)\n_sym_db.RegisterEnumDescriptor(_LRNPARAMETER_ENGINE)\n\n_POOLINGPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.PoolingParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9603,\n  serialized_end=9649,\n)\n_sym_db.RegisterEnumDescriptor(_POOLINGPARAMETER_POOLMETHOD)\n\n_POOLINGPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.PoolingParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6718,\n  serialized_end=6761,\n)\n_sym_db.RegisterEnumDescriptor(_POOLINGPARAMETER_ENGINE)\n\n_REDUCTIONPARAMETER_REDUCTIONOP = _descriptor.EnumDescriptor(\n  name=\'ReductionOp\',\n  full_name=\'caffe.ReductionParameter.ReductionOp\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'SUM\', index=0, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ASUM\', index=1, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SUMSQ\', index=2, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEAN\', index=3, number=4,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=10189,\n  serialized_end=10242,\n)\n_sym_db.RegisterEnumDescriptor(_REDUCTIONPARAMETER_REDUCTIONOP)\n\n_RELUPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.ReLUParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6718,\n  serialized_end=6761,\n)\n_sym_db.RegisterEnumDescriptor(_RELUPARAMETER_ENGINE)\n\n_SIGMOIDPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SigmoidParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6718,\n  serialized_end=6761,\n)\n_sym_db.RegisterEnumDescriptor(_SIGMOIDPARAMETER_ENGINE)\n\n_SOFTMAXPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SoftmaxParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6718,\n  serialized_end=6761,\n)\n_sym_db.RegisterEnumDescriptor(_SOFTMAXPARAMETER_ENGINE)\n\n_TANHPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.TanHParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6718,\n  serialized_end=6761,\n)\n_sym_db.RegisterEnumDescriptor(_TANHPARAMETER_ENGINE)\n\n_SPPPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.SPPParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9603,\n  serialized_end=9649,\n)\n_sym_db.RegisterEnumDescriptor(_SPPPARAMETER_POOLMETHOD)\n\n_SPPPARAMETER_ENGINE = _descriptor.EnumDescriptor(\n  name=\'Engine\',\n  full_name=\'caffe.SPPParameter.Engine\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DEFAULT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CAFFE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CUDNN\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=6718,\n  serialized_end=6761,\n)\n_sym_db.RegisterEnumDescriptor(_SPPPARAMETER_ENGINE)\n\n_V1LAYERPARAMETER_LAYERTYPE = _descriptor.EnumDescriptor(\n  name=\'LayerType\',\n  full_name=\'caffe.V1LayerParameter.LayerType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'NONE\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ABSVAL\', index=1, number=35,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ACCURACY\', index=2, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ARGMAX\', index=3, number=30,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'BNLL\', index=4, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONCAT\', index=5, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONTRASTIVE_LOSS\', index=6, number=37,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'CONVOLUTION\', index=7, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DATA\', index=8, number=5,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DECONVOLUTION\', index=9, number=39,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DROPOUT\', index=10, number=6,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DUMMY_DATA\', index=11, number=32,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EUCLIDEAN_LOSS\', index=12, number=7,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'ELTWISE\', index=13, number=25,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'EXP\', index=14, number=38,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'FLATTEN\', index=15, number=8,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_DATA\', index=16, number=9,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HDF5_OUTPUT\', index=17, number=10,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'HINGE_LOSS\', index=18, number=28,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IM2COL\', index=19, number=11,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'IMAGE_DATA\', index=20, number=12,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INFOGAIN_LOSS\', index=21, number=13,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'INNER_PRODUCT\', index=22, number=14,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'LRN\', index=23, number=15,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MEMORY_DATA\', index=24, number=29,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MULTINOMIAL_LOGISTIC_LOSS\', index=25, number=16,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'MVN\', index=26, number=34,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POOLING\', index=27, number=17,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'POWER\', index=28, number=26,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'RELU\', index=29, number=18,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID\', index=30, number=19,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SIGMOID_CROSS_ENTROPY_LOSS\', index=31, number=27,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SILENCE\', index=32, number=36,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX\', index=33, number=20,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SOFTMAX_LOSS\', index=34, number=21,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SPLIT\', index=35, number=22,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'SLICE\', index=36, number=33,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'TANH\', index=37, number=23,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'WINDOW_DATA\', index=38, number=24,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'THRESHOLD\', index=39, number=31,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=13644,\n  serialized_end=14244,\n)\n_sym_db.RegisterEnumDescriptor(_V1LAYERPARAMETER_LAYERTYPE)\n\n_V1LAYERPARAMETER_DIMCHECKMODE = _descriptor.EnumDescriptor(\n  name=\'DimCheckMode\',\n  full_name=\'caffe.V1LayerParameter.DimCheckMode\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'STRICT\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'PERMISSIVE\', index=1, number=1,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=2764,\n  serialized_end=2806,\n)\n_sym_db.RegisterEnumDescriptor(_V1LAYERPARAMETER_DIMCHECKMODE)\n\n_V0LAYERPARAMETER_POOLMETHOD = _descriptor.EnumDescriptor(\n  name=\'PoolMethod\',\n  full_name=\'caffe.V0LayerParameter.PoolMethod\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'MAX\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'AVE\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'STOCHASTIC\', index=2, number=2,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=9603,\n  serialized_end=9649,\n)\n_sym_db.RegisterEnumDescriptor(_V0LAYERPARAMETER_POOLMETHOD)\n\n\n_BLOBSHAPE = _descriptor.Descriptor(\n  name=\'BlobShape\',\n  full_name=\'caffe.BlobShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'caffe.BlobShape.dim\', index=0,\n      number=1, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=22,\n  serialized_end=50,\n)\n\n\n_BLOBPROTO = _descriptor.Descriptor(\n  name=\'BlobProto\',\n  full_name=\'caffe.BlobProto\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.BlobProto.shape\', index=0,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.BlobProto.data\', index=1,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'diff\', full_name=\'caffe.BlobProto.diff\', index=2,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'double_data\', full_name=\'caffe.BlobProto.double_data\', index=3,\n      number=8, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'double_diff\', full_name=\'caffe.BlobProto.double_diff\', index=4,\n      number=9, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.BlobProto.num\', index=5,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.BlobProto.channels\', index=6,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.BlobProto.height\', index=7,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.BlobProto.width\', index=8,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=53,\n  serialized_end=257,\n)\n\n\n_BLOBPROTOVECTOR = _descriptor.Descriptor(\n  name=\'BlobProtoVector\',\n  full_name=\'caffe.BlobProtoVector\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.BlobProtoVector.blobs\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=259,\n  serialized_end=309,\n)\n\n\n_DATUM = _descriptor.Descriptor(\n  name=\'Datum\',\n  full_name=\'caffe.Datum\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.Datum.channels\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.Datum.height\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.Datum.width\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data\', full_name=\'caffe.Datum.data\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'label\', full_name=\'caffe.Datum.label\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'float_data\', full_name=\'caffe.Datum.float_data\', index=5,\n      number=6, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'encoded\', full_name=\'caffe.Datum.encoded\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=312,\n  serialized_end=441,\n)\n\n\n_FILLERPARAMETER = _descriptor.Descriptor(\n  name=\'FillerParameter\',\n  full_name=\'caffe.FillerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.FillerParameter.type\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""constant"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'caffe.FillerParameter.value\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min\', full_name=\'caffe.FillerParameter.min\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max\', full_name=\'caffe.FillerParameter.max\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean\', full_name=\'caffe.FillerParameter.mean\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'std\', full_name=\'caffe.FillerParameter.std\', index=5,\n      number=6, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sparse\', full_name=\'caffe.FillerParameter.sparse\', index=6,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'variance_norm\', full_name=\'caffe.FillerParameter.variance_norm\', index=7,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _FILLERPARAMETER_VARIANCENORM,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=444,\n  serialized_end=710,\n)\n\n\n_NETPARAMETER = _descriptor.Descriptor(\n  name=\'NetParameter\',\n  full_name=\'caffe.NetParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.NetParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'caffe.NetParameter.input\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_shape\', full_name=\'caffe.NetParameter.input_shape\', index=2,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.NetParameter.input_dim\', index=3,\n      number=4, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_backward\', full_name=\'caffe.NetParameter.force_backward\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'state\', full_name=\'caffe.NetParameter.state\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.NetParameter.debug_info\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.NetParameter.layer\', index=7,\n      number=100, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layers\', full_name=\'caffe.NetParameter.layers\', index=8,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=713,\n  serialized_end=983,\n)\n\n\n_SOLVERPARAMETER = _descriptor.Descriptor(\n  name=\'SolverParameter\',\n  full_name=\'caffe.SolverParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'net\', full_name=\'caffe.SolverParameter.net\', index=0,\n      number=24, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'net_param\', full_name=\'caffe.SolverParameter.net_param\', index=1,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net\', full_name=\'caffe.SolverParameter.train_net\', index=2,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net\', full_name=\'caffe.SolverParameter.test_net\', index=3,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_net_param\', full_name=\'caffe.SolverParameter.train_net_param\', index=4,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_net_param\', full_name=\'caffe.SolverParameter.test_net_param\', index=5,\n      number=22, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'train_state\', full_name=\'caffe.SolverParameter.train_state\', index=6,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_state\', full_name=\'caffe.SolverParameter.test_state\', index=7,\n      number=27, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_iter\', full_name=\'caffe.SolverParameter.test_iter\', index=8,\n      number=3, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_interval\', full_name=\'caffe.SolverParameter.test_interval\', index=9,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_compute_loss\', full_name=\'caffe.SolverParameter.test_compute_loss\', index=10,\n      number=19, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'test_initialization\', full_name=\'caffe.SolverParameter.test_initialization\', index=11,\n      number=32, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'base_lr\', full_name=\'caffe.SolverParameter.base_lr\', index=12,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'display\', full_name=\'caffe.SolverParameter.display\', index=13,\n      number=6, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'average_loss\', full_name=\'caffe.SolverParameter.average_loss\', index=14,\n      number=33, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_iter\', full_name=\'caffe.SolverParameter.max_iter\', index=15,\n      number=7, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'iter_size\', full_name=\'caffe.SolverParameter.iter_size\', index=16,\n      number=36, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_policy\', full_name=\'caffe.SolverParameter.lr_policy\', index=17,\n      number=8, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'gamma\', full_name=\'caffe.SolverParameter.gamma\', index=18,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.SolverParameter.power\', index=19,\n      number=10, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum\', full_name=\'caffe.SolverParameter.momentum\', index=20,\n      number=11, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.SolverParameter.weight_decay\', index=21,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'regularization_type\', full_name=\'caffe.SolverParameter.regularization_type\', index=22,\n      number=29, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""L2"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepsize\', full_name=\'caffe.SolverParameter.stepsize\', index=23,\n      number=13, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stepvalue\', full_name=\'caffe.SolverParameter.stepvalue\', index=24,\n      number=34, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'clip_gradients\', full_name=\'caffe.SolverParameter.clip_gradients\', index=25,\n      number=35, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot\', full_name=\'caffe.SolverParameter.snapshot\', index=26,\n      number=14, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_prefix\', full_name=\'caffe.SolverParameter.snapshot_prefix\', index=27,\n      number=15, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_diff\', full_name=\'caffe.SolverParameter.snapshot_diff\', index=28,\n      number=16, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_format\', full_name=\'caffe.SolverParameter.snapshot_format\', index=29,\n      number=37, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_mode\', full_name=\'caffe.SolverParameter.solver_mode\', index=30,\n      number=17, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'device_id\', full_name=\'caffe.SolverParameter.device_id\', index=31,\n      number=18, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'random_seed\', full_name=\'caffe.SolverParameter.random_seed\', index=32,\n      number=20, type=3, cpp_type=2, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.SolverParameter.type\', index=33,\n      number=40, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""SGD"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'delta\', full_name=\'caffe.SolverParameter.delta\', index=34,\n      number=31, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-08),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'momentum2\', full_name=\'caffe.SolverParameter.momentum2\', index=35,\n      number=39, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.999),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rms_decay\', full_name=\'caffe.SolverParameter.rms_decay\', index=36,\n      number=38, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.99),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.SolverParameter.debug_info\', index=37,\n      number=23, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'snapshot_after_train\', full_name=\'caffe.SolverParameter.snapshot_after_train\', index=38,\n      number=28, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'solver_type\', full_name=\'caffe.SolverParameter.solver_type\', index=39,\n      number=30, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer_wise_reduce\', full_name=\'caffe.SolverParameter.layer_wise_reduce\', index=40,\n      number=41, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOLVERPARAMETER_SNAPSHOTFORMAT,\n    _SOLVERPARAMETER_SOLVERMODE,\n    _SOLVERPARAMETER_SOLVERTYPE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=986,\n  serialized_end=2333,\n)\n\n\n_SOLVERSTATE = _descriptor.Descriptor(\n  name=\'SolverState\',\n  full_name=\'caffe.SolverState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'iter\', full_name=\'caffe.SolverState.iter\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'learned_net\', full_name=\'caffe.SolverState.learned_net\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'history\', full_name=\'caffe.SolverState.history\', index=2,\n      number=3, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'current_step\', full_name=\'caffe.SolverState.current_step\', index=3,\n      number=4, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2335,\n  serialized_end=2443,\n)\n\n\n_NETSTATE = _descriptor.Descriptor(\n  name=\'NetState\',\n  full_name=\'caffe.NetState\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetState.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'level\', full_name=\'caffe.NetState.level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetState.stage\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2445,\n  serialized_end=2523,\n)\n\n\n_NETSTATERULE = _descriptor.Descriptor(\n  name=\'NetStateRule\',\n  full_name=\'caffe.NetStateRule\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.NetStateRule.phase\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'min_level\', full_name=\'caffe.NetStateRule.min_level\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'max_level\', full_name=\'caffe.NetStateRule.max_level\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stage\', full_name=\'caffe.NetStateRule.stage\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'not_stage\', full_name=\'caffe.NetStateRule.not_stage\', index=4,\n      number=5, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2525,\n  serialized_end=2640,\n)\n\n\n_PARAMSPEC = _descriptor.Descriptor(\n  name=\'ParamSpec\',\n  full_name=\'caffe.ParamSpec\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.ParamSpec.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_mode\', full_name=\'caffe.ParamSpec.share_mode\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lr_mult\', full_name=\'caffe.ParamSpec.lr_mult\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'decay_mult\', full_name=\'caffe.ParamSpec.decay_mult\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _PARAMSPEC_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2643,\n  serialized_end=2806,\n)\n\n\n_LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'LayerParameter\',\n  full_name=\'caffe.LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.LayerParameter.bottom\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.LayerParameter.top\', index=3,\n      number=4, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'phase\', full_name=\'caffe.LayerParameter.phase\', index=4,\n      number=10, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.LayerParameter.loss_weight\', index=5,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.LayerParameter.param\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.LayerParameter.blobs\', index=7,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'propagate_down\', full_name=\'caffe.LayerParameter.propagate_down\', index=8,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.LayerParameter.include\', index=9,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.LayerParameter.exclude\', index=10,\n      number=9, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.LayerParameter.transform_param\', index=11,\n      number=100, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.LayerParameter.loss_param\', index=12,\n      number=101, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.LayerParameter.accuracy_param\', index=13,\n      number=102, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.LayerParameter.argmax_param\', index=14,\n      number=103, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_norm_param\', full_name=\'caffe.LayerParameter.batch_norm_param\', index=15,\n      number=139, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_param\', full_name=\'caffe.LayerParameter.bias_param\', index=16,\n      number=141, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.LayerParameter.concat_param\', index=17,\n      number=104, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.LayerParameter.contrastive_loss_param\', index=18,\n      number=105, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.LayerParameter.convolution_param\', index=19,\n      number=106, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_param\', full_name=\'caffe.LayerParameter.crop_param\', index=20,\n      number=144, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.LayerParameter.data_param\', index=21,\n      number=107, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.LayerParameter.dropout_param\', index=22,\n      number=108, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.LayerParameter.dummy_data_param\', index=23,\n      number=109, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.LayerParameter.eltwise_param\', index=24,\n      number=110, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'elu_param\', full_name=\'caffe.LayerParameter.elu_param\', index=25,\n      number=140, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'embed_param\', full_name=\'caffe.LayerParameter.embed_param\', index=26,\n      number=137, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.LayerParameter.exp_param\', index=27,\n      number=111, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'flatten_param\', full_name=\'caffe.LayerParameter.flatten_param\', index=28,\n      number=135, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.LayerParameter.hdf5_data_param\', index=29,\n      number=112, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.LayerParameter.hdf5_output_param\', index=30,\n      number=113, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.LayerParameter.hinge_loss_param\', index=31,\n      number=114, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.LayerParameter.image_data_param\', index=32,\n      number=115, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.LayerParameter.infogain_loss_param\', index=33,\n      number=116, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.LayerParameter.inner_product_param\', index=34,\n      number=117, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_param\', full_name=\'caffe.LayerParameter.input_param\', index=35,\n      number=143, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'log_param\', full_name=\'caffe.LayerParameter.log_param\', index=36,\n      number=134, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.LayerParameter.lrn_param\', index=37,\n      number=118, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.LayerParameter.memory_data_param\', index=38,\n      number=119, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.LayerParameter.mvn_param\', index=39,\n      number=120, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'parameter_param\', full_name=\'caffe.LayerParameter.parameter_param\', index=40,\n      number=145, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.LayerParameter.pooling_param\', index=41,\n      number=121, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.LayerParameter.power_param\', index=42,\n      number=122, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prelu_param\', full_name=\'caffe.LayerParameter.prelu_param\', index=43,\n      number=131, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'python_param\', full_name=\'caffe.LayerParameter.python_param\', index=44,\n      number=130, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'recurrent_param\', full_name=\'caffe.LayerParameter.recurrent_param\', index=45,\n      number=146, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reduction_param\', full_name=\'caffe.LayerParameter.reduction_param\', index=46,\n      number=136, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.LayerParameter.relu_param\', index=47,\n      number=123, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'reshape_param\', full_name=\'caffe.LayerParameter.reshape_param\', index=48,\n      number=133, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale_param\', full_name=\'caffe.LayerParameter.scale_param\', index=49,\n      number=142, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.LayerParameter.sigmoid_param\', index=50,\n      number=124, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.LayerParameter.softmax_param\', index=51,\n      number=125, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'spp_param\', full_name=\'caffe.LayerParameter.spp_param\', index=52,\n      number=132, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.LayerParameter.slice_param\', index=53,\n      number=126, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.LayerParameter.tanh_param\', index=54,\n      number=127, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.LayerParameter.threshold_param\', index=55,\n      number=128, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tile_param\', full_name=\'caffe.LayerParameter.tile_param\', index=56,\n      number=138, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.LayerParameter.window_data_param\', index=57,\n      number=129, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=2809,\n  serialized_end=5371,\n)\n\n\n_TRANSFORMATIONPARAMETER = _descriptor.Descriptor(\n  name=\'TransformationParameter\',\n  full_name=\'caffe.TransformationParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.TransformationParameter.scale\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.TransformationParameter.mirror\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.TransformationParameter.crop_size\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.TransformationParameter.mean_file\', index=3,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_value\', full_name=\'caffe.TransformationParameter.mean_value\', index=4,\n      number=5, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_color\', full_name=\'caffe.TransformationParameter.force_color\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_gray\', full_name=\'caffe.TransformationParameter.force_gray\', index=6,\n      number=7, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=5374,\n  serialized_end=5556,\n)\n\n\n_LOSSPARAMETER = _descriptor.Descriptor(\n  name=\'LossParameter\',\n  full_name=\'caffe.LossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.LossParameter.ignore_label\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalization\', full_name=\'caffe.LossParameter.normalization\', index=1,\n      number=3, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'normalize\', full_name=\'caffe.LossParameter.normalize\', index=2,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LOSSPARAMETER_NORMALIZATIONMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=5559,\n  serialized_end=5753,\n)\n\n\n_ACCURACYPARAMETER = _descriptor.Descriptor(\n  name=\'AccuracyParameter\',\n  full_name=\'caffe.AccuracyParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.AccuracyParameter.top_k\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.AccuracyParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'ignore_label\', full_name=\'caffe.AccuracyParameter.ignore_label\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=5755,\n  serialized_end=5831,\n)\n\n\n_ARGMAXPARAMETER = _descriptor.Descriptor(\n  name=\'ArgMaxParameter\',\n  full_name=\'caffe.ArgMaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'out_max_val\', full_name=\'caffe.ArgMaxParameter.out_max_val\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top_k\', full_name=\'caffe.ArgMaxParameter.top_k\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ArgMaxParameter.axis\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=5833,\n  serialized_end=5910,\n)\n\n\n_CONCATPARAMETER = _descriptor.Descriptor(\n  name=\'ConcatParameter\',\n  full_name=\'caffe.ConcatParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConcatParameter.axis\', index=0,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.ConcatParameter.concat_dim\', index=1,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=5912,\n  serialized_end=5969,\n)\n\n\n_BATCHNORMPARAMETER = _descriptor.Descriptor(\n  name=\'BatchNormParameter\',\n  full_name=\'caffe.BatchNormParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'use_global_stats\', full_name=\'caffe.BatchNormParameter.use_global_stats\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'moving_average_fraction\', full_name=\'caffe.BatchNormParameter.moving_average_fraction\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.999),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.BatchNormParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-05),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=5971,\n  serialized_end=6077,\n)\n\n\n_BIASPARAMETER = _descriptor.Descriptor(\n  name=\'BiasParameter\',\n  full_name=\'caffe.BiasParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.BiasParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.BiasParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.BiasParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6079,\n  serialized_end=6172,\n)\n\n\n_CONTRASTIVELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'ContrastiveLossParameter\',\n  full_name=\'caffe.ContrastiveLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'margin\', full_name=\'caffe.ContrastiveLossParameter.margin\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'legacy_version\', full_name=\'caffe.ContrastiveLossParameter.legacy_version\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6174,\n  serialized_end=6250,\n)\n\n\n_CONVOLUTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ConvolutionParameter\',\n  full_name=\'caffe.ConvolutionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.ConvolutionParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ConvolutionParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.ConvolutionParameter.pad\', index=2,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.ConvolutionParameter.kernel_size\', index=3,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.ConvolutionParameter.stride\', index=4,\n      number=6, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dilation\', full_name=\'caffe.ConvolutionParameter.dilation\', index=5,\n      number=18, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.ConvolutionParameter.pad_h\', index=6,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.ConvolutionParameter.pad_w\', index=7,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.ConvolutionParameter.kernel_h\', index=8,\n      number=11, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.ConvolutionParameter.kernel_w\', index=9,\n      number=12, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.ConvolutionParameter.stride_h\', index=10,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.ConvolutionParameter.stride_w\', index=11,\n      number=14, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.ConvolutionParameter.group\', index=12,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.ConvolutionParameter.weight_filler\', index=13,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ConvolutionParameter.bias_filler\', index=14,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ConvolutionParameter.engine\', index=15,\n      number=15, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ConvolutionParameter.axis\', index=16,\n      number=16, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_nd_im2col\', full_name=\'caffe.ConvolutionParameter.force_nd_im2col\', index=17,\n      number=17, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _CONVOLUTIONPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6253,\n  serialized_end=6761,\n)\n\n\n_CROPPARAMETER = _descriptor.Descriptor(\n  name=\'CropParameter\',\n  full_name=\'caffe.CropParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.CropParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=2,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'offset\', full_name=\'caffe.CropParameter.offset\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6763,\n  serialized_end=6811,\n)\n\n\n_DATAPARAMETER = _descriptor.Descriptor(\n  name=\'DataParameter\',\n  full_name=\'caffe.DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.DataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.DataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'backend\', full_name=\'caffe.DataParameter.backend\', index=3,\n      number=8, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.DataParameter.scale\', index=4,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.DataParameter.mean_file\', index=5,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.DataParameter.crop_size\', index=6,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.DataParameter.mirror\', index=7,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'force_encoded_color\', full_name=\'caffe.DataParameter.force_encoded_color\', index=8,\n      number=9, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'prefetch\', full_name=\'caffe.DataParameter.prefetch\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=4,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _DATAPARAMETER_DB,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=6814,\n  serialized_end=7106,\n)\n\n\n_DROPOUTPARAMETER = _descriptor.Descriptor(\n  name=\'DropoutParameter\',\n  full_name=\'caffe.DropoutParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.DropoutParameter.dropout_ratio\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7108,\n  serialized_end=7154,\n)\n\n\n_DUMMYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'DummyDataParameter\',\n  full_name=\'caffe.DummyDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'data_filler\', full_name=\'caffe.DummyDataParameter.data_filler\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.DummyDataParameter.shape\', index=1,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num\', full_name=\'caffe.DummyDataParameter.num\', index=2,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.DummyDataParameter.channels\', index=3,\n      number=3, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.DummyDataParameter.height\', index=4,\n      number=4, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.DummyDataParameter.width\', index=5,\n      number=5, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7157,\n  serialized_end=7317,\n)\n\n\n_ELTWISEPARAMETER = _descriptor.Descriptor(\n  name=\'EltwiseParameter\',\n  full_name=\'caffe.EltwiseParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.EltwiseParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.EltwiseParameter.coeff\', index=1,\n      number=2, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stable_prod_grad\', full_name=\'caffe.EltwiseParameter.stable_prod_grad\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _ELTWISEPARAMETER_ELTWISEOP,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7320,\n  serialized_end=7485,\n)\n\n\n_ELUPARAMETER = _descriptor.Descriptor(\n  name=\'ELUParameter\',\n  full_name=\'caffe.ELUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.ELUParameter.alpha\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7487,\n  serialized_end=7519,\n)\n\n\n_EMBEDPARAMETER = _descriptor.Descriptor(\n  name=\'EmbedParameter\',\n  full_name=\'caffe.EmbedParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.EmbedParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input_dim\', full_name=\'caffe.EmbedParameter.input_dim\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.EmbedParameter.bias_term\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.EmbedParameter.weight_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.EmbedParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7522,\n  serialized_end=7694,\n)\n\n\n_EXPPARAMETER = _descriptor.Descriptor(\n  name=\'ExpParameter\',\n  full_name=\'caffe.ExpParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.ExpParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ExpParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.ExpParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7696,\n  serialized_end=7764,\n)\n\n\n_FLATTENPARAMETER = _descriptor.Descriptor(\n  name=\'FlattenParameter\',\n  full_name=\'caffe.FlattenParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.FlattenParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'end_axis\', full_name=\'caffe.FlattenParameter.end_axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7766,\n  serialized_end=7823,\n)\n\n\n_HDF5DATAPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5DataParameter\',\n  full_name=\'caffe.HDF5DataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.HDF5DataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.HDF5DataParameter.batch_size\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.HDF5DataParameter.shuffle\', index=2,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7825,\n  serialized_end=7904,\n)\n\n\n_HDF5OUTPUTPARAMETER = _descriptor.Descriptor(\n  name=\'HDF5OutputParameter\',\n  full_name=\'caffe.HDF5OutputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'file_name\', full_name=\'caffe.HDF5OutputParameter.file_name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7906,\n  serialized_end=7946,\n)\n\n\n_HINGELOSSPARAMETER = _descriptor.Descriptor(\n  name=\'HingeLossParameter\',\n  full_name=\'caffe.HingeLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'norm\', full_name=\'caffe.HingeLossParameter.norm\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _HINGELOSSPARAMETER_NORM,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=7948,\n  serialized_end=8042,\n)\n\n\n_IMAGEDATAPARAMETER = _descriptor.Descriptor(\n  name=\'ImageDataParameter\',\n  full_name=\'caffe.ImageDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.ImageDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.ImageDataParameter.batch_size\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.ImageDataParameter.rand_skip\', index=2,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle\', full_name=\'caffe.ImageDataParameter.shuffle\', index=3,\n      number=8, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.ImageDataParameter.new_height\', index=4,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.ImageDataParameter.new_width\', index=5,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'is_color\', full_name=\'caffe.ImageDataParameter.is_color\', index=6,\n      number=11, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.ImageDataParameter.scale\', index=7,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.ImageDataParameter.mean_file\', index=8,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.ImageDataParameter.crop_size\', index=9,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.ImageDataParameter.mirror\', index=10,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.ImageDataParameter.root_folder\', index=11,\n      number=12, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8045,\n  serialized_end=8324,\n)\n\n\n_INFOGAINLOSSPARAMETER = _descriptor.Descriptor(\n  name=\'InfogainLossParameter\',\n  full_name=\'caffe.InfogainLossParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.InfogainLossParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.InfogainLossParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8326,\n  serialized_end=8382,\n)\n\n\n_INNERPRODUCTPARAMETER = _descriptor.Descriptor(\n  name=\'InnerProductParameter\',\n  full_name=\'caffe.InnerProductParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.InnerProductParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.InnerProductParameter.bias_term\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.InnerProductParameter.weight_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.InnerProductParameter.bias_filler\', index=3,\n      number=4, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.InnerProductParameter.axis\', index=4,\n      number=5, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transpose\', full_name=\'caffe.InnerProductParameter.transpose\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8385,\n  serialized_end=8588,\n)\n\n\n_INPUTPARAMETER = _descriptor.Descriptor(\n  name=\'InputParameter\',\n  full_name=\'caffe.InputParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.InputParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8590,\n  serialized_end=8639,\n)\n\n\n_LOGPARAMETER = _descriptor.Descriptor(\n  name=\'LogParameter\',\n  full_name=\'caffe.LogParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'base\', full_name=\'caffe.LogParameter.base\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(-1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.LogParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.LogParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8641,\n  serialized_end=8709,\n)\n\n\n_LRNPARAMETER = _descriptor.Descriptor(\n  name=\'LRNParameter\',\n  full_name=\'caffe.LRNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.LRNParameter.local_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.LRNParameter.alpha\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.LRNParameter.beta\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.75),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'norm_region\', full_name=\'caffe.LRNParameter.norm_region\', index=3,\n      number=4, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.LRNParameter.k\', index=4,\n      number=5, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.LRNParameter.engine\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _LRNPARAMETER_NORMREGION,\n    _LRNPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=8712,\n  serialized_end=9024,\n)\n\n\n_MEMORYDATAPARAMETER = _descriptor.Descriptor(\n  name=\'MemoryDataParameter\',\n  full_name=\'caffe.MemoryDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.MemoryDataParameter.batch_size\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channels\', full_name=\'caffe.MemoryDataParameter.channels\', index=1,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'height\', full_name=\'caffe.MemoryDataParameter.height\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'width\', full_name=\'caffe.MemoryDataParameter.width\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9026,\n  serialized_end=9116,\n)\n\n\n_MVNPARAMETER = _descriptor.Descriptor(\n  name=\'MVNParameter\',\n  full_name=\'caffe.MVNParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'normalize_variance\', full_name=\'caffe.MVNParameter.normalize_variance\', index=0,\n      number=1, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'across_channels\', full_name=\'caffe.MVNParameter.across_channels\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eps\', full_name=\'caffe.MVNParameter.eps\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1e-09),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9118,\n  serialized_end=9218,\n)\n\n\n_PARAMETERPARAMETER = _descriptor.Descriptor(\n  name=\'ParameterParameter\',\n  full_name=\'caffe.ParameterParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ParameterParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9220,\n  serialized_end=9273,\n)\n\n\n_POOLINGPARAMETER = _descriptor.Descriptor(\n  name=\'PoolingParameter\',\n  full_name=\'caffe.PoolingParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.PoolingParameter.pool\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.PoolingParameter.pad\', index=1,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_h\', full_name=\'caffe.PoolingParameter.pad_h\', index=2,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad_w\', full_name=\'caffe.PoolingParameter.pad_w\', index=3,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_size\', full_name=\'caffe.PoolingParameter.kernel_size\', index=4,\n      number=2, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_h\', full_name=\'caffe.PoolingParameter.kernel_h\', index=5,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernel_w\', full_name=\'caffe.PoolingParameter.kernel_w\', index=6,\n      number=6, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.PoolingParameter.stride\', index=7,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_h\', full_name=\'caffe.PoolingParameter.stride_h\', index=8,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride_w\', full_name=\'caffe.PoolingParameter.stride_w\', index=9,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.PoolingParameter.engine\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'global_pooling\', full_name=\'caffe.PoolingParameter.global_pooling\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _POOLINGPARAMETER_POOLMETHOD,\n    _POOLINGPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9276,\n  serialized_end=9694,\n)\n\n\n_POWERPARAMETER = _descriptor.Descriptor(\n  name=\'PowerParameter\',\n  full_name=\'caffe.PowerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'power\', full_name=\'caffe.PowerParameter.power\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.PowerParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shift\', full_name=\'caffe.PowerParameter.shift\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9696,\n  serialized_end=9766,\n)\n\n\n_PYTHONPARAMETER = _descriptor.Descriptor(\n  name=\'PythonParameter\',\n  full_name=\'caffe.PythonParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'module\', full_name=\'caffe.PythonParameter.module\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.PythonParameter.layer\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param_str\', full_name=\'caffe.PythonParameter.param_str\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'share_in_parallel\', full_name=\'caffe.PythonParameter.share_in_parallel\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9768,\n  serialized_end=9871,\n)\n\n\n_RECURRENTPARAMETER = _descriptor.Descriptor(\n  name=\'RecurrentParameter\',\n  full_name=\'caffe.RecurrentParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.RecurrentParameter.num_output\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.RecurrentParameter.weight_filler\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.RecurrentParameter.bias_filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'debug_info\', full_name=\'caffe.RecurrentParameter.debug_info\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'expose_hidden\', full_name=\'caffe.RecurrentParameter.expose_hidden\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=9874,\n  serialized_end=10066,\n)\n\n\n_REDUCTIONPARAMETER = _descriptor.Descriptor(\n  name=\'ReductionParameter\',\n  full_name=\'caffe.ReductionParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'operation\', full_name=\'caffe.ReductionParameter.operation\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReductionParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'coeff\', full_name=\'caffe.ReductionParameter.coeff\', index=2,\n      number=3, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _REDUCTIONPARAMETER_REDUCTIONOP,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10069,\n  serialized_end=10242,\n)\n\n\n_RELUPARAMETER = _descriptor.Descriptor(\n  name=\'ReLUParameter\',\n  full_name=\'caffe.ReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'negative_slope\', full_name=\'caffe.ReLUParameter.negative_slope\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.ReLUParameter.engine\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _RELUPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10245,\n  serialized_end=10386,\n)\n\n\n_RESHAPEPARAMETER = _descriptor.Descriptor(\n  name=\'ReshapeParameter\',\n  full_name=\'caffe.ReshapeParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'caffe.ReshapeParameter.shape\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ReshapeParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ReshapeParameter.num_axes\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=-1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10388,\n  serialized_end=10478,\n)\n\n\n_SCALEPARAMETER = _descriptor.Descriptor(\n  name=\'ScaleParameter\',\n  full_name=\'caffe.ScaleParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.ScaleParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_axes\', full_name=\'caffe.ScaleParameter.num_axes\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.ScaleParameter.filler\', index=2,\n      number=3, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_term\', full_name=\'caffe.ScaleParameter.bias_term\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.ScaleParameter.bias_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10481,\n  serialized_end=10646,\n)\n\n\n_SIGMOIDPARAMETER = _descriptor.Descriptor(\n  name=\'SigmoidParameter\',\n  full_name=\'caffe.SigmoidParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SigmoidParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SIGMOIDPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10648,\n  serialized_end=10768,\n)\n\n\n_SLICEPARAMETER = _descriptor.Descriptor(\n  name=\'SliceParameter\',\n  full_name=\'caffe.SliceParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SliceParameter.axis\', index=0,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_point\', full_name=\'caffe.SliceParameter.slice_point\', index=1,\n      number=2, type=13, cpp_type=3, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_dim\', full_name=\'caffe.SliceParameter.slice_dim\', index=2,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10770,\n  serialized_end=10846,\n)\n\n\n_SOFTMAXPARAMETER = _descriptor.Descriptor(\n  name=\'SoftmaxParameter\',\n  full_name=\'caffe.SoftmaxParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SoftmaxParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.SoftmaxParameter.axis\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SOFTMAXPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10849,\n  serialized_end=10986,\n)\n\n\n_TANHPARAMETER = _descriptor.Descriptor(\n  name=\'TanHParameter\',\n  full_name=\'caffe.TanHParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.TanHParameter.engine\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _TANHPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=10988,\n  serialized_end=11102,\n)\n\n\n_TILEPARAMETER = _descriptor.Descriptor(\n  name=\'TileParameter\',\n  full_name=\'caffe.TileParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'axis\', full_name=\'caffe.TileParameter.axis\', index=0,\n      number=1, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tiles\', full_name=\'caffe.TileParameter.tiles\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11104,\n  serialized_end=11151,\n)\n\n\n_THRESHOLDPARAMETER = _descriptor.Descriptor(\n  name=\'ThresholdParameter\',\n  full_name=\'caffe.ThresholdParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'threshold\', full_name=\'caffe.ThresholdParameter.threshold\', index=0,\n      number=1, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11153,\n  serialized_end=11195,\n)\n\n\n_WINDOWDATAPARAMETER = _descriptor.Descriptor(\n  name=\'WindowDataParameter\',\n  full_name=\'caffe.WindowDataParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.WindowDataParameter.source\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.WindowDataParameter.scale\', index=1,\n      number=2, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mean_file\', full_name=\'caffe.WindowDataParameter.mean_file\', index=2,\n      number=3, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batch_size\', full_name=\'caffe.WindowDataParameter.batch_size\', index=3,\n      number=4, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_size\', full_name=\'caffe.WindowDataParameter.crop_size\', index=4,\n      number=5, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.WindowDataParameter.mirror\', index=5,\n      number=6, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_threshold\', full_name=\'caffe.WindowDataParameter.fg_threshold\', index=6,\n      number=7, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bg_threshold\', full_name=\'caffe.WindowDataParameter.bg_threshold\', index=7,\n      number=8, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'fg_fraction\', full_name=\'caffe.WindowDataParameter.fg_fraction\', index=8,\n      number=9, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.25),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'context_pad\', full_name=\'caffe.WindowDataParameter.context_pad\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'crop_mode\', full_name=\'caffe.WindowDataParameter.crop_mode\', index=10,\n      number=11, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""warp"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cache_images\', full_name=\'caffe.WindowDataParameter.cache_images\', index=11,\n      number=12, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'root_folder\', full_name=\'caffe.WindowDataParameter.root_folder\', index=12,\n      number=13, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11198,\n  serialized_end=11519,\n)\n\n\n_SPPPARAMETER = _descriptor.Descriptor(\n  name=\'SPPParameter\',\n  full_name=\'caffe.SPPParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'pyramid_height\', full_name=\'caffe.SPPParameter.pyramid_height\', index=0,\n      number=1, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.SPPParameter.pool\', index=1,\n      number=2, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'engine\', full_name=\'caffe.SPPParameter.engine\', index=2,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _SPPPARAMETER_POOLMETHOD,\n    _SPPPARAMETER_ENGINE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11522,\n  serialized_end=11757,\n)\n\n\n_V1LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V1LayerParameter\',\n  full_name=\'caffe.V1LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'bottom\', full_name=\'caffe.V1LayerParameter.bottom\', index=0,\n      number=2, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'top\', full_name=\'caffe.V1LayerParameter.top\', index=1,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V1LayerParameter.name\', index=2,\n      number=4, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'include\', full_name=\'caffe.V1LayerParameter.include\', index=3,\n      number=32, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exclude\', full_name=\'caffe.V1LayerParameter.exclude\', index=4,\n      number=33, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V1LayerParameter.type\', index=5,\n      number=5, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V1LayerParameter.blobs\', index=6,\n      number=6, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'param\', full_name=\'caffe.V1LayerParameter.param\', index=7,\n      number=1001, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blob_share_mode\', full_name=\'caffe.V1LayerParameter.blob_share_mode\', index=8,\n      number=1002, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V1LayerParameter.blobs_lr\', index=9,\n      number=7, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V1LayerParameter.weight_decay\', index=10,\n      number=8, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_weight\', full_name=\'caffe.V1LayerParameter.loss_weight\', index=11,\n      number=35, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'accuracy_param\', full_name=\'caffe.V1LayerParameter.accuracy_param\', index=12,\n      number=27, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'argmax_param\', full_name=\'caffe.V1LayerParameter.argmax_param\', index=13,\n      number=23, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_param\', full_name=\'caffe.V1LayerParameter.concat_param\', index=14,\n      number=9, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'contrastive_loss_param\', full_name=\'caffe.V1LayerParameter.contrastive_loss_param\', index=15,\n      number=40, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'convolution_param\', full_name=\'caffe.V1LayerParameter.convolution_param\', index=16,\n      number=10, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'data_param\', full_name=\'caffe.V1LayerParameter.data_param\', index=17,\n      number=11, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_param\', full_name=\'caffe.V1LayerParameter.dropout_param\', index=18,\n      number=12, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dummy_data_param\', full_name=\'caffe.V1LayerParameter.dummy_data_param\', index=19,\n      number=26, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'eltwise_param\', full_name=\'caffe.V1LayerParameter.eltwise_param\', index=20,\n      number=24, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'exp_param\', full_name=\'caffe.V1LayerParameter.exp_param\', index=21,\n      number=41, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_data_param\', full_name=\'caffe.V1LayerParameter.hdf5_data_param\', index=22,\n      number=13, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V1LayerParameter.hdf5_output_param\', index=23,\n      number=14, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hinge_loss_param\', full_name=\'caffe.V1LayerParameter.hinge_loss_param\', index=24,\n      number=29, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'image_data_param\', full_name=\'caffe.V1LayerParameter.image_data_param\', index=25,\n      number=15, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'infogain_loss_param\', full_name=\'caffe.V1LayerParameter.infogain_loss_param\', index=26,\n      number=16, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'inner_product_param\', full_name=\'caffe.V1LayerParameter.inner_product_param\', index=27,\n      number=17, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'lrn_param\', full_name=\'caffe.V1LayerParameter.lrn_param\', index=28,\n      number=18, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'memory_data_param\', full_name=\'caffe.V1LayerParameter.memory_data_param\', index=29,\n      number=22, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mvn_param\', full_name=\'caffe.V1LayerParameter.mvn_param\', index=30,\n      number=34, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pooling_param\', full_name=\'caffe.V1LayerParameter.pooling_param\', index=31,\n      number=19, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'power_param\', full_name=\'caffe.V1LayerParameter.power_param\', index=32,\n      number=21, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'relu_param\', full_name=\'caffe.V1LayerParameter.relu_param\', index=33,\n      number=30, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'sigmoid_param\', full_name=\'caffe.V1LayerParameter.sigmoid_param\', index=34,\n      number=38, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'softmax_param\', full_name=\'caffe.V1LayerParameter.softmax_param\', index=35,\n      number=39, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'slice_param\', full_name=\'caffe.V1LayerParameter.slice_param\', index=36,\n      number=31, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tanh_param\', full_name=\'caffe.V1LayerParameter.tanh_param\', index=37,\n      number=37, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'threshold_param\', full_name=\'caffe.V1LayerParameter.threshold_param\', index=38,\n      number=25, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'window_data_param\', full_name=\'caffe.V1LayerParameter.window_data_param\', index=39,\n      number=20, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'transform_param\', full_name=\'caffe.V1LayerParameter.transform_param\', index=40,\n      number=36, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'loss_param\', full_name=\'caffe.V1LayerParameter.loss_param\', index=41,\n      number=42, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'layer\', full_name=\'caffe.V1LayerParameter.layer\', index=42,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V1LAYERPARAMETER_LAYERTYPE,\n    _V1LAYERPARAMETER_DIMCHECKMODE,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=11760,\n  serialized_end=14288,\n)\n\n\n_V0LAYERPARAMETER = _descriptor.Descriptor(\n  name=\'V0LayerParameter\',\n  full_name=\'caffe.V0LayerParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'caffe.V0LayerParameter.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'caffe.V0LayerParameter.type\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'num_output\', full_name=\'caffe.V0LayerParameter.num_output\', index=2,\n      number=3, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'biasterm\', full_name=\'caffe.V0LayerParameter.biasterm\', index=3,\n      number=4, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=True,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_filler\', full_name=\'caffe.V0LayerParameter.weight_filler\', index=4,\n      number=5, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'bias_filler\', full_name=\'caffe.V0LayerParameter.bias_filler\', index=5,\n      number=6, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pad\', full_name=\'caffe.V0LayerParameter.pad\', index=6,\n      number=7, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'kernelsize\', full_name=\'caffe.V0LayerParameter.kernelsize\', index=7,\n      number=8, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'group\', full_name=\'caffe.V0LayerParameter.group\', index=8,\n      number=9, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'stride\', full_name=\'caffe.V0LayerParameter.stride\', index=9,\n      number=10, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'pool\', full_name=\'caffe.V0LayerParameter.pool\', index=10,\n      number=11, type=14, cpp_type=8, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'dropout_ratio\', full_name=\'caffe.V0LayerParameter.dropout_ratio\', index=11,\n      number=12, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'local_size\', full_name=\'caffe.V0LayerParameter.local_size\', index=12,\n      number=13, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=5,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'alpha\', full_name=\'caffe.V0LayerParameter.alpha\', index=13,\n      number=14, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'beta\', full_name=\'caffe.V0LayerParameter.beta\', index=14,\n      number=15, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.75),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'k\', full_name=\'caffe.V0LayerParameter.k\', index=15,\n      number=22, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'source\', full_name=\'caffe.V0LayerParameter.source\', index=16,\n      number=16, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'scale\', full_name=\'caffe.V0LayerParameter.scale\', index=17,\n      number=17, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(1),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'meanfile\', full_name=\'caffe.V0LayerParameter.meanfile\', index=18,\n      number=18, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'batchsize\', full_name=\'caffe.V0LayerParameter.batchsize\', index=19,\n      number=19, type=13, cpp_type=3, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'cropsize\', full_name=\'caffe.V0LayerParameter.cropsize\', index=20,\n      number=20, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'mirror\', full_name=\'caffe.V0LayerParameter.mirror\', index=21,\n      number=21, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs\', full_name=\'caffe.V0LayerParameter.blobs\', index=22,\n      number=50, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'blobs_lr\', full_name=\'caffe.V0LayerParameter.blobs_lr\', index=23,\n      number=51, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'weight_decay\', full_name=\'caffe.V0LayerParameter.weight_decay\', index=24,\n      number=52, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'rand_skip\', full_name=\'caffe.V0LayerParameter.rand_skip\', index=25,\n      number=53, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_threshold\', full_name=\'caffe.V0LayerParameter.det_fg_threshold\', index=26,\n      number=54, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_bg_threshold\', full_name=\'caffe.V0LayerParameter.det_bg_threshold\', index=27,\n      number=55, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.5),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_fg_fraction\', full_name=\'caffe.V0LayerParameter.det_fg_fraction\', index=28,\n      number=56, type=2, cpp_type=6, label=1,\n      has_default_value=True, default_value=float(0.25),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_context_pad\', full_name=\'caffe.V0LayerParameter.det_context_pad\', index=29,\n      number=58, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'det_crop_mode\', full_name=\'caffe.V0LayerParameter.det_crop_mode\', index=30,\n      number=59, type=9, cpp_type=9, label=1,\n      has_default_value=True, default_value=_b(""warp"").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_num\', full_name=\'caffe.V0LayerParameter.new_num\', index=31,\n      number=60, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_channels\', full_name=\'caffe.V0LayerParameter.new_channels\', index=32,\n      number=61, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_height\', full_name=\'caffe.V0LayerParameter.new_height\', index=33,\n      number=62, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'new_width\', full_name=\'caffe.V0LayerParameter.new_width\', index=34,\n      number=63, type=5, cpp_type=1, label=1,\n      has_default_value=True, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shuffle_images\', full_name=\'caffe.V0LayerParameter.shuffle_images\', index=35,\n      number=64, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'concat_dim\', full_name=\'caffe.V0LayerParameter.concat_dim\', index=36,\n      number=65, type=13, cpp_type=3, label=1,\n      has_default_value=True, default_value=1,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'hdf5_output_param\', full_name=\'caffe.V0LayerParameter.hdf5_output_param\', index=37,\n      number=1001, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n    _V0LAYERPARAMETER_POOLMETHOD,\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=14291,\n  serialized_end=15312,\n)\n\n\n_PRELUPARAMETER = _descriptor.Descriptor(\n  name=\'PReLUParameter\',\n  full_name=\'caffe.PReLUParameter\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'filler\', full_name=\'caffe.PReLUParameter.filler\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'channel_shared\', full_name=\'caffe.PReLUParameter.channel_shared\', index=1,\n      number=2, type=8, cpp_type=7, label=1,\n      has_default_value=True, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto2\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=15314,\n  serialized_end=15401,\n)\n\n_BLOBPROTO.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_BLOBPROTOVECTOR.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_FILLERPARAMETER.fields_by_name[\'variance_norm\'].enum_type = _FILLERPARAMETER_VARIANCENORM\n_FILLERPARAMETER_VARIANCENORM.containing_type = _FILLERPARAMETER\n_NETPARAMETER.fields_by_name[\'input_shape\'].message_type = _BLOBSHAPE\n_NETPARAMETER.fields_by_name[\'state\'].message_type = _NETSTATE\n_NETPARAMETER.fields_by_name[\'layer\'].message_type = _LAYERPARAMETER\n_NETPARAMETER.fields_by_name[\'layers\'].message_type = _V1LAYERPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'test_net_param\'].message_type = _NETPARAMETER\n_SOLVERPARAMETER.fields_by_name[\'train_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'test_state\'].message_type = _NETSTATE\n_SOLVERPARAMETER.fields_by_name[\'snapshot_format\'].enum_type = _SOLVERPARAMETER_SNAPSHOTFORMAT\n_SOLVERPARAMETER.fields_by_name[\'solver_mode\'].enum_type = _SOLVERPARAMETER_SOLVERMODE\n_SOLVERPARAMETER.fields_by_name[\'solver_type\'].enum_type = _SOLVERPARAMETER_SOLVERTYPE\n_SOLVERPARAMETER_SNAPSHOTFORMAT.containing_type = _SOLVERPARAMETER\n_SOLVERPARAMETER_SOLVERMODE.containing_type = _SOLVERPARAMETER\n_SOLVERPARAMETER_SOLVERTYPE.containing_type = _SOLVERPARAMETER\n_SOLVERSTATE.fields_by_name[\'history\'].message_type = _BLOBPROTO\n_NETSTATE.fields_by_name[\'phase\'].enum_type = _PHASE\n_NETSTATERULE.fields_by_name[\'phase\'].enum_type = _PHASE\n_PARAMSPEC.fields_by_name[\'share_mode\'].enum_type = _PARAMSPEC_DIMCHECKMODE\n_PARAMSPEC_DIMCHECKMODE.containing_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'phase\'].enum_type = _PHASE\n_LAYERPARAMETER.fields_by_name[\'param\'].message_type = _PARAMSPEC\n_LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'batch_norm_param\'].message_type = _BATCHNORMPARAMETER\n_LAYERPARAMETER.fields_by_name[\'bias_param\'].message_type = _BIASPARAMETER\n_LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'crop_param\'].message_type = _CROPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'elu_param\'].message_type = _ELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'embed_param\'].message_type = _EMBEDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'flatten_param\'].message_type = _FLATTENPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'input_param\'].message_type = _INPUTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'log_param\'].message_type = _LOGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_LAYERPARAMETER.fields_by_name[\'parameter_param\'].message_type = _PARAMETERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_LAYERPARAMETER.fields_by_name[\'prelu_param\'].message_type = _PRELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'python_param\'].message_type = _PYTHONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'recurrent_param\'].message_type = _RECURRENTPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reduction_param\'].message_type = _REDUCTIONPARAMETER\n_LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_LAYERPARAMETER.fields_by_name[\'reshape_param\'].message_type = _RESHAPEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'scale_param\'].message_type = _SCALEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_LAYERPARAMETER.fields_by_name[\'spp_param\'].message_type = _SPPPARAMETER\n_LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_LAYERPARAMETER.fields_by_name[\'tile_param\'].message_type = _TILEPARAMETER\n_LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_LOSSPARAMETER.fields_by_name[\'normalization\'].enum_type = _LOSSPARAMETER_NORMALIZATIONMODE\n_LOSSPARAMETER_NORMALIZATIONMODE.containing_type = _LOSSPARAMETER\n_BIASPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_CONVOLUTIONPARAMETER.fields_by_name[\'engine\'].enum_type = _CONVOLUTIONPARAMETER_ENGINE\n_CONVOLUTIONPARAMETER_ENGINE.containing_type = _CONVOLUTIONPARAMETER\n_DATAPARAMETER.fields_by_name[\'backend\'].enum_type = _DATAPARAMETER_DB\n_DATAPARAMETER_DB.containing_type = _DATAPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'data_filler\'].message_type = _FILLERPARAMETER\n_DUMMYDATAPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_ELTWISEPARAMETER.fields_by_name[\'operation\'].enum_type = _ELTWISEPARAMETER_ELTWISEOP\n_ELTWISEPARAMETER_ELTWISEOP.containing_type = _ELTWISEPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_EMBEDPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_HINGELOSSPARAMETER.fields_by_name[\'norm\'].enum_type = _HINGELOSSPARAMETER_NORM\n_HINGELOSSPARAMETER_NORM.containing_type = _HINGELOSSPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_INNERPRODUCTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_INPUTPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_LRNPARAMETER.fields_by_name[\'norm_region\'].enum_type = _LRNPARAMETER_NORMREGION\n_LRNPARAMETER.fields_by_name[\'engine\'].enum_type = _LRNPARAMETER_ENGINE\n_LRNPARAMETER_NORMREGION.containing_type = _LRNPARAMETER\n_LRNPARAMETER_ENGINE.containing_type = _LRNPARAMETER\n_PARAMETERPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_POOLINGPARAMETER.fields_by_name[\'pool\'].enum_type = _POOLINGPARAMETER_POOLMETHOD\n_POOLINGPARAMETER.fields_by_name[\'engine\'].enum_type = _POOLINGPARAMETER_ENGINE\n_POOLINGPARAMETER_POOLMETHOD.containing_type = _POOLINGPARAMETER\n_POOLINGPARAMETER_ENGINE.containing_type = _POOLINGPARAMETER\n_RECURRENTPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_RECURRENTPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_REDUCTIONPARAMETER.fields_by_name[\'operation\'].enum_type = _REDUCTIONPARAMETER_REDUCTIONOP\n_REDUCTIONPARAMETER_REDUCTIONOP.containing_type = _REDUCTIONPARAMETER\n_RELUPARAMETER.fields_by_name[\'engine\'].enum_type = _RELUPARAMETER_ENGINE\n_RELUPARAMETER_ENGINE.containing_type = _RELUPARAMETER\n_RESHAPEPARAMETER.fields_by_name[\'shape\'].message_type = _BLOBSHAPE\n_SCALEPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\n_SCALEPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_SIGMOIDPARAMETER.fields_by_name[\'engine\'].enum_type = _SIGMOIDPARAMETER_ENGINE\n_SIGMOIDPARAMETER_ENGINE.containing_type = _SIGMOIDPARAMETER\n_SOFTMAXPARAMETER.fields_by_name[\'engine\'].enum_type = _SOFTMAXPARAMETER_ENGINE\n_SOFTMAXPARAMETER_ENGINE.containing_type = _SOFTMAXPARAMETER\n_TANHPARAMETER.fields_by_name[\'engine\'].enum_type = _TANHPARAMETER_ENGINE\n_TANHPARAMETER_ENGINE.containing_type = _TANHPARAMETER\n_SPPPARAMETER.fields_by_name[\'pool\'].enum_type = _SPPPARAMETER_POOLMETHOD\n_SPPPARAMETER.fields_by_name[\'engine\'].enum_type = _SPPPARAMETER_ENGINE\n_SPPPARAMETER_POOLMETHOD.containing_type = _SPPPARAMETER\n_SPPPARAMETER_ENGINE.containing_type = _SPPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'include\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'exclude\'].message_type = _NETSTATERULE\n_V1LAYERPARAMETER.fields_by_name[\'type\'].enum_type = _V1LAYERPARAMETER_LAYERTYPE\n_V1LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V1LAYERPARAMETER.fields_by_name[\'blob_share_mode\'].enum_type = _V1LAYERPARAMETER_DIMCHECKMODE\n_V1LAYERPARAMETER.fields_by_name[\'accuracy_param\'].message_type = _ACCURACYPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'argmax_param\'].message_type = _ARGMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'concat_param\'].message_type = _CONCATPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'contrastive_loss_param\'].message_type = _CONTRASTIVELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'convolution_param\'].message_type = _CONVOLUTIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'data_param\'].message_type = _DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dropout_param\'].message_type = _DROPOUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'dummy_data_param\'].message_type = _DUMMYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'eltwise_param\'].message_type = _ELTWISEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'exp_param\'].message_type = _EXPPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_data_param\'].message_type = _HDF5DATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'hinge_loss_param\'].message_type = _HINGELOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'image_data_param\'].message_type = _IMAGEDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'infogain_loss_param\'].message_type = _INFOGAINLOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'inner_product_param\'].message_type = _INNERPRODUCTPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'lrn_param\'].message_type = _LRNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'memory_data_param\'].message_type = _MEMORYDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'mvn_param\'].message_type = _MVNPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'pooling_param\'].message_type = _POOLINGPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'power_param\'].message_type = _POWERPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'relu_param\'].message_type = _RELUPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'sigmoid_param\'].message_type = _SIGMOIDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'softmax_param\'].message_type = _SOFTMAXPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'slice_param\'].message_type = _SLICEPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'tanh_param\'].message_type = _TANHPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'threshold_param\'].message_type = _THRESHOLDPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'window_data_param\'].message_type = _WINDOWDATAPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'transform_param\'].message_type = _TRANSFORMATIONPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'loss_param\'].message_type = _LOSSPARAMETER\n_V1LAYERPARAMETER.fields_by_name[\'layer\'].message_type = _V0LAYERPARAMETER\n_V1LAYERPARAMETER_LAYERTYPE.containing_type = _V1LAYERPARAMETER\n_V1LAYERPARAMETER_DIMCHECKMODE.containing_type = _V1LAYERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'weight_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'bias_filler\'].message_type = _FILLERPARAMETER\n_V0LAYERPARAMETER.fields_by_name[\'pool\'].enum_type = _V0LAYERPARAMETER_POOLMETHOD\n_V0LAYERPARAMETER.fields_by_name[\'blobs\'].message_type = _BLOBPROTO\n_V0LAYERPARAMETER.fields_by_name[\'hdf5_output_param\'].message_type = _HDF5OUTPUTPARAMETER\n_V0LAYERPARAMETER_POOLMETHOD.containing_type = _V0LAYERPARAMETER\n_PRELUPARAMETER.fields_by_name[\'filler\'].message_type = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'BlobShape\'] = _BLOBSHAPE\nDESCRIPTOR.message_types_by_name[\'BlobProto\'] = _BLOBPROTO\nDESCRIPTOR.message_types_by_name[\'BlobProtoVector\'] = _BLOBPROTOVECTOR\nDESCRIPTOR.message_types_by_name[\'Datum\'] = _DATUM\nDESCRIPTOR.message_types_by_name[\'FillerParameter\'] = _FILLERPARAMETER\nDESCRIPTOR.message_types_by_name[\'NetParameter\'] = _NETPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverParameter\'] = _SOLVERPARAMETER\nDESCRIPTOR.message_types_by_name[\'SolverState\'] = _SOLVERSTATE\nDESCRIPTOR.message_types_by_name[\'NetState\'] = _NETSTATE\nDESCRIPTOR.message_types_by_name[\'NetStateRule\'] = _NETSTATERULE\nDESCRIPTOR.message_types_by_name[\'ParamSpec\'] = _PARAMSPEC\nDESCRIPTOR.message_types_by_name[\'LayerParameter\'] = _LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'TransformationParameter\'] = _TRANSFORMATIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'LossParameter\'] = _LOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'AccuracyParameter\'] = _ACCURACYPARAMETER\nDESCRIPTOR.message_types_by_name[\'ArgMaxParameter\'] = _ARGMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConcatParameter\'] = _CONCATPARAMETER\nDESCRIPTOR.message_types_by_name[\'BatchNormParameter\'] = _BATCHNORMPARAMETER\nDESCRIPTOR.message_types_by_name[\'BiasParameter\'] = _BIASPARAMETER\nDESCRIPTOR.message_types_by_name[\'ContrastiveLossParameter\'] = _CONTRASTIVELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ConvolutionParameter\'] = _CONVOLUTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'CropParameter\'] = _CROPPARAMETER\nDESCRIPTOR.message_types_by_name[\'DataParameter\'] = _DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'DropoutParameter\'] = _DROPOUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'DummyDataParameter\'] = _DUMMYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'EltwiseParameter\'] = _ELTWISEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ELUParameter\'] = _ELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'EmbedParameter\'] = _EMBEDPARAMETER\nDESCRIPTOR.message_types_by_name[\'ExpParameter\'] = _EXPPARAMETER\nDESCRIPTOR.message_types_by_name[\'FlattenParameter\'] = _FLATTENPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5DataParameter\'] = _HDF5DATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'HDF5OutputParameter\'] = _HDF5OUTPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'HingeLossParameter\'] = _HINGELOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'ImageDataParameter\'] = _IMAGEDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'InfogainLossParameter\'] = _INFOGAINLOSSPARAMETER\nDESCRIPTOR.message_types_by_name[\'InnerProductParameter\'] = _INNERPRODUCTPARAMETER\nDESCRIPTOR.message_types_by_name[\'InputParameter\'] = _INPUTPARAMETER\nDESCRIPTOR.message_types_by_name[\'LogParameter\'] = _LOGPARAMETER\nDESCRIPTOR.message_types_by_name[\'LRNParameter\'] = _LRNPARAMETER\nDESCRIPTOR.message_types_by_name[\'MemoryDataParameter\'] = _MEMORYDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'MVNParameter\'] = _MVNPARAMETER\nDESCRIPTOR.message_types_by_name[\'ParameterParameter\'] = _PARAMETERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PoolingParameter\'] = _POOLINGPARAMETER\nDESCRIPTOR.message_types_by_name[\'PowerParameter\'] = _POWERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PythonParameter\'] = _PYTHONPARAMETER\nDESCRIPTOR.message_types_by_name[\'RecurrentParameter\'] = _RECURRENTPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReductionParameter\'] = _REDUCTIONPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReLUParameter\'] = _RELUPARAMETER\nDESCRIPTOR.message_types_by_name[\'ReshapeParameter\'] = _RESHAPEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ScaleParameter\'] = _SCALEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SigmoidParameter\'] = _SIGMOIDPARAMETER\nDESCRIPTOR.message_types_by_name[\'SliceParameter\'] = _SLICEPARAMETER\nDESCRIPTOR.message_types_by_name[\'SoftmaxParameter\'] = _SOFTMAXPARAMETER\nDESCRIPTOR.message_types_by_name[\'TanHParameter\'] = _TANHPARAMETER\nDESCRIPTOR.message_types_by_name[\'TileParameter\'] = _TILEPARAMETER\nDESCRIPTOR.message_types_by_name[\'ThresholdParameter\'] = _THRESHOLDPARAMETER\nDESCRIPTOR.message_types_by_name[\'WindowDataParameter\'] = _WINDOWDATAPARAMETER\nDESCRIPTOR.message_types_by_name[\'SPPParameter\'] = _SPPPARAMETER\nDESCRIPTOR.message_types_by_name[\'V1LayerParameter\'] = _V1LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'V0LayerParameter\'] = _V0LAYERPARAMETER\nDESCRIPTOR.message_types_by_name[\'PReLUParameter\'] = _PRELUPARAMETER\nDESCRIPTOR.enum_types_by_name[\'Phase\'] = _PHASE\n\nBlobShape = _reflection.GeneratedProtocolMessageType(\'BlobShape\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBSHAPE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobShape)\n  ))\n_sym_db.RegisterMessage(BlobShape)\n\nBlobProto = _reflection.GeneratedProtocolMessageType(\'BlobProto\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBPROTO,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobProto)\n  ))\n_sym_db.RegisterMessage(BlobProto)\n\nBlobProtoVector = _reflection.GeneratedProtocolMessageType(\'BlobProtoVector\', (_message.Message,), dict(\n  DESCRIPTOR = _BLOBPROTOVECTOR,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BlobProtoVector)\n  ))\n_sym_db.RegisterMessage(BlobProtoVector)\n\nDatum = _reflection.GeneratedProtocolMessageType(\'Datum\', (_message.Message,), dict(\n  DESCRIPTOR = _DATUM,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.Datum)\n  ))\n_sym_db.RegisterMessage(Datum)\n\nFillerParameter = _reflection.GeneratedProtocolMessageType(\'FillerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _FILLERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.FillerParameter)\n  ))\n_sym_db.RegisterMessage(FillerParameter)\n\nNetParameter = _reflection.GeneratedProtocolMessageType(\'NetParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _NETPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetParameter)\n  ))\n_sym_db.RegisterMessage(NetParameter)\n\nSolverParameter = _reflection.GeneratedProtocolMessageType(\'SolverParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SOLVERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SolverParameter)\n  ))\n_sym_db.RegisterMessage(SolverParameter)\n\nSolverState = _reflection.GeneratedProtocolMessageType(\'SolverState\', (_message.Message,), dict(\n  DESCRIPTOR = _SOLVERSTATE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SolverState)\n  ))\n_sym_db.RegisterMessage(SolverState)\n\nNetState = _reflection.GeneratedProtocolMessageType(\'NetState\', (_message.Message,), dict(\n  DESCRIPTOR = _NETSTATE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetState)\n  ))\n_sym_db.RegisterMessage(NetState)\n\nNetStateRule = _reflection.GeneratedProtocolMessageType(\'NetStateRule\', (_message.Message,), dict(\n  DESCRIPTOR = _NETSTATERULE,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.NetStateRule)\n  ))\n_sym_db.RegisterMessage(NetStateRule)\n\nParamSpec = _reflection.GeneratedProtocolMessageType(\'ParamSpec\', (_message.Message,), dict(\n  DESCRIPTOR = _PARAMSPEC,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ParamSpec)\n  ))\n_sym_db.RegisterMessage(ParamSpec)\n\nLayerParameter = _reflection.GeneratedProtocolMessageType(\'LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LayerParameter)\n  ))\n_sym_db.RegisterMessage(LayerParameter)\n\nTransformationParameter = _reflection.GeneratedProtocolMessageType(\'TransformationParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TRANSFORMATIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TransformationParameter)\n  ))\n_sym_db.RegisterMessage(TransformationParameter)\n\nLossParameter = _reflection.GeneratedProtocolMessageType(\'LossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LossParameter)\n  ))\n_sym_db.RegisterMessage(LossParameter)\n\nAccuracyParameter = _reflection.GeneratedProtocolMessageType(\'AccuracyParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ACCURACYPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.AccuracyParameter)\n  ))\n_sym_db.RegisterMessage(AccuracyParameter)\n\nArgMaxParameter = _reflection.GeneratedProtocolMessageType(\'ArgMaxParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ARGMAXPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ArgMaxParameter)\n  ))\n_sym_db.RegisterMessage(ArgMaxParameter)\n\nConcatParameter = _reflection.GeneratedProtocolMessageType(\'ConcatParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONCATPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ConcatParameter)\n  ))\n_sym_db.RegisterMessage(ConcatParameter)\n\nBatchNormParameter = _reflection.GeneratedProtocolMessageType(\'BatchNormParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BATCHNORMPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BatchNormParameter)\n  ))\n_sym_db.RegisterMessage(BatchNormParameter)\n\nBiasParameter = _reflection.GeneratedProtocolMessageType(\'BiasParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _BIASPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.BiasParameter)\n  ))\n_sym_db.RegisterMessage(BiasParameter)\n\nContrastiveLossParameter = _reflection.GeneratedProtocolMessageType(\'ContrastiveLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONTRASTIVELOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ContrastiveLossParameter)\n  ))\n_sym_db.RegisterMessage(ContrastiveLossParameter)\n\nConvolutionParameter = _reflection.GeneratedProtocolMessageType(\'ConvolutionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CONVOLUTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ConvolutionParameter)\n  ))\n_sym_db.RegisterMessage(ConvolutionParameter)\n\nCropParameter = _reflection.GeneratedProtocolMessageType(\'CropParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _CROPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.CropParameter)\n  ))\n_sym_db.RegisterMessage(CropParameter)\n\nDataParameter = _reflection.GeneratedProtocolMessageType(\'DataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DataParameter)\n  ))\n_sym_db.RegisterMessage(DataParameter)\n\nDropoutParameter = _reflection.GeneratedProtocolMessageType(\'DropoutParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DROPOUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DropoutParameter)\n  ))\n_sym_db.RegisterMessage(DropoutParameter)\n\nDummyDataParameter = _reflection.GeneratedProtocolMessageType(\'DummyDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _DUMMYDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.DummyDataParameter)\n  ))\n_sym_db.RegisterMessage(DummyDataParameter)\n\nEltwiseParameter = _reflection.GeneratedProtocolMessageType(\'EltwiseParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ELTWISEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.EltwiseParameter)\n  ))\n_sym_db.RegisterMessage(EltwiseParameter)\n\nELUParameter = _reflection.GeneratedProtocolMessageType(\'ELUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _ELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ELUParameter)\n  ))\n_sym_db.RegisterMessage(ELUParameter)\n\nEmbedParameter = _reflection.GeneratedProtocolMessageType(\'EmbedParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _EMBEDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.EmbedParameter)\n  ))\n_sym_db.RegisterMessage(EmbedParameter)\n\nExpParameter = _reflection.GeneratedProtocolMessageType(\'ExpParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _EXPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ExpParameter)\n  ))\n_sym_db.RegisterMessage(ExpParameter)\n\nFlattenParameter = _reflection.GeneratedProtocolMessageType(\'FlattenParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _FLATTENPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.FlattenParameter)\n  ))\n_sym_db.RegisterMessage(FlattenParameter)\n\nHDF5DataParameter = _reflection.GeneratedProtocolMessageType(\'HDF5DataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HDF5DATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HDF5DataParameter)\n  ))\n_sym_db.RegisterMessage(HDF5DataParameter)\n\nHDF5OutputParameter = _reflection.GeneratedProtocolMessageType(\'HDF5OutputParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HDF5OUTPUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HDF5OutputParameter)\n  ))\n_sym_db.RegisterMessage(HDF5OutputParameter)\n\nHingeLossParameter = _reflection.GeneratedProtocolMessageType(\'HingeLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _HINGELOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.HingeLossParameter)\n  ))\n_sym_db.RegisterMessage(HingeLossParameter)\n\nImageDataParameter = _reflection.GeneratedProtocolMessageType(\'ImageDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _IMAGEDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ImageDataParameter)\n  ))\n_sym_db.RegisterMessage(ImageDataParameter)\n\nInfogainLossParameter = _reflection.GeneratedProtocolMessageType(\'InfogainLossParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INFOGAINLOSSPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InfogainLossParameter)\n  ))\n_sym_db.RegisterMessage(InfogainLossParameter)\n\nInnerProductParameter = _reflection.GeneratedProtocolMessageType(\'InnerProductParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INNERPRODUCTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InnerProductParameter)\n  ))\n_sym_db.RegisterMessage(InnerProductParameter)\n\nInputParameter = _reflection.GeneratedProtocolMessageType(\'InputParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _INPUTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.InputParameter)\n  ))\n_sym_db.RegisterMessage(InputParameter)\n\nLogParameter = _reflection.GeneratedProtocolMessageType(\'LogParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LOGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LogParameter)\n  ))\n_sym_db.RegisterMessage(LogParameter)\n\nLRNParameter = _reflection.GeneratedProtocolMessageType(\'LRNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _LRNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.LRNParameter)\n  ))\n_sym_db.RegisterMessage(LRNParameter)\n\nMemoryDataParameter = _reflection.GeneratedProtocolMessageType(\'MemoryDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MEMORYDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MemoryDataParameter)\n  ))\n_sym_db.RegisterMessage(MemoryDataParameter)\n\nMVNParameter = _reflection.GeneratedProtocolMessageType(\'MVNParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _MVNPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.MVNParameter)\n  ))\n_sym_db.RegisterMessage(MVNParameter)\n\nParameterParameter = _reflection.GeneratedProtocolMessageType(\'ParameterParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PARAMETERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ParameterParameter)\n  ))\n_sym_db.RegisterMessage(ParameterParameter)\n\nPoolingParameter = _reflection.GeneratedProtocolMessageType(\'PoolingParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _POOLINGPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PoolingParameter)\n  ))\n_sym_db.RegisterMessage(PoolingParameter)\n\nPowerParameter = _reflection.GeneratedProtocolMessageType(\'PowerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _POWERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PowerParameter)\n  ))\n_sym_db.RegisterMessage(PowerParameter)\n\nPythonParameter = _reflection.GeneratedProtocolMessageType(\'PythonParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PYTHONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PythonParameter)\n  ))\n_sym_db.RegisterMessage(PythonParameter)\n\nRecurrentParameter = _reflection.GeneratedProtocolMessageType(\'RecurrentParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RECURRENTPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.RecurrentParameter)\n  ))\n_sym_db.RegisterMessage(RecurrentParameter)\n\nReductionParameter = _reflection.GeneratedProtocolMessageType(\'ReductionParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _REDUCTIONPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReductionParameter)\n  ))\n_sym_db.RegisterMessage(ReductionParameter)\n\nReLUParameter = _reflection.GeneratedProtocolMessageType(\'ReLUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReLUParameter)\n  ))\n_sym_db.RegisterMessage(ReLUParameter)\n\nReshapeParameter = _reflection.GeneratedProtocolMessageType(\'ReshapeParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _RESHAPEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ReshapeParameter)\n  ))\n_sym_db.RegisterMessage(ReshapeParameter)\n\nScaleParameter = _reflection.GeneratedProtocolMessageType(\'ScaleParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SCALEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ScaleParameter)\n  ))\n_sym_db.RegisterMessage(ScaleParameter)\n\nSigmoidParameter = _reflection.GeneratedProtocolMessageType(\'SigmoidParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SIGMOIDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SigmoidParameter)\n  ))\n_sym_db.RegisterMessage(SigmoidParameter)\n\nSliceParameter = _reflection.GeneratedProtocolMessageType(\'SliceParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SLICEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SliceParameter)\n  ))\n_sym_db.RegisterMessage(SliceParameter)\n\nSoftmaxParameter = _reflection.GeneratedProtocolMessageType(\'SoftmaxParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SOFTMAXPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SoftmaxParameter)\n  ))\n_sym_db.RegisterMessage(SoftmaxParameter)\n\nTanHParameter = _reflection.GeneratedProtocolMessageType(\'TanHParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TANHPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TanHParameter)\n  ))\n_sym_db.RegisterMessage(TanHParameter)\n\nTileParameter = _reflection.GeneratedProtocolMessageType(\'TileParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _TILEPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.TileParameter)\n  ))\n_sym_db.RegisterMessage(TileParameter)\n\nThresholdParameter = _reflection.GeneratedProtocolMessageType(\'ThresholdParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _THRESHOLDPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.ThresholdParameter)\n  ))\n_sym_db.RegisterMessage(ThresholdParameter)\n\nWindowDataParameter = _reflection.GeneratedProtocolMessageType(\'WindowDataParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _WINDOWDATAPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.WindowDataParameter)\n  ))\n_sym_db.RegisterMessage(WindowDataParameter)\n\nSPPParameter = _reflection.GeneratedProtocolMessageType(\'SPPParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _SPPPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.SPPParameter)\n  ))\n_sym_db.RegisterMessage(SPPParameter)\n\nV1LayerParameter = _reflection.GeneratedProtocolMessageType(\'V1LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _V1LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.V1LayerParameter)\n  ))\n_sym_db.RegisterMessage(V1LayerParameter)\n\nV0LayerParameter = _reflection.GeneratedProtocolMessageType(\'V0LayerParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _V0LAYERPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.V0LayerParameter)\n  ))\n_sym_db.RegisterMessage(V0LayerParameter)\n\nPReLUParameter = _reflection.GeneratedProtocolMessageType(\'PReLUParameter\', (_message.Message,), dict(\n  DESCRIPTOR = _PRELUPARAMETER,\n  __module__ = \'caffe_pb2\'\n  # @@protoc_insertion_point(class_scope:caffe.PReLUParameter)\n  ))\n_sym_db.RegisterMessage(PReLUParameter)\n\n\n_BLOBSHAPE.fields_by_name[\'dim\'].has_options = True\n_BLOBSHAPE.fields_by_name[\'dim\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_BLOBPROTO.fields_by_name[\'data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_BLOBPROTO.fields_by_name[\'diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_BLOBPROTO.fields_by_name[\'double_data\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_data\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_BLOBPROTO.fields_by_name[\'double_diff\'].has_options = True\n_BLOBPROTO.fields_by_name[\'double_diff\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n# @@protoc_insertion_point(module_scope)\n'"
mmdnn/conversion/caffe/common_graph.py,0,"b""#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport six\nfrom six import string_types as _string_types\nfrom mmdnn.conversion.caffe.errors import ConversionError\nfrom mmdnn.conversion.common.IR.graph_pb2 import GraphDef, NodeDef, TensorShape\nfrom mmdnn.conversion.caffe.utils import get_real_name\n\n\ndef assign_attr_value(attr, val):\n    '''Assign value to AttrValue proto according to data type.'''\n    if isinstance(val, bool):\n        attr.b = val\n    elif isinstance(val, six.integer_types):\n        attr.i = val\n    elif isinstance(val, float):\n        attr.f = val\n    elif isinstance(val, str):\n        attr.s = val.encode('utf-8')\n    elif isinstance(val, TensorShape):\n        attr.shape.MergeFromString(val.SerializeToString())\n    elif isinstance(val, list):\n        if len(val) == 0: return\n\n        if isinstance(val[0], six.integer_types):\n            attr.list.i.extend(val)\n        elif isinstance(val[0], TensorShape):\n            attr.list.shape.extend(val)\n        else:\n            raise NotImplementedError('AttrValue cannot be of %s %s' % (type(val), type(val[0])))\n    else:\n        raise NotImplementedError('AttrValue cannot be of %s' % type(val))\n\n\ndef fetch_attr_value(attr):\n    '''Fetch valid value from AttrValue proto.'''\n    field = attr.WhichOneof('value')\n    val = getattr(attr, field) if field else None\n    return val.decode('utf-8') if isinstance(val, bytes) else val\n\n\nclass Node(object):\n    '''An intermediate representation for DL operations.'''\n\n    def __init__(self, node_pb2):\n        assert isinstance(node_pb2, NodeDef)\n        self.node_pb2 = node_pb2\n        self.output = []\n\n    @staticmethod\n    def create(op, **kwargs):\n        node_pb2 = NodeDef()\n        node_pb2.op = op\n        for k, v in kwargs.items():\n            assign_attr_value(node_pb2.attr[k], v)\n        return Node(node_pb2)\n\n    @property\n    def op(self):\n        return self.node_pb2.op\n\n    @property\n    def name(self):\n        return self.node_pb2.name\n\n    @name.setter\n    def name(self, value):\n        assert isinstance(value, _string_types)\n        self.node_pb2.name = value\n\n    @property\n    def input(self):\n        return self.node_pb2.input\n\n    @property\n    def attr(self):\n        return self.node_pb2.attr.items()\n\n\nclass Graph(object):\n    '''An intermediate representation for DL graph.'''\n\n    def __init__(self, name, node_list, version=0):\n        if node_list and len(node_list):\n            assert isinstance(node_list[0], Node)\n            self.node_dict = {node.name: node for node in node_list}\n        else:\n            self.node_dict = {}\n        self.name = name\n        self.version = version\n\n    def topologically_sorted(self):\n        visited = set()\n        sorted_nodes = []\n        def topo_sort_dfs(node, visited, sorted_nodes):\n            if node in visited:\n                return\n            visited.add(node)\n            for n in self.get_input(node):\n                topo_sort_dfs(n, visited, sorted_nodes)\n            sorted_nodes.append(node)\n        for node in self.node_dict.values():\n            topo_sort_dfs(node, visited, sorted_nodes)\n        return sorted_nodes\n\n    def get_node(self, name):\n        return self.node_dict[name]\n\n    def add_node(self, node):\n        assert node.name not in self.node_dict\n        self.node_dict[node.name] = node\n\n    def remove_node(self, name):\n        return self.node_dict.pop(name)\n\n    def get_input(self, node):\n        input_nodes = []\n        for name in node.input:\n            name = get_real_name(name)\n            if name in self.node_dict:\n                input_nodes.append(self.get_node(name))\n        return input_nodes\n\n    def as_graph_def(self):\n        graph_pb2 = GraphDef()\n        graph_pb2.version = self.version\n        graph_pb2.node.extend([node.node_pb2 for node in self.node_dict.values()])\n        return graph_pb2"""
mmdnn/conversion/caffe/errors.py,0,"b""import sys\n\n\nclass ConversionError(Exception):\n    '''\n    an abtract class\n    '''\n    pass\n\n\ndef print_stderr(msg):\n    '''\n    a function to print information to the std\n    '''\n    sys.stderr.write('%s\\n' % msg)\n"""
mmdnn/conversion/caffe/graph.py,0,"b'from collections import namedtuple\nfrom functools import reduce\nfrom google.protobuf import text_format\nfrom copy import deepcopy\nimport numbers\nimport os\nimport tempfile\n\nfrom mmdnn.conversion.caffe.mapper import get_handler_name\nfrom mmdnn.conversion.caffe.resolver import get_caffe_resolver, has_pycaffe\nfrom mmdnn.conversion.caffe.shape import *\nfrom mmdnn.conversion.caffe.errors import print_stderr, ConversionError\n\n\nlayer_num_to_name = {\n    0: \'None\',\n    1: \'Accuracy\',\n    2: \'BNLL\',\n    3: \'Concat\',\n    4: \'Convolution\',\n    5: \'Data\',\n    6: \'Dropout\',\n    7: \'EuclideanLoss\',\n    8: \'Flatten\',\n    9: \'HDF5Data\',\n    10: \'HDF5Output\',\n    11: \'Im2col\',\n    12: \'ImageData\',\n    13: \'InfogainLoss\',\n    14: \'InnerProduct\',\n    15: \'LRN\',\n    16: \'MultinomialLogisticLoss\',\n    17: \'Pooling\',\n    18: \'ReLU\',\n    19: \'Sigmoid\',\n    20: \'Softmax\',\n    21: \'SoftmaxWithLoss\',\n    22: \'Split\',\n    23: \'TanH\',\n    24: \'WindowData\',\n    25: \'Eltwise\',\n    26: \'Power\',\n    27: \'SigmoidCrossEntropyLoss\',\n    28: \'HingeLoss\',\n    29: \'MemoryData\',\n    30: \'ArgMax\',\n    31: \'Threshold\',\n    32: \'DummyData\',\n    33: \'Slice\',\n    34: \'MVN\',\n    35: \'AbsVal\',\n    36: \'Silence\',\n    37: \'ContrastiveLoss\',\n    38: \'Exp\',\n    39: \'Deconvolution\',\n    40: \'PReLU\',\n    41: \'ELU\',\n    }\n\nLAYER_DESCRIPTORS = {\n    # Caffe Types\n    \'AbsVal\': shape_identity,\n    \'Accuracy\': shape_scalar,\n    \'ArgMax\': shape_not_implemented,\n    \'BatchNorm\': shape_identity,\n    \'BNLL\': shape_not_implemented,\n    \'Concat\': shape_concat,\n    \'ContrastiveLoss\': shape_scalar,\n    \'Convolution\': shape_convolution,\n    \'Crop\': shape_not_implemented,\n    \'Deconvolution\': shape_deconvolution,\n    \'Data\': shape_data,\n    \'Dropout\': shape_identity,\n    \'DummyData\': shape_data,\n    \'EuclideanLoss\': shape_scalar,\n    \'Eltwise\': shape_identity,\n    \'Exp\': shape_identity,\n    \'Flatten\': shape_flatten,\n    \'HDF5Data\': shape_data,\n    \'HDF5Output\': shape_identity,\n    \'HingeLoss\': shape_scalar,\n    \'Im2col\': shape_not_implemented,\n    \'ImageData\': shape_data,\n    \'InfogainLoss\': shape_scalar,\n    \'InnerProduct\': shape_inner_product,\n    \'Input\': shape_data,\n    \'LRN\': shape_identity,\n    \'MemoryData\': shape_mem_data,\n    \'MultinomialLogisticLoss\': shape_scalar,\n    \'MVN\': shape_not_implemented,\n    \'Pooling\': shape_pool,\n    \'Unpooling\': shape_unpool,\n    \'Power\': shape_identity,\n    \'ReLU\': shape_identity,\n    \'Scale\': shape_identity,\n    \'Sigmoid\': shape_identity,\n    \'SigmoidCrossEntropyLoss\': shape_scalar,\n    \'Silence\': shape_identity,\n    \'Softmax\': shape_identity,\n    \'SoftmaxWithLoss\': shape_scalar,\n    \'Split\': shape_split,\n    \'Slice\': shape_not_implemented,\n    \'TanH\': shape_identity,\n    \'WindowData\': shape_not_implemented,\n    \'Threshold\': shape_identity,\n    \'Reshape\' : shape_reshape,\n    \'ResizeBilinear\': shape_reshape,\n    \'PReLU\'   : shape_identity,\n    \'ELU\' : shape_identity,\n    }\n\nLAYER_TYPES = LAYER_DESCRIPTORS.keys()\n\nLayerType = type(\'LayerType\', (), {t : t for t in LAYER_TYPES})\n\nKernelParameters = namedtuple(\'KernelParameters\', [\'global_pooling\', \'k_h\', \'k_w\', \'s_h\', \'s_w\', \'p_h\', \'p_w\'])\n\nclass NodeKind(LayerType):\n\n    @staticmethod\n    def map_raw_kind(node_kind):\n        if isinstance(node_kind, int):\n            node_kind = layer_num_to_name[node_kind]\n        else:\n            node_kind = str(node_kind)\n        if node_kind in LAYER_TYPES:\n            return node_kind\n        return None\n\n    @staticmethod\n    def compute_output_shape(node):\n        try:\n            return LAYER_DESCRIPTORS[node.kind](node)\n        except NotImplementedError:\n            raise ConversionError(\'Output shape computation not implemented for type: %s\' % node.kind)\n\nLAYER_IN_TRAIN_PROTO = [NodeKind.ImageData, NodeKind.Data, NodeKind.HDF5Data, NodeKind.HDF5Output, NodeKind.WindowData, NodeKind.DummyData, NodeKind.MemoryData]\n\nclass CaffeNode(object):\n    def __init__(self, name, kind, layer=None):\n        self.name = name\n        self.kind = kind\n        self.layer = layer\n        self.parents = []\n        self.children = []\n        self.data = None\n        self.output = []\n        self.output_shape = None\n        self.metadata = {}\n\n    def add_parent(self, parent_node, from_output, index=None):\n        assert parent_node not in self.parents\n        index = len(self.parents) if index is None else index\n        self.parents.insert(index, (parent_node, from_output))\n        if self not in parent_node.children:\n            parent_node.children.append(self)\n\n    def get_only_parent(self):\n        if len(self.parents) != 1:\n            raise ConversionError(\'Node (%s) expected to have 1 parent. Found %s.\' % (self, len(self.parents)))\n        return self.parents[0]\n\n    @property\n    def parameters(self):\n        if self.layer is not None:\n            params = get_handler_name(self.kind)\n            if params == \'deconvolution\':\n                params = \'convolution\'\n            params = \'_\'.join((params, \'param\'))\n            try:\n                return getattr(self.layer, params)\n            except AttributeError:\n                raise ConversionError(\'Caffe parameters not found for layer kind: %s\' % (self.kind))\n        return None\n\n    @staticmethod\n    def get_kernel_value(scalar, repeated, idx, default=None):\n        if scalar:\n            return scalar\n        if repeated:\n            if isinstance(repeated, numbers.Number):\n                return repeated\n            if len(repeated) == 1:\n                # Same value applies to all spatial dimensions\n                return int(repeated[0])\n            assert idx < len(repeated)\n            # Extract the value for the given spatial dimension\n            return repeated[idx]\n        if default is None:\n            raise ValueError(\'Unable to determine kernel parameter!\')\n        return default\n\n    @property\n    def kernel_parameters(self):\n        assert self.kind in (NodeKind.Convolution, NodeKind.Pooling, NodeKind.Unpooling, NodeKind.Deconvolution)\n        params = self.parameters\n        global_pooling = hasattr(params, \'global_pooling\') and params.global_pooling\n        if not global_pooling:\n            k_h = self.get_kernel_value(params.kernel_h, params.kernel_size, 0)\n            k_w = self.get_kernel_value(params.kernel_w, params.kernel_size, 1)\n            s_h = self.get_kernel_value(params.stride_h, params.stride, 0, default=1)\n            s_w = self.get_kernel_value(params.stride_w, params.stride, 1, default=1)\n        else:\n            k_h = k_w = 0\n            s_h = s_w = 1\n        p_h = self.get_kernel_value(params.pad_h, params.pad, 0, default=0)\n        p_w = self.get_kernel_value(params.pad_w, params.pad, 1, default=0)\n        return KernelParameters(global_pooling, k_h, k_w, s_h, s_w, p_h, p_w)\n\n    def __str__(self):\n        return \'[%s] %s\' % (self.kind, self.name)\n\n    def __repr__(self):\n        return \'%s (0x%x)\' %(self.name, id(self))\n\n\nclass CaffeGraph(object):\n\n    def __init__(self, nodes=None, name=None):\n        self.nodes = nodes or []\n        self.node_lut = {node.name: node for node in self.nodes}\n        self.name = name\n        self.prototxt = None\n\n    def add_node(self, node):\n        self.nodes.append(node)\n        self.node_lut[node.name] = node\n\n    def get_node(self, name):\n        try:\n            return self.node_lut[name]\n        except KeyError:\n            raise ConversionError(\'Layer not found: %s\' % name)\n\n    def get_input_nodes(self):\n        return [node for node in self.nodes if len(node.parents) == 0]\n\n    def get_output_nodes(self):\n        return [node for node in self.nodes if len(node.children) == 0]\n\n    def topologically_sorted(self):\n        visited = set()\n        sorted_nodes = []\n        def topo_sort_dfs(node, visited, sorted_nodes):\n            if node in visited:\n                return\n            visited.add(node)\n            for n, idx in node.parents:\n                topo_sort_dfs(n, visited, sorted_nodes)\n            sorted_nodes.append(node)\n        for node in self.nodes:\n            topo_sort_dfs(node, visited, sorted_nodes)\n        return sorted_nodes\n\n    def compute_output_shapes(self, model):\n        sorted_nodes = self.topologically_sorted()\n        (tmp_handle, tmp_prototxt) = tempfile.mkstemp(suffix="".prototxt"")\n        with open(tmp_prototxt, \'w\') as f:\n            f.write(text_format.MessageToString(model))\n        self.prototxt = tmp_prototxt\n        if has_pycaffe():\n            caffe = get_caffe_resolver().caffe\n            net = caffe.Net(tmp_prototxt, caffe.TEST)\n            for key, value in net.blobs.items():\n                try:\n                    node = self.get_node(key)\n                    dims = list(value.shape)\n                    dims = dims + [1] * (4 - len(dims))\n                    node.output_shape = TensorShape(*dims)\n                except:\n                    continue\n            for node in sorted_nodes:\n                if node.output_shape is None:\n                    node.output_shape = TensorShape(*NodeKind.compute_output_shape(node))\n            os.close(tmp_handle)\n        else:\n            for node in sorted_nodes:\n                node.output_shape = TensorShape(*NodeKind.compute_output_shape(node))\n\n    # consider rewrite this function to Network.py\n    def replaced(self, new_nodes):\n        return CaffeGraph(nodes=new_nodes, name=self.name)\n\n    def transformed(self, transformers):\n        graph = self\n        for transformer in transformers:\n            graph = transformer(graph)\n            if graph is None:\n                raise ConversionError(\'Transformer failed: {}\'.format(transformer))\n            assert isinstance(graph, CaffeGraph)\n        return graph\n\n    def __contains__(self, key):\n        return key in self.node_lut\n\n    def __str__(self):\n        def get_max_shape(data):\n            if isinstance(data, dict):\n                max = 0\n                val = None\n                for k, v in data.items():\n                    tmp = reduce(lambda x, y: x*y, v.shape)\n                    if  tmp > max:\n                        val = v.shape\n                        max = tmp\n                return val\n            else:\n                return data[0].shape\n        hdr = \'{:<20} {:<30} {:>20} {:>20}\'.format(\'Type\', \'Name\', \'Param\', \'Output\')\n        s = [hdr, \'-\' * 94]\n        for node in self.topologically_sorted():\n            data_shape = get_max_shape(node.data) if node.data else \'--\'\n            out_shape = node.output_shape or \'--\'\n            s.append(\'{:<20} {:<30} {!s:>20} {!s:>20}\'.format(node.kind, node.name, data_shape, tuple(out_shape)))\n        return \'\\n\'.join(s)\n\n\nclass GraphBuilder(object):\n    def __init__(self, model_path, input_shape=None, is_train_proto=False, phase=\'test\'):\n        self.model_path = model_path\n        self.phase = phase\n        self.is_train_proto = is_train_proto\n        self.input_shape = input_shape\n        self.load()\n\n    def load(self):\n        self.model = get_caffe_resolver().NetParameter()\n        with open(self.model_path, \'r\') as f:\n            text_format.Merge(f.read(), self.model)\n        if self.is_train_proto:\n            self.process_train_proto()\n\n    def process_train_proto(self):\n        layers = self.model.layer or self.model.layers\n        delete_layer = set()\n        split_op_map = dict()\n        loss_layers = [layer for layer in layers if NodeKind.map_raw_kind(layer.type) in (NodeKind.SoftmaxWithLoss, NodeKind.SigmoidCrossEntropyLoss)]\n        a = [layers.remove(layer) for layer in layers[:] if layer in loss_layers[:-1] or NodeKind.map_raw_kind(layer.type) in LAYER_IN_TRAIN_PROTO]\n        for layer in layers[:]:\n            if \'label\' in layer.bottom:\n                if NodeKind.map_raw_kind(layer.type) in (NodeKind.SoftmaxWithLoss, NodeKind.SigmoidCrossEntropyLoss):\n                    continue\n                elif NodeKind.map_raw_kind(layer.type) == NodeKind.Split:\n                    for item in layer.top:\n                        delete_layer.add(item)\n                layers.remove(layer)\n            elif NodeKind.map_raw_kind(layer.type) == NodeKind.Split:\n                for item in layer.top:\n                    split_op_map[item] = layer.bottom[0]\n                layers.remove(layer)\n\n        for layer in layers[:]:\n            for item in delete_layer:\n                if item in layer.bottom:\n                    layers.remove(layer)\n                    break\n            for key, value in split_op_map.items():\n                if key in layer.bottom:\n                    layer.bottom.remove(key)\n                    layer.bottom.append(value)\n        self.model.input.append(\'data\')\n        self.model.input_dim.extend(self.input_shape)\n        last_layer = layers[-1]\n        kind = NodeKind.map_raw_kind(last_layer.type)\n        if kind in (NodeKind.SoftmaxWithLoss, NodeKind.SigmoidCrossEntropyLoss):\n            pred = layers.add()\n            pred.name = \'prob\'\n            pred.top.append(\'prob\')\n            pred.bottom.append(last_layer.bottom[0])\n            if kind == NodeKind.SoftmaxWithLoss:\n                pred.type = NodeKind.Softmax if self.model.layer else 20 # competiable with old version caffe proto\n            elif kind == NodeKind.SigmoidCrossEntropyLoss:\n                pred.type = NodeKind.Sigmoid if self.model.layer else 19\n        layers.remove(last_layer)\n\n    def filter_layers(self, layers):\n        phase_map = {0: \'train\', 1: \'test\'}\n        filtered_layer_names = set()\n        filtered_layers = []\n        for layer in layers:\n            phase = self.phase\n            if len(layer.include):\n                phase = phase_map[layer.include[0].phase]\n            if len(layer.exclude):\n                phase = phase_map[1 - layer.include[0].phase]\n            exclude = (phase != self.phase)\n            # Dropout layers appear in a fair number of Caffe\n            # test-time networks. These are just ignored. We\'ll\n            # filter them out here.\n            if (not exclude) and (phase == \'test\'):\n                exclude = (layer.type == LayerType.Dropout)\n            if (not exclude):\n                exclude = (layer.type == LayerType.Silence)\n            if not exclude:\n                if layer.name in filtered_layer_names:\n                    for i in range(1, len(filtered_layer_names)):\n                        new_name = layer.name + \'_%s\' % i\n                        if new_name not in filtered_layer_names:\n                            layer.name = new_name\n                            break\n                filtered_layer_names.add(layer.name)\n                filtered_layers.append(layer)\n        return filtered_layers\n\n    def make_node(self, layer):\n        kind = NodeKind.map_raw_kind(layer.type)\n        if kind is None:\n            # TODO: raise error\n            pass\n        node = CaffeNode(layer.name, kind, layer=layer)\n        node.output.append(layer.name.replace(\'/\', \'_\'))\n        node.output.extend(layer.top[1:])\n        return node\n\n    def make_input_node(self):\n        nodes = [CaffeNode(name, NodeKind.Data) for name in self.model.input]\n        if len(nodes):\n            input_dim = list(map(int, self.model.input_dim))\n            if not input_dim:\n                if len(self.model.input_shape) > 0:\n                    input_dim = list(map(int, self.model.input_shape[0].dim))\n                else:\n                    # TODO: raise error\n                    pass\n            for node in nodes:\n                node.output_shape = tuple(input_dim)\n                node.output.append(\'data\')\n        return nodes\n\n    def build(self):\n        layers = self.model.layers or self.model.layer\n        layers = self.filter_layers(layers)\n        nodes = self.make_input_node()\n        nodes += [self.make_node(layer) for layer in layers]\n        graph = CaffeGraph(nodes=nodes, name=self.model.name)\n        node_outputs = {}\n        for idx, layer in enumerate(layers):\n            node = graph.get_node(layer.name)\n            for input_name in layer.bottom:\n                assert input_name != layer.name\n                parent_node = node_outputs.get(input_name)\n                if (parent_node is None) or (parent_node==node):\n                    parent_node = graph.get_node(input_name)\n                if parent_node.layer:\n                    for i, output in enumerate(parent_node.layer.top):\n                        if input_name == output:\n                            node.add_parent(parent_node, i)\n                else:\n                    node.add_parent(parent_node, 0)\n            for output_name in layer.top:\n                if output_name == layer.name:\n                    continue\n                node_outputs[output_name] = node\n        graph.compute_output_shapes(self.model)\n        return graph\n'"
mmdnn/conversion/caffe/mapper.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nimport numpy as np\n\nfrom mmdnn.conversion.caffe.errors import ConversionError\nfrom mmdnn.conversion.caffe.common_graph import Node\nfrom mmdnn.conversion.caffe.network import DEFAULT_PADDING\nfrom mmdnn.conversion.caffe.utils import get_lower_case\nfrom mmdnn.conversion.common.IR.graph_pb2 import TensorShape\n\n\ndef get_handler_name(node_kind):\n    if node_kind is None:\n        return node_kind\n    else:\n        if len(node_kind) <= 4:\n            return node_kind.lower()\n        else:\n            return get_lower_case(node_kind)\n\n\nclass NodeMapper(object):\n\n    @classmethod\n    def _convert_output_shape(cls, kwargs, node):\n        shape = TensorShape()\n        dim = shape.dim.add()\n        dim.size = -1\n\n        if len(node.output_shape) > 2:\n            for i in node.output_shape[2:]:\n                dim = shape.dim.add()\n                dim.size = i\n            dim = shape.dim.add()\n            dim.size = node.output_shape.channels\n        else:\n            dim = shape.dim.add()\n            dim.size = node.output_shape[1]\n        kwargs['_output_shapes'] = [shape]\n\n    @classmethod\n    def get_kernel_params(cls, node, input_shape):\n        kwargs = {}\n\n        if node.kernel_parameters.global_pooling:\n            kwargs['kernel_shape'] = [1, input_shape.height, input_shape.width, 1]\n            kwargs['pads'] = [0] * 8\n\n        else:\n            from mmdnn.conversion.caffe.graph import NodeKind\n            if node.kind == NodeKind.Pooling:\n                kwargs['kernel_shape'] = [1, node.kernel_parameters.k_h, node.kernel_parameters.k_w, 1]\n            elif node.kind in [NodeKind.Convolution, NodeKind.Deconvolution]:\n                pass\n            else:\n                raise ValueError\n\n            dilation = node.parameters.dilation[0] if hasattr(node.parameters, 'dilation') and node.parameters.dilation else 1\n            o_h_caffe = node.output_shape.height\n            o_w_caffe = node.output_shape.width\n            ko_h = dilation * (int(node.kernel_parameters.k_h) - 1) + 1\n            ko_w = dilation * (int(node.kernel_parameters.k_w) - 1) + 1\n\n            if node.kind == NodeKind.Deconvolution:\n                o_h_tf = int(node.kernel_parameters.s_h) * (input_shape.height - 1) + ko_h - 2 * int(node.kernel_parameters.p_h)\n                o_w_tf = int(node.kernel_parameters.s_w) * (input_shape.width - 1) + ko_w - 2 * int(node.kernel_parameters.p_w)\n            else:\n                o_h_tf = (input_shape.height + node.kernel_parameters.p_h * 2 - ko_h + 1) // node.kernel_parameters.s_h\n                o_w_tf = (input_shape.width + node.kernel_parameters.p_w * 2 - ko_w + 1) // node.kernel_parameters.s_w\n            \n            kwargs['pads'] = [0, node.kernel_parameters.p_h, node.kernel_parameters.p_w, 0] + \\\n                    [0, node.kernel_parameters.p_h + o_h_caffe - o_h_tf, node.kernel_parameters.p_w + o_w_caffe - o_w_tf, 0]\n\n        kwargs['strides'] = [1, node.kernel_parameters.s_h, node.kernel_parameters.s_w, 1]\n        cls._convert_output_shape(kwargs, node)\n\n        return kwargs\n\n\n    @classmethod\n    def map_data(cls, node):\n        # TODO: We need to identify whether this is 4D image data, otherwise we shouldn't change the dimension order\n        shape = TensorShape()\n        dim = shape.dim.add()\n        dim.size = -1\n        for i in node.output_shape[2:]:\n            dim = shape.dim.add()\n            dim.size = i\n        dim = shape.dim.add()\n        dim.size = node.output_shape.channels\n\n        kwargs = {'shape': shape} # Ignore the dimension of batch size\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('DataInput', **kwargs)\n\n\n    @classmethod\n    def map_input(cls, node):\n        return cls.map_data(node)\n\n    @classmethod\n    def map_convolution(cls, node):\n        parent, _ = node.get_only_parent()\n        kwargs = cls.get_kernel_params(node, parent.output_shape)\n        kwargs['kernel_shape'] = [node.kernel_parameters.k_h, node.kernel_parameters.k_w, parent.output_shape.channels, node.parameters.num_output]\n        kwargs['use_bias'] = node.parameters.bias_term\n        if node.parameters.dilation:\n            dilation = node.parameters.dilation[0]\n            if dilation != 1:\n                kwargs['dilations'] = [1, dilation, dilation, 1]\n        kwargs['group'] = node.parameters.group\n        return Node.create('Conv', **kwargs)\n\n\n    @classmethod\n    def map_deconvolution(cls, node):\n        parent, _ = node.get_only_parent()\n        kwargs = cls.get_kernel_params(node, parent.output_shape)\n\n        kwargs['kernel_shape'] = [node.kernel_parameters.k_h, node.kernel_parameters.k_w, node.parameters.num_output, parent.output_shape.channels]\n        kwargs['use_bias'] = node.parameters.bias_term\n        if node.parameters.dilation:\n            dilation = node.parameters.dilation[0]\n            if dilation != 1:\n                kwargs['dilations'] = [1, dilation, dilation, 1]\n        kwargs['group'] = node.parameters.group\n        return Node.create('ConvTranspose', **kwargs)\n\n\n    @classmethod\n    def map_crop(cls, node):\n        kwargs = {}\n        cls._convert_output_shape(kwargs, node)\n        offset = node.parameters.offset\n        if offset:\n            if len(offset) == 1:\n                kwargs['border'] = [offset[0], offset[0], 0, 0]\n            else:\n                kwargs['border'] = [offset[0], offset[1], 0, 0]\n\n        return Node.create('Crop', **kwargs)\n\n\n    @classmethod\n    def map_elu(cls, node):\n        kwargs = {}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('ELU', **kwargs)\n\n\n    @classmethod\n    def map_relu(cls, node):\n        kwargs = {}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('Relu', **kwargs)\n\n\n    @classmethod\n    def map_p_re_lu(cls, node):\n        # print(node.parameters)\n        # assert False\n        try:\n            scale_value = float(node.parameters.filler.value)\n            kwargs = {'gamma' : scale_value}\n        except ConversionError:\n            kwargs = {'gamma' : 0.25}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('PRelu', **kwargs)\n\n\n    @classmethod\n    def map_pooling(cls, node):\n        parent, _ = node.get_only_parent()\n        kwargs = cls.get_kernel_params(node, parent.output_shape)\n        if node.parameters.pool == 0:\n            kwargs['pooling_type'] = 'MAX'\n        elif node.parameters.pool == 1:\n            kwargs['pooling_type'] = 'AVG'\n        else:\n            # Stochastic pooling, for instance.\n            raise ConversionError('Unsupported pooling type.')\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('Pool', **kwargs)\n\n\n    @classmethod\n    def map_unpooling(cls, node):\n        kwargs = {}\n        kwargs['kernel_shape'] = [1, node.kernel_parameters.k_h, node.kernel_parameters.k_w, 1]\n        kwargs['pads'] = [0, node.kernel_parameters.p_h, node.kernel_parameters.p_w, 0]\n        kwargs['strides'] = [1, node.kernel_parameters.s_h, node.kernel_parameters.s_w, 1]\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('Unpool', **kwargs)\n\n\n    @classmethod\n    def _add_flatten_layer(cls, node):\n        shape = TensorShape()\n        dim = shape.dim.add()\n        dim.size = -1\n\n        dim = shape.dim.add()\n        dim.size = 1\n        for i in node.output_shape[1:]:\n            dim.size *= i\n        kwargs = {'_output_shapes' : [shape]}\n        return Node.create('Flatten', **kwargs)\n\n    @classmethod\n    def map_inner_product(cls, node):\n        #TODO: Axis\n        assert node.parameters.axis == 1\n        #TODO: Unbiased\n        shape = TensorShape()\n        dim = shape.dim.add()\n        dim.size = -1\n        dim = shape.dim.add()\n        dim.size = 1\n        for i in node.output_shape[1:]:\n            dim.size *= i\n        kwargs = {'use_bias' : node.parameters.bias_term, 'units' : node.parameters.num_output,\n                '_output_shapes': [shape]}\n\n        # check if need the Flatten layer\n        parent, _ = node.get_only_parent()\n        ret = []\n\n        # if parent.output_shape.height > 1 or parent.output_shape.width > 1:\n        ret.append(cls._add_flatten_layer(parent))\n        ret.append(Node.create('FullyConnected', **kwargs))\n        return ret\n\n    @classmethod\n    def map_softmax(cls, node):\n        kwargs = {}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('Softmax', **kwargs)\n\n    @classmethod\n    def map_lrn(cls, node):\n        params = node.parameters\n        assert params.local_size % 2 == 1\n        kwargs = {'size': int(params.local_size), 'alpha': params.alpha, 'beta': params.beta, 'bias' : params.k}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('LRN', **kwargs)\n\n    @classmethod\n    def map_concat(cls, node):\n        kwargs = {'axis': (2, 3, 1, 0)[node.parameters.axis]}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('Concat', **kwargs)\n\n    @classmethod\n    def map_dropout(cls, node):\n        kwargs = {'keep_prob': node.parameters.dropout_ratio}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('Dropout', **kwargs)\n\n    @classmethod\n    def map_batch_norm(cls, node):\n        kwargs = {'scale' : len(node.data) >= 3, 'bias' : len(node.data) == 4}\n        epsilon = node.parameters.eps\n        kwargs['epsilon'] = epsilon\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('BatchNorm', **kwargs)\n\n    @classmethod\n    def map_scale(cls, node):\n        # TODO: The gamma parameter has to be set (in node.data?) and this should work.\n        # Also, mean should be set to 0, and var to 1, just to be safe.\n        if node.data:\n            scale_value = float(node.parameters.filler.value)\n            if node.parameters.bias_term:\n                bias_value = float(node.parameters.bias_filler.value)\n                kwargs = {'use_scale' : True, 'use_bias' : node.parameters.bias_term, 'gamma' : scale_value, 'beta': bias_value, 'epsilon': 0}\n            else:\n                kwargs = {'use_scale' : True, 'use_bias' : node.parameters.bias_term, 'gamma' : scale_value, 'epsilon': 0}\n\n            cls._convert_output_shape(kwargs, node)\n            return Node.create('Affine', **kwargs)\n        else:\n            return Node.create('Mul')\n\n\n    @classmethod\n    def map_eltwise(cls, node):\n        operations = {0: 'Mul', 1: 'Add', 2: 'Max'}\n        op_code = node.parameters.operation\n        try:\n            kwargs = {}\n            cls._convert_output_shape(kwargs, node)\n            return Node.create(operations[op_code], **kwargs)\n        except KeyError:\n            raise ConversionError('Unknown elementwise operation: {}'.format(op_code))\n\n    @classmethod\n    def map_abs_val(cls, node):\n        return Node.create('Abs')\n\n    @classmethod\n    def map_tanh(cls, node):\n        return Node.create('Tanh')\n\n    @classmethod\n    def map_sigmoid(cls, node):\n        return Node.create('Sigmoid')\n\n    @classmethod\n    def map_reshape(cls, node):\n        kwargs = {'shape' : [dim for dim in node.output_shape]}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('Reshape', **kwargs)\n\n    @classmethod\n    def map_flatten(cls, node):\n        return cls._add_flatten_layer(node)\n\n    @classmethod\n    def map_split(cls, node):\n        # skip the split node\n        return\n\n    @classmethod\n    def map_elu(cls, node):\n        kwargs = {}\n        cls._convert_output_shape(kwargs, node)\n        return Node.create('ELU', **kwargs)\n"""
mmdnn/conversion/caffe/network.py,0,"b""import numpy as np\n\nDEFAULT_PADDING = 'SAME'\n\n\ndef layer(op):\n    '''Decorator for composable network layers.'''\n\n    def layer_decorated(self, *args, **kwargs):\n        # Automatically set a name if not provided.\n        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n        # Figure out the layer inputs.\n        assert len(args) >= 1\n        if len(args) == 1:\n            layer_inputs = args[0]\n        else:\n            layer_inputs = list(args) \n        layer_output = op(self, layer_inputs, **kwargs)\n        # print('op: %s   shape: %s' % (op, layer_output._keras_shape))\n        # print('op: %s   shape: %s' % (op, layer_output.get_shape().as_list()))\n        # Add to layer LUT.\n        self.layers[name] = layer_output\n        self.output = layer_output\n        return layer_output\n\n    return layer_decorated\n\n\nclass Network(object):\n\n    def __init__(self, trainable=False):\n        self.output = None\n        self.layers = {}\n        self.trainable = trainable\n        self.setup()\n\n    def setup(self):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    def load(self, data_path, session, ignore_missing=False):\n        raise NotImplementedError('Must be implemented by the subclass')\n    \n    def input(self, shape, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    def get_output(self):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    def get_unique_name(self, prefix):\n        raise NotImplementedError('Must be implemented by the subclass')\n    \n    @layer\n    def conv(self, input, k_h, k_w, c_o, s_h, s_w, p_h, p_w, name, group=1, biased=True):\n        raise NotImplementedError('Must be implemented by the subclass')\n    \n    @layer\n    def deconv(self, input, c_o, k_h, k_w, s_h, s_w, p_h, p_w, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def relu(self, input, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def sigmoid(self, input, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def max_pool(self, input, k_h, k_w, s_h, s_w, p_h, p_w, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def max_unpool(self, input, k_h, k_w, s_h, s_w, p_h, p_w, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def avg_pool(self, input, k_h, k_w, s_h, s_w, p_h, p_w, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def lrn(self, input, local_size, alpha, beta, name, bias=1):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def concat(self, inputs, axis, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n    \n    @layer\n    def add(self, inputs, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def fc(self, input, num_out, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def softmax(self, input, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def batch_normalization(self, input, name, epsilon=0.00001, scale_offset=True):\n        raise NotImplementedError('Must be implemented by the subclass')\n\n    @layer\n    def dropout(self, input, keep_prob, name):\n        raise NotImplementedError('Must be implemented by the subclass')\n    \n    @layer\n    def crop(self, inputs, offset, name):\n        raise NotImplementedError('Must be implemented by the subclass')"""
mmdnn/conversion/caffe/resolver.py,0,"b""import sys\n\nSHARED_CAFFE_RESOLVER = None\n\n\nclass CaffeResolver(object):\n    def __init__(self):\n        self.import_caffe()\n\n    def import_caffe(self):\n        self.caffe = None\n\n        try:\n            import caffe\n            self.caffe = caffe\n        except ImportError:\n            # Fall back to the protobuf implementation\n            from mmdnn.conversion.caffe import caffe_pb2\n            self.caffepb = caffe_pb2\n            show_fallback_warning()\n        if self.caffe:\n            self.caffepb = self.caffe.proto.caffe_pb2\n        self.NetParameter = self.caffepb.NetParameter\n\n    def has_pycaffe(self):\n        return self.caffe is not None\n\n\ndef get_caffe_resolver():\n    global SHARED_CAFFE_RESOLVER\n    if SHARED_CAFFE_RESOLVER is None:\n        SHARED_CAFFE_RESOLVER = CaffeResolver()\n    return SHARED_CAFFE_RESOLVER\n\n\ndef has_pycaffe():\n    return get_caffe_resolver().has_pycaffe()\n\n\ndef show_fallback_warning():\n    msg = '''\n------------------------------------------------------------\n    WARNING: PyCaffe not found!\n    Falling back to a pure protocol buffer implementation.\n    * Conversions will be drastically slower.\n    * This backend is UNTESTED!\n------------------------------------------------------------\n\n'''\n    sys.stderr.write(msg)\n"""
mmdnn/conversion/caffe/saver.py,0,"b""import caffe\n\n\ndef save_model(MainModel, network_filepath, weight_filepath, dump_filepath):\n    dump_net = dump_filepath + '.prototxt'\n    dump_weight = dump_filepath + '.caffemodel'\n    dump_net = str(dump_net)\n    dump_weight = str(dump_weight)\n    MainModel.make_net(dump_net)\n    MainModel.gen_weight(weight_filepath, dump_weight, dump_net)\n    print('Caffe model files are saved as [{}] and [{}], generated by [{}.py] and [{}].'.format(\n        dump_net, dump_weight, network_filepath, weight_filepath))\n"""
mmdnn/conversion/caffe/shape.py,0,"b'from collections import namedtuple\nimport math\n\nTensorShape = namedtuple(\'TensorShape\', [\'batch_size\', \'channels\', \'height\', \'width\'])\n\n\ndef get_kernel_extents(params, dilation):\n    ko_h = dilation * (int(params.k_h) - 1) + 1\n    ko_w = dilation * (int(params.k_w) - 1) + 1\n    return ko_h, ko_w\n\ndef get_filter_output_shape(i_h, i_w, dilation, params, round_func):\n    ko_h, ko_w = get_kernel_extents(params, dilation)\n\n    o_h = (i_h + 2 * params.p_h - ko_h) / float(params.s_h) + 1\n    o_w = (i_w + 2 * params.p_w - ko_w) / float(params.s_w) + 1\n    return (int(round_func(o_h)), int(round_func(o_w)))\n\n\ndef get_strided_kernel_output_shape(node, round_func):\n    assert node.layer is not None\n    input_shape = node.get_only_parent()[0].output_shape\n    params = node.kernel_parameters\n    dilation = node.parameters.dilation[0] if hasattr(node.parameters, \'dilation\') and node.parameters.dilation else 1\n\n    o_h, o_w = get_filter_output_shape(input_shape.height, input_shape.width,\n                                       dilation, params, round_func)\n    params = node.parameters\n    has_c_o = hasattr(params, \'num_output\')\n    c = params.num_output if has_c_o else input_shape.channels\n    return TensorShape(input_shape.batch_size, c, o_h, o_w)\n\n\ndef shape_not_implemented(node):\n    raise NotImplementedError\n\ndef shape_deconvolution(node):\n    input_shape = node.get_only_parent()[0].output_shape\n    params = node.kernel_parameters\n    dilation = 1 if len(node.parameters.dilation) == 0 else node.parameters.dilation[0]\n\n    ko_h, ko_w = get_kernel_extents(params, dilation)\n    o_h = int(params.s_h) * (input_shape.height - 1) + ko_h - 2 * int(params.p_h)\n    o_w = int(params.s_w) * (input_shape.width - 1) + ko_w - 2 * int(params.p_w)\n\n    has_c_o = hasattr(node.parameters, \'num_output\')\n    c = node.parameters.num_output if has_c_o else input_shape.channels\n    return TensorShape(input_shape.batch_size, c, o_h, o_w)\n\ndef shape_identity(node):\n    assert len(node.parents) > 0\n    return node.parents[0][0].output_shape\n\n\ndef shape_scalar(node):\n    return TensorShape(1, 1, 1, 1)\n\ndef shape_reshape(node):\n    last_shape = node.get_only_parent()[0].output_shape\n    shapes = []\n    for idx, shape in enumerate(node.layer.reshape_param.shape.dim):\n        shapes.append(shape if shape != 0 else last_shape[idx])\n\n    if len(shapes) == 1 and shapes[0]==-1:\n        total_dim = 1\n        for i in last_shape:\n            total_dim *= i\n        return TensorShape(1, 1, 1, total_dim) # return NHWC format\n\n    elif len(shapes) == 4:\n        return TensorShape(shapes[0], shapes[1], shapes[2], shapes[3])\n\n    else:\n        raise NotImplementedError\n\ndef shape_data(node):\n    if node.output_shape:\n        # Old-style input specification\n        return node.output_shape\n    try:\n        # New-style input specification\n        return tuple(map(int, node.parameters.shape[0].dim))\n    except:\n        # We most likely have a data layer on our hands. The problem is,\n        # Caffe infers the dimensions of the data from the source (eg: LMDB).\n        # We want to avoid reading datasets here. Fail for now.\n        # This can be temporarily fixed by transforming the data layer to\n        # Caffe\'s ""input"" layer (as is usually used in the ""deploy"" version).\n        # TODO: Find a better solution for this.\n        pass\n\n\ndef shape_mem_data(node):\n    params = node.parameters\n    return TensorShape(params.batch_size, params.channels, params.height, params.width)\n\n\ndef shape_concat(node):\n    axis = node.parameters.axis\n    output_shape = None\n    for parent, idx in node.parents:\n        if output_shape is None:\n            output_shape = list(parent.output_shape)\n        else:\n            output_shape[axis] += parent.output_shape[axis]\n    return tuple(output_shape)\n\n\ndef shape_convolution(node):\n    return get_strided_kernel_output_shape(node, math.floor)\n\n\ndef shape_pool(node):\n    if node.parameters.global_pooling:\n        return shape_global_pooling(node)\n    return get_strided_kernel_output_shape(node, math.ceil)\n\ndef shape_unpool(node):\n    return get_strided_kernel_output_shape(node, math.ceil)\n\ndef shape_inner_product(node):\n    input_shape = node.get_only_parent()[0].output_shape\n    return TensorShape(input_shape.batch_size, node.parameters.num_output, 1, 1)\n\n\ndef shape_global_pooling(node):\n    input_shape = node.get_only_parent()[0].output_shape\n    params = node.kernel_parameters\n    has_c_o = hasattr(params, \'num_output\')\n    c = params.num_output if has_c_o else input_shape.channels\n    return TensorShape(input_shape.batch_size, c, 1, 1)  # Output height and width is 1 when global_pooling\n\n\ndef shape_split(node):\n    input_shape = node.get_only_parent()[0].output_shape\n    return TensorShape(input_shape.batch_size, input_shape.channels, input_shape.height, input_shape.width)\n\n\ndef shape_flatten(node):\n    input_shape = node.get_only_parent()[0].output_shape\n    return TensorShape(input_shape.batch_size, input_shape.channels * input_shape.height * input_shape.width, 1, 1)\n\n'"
mmdnn/conversion/caffe/transformer.py,0,"b""from __future__ import unicode_literals\nfrom google.protobuf import text_format\nimport numpy as np\nfrom mmdnn.conversion.caffe.graph import GraphBuilder, NodeKind, LAYER_IN_TRAIN_PROTO\nfrom mmdnn.conversion.caffe.mapper import NodeMapper, get_handler_name\nfrom mmdnn.conversion.caffe.resolver import get_caffe_resolver, has_pycaffe\nfrom mmdnn.conversion.caffe.errors import print_stderr, ConversionError\nfrom mmdnn.conversion.caffe.common_graph import Graph\nfrom mmdnn.conversion.caffe.utils import get_lower_case, get_upper_case\n\n\nclass DataInjector(object):\n    '''\n    Associates parameters loaded from a .caffemodel file with their corresponding nodes.\n    '''\n\n    def __init__(self, def_path, data_path):\n        # The .prototxt file defining the graph\n        self.def_path = def_path\n        # The .caffemodel file containing the learned parameters\n        self.data_path = data_path\n        # Set to true if the fallback protocol-buffer based backend was used\n        self.did_use_pb = False\n        # A list containing (layer name, parameters) tuples\n        self.params = None\n        # Load the parameters\n        self.caffemodel = None\n        if has_pycaffe() and self.def_path:\n            self.load_using_caffe()\n        else:\n            self.load_using_pb()\n\n    def load_using_caffe(self):\n        caffe = get_caffe_resolver().caffe\n        net = caffe.Net(str(self.def_path), str(self.data_path), caffe.TEST)\n        data = lambda blob: blob.data\n        self.params = [(k, list(map(data, v))) for k, v in net.params.items()]\n\n    def load_using_pb(self):\n        self.caffemodel = get_caffe_resolver().NetParameter()\n        self.caffemodel.MergeFromString(open(self.data_path, 'rb').read())\n        pair = lambda layer: (layer.name, self.normalize_pb_data(layer))\n        layers = self.caffemodel.layers or self.caffemodel.layer\n        self.params = [pair(layer) for layer in layers if layer.blobs]\n        self.did_use_pb = True\n\n    def normalize_pb_data(self, layer):\n        transformed = []\n        for blob in layer.blobs:\n            if len(blob.shape.dim):\n                dims = blob.shape.dim\n                c_o, c_i, h, w = map(int, [1] * (4 - len(dims)) + list(dims))\n            else:\n                c_o = blob.num\n                c_i = blob.channels\n                h = blob.height\n                w = blob.width\n            data = np.array(blob.data, dtype=np.float32).reshape(c_o, c_i, h, w)\n            transformed.append(data)\n        return transformed\n\n    def adjust_parameters(self, node, data):\n        if not self.did_use_pb:\n            return data\n        # When using the protobuf-backend, each parameter initially has four dimensions.\n        # In certain cases (like FC layers), we want to eliminate the singleton dimensions.\n        # This implementation takes care of the common cases. However, it does leave the\n        # potential for future issues.\n        # The Caffe-backend does not suffer from this problem.\n        data = list(data)\n        squeeze_indices = [1]  # Squeeze biases.\n        if node.kind == NodeKind.InnerProduct:\n            squeeze_indices.append(0)  # Squeeze FC.\n        if len(data)==1:\n            squeeze_indices=[0]\n        if node.kind == 'Convolution':\n            return data\n        for idx in squeeze_indices:\n            data[idx] = np.squeeze(data[idx])\n        return data\n\n    def __call__(self, graph):\n        for layer_name, data in self.params:\n            if layer_name in graph:\n                node = graph.get_node(layer_name)\n                node.data = self.adjust_parameters(node, data)\n            else:\n                print_stderr('Ignoring parameters for non-existent layer: %s' % layer_name)\n        return graph\n\n\nclass NodeRenamer(object):\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            node.name = node.name.replace('/', '_')\n        return graph\n\n\nclass DataReshaper(object):\n\n    def __init__(self, mapping, replace=True):\n        # A dictionary mapping NodeKind to the transposed order.\n        self.mapping = mapping\n        # The node kinds eligible for reshaping\n        self.reshaped_node_types = self.mapping.keys()\n        # If true, the reshaped data will replace the old one.\n        # Otherwise, it's set to the reshaped_data attribute.\n        self.replace = replace\n\n    def has_spatial_parent(self, node):\n        try:\n            parent = node.get_only_parent()[0]\n            s = parent.output_shape\n            return s.height > 1 or s.width > 1\n        except ConversionError:\n            return False\n\n    def map(self, node_kind):\n        try:\n            return self.mapping[node_kind]\n        except KeyError:\n            raise ConversionError('Ordering not found for node kind: {}'.format(node_kind))\n\n    def _is_image_data(self, node):\n        return len([child for child in node.children if child.kind in (NodeKind.Convolution, NodeKind.Pooling, NodeKind.Unpooling)])\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind not in self.reshaped_node_types:\n                # Check for 2+ dimensional data\n                if any(len(tensor.shape) > 1 for tensor in node.data):\n                    print_stderr('Warning: parameters not reshaped for node: {}'.format(node))\n                continue\n            transpose_order = self.map(node.kind)\n            weights = node.data[0]\n            if (node.kind == NodeKind.InnerProduct) and self.has_spatial_parent(node):\n                # The FC layer connected to the spatial layer needs to be\n                # re-wired to match the new spatial ordering.\n                in_shape = node.get_only_parent()[0].output_shape\n                fc_shape = weights.shape\n                output_channels = fc_shape[0]\n                weights = weights.reshape((output_channels, in_shape.channels, in_shape.height,\n                                           in_shape.width))\n                weights = weights.transpose(self.map(NodeKind.Convolution))\n                node.reshaped_data = weights.reshape(fc_shape[transpose_order[0]],\n                                                     fc_shape[transpose_order[1]])\n            else:\n                node.reshaped_data = weights.transpose(transpose_order)\n            # node.reshaped_data = weights.transpose(transpose_order)\n        if self.replace:\n            for node in graph.nodes:\n                if hasattr(node, 'reshaped_data'):\n                    # Set the weights\n                    node.data[0] = node.reshaped_data\n                    del node.reshaped_data\n        return graph\n\n\nclass SubNodeFuser(object):\n    '''\n    An abstract helper for merging a single-child with its single-parent.\n    '''\n\n    def __call__(self, graph):\n        nodes = graph.nodes\n        fused_nodes = []\n        for node in nodes:\n            if len(node.parents) != 1:\n                # We're only fusing nodes with single parents\n                continue\n            parent, from_output = node.get_only_parent()\n            if len(parent.children) != 1:\n                # We can only fuse a node if its parent's\n                # value isn't used by any other node.\n                continue\n            if not self.is_eligible_pair(parent, node):\n                continue\n            # Rewrite the fused node's children to its parent.\n            for child in node.children:\n                index = [n for n, (input, idx) in enumerate(child.parents) if input == node][0]\n                child.parents.pop(index)\n                child.add_parent(parent, from_output, index)\n            # Disconnect the fused node from the graph.\n            parent.children.remove(node)\n            fused_nodes.append(node)\n            # Let the sub-class merge the fused node in any arbitrary way.\n            self.merge(parent, node)\n        transformed_nodes = [node for node in nodes if node not in fused_nodes]\n        return graph.replaced(transformed_nodes)\n\n    def is_eligible_pair(self, parent, child):\n        '''Returns true if this parent/child pair is eligible for fusion.'''\n        raise NotImplementedError('Must be implemented by subclass.')\n\n    def merge(self, parent, child):\n        '''Merge the child node into the parent.'''\n        raise NotImplementedError('Must be implemented by subclass')\n\n\nclass ReLUFuser(SubNodeFuser):\n    '''\n    Fuses rectified linear units with their parent nodes.\n    '''\n\n    def __init__(self, allowed_parent_types=None):\n        # Fuse ReLUs when the parent node is one of the given types.\n        # If None, all node types are eligible.\n        self.allowed_parent_types = allowed_parent_types\n\n    def is_eligible_pair(self, parent, child):\n        return ((self.allowed_parent_types is None or parent.kind in self.allowed_parent_types) and\n                child.kind == NodeKind.ReLU)\n\n    def merge(self, parent, _):\n        parent.metadata['relu'] = True\n\n\nclass BatchNormScaleBiasFuser(SubNodeFuser):\n    '''\n    The original batch normalization paper includes two learned\n    parameters: a scaling factor \\gamma and a bias \\beta.\n    Caffe's implementation does not include these two. However, it is commonly\n    replicated by adding a scaling+bias layer immidiately after the batch norm.\n\n    This fuser merges the scaling+bias layer with the batch norm.\n    '''\n\n    def is_eligible_pair(self, parent, child):\n        return (parent.kind == NodeKind.BatchNorm and child.kind == NodeKind.Scale and\n                child.parameters.axis == 1 and child.parameters.bias_term == True)\n\n    def merge(self, parent, child):\n        parent.scale_bias_node = child\n\n\nclass BatchNormPreprocessor(object):\n    '''\n    Prescale batch normalization parameters.\n    Concatenate gamma (scale) and beta (bias) terms if set.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.kind != NodeKind.BatchNorm:\n                continue\n            assert node.data is not None\n            assert len(node.data) == 3\n            mean, variance, scale = node.data\n\n            # Prescale the stats\n            scaling_factor = 1.0 / scale if scale != 0 else 0\n\n            if len(np.squeeze(mean) == 1):\n                mean = np.squeeze(mean)\n                variance = np.squeeze(variance)\n                scaling_factor = np.squeeze(scaling_factor)\n\n            mean *= scaling_factor\n            variance *= scaling_factor\n\n            # Replace with the updated values\n            node.data = [mean, variance]\n            if hasattr(node, 'scale_bias_node'):\n                # Include the scale and bias terms\n                gamma, beta = node.scale_bias_node.data\n                node.data += [gamma, beta]\n        return graph\n\n\nclass ParameterNamer(object):\n    '''\n    Convert layer data arrays to a dictionary mapping parameter names to their values.\n    '''\n\n    def __call__(self, graph):\n        for node in graph.nodes:\n            if node.data is None:\n                continue\n            if node.kind in (NodeKind.Convolution, NodeKind.Deconvolution, NodeKind.InnerProduct):\n                names = ('weights',)\n                if node.parameters.bias_term:\n                    names += ('bias',)\n            elif node.kind == NodeKind.BatchNorm:\n                names = ('mean', 'var')\n                if len(node.data) == 4:\n                    names += ('scale', 'bias')\n            elif node.kind == NodeKind.PReLU:\n                names = ('gamma',)\n            elif node.kind == NodeKind.ELU:\n                names = ('alpha',)\n            else:\n                print_stderr('WARNING: Unhandled parameters: {}'.format(node.kind))\n                continue\n            assert len(names) == len(node.data)\n            node.data = dict(zip(names, node.data))\n        return graph\n\n\nclass CaffeTransformer(object):\n\n    def __init__(self, def_path, data_path, target_toolkit, input_shape=None, phase='test'):\n        self.layer_name_map = {}\n        self.data_injector = None\n        self.is_train_proto = False\n        self.input_shape = input_shape\n        if def_path is None:\n            if self.input_shape is None:\n                raise ConversionError('if the graph prototxt is not provided, the input shape should be provided')\n            self.input_shape = [1] + self.input_shape\n            def_path, self.data_injector = self.gen_prototxt_from_caffemodel(data_path, self.input_shape)\n            self.is_train_proto = True\n        else:\n            model = get_caffe_resolver().NetParameter()\n            with open(def_path, 'r') as f:\n                text_format.Merge(f.read(), model)\n            layers = model.layers or model.layer\n            if len([layer for layer in layers if NodeKind.map_raw_kind(layer.type) in LAYER_IN_TRAIN_PROTO]) > 0:\n                if self.input_shape is None:\n                    raise ConversionError('the train_val.prototxt should be provided with the input shape')\n                self.input_shape = [1] + self.input_shape\n                self.is_train_proto = True\n        graph = GraphBuilder(def_path, self.input_shape, self.is_train_proto, phase).build()\n        if self.is_train_proto:\n            def_path = graph.prototxt\n        if data_path is not None:\n            graph = graph.transformed([\n                self.data_injector if self.data_injector else DataInjector(def_path, data_path), # Load and associate learned parameters\n                BatchNormScaleBiasFuser(),\n                BatchNormPreprocessor() # Pre-process batch normalization data\n            ])\n            target_toolkit = target_toolkit.lower()\n            if target_toolkit not in ('caffe', 'caffe2'):\n                graph = graph.transformed([DataReshaper({ # Reshape the parameters to TensorFlow's ordering\n                    NodeKind.Convolution: (2, 3, 1, 0), # (c_o, c_i, h, w) -> (h, w, c_i, c_o)\n                    NodeKind.Deconvolution: (2, 3, 1, 0), # (c_o, c_i, h, w) -> (h, w, c_i, c_o)\n                    NodeKind.InnerProduct: (1, 0) # (c_o, c_i) -> (c_i, c_o)\n                }),\n                    ParameterNamer() # Convert parameters to dictionaries\n                ])\n        self.graph = graph\n        #  self.graph = NodeRenamer()(graph)\n        print (self.graph)\n\n    def gen_prototxt_from_caffemodel(self, data_path, input_shape):\n        prototxt = 'deploy.prototxt'\n        data_injector = DataInjector(None, data_path)\n        caffemodel = data_injector.caffemodel\n        layers = caffemodel.layers or caffemodel.layer\n        for item in layers:\n            item.ClearField('blobs')\n        with open(prototxt ,'w') as f:\n            f.write(str(caffemodel))\n        return prototxt, data_injector\n\n    def transform_data(self):\n        return {self.layer_name_map[node.name]: node.data for node in self.graph.nodes if node.data}\n\n    def transform_graph(self):\n        for node in self.graph.nodes:\n            self.layer_name_map[node.name] = node.name\n\n        ret = []\n        for node in self.graph.nodes:\n            mapped_node = self.map_node(node)\n            if isinstance(mapped_node, list):\n                ret.extend([n for n in mapped_node])\n            elif mapped_node:\n                ret.append(mapped_node)\n\n\n        name = get_upper_case(get_lower_case(self.graph.name))\n        return Graph(name, ret)\n        #return Graph(name, [self.map_node(node) for node in self.graph.nodes])\n\n    def get_handler(self, node_kind, prefix):\n        name = get_handler_name(node_kind)\n        name = '_'.join((prefix, name))\n        try:\n            return getattr(NodeMapper, name)\n        except AttributeError:\n            raise ConversionError('No handler found for node kind: %s (expected: %s)' % (node_kind, name))\n\n    def map_node(self, node):\n        map_func = self.get_handler(node.kind, 'map')\n\n        mapped_node = map_func(node)\n        # assert mapped_node is not None\n\n        if isinstance(mapped_node, list):\n            ret = []\n            for idx, cur_node in enumerate(mapped_node):\n                cur_node.name = node.name + '_' + str(idx)\n                if idx == 0:\n                    cur_node.input.extend([self.layer_name_map[input.name] for input, idx in node.parents])\n                else:\n                    cur_node.input.extend([node.name + '_' + str(idx - 1)])\n\n                if idx == len(mapped_node) - 1:\n                    cur_node.output.extend(node.output)\n                else:\n                    cur_node.output.extend([node.name + '_' + str(idx + 1)])\n\n                self.layer_name_map[node.name] = node.name + '_' + str(len(mapped_node) - 1)\n                ret.append(cur_node)\n            return ret\n\n        # skip when mapped_node is None\n        elif not mapped_node:\n            input_of_next = node.get_only_parent()[0]\n            next_node = node.children\n            for next in next_node:\n                next.parents[0] = tuple([input_of_next, next.parents[0][1]])\n\n        else:\n            mapped_node.name = node.name\n            mapped_node.input.extend(['%s' % (self.layer_name_map[input.name]) for input, idx in node.parents])\n            mapped_node.output.extend(node.output)\n            return mapped_node\n\n"""
mmdnn/conversion/caffe/utils.py,0,"b""#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport re\n\ndef get_lower_case(text):\n    '''\n    Convert PascalCase name to words concatenated by '_'.\n    'PascalCase' -> 'pascal_case'\n    '''\n    name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', text)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n\n    \ndef get_upper_case(text):\n    '''\n    'pascal_case' -> 'PascalCase'\n    '''\n    return ''.join([item.title() for item in text.split('_')])\n\ndef get_real_name(text):\n    text = text.strip().split(':')\n    return ''.join(text[:-1])\n"""
mmdnn/conversion/caffe/writer.py,0,"b'import base64\nfrom google.protobuf import json_format\nfrom importlib import import_module\nimport json\nimport numpy as np\nimport os\nimport sys\n\nfrom mmdnn.conversion.caffe.errors import ConversionError\nfrom mmdnn.conversion.caffe.common_graph import fetch_attr_value\nfrom mmdnn.conversion.caffe.utils import get_lower_case, get_upper_case, get_real_name\n\n\nclass JsonFormatter(object):\n    \'\'\'Dumpt a DL graph into a Json file.\'\'\'\n\n    def __init__(self, graph):\n        self.graph_def = graph.as_graph_def()\n\n    def dump(self, json_path):\n        json_txt = json_format.MessageToJson(self.graph_def)\n        parsed = json.loads(json_txt)\n        formatted = json.dumps(parsed, indent=4, sort_keys=True)\n        with open(json_path, \'w\') as f:\n            f.write(formatted)\n\n    \nclass PyWriter(object):\n    \'\'\'Dumpt a DL graph into a Python script.\'\'\'\n\n    def __init__(self, graph, data, target):\n        self.graph = graph\n        self.data = data\n        self.tab = \' \' * 4\n        self.prefix = \'\'\n        target = target.lower()\n        if target == \'tensorflow\':\n            self.target = target\n            self.net = \'TensorFlowNetwork\'\n        elif target == \'keras\':\n            self.target = target\n            self.net = \'KerasNetwork\'\n        elif target == \'caffe\':\n            self.target = target\n            self.net = \'CaffeNetwork\'\n        else:\n            raise ConversionError(\'Target %s is not supported yet.\' % target)\n\n    def indent(self):\n        self.prefix += self.tab\n\n    def outdent(self):\n        self.prefix = self.prefix[:-len(self.tab)]\n\n    def statement(self, s):\n        return self.prefix + s + \'\\n\'\n\n    def emit_imports(self):\n        return self.statement(\'from dlconv.%s import %s\\n\' % (self.target, self.net))\n\n    def emit_class_def(self, name):\n        return self.statement(\'class %s(%s):\' % (name, self.net))\n\n    def emit_setup_def(self):\n        return self.statement(\'def setup(self):\')\n\n    def emit_node(self, node):\n        \'\'\'Emits the Python source for this node.\'\'\'\n        \n        def pair(key, value):\n            return \'%s=%s\' % (key, value)\n        args = []\n        for input in node.input:\n            input = input.strip().split(\':\')\n            name = \'\'.join(input[:-1])\n            idx = int(input[-1])\n            assert name in self.graph.node_dict\n            parent = self.graph.get_node(name)\n            args.append(parent.output[idx])\n        #FIXME:\n        output = [node.output[0]]\n        # output = node.output\n        for k, v in node.attr:\n            if k == \'cell_type\':\n                args.append(pair(k, ""\'"" + fetch_attr_value(v) + ""\'""))\n            else:\n                args.append(pair(k, fetch_attr_value(v)))\n        args.append(pair(\'name\', ""\'"" + node.name + ""\'"")) # Set the node name\n        args = \', \'.join(args)\n        return self.statement(\'%s = self.%s(%s)\' % (\', \'.join(output), node.op, args))\n\n    def dump(self, code_output_dir):\n        if not os.path.exists(code_output_dir):\n            os.makedirs(code_output_dir)\n        file_name = get_lower_case(self.graph.name)\n        code_output_path = os.path.join(code_output_dir, file_name + \'.py\')\n        data_output_path = os.path.join(code_output_dir, file_name + \'.npy\')\n        with open(code_output_path, \'w\') as f:\n            f.write(self.emit())\n        with open(data_output_path, \'wb\') as f:\n            np.save(f, self.data)\n        return code_output_path, data_output_path\n\n    def emit(self):\n        # Decompose DAG into chains\n        chains = []\n        for node in self.graph.topologically_sorted():\n            attach_to_chain = None\n            if len(node.input) == 1:\n                parent = get_real_name(node.input[0])\n                for chain in chains:\n                    if chain[-1].name == parent: # Node is part of an existing chain.\n                        attach_to_chain = chain\n                        break\n            if attach_to_chain is None: # Start a new chain for this node.\n                attach_to_chain = []\n                chains.append(attach_to_chain)\n            attach_to_chain.append(node)\n            \n        # Generate Python code line by line\n        source = self.emit_imports()\n        source += self.emit_class_def(self.graph.name)\n        self.indent()\n        source += self.emit_setup_def()\n        self.indent()\n        blocks = []\n        for chain in chains:\n            b = \'\'\n            for node in chain:\n                b += self.emit_node(node)\n            blocks.append(b[:-1])\n        source += \'\\n\\n\'.join(blocks)\n        return source\n\n\nclass ModelSaver(object):\n\n    def __init__(self, code_output_path, data_output_path):\n        self.code_output_path = code_output_path\n        self.data_output_path = data_output_path\n\n    def dump(self, model_output_dir):\n        \'\'\'Return the file path containing graph in generated model files.\'\'\'\n        if not os.path.exists(model_output_dir):\n            os.makedirs(model_output_dir)\n        sys.path.append(os.path.dirname(self.code_output_path))\n        file_name = os.path.splitext(os.path.basename(self.code_output_path))[0]\n        module = import_module(file_name)\n        class_name = get_upper_case(file_name)\n        net = getattr(module, class_name)\n        return net.dump(self.data_output_path, model_output_dir)\n\n\nclass GraphDrawer(object):\n\n    def __init__(self, toolkit, meta_path):\n        self.toolkit = toolkit.lower()\n        self.meta_path = meta_path\n\n    def dump(self, graph_path):\n        if self.toolkit == \'tensorflow\':\n            from dlconv.tensorflow.visualizer import TensorFlowVisualizer\n            if self._is_web_page(graph_path):\n                TensorFlowVisualizer(self.meta_path).dump_html(graph_path)\n            else:\n                raise NotImplementedError(\'Image format or %s is unsupported!\' % graph_path)\n        elif self.toolkit == \'keras\':\n            from dlconv.keras.visualizer import KerasVisualizer\n            png_path, html_path = (None, None)\n            if graph_path.endswith(\'.png\'):\n                png_path = graph_path\n            elif self._is_web_page(graph_path):\n                png_path = graph_path + "".png""\n                html_path = graph_path\n            else:\n                raise NotImplementedError(\'Image format or %s is unsupported!\' % graph_path)\n            KerasVisualizer(self.meta_path).dump_png(png_path)\n            if html_path:\n                self._png_to_html(png_path, html_path)\n                os.remove(png_path)\n        else:\n            raise NotImplementedError(\'Visualization of %s is unsupported!\' % self.toolkit)\n\n    def _is_web_page(self, path):\n        return path.split(\'.\')[-1] in (\'html\', \'htm\')\n\n    def _png_to_html(self, png_path, html_path):\n        with open(png_path, ""rb"") as f:\n            encoded = base64.b64encode(f.read()).decode(\'utf-8\')\n        source = """"""<!DOCTYPE>\n<html>\n    <head>\n        <meta charset=""utf-8"">\n        <title>Keras</title>\n    </head>\n    <body>\n        <img alt=""Model Graph"" src=""data:image/png;base64,{base64_str}"" />\n    </body>\n</html>"""""".format(base64_str=encoded)\n        with open(html_path, \'w\', encoding=\'utf-8\') as f:\n            f.write(source)'"
mmdnn/conversion/cntk/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/cntk/cntk_emitter.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport os\nfrom six.moves import xrange\n\nimport cntk\nfrom mmdnn.conversion.common.IR.IR_graph import IRGraph, IRGraphNode\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.emitter import Emitter\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.rewriter.folder import *\n\nclass CntkEmitter(Emitter):\n    \n    dtype_map = {\n        graph_pb2.DT_FLOAT16 : ""np.float16"",\n        graph_pb2.DT_FLOAT32 : ""np.float32"",\n        graph_pb2.DT_FLOAT64 : ""np.float64"",\n        graph_pb2.DT_INT16 : ""np.float16"",  # Cntk does not support Int.\n        graph_pb2.DT_INT32 : ""np.float32"",  # Cntk does not support Int.\n        graph_pb2.DT_INT64 : ""np.float64"",  # Cntk does not support Int.\n        graph_pb2.DT_UINT8 : ""np.uint8"",\n        graph_pb2.DT_UINT16 : ""np.uint16""\n    }\n\n\n    naive_scope_pattern = [\'gru_cell\', \'lstm_cell\']\n\n    def __init__(self, model):\n        from six import string_types as _string_types\n        super(CntkEmitter, self).__init__()\n        if isinstance(model, _string_types):\n            network_path = model\n        else:\n            network_path = model[0]\n            self._load_weights(model[1])\n\n        self.IR_graph = IRGraph(network_path)\n        super(CntkEmitter, self)._build()\n        self.yolo_parameter = []\n        folder = Folder(self.IR_graph, self.weights_dict)\n        folder.fold()\n\n\n    @property\n    def header_code(self):\n        return """"""import numpy as np\nimport cntk\nfrom cntk import ops, layers\nfrom cntk.contrib.crosstalkcaffe.unimodel.cntkinstance import BlockApiSetup\n\n__weights_dict = dict()\n\ndef load_weights(weight_file):\n    if weight_file == None:\n        return\n\n    try:\n        weights_dict = np.load(weight_file, allow_pickle=True).item()\n    except:\n        weights_dict = np.load(weight_file, allow_pickle=True, encoding=\'bytes\').item()\n\n    return weights_dict\n\n\ndef KitModel(weight_file = None):\n    global __weights_dict\n    __weights_dict = load_weights(weight_file)\n\n""""""\n\n\n    def gen_code(self, phase = \'test\'):\n        self.phase = phase\n        self.add_body(0, self.header_code)\n\n        for layer in self.IR_graph.topological_sort:\n            current_node = self.IR_graph.get_node(layer)\n            node_type = current_node.type\n\n            if hasattr(self, ""emit_"" + node_type):\n                func = getattr(self, ""emit_"" + node_type)\n                line = func(current_node)\n                if line:\n                    self.add_body(1, line)\n            else:\n                print(""CntkEmitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(current_node)\n\n        self.add_body(1, ""return {}"".format(\n            \',\'.join([self.IR_graph.get_node(name).real_variable_name for name in self.IR_graph.output_layers])))\n\n        self.add_body(0, """")\n        for i in self.used_layers:\n            func = getattr(self, ""_layer_"" + i)\n            func()\n\n        self.add_body(0, """")\n        for code in self.layers_codes.values():\n            self.add_body(0, code)\n\n        return self.body_code\n\n\n    @staticmethod\n    def _shapeToStr(shapes):\n        new_shape = filter(lambda x:x >- 1, [dim.size for dim in shapes.dim])\n        return \', \'.join(\'%s\' % i for i in new_shape)\n\n\n    @staticmethod\n    def is_valid_padding(auto_pad, pads):\n        """"""\n        different from utils.is_valid_padding\n        """"""\n        if auto_pad:\n            if auto_pad == \'VALID\':\n                return True\n            elif auto_pad.startswith(\'SAME\'):\n                return False\n            else:\n                raise ValueError(""Unknown padding type{}."".format(auto_pad))\n\n        else:\n            lens = len(pads)\n            assert lens % 2 == 0\n            for i in range(0, lens // 2):\n                if pads[i] != 0:\n                    return False\n            return True\n\n    @staticmethod\n    def is_ceil_mode(pads):\n        lens = len(pads)\n        for i in range(lens // 2 + 1, lens - 1):\n            if pads[i] == pads[i - lens // 2]:\n                return False\n        else:\n            return True\n\n\n    def _defuse_padding(self, IR_node):\n        auto_pad = IR_node.get_attr(\'auto_pad\')\n        if auto_pad:\n            input_node = self.parent_variable_name(IR_node)\n            if auto_pad == \'VALID\':\n                padding = False\n            elif auto_pad.startswith(""SAME""):\n                padding = True\n            else:\n                raise ValueError(""Unknown padding type [{}]."".format(auto_pad))\n\n            return input_node, padding\n\n        else:\n            padding = IR_node.get_attr(\'pads\')\n            if not is_valid_padding(padding):\n                dim = len(padding) // 2\n                padding_str = list()\n                for i in xrange(1, dim):\n                    padding_str.append((padding[i], padding[i + dim]))\n                input_node = IR_node.variable_name + \'_pad\'\n                self.add_body(1, ""{:<15} = cntk.pad({}, pattern={})"".format(\n                    input_node,\n                    self.parent_variable_name(IR_node),\n                    padding_str))\n\n            else:\n                input_node = self.parent_variable_name(IR_node)\n\n            return input_node, False\n\n\n\n    def emit_Conv(self, IR_node):\n        codes = list()\n        if self.weight_loaded:\n            self.used_layers.add(\'Conv\')\n            input_node, padding = self._defuse_padding(IR_node)\n\n            dim = len(IR_node.get_attr(\'strides\')) - 2\n            padding = [False] + [padding] * dim\n\n            if IR_node.type == \'DepthwiseConv\':\n                groups = IR_node.get_attr(\'kernel_shape\')[-2]\n                codes.append(""__weights_dict[\'{}\'][\'weights\'] = np.swapaxes(__weights_dict[\'{}\'][\'weights\'], -1, -2)"".format(\n                    IR_node.real_name, IR_node.real_name))\n            else:\n                groups = IR_node.get_attr(\'group\', 1)\n\n            codes.append(""{:<15} = convolution({}, is_transpose={}, strides={}, auto_padding={}, dilation={}, groups={}, name=\'{}\')"".format(\n                IR_node.variable_name,\n                input_node,\n                IR_node.type == \'ConvTranspose\',\n                tuple(IR_node.get_attr(\'strides\')[1:-1]),\n                padding,\n                tuple(IR_node.get_attr(\'dilations\', [1])),\n                groups,\n                IR_node.name))\n\n        else:\n            codes.append(""{:<15} = Convolution(name = \'{}\', num_filters = {}, filter_shape = ({}), strides = ({},), pad = {}, bias = {})({})\\n"".format(\n                IR_node.variable_name,\n                IR_node.name,\n                IR_node.get_attr(\'kernel_shape\')[-1],\n                \', \'.join(\'%s\' % i for i in IR_node.layer.attr[""kernel_shape""].list.i[:-2]),\n                \', \'.join(\'%s\' % i for i in IR_node.layer.attr[\'strides\'].list.i[1:-1]),\n                IR_node.get_attr(\'auto_pad\') != \'VALID\',\n                IR_node.get_attr(\'use_bias\'),\n                self.parent_variable_name(IR_node)))\n        return codes\n\n\n    def emit_Pool(self, IR_node):\n        input_node = self.IR_graph.get_node(IR_node.in_edges[0]).real_variable_name\n        if IR_node.layer.attr[\'global_pooling\'].b:\n            self.used_layers.add(\'GlobalPooling\')\n            code = ""{:<15} = global_pooling({}, \'{}\', name = \'{}\')"".format(\n                IR_node.variable_name,\n                input_node,\n                IR_node.get_attr(\'pooling_type\'),\n                IR_node.name)\n        else:\n            for e in IR_node.get_attr(\'dilations\', []):\n                assert e == 1\n\n            dim = len(IR_node.get_attr(\'kernel_shape\')) - 2\n            padding = not self.is_valid_padding(IR_node.get_attr(\'auto_pad\'), IR_node.get_attr(\'pads\'))\n            padding = [False] + [padding] * dim\n            ceil_out_dim = self.is_ceil_mode(IR_node.get_attr(\'pads\'))\n\n            pooling_type = IR_node.get_attr(\'pooling_type\')\n            if pooling_type == \'MAX\':\n                pooling_type = cntk.MAX_POOLING\n            elif pooling_type == \'AVG\':\n                pooling_type = cntk.AVG_POOLING\n            else:\n                raise ValueError\n\n            if self.weight_loaded:\n                self.used_layers.add(IR_node.type)\n                code = ""{:<15} = pooling({}, pooling_type={}, pooling_window_shape={}, strides={}, auto_padding={}, ceil_out_dim={})"".format(\n                    IR_node.variable_name,\n                    input_node,\n                    pooling_type,\n                    tuple(IR_node.get_attr(\'kernel_shape\')[1:-1]),\n                    tuple(IR_node.get_attr(\'strides\')[1:-1]),\n                    padding,\n                    ceil_out_dim\n                    )\n            else:\n                raise NotImplementedError\n        return code\n\n\n    def emit_UNKNOWN(self, IR_node):\n        print(IR_node.IR_layer.name)\n\n\n    def emit_DataInput(self, IR_node):\n\n        shape_str = self._shapeToStr(IR_node.IR_layer.attr[""shape""].shape)\n        \n        dtype_str = "", dtype = {}"".format(self.dtype_map[IR_node.layer.attr[\'dtype\'].type]) if \'dtype\' in IR_node.layer.attr else """"\n        code = ""{:<15} = cntk.sequence.input_variable(({},) {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            shape_str,\n            dtype_str,\n            IR_node.name)\n        return code\n\n\n    def emit_Dropout(self, IR_node):\n        parent = self.IR_graph.get_parent(IR_node.name, [0])\n        if self.phase == \'train\':\n            code = ""{:<15} = Dropout({}, name = \'{}\')({})"".format(\n                IR_node.variable_name,\n                1 - IR_node.get_attr(\'keep_prob\'),\n                IR_node.name,\n                parent.real_variable_name)\n            return code\n        else:\n            IR_node.real_name = parent.real_name\n\n\n    def emit_FullyConnected(self, IR_node):\n        input_node = self.parent_variable_name(IR_node)\n        if self.weight_loaded:\n            self.used_layers.add(IR_node.type)\n            code = ""{:<15} = dense({}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                input_node,\n                IR_node.name)\n\n        else:\n            code = ""{:<15} = Dense({}, bias = {}, name = \'{}\')({})"".format(\n                IR_node.variable_name,\n                IR_node.layer.attr[""units""].i,\n                IR_node.layer.attr[\'use_bias\'].b,\n                IR_node.name,\n                input_node)\n        return code\n\n\n    def emit_Flatten(self, IR_node):\n        code = ""{:<15} = ops.reshape({}, (-1,), name = \'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name)\n        return code\n\n\n    def emit_Reshape(self, IR_node):\n        code = ""{:<15} = cntk.reshape({}, shape={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            tuple(IR_node.get_attr(\'shape\')),\n            IR_node.name)\n        return code\n\n\n    def _emit_activation(self, IR_node, op_name):\n        code = ""{:<15} = layers.Activation(activation = {}, name = \'{}\')({})"".format(\n            IR_node.variable_name,\n            op_name,\n            IR_node.name,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Tanh(self, IR_node):\n        return self._emit_activation(IR_node, \'ops.tanh\')\n\n\n    def emit_Relu(self, IR_node):\n        return self._emit_activation(IR_node, \'ops.relu\')\n\n\n    def emit_Softmax(self, IR_node):\n        return self._emit_activation(IR_node, \'ops.softmax\')\n\n\n    def emit_Sigmoid(self, IR_node):\n        return self._emit_activation(IR_node, \'ops.sigmoid\')\n\n\n    def emit_RNNs(self, IR_node, func):\n        assert False\n\n\n    def emit_LSTM(self, IR_node):\n        return self.emit_RNNs(IR_node, ""LSTM"")\n\n    def emit_GRU(self, IR_node):\n        return self.emit_RNNs(IR_node, ""GRU"")\n\n\n    def emit_Add(self, IR_node):\n        if len(IR_node.in_edges) > 1:\n            inputs = \' + \'.join(self.parent_variable_name(IR_node, i) for i in IR_node.in_edges)\n            code = ""{:<15} = {}"".format(\n                IR_node.variable_name,\n                inputs)\n            return code\n\n\n    def emit_Sub(self, IR_node):\n        if len(IR_node.in_edges) > 1:\n            inputs = \' - \'.join(self.parent_variable_name(IR_node, i) for i in IR_node.in_edges)\n            code = ""{:<15} = {}"".format(\n                IR_node.variable_name,\n                inputs)\n            return code\n\n\n    def emit_Mul(self, IR_node):\n        if len(IR_node.in_edges) > 1:\n            inputs = \' * \'.join(self.parent_variable_name(IR_node, i) for i in IR_node.in_edges)\n            code = ""{:<15} = {}"".format(\n                IR_node.variable_name,\n                inputs)\n            return code\n\n\n    def emit_Constant(self, IR_node):\n        if IR_node.get_attr(\'value\'):\n            code = ""{:<15} = cntk.Constant(value={})"".format(\n            IR_node.variable_name, IR_node.get_attr(\'value\'))\n        else:\n            code = ""{:<15} = cntk.Constant(value=__weights_dict[\'{}\'][\'value\'])"".format(\n                IR_node.variable_name, IR_node.name)\n        return code\n\n\n    def emit_Concat(self, IR_node):\n        inputs = \', \'.join(self.parent_variable_name(IR_node, i) for i in IR_node.in_edges)\n        for s in IR_node.in_edges:\n            node = self.IR_graph.get_node(s)\n\n        code = ""{:<15} = cntk.splice({}, axis={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            inputs,\n            IR_node.get_attr(\'axis\') -1 , # why -1 ?\n            IR_node.name)\n        return code\n\n\n    def emit_BatchNorm(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        code = ""{:<15} = batch_normalization({}, epsilon={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'epsilon\'),\n            IR_node.name)\n        return code\n\n\n    def emit_Pad(self, IR_node):\n        if IR_node.get_attr(\'mode\') == \'constant\':\n            mode = \'mode = ops.CONSTANT_PAD, constant_value = {}\'.format(IR_node.get_attr(\'constant_values\', 0.0))\n        elif IR_node.get_attr(\'mode\') == \'reflect\':\n            mode = \'mode = ops.REFLECT_PAD\'\n        elif IR_node.get_attr(\'mode\') == \'SYMMETRIC\':\n            mode = \'mode = ops.SYMMETRIC_PAD\'\n        else:\n            assert False\n\n        padding = IR_node.get_attr(\'pads\')\n        padding = convert_onnx_pad_to_tf(padding)[1:]\n\n        code = ""{:<15} = ops.pad({}, pattern={}, {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            padding,\n            mode)\n        return code\n\n\n    def emit_Squeeze(self, IR_node):\n        IR_node.real_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n\n\n    def emit_Log(self, IR_node):\n        code = ""{:<15} = _cntk.log({}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name)\n        return code\n\n\n    def emit_Exp(self, IR_node):\n        code = ""{:<15} = _cntk.exp({}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name)\n        return code\n\n\n    def emit_Embedding(self, IR_node):\n        \n        codes = list()\n        codes.append(""{}_P = cntk.one_hot({}, __weights_dict[\'{}\'][\'weights\'].shape[0])"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name))\n        \n        codes.append(""{:<15} = layers.Embedding(weights=__weights_dict[\'{}\'][\'weights\'])({}_P)"".format(\n            IR_node.variable_name,\n            # IR_node.get_attr(\'output_dim\'),\n            IR_node.name,\n            IR_node.variable_name))\n\n        return codes\n\n\n    def emit_Reciprocal(self, IR_node):\n        code = ""{:<15} = _cntk.reciprocal({}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name)\n        return code\n\n\n    def emit_ReduceMean(self, IR_node):\n        code = ""{:<15} = ops.reduce_mean({}, axis = ({}), name = \'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            \', \'.join(\'%s\' % (i - 1) for i in IR_node.get_attr(\'axes\')),\n            IR_node.name)\n        return code\n\n\n    def emit_LRN(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        output_name = IR_node.variable_name\n        input_name = self.parent_variable_name(IR_node)\n        IR_name = IR_node.name\n        size = IR_node.get_attr(\'size\')\n        depth_radius = int(size / 2)\n        alpha = IR_node.get_attr(\'alpha\')\n        #alpha = alpha / size\n        beta = IR_node.get_attr(\'beta\')\n        bias = IR_node.get_attr(\'bias\')\n\n        code = ""{:<15} = lrn({}, k={}, n={}, alpha={}, beta={}, name=\'{}\')"".format(\n            output_name,\n            input_name,\n            bias,\n            depth_radius + 1,\n            alpha,\n            beta,\n            IR_name)\n        return code\n\n    # ??\n    def emit_LeakRelu(self, IR_node):\n        code = ""{:<15} = _cntk.relu({}) - {} * _cntk.relu(-{})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'alpha\'),\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_LeakyRelu(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        code = ""{:<15} = _leaky_relu({}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'alpha\'),\n            IR_node.name)\n        return code\n\n\n    def emit_UpSampling2D(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        code = ""{:<15} = Upsampling2D({}, stride = {}, name = \'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'scales\')[0],\n            IR_node.name)\n        return code\n\n\n    def emit_ConvTranspose(self, IR_node):\n        return self.emit_Conv(IR_node)\n\n\n    def emit_yolo(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)\n        )\n        # print(IR_node.layer)\n        self.yolo_parameter = [IR_node.get_attr(\'anchors\'),\n            IR_node.get_attr(\'classes\'),\n            IR_node.get_attr(""ignore_thresh""),\n            IR_node.get_attr(""jitter"")]\n        # assert False\n        return code\n\n\n    def emit_Crop(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        output_shape = IR_node.get_attr(\'_output_shapes\')[0]\n        output_shape = shape_to_list(output_shape)[1:]\n        code = ""{:<15} = _crop({}, {}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'border\')[:2],\n            output_shape,\n            IR_node.real_name)\n        return code\n\n\n    def emit_Relu6(self, IR_node):\n        codes = list()\n        codes.append(self.emit_Relu(IR_node))\n        codes.append(""{:<15} = cntk.clip({}, 0, 6, name=\'{}_clip\')"".format(\n            IR_node.variable_name + ""_clip"",\n            IR_node.variable_name,\n            IR_node.name\n        ))\n        IR_node.real_name = IR_node.name + \'_clip\'\n        return codes\n\n\n    def emit_DepthwiseConv(self, IR_node):\n        return self.emit_Conv(IR_node)\n\n\n    # def emit_Unstack(self, IR_node):\n        # num_str = ""{}.shape[{}]"".format(self.parent_variable_name(IR_node), IR_node.get_attr(\'axis\'))\n        # axis = IR_node.get_attr(\'axis\')\n        # parent_variable_shape = ""list({}.shape)"".format(self.parent_variable_name(IR_node) \n        #         if self.IR_graph.get_parent(IR_node.name, [0]).type != \'Embedding\' \n        #             else self.parent_variable_name(IR_node)+\'.E\')\n        # if axis==1:\n        #     shape_str = ""tuple([{}[0]*{}[{}], 1].extend({}[{}+1:]))"".format(\n        #         parent_variable_shape,\n        #         parent_variable_shape,\n        #         str(axis),\n        #         parent_variable_shape,\n        #         str(axis))\n        # else:\n        #     shape_str = ""tuple([{}[0]*{}[{}]].extend({}[1:{}]).append(1).extend({}[{}+1:]))"".format(\n        #         parent_variable_shape,\n        #         parent_variable_shape,\n        #         str(axis),\n        #         parent_variable_shape,\n        #         str(axis),\n        #         parent_variable_shape,\n        #         str(axis))\n        # code = ""{:<15} = cntk.reshape({}, {}, name=\'{}\')"".format(\n        #     IR_node.variable_name, \n        #     self.parent_variable_name(IR_node), \n        #     shape_str,\n        #     IR_node.variable_name)\n        # code = ""{: <15} = cntk.reshape({}, {}.shape, name=\'{}\')"".format(\n        #     IR_node.variable_name,\n        #     self.parent_variable_name(IR_node),\n        #     self.parent_variable_name(IR_node),\n        #     IR_node.name\n        # )\n        # return code\n\n\n    def emit_Shape(self, IR_node):\n        parent_node = self.IR_graph.get_parent(IR_node.name, [0])\n        code = ""{:<15} = {}.shape"".format(\n            IR_node.variable_name, \n            self.parent_variable_name(IR_node) if parent_node.type != \'Embedding\' else self.parent_variable_name(IR_node)+"".E"")\n        return code\n\n\n    def emit_Slice(self, IR_node):\n        starts = IR_node.get_attr(\'starts\')\n        if len(starts) > 1:\n            starts = [starts[0], starts[-1]] + starts[1:-1]\n        ends = IR_node.get_attr(\'ends\')\n        if len(ends) > 1:\n            ends = [ends[0], ends[-1]] + ends[1:-1]\n        extra_str = """"\n        for idx, _ in enumerate(starts):\n            if idx:\n                extra_str += "", ""\n            extra_str += ""{}:"".format(starts[idx])\n            if ends[idx]:\n                extra_str += ""{}"".format(ends[idx])\n        code = ""{:<15} = {}[{}]"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            extra_str)\n        return code\n\n\n    def emit_Split(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        axis = IR_node.get_attr(\'axis\')\n        split_num = IR_node.get_attr(\'split\')\n        code = ""{:<15} = split(input={}, axis={}, split_num={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            str(axis),\n            str(split_num))\n        \n        return code\n\n\n    # def emit_Fill(self, IR_node):\n    #     code = ""{:<15} = cntk.Constant({}, {}, name=\'{}\')"".format(\n    #         IR_node.variable_name,\n    #         IR_node.get_attr(\'value\'),\n    #         self.parent_variable_name(IR_node),\n    #         IR_node.name)\n    #     return code\n\n\n    def emit_Unsqueeze(self, IR_node):\n        code = ""{:<15} = cntk.expand_dims({}, axis={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'axes\')[0],\n            IR_node.name)\n        return code\n\n\n    def emit_Scope(self, IR_node):\n        pattern = IR_node.pattern\n        if pattern not in self.naive_scope_pattern and re.sub(r\'(_\\d+)*$\', \'\', IR_node.pattern) not in self.naive_scope_pattern:\n            func = getattr(self, ""_emit_"" + pattern)\n            code = func(IR_node)\n        else:\n            code = ""{:<15} = __{}({})"".format(\n                IR_node.real_variable_name,\n                IR_node.pattern,\n                \', \'.join(self.parent_variable_name(IR_node, s) for s in IR_node.in_edges))\n            self._gen_scope_code(IR_node)\n        return code\n\n\n    def _gen_scope_code(self, scope_node):\n\n        def _scope_func(scope_name, params, code, return_var):\n            code = """"""\ndef __{}({}):\n{}\n    return {}\n    """""".format(scope_name, params, code, \', \'.join(return_var))\n            return code\n\n        if not self.layers_codes.get(scope_node.pattern, None):\n            body_code = str()\n            for node_name in scope_node.topology_list:\n                node = self.IR_graph.get_node(node_name)\n                node_type = node.type\n\n                if hasattr(self, ""emit_"" + node_type):\n                    func = getattr(self, ""emit_"" + node_type)\n                    line = func(node)\n                    if line != None:\n                        body_code += ""    "" + line + \'\\n\'\n                else:\n                    print(""CntkEmitter has not supported operator [%s]."" % (node_type))\n                    self.emit_UNKNOWN(node)\n\n            # param_code does not need parameter slice.\n            input_params = scope_node.input_params\n            param_code = \', \'.join(input_params)\n            function_code = _scope_func(scope_node.pattern, param_code, body_code, scope_node.return_variables)\n\n            self.layers_codes[scope_node.pattern] = function_code\n\n\n    def _emit_h_zero(self, IR_node):\n        code = ""{:<15} = cntk.Constant({}, (1, {}))"".format(\n            IR_node.variable_name,\n            IR_node.get_attr(\'fill_value\'),\n            IR_node.get_attr(\'fill_size\'))\n        return code\n\n\n    def _layer_Crop(self):\n        self.add_body(0, \'\'\'\ndef _crop(input, border, output_shape, **kwargs):\n    dim = len(output_shape)\n    output_shape = [output_shape[-1]] + output_shape[:-1]\n    ref_tensor = np.zeros(shape=output_shape, dtype=np.float32)\n\n    input = cntk.transpose(input, [dim - 1] + list(range(0, dim - 1)))\n    layer = cntk.crop_manual(node_input=input, node_referent=ref_tensor, offset_x=border[0], offset_y=border[1])\n    layer = cntk.transpose(layer, list(range(1, dim)) + [0])\n    return layer\n\'\'\')\n\n\n    def _layer_LeakyRelu(self):\n        self.add_body(0, \'\'\'\ndef _leaky_relu(x, leak, name):\n    return cntk.param_relu(cntk.constant((np.ones(x.shape)*leak).astype(np.float32)), x, name = name)\n\'\'\')\n\n\n    def _layer_yolo(self):\n        self.add_body(0, \'\'\'\ndef yolo_parameter():\n    return {}\n\'\'\'.format(self.yolo_parameter))\n\n\n    def _layer_upsample(self):\n        self.add_body(0, \'\'\'\ndef Upsampling2D(x, stride, name):\n    assert stride == 2\n    xr = cntk.reshape(x, (x.shape[0], 1, x.shape[1], 1, x.shape[2]))\n    xx = cntk.splice(xr, xr, axis = -2)\n    xy = cntk.splice(xx, xx, axis = -4)\n    r = cntk.reshape(xy, (x.shape[0] * 2, x.shape[1] * 2, x.shape[2]), name = name)\n    return r\n\'\'\')\n\n\n    def _layer_LRN(self):\n        self.add_body(0, """"""\ndef lrn(input, **kwargs):\n    dim = len(input.output.shape)\n    input = cntk.transpose(input, [dim - 1] + list(range(0, dim - 1)))\n    layer = BlockApiSetup.lrn(**kwargs)(input)\n    layer = cntk.transpose(layer, list(range(1, dim)) + [0])\n    return layer\n"""""")\n\n\n    def _layer_FullyConnected(self):\n        self.add_body(0, """"""\ndef dense(input, name, **kwargs):\n    w = __weights_dict[name][\'weights\']\n    b = __weights_dict[name][\'bias\'] if \'bias\' in __weights_dict[name] else None\n    return BlockApiSetup.linear(output_shape=w.shape[1], input_shape=w.shape[0], scale_init=w, bias_init=b, name=name, **kwargs)(input)\n"""""")\n\n\n    def _layer_Conv(self):\n        self.add_body(0, """"""\ndef convolution(input, is_transpose, name, **kwargs):\n    dim = __weights_dict[name][\'weights\'].ndim\n\n    if is_transpose:\n        weight = np.transpose(__weights_dict[name][\'weights\'], [dim - 2, dim - 1] + list(range(0, dim - 2)))\n        kwargs.pop(\'groups\', None)\n    else:\n        weight = np.transpose(__weights_dict[name][\'weights\'], [dim - 1, dim - 2] + list(range(0, dim - 2)))\n    w = cntk.Parameter(init=weight, name=name + \'_weight\')\n\n    input = cntk.transpose(input, [dim - 2] + list(range(0, dim - 2)))\n\n    if is_transpose:\n        layer = ops.convolution_transpose(w, input, **kwargs)\n    else:\n        layer = ops.convolution(w, input, **kwargs)\n    if \'bias\' in __weights_dict[name]:\n        bias = np.reshape(__weights_dict[name][\'bias\'], [-1] + [1] * (dim - 2))\n        b = cntk.Parameter(init=bias, name=name + \'_bias\')\n        layer = layer + b\n    layer = cntk.transpose(layer, list(range(1, dim - 1)) + [0])\n    return layer\n"""""")\n\n\n    def _layer_Pool(self):\n        self.add_body(0, """"""\ndef pooling(input, **kwargs):\n    dim = len(input.output.shape)\n    input = cntk.transpose(input, [dim - 1] + list(range(0, dim - 1)))\n    layer = ops.pooling(input, **kwargs)\n    layer = cntk.transpose(layer, list(range(1, dim)) + [0])\n    return layer\n"""""")\n\n\n    def _layer_GlobalPooling(self):\n        self.add_body(0, """"""\ndef global_pooling(input, type, **kwargs):\n    dim = len(input.output.shape)\n    input = cntk.transpose(input, [dim - 1] + list(range(0, dim - 1)))\n    layer = layers.GlobalMaxPooling(**kwargs)(input) if type == \'MAX\' else layers.GlobalAveragePooling(**kwargs)(input)\n    layer = cntk.transpose(layer, list(range(1, dim)) + [0])\n    return layer\n"""""")\n\n\n    def _layer_BatchNorm(self):\n        self.add_body(0, """"""\ndef batch_normalization(input, name, epsilon, **kwargs):\n    mean = cntk.Parameter(init = __weights_dict[name][\'mean\'],\n        name = name + ""_mean"")\n    var = cntk.Parameter(init = __weights_dict[name][\'var\'],\n        name = name + ""_var"")\n\n    layer = (input - mean) / cntk.sqrt(var + epsilon)\n    if \'scale\' in __weights_dict[name]:\n        scale = cntk.Parameter(init = __weights_dict[name][\'scale\'],\n            name = name + ""_scale"")\n        layer = scale * layer\n\n    if \'bias\' in __weights_dict[name]:\n        bias = cntk.Parameter(init = __weights_dict[name][\'bias\'],\n            name = name + ""_bias"")\n        layer = layer + bias\n\n    return layer\n"""""")\n\n\n    def _layer_Split(self):\n        self.add_body(0, """"""\ndef split(input, axis, split_num):\n        split_len = input.shape[axis]\n        res = []\n        st = 0\n        for i in range(split_num):\n            ed = st + split_len//split_num\n            res.append(cntk.slice(input, axis, st, ed))\n            st += split_len//split_num\n\n        return res\n        """""")\n'"
mmdnn/conversion/cntk/cntk_graph.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport cntk as _cntk\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\n\n\nclass CntkGraphNode(GraphNode):\n\n    def __init__(self, layer):\n        super(CntkGraphNode, self).__init__(layer)\n\n\n    @property\n    def name(self):\n        return self.layer.uid\n\n\n    @property\n    def type(self):\n        if hasattr(self.layer, \'op_name\'):\n            return self.layer.op_name\n        elif self.layer.is_input:\n            return ""DataInput""\n        else:\n            raise NotImplementedError()\n\n\n    @property\n    def cntk_layer(self):\n        return self.layer\n\n\n    def get_attr(self, name, default_value=None):\n        if self.layer.is_block:\n            return self.layer.block_root.attributes[name]\n        else:\n            return self.layer.attributes[name]\n\n\nclass CntkGraph(Graph):\n\n    def __init__(self, model):\n        # sanity check.\n        pass\n\n        self.weights = dict()\n        self.visited = set()\n        super(CntkGraph, self).__init__(model)\n\n\n    def _traverse_graph(self, son_node):\n        if not son_node.uid in self.visited:\n            self.visited.add(son_node.uid)\n\n            if son_node.is_block:\n                inputs = [input for _, input in son_node.block_arguments_mapping]\n\n            else:\n                inputs = son_node.inputs\n\n            for input_node in inputs:\n                if input_node.is_output:\n                    input_node = input_node.owner\n                    if not input_node.uid in self.layer_map:\n                        self.layer_map[input_node.uid] = CntkGraphNode(input_node)\n                    self._make_connection(input_node.uid, son_node.uid)\n                    self._traverse_graph(input_node)\n\n                elif input_node.is_input:\n                    if not input_node.uid in self.layer_map:\n                        self.layer_map[input_node.uid] = CntkGraphNode(input_node)\n                    self._make_connection(input_node.uid, son_node.uid)\n\n                elif input_node.is_placeholder:\n                    raise NotImplementedError(""PlaceHolder of placeholder is not supported."")\n\n\n    def build(self):\n        if len(self.model.outputs) > 1:\n            for idx, output in enumerate(self.model.outputs):\n                if len(output.shape) > 0:\n                    eval_node = idx\n                    break\n\n            output = self.model[eval_node].owner\n        else:\n            output = self.model.outputs[0].owner\n\n        self.layer_map[output.uid] = CntkGraphNode(output)\n        self._traverse_graph(output)\n\n        super(CntkGraph, self).build()\n\n""""""\n    def __traverse_graph(self, node):\n        if node.uid in self.visited:\n            return\n\n        self.visited.add(node.uid)\n\n        if isinstance(node, _cntk.Function) and node.is_block:\n            composite = node.block_root\n\n            # BlockFunction node\n            mapping = node.block_arguments_mapping\n\n            # redirect the composite\'s inputs to the true inputs\n            stack.extend([(actual_input, depth-1) for _, actual_input in mapping]) # traverse into actual composite inputs\n            visited |= {comp_input.uid for comp_input, _ in mapping}    # don\'t traverse into the mapped-away inputs\n            stack.append((composite, depth-1))\n            # BlockFunctions are short-circuited, and not added to accum[]\n        try:\n            # Function node\n            stack = list((i, depth) for i in node.root_function.inputs) + stack\n        except AttributeError:\n            # OutputVariable node\n            try:\n                if node.is_output:\n                    stack.insert(0, (node.owner, depth))\n                    visited.add(node.uid)\n                    continue\n            except AttributeError:\n                pass\n\n        if visitor(node):\n            if isinstance(node, Variable):\n                if node.is_parameter:\n                    node = node.as_parameter()\n                elif node.is_constant:\n                    node = node.as_constant()\n\n            accum.append(node)\n\n        visited.add(node.uid)\n\n\n    # def build(self):\n    #     _traverse_graph(self, self.model.root_function)\n    #     super(CntkGraph, self).build()\n""""""'"
mmdnn/conversion/cntk/cntk_parser.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\nimport numpy as np\nfrom six.moves import xrange\nimport cntk as _cntk\nfrom mmdnn.conversion.cntk.cntk_graph import CntkGraph\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\n\n\nclass CntkParser(Parser):\n\n    dtype_map = {\n        0 : graph_pb2.DT_UNDEFINED,\n        np.float32 : graph_pb2.DT_FLOAT32,\n        np.float64 : graph_pb2.DT_FLOAT64,\n        3 : graph_pb2.DT_INT32,\n        4 : graph_pb2.DT_UINT8,\n        5 : graph_pb2.DT_INT16,\n        6 : graph_pb2.DT_INT8,\n        7 : graph_pb2.DT_STRING,\n        9 : graph_pb2.DT_INT64\n    }\n\n\n    @property\n    def src_graph(self):\n        return self.cntk_graph\n\n\n    def __init__(self, model, dest_nodes = None):\n        super(CntkParser, self).__init__()\n\n        if not os.path.exists(model):\n            raise ValueError(\'Cntk model [{}] can not be found!\'.format(model))\n        model = _cntk.Function.load(model)\n        self.weight_loaded = True\n\n        # Build network graph\n        self.cntk_graph = CntkGraph(model)\n        self.cntk_graph.build()\n\n\n    @staticmethod\n    def _convert_padding_to_IR(kernel_shape, auto_pad):\n        lower = []\n        upper = []\n        for idx in range(0, len(kernel_shape)):\n            if auto_pad[idx] == False:\n                lower += [0]\n                upper += [0]\n            else:\n                q = kernel_shape[idx] // 2\n                lower += [q] if kernel_shape[idx] % 2 else [q - 1]\n                upper += [q]\n\n        return [0] + lower + [0, 0] + upper + [0]\n\n\n    def _convert_identity_operation(self, source_node, start_edge=0, end_edge=None, new_op=None, shape_transpose=True):\n        IR_node = self.IR_graph.node.add()\n        CntkParser._copy_and_reop(source_node, IR_node, new_op, shape_transpose)\n        self.convert_inedge(source_node, IR_node, start_edge, end_edge)\n        return IR_node\n\n\n    def gen_IR(self):\n        for layer in self.src_graph.topological_sort:\n            current_node = self.src_graph.get_node(layer)\n            node_type = current_node.type\n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n            else:\n                self.rename_UNKNOWN(current_node)\n\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op=None, shape_transpose=False):\n        if new_op == None: new_op = source_node.type\n        IR_node.name = source_node.real_name\n        IR_node.op = new_op\n\n        kwargs = {}\n\n        if hasattr(source_node.layer, \'dtype\'):\n            assert source_node.layer.dtype in CntkParser.dtype_map, \'type [{}] is unknown.\'.format(source_node.layer.dtype)\n            IR_node.attr[""dtype""].type = CntkParser.dtype_map[source_node.layer.dtype]\n\n        if hasattr(source_node.layer, \'shape\'):\n            shape =  (-1,) + source_node.layer.shape\n            if shape_transpose:\n                shape = CntkParser.channel_first_shape_to_IR(shape)\n            shape = list_to_shape(shape)\n            kwargs[\'_output_shapes\'] = [shape]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def _fuse_bias_node(self, source_node):\n        next_node = self.src_graph.get_son(source_node.name, [0])\n        if next_node is None or next_node.type != \'Plus\' or not next_node.layer.parameters:\n            return False\n\n        next_node.covered = True\n        next_node.real_name = source_node.real_name\n        B = next_node.layer.parameters[0].asarray()\n        self.set_weight(source_node.name, \'bias\', B)\n\n        return True\n\n\n    @staticmethod\n    def _print_layer(source_node):\n        print (""Layer: "", source_node.layer)\n        print (""Parameters: "", source_node.layer.parameters)\n        print (""Attributes: "", source_node.layer.attributes)\n        for in_node in source_node.layer.inputs:\n            print (in_node)\n\n\n    def rename_UNKNOWN(self, source_node):\n        print(""Cntk Parser has not supported operator [%s] with name [%s].""\n              % (source_node.type, source_node.name))\n\n        self._print_layer(source_node)\n        assert False\n\n\n    @staticmethod\n    def get_ndarray(variable):\n        if variable.is_parameter:\n            return variable.as_parameter().asarray()\n\n        elif variable.is_constant:\n            return variable.as_constant().asarray()\n\n        else:\n            raise ValueError(""Unknown variable [{}]."".format(variable))\n\n\n    @staticmethod\n    def _get_attribute(source_node, attribute_name):\n        if attribute_name in source_node.attributes:\n            return source_node.attributes\n\n        node = source_node.block_root\n        while not attribute_name in node.attributes:\n            node = node.inputs[0].owner\n\n        return node.attributes\n\n\n    def rename_Convolution(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=""Conv"")\n\n        for input in source_node.layer.inputs:\n            if input.name.endswith(""W""):\n                W = self.get_ndarray(input)\n                break\n\n        W = self.channel_first_conv_kernel_to_IR(W)\n        self.set_weight(source_node.name, \'weights\', W)\n\n        attributes = CntkParser._get_attribute(source_node.layer, \'strides\')\n\n        kwargs = dict()\n        kwargs[\'strides\'] = [1] + list(attributes[\'strides\'])[1:] + [1]\n        kwargs[\'dilations\'] = [1] + list(attributes[\'dilation\'])[1:] + [1]\n        kwargs[\'kernel_shape\'] = list(W.shape)\n        padding = attributes[\'autoPadding\'][1:]\n\n        for pad in padding:\n            assert pad == padding[0]\n\n        kwargs[\'auto_pad\'] = \'SAME_LOWER\' if padding[0] else \'VALID\'\n        kwargs[\'pads\'] = self._convert_padding_to_IR(kwargs[\'kernel_shape\'][:-2], padding)\n\n        kwargs[\'use_bias\'] = self._fuse_bias_node(source_node)\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_ReLU(self, source_node):\n        self._convert_identity_operation(source_node, new_op=\'Relu\')\n\n\n    def rename_Relu6(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Plus(self, source_node):\n        if not source_node.covered:\n            assert not source_node.layer.parameters\n            IR_node = self._convert_identity_operation(source_node, new_op=\'Add\')\n\n\n    def rename_Minus(self, source_node):\n        if not source_node.covered:\n            assert not source_node.layer.parameters\n            self._convert_binary_operator(source_node, new_op=\'Sub\')\n\n\n    def rename_Sub(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Reshape(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        new_shape = source_node.get_attr(\'newShape\')\n        kwargs = {\'shape\' : self.channel_first_shape_to_IR(new_shape)}\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Times(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'FullyConnected\')\n\n        W = source_node.layer.parameters[0].asarray().squeeze()\n        self.set_weight(source_node.name, \'weights\', W)\n\n        kwargs = dict()\n        kwargs[\'units\'] = W.shape[-1]\n        kwargs[\'use_bias\'] = self._fuse_bias_node(source_node)\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_MaxPooling(self, source_node):\n        if source_node.layer.is_block:\n            source_node.layer = source_node.layer.block_root.owner\n\n        self.rename_Pooling(source_node)\n\n\n    def rename_AveragePooling(self, source_node):\n        self.rename_Pooling(source_node)\n\n    def rename_Slice(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Slice\')\n        kwargs = dict()\n        kwargs[\'axis\'] = source_node.get_attr(\'axis\')[-1] + 1\n        kwargs[\'ends\'] = source_node.get_attr(\'endIndex\')\n        kwargs[\'starts\'] = source_node.get_attr(\'beginIndex\')\n        kwargs[\'strides\'] = source_node.get_attr(\'sliceStrides\')\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Splice(self, source_node):\n        if len(source_node.in_edges) == 1:\n            source_node.in_edges.append(source_node.in_edges[0])\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Concat\')\n        assign_IRnode_values(IR_node, {\'axis\' : source_node.get_attr(\'axis\')[-1] + 1})\n\n\n    def rename_StableSigmoid(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Sigmoid\')\n\n    def rename_BinaryCrossEntropy(self, source_node):\n        pass\n\n    def rename_Pooling(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Pool\')\n        dim = len(IR_node.attr[\'_output_shapes\'].list.shape[0].dim)\n        kwargs = {}\n\n        # strides\n        kwargs[\'strides\'] = list(source_node.get_attr(\'strides\')) + [1]\n        if len(kwargs[\'strides\']) < dim:\n            kwargs[\'strides\'] = [1] + kwargs[\'strides\']\n\n        # window_shape\n        kwargs[\'kernel_shape\'] = list(source_node.get_attr(\'poolingWindowShape\')) + [1]\n        if len(kwargs[\'kernel_shape\']) < dim:\n            kwargs[\'kernel_shape\'] = [1] + kwargs[\'kernel_shape\']\n\n        # pool type\n        pool_type = source_node.get_attr(\'poolingType\')\n        if pool_type == _cntk.MAX_POOLING:\n            kwargs[\'pooling_type\'] = \'MAX\'\n        elif pool_type == _cntk.AVG_POOLING:\n            kwargs[\'pooling_type\'] = \'AVG\'\n        else:\n            raise ValueError(""Unknown pooling type [{}]."".format(pool_type))\n\n        # padding\n        padding = source_node.get_attr(\'autoPadding\')\n        if len(padding) >= dim - 1:\n            padding = padding[1:]\n        elif len(padding) < dim - 2:\n            padding.extend([padding[-1]] * (dim - len(padding) - 2))\n        for pad in padding:\n            assert pad == padding[-1]\n        kwargs[\'auto_pad\'] = \'SAME_LOWER\' if padding[0] else \'VALID\'\n        kwargs[\'pads\'] = self._convert_padding_to_IR(kwargs[\'kernel_shape\'][1:-1], padding)\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_DataInput(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'DataInput\')\n        shape = [-1] + list(source_node.layer.shape)\n        assign_IRnode_values(IR_node, {\'shape\' : list_to_shape(self.channel_first_shape_to_IR(shape))})\n\n\n    def rename_BatchNormalization(self, source_node):\n        kwargs = dict()\n        kwargs[\'scale\'] = False\n        kwargs[\'bias\'] = False\n        for param in source_node.layer.inputs:\n            if param.name.endswith(\'scale\'):\n                self.set_weight(source_node.name, \'scale\', self.get_ndarray(param).flatten())\n                kwargs[\'scale\'] = True\n\n            elif param.name.endswith(\'bias\'):\n                self.set_weight(source_node.name, \'bias\', self.get_ndarray(param).flatten())\n                kwargs[\'bias\'] = True\n\n            elif param.name.lower().endswith(\'mean\'):\n                self.set_weight(source_node.name, \'mean\', self.get_ndarray(param).flatten())\n\n            elif param.name.lower().endswith(\'variance\'):\n                self.set_weight(source_node.name, \'var\', self.get_ndarray(param).flatten())\n\n        IR_node = self._convert_identity_operation(source_node, end_edge=1, new_op=\'BatchNorm\')\n        kwargs[\'epsilon\'] = source_node.get_attr(\'epsilon\')\n        kwargs[\'axis\'] = -1\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def _add_constant_node(self, constant_node, IR_node):\n        new_node = self.IR_graph.node.add()\n        new_node.name = constant_node.uid\n        new_node.op = \'Constant\'\n        value = np.atleast_1d(self.get_ndarray(constant_node))\n        self.set_weight(new_node.name, \'value\', value)\n        IR_node.input.append(new_node.name)\n\n\n    def _convert_binary_operator(self, source_node, new_op):\n        IR_node = self._convert_identity_operation(source_node, new_op=new_op)\n        for in_node in source_node.layer.inputs:\n            if in_node.is_constant:\n                self._add_constant_node(in_node, IR_node)\n\n\n    def rename_ElementTimes(self, source_node):\n        if source_node.layer.inputs[0] == source_node.layer.inputs[1]:\n            # TODO: Handle square\n            pass\n\n        self._convert_binary_operator(source_node, \'Mul\')\n\n\n    def rename_Log(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Exp(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Reciprocal(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Dropout(self, source_node):\n        # self._print_layer(source_node)\n        # print (source_node.name)\n        # print (self.src_graph.get_parent(source_node.name, [0]).real_name)\n        # assert False\n        source_node.real_name = self.src_graph.get_parent(source_node.name, [0]).real_name\n\n\n    def rename_Dense(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'FullyConnected\', shape_transpose=False)\n        for param in source_node.layer.inputs:\n            if param.name.endswith(\'W\'):\n                w = np.squeeze(self.get_ndarray(param))\n                if w.ndim > 2:\n                    w = np.transpose(w, list(range(1, w.ndim - 1)) + [0, -1])\n                    w = np.reshape(w, [-1, w.shape[-1]])\n                self.set_weight(source_node.name, \'weights\', w)\n                assign_IRnode_values(IR_node, {\'units\' : w.shape[-1] })\n\n            elif param.name.endswith(\'b\'):\n                self.set_weight(source_node.name, \'bias\', self.get_ndarray(param))\n                assign_IRnode_values(IR_node, {\'use_bias\' : True })\n\n\n    def rename_Convolution2D(self, source_node):\n        assert source_node.layer.is_block\n\n        # Convolution\n        kwargs = dict()\n        conv_IR_node = self.IR_graph.node.add()\n        conv_node = source_node.layer.block_root.inputs[0].owner.inputs[0].owner\n\n        conv_IR_node.name = conv_node.uid\n        conv_IR_node.op = \'Conv\'\n        conv_IR_node.input.append(self.get_parent(source_node.name, [0]).real_name)\n\n        # Kernel\n        conv_weight = source_node.layer.block_root.inputs[0].owner.inputs[0].owner.inputs[0]\n        conv_weight = self.get_ndarray(conv_weight)\n        W = self.channel_first_conv_kernel_to_IR(conv_weight)\n        self.set_weight(conv_IR_node.name, \'weights\', W)\n\n        # Attributes\n        conv_attr = source_node.layer.block_root.inputs[0].owner.inputs[0].owner.attributes\n\n        kwargs[\'strides\'] = [1] + list(conv_attr[\'strides\'])[1:] + [1]\n        kwargs[\'dilations\'] = [1] + list(conv_attr[\'dilation\'])[1:] + [1]\n        kwargs[\'kernel_shape\'] = list(W.shape)\n        padding = conv_attr[\'autoPadding\'][1:]\n\n        for pad in padding:\n            assert pad == padding[0]\n\n        kwargs[\'auto_pad\'] = \'SAME_LOWER\' if padding[0] else \'VALID\'\n        kwargs[\'pads\'] = self._convert_padding_to_IR(kwargs[\'kernel_shape\'][:-2], padding)\n\n        kwargs[\'use_bias\'] = True\n\n        assign_IRnode_values(conv_IR_node, kwargs)\n\n        # Bias\n        plus = source_node.layer.block_root.inputs[0].owner.inputs[1]\n        plus = np.squeeze(self.get_ndarray(plus))\n        self.set_weight(conv_IR_node.name, \'bias\', plus)\n\n        # Activation\n        activation = source_node.layer.block_root.owner.op_name\n\n        activation_IR = self.IR_graph.node.add()\n        activation_IR.name = source_node.name\n        activation_IR.input.append(conv_IR_node.name)\n        if (activation == \'ReLU\'):\n            activation_IR.op = \'Relu\'\n        else:\n            raise ValueError()\n\n\n    def rename_Activation(self, source_node):\n        assert source_node.layer.is_block\n\n        op = source_node.layer.root_function.owner.name\n\n        if op.startswith(\'relu\'):\n            new_op= \'Relu\'\n        else:\n            raise ValueError()\n\n        self._convert_identity_operation(source_node, new_op=new_op)'"
mmdnn/conversion/cntk/saver.py,0,"b""def save_model(MainModel, network_filepath, weight_filepath, dump_filepath):\n    model = MainModel.KitModel(weight_filepath)\n    model.save(dump_filepath)\n    print('CNTK model file is saved as [{}], generated by [{}.py] and [{}].'.format(\n        dump_filepath, network_filepath, weight_filepath))\n"""
mmdnn/conversion/common/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/common/utils.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import division\nimport os\nimport sys\nimport numpy as np\nfrom six import text_type, binary_type, integer_types\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\n\n\n__all__ = [""assign_IRnode_values"", ""convert_onnx_pad_to_tf"", \'convert_tf_pad_to_onnx\',\n           \'compute_tf_same_padding\', \'is_valid_padding\', \'download_file\',\n           \'shape_to_list\', \'list_to_shape\']\n\n\ndef assign_attr_value(attr, val):\n    from mmdnn.conversion.common.IR.graph_pb2 import TensorShape\n    \'\'\'Assign value to AttrValue proto according to data type.\'\'\'\n    if isinstance(val, bool):\n        attr.b = val\n    elif isinstance(val, integer_types):\n        attr.i = val\n    elif isinstance(val, float):\n        attr.f = val\n    elif isinstance(val, binary_type) or isinstance(val, text_type):\n        if hasattr(val, \'encode\'):\n            val = val.encode()\n        attr.s = val\n    elif isinstance(val, TensorShape):\n        attr.shape.MergeFromString(val.SerializeToString())\n    elif isinstance(val, list):\n        if not val: return\n        if isinstance(val[0], integer_types):\n            attr.list.i.extend(val)\n        elif isinstance(val[0], TensorShape):\n            attr.list.shape.extend(val)\n        elif isinstance(val[0], float):\n            attr.list.f.extend(val)\n        else:\n            raise NotImplementedError(\'AttrValue cannot be of list[{}].\'.format(val[0]))\n    elif isinstance(val, np.ndarray):\n        assign_attr_value(attr, val.tolist())\n    else:\n        raise NotImplementedError(\'AttrValue cannot be of %s\' % type(val))\n\n\ndef assign_IRnode_values(IR_node, val_dict):\n    for name, val in val_dict.items():\n        assign_attr_value(IR_node.attr[name], val)\n\n\n# For padding\ndef convert_tf_pad_to_onnx(pads):\n    pads = np.reshape(pads, -1).tolist()\n    dims = len(pads)\n    assert dims % 2 == 0\n    ret = []\n    for idx in range(0, dims, 2):\n        ret.append(pads[idx])\n    for idx in range(1, dims, 2):\n        ret.append(pads[idx])\n    return ret\n\n\ndef convert_onnx_pad_to_tf(pads):\n    return np.transpose(np.array(pads).reshape([2, -1])).reshape(-1, 2).tolist()\n\n\ndef is_valid_padding(pads):\n    return sum(np.reshape(pads, -1)) == 0\n\n\ndef shape_to_list(shape):\n    return [dim.size for dim in shape.dim]\n\n\ndef list_to_shape(shape):\n    ret = graph_pb2.TensorShape()\n    for dim in shape:\n        new_dim = ret.dim.add()\n        new_dim.size = dim\n    return ret\n\n\ndef compute_tf_same_padding(input_shape, kernel_shape, strides, data_format=\'NHWC\'):\n    """""" Convert [SAME] padding in tensorflow, keras to onnx pads,\n        i.e. [x1_begin, x2_begin...x1_end, x2_end,...] """"""\n    # print (input_shape)\n    # print (kernel_shape)\n    # print (strides)\n    if data_format.startswith(\'NC\'):\n        # Not tested\n        input_shape = input_shape[2:]\n        remove_dim = len(strides) - len(input_shape)\n        if remove_dim > 0:\n            strides = strides[remove_dim::]\n\n    else:\n        input_shape = input_shape[1:-1]\n        remove_dim = len(input_shape) - len(strides) + 1\n        if remove_dim < 0:\n            strides = strides[1:remove_dim]\n\n    # print (input_shape)\n    # print (kernel_shape)\n    # print (strides)\n\n    up_list = [0]\n    down_list = [0]\n\n    for idx in range(0, len(input_shape)):\n        # kernel_shape[idx] = (kernel_shape[idx] - 1) * dilation_rate + 1\n        output_shape = (input_shape[idx] + strides[idx] - 1) // strides[idx]\n        this_padding = (output_shape - 1) * strides[idx] + kernel_shape[idx] - input_shape[idx]\n        this_padding = max(0, this_padding)\n        up_list.append(this_padding // 2)\n        down_list.append(this_padding - this_padding // 2)\n\n    # print ([0] + up_list + [0] + down_list if data_format.startswith(\'NC\') else up_list + [0] + down_list + [0])\n    # print (\'-----------------------------------------------------\')\n    return [0] + up_list + [0] + down_list if data_format.startswith(\'NC\') else up_list + [0] + down_list + [0]\n\n\n\n# network library\ndef sizeof_fmt(num, suffix=\'B\'):\n    for unit in [\'\',\'Ki\',\'Mi\',\'Gi\',\'Ti\',\'Pi\',\'Ei\',\'Zi\']:\n        if abs(num) < 1024.0:\n            return ""%3.1f %s%s"" % (num, unit, suffix)\n        num /= 1024.0\n    return ""%.1f %s%s"" % (num, \'Yi\', suffix)\n\n\ndef _progress_check(count, block_size, total_size):\n    read_size = count * block_size\n    read_size_str = sizeof_fmt(read_size)\n    if total_size > 0:\n        percent = int(count * block_size * 100 / total_size)\n        percent = min(percent, 100)\n        sys.stdout.write(""\\rprogress: {} downloaded, {}%."".format(read_size_str, percent))\n        if read_size >= total_size:\n            sys.stdout.write(""\\n"")\n    else:\n        sys.stdout.write(""\\rprogress: {} downloaded."".format(read_size_str))\n    sys.stdout.flush()\n\n\ndef _single_thread_download(url, file_name):\n    from six.moves import urllib\n    result, _ = urllib.request.urlretrieve(url, file_name, _progress_check)\n    return result\n\n\ndef _downloader(start, end, url, filename):\n    import requests\n    headers = {\'Range\': \'bytes=%d-%d\' % (start, end)}\n    r = requests.get(url, headers=headers, stream=True)\n    with open(filename, ""r+b"") as fp:\n        fp.seek(start)\n        var = fp.tell()\n        fp.write(r.content)\n\n\ndef _multi_thread_download(url, file_name, file_size, thread_count):\n    import threading\n    fp = open(file_name, ""wb"")\n    fp.truncate(file_size)\n    fp.close()\n\n    part = file_size // thread_count\n    for i in range(thread_count):\n        start = part * i\n        if i == thread_count - 1:\n            end = file_size\n        else:\n            end = start + part\n\n        t = threading.Thread(target=_downloader, kwargs={\'start\': start, \'end\': end, \'url\': url, \'filename\': file_name})\n        t.setDaemon(True)\n        t.start()\n\n    main_thread = threading.current_thread()\n    for t in threading.enumerate():\n        if t is main_thread:\n            continue\n        t.join()\n\n    return file_name\n\n\ndef download_file(url, directory=\'./\', local_fname=None, force_write=False, auto_unzip=False, compre_type=\'\'):\n    """"""Download the data from source url, unless it\'s already here.\n\n    Args:\n        filename: string, name of the file in the directory.\n        work_directory: string, path to working directory.\n        source_url: url to download from if file doesn\'t exist.\n\n    Returns:\n        Path to resulting file.\n    """"""\n\n    if not os.path.isdir(directory):\n        os.mkdir(directory)\n\n    if not local_fname:\n        k = url.rfind(\'/\')\n        local_fname = url[k + 1:]\n\n    local_fname = os.path.join(directory, local_fname)\n\n    if os.path.exists(local_fname) and not force_write:\n        print (""File [{}] existed!"".format(local_fname))\n        return local_fname\n\n    else:\n        print (""Downloading file [{}] from [{}]"".format(local_fname, url))\n        try:\n            import wget\n            ret = wget.download(url, local_fname)\n            print ("""")\n        except:\n            ret = _single_thread_download(url, local_fname)\n\n    if auto_unzip:\n        if ret.endswith("".tar.gz"") or ret.endswith("".tgz""):\n            try:\n                import tarfile\n                tar = tarfile.open(ret)\n                for name in tar.getnames():\n                    if not (os.path.realpath(os.path.join(directory, name))+ os.sep).startswith(os.path.realpath(directory) + os.sep):\n                        raise ValueError(\'The decompression path does not match the current path. For more info: https://docs.python.org/3/library/tarfile.html#tarfile.TarFile.extractall\')\n                tar.extractall(directory)\n                tar.close()\n            except ValueError:\n                raise\n            except:\n                print(""Unzip file [{}] failed."".format(ret))\n\n        elif ret.endswith(\'.zip\'):\n            try:\n                import zipfile\n                zip_ref = zipfile.ZipFile(ret, \'r\')\n                for name in zip_ref.namelist():\n                    if not (os.path.realpath(os.path.join(directory, name))+ os.sep).startswith(os.path.realpath(directory) + os.sep):\n                        raise ValueError(\'The decompression path does not match the current path. For more info: https://docs.python.org/3/library/zipfile.html?highlight=zipfile#zipfile.ZipFile.extractall\')\n                zip_ref.extractall(directory)\n                zip_ref.close()\n            except ValueError:\n                raise\n            except:\n                print(""Unzip file [{}] failed."".format(ret))\n    return ret\n""""""\n    r = requests.head(url)\n    try:\n        file_size = int(r.headers[\'content-length\'])\n        return _multi_thread_download(url, local_fname, file_size, 5)\n\n    except:\n        # not support multi-threads download\n        return _single_thread_download(url, local_fname)\n\n    return result\n""""""\n'"
mmdnn/conversion/coreml/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/coreml/coreml_emitter.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import division\n\nimport os\nimport numpy as np\nfrom six import string_types as _string_types\nfrom mmdnn.conversion.common.IR.IR_graph import IRGraph, IRGraphNode\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.emitter import Emitter\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.coreml.coreml_utils import _infer_coreml_input_shape\n\nfrom coremltools.models.neural_network import NeuralNetworkBuilder as _NeuralNetworkBuilder\nfrom coremltools.models import datatypes\nfrom coremltools.models import MLModel as _MLModel\nfrom coremltools.models.utils import save_spec as _save_spec\n\n\nclass CoreMLEmitter(Emitter):\n\n    def __init__(self, architecture, weight):\n        super(CoreMLEmitter, self).__init__()\n        if os.path.exists(architecture) == False:\n            raise ValueError(""IR architecture file [{}] is not found."".format(architecture))\n        else:\n            self.IR_graph = IRGraph(architecture)\n            self.IR_graph.build()\n\n        if os.path.exists(weight) == False:\n            raise ValueError(""IR weight file [{}] is not found."".format(weight))\n        else:\n            self._load_weights(weight)\n\n\n    def _get_inout(self):\n        input_features = []\n        output_features = []\n        for input_node in self.IR_graph.input_layers:\n            if self.IR_graph.get_node(input_node).type == \'Const\':\n                continue\n            shape = shape_to_list(self.IR_graph.get_node(input_node).get_attr(\'shape\'))\n            shape = _infer_coreml_input_shape(shape)\n            input_features.append((str(input_node), shape))\n            print(""CoreML Model Input Layer: [{}] {}"".format(input_node, shape))\n\n        for output_node in self.IR_graph.output_layers:\n\n            node = self.IR_graph.get_node(output_node)\n\n            if node.type == \'Pack\':\n                continue\n\n            node.out_edges.append(node.name)\n            shape = node.get_attr(\'_output_shapes\')\n            if shape:\n                shape = shape_to_list(shape[0])\n            else:\n                shape = [1]\n\n            shape = _infer_coreml_input_shape(shape)\n\n            output_features.append((str(output_node), shape))\n\n            print(""CoreML Model Output Layer: [{}] {}"".format(output_node, shape))\n\n\n        return list(input_features), list(output_features)\n\n    def _connect_coreml_layers(self):\n        for layer in self.builder.nn_spec.layers:\n            for i, out_node in enumerate(layer.output):\n                layer.output[i] = self.IR_graph.get_node(out_node).real_name\n\n    def gen_model(self,\n                  input_names=None,\n                  output_names=None,\n                  image_input_names=None,\n                  is_bgr=False,\n                  red_bias=0.0,\n                  green_bias=0.0,\n                  blue_bias=0.0,\n                  gray_bias=0.0,\n                  image_scale=1.0,\n                  class_labels=None,\n                  predicted_feature_name=None,\n                  predicted_probabilities_output=\'\'):\n\n        input_features, output_features = self._get_inout()\n        is_classifier = class_labels is not None\n        mode = \'classifier\' if is_classifier else None\n        self.builder = _NeuralNetworkBuilder(input_features, output_features, mode=mode)\n\n        for layer in self.IR_graph.topological_sort:\n            current_node = self.IR_graph.get_node(layer)\n            print(""Converting layer {}({})"".format(current_node.name, current_node.type))\n            node_type = current_node.type\n            if hasattr(self, ""emit_"" + node_type):\n                func = getattr(self, ""emit_"" + node_type)\n                func(current_node)\n            else:\n                print(""CoreMLEmitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(current_node)\n                assert False\n\n        # Add classifier classes (if applicable)\n        if is_classifier:\n            classes_in = class_labels\n            if isinstance(classes_in, _string_types):\n                if not os.path.isfile(classes_in):\n                    raise ValueError(""Path to class labels [{}] does not exist."".format(classes_in))\n                with open(classes_in, \'r\') as f:\n                    classes = f.read()\n                classes = classes.splitlines()\n            elif type(classes_in) is list: # list[int or str]\n                classes = classes_in\n            else:\n                raise ValueError(\'Class labels must be a list of integers / strings, or a file path\')\n\n            if predicted_feature_name is not None:\n                self.builder.set_class_labels(classes, predicted_feature_name = predicted_feature_name,\n                    prediction_blob = predicted_probabilities_output)\n            else:\n                self.builder.set_class_labels(classes)\n\n        # Set pre-processing paramsters\n        self.builder.set_pre_processing_parameters(\n            image_input_names=[input_features[0][0]],\n            #image_input_names,\n            is_bgr=is_bgr,\n            red_bias=red_bias,\n            green_bias=green_bias,\n            blue_bias=blue_bias,\n            gray_bias=gray_bias,\n            image_scale=image_scale)\n\n        # Return the protobuf spec\n        # model = _MLModel(self.builder.spec)\n\n        print (self.builder.spec.description)\n\n        return self.builder.spec, input_features, output_features\n\n\n    @staticmethod\n    def _get_padding(IR_node):\n\n        auto_pad = IR_node.get_attr(\'auto_pad\')\n        if auto_pad is not None:\n            if auto_pad == \'VALID\':\n                pass\n            else:\n                return \'SAME\'\n\n        pads = IR_node.get_attr(\'pads\', [0,0,0,0,0,0,0,0])\n\n        return pads\n\n    def emit_Mul(self, IR_node):\n        """"""\n        Not implement yet\n        """"""\n        pass\n        # if IR_node.name in self.weights_dict and \'weights\' in self.weights_dict[IR_node.name]:\n        #     pass\n        \n        # self._emit_merge(IR_node,\'DOT\')\n        \n\n    def _emit_merge(self, IR_node, func):\n        """"""\n        Convert concat layer to coreml.\n        """"""\n        # Get input and output names\n        input_names = [self.IR_graph.get_node(inp).real_name for inp in IR_node.in_edges]\n\n        self.builder.add_elementwise(name=IR_node.name, input_names=input_names,\n            output_name=IR_node.name, mode=func)\n\n    def emit_Conv(self, IR_node):\n        """"""\n        Convert convolution layer to coreml.\n        """"""\n        has_bias = IR_node.get_attr(\'use_bias\', False)\n        is_deconv = False\n\n\n        # Dimensions and weights\n        kernel_shape = IR_node.get_attr(\'kernel_shape\')\n\n        if len(kernel_shape) == 4:\n            height, width, input_channels, output_channels = kernel_shape\n        elif len(kernel_shape) == 5:\n            depth, height, width, input_channels, output_channels = kernel_shape\n        else:\n            raise NotImplementedError()\n\n        output_shape = None\n\n        # W should have shape (height, width, kernel_channels, output_channels), where kernel_channel = input_channels / groups\n        W = self.weights_dict[IR_node.name][\'weights\']\n        b = self.weights_dict[IR_node.name][\'bias\'] if has_bias else None\n\n\n        stride_height, stride_width = IR_node.get_attr(\'strides\')[1], IR_node.get_attr(\'strides\')[2]\n\n        # Dilations\n        dilations = IR_node.get_attr(\'dilations\', [1, 1])\n        if is_deconv and not dilations == [1, 1]:\n            raise ValueError(""Unsupported non-unity dilation for Deconvolution layer"")\n\n        groups = IR_node.get_attr(\'group\', 1)\n\n        kernel_channels = input_channels // groups\n        padding = self._get_padding(IR_node)\n\n        if isinstance(padding, list):\n            border_mode = ""valid""\n            # see protobuf\n            padding_top, padding_left, padding_bottom, padding_right = padding[1], padding [2], padding[5], padding [6]\n        else:\n            border_mode = ""same""\n            padding_top, padding_left, padding_bottom, padding_right = 0, 0, 0, 0\n\n\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n\n        self.builder.add_convolution(name=IR_node.real_name,\n                                     kernel_channels=kernel_channels,\n                                     output_channels=output_channels,\n                                     height=height,\n                                     width=width,\n                                     stride_height=stride_height,\n                                     stride_width=stride_width,\n                                     border_mode= border_mode,\n                                     groups=groups,\n                                     W=W,\n                                     b=b,\n                                     has_bias=has_bias,\n                                     is_deconv=is_deconv,\n                                     output_shape=output_shape,\n                                     input_name=input_name,\n                                     padding_top= padding_top,\n                                     padding_left= padding_left,\n                                     padding_bottom= padding_bottom,\n                                     padding_right= padding_right,\n                                     output_name=IR_node.real_name,\n                                     dilation_factors=dilations)\n\n\n\n\n    def emit_ConvTranspose(self, IR_node):\n        """"""\n        Convert convolution layer to coreml.\n        """"""\n\n        # assert False\n        has_bias = IR_node.get_attr(\'use_bias\', False)\n        is_deconv = True\n\n        # Get the weights.\n\n        kernel_shape = IR_node.get_attr(\'kernel_shape\')\n\n        if len(kernel_shape) == 4:\n            height, width, output_channels, kernel_channels = kernel_shape\n            W = self.weights_dict[IR_node.name][\'weights\']\n            W = W.reshape(kernel_shape)\n            W = W.transpose((0, 1, 3, 2))\n        elif len(kernel_shape) == 5:\n            depth, height, width, output_channels, kernel_channels = kernel_shape\n            W = self.weights_dict[IR_node.name][\'weights\']\n            W = W.reshape(kernel_shape)\n            W = W.transpose((0, 1, 2, 4, 3))\n        else:\n            raise NotImplementedError()\n\n\n        output_shape = None\n        b = self.weights_dict[IR_node.name][\'bias\'] if has_bias else None\n\n        stride_height, stride_width = IR_node.get_attr(\'strides\')[1], IR_node.get_attr(\'strides\')[2]\n\n        # Dilations\n        dilations = IR_node.get_attr(\'dilations\', [1, 1])\n        if is_deconv and not dilations == [1, 1]:\n            raise ValueError(""Unsupported non-unity dilation for Deconvolution layer"")\n\n        groups = IR_node.get_attr(\'group\', 1)\n\n        padding = self._get_padding(IR_node)\n\n        if isinstance(padding, list):\n            border_mode = ""valid""\n            # see protobuf\n            padding_top, padding_left, padding_bottom, padding_right = padding[1], padding [2], padding[5], padding [6]\n        else:\n            border_mode = ""same""\n            padding_top, padding_left, padding_bottom, padding_right = 0, 0, 0, 0\n\n\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n\n        self.builder.add_convolution(name=IR_node.real_name,\n                                     kernel_channels=kernel_channels,\n                                     output_channels=output_channels,\n                                     height=height,\n                                     width=width,\n                                     stride_height=stride_height,\n                                     stride_width=stride_width,\n                                     border_mode= border_mode,\n                                     groups=groups,\n                                     W=W,\n                                     b=b,\n                                     has_bias=has_bias,\n                                     is_deconv=is_deconv,\n                                     output_shape=output_shape,\n                                     input_name=input_name,\n                                     padding_top= padding_top,\n                                     padding_left= padding_left,\n                                     padding_bottom= padding_bottom,\n                                     padding_right= padding_right,\n                                     output_name=IR_node.real_name,\n                                     dilation_factors=dilations)\n\n\n\n    def emit_DepthwiseConv(self, IR_node):\n        # depth-wise convolution\n\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n        kernel_channels = 1\n        is_deconv = False\n        has_bias = IR_node.get_attr(\'use_bias\', False)\n\n        depth_multiplier = IR_node.get_attr(\'kernel_shape\')[-1]\n\n        W = self.weights_dict[IR_node.name][\'weights\']\n        height, width, channels, n_filters = W.shape\n        output_shape = None\n        W = np.reshape(W,(height, width,1,channels * depth_multiplier))\n        b = self.weights_dict[IR_node.name][\'bias\'] if has_bias else None\n\n        # Dilations\n        dilations = IR_node.get_attr(\'dilations\', [1, 1])\n\n\n        padding = self._get_padding(IR_node)\n\n\n\n        if isinstance(padding, list):\n            border_mode = ""valid""\n            # see protobuf\n            padding_top, padding_left, padding_bottom, padding_right = padding[1], padding [2], padding[5], padding [6]\n        else:\n            border_mode = ""same""\n            padding_top, padding_left, padding_bottom, padding_right = 0, 0, 0, 0\n\n\n\n\n\n        output_channels = W.shape[-1]\n        groups = W.shape[-1]\n        stride_height, stride_width = IR_node.get_attr(\'strides\')[1], IR_node.get_attr(\'strides\')[2]\n\n        self.builder.add_convolution(name=IR_node.real_name,\n                                     kernel_channels=kernel_channels,\n                                     output_channels=output_channels,\n                                     height=height,\n                                     width=width,\n                                     stride_height=stride_height,\n                                     stride_width=stride_width,\n                                     border_mode=border_mode,\n                                     groups=groups,\n                                     W=W,\n                                     b=b,\n                                     has_bias=has_bias,\n                                     is_deconv=is_deconv,\n                                     output_shape=output_shape,\n                                     padding_top= padding_top,\n                                     padding_left= padding_left,\n                                     padding_bottom= padding_bottom,\n                                     padding_right= padding_right,\n                                     input_name=input_name,\n                                     output_name=IR_node.real_name,\n                                     dilation_factors=dilations)\n\n\n    def emit_Pool(self, IR_node):\n        """"""\n        Convert pooling layer to coreml.\n        """"""\n        # Get input and output names\n        input_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n\n        # Pooling layer type\n        pooling_type = IR_node.get_attr(\'pooling_type\')\n        if pooling_type == \'MAX\':\n            layer_type_str = \'MAX\'\n        elif pooling_type == \'AVG\':\n            layer_type_str = \'AVERAGE\'\n        else:\n            raise TypeError(""Pooling type %s not supported"" % pooling_type)\n\n\n        # if it\'s global, set the global flag\n        global_pooling = IR_node.get_attr(\'global_pooling\', False)\n        dim = len(IR_node.get_attr(\'strides\')) - 2\n\n\n        if global_pooling:\n            if dim == 2:\n\n\n\n                stride_height, stride_width = tuple(IR_node.get_attr(\'strides\')[1:-1])\n                height, width = 1, 1\n\n                # TODO  global pooling modification\n\n                # Padding\n                padding = self._get_padding(IR_node)\n\n                if isinstance(padding, list):\n                    padding_type = ""VALID""\n                    # see protobuf\n                    padding_top, padding_left, padding_bottom, padding_right = padding[1], padding[2], padding[5], padding[6]\n                else:\n                    padding_type = ""SAME""\n                    padding_top, padding_left, padding_bottom, padding_right = 0, 0, 0, 0\n\n\n            elif dim == 1:\n                raise NotImplementedError()\n                global_pooling = False\n                _, width, channels = keras_layer.input_shape\n                height = 1\n                stride_height, stride_width = height, width\n                padding_type = \'VALID\'\n            else:\n                raise NotImplementedError()\n\n        else:\n\n            height, width = tuple(IR_node.get_attr(\'kernel_shape\')[1:-1])\n            stride_height, stride_width = tuple(IR_node.get_attr(\'strides\')[1:-1])\n\n            # Padding\n            padding = self._get_padding(IR_node)\n            if isinstance(padding, list):\n\n                padding_type = ""VALID""\n                # see protobuf\n                padding_top, padding_left, padding_bottom, padding_right = padding[1], padding [2], padding[5], padding [6]\n            else:\n                padding_type = ""SAME""\n                padding_top, padding_left, padding_bottom, padding_right = 0, 0, 0, 0\n\n\n        self.builder.add_pooling(name=IR_node.name,\n                                    height=height,\n                                    width=width,\n                                    stride_height=stride_height,\n                                    stride_width=stride_width,\n                                    layer_type=layer_type_str,\n                                    padding_type=padding_type,\n                                    padding_top= padding_top,\n                                    padding_left= padding_left,\n                                    padding_bottom= padding_bottom,\n                                    padding_right= padding_right,\n                                    input_name=input_name,\n                                    output_name=IR_node.name,\n                                    exclude_pad_area=True,\n                                    is_global=global_pooling)\n\n\n    def emit_Scale(self, IR_node):\n        # Get input and output names\n        input_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n\n        weights = IR_node.get_attr(\'scale\', False)\n        weights = self.weights_dict[IR_node.name][\'scale\']\n        has_bias = IR_node.get_attr(\'use_bias\', False)\n        if has_bias:\n            bias = self.weights_dict[IR_node.name][\'bias\']\n\n\n        shape_scale = self.weights_dict[IR_node.name][\'shapeScale\']\n        if has_bias:\n            shape_bias = self.weights_dict[IR_node.name][\'shapeBias\']\n\n\n\n        self.builder.add_scale(name = IR_node.real_name,\n                                        W = weights,\n                                        b = bias,\n                                        has_bias = has_bias,\n                                        input_name = input_name,\n                                        output_name =IR_node.name,\n                                        shape_scale= [shape_scale],\n                                        shape_bias= [shape_bias])\n\n\n\n    def emit_UNKNOWN(self, IR_node):\n        print(IR_node.name)\n\n\n    def emit_Crop(self, IR_node):\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n        output_name=IR_node.real_name\n\n        is_1d = False\n        border = IR_node.get_attr(\'border\')\n\n        if is_1d:\n            raise ValueError(""Unrecognized padding option: %s"" % (str(border)))\n        else:\n            if type(border) is int:\n                top = left = bottom = right = border\n            elif type(border) is list:\n                # type: ""list(int). A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder).""\n                # This is central crop\n                top, left = border[1], border[0]\n                bottom, right = border[1], border[0]\n            else:\n                raise ValueError(""Unrecognized padding option: %s"" % (str(border)))\n\n        # Now add the layer\n        self.builder.add_crop(name = IR_node.name,\n            left = left, right=right, top=top, bottom=bottom, offset = [0,0],\n            input_names = [input_name], output_name=output_name\n            )\n\n\n    def emit_ReduceMean(self, IR_node):\n        """"""\n        Convert ReduceMean layer to coreml.\n        """"""\n\n        axis = IR_node.get_attr(\'axes\', [1,2])\n\n#       Allowed values: \'CHW\', \'HW\', \'C\', \'H\', \'W\'\n        if len(axis) == 1:\n            if axis[0] == 0:\n                axis_str = \'C\'\n            elif axis[0] == 1:\n                axis_str = \'H\'\n            elif axis[0] == 2:\n                axis_str = \'W\'\n        elif len(axis) == 2:\n            axis_str = \'HW\'\n        elif len(axis) == 3:\n            axis_str = \'CHW\'\n\n        # Get input and output names\n        input_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n\n\n        self.builder.add_reduce(IR_node.name,\n                            input_name = input_name,\n                            output_name = IR_node.name,\n                            axis = axis_str,\n                            mode = \'avg\',\n                            epsilon = 1e-6)\n\n\n    def emit_DataInput(self, IR_node):\n        """""" Layers that can be skipped. """"""\n        return\n\n\n    def emit_Dropout(self, IR_node):\n        """""" Layers that can be skipped (because they are train time only. """"""\n        IR_node.real_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n\n\n    def emit_FullyConnected(self, IR_node):\n        """"""\n        Convert a dense layer to coreml.\n        """"""\n        # Get input and output names\n        input_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n        output_name = IR_node.out_edges[0]\n\n        has_bias = IR_node.get_attr(\'use_bias\')\n\n        # Get the weights from keras\n        W = self.weights_dict[IR_node.name][\'weights\'].T\n        Wb = self.weights_dict[IR_node.name][\'bias\'].T if has_bias else None\n        output_channels, input_channels = W.shape\n\n        self.builder.add_inner_product(name=IR_node.name,\n                                       W=W,\n                                       b=Wb,\n                                       input_channels=input_channels,\n                                       output_channels=output_channels,\n                                       has_bias=has_bias,\n                                       input_name=input_name,\n                                       output_name=IR_node.name)\n\n\n    def emit_Flatten(self, IR_node):\n        """"""\n        Convert a flatten layer from keras to coreml.\n        """"""\n        # Get input and output names\n        input_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n        output_name = IR_node.out_edges[0]\n\n        """"""\n        # blob_order == 0 if the input blob needs not be rearranged\n        # blob_order == 1 if the input blob needs to be rearranged\n        blob_order = 0\n\n        # using keras_layer.input.shape have a ""?"" (Dimension[None] at the front),\n        # making a 3D tensor with unknown batch size 4D\n        if len(keras_layer.input.shape) == 4:\n            blob_order = 1\n        """"""\n\n        self.builder.add_flatten(name=IR_node.name, mode=1,\n                                 input_name=input_name, output_name=IR_node.name)\n\n\n    def emit_Reshape(self, IR_node):\n        def ShapetrToTuple(string, batch_none = False):\n            if batch_none == True:\n                ls = [int(item) for item in string.split(\', \')]\n                ls.insert(0,None)\n                return tuple(ls)\n            else:\n                ls = [int(item) for item in string.split(\', \')]\n                return tuple(ls)\n\n        last_node = self.IR_graph.get_node(IR_node.in_edges[0]).layer\n        input_shape_dims = last_node.attr[""_output_shapes""].list.shape\n        target_shape_dims = IR_node.IR_layer.attr[""_output_shapes""].list.shape\n\n        input_shape = ShapetrToTuple(IRGraph.shapeToStr(input_shape_dims[0]),True)\n        target_shape = ShapetrToTuple(IRGraph.shapeToStr(target_shape_dims[0]))\n\n        def get_coreml_target_shape(target_shape):\n            if len(target_shape) == 1: #(D,)\n                coreml_shape = (1,target_shape[0],1,1)\n            elif len(target_shape) == 2: #(S,D)\n                coreml_shape = target_shape + (1,1)\n            elif len(target_shape) == 3: #(H,W,C)\n                coreml_shape = (1, target_shape[2], target_shape[0], target_shape[1])\n            else:\n                coreml_shape = None\n            return coreml_shape\n\n        def get_mode(input_shape, target_shape):\n            in_shape = input_shape[1:]\n            if len(in_shape) == 3 or len(target_shape) == 3:\n                    return 1\n            else:\n                return 0\n        input_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n        new_shape = get_coreml_target_shape(target_shape)\n        mode = get_mode(input_shape, target_shape)\n\n        self.builder.add_reshape(\n            name=IR_node.real_name,\n            input_name=input_name,\n            output_name=IR_node.real_name,\n            target_shape=new_shape,\n            mode=mode)\n\n\n\n    def _emit_activation(self, IR_node, act, params=None):\n        # Get input and output names\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n        output_name = IR_node.real_name\n        if not isinstance(params, list):\n            params = [params]\n\n        self.builder.add_activation(name=IR_node.real_name,\n            non_linearity=act,\n            input_name=input_name,\n            output_name=output_name,\n            params=params)\n\n\n    # activation emit\n    def emit_Relu(self, IR_node):\n        self._emit_activation(IR_node, \'RELU\')\n    def emit_Tanh(self, IR_node):\n        self._emit_activation(IR_node, \'TANH\')\n    def emit_PRelu(self, IR_node):\n        self._emit_activation(IR_node, \'PRELU\', IR_node.get_attr(\'gamma\', 0) )\n    def emit_LeakyRelu(self, IR_node):\n        self._emit_activation(IR_node, \'LEAKYRELU\', IR_node.get_attr(\'alpha\', 0) )\n    def emit_Elu(self,IR_node):\n        self._emit_activation(IR_node, \'ELU\',  IR_node.get_attr(\'alpha\', 0)  )\n    def emit_ThresholdedRelu(self, IR_node):\n        self._emit_activation(IR_node, \'THRESHOLDEDRELU\', IR_node.get_attr(\'alpha\', 0) )\n    def emit_ScaledTanh(self, IR_node):\n        self._emit_activation(IR_node, \'SCALED_TANH\', [IR_node.get_attr(\'alpha\', 0),IR_node.get_attr(\'beta\', 0)])\n    def emit_linear(self, IR_node):\n        self._emit_activation(IR_node, \'LINEAR\', [IR_node.get_attr(\'alpha\', 0),IR_node.get_attr(\'beta\', 0)])\n    def emit_SigmoidHard(self, IR_node):\n        self._emit_activation(IR_node, \'SIGMOID_HARD\', [IR_node.get_attr(\'alpha\', 0),IR_node.get_attr(\'beta\', 0)])\n    def emit_ParametricSoftplus(self, IR_node):\n        self._emit_activation(IR_node, \'PARAMETRICSOFTPLUS\', [ IR_node.get_attr(\'alpha\', 0),IR_node.get_attr(\'beta\', 0) ])\n\n\n\n\n    def emit_Softmax(self, IR_node):\n        # Get input and output names\n        input_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n        output_name = IR_node.out_edges[0]\n        self.builder.add_softmax(name=IR_node.name, input_name=input_name,\n                                 output_name=IR_node.name)\n\n\n    def emit_Sigmoid(self, IR_node):\n        assert False\n        code = ""{:<15} = Activation(name = \'{}\', activation = \'sigmoid\')({})"".format(\n                IR_node.replace_scope(IR_node.name),\n                IR_node.name,\n                IR_node.replace_scope(IR_node.in_edges[0]))\n        return code\n\n\n    def emit_Relu6(self, IR_node):\n\n        layer = IR_node.real_name\n        input_name, output_name = (IR_node.IR_layer.input[0], IR_node.IR_layer.name)\n\n        relu_output_name = output_name + \'_relu\'\n        self.builder.add_activation(layer, \'RELU\', input_name, relu_output_name)\n        # negate it\n        neg_output_name = relu_output_name + \'_neg\'\n        self.builder.add_activation(layer+\'__neg__\', \'LINEAR\', relu_output_name,\n                neg_output_name,[-1.0, 0])\n        # apply threshold\n        clip_output_name = relu_output_name + \'_clip\'\n        self.builder.add_unary(layer+\'__clip__\', neg_output_name, clip_output_name,\n                \'threshold\', alpha = -6.0)\n        # negate it back\n        self.builder.add_activation(\n            layer + \'_neg2\',\n            \'LINEAR\',\n            clip_output_name,\n            output_name,\n            [-1.0, 0])\n\n    def emit_Gather(self, IR_node):\n        raise NotImplementedError()\n        W = self.weights_dict[IR_node.name][\'weights\']\n        if W.ndim == 2:\n            vocab_size = W.shape[0]\n            output_channels = W.shape[1]\n            builder.add_embedding(\n                name=IR_node.real_name,\n                W = W,\n                b = None,\n                input_dim = vocab_size,\n                output_channels = output_channels,\n                has_bias=False,\n                input_name=input_name,\n                output_name=IR_node.real_name)\n        else:\n            raise NotImplementedError()\n\n    def emit_RNNs(self, IR_node, func):\n        assert False\n        # for Keras\n        if ""dropout"" in IR_node.IR_layer.attr:\n            dropout_str = "",dropout = {}, recurrent_dropout = {}"".format(\n                    IR_node.IR_layer.attr[\'dropout\'].f,\n                    IR_node.IR_layer.attr[\'recurrent_dropout\'].f)\n        else:\n            dropout_str = """"\n\n        code = ""{:<15} = {}(units = {}, use_bias = {} {})({})"".format(\n                IR_node.name,\n                func,\n                IR_node.IR_layer.attr[\'units\'].i,\n                IR_node.IR_layer.attr[\'use_bias\'].b,\n                dropout_str,\n                IR_node.in_edges[0])\n\n        return code\n\n\n    def emit_LSTM(self, IR_node):\n        return self.emit_RNNs(IR_node, ""LSTM"")\n\n\n    def emit_GRU(self, IR_node):\n        return self.emit_RNNs(IR_node, ""GRU"")\n\n\n    def emit_Add(self, IR_node):\n        self._emit_merge(IR_node, \'ADD\')\n\n\n    def emit_Concat(self, IR_node):\n        self._emit_merge(IR_node, ""CONCAT"")\n\n\n    def emit_BatchNorm(self, IR_node):\n        """"""\n        Convert a Batch Normalization layer.\n        """"""\n        # Get input and output names\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n\n\n        axis = IR_node.get_attr(\'axis\', -1)\n        nb_channels = IR_node.get_attr(\'_output_shapes\')[0].dim[axis].size\n\n\n        # Set parameters\n        # Parameter arrangement in Keras: gamma, beta, mean, variance\n        weights = self.weights_dict[IR_node.name]\n        mean = weights[\'mean\']\n        std = weights[\'var\']\n        gamma = weights.get(\'scale\', np.ones(mean.shape))\n        beta = weights.get(\'bias\', np.zeros(mean.shape))\n\n        # compute adjusted parameters\n        # Reference: parameter transformation https://github.com/apple/coremltools/issues/153\n        variance = std * std\n        f = 1.0 / np.sqrt(std + IR_node.get_attr(\'epsilon\'))\n        gamma1 = gamma*f\n        beta1 = beta - gamma*mean*f\n        mean[:] = 0.0 #mean\n        variance[:] = 1.0 - .00001 #stddev\n\n\n        self.builder.add_batchnorm(\n            name=IR_node.real_name,\n            channels = nb_channels,\n            gamma = gamma1,\n            beta = beta1,\n            mean = mean,\n            variance = variance,\n            input_name = input_name,\n            output_name=IR_node.real_name)\n\n\n\n    def emit_Pad(self, IR_node):\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n        output_name=IR_node.real_name\n        is_1d = False\n        padding = IR_node.get_attr(\'pads\')\n        if is_1d:\n            raise ValueError(""Unrecognized padding option: %s"" % (str(padding)))\n        else:\n            if type(padding) is int:\n                top = left = bottom = right = padding\n            elif type(padding) is list:\n                top, left = padding[1], padding [2]\n                bottom, right = padding[5], padding [6]\n            else:\n                raise ValueError(""Unrecognized padding option: %s"" % (str(padding)))\n\n        # padding type TODO\n        # Type of the padding. Can be one of \'constant\', \'reflection\' or \'replication\n        padding_type = IR_node.get_attr(\'mode\', \'CONSTANT\')\n        if padding_type == \'CONSTANT\':\n            padding_type = \'constant\'\n        elif padding_type == \'REFLECT\':\n            padding_type = \'reflection\'\n        elif padding_type == \'SYMMETRIC\':\n            padding_type = \'replication\'\n\n\n        # Now add the layer\n        self.builder.add_padding(name = IR_node.name,\n            left = left, right=right, top=top, bottom=bottom, value = 0,\n            input_name = input_name, output_name=output_name, padding_type = padding_type\n            )\n\n\n    def emit_Squeeze(self, IR_node):\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n        output_name=IR_node.real_name\n\n        self.builder.add_bias(name = IR_node.name,\n                              b = 0,\n                              input_name = input_name,\n                              output_name = output_name,\n                              shape_bias = [1])\n        # self.emit_Flatten(IR_node)\n\n\n    def emit_LRN(self, IR_node):\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n        output_name = IR_node.real_name\n        alpha = IR_node.get_attr(\'alpha\')\n        beta = IR_node.get_attr(\'beta\')\n        bias = IR_node.get_attr(\'bias\')\n        size = IR_node.get_attr(\'size\')\n\n        self.builder.add_lrn(output_name, input_name, output_name,\n                          alpha=alpha,\n                          beta=beta,\n                          local_size=size,\n                          k=bias)\n\n\n    def emit_SeparableConv(self, IR_node):\n\n        input_name = self.IR_graph.get_parent(IR_node.name, [0]).real_name\n        output_name = IR_node.real_name\n\n\n\n        strides = IR_node.get_attr(\'strides\')\n        stride_height, stride_width = (strides[1], strides[2])\n\n        # Get the weights\n        W0 = self.weights_dict[IR_node.name][\'depthwise_filter\']\n        W1 = self.weights_dict[IR_node.name][\'pointwise_filter\']\n\n        padding = IR_node.get_attr(\'auto_pad\').split(\'_\')[0].lower()\n        has_bias = IR_node.get_attr(\'use_bias\')\n        b = self.weights_dict[IR_node.name][\'bias\'] if has_bias else None\n\n        output_blob_shape = IR_node.get_attr(\'_output_shapes\')\n        shape = shape_to_list(output_blob_shape[0])\n        output_channels = shape[-1]\n\n        height, width, input_channels, depth_mult = W0.shape\n\n        W0 = np.reshape(W0, (height, width, 1, input_channels * depth_mult))\n\n        intermediate_name = input_name + \'_intermin_\'\n\n        self.builder.add_convolution(name = IR_node.name + \'_step_1\',\n             kernel_channels = 1,\n             output_channels = input_channels * depth_mult,\n             height = height,\n             width = width,\n             stride_height = stride_height,\n             stride_width = stride_width,\n             border_mode = padding,\n             groups = input_channels,\n             W = W0,\n             b = None,\n             has_bias = False,\n             is_deconv = False,\n             output_shape = None,\n             input_name = input_name,\n             output_name = intermediate_name,\n             dilation_factors = [1,1])\n\n        self.builder.add_convolution(name = IR_node.name + \'_step_2\',\n                kernel_channels = input_channels * depth_mult,\n                output_channels = output_channels,\n                height = 1,\n                width = 1,\n                stride_height = 1,\n                stride_width = 1,\n                border_mode = padding,\n                groups = 1,\n                W = W1,\n                b = b,\n                has_bias = has_bias,\n                is_deconv = False,\n                output_shape = None,\n                input_name = intermediate_name,\n                output_name = output_name,\n                dilation_factors = [1,1])\n\n\n    def emit_Slice(self, IR_node):\n        pass\n    def emit_Const(self, IR_node):\n        pass\n\n    def emit_Shape(self, IR_node):\n        pass\n    def emit_Pack(self, IR_node):\n        pass\n'"
mmdnn/conversion/coreml/coreml_graph.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\nimport os\n\nimport coremltools\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\n\n\nclass CoremlGraphNode(GraphNode):\n\n    def __init__(self, layer):\n        super(CoremlGraphNode, self).__init__(layer)\n\n\n    @property\n    def name(self):\n        return self.layer.name\n\n\n    @property\n    def type(self):\n        return self.layer.__class__.__name__\n\n\n    @property\n    def coreml_layer(self):\n        return self.layer\n\n\n\nclass CoremlGraph(Graph):\n\n    def __init__(self, model):\n        from coremltools.proto import Model_pb2\n\n        # sanity check.\n        if not isinstance(model, Model_pb2.Model):\n            raise TypeError(""Coreml layer of type %s is not supported."" % type(model))\n        super(CoremlGraph, self).__init__(model)\n        self.model = model\n\n\n    def build(self):\n        self.input_layers = list()\n\n        # input layer\n\n        for layer in self.model.description.input:\n            self.layer_map[layer.name] = CoremlGraphNode(layer)\n            self.layer_name_map[layer.name] = layer.name\n\n\n        model_type = self.model.WhichOneof(\'Type\')\n        if model_type == \'neuralNetworkClassifier\':\n            # build each layer\n            for layer in self.model.neuralNetworkClassifier.layers:\n                self.layer_map[layer.name] = CoremlGraphNode(layer)\n                self.layer_name_map[layer.name] = layer.name\n\n            # if A.output == B.input, then make the connection: A -> B\n            for layerA in self.model.neuralNetworkClassifier.layers:\n                for layerB in self.model.neuralNetworkClassifier.layers:\n                    for A in layerA.output:\n                        for B in layerB.input:\n                            if A == B :\n                                # print(\'{0:20}->     {1:20}\'.format(layerA.name, layerB.name))\n                                self._make_connection(layerA.name, layerB.name)\n\n            # if A.name == B.input, then make the connection: A -> B, here A is the input\n            for layerA in self.model.description.input:\n                for layerB in self.model.neuralNetworkClassifier.layers:\n                    for B in layerB.input:\n                        if layerA.name == B:\n                            self._make_connection(layerA.name, layerB.name)\n        elif model_type == \'neuralNetwork\':\n            # build each layer\n            for layer in self.model.neuralNetwork.layers:\n                self.layer_map[layer.name] = CoremlGraphNode(layer)\n                self.layer_name_map[layer.name] = layer.name\n\n            # if A.output == B.input, then make the connection: A -> B\n            for layerA in self.model.neuralNetwork.layers:\n                for layerB in self.model.neuralNetwork.layers:\n                    for A in layerA.output:\n                        for B in layerB.input:\n                            if A == B :\n                                # print(\'{0:20}->     {1:20}\'.format(layerA.name, layerB.name))\n                                self._make_connection(layerA.name, layerB.name)\n            # if A.name == B.input, then make the connection: A -> B, here A is the input\n            for layerA in self.model.description.input:\n                for layerB in self.model.neuralNetwork.layers:\n                    for B in layerB.input:\n                        if layerA.name == B:\n                            self._make_connection(layerA.name, layerB.name)\n        elif model_type == \'neuralNetworkRegressor\':\n            # build each layer\n            for layer in self.model.neuralNetworkRegressor.layers:\n                self.layer_map[layer.name] = CoremlGraphNode(layer)\n                self.layer_name_map[layer.name] = layer.name\n\n            # if A.output == B.input, then make the connection: A -> B\n            for layerA in self.model.neuralNetworkRegressor.layers:\n                for layerB in self.model.neuralNetworkRegressor.layers:\n                    for A in layerA.output:\n                        for B in layerB.input:\n                            if A == B :\n                                # print(\'{0:20}->     {1:20}\'.format(layerA.name, layerB.name))\n                                self._make_connection(layerA.name, layerB.name)\n            # if A.name == B.input, then make the connection: A -> B, here A is the input\n            for layerA in self.model.description.input:\n                for layerB in self.model.neuralNetworkRegressor.layers:\n                    for B in layerB.input:\n                        if layerA.name == B:\n                            self._make_connection(layerA.name, layerB.name)\n        else:\n            assert False\n\n\n\n            # The information of the layer\n        super(CoremlGraph, self).build()\n\n\n\n'"
mmdnn/conversion/coreml/coreml_parser.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\n\nimport os\nfrom six import string_types as _string_types\nimport numpy as np\nimport math\n\nfrom coremltools.models.neural_network import NeuralNetworkBuilder as _NeuralNetworkBuilder\nfrom coremltools.models import datatypes\nfrom coremltools.models import MLModel as _MLModel\nfrom coremltools.models.utils import save_spec as _save_spec\nfrom coremltools.models._infer_shapes_nn_mlmodel import infer_shapes\nfrom coremltools.proto import Model_pb2 ,NeuralNetwork_pb2\n\n\nfrom mmdnn.conversion.coreml.coreml_graph import CoremlGraph\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom mmdnn.conversion.common.utils import *\n\n\nclass CoremlParser(Parser):\n\n    activation_map = {\n        ""ReLU""          : ""Relu"",\n        ""leakyReLU""     : ""LeakyRelu"",\n        ""linear""        : ""linear"",\n        ""thresholdedReLU"" : ""ThresholdedRelu"",\n        ""PReLU""         : ""PRelu"",\n        ""tanh""          : ""Tanh"",\n        ""scaledTanh""    : ""ScaledTanh"",\n        \'sigmoid\'       : ""Sigmoid"",\n        ""sigmoidHard""   : ""SigmoidHard"",\n        ""ELU""           : ""Elu"",\n        \'softplus\'      : \'Softplus\',\n        \'softsign\'      : \'Softsign\',\n        \'parametricSoftplus\'    : ""ParametricSoftplus""\n    }\n\n\n\n\n    def __init__(self, model):\n        super(CoremlParser, self).__init__()\n\n        # load model file into Coreml Graph\n        if isinstance(model, _string_types):\n            # model.encode() convert to str --- python2 may crash due to type \'unicode\'\n            model = _MLModel(model)\n            model = model.get_spec()\n            self.weight_loaded = True\n        else:\n            assert False\n\n        # Build Network Graph\n\n        model_type = model.WhichOneof(\'Type\')\n        if model_type == \'neuralNetworkClassifier\':\n            CoremlParser.shape_dict = infer_shapes(model.neuralNetworkClassifier, model.description.input)\n        elif model_type == \'neuralNetwork\':\n            CoremlParser.shape_dict = infer_shapes(model.neuralNetwork, model.description.input)\n        elif model_type == \'neuralNetworkRegressor\':\n            CoremlParser.shape_dict = infer_shapes(model.neuralNetworkRegressor, model.description.input)\n        else:\n            assert False\n\n        # self.data_format ? TODO\n        self.data_format = \'channels_first\'\n        self.coreml_graph = CoremlGraph(model)\n        self.coreml_graph.build()\n        self.lambda_layer_count = 0\n\n\n    def _load_model(self, model_network_path):\n        """"""Load a Coreml model from disk\n\n        Parameters\n        ----------\n\n        model_network_path: str\n            Path where the model network path is (mlmodel file)\n\n        Returns\n        -------\n        model: A coreml model\n        """"""\n\n        from coremltools.models import MLModel\n\n        if os.path.isfile(model_network_path):\n            # load the model network\n            loaded_model_ml = MLModel(model_network_path)\n            # convert to Model_pb2.Model\n            loaded_model_pb = loaded_model_ml.get_spec()\n            self.weight_loaded = True\n            print(""Network file [{}] is loaded successfully."".format(model_network_path))\n        else:\n            print(""Warning: Weights File [{}] is not found."".format(model_network_path))\n\n        return loaded_model_pb\n\n\n    @property\n    def src_graph(self):\n        return self.coreml_graph\n\n\n\n    def gen_IR(self):\n        for i, layer in enumerate(self.coreml_graph.topological_sort):\n\n            current_node = self.coreml_graph.get_node(layer)\n            current_node_layer = current_node.layer\n\n            # determine the type of the current_node\n            node_type = current_node_layer.name\n\n            if isinstance(current_node_layer, Model_pb2.FeatureDescription):\n                self.rename_InputLayer(current_node)\n            elif isinstance(current_node_layer, NeuralNetwork_pb2.NeuralNetworkLayer):\n                if current_node_layer.HasField(""convolution""):\n                    self.rename_CONV2D(current_node)\n                elif current_node_layer.HasField(\'batchnorm\'):\n                    self.rename_BatchNormalization(current_node)\n                elif current_node_layer.HasField(""scale""):\n                    self.rename_scale(current_node)\n                elif current_node_layer.HasField(""pooling""):\n                    self.rename_Pooling(current_node)\n                elif current_node_layer.HasField(""activation""):\n                    self.rename_Activation(current_node)\n                elif current_node_layer.HasField(""softmax""):\n                    self.rename_Softmax(current_node)\n                elif current_node_layer.HasField(""padding""):\n                    self.rename_Padding(current_node)\n                elif current_node_layer.HasField(""add""):\n                    self.rename_Add(current_node)\n                elif current_node_layer.HasField(""flatten""):\n                    self.rename_Flatten(current_node)\n                elif current_node_layer.HasField(""innerProduct""):\n                    self.rename_innerProduct(current_node)\n                elif current_node_layer.HasField(""concat""):\n                    self.rename_Concatenate(current_node)\n                else:\n                    print(""CoremlParser has not supported operator [{}]"".format(node_type))\n                    self.rename_UNKNOWN(current_node)\n            else:\n                assert False\n\n\n\n    # staticmethods\n    @staticmethod\n    def _set_output_shape(source_node, IR_node):\n\n        shape = graph_pb2.TensorShape()\n        source_node_layer = source_node.layer\n\n        layer_name = source_node_layer.output[0]\n\n        shape_coreml = CoremlParser.shape_dict[layer_name]\n        # (seq, batch, C, H, W)  & NHWC\n\n        new_dim = shape.dim.add()\n        if shape_coreml[1] == 1:\n            new_dim.size = -1\n        else:\n            new_dim.size = shape_coreml[1]\n        for index in [3, 4, 2]:\n            new_dim = shape.dim.add()\n            dim = shape_coreml[index]\n            new_dim.size = dim if dim else -1\n\n        IR_node.attr[""_output_shapes""].list.shape.extend([shape])\n\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op = None):\n        source_node_layer = source_node.layer\n        IR_node.name = source_node_layer.name\n\n        if new_op:\n            IR_node.op = new_op\n        elif source_node_layer.HasField(""convolution""):\n            IR_node.op = ""convolution""\n        elif source_node_layer.HasField(\'batchnorm\'):\n            IR_node.op = ""batchnorm""\n        elif source_node_layer.HasField(""scale""):\n            IR_node.op = ""scale""\n        elif source_node_layer.HasField(""pooling""):\n            IR_node.op = ""pooling""\n        elif source_node_layer.HasField(""activation""):\n            IR_node.op = ""activation""\n        elif source_node_layer.HasField(""softmax""):\n            IR_node.op = ""softmax""\n        elif source_node_layer.HasField(""padding""):\n            IR_node.op = ""padding""\n        elif source_node_layer.HasField(""add""):\n            IR_node.op = ""add""\n        elif source_node_layer.HasField(""flatten""):\n            IR_node.op = ""flatten""\n        elif source_node_layer.HasField(""innerProduct""):\n            IR_node.op = ""innerProduct""\n        elif source_node_layer.HasField(""concat""):\n            IR_node.op = ""concatenate""\n        else:\n            assert False\n\n        #  TODO dtype_map\n        if hasattr(source_node.layer, ""dtype""):\n            IR_node.attr[""dtype""].type = CoremlParser.dtype_map[source_node.layer.dtype]\n\n        CoremlParser._set_output_shape(source_node, IR_node)\n\n    @staticmethod\n    def _copy_shape(source_node, target_node):\n        if hasattr(source_node, ""output_shape""):\n            for dim in source_node.output_shape:\n                new_dim = target_node.attr[\'shape\'].shape.dim.add()\n                new_dim.size = -1 if dim == None else new_dim\n        else:\n            target_node.attr[\'shape\'].shape.unknown_rank = True\n\n    @staticmethod\n    def _convert_dataformat(source_node, target_node):\n        if source_node.coreml_layer.data_format == ""channels_last"":\n            target_node.attr[\'data_format\'].s = ""NHWC""\n        elif source_node.coreml_layer.data_format == \'channels_first\':\n            target_node.attr[\'data_format\'].s = ""NCHW""\n        else:\n            print(""Warning: [%s] don\'t have data format info"" % (source_node.coreml_layer.name))\n\n\n###### convert methods\n\n    # convolution\n    def __convert_convolution(self, source_node, dim):\n\n        IR_node = self.IR_graph.node.add()\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n        source_node_layer = source_node.layer\n        source_node_conv = source_node_layer.convolution\n        layer_name = source_node_layer.name.split(\'/\')[-1]\n\n        # important!\n        if source_node_conv.HasField(\'weights\'):\n            # reshape the weight!\n            [h , w , k , o] = list(source_node_conv.kernelSize) + [source_node_conv.kernelChannels , source_node_conv.outputChannels]\n            # [2, 3, 0, 1]\n            weights = np.array(source_node_conv.weights.floatValue, dtype=np.float32).reshape([o, k, h, w]).transpose([2, 3, 1, 0])\n\n\n\n        kwargs = dict()\n        kwargs[\'kernel_shape\'] = list(source_node_conv.kernelSize) + [source_node_conv.kernelChannels, source_node_conv.outputChannels]\n\n        # pads\n        CoremlParser._convert_padding(source_node, IR_node)\n        # use_bias\n        kwargs[\'use_bias\'] = source_node_conv.hasBias\n        # isDeconvolution\n        kwargs[\'isDeconvolution\'] = source_node_conv.isDeconvolution\n        # name, op\n        if layer_name == \'sep\':\n            CoremlParser._copy_and_reop(source_node, IR_node, ""Conv"")\n        elif layer_name == \'dw\':\n            CoremlParser._copy_and_reop(source_node, IR_node, ""DepthwiseConv"")\n            weights = weights.transpose((0,1,3,2))\n            kwargs[\'kernel_shape\'] = list(source_node_conv.kernelSize) + [source_node_conv.outputChannels, source_node_conv.kernelChannels]\n\n\n        else:\n            if kwargs[\'isDeconvolution\']:\n                CoremlParser._copy_and_reop(source_node, IR_node, ""ConvTranspose"")\n            else:\n                CoremlParser._copy_and_reop(source_node, IR_node, ""Conv"")\n\n        self.set_weight(source_node.name, \'weights\',  weights)\n        if source_node_layer.convolution.HasField(\'bias\'):\n            self.set_weight(source_node.name, \'bias\', np.array(source_node_conv.bias.floatValue, dtype=np.float32))\n\n\n\n        # kwargs[\'kernel_shape\'] = weights.shape\n\n        kwargs[\'group\'] = source_node_conv.nGroups\n\n        # strides\n        # [1, sd, sh, sw, 1]\n        kwargs[\'strides\'] = [1] + list(source_node_conv.stride) + [1]\n\n        dilation = list(source_node_conv.dilationFactor)\n        if dilation == []:\n            dilation = [1,1]\n        kwargs[\'dilations\'] = [1] + dilation + [1]\n\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n        # activation\n        # TODO\n        self._defuse_activation(source_node)\n\n\n\n    @staticmethod\n    def _convert_padding(source_node, IR_node):\n        source_node_layer = source_node.layer\n\n        if source_node_layer.HasField(\'convolution\'):\n            # padding in conv\n\n            source_node_conv = source_node_layer.convolution\n\n\n            if source_node_conv.HasField(\'valid\'):\n                # pad in IR is [x1_b, x2_b, ..., x1_e, x2_e, ...]\n\n                dim = []\n                for i in source_node_conv.valid.paddingAmounts.borderAmounts:\n                    dim.extend([i.startEdgeSize, i.endEdgeSize])\n\n\n                if dim == []:\n                    assign_IRnode_values(IR_node, { \'auto_pad\': \'VALID\'})\n                    pad_dim = [0] * 8\n                    pad_dim = convert_tf_pad_to_onnx(pad_dim)\n\n                    assign_IRnode_values(IR_node, { \'pads\':  pad_dim})\n                else:\n\n                    # padding\n                    pad_dim = [0, 0]\n\n                    pad_dim.extend(dim)\n\n                    pad_dim += [0, 0]\n\n                    pad_dim = convert_tf_pad_to_onnx(pad_dim)\n\n\n                    assign_IRnode_values(IR_node, { \'pads\':  pad_dim})\n\n            elif source_node_conv.HasField(\'same\'):\n\n                # compute padding for \'same\'\n                assign_IRnode_values(IR_node, {\'auto_pad\': ""SAME""})\n\n\n                kernel = list(source_node_conv.kernelSize)\n                dilation = list(source_node_conv.dilationFactor)\n                if dilation == []:\n                    dilation = [1,1]\n                stride = list(source_node_conv.stride)\n                if stride == []:\n                    stride = [1,1]\n\n                kernel[0] = dilation[0] * ( kernel[0] -1 ) + 1\n                kernel[1] = dilation[1] * ( kernel[1] -1 ) + 1\n\n\n                if stride == [1,1]:\n\n                    # https://discuss.mxnet.io/t/pooling-and-convolution-with-same-mode/528/3\n\n                    p0 =  ( kernel[0] -1 ) // 2\n                    p1 =  ( kernel[1] -1 ) // 2\n\n                    if kernel[0] % 2 == 0:\n                        p00 = p0\n                        p01 = p0 + 1\n                    else:\n                        p00 = p0\n                        p01 = p0\n\n                    if kernel[1] % 2 == 0:\n                        p10 = p1\n                        p11 = p1 + 1\n                    else:\n                        p10 = p1\n                        p11 = p1\n\n                    pad_dim = [0, 0, p00, p01, p10, p11, 0, 0]\n\n\n                    pad_dim = convert_tf_pad_to_onnx(pad_dim)\n\n                    assign_IRnode_values(IR_node, { \'pads\':  pad_dim})\n                else:\n                    # https://www.jianshu.com/p/05c4f1621c7e\n                    pad_dim = [0, 0, 0, 0, 0, 0, 0, 0]\n\n                    pad_dim = convert_tf_pad_to_onnx(pad_dim)\n\n                    assign_IRnode_values(IR_node, { \'pads\':  pad_dim})\n\n            else:\n                assert False\n\n        elif source_node_layer.HasField(\'pooling\'):\n            # padding in pooling\n            source_node_pool = source_node_layer.pooling\n            if  source_node_pool.HasField(\'valid\'):\n\n                dim = []\n                for i in source_node_pool.valid.paddingAmounts.borderAmounts:\n                    dim.extend([i.startEdgeSize, i.endEdgeSize])\n\n\n                if dim == []:\n                    assign_IRnode_values(IR_node, { \'auto_pad\': \'VALID\'})\n                    pad_dim = [0] * 8\n                    pad_dim = convert_tf_pad_to_onnx(pad_dim)\n\n                    assign_IRnode_values(IR_node, { \'pads\':  pad_dim})\n                else:\n                    # padding\n                    pad_dim = [0, 0]\n\n                    pad_dim.extend(dim)\n\n                    pad_dim += [0, 0]\n                    pad_dim = convert_tf_pad_to_onnx(pad_dim)\n                    assign_IRnode_values(IR_node, { \'pads\':  pad_dim})\n\n\n            elif source_node_pool.HasField(\'same\'):\n\n                assign_IRnode_values(IR_node, { \'auto_pad\': \'SAME\'})\n\n                kernel = list(source_node_pool.kernelSize)\n                stride = list(source_node_pool.stride)\n                if stride == []:\n                    stride = [1,1]\n\n\n                if stride == [1,1]:\n                    # https://discuss.mxnet.io/t/pooling-and-convolution-with-same-mode/528/3\n                    p0 =  ( kernel[0] -1 ) // 2\n                    p1 =  ( kernel[1] -1 ) // 2\n\n\n\n                    if kernel[0] % 2 == 0:\n                        p00 = p0\n                        p01 = p0 + 1\n                    else:\n                        p00 = p0\n                        p01 = p0\n\n                    if kernel[1] % 2 == 0:\n                        p10 = p1\n                        p11 = p1 + 1\n                    else:\n                        p10 = p1\n                        p11 = p1\n\n                    pad_dim = [0, 0, p00, p01, p10, p11, 0, 0]\n\n\n\n                    pad_dim = convert_tf_pad_to_onnx(pad_dim)\n\n                    assign_IRnode_values(IR_node, { \'pads\':  pad_dim})\n                else:\n                    # TODO\n                    pad_dim = [0, 0, 0, 0, 0, 0, 0, 0]\n\n                    pad_dim = convert_tf_pad_to_onnx(pad_dim)\n\n                    assign_IRnode_values(IR_node, { \'pads\':  pad_dim})\n\n            elif source_node_pool.HasField(\'includeLastPixel\'):\n\n                # symmetric padding\n                h, w = source_node_pool.includeLastPixel.paddingAmounts\n                assign_IRnode_values(IR_node, { \'pads\':  [ 0,h, h,0,0, w, w,0]})\n            else:\n                assert False\n\n        else:\n            assert False\n\n\n\n\n    def _convert_merge(self, source_node, new_name = None):\n\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        CoremlParser._copy_and_reop(source_node, IR_node, new_name)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # For concat axis\n        # NO axis in coreml, so set the last axis\n        IR_node.attr[\'axis\'].i = len(CoremlParser.shape_dict[source_node.layer.output[0]])-1 -1\n        # The first -1 means in coreml there is one-more axis,\n        # The second -1 means the last axis\n\n        return IR_node\n\n\n    def _convert_padding_api(self, source_node, IR_node):\n        # name, op\n        CoremlParser._copy_and_reop(source_node, IR_node, ""Pad"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        kwargs = dict()\n\n        source_node_layer = source_node.layer\n        source_node_pad = source_node_layer.padding\n\n        if source_node_pad.HasField(\'constant\'):\n            kwargs[\'mode\'] = \'CONSTANT\'\n        elif source_node_pad.HasField(\'reflection\'):\n            kwargs[\'mode\'] = \'REFLECT\'\n        elif source_node_pad.HasField(\'replication\'):\n            kwargs[\'mode\'] = \'SYMMETRIC\'\n        else:\n            assert False\n\n\n        dim = []\n        for i in source_node_pad.paddingAmounts.borderAmounts:\n            dim.extend([i.startEdgeSize, i.endEdgeSize])\n\n\n        if dim == []:\n            dim = [0,0,0,0]\n\n        # padding\n        kwargs[\'pads\'] = [0, 0]\n\n        kwargs[\'pads\'].extend(dim)\n\n        kwargs[\'pads\'] += [0, 0]\n        kwargs[\'pads\'] = convert_tf_pad_to_onnx(kwargs[\'pads\'])\n\n        assign_IRnode_values(IR_node, kwargs)\n\n    def _defuse_activation(self, source_node):\n        # Future Module TODO\n        pass\n        return\n\n\n##### rename methods\n\n\n    def rename_UNKNOWN(self, source_node):\n        print(source_node.layer.get_config())\n        IR_node = self.IR_graph.node.add()\n        CoremlParser._copy_and_reop(source, IR_node)\n        self.convert_inedge(source_node, IR_node)\n\n\n\n    def rename_Activation(self, coreml_node):\n        IR_node = self.IR_graph.node.add()\n\n\n        coreml_node_layer = coreml_node.layer\n        coreml_node_activation = coreml_node_layer.activation\n\n        # name, op\n        for activation_name in self.activation_map.keys():\n            if coreml_node_activation.HasField(activation_name):\n                CoremlParser._copy_and_reop(coreml_node, IR_node, self.activation_map[activation_name])\n\n\n        # activation type\n        activation_type = coreml_node_activation.WhichOneof(""NonlinearityType"")\n\n\n        if activation_type == \'leakyReLU\':\n            assign_IRnode_values(IR_node, {\'alpha\' : coreml_node_activation.leakyReLU.alpha})\n        elif activation_type == \'PReLU\':\n            assign_IRnode_values(IR_node, {\'gamma\' : coreml_node_activation.PReLU.alpha})\n        elif activation_type == \'ELU\':\n            assign_IRnode_values(IR_node, {\'alpha\' : coreml_node_activation.ELU.alpha})\n        elif activation_type == \'thresholdedRelu\':\n            assign_IRnode_values(IR_node, {\'alpha\' : coreml_node_activation.thresholdedReLU.alpha})\n        elif activation_type == \'scaledTanh\':\n            assign_IRnode_values(IR_node, {\'alpha\' : coreml_node_activation.scaledTanh.alpha})\n            assign_IRnode_values(IR_node, {\'beta\' : coreml_node_activation.scaledTanh.beta})\n        elif activation_type == \'linear\':\n            assign_IRnode_values(IR_node, {\'alpha\' : coreml_node_activation.linear.alpha})\n            assign_IRnode_values(IR_node, {\'beta\' : coreml_node_activation.linear.beta})\n        elif activation_type == \'sigmoidHard\':\n            assign_IRnode_values(IR_node, {\'alpha\' : coreml_node_activation.sigmoidHard.alpha})\n            assign_IRnode_values(IR_node, {\'beta\' : coreml_node_activation.sigmoidHard.beta})\n        elif activation_type == \'parametricSoftplus\':\n            assign_IRnode_values(IR_node, {\'alpha\' : coreml_node_activation.parametricSoftplus.alpha})\n            assign_IRnode_values(IR_node, {\'beta\' : coreml_node_activation.parametricSoftplus.beta})\n        # else:\n            # assert False\n\n        # input edge\n        self.convert_inedge(coreml_node, IR_node)\n\n    # Merge layers\n    def rename_Add(self, source_node):\n        self._convert_merge(source_node, \'Add\')\n\n    def rename_CONV2D(self, source_node):\n        self.__convert_convolution(source_node, 2)\n\n\n    def rename_InputLayer(self, source_node):\n        # only for training\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        IR_node.name = source_node.name\n        IR_node.op = ""DataInput""\n        graph_shape = graph_pb2.TensorShape()\n        coreml_node_layer = source_node.layer\n\n        new_dim = graph_shape.dim.add()\n        new_dim.size = -1\n        new_dim = graph_shape.dim.add()\n        new_dim.size = coreml_node_layer.type.imageType.width\n        new_dim = graph_shape.dim.add()\n        new_dim.size = coreml_node_layer.type.imageType.height\n        new_dim = graph_shape.dim.add()\n\n        if coreml_node_layer.type.imageType.colorSpace == 10:\n            new_dim.size = 2\n        elif coreml_node_layer.type.imageType.colorSpace == 20:\n            new_dim.size = 3\n        elif coreml_node_layer.type.imageType.colorSpace == 30:\n            new_dim.size = 3\n        else:\n            assert False\n        IR_node.attr[""_output_shapes""].list.shape.extend([graph_shape])\n\n\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n\n\n\n        # shape\n        # NHWC channel last\n        # in fact, here is NWHC\n        new_dim = IR_node.attr[\'shape\'].shape.dim.add()\n        new_dim.size = -1\n        new_dim = IR_node.attr[\'shape\'].shape.dim.add()\n        new_dim.size = coreml_node_layer.type.imageType.width\n        new_dim = IR_node.attr[\'shape\'].shape.dim.add()\n        new_dim.size = coreml_node_layer.type.imageType.height\n        new_dim = IR_node.attr[\'shape\'].shape.dim.add()\n\n        if coreml_node_layer.type.imageType.colorSpace == 10:\n            new_dim.size = 2\n        elif coreml_node_layer.type.imageType.colorSpace == 20:\n            new_dim.size = 3\n        elif coreml_node_layer.type.imageType.colorSpace == 30:\n            new_dim.size = 3\n        else:\n            assert False\n\n\n    def rename_BatchNormalization(self, coreml_node):\n\n        IR_node = self.IR_graph.node.add()\n\n        coreml_node_layer = coreml_node.layer\n        coreml_node_bn = coreml_node_layer.batchnorm\n\n\n        # name, op\n        CoremlParser._copy_and_reop(coreml_node, IR_node, ""BatchNorm"")\n\n        # input edge\n        self.convert_inedge(coreml_node, IR_node)\n\n\n        # axis TODO\n        # channels_first, then axis = 1\n        IR_node.attr[\'axis\'].i = -1\n\n        # scale\n        IR_node.attr[\'scale\'].b = coreml_node_bn.HasField(""gamma"")\n\n        # bias\n        IR_node.attr[\'bias\'].b = coreml_node_bn.HasField(""beta"")\n\n        # epsilon\n        IR_node.attr[\'epsilon\'].f = coreml_node_bn.epsilon\n\n        if IR_node.attr[\'scale\'].b:\n            self.set_weight(coreml_node_layer.name, ""scale"", np.array(coreml_node_bn.gamma.floatValue, dtype=np.float32))\n\n        if IR_node.attr[\'bias\'].b:\n            self.set_weight(coreml_node_layer.name, ""bias"", np.array(coreml_node_bn.beta.floatValue, dtype=np.float32))\n\n\n\n        gamma, beta = None, None\n        if IR_node.attr[\'scale\'].b:\n            gamma = np.array(coreml_node_bn.gamma.floatValue, dtype=np.float32)\n        if IR_node.attr[\'bias\'].b:\n            beta =  np.array(coreml_node_bn.beta.floatValue, dtype=np.float32)\n\n        mean = np.array(coreml_node_bn.mean.floatValue)\n        variance  =  np.array(coreml_node_bn.variance.floatValue)\n\n        gamma = np.ones(mean.shape) if gamma is None else gamma\n        beta = np.zeros(mean.shape) if beta is None else beta\n\n        # compute adjusted parameters\n        # Reference: parameter transformation https://github.com/apple/coremltools/issues/153\n        f = 1.0 / np.sqrt(variance +  coreml_node_bn.epsilon)\n        gamma1 = gamma*f\n        beta1 = beta - gamma*mean*f\n        mean[:] = 0.0 #mean\n        variance[:] = 1.0 - .00001 #stddev\n\n        # convert type because of tensorflow\n        gamma1 = gamma1.astype(np.float32)\n        beta1 = beta1.astype(np.float32)\n        mean = mean.astype(np.float32)\n        variance = variance.astype(np.float32)\n\n\n        if IR_node.attr[\'scale\'].b:\n            self.set_weight(coreml_node_layer.name, ""scale"", gamma1)\n\n        if IR_node.attr[\'bias\'].b:\n            self.set_weight(coreml_node_layer.name, ""bias"", beta1)\n\n        # mean\n        self.set_weight(coreml_node_layer.name, ""mean"", mean)\n\n        # var\n        self.set_weight(coreml_node_layer.name, ""var"", variance)\n\n    def rename_scale(self, coreml_node):\n\n\n        IR_node = self.IR_graph.node.add()\n\n        coreml_node_layer = coreml_node.layer\n        coreml_node_scale = coreml_node_layer.scale\n\n\n\n        # name, op\n        CoremlParser._copy_and_reop(coreml_node, IR_node, ""Scale"")\n\n        # input edge\n        self.convert_inedge(coreml_node, IR_node)\n\n        # bias\n        IR_node.attr[\'use_bias\'].b = coreml_node_scale.hasBias\n\n        IR_node.attr[\'scale\'].b = True\n\n\n        self.set_weight(coreml_node_layer.name, ""scale"", np.array(coreml_node_scale.scale.floatValue).astype(np.float32))\n        self.set_weight(coreml_node_layer.name, ""scale_mean"", np.zeros_like(coreml_node_scale.scale.floatValue).astype(np.float32))\n        self.set_weight(coreml_node_layer.name, ""scale_var"", np.ones_like(coreml_node_scale.scale.floatValue).astype(np.float32))\n\n        self.set_weight(coreml_node_layer.name, ""shapeScale"", coreml_node_scale.shapeScale[0])\n\n\n\n        if IR_node.attr[\'use_bias\'].b:\n            self.set_weight(coreml_node_layer.name, ""bias"", np.array(coreml_node_scale.bias.floatValue).astype(np.float32))\n            self.set_weight(coreml_node_layer.name, ""shapeBias"", coreml_node_scale.shapeBias[0])\n\n    def rename_Pooling(self, coreml_node):\n\n\n        IR_node = self.IR_graph.node.add()\n\n        coreml_node_layer = coreml_node.layer\n        coreml_node_pool = coreml_node_layer.pooling\n\n\n\n\n\n        # name, op\n        CoremlParser._copy_and_reop(coreml_node, IR_node, ""Pool"")\n\n        # input edge\n        self.convert_inedge(coreml_node, IR_node)\n\n        kwargs = {}\n\n        # MAX = 0, AVERAGE = 1, L2 = 2\n        if coreml_node_pool.type == 0:\n            kwargs[\'pooling_type\'] = \'MAX\'\n        elif coreml_node_pool.type == 1:\n            kwargs[\'pooling_type\'] = \'AVG\'\n        elif coreml_node_pool.type == 2:\n            kwargs[\'pooling_type\'] = \'L2\'\n\n\n\n        is_global = coreml_node_pool.globalPooling\n\n\n        if is_global:\n            kwargs[\'global_pooling\'] = True\n            kwargs[\'global_pooling_coreml\'] = True\n            kwargs[\'shape_coreml\'] = [self.shape_dict[coreml_node_layer.name][3], self.shape_dict[coreml_node_layer.name][4], self.shape_dict[coreml_node_layer.name][2] ]\n\n\n        # padding\n        self._convert_padding(coreml_node, IR_node)\n\n        # strides\n        # [1, sd, sh, sw, 1]\n        kwargs[\'strides\'] = [1] + list(coreml_node_pool.stride) + [1]\n\n\n        # window_shape\n        # [1, pd, ph, pw, 1]\n        kwargs[\'kernel_shape\'] = [1] + list(coreml_node_pool.kernelSize) + [1]\n\n\n\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n\n\n    def rename_Softmax(self, coreml_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        CoremlParser._copy_and_reop(coreml_node, IR_node, \'Softmax\')\n\n        # input edge\n        self.convert_inedge(coreml_node, IR_node)\n\n    def rename_Concatenate(self, source_node):\n        IR_node = self._convert_merge(source_node, \'Concat\')\n\n\n    def rename_Flatten(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        CoremlParser._copy_and_reop(source_node, IR_node, \'Flatten\')\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n\n    def rename_innerProduct(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        CoremlParser._copy_and_reop(source_node, IR_node, ""FullyConnected"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        source_node_layer = source_node.layer\n        source_node_inner = source_node_layer.innerProduct\n\n\n        # units\n        IR_node.attr[\'units\'].i = source_node_inner.outputChannels\n\n        # use_bias\n        IR_node.attr[\'use_bias\'].b = source_node_inner.hasBias\n\n        # weights\n        self.set_weight(source_node_layer.name, \'weights\', np.array(source_node_inner.weights.floatValue).astype(np.float32).reshape( source_node_inner.outputChannels,  source_node_inner.inputChannels).transpose() )\n        if IR_node.attr[\'use_bias\'].b:\n            self.set_weight(source_node_layer.name, \'bias\', np.array(source_node_inner.bias.floatValue).astype(np.float32) )\n        # change to single because of the tf matmul\n        \n        # in features\n        IR_node.attr[\'in_features\'].i = source_node_inner.inputChannels\n\n    def rename_Padding(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        self._convert_padding_api(source_node, IR_node)\n\n'"
mmdnn/conversion/coreml/coreml_utils.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom coremltools.models import datatypes\n\ndef _infer_coreml_input_shape(IR_shape, if_convert=True):\n    """"""Infer CoreML input shape from IR shape.\n    """"""\n    if len(IR_shape) == 0:\n        # the end of the tensorflow_resnet_v2_50\'s squeeze shape is [unknown_rank: true] with len 0\n        # 1001 means the 1001 classes for tensorflow_resnet_v2_50\n        # !Alert! TODO\n        # Future implement can be changed to the last two layer\n        shape = [1001,1,1]\n    elif len(IR_shape) == 1:\n        # TODO - remove style transfer 1D hack\n        # Input is 1D but it goes to the width dimension: (1,1,W)\n        shape = [1, 1, IR_shape[0]]  #(C,H,W)\n    elif len(IR_shape) == 2:\n        # assume (Batch, Channels) - Batch dimension should be dropped\n        shape = [IR_shape[1]]\n    elif len(IR_shape) == 3:\n        # assume (Batch, Sequence-Length, channels)\n        shape = [IR_shape[2], 1, IR_shape[1]]\n    elif len(IR_shape) == 4:   #(B,H,W,C) --> (C,H,W)\n        shape = [IR_shape[3], IR_shape[1], IR_shape[2]] #(C,H,W)\n    else:\n        raise ValueError(\'Unrecognized IR input shape {}\'.format(shape))\n    if if_convert:\n        shape = datatypes.Array(*shape)\n    return shape\n'"
mmdnn/conversion/darknet/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/darknet/cfg.py,13,"b""import torch\nfrom collections import OrderedDict\n\ndef parse_cfg(cfgfile):\n    def erase_comment(line):\n        line = line.split('#')[0]\n        return line\n    blocks = []\n    fp = open(cfgfile, 'r')\n    block =  None\n    line = fp.readline()\n    while line != '':\n        line = line.rstrip()\n        if line == '' or line[0] == '#':\n            line = fp.readline()\n            continue        \n        elif line[0] == '[':\n            if block:\n                blocks.append(block)\n            block = OrderedDict()\n            block['type'] = line.lstrip('[').rstrip(']')\n            # set default value\n            if block['type'] == 'convolutional':\n                block['batch_normalize'] = 0\n        else:\n            line = erase_comment(line)\n            key,value = line.split('=')\n            key = key.strip()\n            if key == 'type':\n                key = '_type'\n            value = value.strip()\n            block[key] = value\n        line = fp.readline()\n\n    if block:\n        blocks.append(block)\n    fp.close()\n    return blocks\n\ndef print_cfg(blocks):\n    for block in blocks:\n        print('[%s]' % (block['type']))\n        for key,value in block.items():\n            if key != 'type':\n                print('%s=%s' % (key, value))\n        print('')\ndef save_cfg(blocks, cfgfile):\n    with open(cfgfile, 'w') as fp:\n        for block in blocks:\n            fp.write('[%s]\\n' % (block['type']))\n            for key,value in block.items():\n                if key != 'type':\n                    fp.write('%s=%s\\n' % (key, value))\n            fp.write('\\n')\n\ndef print_cfg_nicely(blocks):\n    print('layer     filters    size              input                output');\n    prev_width = 416\n    prev_height = 416\n    prev_filters = 3\n    out_filters =[]\n    out_widths =[]\n    out_heights =[]\n    ind = -2\n    for block in blocks:\n        ind = ind + 1\n        if block['type'] == 'net':\n            prev_width = int(block['width'])\n            prev_height = int(block['height'])\n            continue\n        elif block['type'] == 'convolutional':\n            filters = int(block['filters'])\n            kernel_size = int(block['size'])\n            stride = int(block['stride'])\n            is_pad = int(block['pad'])\n            pad = (kernel_size-1)/2 if is_pad else 0\n            width = (prev_width + 2*pad - kernel_size)/stride + 1\n            height = (prev_height + 2*pad - kernel_size)/stride + 1\n            print('%5d %-6s %4d  %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'conv', filters, kernel_size, kernel_size, stride, prev_width, prev_height, prev_filters, width, height, filters))\n            prev_width = width\n            prev_height = height\n            prev_filters = filters\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'maxpool':\n            pool_size = int(block['size'])\n            stride = int(block['stride'])\n            width = prev_width/stride\n            height = prev_height/stride\n            print('%5d %-6s       %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'max', pool_size, pool_size, stride, prev_width, prev_height, prev_filters, width, height, filters))\n            prev_width = width\n            prev_height = height\n            prev_filters = filters\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'avgpool':\n            width = 1\n            height = 1\n            print('%5d %-6s                   %3d x %3d x%4d   ->      %3d' % (ind, 'avg', prev_width, prev_height, prev_filters,  prev_filters))\n            prev_width = 1\n            prev_height = 1\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'softmax':\n            print('%5d %-6s                                    ->      %3d' % (ind, 'softmax', prev_filters))\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'cost':\n            print('%5d %-6s                                     ->      %3d' % (ind, 'cost', prev_filters))\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'reorg':\n            stride = int(block['stride'])\n            filters = stride * stride * prev_filters\n            width = prev_width/stride\n            height = prev_height/stride\n            print('%5d %-6s             / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'reorg', stride, prev_width, prev_height, prev_filters, width, height, filters))\n            prev_width = width\n            prev_height = height\n            prev_filters = filters\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'route':\n            layers = block['layers'].split(',')\n            layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n            if len(layers) == 1:\n                print('%5d %-6s %d' % (ind, 'route', layers[0]))\n                prev_width = out_widths[layers[0]]\n                prev_height = out_heights[layers[0]]\n                prev_filters = out_filters[layers[0]]\n            elif len(layers) == 2:\n                print('%5d %-6s %d %d' % (ind, 'route', layers[0], layers[1]))\n                prev_width = out_widths[layers[0]]\n                prev_height = out_heights[layers[0]]\n                assert(prev_width == out_widths[layers[1]])\n                assert(prev_height == out_heights[layers[1]])\n                prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'region':\n            print('%5d %-6s' % (ind, 'detection'))\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'shortcut':\n            from_id = int(block['from'])\n            from_id = from_id if from_id > 0 else from_id+ind\n            print('%5d %-6s %d' % (ind, 'shortcut', from_id))\n            prev_width = out_widths[from_id]\n            prev_height = out_heights[from_id]\n            prev_filters = out_filters[from_id]\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'softmax':\n            print('%5d %-6s' % (ind, 'softmax'))\n            out_widths.append(prev_width)\n            out_heights.append(prev_height)\n            out_filters.append(prev_filters)\n        elif block['type'] == 'connected':\n            filters = int(block['output'])\n            print('%5d %-6s                            %d  ->      %3d' % (ind, 'connected', prev_filters,  filters))\n            prev_filters = filters\n            out_widths.append(1)\n            out_heights.append(1)\n            out_filters.append(prev_filters)\n        else:\n            print('unknown type %s' % (block['type']))\n\ndef load_conv(buf, start, conv_model):\n    num_w = conv_model.weight.numel()\n    num_b = conv_model.bias.numel()\n    conv_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\n    return start\n\ndef save_conv(fp, conv_model):\n    if conv_model.bias.is_cuda:\n        convert2cpu(conv_model.bias.data).numpy().tofile(fp)\n        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n    else:\n        conv_model.bias.data.numpy().tofile(fp)\n        conv_model.weight.data.numpy().tofile(fp)\n\ndef load_conv_bn(buf, start, conv_model, bn_model):\n    num_w = conv_model.weight.numel()\n    num_b = bn_model.bias.numel()\n    bn_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));     start = start + num_b\n    bn_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n    bn_model.running_mean.copy_(torch.from_numpy(buf[start:start+num_b]));  start = start + num_b\n    bn_model.running_var.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w \n    return start\n\ndef save_conv_bn(fp, conv_model, bn_model):\n    if bn_model.bias.is_cuda:\n        convert2cpu(bn_model.bias.data).numpy().tofile(fp)\n        convert2cpu(bn_model.weight.data).numpy().tofile(fp)\n        convert2cpu(bn_model.running_mean).numpy().tofile(fp)\n        convert2cpu(bn_model.running_var).numpy().tofile(fp)\n        convert2cpu(conv_model.weight.data).numpy().tofile(fp)\n    else:\n        bn_model.bias.data.numpy().tofile(fp)\n        bn_model.weight.data.numpy().tofile(fp)\n        bn_model.running_mean.numpy().tofile(fp)\n        bn_model.running_var.numpy().tofile(fp)\n        conv_model.weight.data.numpy().tofile(fp)\n\ndef save_conv_shrink_bn(fp, conv_model, bn_model, eps=1e-5):\n    if bn_model.bias.is_cuda:\n        bias = bn_model.bias.data - bn_model.running_mean * bn_model.weight.data / torch.sqrt(bn_model.running_var + eps)\n        convert2cpu(bias).numpy().tofile(fp)\n        s = conv_model.weight.data.size()\n        weight = conv_model.weight.data * (bn_model.weight.data / torch.sqrt(bn_model.running_var + eps)).view(-1,1,1,1).repeat(1, s[1], s[2], s[3])\n        convert2cpu(weight).numpy().tofile(fp)\n    else:\n        bias = bn_model.bias.data - bn_model.running_mean * bn_model.weight.data / torch.sqrt(bn_model.running_var + eps)\n        bias.numpy().tofile(fp)\n        s = conv_model.weight.data.size()\n        weight = conv_model.weight.data * (bn_model.weight.data / torch.sqrt(bn_model.running_var + eps)).view(-1,1,1,1).repeat(1, s[1], s[2], s[3])\n        weight.numpy().tofile(fp)\n\ndef load_fc(buf, start, fc_model):\n    num_w = fc_model.weight.numel()\n    num_b = fc_model.bias.numel()\n    fc_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));     start = start + num_b\n    fc_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w]));   start = start + num_w \n    return start\n\ndef save_fc(fp, fc_model):\n    fc_model.bias.data.numpy().tofile(fp)\n    fc_model.weight.data.numpy().tofile(fp)\n\n\nif __name__ == '__main__':\n    import sys\n    if len(sys.argv) != 2:\n        print('Usage: python cfg.py model.cfg')\n        exit()\n\n    blocks = parse_cfg(sys.argv[1])\n    print_cfg_nicely(blocks)\n"""
mmdnn/conversion/darknet/darknet_graph.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom collections import OrderedDict\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\n# from tensorflow.core.framework.node_def_pb2 import NodeDef\n# from tensorflow.core.framework import attr_value_pb2\n\n\nclass DarknetGraphNode(GraphNode):\n\n    def __init__(self, layer):\n\n        super(DarknetGraphNode, self).__init__(layer)\n\n\n    @property\n    def name(self):\n        return self.layer[\'name\']\n\n\n    @property\n    def type(self):\n        return self.layer[\'type\']\n\n\n    @property\n    def dk_layer(self):\n        return self.layer\n\n\n    def get_attr(self, name, default_value = None):\n        if name in self.layer[\'attr\'].keys():\n            return self.layer[\'attr\'][name]\n        else:\n            return default_value\n\n\nclass DarknetGraph(Graph):\n\n    def __init__(self, model):\n        # pass\n\n        super(DarknetGraph, self).__init__(model)\n        self.layer_num_map = {}\n        self.model = model\n        self.weights = {}\n        self.original_list = OrderedDict()\n\n    @staticmethod\n    def dim_str_to_int(input_dim):\n        if type(input_dim) == list:\n            return [int(i) for i in input_dim]\n\n    @staticmethod\n    def conv_output_width(width, padding, kernel_size, stride):\n        return (width + 2*padding - kernel_size)/stride + 1\n\n    @staticmethod\n    def conv_output_height(height, padding, kernel_size, stride):\n        return (height + 2*padding - kernel_size)/stride + 1\n\n    def build(self):\n\n        for i, block in enumerate(self.model):\n            # print(""\\n"")\n            # print(i)\n            # print(block)\n\n            # continue\n            node = OrderedDict()\n            if block[\'type\'] == \'net\':\n                node[\'name\'] = \'dk_Input\'\n                node[\'input\'] = [\'data\']\n                node[\'type\'] = \'DataInput\'\n                node[\'input_dim\'] = [\'-1\']\n                # NHWC\n                node[\'input_dim\'].append(block[\'height\'])\n                node[\'input_dim\'].append(block[\'width\'])\n                node[\'input_dim\'].append(block[\'channels\'])\n                input_param = OrderedDict()\n                input_param[\'shape\'] = self.dim_str_to_int(node[\'input_dim\'])\n                input_param[\'_output_shape\'] = self.dim_str_to_int(node[\'input_dim\'])\n                node[\'attr\'] = input_param\n                self.layer_map[node[\'name\']] = DarknetGraphNode(node)\n                self.original_list[node[\'name\']] = DarknetGraphNode(node)\n                self.layer_num_map[i] = node[\'name\']\n                pre_node_name = node[\'name\']\n\n            elif block[\'type\'] == \'convolutional\':\n                conv_layer = OrderedDict()\n                conv_layer[\'input\'] = [pre_node_name]\n\n                input_shape = self.layer_map[pre_node_name].get_attr(\'_output_shape\')\n                w = input_shape[1]\n                h = input_shape[2]\n                channels = input_shape[3]\n                # assert False\n\n                if \'name\' in block.keys():\n                    conv_layer[\'name\'] = block[\'name\']\n                else:\n                    conv_layer[\'name\'] = \'layer%d-conv\' % i\n                conv_layer[\'type\'] = \'Conv\'\n\n                convolution_param = OrderedDict()\n                convolution_param[\'num_output\'] = int(block[\'filters\'])\n                convolution_param[\'kernel_size\'] = int(block[\'size\'])\n                convolution_param[\'kernel\'] = [int(block[\'size\']), int(block[\'size\']), channels, int(block[\'filters\'])]\n                convolution_param[\'pad\'] = int(block[\'pad\'])\n\n                if block[\'pad\'] == \'1\':\n                    convolution_param[\'padding\'] = int(convolution_param[\'kernel_size\'])//2\n                convolution_param[\'stride\'] = int(block[\'stride\'])\n                if block[\'batch_normalize\'] == \'1\':\n                    convolution_param[\'bias_term\'] = \'false\'\n                else:\n                    convolution_param[\'bias_term\'] = \'true\'\n                output_w = self.conv_output_width(w ,convolution_param[\'padding\'], convolution_param[\'kernel_size\'], convolution_param[\'stride\'])\n                output_h = self.conv_output_height(h ,convolution_param[\'padding\'], convolution_param[\'kernel_size\'], convolution_param[\'stride\'])\n                convolution_param[\'_output_shape\'] = [-1, output_w, output_h, convolution_param[\'num_output\']]\n                conv_layer[\'attr\'] = convolution_param\n                self.layer_map[conv_layer[\'name\']] = DarknetGraphNode(conv_layer)\n                self.original_list[conv_layer[\'name\']] = DarknetGraphNode(conv_layer)\n                pre_node_name = conv_layer[\'name\']\n\n                if block[\'batch_normalize\'] == \'1\':\n                    bn_layer = OrderedDict()\n                    bn_layer[\'input\'] = [pre_node_name]\n\n\n                    input_shape = self.layer_map[pre_node_name].get_attr(\'_output_shape\')\n                    if \'name\' in block.keys():\n                        bn_layer[\'name\'] = \'%s-bn\' % block[\'name\']\n                    else:\n                        bn_layer[\'name\'] = \'layer%d-bn\' % i\n                    bn_layer[\'type\'] = \'BatchNorm\'\n                    batch_norm_param = OrderedDict()\n                    batch_norm_param[\'use_global_stats\'] = True\n                    batch_norm_param[\'_output_shape\'] = convolution_param[\'_output_shape\']\n                    batch_norm_param[\'bias_term\'] = True\n                    batch_norm_param[\'scale\'] = True\n                    bn_layer[\'attr\'] = batch_norm_param\n\n\n                    self.layer_map[bn_layer[\'name\']] = DarknetGraphNode(bn_layer)\n                    self.original_list[bn_layer[\'name\']] = DarknetGraphNode(bn_layer)\n\n                    pre_node_name = bn_layer[\'name\']\n\n\n                if block[\'activation\'] != \'linear\':\n                    relu_layer = OrderedDict()\n                    relu_layer[\'input\'] = [pre_node_name]\n                    if \'name\' in block.keys():\n                        relu_layer[\'name\'] = \'%s-act\' % block[\'name\']\n                    else:\n                        relu_layer[\'name\'] = \'layer%d-act\' % i\n                    relu_layer[\'type\'] = \'ReLU\'\n                    relu_param = OrderedDict()\n                    if block[\'activation\'] == \'leaky\':\n                        relu_layer[\'type\'] = \'leakyReLU\'\n                        relu_param[\'negative_slope\'] = \'0.1\'\n                    relu_param[\'_output_shape\'] = input_shape\n                    relu_layer[\'attr\'] = relu_param\n                    self.layer_map[relu_layer[\'name\']] = DarknetGraphNode(relu_layer)\n                    self.layer_num_map[i] = relu_layer[\'name\']\n                    self.original_list[relu_layer[\'name\']] = DarknetGraphNode(relu_layer)\n                    pre_node_name = relu_layer[\'name\']\n\n                else:\n                    self.layer_num_map[i] = bn_layer[\'name\']\n\n\n            elif block[\'type\'] == \'maxpool\':\n                max_layer = OrderedDict()\n                max_layer[\'input\'] = [pre_node_name]\n                if \'name\' in block.keys():\n                    max_layer[\'name\'] = block[\'name\']\n                else:\n                    max_layer[\'name\'] = \'layer%d-maxpool\' % i\n                max_layer[\'type\'] = \'Pooling\'\n                pooling_param = OrderedDict()\n                pooling_param[\'kernel_size\'] = int(block[\'size\'])\n                pooling_param[\'stride\'] = int(block[\'stride\'])\n                pooling_param[\'pool\'] = \'MAX\'\n                pooling_param[\'padding\'] = 0\n                if \'pad\' in block.keys() and int(block[\'pad\']) == 1:\n                    pooling_param[\'padding\'] = (int(block[\'size\'])-1)/2\n\n                input_shape = self.layer_map[pre_node_name].get_attr(\'_output_shape\')\n                w = input_shape[1]\n                h = input_shape[2]\n                output_w = (w + 2*pooling_param[\'padding\'])/pooling_param[\'stride\']\n                output_h = (h + 2*pooling_param[\'padding\'])/pooling_param[\'stride\']\n\n                pooling_param[\'_output_shape\'] = [-1, output_w, output_h, input_shape[-1]]\n                max_layer[\'attr\'] = pooling_param\n                self.layer_map[max_layer[\'name\']] = DarknetGraphNode(max_layer)\n                self.original_list[max_layer[\'name\']] = DarknetGraphNode(max_layer)\n                self.layer_num_map[i] = max_layer[\'name\']\n                pre_node_name = max_layer[\'name\']\n\n            elif block[\'type\'] == \'avgpool\':\n                avg_layer = OrderedDict()\n\n                avg_layer[\'input\'] = [pre_node_name]\n                if \'name\' in block.keys():\n                    avg_layer[\'name\'] = block[\'name\']\n                else:\n                    avg_layer[\'name\'] = \'layer%d-avgpool\' % i\n                avg_layer[\'type\'] = \'Pooling\'\n                pooling_param = OrderedDict()\n                input_shape = self.layer_map[pre_node_name].get_attr(\'_output_shape\')\n                pooling_param[\'_output_shape\'] = [-1, 1, 1, input_shape[-1]]\n                pooling_param[\'pool\'] = \'AVG\'\n                avg_layer[\'attr\'] = pooling_param\n                self.layer_map[avg_layer[\'name\']] = DarknetGraphNode(avg_layer)\n                self.original_list[avg_layer[\'name\']] = DarknetGraphNode(avg_layer)\n                self.layer_num_map[i] = avg_layer[\'name\']\n                pre_node_name = avg_layer[\'name\']\n\n            elif block[\'type\'] == \'route\':\n                prev = block[\'layers\'].split(\',\') #[-1,61]\n                if len(prev) == 1:\n                    prev_layer_id = i + int(prev[0])\n                    self.layer_num_map[i] = self.layer_num_map[prev_layer_id]\n                    pre_node_name = self.layer_num_map[i]\n                elif len(prev) == 2:\n                    input_list = []\n                    input_shape = []\n                    route_layer = OrderedDict()\n                    for p in prev:\n                        if int(p)>0:\n\n                            input_name = self.layer_num_map[int(p)+1]\n                            input_list.append(input_name)\n                            input_shape.append(self.layer_map[input_name].get_attr(\'_output_shape\'))\n\n                        else:\n                            prev_layer_id = i + int(p)\n                            input_name = self.layer_num_map[prev_layer_id]\n                            input_shape.append(self.layer_map[input_name].get_attr(\'_output_shape\'))\n                            input_list.append(input_name)\n                    route_param = OrderedDict()\n\n\n                    shape_ = 0\n                    for shape in input_shape:\n                        shape_ += shape[-1]\n                    route_param[\'axis\'] = 3\n                    route_param[\'_output_shape\'] = input_shape[0][:-1] + [shape_]\n                    route_layer[\'input\'] = input_list\n\n                    if \'name\' in block.keys():\n                        route_layer[\'name\'] = block[\'name\']\n                    else:\n                        route_layer[\'name\'] = \'layer%d-concat\' % i\n\n                    route_layer[\'type\'] = \'Concat\'\n                    route_layer[\'attr\'] = route_param\n\n                    self.layer_map[route_layer[\'name\']] = DarknetGraphNode(route_layer)\n                    self.original_list[route_layer[\'name\']] = DarknetGraphNode(route_layer)\n                    self.layer_num_map[i] = route_layer[\'name\']\n                    pre_node_name = route_layer[\'name\']\n\n            elif block[\'type\'] == \'shortcut\':\n                prev_layer_id1 = i + int(block[\'from\'])\n                prev_layer_id2 = i - 1\n                bottom1 = self.layer_num_map[prev_layer_id1]\n                bottom2 = self.layer_num_map[prev_layer_id2]\n                input_shape = self.layer_map[bottom2].get_attr(\'_output_shape\')\n                shortcut_layer = OrderedDict()\n                shortcut_layer[\'input\'] = [bottom1, bottom2]\n                # print(shortcut_layer[\'input\'] )\n                if \'name\' in block.keys():\n                    shortcut_layer[\'name\'] = block[\'name\']\n                else:\n                    shortcut_layer[\'name\'] = \'layer%d-shortcut\' % i\n                shortcut_layer[\'type\'] = \'Add\'\n                eltwise_param = OrderedDict()\n                eltwise_param[\'operation\'] = \'SUM\'\n                eltwise_param[\'_output_shape\'] = input_shape\n                shortcut_layer[\'attr\'] = eltwise_param\n\n\n                self.layer_map[shortcut_layer[\'name\']] = DarknetGraphNode(shortcut_layer)\n                self.original_list[shortcut_layer[\'name\']] = DarknetGraphNode(shortcut_layer)\n                self.layer_num_map[i] = shortcut_layer[\'name\']\n                pre_node_name = shortcut_layer[\'name\']\n\n                if block[\'activation\'] != \'linear\':\n                    relu_layer = OrderedDict()\n                    relu_layer[\'input\'] = [pre_node_name]\n                    if \'name\' in block.keys():\n                        relu_layer[\'name\'] = \'%s-act\' % block[\'name\']\n                    else:\n                        relu_layer[\'name\'] = \'layer%d-act\' % i\n                    relu_layer[\'type\'] = \'ReLU\'\n                    relu_param = OrderedDict()\n                    relu_param[\'_output_shape\'] = input_shape\n                    if block[\'activation\'] == \'leaky\':\n\n                        relu_param[\'negative_slope\'] = \'0.1\'\n\n                    relu_layer[\'attr\'] = relu_param\n                    self.layer_map[relu_layer[\'name\']] = DarknetGraphNode(relu_layer)\n                    self.original_list[relu_layer[\'name\']] = DarknetGraphNode(relu_layer)\n                    pre_node_name = relu_layer[\'name\']\n\n            elif block[\'type\'] == \'connected\':\n                fc_layer = OrderedDict()\n                fc_layer[\'input\'] = [pre_node_name]\n                if \'name\' in block.keys():\n                    fc_layer[\'name\'] = block[\'name\']\n                else:\n                    fc_layer[\'name\'] = \'layer%d-fc\' % i\n                fc_layer[\'type\'] = \'InnerProduct\'\n                fc_param = OrderedDict()\n                fc_param[\'num_output\'] = int(block[\'output\'])\n                input_shape = self.layer_map[pre_node_name].get_attr(\'_output_shape\')\n                fc_param[\'_output_shape\'] = input_shape[:-1] + [fc_param[\'num_output\']]\n                fc_layer[\'attr\'] = fc_param\n                self.layer_map[fc_layer[\'name\']] = DarknetGraphNode(fc_layer)\n                self.original_list[fc_layer[\'name\']] = DarknetGraphNode(fc_layer)\n                self.layer_num_map[i] = fc_layer[\'name\']\n                pre_node_name = fc_layer[\'name\']\n\n                if block[\'activation\'] != \'linear\':\n                    relu_layer = OrderedDict()\n                    relu_layer[\'input\'] = [pre_node_name]\n                    if \'name\' in block.keys():\n                        relu_layer[\'name\'] = \'%s-act\' % block[\'name\']\n                    else:\n                        relu_layer[\'name\'] = \'layer%d-act\' % i\n                    relu_layer[\'type\'] = \'ReLU\'\n                    relu_param = OrderedDict()\n                    if block[\'activation\'] == \'leaky\':\n\n                        relu_param[\'negative_slope\'] = \'0.1\'\n                    relu_param[\'_output_shape\'] = fc_param[\'_output_shape\']\n                    relu_layer[\'attr\'] = relu_param\n                    self.layer_map[relu_layer[\'name\']] = DarknetGraphNode(relu_layer)\n                    self.original_list[relu_layer[\'name\']] = DarknetGraphNode(relu_layer)\n                    pre_node_name = relu_layer[\'name\']\n\n            elif block[\'type\'] == \'softmax\':\n                sm_layer = OrderedDict()\n\n                sm_layer[\'input\'] = [pre_node_name]\n                if \'name\' in block.keys():\n                    sm_layer[\'name\'] = block[\'name\']\n                else:\n                    sm_layer[\'name\'] = \'layer%d-softmax\' % i\n                sm_layer[\'type\'] = \'Softmax\'\n                softmax_param = OrderedDict()\n                input_shape = self.layer_map[pre_node_name].get_attr(\'_output_shape\')\n                softmax_param[\'_output_shape\'] = input_shape\n                sm_layer[\'attr\'] = softmax_param\n                self.layer_map[sm_layer[\'name\']] = DarknetGraphNode(sm_layer)\n                self.original_list[sm_layer[\'name\']] = DarknetGraphNode(sm_layer)\n                self.layer_num_map[i] = sm_layer[\'name\']\n                pre_node_name = sm_layer[\'name\']\n\n            elif block[\'type\'] == \'yolo\':\n\n                yolo_layer = OrderedDict()\n                yolo_layer[\'input\'] = [pre_node_name]\n                if \'name\' in block.keys():\n                    yolo_layer[\'name\'] = block[\'name\']\n                else:\n                    yolo_layer[\'name\'] = \'layer%d-yolo\' % i\n                yolo_layer[\'type\'] = \'yolo\'\n                yolo_param = OrderedDict()\n                yolo_param[\'truth_thresh\'] = float(block[\'truth_thresh\'])\n                yolo_param[\'random\'] = float(block[\'random\'])\n                yolo_param[\'ignore_thresh\'] = float(block[\'ignore_thresh\'])\n                yolo_param[\'jitter\'] = float(block[\'jitter\'])\n                yolo_param[\'num\'] = int(block[\'num\'])\n                yolo_param[\'classes\'] = int(block[\'classes\'])\n                anchors = [int(t) for t in block[\'anchors\'].split(\',\')]\n                yolo_param[\'anchors\'] = anchors\n                mask = [int(t) for t in block[\'mask\'].split(\',\')]\n                yolo_param[\'mask\'] = mask\n\n                yolo_layer[\'attr\'] = yolo_param\n                self.layer_map[yolo_layer[\'name\']] = DarknetGraphNode(yolo_layer)\n                self.original_list[yolo_layer[\'name\']] = DarknetGraphNode(yolo_layer)\n                self.layer_num_map[i] = yolo_layer[\'name\']\n\n            elif block[\'type\'] == \'upsample\':\n\n                input_shape = self.layer_map[pre_node_name].get_attr(\'_output_shape\')\n                upsample_layer = OrderedDict()\n                upsample_layer[\'input\'] = [pre_node_name]\n                if \'name\' in block.keys():\n                    upsample_layer[\'name\'] = block[\'name\']\n                else:\n                    upsample_layer[\'name\'] = \'layer%d-upsample\' % i\n                upsample_layer[\'type\'] = \'upsample\'\n                upsample_param = OrderedDict()\n                stride = block[\'stride\']\n                upsample_param[\'scales\'] = [int(stride), int(stride)]\n                upsample_param[\'_output_shape\'] = [input_shape[0]] + [q*int(stride) for q in input_shape[1:3]] + [input_shape[-1]]\n                upsample_layer[\'attr\'] = upsample_param\n                self.layer_map[upsample_layer[\'name\']] = DarknetGraphNode(upsample_layer)\n                self.original_list[upsample_layer[\'name\']] = DarknetGraphNode(upsample_layer)\n                self.layer_num_map[i] = upsample_layer[\'name\']\n                pre_node_name = upsample_layer[\'name\']\n\n            elif block[\'type\'] == \'cost\':\n                continue\n\n            # spacetodepth\n            elif block[\'type\'] == \'reorg\':\n                input_shape = self.layer_map[pre_node_name].get_attr(\'_output_shape\')\n                reorg_layer = OrderedDict()\n                reorg_layer[\'input\'] = [pre_node_name]\n                if \'name\' in block.keys():\n                    reorg_layer[\'name\'] = block[\'name\']\n                else:\n                    reorg_layer[\'name\'] = \'layer%d-reorg\' % i\n\n                reorg_layer[\'type\'] = \'SpaceToDepth\'\n                reorg_param = OrderedDict()\n                stride = int(block[\'stride\'])\n                reorg_param[\'strides\'] = stride\n                reorg_param[\'_output_shape\'] = [-1, input_shape[1]/stride, input_shape[2]/stride, input_shape[3]*stride*stride]\n                reorg_layer[\'attr\'] = reorg_param\n\n                self.layer_map[reorg_layer[\'name\']] = DarknetGraphNode(reorg_layer)\n                self.original_list[reorg_layer[\'name\']] = DarknetGraphNode(reorg_layer)\n                self.layer_num_map[i] = reorg_layer[\'name\']\n                pre_node_name = reorg_layer[\'name\']\n\n\n            elif block[\'type\'] == \'region\':\n                # print(block)\n                region_layer = OrderedDict()\n                region_layer[\'input\'] = [pre_node_name]\n                if \'name\' in block.keys():\n                    region_layer[\'name\'] = block[\'name\']\n                else:\n                    region_layer[\'name\'] = \'layer%d-region\' % i\n                region_layer[\'type\'] = \'region\'\n                region_param = OrderedDict()\n                region_param[\'softmax\'] = int(block[\'softmax\'])\n                region_param[\'thresh\'] = float(block[\'thresh\'])\n                region_param[\'random\'] = float(block[\'random\'])\n                region_param[\'jitter\'] = float(block[\'jitter\'])\n                region_param[\'num\'] = int(block[\'num\'])\n                region_param[\'classes\'] = int(block[\'classes\'])\n                region_param[\'coords\'] = int(block[\'coords\'])\n                region_param[\'rescore\'] = int(block[\'rescore\'])\n                region_param[\'object_scale\'] = int(block[\'object_scale\'])\n\n                region_param[\'noobject_scale\'] = int(block[\'noobject_scale\'])\n                region_param[\'class_scale\'] = int(block[\'class_scale\'])\n                region_param[\'coord_scale\'] = int(block[\'coord_scale\'])\n\n                region_param[\'bias_match\'] = int(block[\'bias_match\'])\n                region_param[\'absolute\'] = int(block[\'absolute\'])\n\n                anchors = [float(t) for t in block[\'anchors\'].split(\',\')]\n                region_param[\'anchors\'] = anchors\n\n                region_layer[\'attr\'] = region_param\n                # print(region_layer)\n                self.layer_map[region_layer[\'name\']] = DarknetGraphNode(region_layer)\n                self.original_list[region_layer[\'name\']] = DarknetGraphNode(region_layer)\n                self.layer_num_map[i] = region_layer[\'name\']\n                # assert False\n\n\n            else:\n                print(\'unknown layer type %s \' % block[\'type\'])\n                print(block,""\\n"")\n                assert False\n\n\n\n        for layer in self.layer_map:\n            for pred in self.layer_map[layer].layer[\'input\']:\n                if pred not in self.layer_map.keys() and pred != \'data\':\n                    print(pred)\n                    print(""::::::::::::: unknown input :::::::::::::"")\n                    assert False\n\n                self._make_connection(pred, layer)\n\n        super(DarknetGraph, self).build()\n\n'"
mmdnn/conversion/darknet/darknet_parser.py,0,"b'\nimport os\nimport numpy as np\n\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.darknet.prototxt import *\nfrom mmdnn.conversion.darknet.darknet_utils import *\n\nfrom mmdnn.conversion.darknet.darknet_graph import DarknetGraph\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\n\nclass DarknetParser(Parser):\n\n    dtype_map = {\n        0 : graph_pb2.DT_UNDEFINED,\n        np.float32 : graph_pb2.DT_FLOAT32,\n        np.float64 : graph_pb2.DT_FLOAT64,\n        3 : graph_pb2.DT_INT32,\n        4 : graph_pb2.DT_UINT8,\n        5 : graph_pb2.DT_INT16,\n        6 : graph_pb2.DT_INT8,\n        7 : graph_pb2.DT_STRING,\n        9 : graph_pb2.DT_INT64\n    }\n\n    @property\n    def src_graph(self):\n        return self.dk_graph\n\n    def __init__(self, model_config, weightfile, yolo):\n        super(DarknetParser, self).__init__()\n\n        if not os.path.exists(model_config):\n            raise ValueError(\'Darknet model config [{}] can not be found!\'.format(model_config))\n\n        if weightfile:\n            self.weight_loaded = True\n\n        fp = open(weightfile, \'rb\')\n        header = np.fromfile(fp, count=4, dtype=np.int32)\n        self.buf = np.fromfile(fp, dtype = np.float32)\n        print(""weights buf size: {}"".format(self.buf.size))\n\n        fp.close()\n\n        # yolo3(608) start at 1, yolo2(608) start at 0. yolo2(416) start at 1, yolo3(416) start at 0\n        if yolo == ""1"":\n            self.start = 1  #yolov3\n        else:\n            self.start = 0   #yolov2\n\n        model = parse_cfg(model_config)\n        self.dk_graph = DarknetGraph(model)\n        self.dk_graph.build()\n\n    def gen_IR(self):\n\n        # load weight by original order\n        for layer in self.dk_graph.original_list:\n\n            current_node = self.dk_graph.get_node(layer)\n            node_type = current_node.type\n            # print(node_type)\n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n            else:\n                self.rename_UNKNOWN(current_node)\n\n        print(""loaded weights buf size: {}"".format(self.start))\n\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op = None):\n        if new_op == None: new_op = source_node.type\n        IR_node.name = source_node.name\n        IR_node.op = new_op\n\n        if \'_output_shape\' in source_node.layer[\'attr\'].keys():\n            output_list = source_node.layer[\'attr\'][\'_output_shape\']\n            shape = graph_pb2.TensorShape()\n            for dim in output_list:\n                new_dim = shape.dim.add()\n                if dim == None:\n                    new_dim.size = -1\n                else:\n                    new_dim.size = int(dim)\n\n            IR_node.attr[""_output_shape""].list.shape.extend([shape])\n\n        if \'shape\' in source_node.layer[\'attr\'].keys():\n            shape_list = source_node.layer[\'attr\'][\'shape\']\n            if not output_list == None:\n                for dim in shape_list:\n                    new_dim = IR_node.attr[""shape""].shape.dim.add()\n                    if dim == None:\n                        new_dim.size = -1\n                    else:\n                        new_dim.size = int(dim)\n            else:\n                IR_node.attr[""shape""].shape.unknown_rank = True\n\n\n    def _convert_inedge(self, source_node, IR_node, start_idx = 0, end_idx = None):\n        if end_idx == None: end_idx = len(source_node.in_edges)\n        for idx in range(start_idx, end_idx):\n            IR_node.input.append(self.src_graph.get_node(source_node.in_edges[idx]).real_name)\n\n    def _convert_identity_operation(self, source_node, start_idx = 0, end_idx = None, new_op = None):\n        IR_node = self.IR_graph.node.add()\n        DarknetParser._copy_and_reop(source_node, IR_node, new_op)\n        self._convert_inedge(source_node, IR_node, start_idx, end_idx)\n        return IR_node\n\n    def rename_UNKNOWN(self, source_node):\n        print(source_node.layer)\n        print(""Darknet has not supported operator [%s] with name [%s].""\n              % (source_node.type, source_node.name))\n        assert False\n\n    def rename_DataInput(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'DataInput\')\n        # print(IR_node)\n        # assert False\n\n    def rename_Conv(self, source_node):\n        """"""\n        weights: name_weights, name_bias\n        """"""\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Conv\')\n        kwargs = {}\n\n        # strides\n        stride = source_node.get_attr(\'stride\')\n        kwargs[\'strides\'] = [1, stride, stride, 1]\n\n        innode = self.dk_graph.get_node(source_node.in_edges[0])\n        input_shape = innode.get_attr(\'_output_shape\')\n\n        # assert False\n        kwargs[\'kernel_shape\'] = source_node.get_attr(\'kernel\')\n\n        # padding\n        if source_node.get_attr(\'pad\'):\n            kwargs[\'auto_pad\'] = ""SAME""\n            padding = source_node.get_attr(\'padding\')\n            kwargs[\'pads\'] = [0, padding, padding, 0, 0, padding, padding, 0]\n        else:\n            kwargs[\'auto_pad\'] = ""VALID""\n\n        # only load weight conv\n\n        if source_node.get_attr(\'bias_term\') == \'true\':\n            kwargs[\'use_bias\'] = True\n\n            kernel = kwargs[\'kernel_shape\']\n            kernel = np.zeros([kernel[-1], kernel[-2], kernel[0], kernel[1]])\n            k_bias = np.zeros(kwargs[\'kernel_shape\'][-1])\n\n            conv_name = source_node.name\n\n            # print(""----------------"",self.start)\n            # print(kernel.shape)\n            # print(k_bias.shape)\n\n            b = np.reshape(self.buf[self.start:self.start+k_bias.size], k_bias.shape)\n            self.start = self.start + k_bias.size\n            self.set_weight(conv_name, \'bias\', b)\n\n            W = np.reshape(self.buf[self.start:self.start+kernel.size], kernel.shape)\n            self.start = self.start + kernel.size\n            W = np.transpose(W, (2, 3, 1, 0))\n            self.set_weight(conv_name, \'weights\', W)\n        else:\n            kwargs[\'use_bias\'] = False\n\n\n        assign_IRnode_values(IR_node, kwargs)\n\n    def rename_BatchNorm(self, source_node):\n\n        IR_node = self._convert_identity_operation(source_node, new_op=\'BatchNorm\')\n        kwargs = {}\n        IR_node.attr[\'use_global_stats\'].b = source_node.get_attr(\'use_global_stats\')\n        IR_node.attr[\'bias\'].b = source_node.get_attr(\'use_global_stats\')\n        IR_node.attr[\'scale\'].b = source_node.get_attr(\'use_global_stats\')\n        IR_node.attr[\'epsilon\'].f = 1e-5\n\n        assign_IRnode_values(IR_node, kwargs)\n\n        innode = self.dk_graph.get_node(source_node.in_edges[0])\n        input_shape = innode.get_attr(\'_output_shape\')\n        kernel = innode.get_attr(\'kernel\')\n        kernel = np.zeros([kernel[-1], kernel[-2], kernel[0], kernel[1]])\n\n        # buf, start, scale_layer[\'name\'], bn_layer[\'name\'], conv_layer[\'name\']\n        # print(""=============="",self.start)\n        bias = np.zeros(input_shape[-1])\n        scale = np.zeros(input_shape[-1])\n        mean = np.zeros(input_shape[-1])\n        var = np.zeros(input_shape[-1])\n        # print(bias.shape)\n        # print(scale.shape)\n        # print(mean.shape)\n        # print(var.shape)\n        # print(kernel.shape)\n\n        bias_content = np.reshape(self.buf[self.start:self.start+bias.size], bias.shape)\n        self.start = self.start + bias.size\n        self.set_weight(source_node.name, \'bias\', bias_content)\n\n        scale_content = np.reshape(self.buf[self.start:self.start+scale.size], scale.shape)\n        self.start = self.start + scale.size\n        self.set_weight(source_node.name, \'scale\', scale_content)\n\n\n        mean_content = np.reshape(self.buf[self.start:self.start+mean.size], mean.shape)\n        self.start = self.start + mean.size\n        self.set_weight(source_node.name, \'mean\', mean_content)\n\n\n        var_content = np.reshape(self.buf[self.start:self.start+var.size], var.shape)\n        self.start = self.start + var.size\n        self.set_weight(source_node.name, \'var\', var_content)\n\n\n        W = np.reshape(self.buf[self.start:self.start+kernel.size], kernel.shape)\n        self.start = self.start + kernel.size\n        W = np.transpose(W, (2, 3, 1, 0))\n        # print(W)\n        # assert False\n        self.set_weight(innode.name, \'weights\', W)\n\n\n    # no use\n    def rename_ReLU(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Relu\')\n\n\n    def rename_leakyReLU(self, source_node):\n        # print(source_node.layer)\n        kwargs = {}\n        kwargs[\'alpha\'] = float(source_node.get_attr(\'negative_slope\'))\n        IR_node = self._convert_identity_operation(source_node, new_op=\'LeakyRelu\')\n        assign_IRnode_values(IR_node, kwargs)\n\n\n\n    def rename_Pooling(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Pool\')\n        kwargs = {}\n        if source_node.get_attr(\'pool\') == \'MAX\':\n            kernel = source_node.get_attr(\'kernel_size\')\n            kwargs[\'kernel_shape\'] = [1, kernel, kernel, 1]\n            stride = source_node.get_attr(\'stride\')\n            kwargs[\'strides\'] = [1, stride, stride, 1]\n            kwargs[\'pooling_type\'] = source_node.get_attr(\'pool\')\n            pad = source_node.get_attr(\'padding\')\n            IR_node.attr[""pads""].list.i.extend(([0]+[pad, pad]+[0])*2)\n\n        # for image classification(resnet) AVG pooling\n        else:\n            print(source_node.layer)\n            innode = self.dk_graph.get_node(source_node.in_edges[0])\n            input_shape = innode.get_attr(\'_output_shape\')\n            kwargs[\'kernel_shape\'] = [1] + input_shape[1:2] + [1]\n            kwargs[\'strides\'] = [1, 1, 1, 1]\n\n            kwargs[\'pooling_type\'] = source_node.get_attr(\'pool\')\n            IR_node.attr[""pads""].list.i.extend(([0, 0, 0, 0])*2)\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_yolo(self, source_node):\n        # print(source_node.layer)\n        IR_node = self._convert_identity_operation(source_node, new_op=\'yolo\')\n        kwargs = {}\n        kwargs[\'truth_thresh\'] = source_node.get_attr(\'truth_thresh\')\n        kwargs[\'random\'] = source_node.get_attr(\'random\')\n        kwargs[\'ignore_thresh\'] = source_node.get_attr(\'ignore_thresh\')\n        kwargs[\'jitter\'] = source_node.get_attr(\'jitter\')\n        kwargs[\'num\'] = source_node.get_attr(\'num\')\n        kwargs[\'classes\'] = source_node.get_attr(\'classes\')\n        kwargs[\'anchors\'] = source_node.get_attr(\'anchors\')\n        kwargs[\'mask\'] = source_node.get_attr(\'mask\')\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Concat(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Concat\')\n        IR_node.attr[""axis""].i = int(source_node.get_attr(""axis"", ""1""))\n\n\n    def rename_upsample(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'UpSampling2D\')\n        scales = source_node.get_attr(\'scales\')\n        kwargs = {}\n        kwargs[\'scales\'] = scales\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Add(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Add\')\n\n\n    def rename_SpaceToDepth(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'SpaceToDepth\')\n        stride = source_node.get_attr(\'strides\')\n        kwargs = {}\n        kwargs[\'blocksize\'] = stride\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_InnerProduct(self, source_node):\n        print(source_node.layer)\n        assert False\n\n\n    def rename_region(self, source_node):\n        # print(source_node.layer)\n        IR_node = self._convert_identity_operation(source_node, new_op=\'region\')\n        kwargs = {}\n        kwargs[\'thresh\'] = source_node.get_attr(\'thresh\')\n        kwargs[\'random\'] = source_node.get_attr(\'random\')\n        # kwargs[\'ignore_thresh\'] = source_node.get_attr(\'ignore_thresh\')\n        kwargs[\'jitter\'] = source_node.get_attr(\'jitter\')\n        kwargs[\'num\'] = source_node.get_attr(\'num\')\n        kwargs[\'classes\'] = source_node.get_attr(\'classes\')\n\n        kwargs[\'softmax\'] = source_node.get_attr(\'softmax\')\n        kwargs[\'coords\'] = source_node.get_attr(\'coords\')\n        kwargs[\'rescore\'] = source_node.get_attr(\'rescore\')\n        # print(source_node.get_attr(\'anchors\'))\n        kwargs[\'anchors\'] = source_node.get_attr(\'anchors\')\n        # kwargs[\'anchors\'] = [\'0.52\',\'0.22\']\n        # kwargs[\'mask\'] = source_node.get_attr(\'mask\')\n        kwargs[\'object_scale\'] = source_node.get_attr(\'object_scale\')\n        kwargs[\'noobject_scale\'] = source_node.get_attr(\'noobject_scale\')\n        kwargs[\'class_scale\'] = source_node.get_attr(\'class_scale\')\n        kwargs[\'coord_scale\'] = source_node.get_attr(\'coord_scale\')\n\n        kwargs[\'bias_match\'] = source_node.get_attr(\'bias_match\')\n        kwargs[\'absolute\'] = source_node.get_attr(\'absolute\')\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Softmax(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n\n'"
mmdnn/conversion/darknet/darknet_utils.py,0,b'\nimport numpy as np\nfrom collections import OrderedDict\nfrom mmdnn.conversion.darknet.cfg import *\n'
mmdnn/conversion/darknet/prototxt.py,0,"b'from collections import OrderedDict\n\ndef parse_prototxt(protofile):\n    def line_type(line):\n        if line.find(\':\') >= 0:\n            return 0\n        elif line.find(\'{\') >= 0:\n            return 1\n        return -1\n\n    def parse_block(fp):\n        block = OrderedDict()\n        line = fp.readline().strip()\n        while line != \'}\':\n            ltype = line_type(line)\n            if ltype == 0: # key: value\n                #print line\n                line = line.split(\'#\')[0]\n                key, value = line.split(\':\')\n                key = key.strip()\n                value = value.strip().strip(\'""\')\n                if key in block.keys():\n                    if type(block[key]) == list:\n                        block[key].append(value)\n                    else:\n                        block[key] = [block[key], value]\n                else:\n                    block[key] = value\n            elif ltype == 1: # blockname {\n                key = line.split(\'{\')[0].strip()\n                sub_block = parse_block(fp)\n                block[key] = sub_block\n            line = fp.readline().strip()\n            line = line.split(\'#\')[0]\n        return block\n\n    fp = open(protofile, \'r\')\n    props = OrderedDict()\n    layers = []\n    line = fp.readline()\n    while line != \'\':\n        line = line.strip().split(\'#\')[0]\n        if line == \'\':\n            line = fp.readline()\n            continue\n        ltype = line_type(line)\n        if ltype == 0: # key: value\n            key, value = line.split(\':\')\n            key = key.strip()\n            value = value.strip().strip(\'""\')\n            if key in props.keys():\n               if type(props[key]) == list:\n                   props[key].append(value)\n               else:\n                   props[key] = [props[key], value]\n            else:\n                props[key] = value\n        elif ltype == 1: # blockname {\n            key = line.split(\'{\')[0].strip()\n            if key == \'layer\':\n                layer = parse_block(fp)\n                layers.append(layer)\n            else:\n                props[key] = parse_block(fp)\n        line = fp.readline()\n\n    if len(layers) > 0:\n        net_info = OrderedDict()\n        net_info[\'props\'] = props\n        net_info[\'layers\'] = layers\n        return net_info\n    else:\n        return props\n\ndef is_number(s):\n    try:\n        float(s)\n        return True\n    except ValueError:\n        return False\n'"
mmdnn/conversion/examples/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\n\nclass base_extractor(object):\n\n    def __init__(self):\n        pass\n\n\n    @classmethod\n    def help(cls):\n        print (\'Support frameworks: {}\'.format(list(cls.architecture_map.keys())))\n\n\n    @classmethod\n    def sanity_check(cls, architecture):\n        if architecture is None:\n            cls.help()\n            return False\n\n        elif not architecture in cls.architecture_map:\n            cls.help()\n            raise ValueError(""Unknown pretrained model name [{}]."".format(architecture))\n\n        else:\n            return True\n\n    @classmethod\n    def download(cls, architecture):\n        raise NotImplementedError()\n\n\n    @classmethod\n    def inference(cls, image_path):\n        raise NotImplementedError()\n'"
mmdnn/conversion/examples/imagenet_test.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nimport argparse\nimport numpy as np\nfrom six import text_type as _text_type\nfrom PIL import Image\n\n\n\nclass TestKit(object):\n\n    truth = {\n        \'caffe\' : {\n            \'alexnet\'        : [(821, 0.25088307), (657, 0.20857951), (744, 0.096812263), (595, 0.066312768), (847, 0.053720973)],\n            \'vgg19\'          : [(21, 0.37522122), (144, 0.28500062), (23, 0.099720284), (134, 0.036305398), (22, 0.033559237)],\n            \'inception_v1\'   : [(21, 0.93591732), (23, 0.037170019), (22, 0.014315935), (128, 0.005050648), (749, 0.001965977)],\n            \'resnet152\'      : [(144, 0.93159181), (23, 0.033074539), (21, 0.028599562), (99, 0.001878676), (146, 0.001557963)],\n            \'squeezenet\'     : [(21, 0.5285601), (128, 0.071685813), (144, 0.064104252), (416, 0.050044473), (22, 0.049522042)]\n        },\n        \'tensorflow\' : {\n            \'vgg19\'             : [(21, 11.285443), (144, 10.240093), (23, 9.1792336), (22, 8.1113129), (128, 8.1065922)],\n            \'resnet\'            : [(22, 11.756789), (147, 8.5718527), (24, 6.1751032), (88, 4.3121386), (141, 4.1778097)],\n            \'resnet_v1_101\'     : [(21, 14.384739), (23, 14.262486), (144, 14.068737), (94, 12.17205), (134, 12.064575)],\n            \'resnet_v2_50\'      : [(22, 12.202208), (145, 7.9816318), (24, 7.6646066), (147, 7.008089), (88, 5.180175)],\n            \'resnet_v2_152\'     : [(22, 13.370557), (147, 8.807369), (24, 5.702235), (90, 5.6126657), (95, 4.8026266)],\n            \'inception_v1\'      : [(22, 9.2353525), (95, 6.9062357), (24, 6.693231), (750, 6.494348), (145, 6.054538)],\n            \'inception_v3\'      : [(22, 9.4921198), (24, 4.0932288), (25, 3.700398), (23, 3.3715961), (147, 3.3620636)],\n            \'mobilenet_v1_1.0\'         : [(22, 16.223597), (24, 14.54775), (147, 13.173758), (145, 11.36431), (728, 11.083847)],\n            \'mobilenet_v2_1.0_224\' : [(22, 9.384777), (147, 5.865254), (23, 5.5761757), (750, 5.0572333), (132, 4.865659)]\n\n        },\n        \'keras\' : {\n            \'vgg16\'             : [(21, 0.81199354), (562, 0.019326132), (23, 0.018279659), (144, 0.012460723), (22, 0.012429929)],\n            \'vgg19\'             : [(21, 0.37522098), (144, 0.28500044), (23, 0.099720411), (134, 0.036305476), (22, 0.033559218)],\n            \'inception_v3\'      : [(21, 0.91967654), (23, 0.0029040477), (24, 0.0020232804), (146, 0.0019062747), (22, 0.0017500133)],\n            \'xception\'          : [(21, 0.67462814), (23, 0.063138723), (87, 0.028424012), (89, 0.02484037), (88, 0.0062591862)],\n            \'mobilenet\'         : [(21, 0.7869994), (23, 0.14728773), (146, 0.037277445), (144, 0.0061039869), (727, 0.0046111974)],\n            \'resnet\'            : [(144, 0.80301273), (23, 0.067478567), (21, 0.046560187), (562, 0.037413299), (146, 0.015967956)],\n            \'inception_resnet_v2\'  : [(21, 0.93837249), (87, 0.0021177295), (146, 0.0019775454), (23, 0.00072135136), (24, 0.00056668324)],\n            \'densenet\'          : [(21, 0.86279225), (146, 0.051543437), (23, 0.030489875), (144, 0.028583106), (141, 0.003564599)],\n            \'nasnet\'            : [(21, 0.8541155), (22, 0.0030572189), (146, 0.0026522065), (23, 0.0020259875), (88, 0.0020091296)]\n        },\n        \'mxnet\' : {\n            \'vgg19\'                         : [(21, 0.54552644), (144, 0.19179004), (23, 0.066389613), (22, 0.022819581), (128, 0.02271222)],\n            \'resnet\'                        : [(21, 0.84012794), (144, 0.097428247), (23, 0.039757393), (146, 0.010432643), (99, 0.0023797606)],\n            \'squeezenet\'                    : [(21, 0.36026478), (128, 0.084114805), (835, 0.07940048), (144, 0.057378717), (749, 0.053491514)],\n            \'inception_bn\'                  : [(21, 0.84332663), (144, 0.041747514), (677, 0.021810319), (973, 0.02054958), (115, 0.008529461)],\n            \'resnet152-11k\'                 : [(1278, 0.49073416), (1277, 0.21393695), (282, 0.12980066), (1282, 0.0663582), (1224, 0.022041745)],\n            \'imagenet1k-resnext-101-64x4d\'  : [(21, 0.587986), (23, 0.29983738), (862, 0.044453762), (596, 0.00983246), (80, 0.00465048)],\n            \'imagenet1k-resnext-50\'         : [(396, 0.7104751), (398, 0.122665755), (438, 0.06391319), (440, 0.029796895), (417, 0.019492012)],\n            \'resnext\'                       : [(21, 0.58798772), (23, 0.29983655), (862, 0.044453178), (596, 0.0098323636), (80, 0.0046504852)]\n        },\n        \'pytorch\' : {\n            \'resnet18\'  : [(394, 10.310125), (395, 9.2285385), (21, 8.9611788), (144, 8.3729601), (749, 7.9692998)],\n            \'resnet152\' : [(21, 13.080057), (141, 12.32998), (94, 9.8761454), (146, 9.3761511), (143, 8.9194641)],\n            \'vgg19\'     : [(821, 8.4734678), (562, 8.3472366), (835, 8.2712851), (749, 7.792901), (807, 6.6604013)],\n        },\n\n        \'cntk\' : {\n            \'alexnet\'       : [(836, 7.5413785), (837, 7.076382), (84, 6.9632936), (148, 6.90293), (416, 6.571906)],\n            \'resnet18\'      : [(21, 8.2490816), (22, 7.7600741), (23, 7.4341722), (148, 7.1398726), (144, 6.9187264)],\n            \'resnet152\'     : [(21, 12.461424), (99, 12.38283), (144, 11.1572275), (94, 10.569823), (146, 10.096423)],\n            \'inception_v3\'  : [(21, 15.558625), (22, 9.7712708), (23, 9.6847782), (146, 9.188818), (144, 8.0436306)]\n        },\n        \'coreml\' : {\n            \'mobilenet\' : [],\n        },\n\n        \'darknet\' : {\n            \'yolov3\'        :[],\n        },\n\n    }\n\n    preprocess_func = {\n        \'caffe\' : {\n            \'alexnet\'       : lambda path : TestKit.ZeroCenter(path, 227, True),\n            \'vgg19\'         : lambda path : TestKit.ZeroCenter(path, 224, True),\n            \'inception_v1\'  : lambda path : TestKit.ZeroCenter(path, 224, True),\n            \'resnet152\'     : lambda path : TestKit.ZeroCenter(path, 224, True),\n            \'squeezenet\'    : lambda path : TestKit.ZeroCenter(path, 227),\n            \'inception_v4\'  : lambda path : TestKit.Standard(path, 299, True),\n            \'xception\'      : lambda path : TestKit.Standard(path, 299, True),\n            \'voc-fcn8s\'     : lambda path : TestKit.ZeroCenter(path, 500, True),\n            \'voc-fcn16s\'    : lambda path : TestKit.ZeroCenter(path, 500, True),\n            \'voc-fcn32s\'    : lambda path : TestKit.ZeroCenter(path, 500, True),\n            \'trailnet_sresnet\': lambda path: TestKit.ZeroCenter(path, (320, 180), True)\n        },\n\n        \'tensorflow\' : {\n            \'vgg16\'         : lambda path : TestKit.ZeroCenter(path, 224),\n            \'vgg19\'         : lambda path : TestKit.ZeroCenter(path, 224),\n            \'inception_v1\'  : lambda path : TestKit.Standard(path, 224),\n            \'inception_v3\'  : lambda path : TestKit.Standard(path, 299),\n            \'resnet\'        : lambda path : TestKit.Standard(path, 299),\n            \'resnet_v1_50\'  : lambda path : TestKit.ZeroCenter(path, 224),\n            \'resnet_v1_101\' : lambda path : TestKit.ZeroCenter(path, 224),\n            \'resnet_v1_152\' : lambda path : TestKit.ZeroCenter(path, 224),\n            \'resnet_v2_50\'  : lambda path : TestKit.Standard(path, 299),\n            \'resnet_v2_101\' : lambda path : TestKit.Standard(path, 299),\n            \'resnet_v2_152\' : lambda path : TestKit.Standard(path, 299),\n            \'resnet_v2_200\' : lambda path : TestKit.Standard(path, 299),\n            \'resnet152\'     : lambda path : TestKit.Standard(path, 299),\n            \'mobilenet_v1_1.0\'  : lambda path : TestKit.Standard(path, 224),\n            \'mobilenet_v1_0.50\' : lambda path : TestKit.Standard(path, 224),\n            \'mobilenet_v1_0.25\' : lambda path : TestKit.Standard(path, 224),\n            \'mobilenet\'     : lambda path : TestKit.Standard(path, 224),\n            \'mobilenet_v2_1.0_224\'  : lambda path : TestKit.Standard(path, 224),\n            \'nasnet-a_large\'     : lambda path : TestKit.Standard(path, 331),\n            \'inception_resnet_v2\' : lambda path : TestKit.Standard(path, 299),\n            \'facenet\'           : lambda path: TestKit.Standard(path, 160),\n            \'rnn\'               : lambda path : TestKit.RNN(path),\n        },\n\n        \'keras\' : {\n            \'vgg16\'                : lambda path : TestKit.ZeroCenter(path, 224, True),\n            \'vgg19\'                : lambda path : TestKit.ZeroCenter(path, 224, True),\n            \'inception_v3\'         : lambda path : TestKit.Standard(path, 299),\n            \'resnet50\'             : lambda path : TestKit.ZeroCenter(path, 224, True),\n            \'xception\'             : lambda path : TestKit.Standard(path, 299),\n            \'mobilenet\'            : lambda path : TestKit.Standard(path, 224),\n            \'inception_resnet_v2\'  : lambda path : TestKit.Standard(path, 299),\n            \'densenet\'             : lambda path : TestKit.Standard(path, 224),\n            \'nasnet\'               : lambda path : TestKit.Standard(path, 331),\n            \'yolo2-tiny\'           : lambda path : TestKit.Identity(path, 416),\n            \'yolo2\'                : lambda path : TestKit.Identity(path, 416),\n        },\n\n        \'mxnet\' : {\n            \'vgg16\'                         : lambda path : TestKit.ZeroCenter(path, 224, False),\n            \'vgg19\'                         : lambda path : TestKit.ZeroCenter(path, 224, False),\n            \'resnet\'                        : lambda path : TestKit.Identity(path, 224, True),\n            \'squeezenet_v1.0\'               : lambda path : TestKit.ZeroCenter(path, 224, False),\n            \'squeezenet_v1.1\'               : lambda path : TestKit.ZeroCenter(path, 224, False),\n            \'imagenet1k-inception-bn\'       : lambda path : TestKit.Identity(path, 224, False),\n            \'imagenet1k-resnet-18\'          : lambda path : TestKit.Identity(path, 224, True),\n            \'imagenet1k-resnet-152\'         : lambda path : TestKit.Identity(path, 224, True),\n            \'resnext\'                       : lambda path : TestKit.Identity(path, 224, False),\n            \'imagenet1k-resnext-50\'         : lambda path : TestKit.Identity(path, 224, False),\n            \'imagenet1k-resnext-101-64x4d\'  : lambda path : TestKit.Identity(path, 224, False),\n        },\n\n        \'pytorch\' : {\n            \'alexnet\'       : lambda path : TestKit.Standard(path, 227),\n            \'densenet121\'   : lambda path : TestKit.Standard(path, 224),\n            \'densenet169\'   : lambda path : TestKit.Standard(path, 224),\n            \'densenet161\'   : lambda path : TestKit.Standard(path, 224),\n            \'densenet201\'   : lambda path : TestKit.Standard(path, 224),\n            \'vgg11\'         : lambda path : TestKit.Standard(path, 224),\n            \'vgg13\'         : lambda path : TestKit.Standard(path, 224),\n            \'vgg16\'         : lambda path : TestKit.Standard(path, 224),\n            \'vgg19\'         : lambda path : TestKit.Standard(path, 224),\n            \'vgg11_bn\'         : lambda path : TestKit.Standard(path, 224),\n            \'vgg13_bn\'         : lambda path : TestKit.Standard(path, 224),\n            \'vgg16_bn\'         : lambda path : TestKit.Standard(path, 224),\n            \'vgg19_bn\'         : lambda path : TestKit.Standard(path, 224),\n            \'resnet18\'      : lambda path : TestKit.Standard(path, 224),\n            \'resnet34\'      : lambda path : TestKit.Standard(path, 224),\n            \'resnet50\'      : lambda path : TestKit.Standard(path, 224),\n            \'resnet101\'      : lambda path : TestKit.Standard(path, 224),\n            \'resnet152\'     : lambda path : TestKit.Standard(path, 224),\n            \'squeezenet1_0\' : lambda path : TestKit.Standard(path, 224),\n            \'inception_v3\'  : lambda path : TestKit.Standard(path, 299),\n        },\n\n        \'cntk\' : {\n            \'alexnet\'       : lambda path : TestKit.Identity(path, 227),\n            \'resnet18\'      : lambda path : TestKit.Identity(path, 224),\n            \'resnet152\'     : lambda path : TestKit.Identity(path, 224),\n            \'inception_v3\'  : lambda path : TestKit.Identity(path, 299),\n        },\n\n\n        \'darknet\' : {\n            \'yolov3\'        : lambda path : TestKit.Identity(path, 608),\n            \'yolov2\'        : lambda path : TestKit.Identity(path, 608),\n        },\n\n\n        \'coreml\' : {\n            \'mobilenet\'         : lambda path :  TestKit.Normalize(path, 224, 0.0170000009239, [-2.10256004333, -1.98526000977, -1.76698005199], [1.0, 1.0, 1.0], True),\n            \'inception_v3\'      : lambda path : TestKit.Standard(path, 299),\n            \'vgg16\'             : lambda path : TestKit.ZeroCenter(path, 224, True),\n            \'resnet50\'          : lambda path : TestKit.ZeroCenter(path, 224, True),\n            \'tinyyolo\'          : lambda path : TestKit.Normalize(path, 416, 0.00392156863, [0, 0, 0], [1.0, 1.0, 1.0], False),\n        },\n\n        \'paddle\' : {\n            \'resnet50\'       : lambda path : TestKit.Standard(path, 224),\n            \'resnet101\'      : lambda path : TestKit.Standard(path, 224),\n            \'vgg16\'          : lambda path : TestKit.Standard(path, 224),\n        }\n\n    }\n\n    def __init__(self):\n        parser = argparse.ArgumentParser()\n\n        parser.add_argument(\'-p\', \'--preprocess\', type=_text_type, help=\'Model Preprocess Type\')\n\n        parser.add_argument(\'-n\', type=_text_type, default=\'kit_imagenet\',\n                            help=\'Network structure file name.\')\n\n        parser.add_argument(\'-s\', type=_text_type, help=\'Source Framework Type\',\n                            choices=self.truth.keys())\n\n        parser.add_argument(\'-w\', type=_text_type, required=True,\n                            help=\'Network weights file name\')\n\n        parser.add_argument(\'--image\', \'-i\',\n                            type=_text_type, help=\'Test image path.\',\n                            default=""mmdnn/conversion/examples/data/seagull.jpg""\n        )\n\n        parser.add_argument(\'-l\', \'--label\',\n                            type=_text_type,\n                            default=\'mmdnn/conversion/examples/data/imagenet_1000.txt\',\n                            help=\'Path of label.\')\n\n        parser.add_argument(\'--dump\',\n            type=_text_type,\n            default=None,\n            help=\'Target model path.\')\n\n        parser.add_argument(\'--detect\',\n            type=_text_type,\n            default=None,\n            help=\'Model detection result path.\')\n\n        # tensorflow dump tag\n        parser.add_argument(\'--dump_tag\',\n            type=_text_type,\n            default=None,\n            help=\'Tensorflow model dump type\',\n            choices=[\'SERVING\', \'TRAINING\'])\n\n\n        self.args = parser.parse_args()\n        import imp\n        self.MainModel = imp.load_source(\'MainModel\', self.args.n)\n\n\n    @staticmethod\n    def ZeroCenter(path, size, BGRTranspose=False):\n        img = Image.open(path)\n        if isinstance(size, tuple):\n            h, w = size[0], size[1]\n        else:\n            h, w = size, size\n        img = img.resize((h, w))\n        x = np.array(img, dtype=np.float32)\n\n        # Reference: 1) Keras image preprocess: https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py\n        #            2) tensorflow github issue: https://github.com/tensorflow/models/issues/517\n        # R-G-B for Imagenet === [123.68, 116.78, 103.94]\n\n\n        x[..., 0] -= 123.68\n        x[..., 1] -= 116.779\n        x[..., 2] -= 103.939\n\n        if BGRTranspose == True:\n            x = x[..., ::-1]\n\n        return x\n\n\n    @staticmethod\n    def Normalize(path, size=224, scale=0.0392156863 ,mean=[-0.485, -0.456, -0.406], std=[0.229, 0.224, 0.225], BGRTranspose = False):\n        img = Image.open(path)\n        img = img.resize((size, size))\n        x = np.array(img, dtype=np.float32)\n        x *= scale\n        for i in range(0, 3):\n            x[..., i] += mean[i]\n            x[..., i] /= std[i]\n        if BGRTranspose == True:\n            x = x[..., ::-1]\n        return x\n\n\n    @staticmethod\n    def Standard(path, size, BGRTranspose=False):\n        img = Image.open(path)\n        img = img.resize((size, size))\n        x = np.array(img, dtype=np.float32)\n        x /= 255.0\n        x -= 0.5\n        x *= 2.0\n        if BGRTranspose == True:\n            x = x[..., ::-1]\n        return x\n\n\n    @staticmethod\n    def Identity(path, size, BGRTranspose=False):\n        img = Image.open(path)\n        img = img.resize((size, size))\n        x = np.array(img, dtype=np.float32)\n        if BGRTranspose == True:\n            x = x[..., ::-1]\n        return x\n\n\n    @staticmethod\n    def RNN(path):\n        x = np.load(path)\n        return x\n\n    def preprocess(self, image_path):\n        func = self.preprocess_func[self.args.s][self.args.preprocess]\n        return func(image_path)\n\n\n    def print_result(self, predict):\n        predict = np.squeeze(predict)\n        if predict.ndim == 1:\n            top_indices = predict.argsort()[-5:][::-1]\n            if predict.shape[0] == 1001 or predict.shape[0] == 1000:\n                if predict.shape[0] == 1000:\n                    offset = 0\n                else:\n                    offset = 1\n\n                import os\n                if os.path.exists(self.args.label):\n                    with open(self.args.label, \'r\') as f:\n                        labels = [l.rstrip() for l in f]\n\n                    for i in top_indices:\n                        print (labels[i - offset], i, predict[i])\n\n                else:\n                    for i in top_indices:\n                        print (i, predict[i])\n\n            self.result = [(i, predict[i]) for i in top_indices]\n\n        else:\n            self.result = predict\n            print (self.result)\n\n    @staticmethod\n    def print_intermediate_result(intermediate_output, if_transpose=False):\n        intermediate_output = np.squeeze(intermediate_output)\n\n        if if_transpose == True:\n            intermediate_output = np.transpose(intermediate_output, [2, 0, 1])\n\n        print (intermediate_output)\n        print (intermediate_output.shape)\n        print (""Sum = %.30f"" % np.sum(intermediate_output))\n        print (""Std = %.30f"" % np.std(intermediate_output))\n\n\n    def test_truth(self):\n        this_truth = self.truth[self.args.s][self.args.preprocess]\n        for index, i in enumerate(self.result):\n            assert this_truth[index][0] == i[0]\n            assert np.isclose(this_truth[index][1], i[1], atol = 1e-6)\n\n        print (""Test model [{}] from [{}] passed."".format(\n            self.args.preprocess,\n            self.args.s\n        ))\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n        self.print_result()\n\n\n    def dump(self, path = None):\n        raise NotImplementedError()\n\n\n\'\'\'\nif __name__==\'__main__\':\n    tester = TestKit()\n    tester.inference(\'examples/data/seagull.jpg\')\n\'\'\'\n'"
mmdnn/conversion/keras/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/keras/extra_layers.py,0,"b'# -*- coding: utf-8 -*-\n""""""Normalization layers.\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom keras.engine import Layer, InputSpec\nfrom keras import initializers\n# from keras.layers.core import Layer\nfrom keras  import backend as K\n\n\nclass Scale(Layer):\n    """"""Scale layer (2018).\n\n    Scale the activations of the previous layer at each batch.\n\n    # Arguments\n        axis: Integer, the axis that should be normalized\n            (typically the features axis).\n            For instance, after a `Conv2D` layer with\n            `data_format=""channels_first""`,\n            set `axis=1` in `BatchNormalization`.\n        center: If True, add offset of `beta` to normalized tensor.\n            If False, `beta` is ignored.\n        scale: If True, multiply by `gamma`.\n            If False, `gamma` is not used.\n            When the next layer is linear (also e.g. `nn.relu`),\n            this can be disabled since the scaling\n            will be done by the next layer.\n        beta_initializer: Initializer for the beta weight.\n        gamma_initializer: Initializer for the gamma weight.\n\n    # Input shape\n        Arbitrary. Use the keyword argument `input_shape`\n        (tuple of integers, does not include the samples axis)\n        when using this layer as the first layer in a model.\n\n    # Output shape\n        Same shape as input.\n\n    """"""\n\n    def __init__(self,\n                 axis=-1,\n                 center=True,\n                 scale=True,\n                 beta_initializer=\'zeros\',\n                 gamma_initializer=\'ones\',\n                 **kwargs):\n        super(Scale, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.axis = axis\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n\n\n    def build(self, input_shape):\n        dim = input_shape[self.axis]\n        if dim is None:\n            raise ValueError(\'Axis \' + str(self.axis) + \' of \'\n                             \'input tensor should have a defined dimension \'\n                             \'but the layer received an input with shape \' +\n                             str(input_shape) + \'.\')\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(shape=shape,\n                                         name=\'gamma\',\n                                         initializer=self.gamma_initializer)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(shape=shape,\n                                        name=\'beta\',\n                                        initializer=self.beta_initializer)\n        else:\n            self.beta = None\n\n\n        self.built = True\n\n    def call(self, inputs, training=None):\n        input_shape = K.int_shape(inputs)\n        # Prepare broadcasting shape.\n        ndim = len(input_shape)\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis]\n        return K.reshape(self.gamma, broadcast_shape) * inputs + K.reshape(self.beta, broadcast_shape)\n\n    def get_config(self):\n        config = {\n            \'axis\': self.axis,\n            \'center\': self.center,\n            \'scale\': self.scale,\n        }\n        base_config = super(Scale, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n'"
mmdnn/conversion/keras/keras2_emitter.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\nfrom six.moves import xrange\n\nfrom mmdnn.conversion.common.IR.IR_graph import IRGraph, IRGraphNode\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.emitter import Emitter\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.keras.extra_layers import Scale\nfrom mmdnn.conversion.rewriter.folder import Folder\n\n\nclass Keras2Emitter(Emitter):\n\n    dtype_map = {\n        graph_pb2.DT_FLOAT16 : ""float16"",\n        graph_pb2.DT_FLOAT32 : ""float32"",\n        graph_pb2.DT_FLOAT64 : ""float64"",\n        graph_pb2.DT_INT16 : ""int16"",\n        graph_pb2.DT_INT32 : ""int32"",\n        graph_pb2.DT_INT64 : ""int64"",\n        graph_pb2.DT_UINT8 : ""uint8"",\n        graph_pb2.DT_UINT16 : ""uint16""\n    }\n\n\n    def __init__(self, model):\n        super(Keras2Emitter, self).__init__()\n        from six import string_types as _string_types\n        if isinstance(model, _string_types):\n            network_path = model\n        else:\n            network_path = model[0]\n            weight_path = model[1]\n            self._load_weights(weight_path)\n\n        self.IR_graph = IRGraph(network_path)\n        self.IR_graph.build()\n        self.yolo_parameter = []\n        self.region_parameter = []\n        self.layers_codes_count = dict()\n\n        folder = Folder(self.IR_graph, self.weights_dict)\n        folder.fold()\n\n\n    @property\n    def header_code(self):\n        return """"""import keras\nfrom keras.models import Model\nfrom keras import layers\nimport keras.backend as K\nimport numpy as np\nfrom keras.layers.core import Lambda\nimport tensorflow as tf\n\n\nweights_dict = dict()\ndef load_weights_from_file(weight_file):\n    try:\n        weights_dict = np.load(weight_file, allow_pickle=True).item()\n    except:\n        weights_dict = np.load(weight_file, allow_pickle=True, encoding=\'bytes\').item()\n\n    return weights_dict\n\n\ndef set_layer_weights(model, weights_dict):\n    for layer in model.layers:\n        if layer.name in weights_dict:\n            cur_dict = weights_dict[layer.name]\n            current_layer_parameters = list()\n            if layer.__class__.__name__ == ""BatchNormalization"":\n                if \'scale\' in cur_dict:\n                    current_layer_parameters.append(cur_dict[\'scale\'])\n                if \'bias\' in cur_dict:\n                    current_layer_parameters.append(cur_dict[\'bias\'])\n                current_layer_parameters.extend([cur_dict[\'mean\'], cur_dict[\'var\']])\n            elif layer.__class__.__name__ == ""Scale"":\n                if \'scale\' in cur_dict:\n                    current_layer_parameters.append(cur_dict[\'scale\'])\n                if \'bias\' in cur_dict:\n                    current_layer_parameters.append(cur_dict[\'bias\'])\n            elif layer.__class__.__name__ == ""SeparableConv2D"":\n                current_layer_parameters = [cur_dict[\'depthwise_filter\'], cur_dict[\'pointwise_filter\']]\n                if \'bias\' in cur_dict:\n                    current_layer_parameters.append(cur_dict[\'bias\'])\n            elif layer.__class__.__name__ == ""Embedding"":\n                current_layer_parameters.append(cur_dict[\'weights\'])\n            elif layer.__class__.__name__ == ""PReLU"":\n                gamma =  np.ones(list(layer.input_shape[1:]))*cur_dict[\'gamma\']\n                current_layer_parameters.append(gamma)\n            else:\n                # rot \n                if \'weights\' in cur_dict:\n                    current_layer_parameters = [cur_dict[\'weights\']]\n                if \'bias\' in cur_dict:\n                    current_layer_parameters.append(cur_dict[\'bias\'])\n            model.get_layer(layer.name).set_weights(current_layer_parameters)\n\n    return model\n\n\ndef KitModel(weight_file = None):\n    global weights_dict\n    weights_dict = load_weights_from_file(weight_file) if not weight_file == None else None\n        """"""\n\n\n    def gen_code(self, phase):\n        self.add_body(0, self.header_code)\n        for layer in self.IR_graph.topological_sort:\n            current_node = self.IR_graph.get_node(layer)\n            node_type = current_node.type\n\n            if hasattr(self, ""emit_"" + node_type):\n                # print(""Converting layer {}({})"".format(current_node.name, node_type))\n                func = getattr(self, ""emit_"" + node_type)\n                line = func(current_node)\n                if line:\n                    self.add_body(1, line)\n            else:\n                print(""KerasEmitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(current_node)\n\n        self.add_body(1, ""{:<15} = Model(inputs = [{}], outputs = [{}])"".format(\n            ""model"",\n            \', \'.join([self.IR_graph.get_node(name).real_variable_name for name in self.IR_graph.input_layers if self.IR_graph.get_node(name).type != \'Const\']),\n            \', \'.join([self.IR_graph.get_node(name).real_variable_name for name in self.IR_graph.output_layers if self.IR_graph.get_node(name).type != \'Pack\'])))\n        self.add_body(1, [""set_layer_weights(model, weights_dict)"", ""return model""])\n\n        for i in self.used_layers:\n            func = getattr(self, ""_layer_"" + i)\n            func()\n\n        self.add_body(0, """")\n        for code in self.layers_codes.values():\n            self.add_body(0, code)\n\n        return self.body_code\n\n\n    @staticmethod\n    def shapeToStr(shapes):\n        return \', \'.join(\'%s\' % i for i in filter(lambda x:x > 0, shapes))\n\n\n    def _emit_activation(self, IR_node, op, in_scope=False):\n        if in_scope:\n            code = ""{:<15} = keras.activations.get(\'{}\')({})"".format(\n                IR_node.variable_name,\n                op,\n                self.parent_variable_name(IR_node))\n        else:\n            code =  ""{:<15} = layers.Activation(name=\'{}\', activation=\'{}\')({})"".format(\n                IR_node.variable_name,\n                IR_node.name,\n                op,\n                self.parent_variable_name(IR_node))\n\n        return code\n\n\n    def _emit_merge(self, IR_node, func):\n        if len(IR_node.in_edges) == 1:\n            IR_node.in_edges.append(IR_node.in_edges[0])\n        inputs = \', \'.join(\'%s\' % self.parent_variable_name(IR_node, i) for i in IR_node.in_edges)\n        axis = \' axis = {},\'.format(IR_node.get_attr(\'axis\')) if \'axis\' in IR_node.layer.attr else """"\n        code =  ""{:<15} = layers.{}(name = \'{}\', inputs = [{}])"".format(\n            IR_node.variable_name,\n            func,\n            IR_node.name,\n            inputs)\n        return code\n\n\n    @staticmethod\n    def _convert_padding(padding):\n        padding = convert_onnx_pad_to_tf(padding)[1:-1]\n\n        for idx, pad in enumerate(padding):\n            padding[idx] = tuple(pad)\n        padding = tuple(padding)\n        return padding\n\n\n    def _defuse_padding(self, IR_node, in_scope=False):\n        auto_pad = IR_node.get_attr(\'auto_pad\')\n\n        if auto_pad != None and auto_pad.startswith(""SAME""):\n            input_node = self.parent_variable_name(IR_node)\n            padding = \'same\'\n            return input_node, padding\n        else:\n\n            padding = IR_node.get_attr(""pads"")\n\n            if padding != None:\n                padding = self._convert_padding(padding)\n\n                if is_valid_padding(padding) == False:\n                    input_node = IR_node.variable_name + \'_input\'\n                    self.add_body(1, ""{:<15} = layers.ZeroPadding{}D(padding = {})({})"".format(\n                        input_node,\n                        len(padding),\n                        padding,\n                        self.parent_variable_name(IR_node)))\n                else:\n                    input_node = self.parent_variable_name(IR_node)\n            else:\n                input_node = self.parent_variable_name(IR_node)\n\n\n            # TODO\n            return input_node, \'valid\'\n            # return input_node, \'same\'\n\n\n    def _emit_convolution(self, IR_node, conv_type):\n        self.used_layers.add(\'Conv\')\n        # assert IR_node.get_attr(\'group\', 1) == 1\n        group = IR_node.get_attr(""group"", 1)\n\n        if conv_type.endswith(\'Transpose\'):\n            filters = IR_node.get_attr(\'kernel_shape\')[-2]\n        else:\n            filters = IR_node.get_attr(\'kernel_shape\')[-1]\n\n        filters_str = \'filters={}\'.format(filters) if not conv_type.endswith(\'DepthwiseConv2D\') else \'depth_multiplier={}\'.format(filters)\n        # change dw from filters to 1\n\n\n        input_node, padding = self._defuse_padding(IR_node)\n\n        dilations = IR_node.get_attr(\'dilations\')\n\n        if not dilations or len(dilations) == 2:\n            # reset the default dilation\n            dilations = [1] * len(IR_node.get_attr(\'kernel_shape\'))\n\n        code = ""{:<15} = convolution(weights_dict, name=\'{}\', input={}, group={}, conv_type=\'{}\', {}, kernel_size={}, strides={}, dilation_rate={}, padding=\'{}\', use_bias={})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            input_node,\n            group,\n            conv_type,\n            filters_str,\n            tuple(IR_node.get_attr(\'kernel_shape\')[:-2]),\n            tuple(IR_node.get_attr(\'strides\')[1:-1]),\n            tuple(dilations[1:-1]),\n            padding,\n            IR_node.get_attr(\'use_bias\'))\n\n        return code\n\n\n    def emit_ConvTranspose(self, IR_node, in_scope=False):\n        dim = len(IR_node.get_attr(\'kernel_shape\')) - 2\n        return self._emit_convolution(IR_node, \'layers.Conv{}DTranspose\'.format(dim))\n\n\n    def emit_Conv(self, IR_node, in_scope=False):\n        dim = len(IR_node.get_attr(\'kernel_shape\')) - 2\n        return self._emit_convolution(IR_node, \'layers.Conv{}D\'.format(dim))\n\n\n    #############\n    # Operators #\n    #############\n\n    def emit_UNKNOWN(self, IR_node, in_scope=False):\n        print (IR_node.name)\n\n\n    def emit_Mul(self, IR_node, in_scope=False):\n\n        if in_scope:\n            code = ""{:<15} = {} * {}"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1]))\n            return code\n\n        node_1 = self.IR_graph.get_node(IR_node.in_edges[0])\n        node_2 = self.IR_graph.get_node(IR_node.in_edges[1])\n\n        if node_1.type == \'Constant\' or node_2.type == \'Constant\':\n            self.used_layers.add(\'Mul_Constant\')\n            if node_1.type == \'Constant\': \n                weight_factor = node_1.get_attr(\'value\')\n                code = ""{:<15} = mul_constant(weight_factor={}, layer_name= {})"".format(\n                    IR_node.variable_name,\n                    weight_factor,\n                    self.parent_variable_name(IR_node, [1]))\n            else: \n                weight_factor = node_2.get_attr(\'value\')\n                code = ""{:<15} = mul_constant(weight_factor={}, layer_name= {})"".format(\n                    IR_node.variable_name,\n                    weight_factor,\n                    self.parent_variable_name(IR_node))\n        else:\n            self.used_layers.add(\'Mul\')\n            code = ""{:<15} = my_mul(name=\'{}\')([{}, {}])"".format(\n                IR_node.variable_name,\n                IR_node.name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1]))  \n        return code\n\n\n    def emit_Sub(self, IR_node, in_scope=False):\n        if in_scope:\n            code = ""{:<15} = {} - {}"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1]))\n            return code\n\n        self.used_layers.add(\'Sub\')\n        code = ""{:<15} = my_sub()({}, {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]))\n\n        # code = self._emit_merge(IR_node, ""subtract"")\n        return code\n\n\n    def emit_Add(self, IR_node, in_scope=False):\n        if in_scope:\n            code = ""{:<15} = {} + {}"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1]))\n            return code\n\n        self.used_layers.add(\'Add\')\n        code = ""{:<15} = my_add()([{}, {}])"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]))\n        return code\n\n\n    def emit_DataInput(self, IR_node, in_scope=False):\n        shape_str = IRGraph.shapeToStr(IR_node.IR_layer.attr[""shape""].shape)\n        dtype_str = "", dtype = \'{}\'"".format(self.dtype_map[IR_node.layer.attr[\'dtype\'].type]) if \'dtype\' in IR_node.layer.attr else """"\n\n        code = ""{:<15} = layers.Input(name = \'{}\', shape = ({},) {})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            shape_str,\n            dtype_str)\n        return code\n\n\n    def emit_Dropout(self, IR_node, in_scope=False):\n        seed = \'None\'\n        if \'seed\' in IR_node.IR_layer.attr:\n            seed = IR_node.IR_layer.attr[\'seed\'].i\n\n        code = ""{:<15} = layers.Dropout(name = \'{}\', rate = {}, seed = {})({})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            IR_node.IR_layer.attr[""keep_prob""].f,\n            seed,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_FullyConnected(self, IR_node, in_scope=False):\n        if in_scope:\n            code = ""{:<15} = K.bias_add(K.dot({}, K.variable(weights_dict[\'{}\'][\'weights\'])), K.variable(weights_dict[\'{}\'][\'bias\']))"".format(\n                IR_node.variable_name, \n                self.parent_variable_name(IR_node),\n                IR_node.name,\n                IR_node.name)\n        else:\n            code = ""{:<15} = layers.Dense(name = \'{}\', units = {}, use_bias = {})({})"".format(\n                IR_node.variable_name,\n                IR_node.name,\n                IR_node.get_attr(\'units\'),\n                IR_node.get_attr(\'use_bias\'),\n                self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Flatten(self, IR_node, in_scope=False):\n        self.used_layers.add(\'Flatten\')\n        code = ""{:<15} = __flatten(name = \'{}\', input = {})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Pool(self, IR_node, in_scope=False):\n        codes = list()\n        dim = len(IR_node.get_attr(""strides"")) - 2\n\n        pooling_type = IR_node.get_attr(\'pooling_type\')\n        if  pooling_type == ""MAX"":\n            pool_name = ""MaxPooling{}D"".format(dim)\n        elif pooling_type == ""AVG"":\n            pool_name = ""AveragePooling{}D"".format(dim)\n        else:\n            print(pooling_type)\n            assert False\n\n        # TODO\n        if IR_node.layer.attr[\'global_pooling\'].b:\n\n            shape_str = IR_node.get_attr(""shape_coreml"")\n            if shape_str:\n                shape_str = \',\'.join([str(i) for i in shape_str])\n\n                codes.append(""{:<15} = layers.Global{}(name = \'{}\')({})"".format(\n                    IR_node.variable_name+\'before\',\n                    pool_name,\n                    IR_node.name,\n                    self.parent_variable_name(IR_node)))\n\n                #  when converting from coreml model, reshape is needed after the global pooling\n                codes.append(""{:<15} = layers.Reshape(name = \'{}\', target_shape = ({},))({})"".format(\n                    IR_node.variable_name,\n                    IR_node.name + \'reshape\',\n                    shape_str,\n                    IR_node.variable_name+\'before\'))\n            else:\n                codes.append(""{:<15} = layers.Global{}(name = \'{}\')({})"".format(\n                IR_node.variable_name,\n                pool_name,\n                IR_node.name,\n                self.parent_variable_name(IR_node)))\n\n        else:\n            dilations = IR_node.get_attr(\'dilations\')\n            if dilations:\n                for e in IR_node.get_attr(\'dilations\'):\n                    assert e == 1\n\n            pool_size = IR_node.get_attr(\'kernel_shape\')[1:-1]\n\n            strides = IR_node.get_attr(\'strides\')[1:-1]\n            padding = IR_node.get_attr(\'pads\')[1:dim]\n\n            if pooling_type == ""AVG"" and pool_size.count(pool_size[0]) == len(pool_size) and strides[0] == 1 and strides.count(strides[0]) == len(strides) and padding.count(padding[0]) == len(padding) and pool_size[0] == padding[0]*2 + 1:\n                pool_size = \', \'.join(\'%s\' % i for i in pool_size)\n                strides = \', \'.join(\'%s\' % i for i in strides)\n                codes.append(""{:<15} = layers.{}(name = \'{}\', pool_size = ({}), strides = ({}), padding = \'{}\')({})"".format(\n                    IR_node.variable_name,\n                    pool_name,\n                    IR_node.name,\n                    pool_size,\n                    strides,\n                    \'same\',\n                    self.parent_variable_name(IR_node)\n                    ))\n\n\n            else:\n\n                pool_size = \', \'.join(\'%s\' % i for i in pool_size)\n                strides = \', \'.join(\'%s\' % i for i in strides)\n                input_node, padding = self._defuse_padding(IR_node)\n\n                codes.append(""{:<15} = layers.{}(name = \'{}\', pool_size = ({}), strides = ({}), padding = \'{}\')({})"".format(\n                    IR_node.variable_name,\n                    pool_name,\n                    IR_node.name,\n                    pool_size,\n                    strides,\n                    padding,\n                    input_node))\n        return codes\n\n\n    def emit_Reshape(self, IR_node, in_scope=False):\n        shape_str = self.shapeToStr(IR_node.IR_layer.attr[""shape""].list.i)\n        code = ""{:<15} = layers.Reshape(name = \'{}\', target_shape = ({},))({})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            shape_str,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Elu(self, IR_node):\n        self._emit_activation(IR_node, \'elu\')\n\n\n    def emit_Relu(self, IR_node):\n        self._emit_activation(IR_node, \'relu\')\n\n\n    def emit_Tanh(self, IR_node, in_scope=False):\n        code = self._emit_activation(IR_node, \'tanh\', in_scope)\n        return code\n\n    def emit_Relu(self, IR_node, in_scope=False):\n        code = self._emit_activation(IR_node, \'relu\', in_scope)\n        return code\n\n    def emit_Softmax(self, IR_node, in_scope=False):\n        code = self._emit_activation(IR_node, \'softmax\', in_scope)\n        return code\n\n    def emit_Sigmoid(self, IR_node, in_scope=False):\n        code = self._emit_activation(IR_node, \'sigmoid\', in_scope)\n        return code\n\n    def emit_Embedding(self, IR_node, in_scope=False):\n\n        code = ""{:<15} = layers.Embedding(name = \'{}\', input_dim = {}, output_dim = {}, mask_zero = {})({})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            IR_node.get_attr(\'input_dim\'),\n            IR_node.get_attr(\'output_dim\'),\n            IR_node.get_attr(\'mask_zero\'),\n            IR_node.in_edges[0])\n        return code\n\n\n    def emit_RNNs(self, IR_node, func):\n        # for Keras\n        if ""dropout"" in IR_node.IR_layer.attr:\n            dropout_str = "",dropout = {}, recurrent_dropout = {}"".format(\n                    IR_node.IR_layer.attr[\'dropout\'].f,\n                    IR_node.IR_layer.attr[\'recurrent_dropout\'].f)\n        else:\n            dropout_str = """"\n\n        code = ""{:<15} = layers.{}(units = {}, use_bias = {} {})({})"".format(\n                IR_node.name,\n                func,\n                IR_node.IR_layer.attr[\'units\'].i,\n                IR_node.IR_layer.attr[\'use_bias\'].b,\n                dropout_str,\n                IR_node.in_edges[0])\n\n        return code\n\n\n    def emit_LSTM(self, IR_node, in_scope=False):\n        return self.emit_RNNs(IR_node, ""LSTM"")\n\n\n    def emit_GRU(self, IR_node, in_scope=False):\n        return self.emit_RNNs(IR_node, ""GRU"")\n\n\n    def emit_Concat(self, IR_node, in_scope=False):\n        inputs = \', \'.join(\'%s\' % self.parent_variable_name(IR_node, s) for s in IR_node.in_edges)\n        if in_scope:\n            code = ""{:<15} = K.concatenate([{}])"".format(\n                IR_node.variable_name,\n                inputs)\n        else:\n            code = self._emit_merge(IR_node, ""concatenate"")\n        return code\n\n\n    def emit_BatchNorm(self, IR_node, in_scope=False):\n        axis = IR_node.layer.attr[\'axis\'].i if \'axis\' in IR_node.layer.attr else -1\n\n        code = ""{:<15} = layers.BatchNormalization(name = \'{}\', axis = {}, epsilon = {}, center = {}, scale = {})({})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            axis,\n            IR_node.layer.attr[\'epsilon\'].f,\n            IR_node.layer.attr[\'bias\'].b,\n            IR_node.layer.attr[\'scale\'].b,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Scale(self, IR_node, in_scope=False):\n        self.used_layers.add(\'Scale\')\n        axis = IR_node.layer.attr[\'axis\'].i if \'axis\' in IR_node.layer.attr else -1\n\n        code = ""{:<15} = Scale(name = \'{}\', axis = {}, center = {}, scale = {})({})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            axis,\n            IR_node.layer.attr[\'use_bias\'].b,\n            True,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Pad(self, IR_node, in_scope=False):\n        mode = IR_node.get_attr(\'mode\', \'constant\')\n        mode = mode.lower()\n        if mode == ""constant"":\n            func = ""ZeroPadding""\n        else:\n            raise NotImplementedError()\n\n        dim = len(IR_node.get_attr(\'pads\')) // 2 - 2\n\n        padding = self._convert_padding(IR_node.get_attr(\'pads\'))\n        code = ""{:<15} = layers.{}{}D(name=\'{}\', padding={})({})"".format(\n            IR_node.variable_name,\n            func,\n            dim,\n            IR_node.name,\n            padding,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Squeeze(self, IR_node, in_scope=False):\n        return self.emit_Flatten(IR_node)\n\n\n    def emit_ReduceMean(self, IR_node, in_scope=False):\n        axes = \', \'.join(\'%s\' % i for i in IR_node.get_attr(\'axes\'))\n\n        code = ""{:<15} = layers.Lambda(lambda x: K.mean(x, axis=[{}], keepdims={}))({})"".format(\n            IR_node.variable_name,\n            axes,\n            IR_node.get_attr(\'keepdims\'),\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_LRN(self, IR_node, in_scope=False):\n        self.used_layers.add(IR_node.type)\n        output_name = IR_node.variable_name\n        input_name = self.parent_variable_name(IR_node)\n        IR_name = IR_node.name\n        size = IR_node.get_attr(\'size\')\n        alpha = IR_node.get_attr(\'alpha\')\n        beta = IR_node.get_attr(\'beta\')\n        bias = IR_node.get_attr(\'bias\')\n\n        code = ""{:<15} = LRN(size = {}, alpha = {}, beta = {}, k = {}, name = \'{}\')({})"".format(\n            output_name,\n            size,\n            alpha,\n            beta,\n            bias,\n            IR_name,\n            input_name)\n        return code\n\n    def emit_Split(self, IR_node, in_scope=False):\n        if in_scope:\n            axis = IR_node.get_attr(\'axis\')\n            split_num = IR_node.get_attr(\'split\')\n            segment_len = ""K.int_shape({})[{}]//{}"".format(self.parent_variable_name(IR_node),axis, split_num)\n            split_str = \'[\' + \',\'.join(\':\' for i in range(axis)) + \',{}:{},...]\'\n            split_strs = []\n\n            for i in range(split_num-1):\n                split_strs.append(self.parent_variable_name(IR_node)+split_str.format(str(i)+\'*\'+ segment_len, str(i+1)+\'*\'+segment_len))\n\n            split_strs.append(self.parent_variable_name(IR_node)+split_str.format(str(split_num-1)+\'*\'+segment_len, \'\'))\n\n            code = ""{:<15} = {}"".format(IR_node.variable_name, \', \'.join(split_strs))\n\n        else:\n            self.used_layers.add(IR_node.type)\n            code = ""{:<15} = __split(input={}, split_num={}, axis={})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                IR_node.get_attr(\'split\'),\n                IR_node.get_attr(\'axis\'))\n\n        return code\n    \n    def emit_Unsqueeze(self, IR_node, in_scope=False):\n        self.used_layers.add(IR_node.type)\n\n        code = ""{:<15} = __unsqueeze(input={}, axis={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'axes\')[0])\n        return code\n\n    def emit_Constant(self, IR_node, in_scope=False):\n\n        if in_scope:\n            if IR_node.get_attr(\'value\'):\n                code = ""{:<15} = K.constant({})"".format(IR_node.variable_name, IR_node.get_attr(\'value\'))\n            else:\n                code = ""{:<15} = K.constant(weights_dict[\'{}\'][\'value\'])"".format(IR_node.variable_name, IR_node.name)\n            return code\n        else:\n           pass \n\n\n    def emit_Shape(self, IR_node, in_scope=False):\n        self.used_layers.add(IR_node.type)\n\n        code = ""{:<15} = __shape(input={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Fill(self, IR_node, in_scope=False):\n        self.used_layers.add(IR_node.type)\n        code = ""{:<15} = __fill(input={}, value={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'value\'))\n        \n        return code\n\n\n    def emit_Slice(self, IR_node, in_scope=False):\n        # It arouses some problems:\n        # it can be implemented by Lambda Layer\n        # https://github.com/keras-team/keras/issues/890\n\n        self.used_layers.add(IR_node.type)\n\n        extra_str = """"\n        if IR_node.get_attr(\'strides\'):\n            extra_str += ""strides={}"".format(IR_node.get_attr(\'strides\'))\n        if IR_node.get_attr(\'begin_mask\'):\n            extra_str += "", begin_mask={}"".format(IR_node.get_attr(\'begin_mask\'))\n        if IR_node.get_attr(\'end_mask\'):\n            extra_str += "", end_mask={}"".format(IR_node.get_attr(\'end_mask\'))\n        if IR_node.get_attr(\'shrink_axis_mask\'):\n            extra_str += "", shrink_axis_mask={}"".format(IR_node.get_attr(\'shrink_axis_mask\'))\n\n        code = ""{:<15} = __slice({}, {}, {}, {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'starts\'),\n            IR_node.get_attr(\'ends\'),\n            extra_str)\n        return code\n\n    def emit_Unstack(self, IR_node, in_scope=False):\n        self.used_layers.add(IR_node.type)\n\n        code = ""{:<15} = __unstack(input={}, num={}, axis={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'num\'),\n            IR_node.get_attr(\'axis\'))\n        return code\n\n    def emit_Pack(self, IR_node, in_scope=False):\n        pass\n\n\n    def emit_SeparableConv(self, IR_node, in_scope=False):\n        assert len(IR_node.get_attr(""strides"")) == 4\n        return self._emit_convolution(IR_node, ""layers.SeparableConv2D"")\n\n\n    def emit_Relu6(self, IR_node, in_scope=False):\n        try:\n            # Keras == 2.1.6\n            from keras.applications.mobilenet import relu6\n            str_relu6 = \'keras.applications.mobilenet.relu6\'\n            code = ""{:<15} = layers.Activation({}, name = \'{}\')({})"".format(\n                IR_node.variable_name,\n                str_relu6,\n                IR_node.name,\n                self.IR_graph.get_node(IR_node.in_edges[0]).real_variable_name)\n            return code\n\n        except:\n            # Keras == 2.2.2\n            from keras.layers import ReLU\n            code = ""{:<15} = layers.ReLU(6, name = \'{}\')({})"".format(\n                IR_node.variable_name,\n                IR_node.name,\n                self.IR_graph.get_node(IR_node.in_edges[0]).real_variable_name)\n            return code\n\n\n    def emit_DepthwiseConv(self, IR_node, in_scope=False):\n        try:\n            from keras.applications.mobilenet import DepthwiseConv2D\n            return self._emit_convolution(IR_node, \'keras.applications.mobilenet.DepthwiseConv2D\')\n        except:\n            return self._emit_convolution(IR_node, \'layers.DepthwiseConv2D\')\n\n\n    def emit_Crop(self, IR_node, in_scope=False):\n        border = IR_node.get_attr(\'border\')\n        rank = len(border) // 2\n        cropping = []\n        for idx in xrange(rank):\n            cropping.append(tuple([border[idx * 2], border[idx * 2 + 1]]))\n\n        code = ""{:<15} = layers.Cropping{}D(cropping={}, name=\'{}\')({})"".format(\n            IR_node.variable_name,\n            rank,\n            tuple(cropping),\n            IR_node.name,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_LeakyRelu(self, IR_node, in_scope=False):\n        code = ""{:<15} = layers.LeakyReLU(name=\'{}\', alpha = {})({})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            IR_node.get_attr(\'alpha\'),\n            self.parent_variable_name(IR_node))\n        return code\n\n    def emit_UpSampling2D(self, IR_node, in_scope=False):\n        code = ""{:<15} = layers.UpSampling2D(name=\'{}\', size= ({}), data_format = \'channels_last\')({})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            IR_node.get_attr(\'scales\'),\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_SpaceToDepth(self, IR_node, in_scope=False):\n        self.used_layers.add(IR_node.type)\n        assert IR_node.get_attr(\'blocksize\') == 2\n        # TODO: arguments won\'t be saved in keras export model\n\n        blocksize = ""arguments={\'blocksize\': %d}"" % 2\n        code = ""{:<15} = layers.Lambda(space_to_depth, {}, name=\'{}\')({})"".format(\n            IR_node.variable_name,\n            blocksize,\n            IR_node.name,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Maxmum(self, IR_node, in_scope=False):\n        if in_scope:\n            code = ""{:<15} = K.maxmum({}, {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1])\n            )\n            return code\n        else:\n            return self._emit_merge(IR_node, \'Maxmum\')\n\n\n    def emit_Minimum(self, IR_node, in_scope=False):\n        if in_scope:\n            code = ""{:<15} = K.minimum({}, {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1])\n            )\n            return code\n        else:\n            return self._emit_merge(IR_node, \'Minimum\')\n\n\n    def emit_PRelu(self, IR_node, in_scope=False):\n        if in_scope:\n            raise NotImplementedError\n        else:\n            code = ""{:<15} = layers.PReLU(name=\'{}\')({})"".format(\n                IR_node.variable_name,\n                IR_node.name,\n                self.parent_variable_name(IR_node)\n            )\n            return code\n\n    def emit_Affine(self, IR_node, in_scope=False):\n        if in_scope:\n            raise NotImplementedError\n        else:\n            self.used_layers.add(\'Affine\')\n            if IR_node.layer.attr.get(\'beta\', None) is None:\n                bias = None\n            else:\n                bias = IR_node.layer.attr[\'beta\'].f\n            code = ""{:<15} = Affine(name=\'{}\', scale={}, bias={})({})"".format(\n                IR_node.variable_name,\n                IR_node.name,\n                IR_node.layer.attr[\'gamma\'].f,\n                bias,\n                self.parent_variable_name(IR_node))\n            return code\n\n    def emit_yolo(self, IR_node, in_scope=False):\n        self.used_layers.add(\'Yolo\')\n        self.yolo_parameter = [IR_node.get_attr(\'anchors\'),\n            IR_node.get_attr(\'classes\'),\n            IR_node.get_attr(""ignore_thresh""),\n            IR_node.get_attr(""jitter"")]\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_region(self, IR_node, in_scope=False):\n        self.used_layers.add(\'Region\')\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node))\n        self.region_parameter = [IR_node.get_attr(\'anchors\'),\n            IR_node.get_attr(\'classes\'),\n            IR_node.get_attr(""thresh""),\n            IR_node.get_attr(""softmax""),\n            IR_node.get_attr(""bias_match""),\n            IR_node.get_attr(""jitter""),\n            IR_node.get_attr(""num""),\n            IR_node.get_attr(""random""),\n            IR_node.get_attr(""coords""),\n            IR_node.get_attr(""absolute""),\n            IR_node.get_attr(""rescore""),\n            IR_node.get_attr(""class_scale""),\n            IR_node.get_attr(""object_scale""),\n            IR_node.get_attr(""noobject_scale""),\n            IR_node.get_attr(""coord_scale""),\n            ]\n        return code\n\n    def emit_Scope(self, IR_node, in_scope=False):\n        if hasattr(self, \'_emit_\' + IR_node.pattern):\n            func = getattr(self, \'_emit_\' + IR_node.pattern)\n            line = func(IR_node)\n            return line\n        \n        input_vars = list()\n        for idx, in_edge in enumerate(IR_node.in_edges):\n            in_node = self.IR_graph.get_node(in_edge)\n            if in_node.type == \'Scope\' and len(in_node.return_variables) > 1 and \':\' not in in_edge: # the input is a list\n                var_name = \', \'.join([(in_node.variable_name + ""[%s]"") %s for s in range(len(in_node.return_variables))])\n                input_vars.append(var_name)\n            else:\n                input_vars.append(self.parent_variable_name(IR_node, [idx]))\n\n        code = ""{:<15} = my_{}()([{}])"".format(\n            IR_node.real_variable_name,\n            IR_node.pattern,\n            \', \'.join(input_vars))\n        self._gen_scope_code(IR_node)\n\n        return code\n\n\n    def _gen_scope_code(self, scope_node):\n\n        def _scope_func(scope_name, params, code, return_var):\n            if len(return_var) > 1:\n                return_var_code = \'[{}]\'.format(\', \'.join(return_var))\n                output_shape_code = \'        self.output_shapes = [{}]\\n\'.format(\', \'.join([\'K.int_shape(%s)\' %s for s in return_var]))\n            else:\n                return_var_code = \', \'.join(return_var)\n                output_shape_code = \'        self.output_shapes = K.int_shape({})\\n\'.format(return_var[0])\n\n            code = """"""\nclass my_{}(keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(my_{}, self).__init__(**kwargs)\n    def call(self, inputs):\n\n{}\n{}\n{}\n        return {}\n    \n    def compute_output_shape(self, input_shape):\n        return self.output_shapes\n\n    """""".format(scope_name, scope_name, params, code, output_shape_code, return_var_code)\n            return code\n\n        if not self.layers_codes.get(scope_node.pattern, None):\n            body_code = str()\n            for node_name in scope_node.topology_list:\n                node = self.IR_graph.get_node(node_name)\n                node_type = node.type\n\n                if hasattr(self, ""emit_"" + node_type):\n                    func = getattr(self, ""emit_"" + node_type)\n                    line = func(node, True)\n                    if line != None:\n                        body_code += ""        "" + line + \'\\n\'\n                else:\n                    print(""KerasEmitter has not supported operator [%s]."" % (node_type))\n                    self.emit_UNKNOWN(node)\n\n            # param_code does not need parameter slice.\n            input_params = scope_node.input_params\n            \n            param_code = str()\n            import re\n            for i, p in enumerate(scope_node.in_edges):\n                p_node = self.IR_graph.get_node(p)\n                if p_node.type == \'Scope\' and len(p_node.return_variables) > 1 and \':\' not in p: # input is a list.\n                    param_code += ""        {} = [{}]\\n"".format(p_node.variable_name, \', \'.join(\'inputs[%s]\'%s for s in range(i, i + len(p_node.return_variables))))\n                else:\n                    param_code += ""        {} = inputs[{}]\\n"".format(p_node.variable_name, i) \n\n            function_code = _scope_func(scope_node.pattern, param_code, body_code, scope_node.return_variables)\n            self.layers_codes[scope_node.pattern] = function_code\n            return body_code\n\n\n    def _emit_h_zero(self, IR_node):\n        if not self.layers_codes.get(IR_node.pattern, None):\n            class_code = \'\'\'\nclass my_h_zero(keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(my_h_zero, self).__init__(**kwargs)\n    \n    def call(self, dummy):\n        {:<15} = K.constant(np.full((1, {}), {}))\n\n        return {}\n            \'\'\'.format(IR_node.variable_name,\n            IR_node.get_attr(\'fill_size\'),\n            IR_node.get_attr(\'fill_value\'),\n            IR_node.variable_name)\n            self.layers_codes[IR_node.pattern] = class_code\n\n        code = ""{:<15} = my_h_zero()({})"".format(IR_node.variable_name, self.parent_variable_name(IR_node))\n\n        return code\n\n\n    def _layer_Yolo(self):\n        self.add_body(0, \'\'\'\ndef yolo_parameter():\n    return {}\n\'\'\'.format(self.yolo_parameter))\n\n\n    def _layer_Region(self):\n        self.add_body(0, \'\'\'\ndef region_parameter():\n    return {}\n\'\'\'.format(self.region_parameter))\n\n\n    def _layer_SpaceToDepth(self):\n        self.add_body(0, \'\'\'\ndef space_to_depth(input, blocksize):\n    import tensorflow as tf\n    return tf.space_to_depth(input, block_size=blocksize)\n\'\'\')\n\n\n    def _layer_Flatten(self):\n        self.add_body(0, \'\'\'\ndef __flatten(name, input):\n    if input.shape.ndims > 2: return layers.Flatten(name = name)(input)\n    else: return input\n\'\'\')\n\n    def _layer_LRN(self):\n        self.add_body(0, \'\'\'\nfrom keras.layers.core import Layer\nclass LRN(Layer):\n\n    def __init__(self, size=5, alpha=0.0005, beta=0.75, k=2, **kwargs):\n        self.n = size\n        self.alpha = alpha\n        self.beta = beta\n        self.k = k\n        super(LRN, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.shape = input_shape\n        super(LRN, self).build(input_shape)\n\n    def call(self, x, mask=None):\n        half_n = int(self.n/2)\n        squared = K.square(x)\n        scale = self.k\n        norm_alpha = self.alpha / self.n\n        if K.image_dim_ordering() == ""th"":\n            b, f, r, c = self.shape\n            squared = K.expand_dims(squared, 0)\n            squared = K.spatial_3d_padding(squared, padding=((half_n, half_n), (0, 0), (0,0)))\n            squared = K.squeeze(squared, 0)\n            for i in range(self.n):\n                scale += norm_alpha * squared[:, i:i+f, :, :]\n        else:\n            b, r, c, f = self.shape\n            squared = K.expand_dims(squared, -1)\n            squared = K.spatial_3d_padding(squared, padding=((0, 0), (0,0), (half_n, half_n)))\n            squared = K.squeeze(squared, -1)\n            for i in range(self.n):\n                scale += norm_alpha * squared[:, :, :, i:i+f]\n\n        scale = K.pow(scale, self.beta)\n        return x / scale\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\'\'\')\n\n\n    def _layer_Conv(self):\n        self.add_body(0, """"""\ndef convolution(weights_dict, name, input, group, conv_type, filters=None, **kwargs):\n    if not conv_type.startswith(\'layer\'):\n        layer = keras.applications.mobilenet.DepthwiseConv2D(name=name, **kwargs)(input)\n        return layer\n    elif conv_type == \'layers.DepthwiseConv2D\':\n        layer = layers.DepthwiseConv2D(name=name, **kwargs)(input)\n        return layer\n    \n    inp_filters = K.int_shape(input)[-1]\n    inp_grouped_channels = int(inp_filters / group)\n    out_grouped_channels = int(filters / group)\n    group_list = []\n    if group == 1:\n        func = getattr(layers, conv_type.split(\'.\')[-1])\n        layer = func(name = name, filters = filters, **kwargs)(input)\n        return layer\n    weight_groups = list()\n    if not weights_dict == None:\n        w = np.array(weights_dict[name][\'weights\'])\n        weight_groups = np.split(w, indices_or_sections=group, axis=-1)\n    for c in range(group):\n        x = layers.Lambda(lambda z: z[..., c * inp_grouped_channels:(c + 1) * inp_grouped_channels])(input)\n        x = layers.Conv2D(name=name + ""_"" + str(c), filters=out_grouped_channels, **kwargs)(x)\n        weights_dict[name + ""_"" + str(c)] = dict()\n        weights_dict[name + ""_"" + str(c)][\'weights\'] = weight_groups[c]\n        group_list.append(x)\n    layer = layers.concatenate(group_list, axis = -1)\n    if \'bias\' in weights_dict[name]:\n        b = K.variable(weights_dict[name][\'bias\'], name = name + ""_bias"")\n        layer = layer + b\n    return layer"""""")\n\n    def _layer_Scale(self):\n        self.add_body(0, """"""\nfrom keras.engine import Layer, InputSpec\nfrom keras import initializers\nfrom keras  import backend as K\n\n\nclass Scale(Layer):\n\n    def __init__(self,\n                 axis=-1,\n                 center=True,\n                 scale=True,\n                 beta_initializer=\'zeros\',\n                 gamma_initializer=\'ones\',\n                 **kwargs):\n        super(Scale, self).__init__(**kwargs)\n        self.supports_masking = True\n        self.axis = axis\n        self.center = center\n        self.scale = scale\n        self.beta_initializer = initializers.get(beta_initializer)\n        self.gamma_initializer = initializers.get(gamma_initializer)\n\n\n    def build(self, input_shape):\n        dim = input_shape[self.axis]\n        if dim is None:\n            raise ValueError(\'Axis \' + str(self.axis) + \' of \'\n                             \'input tensor should have a defined dimension \'\n                             \'but the layer received an input with shape \' +\n                             str(input_shape) + \'.\')\n        self.input_spec = InputSpec(ndim=len(input_shape),\n                                    axes={self.axis: dim})\n        shape = (dim,)\n\n        if self.scale:\n            self.gamma = self.add_weight(shape=shape,\n                                         name=\'gamma\',\n                                         initializer=self.gamma_initializer)\n        else:\n            self.gamma = None\n        if self.center:\n            self.beta = self.add_weight(shape=shape,\n                                        name=\'beta\',\n                                        initializer=self.beta_initializer)\n        else:\n            self.beta = None\n\n\n        self.built = True\n\n    def call(self, inputs, training=None):\n        input_shape = K.int_shape(inputs)\n        # Prepare broadcasting shape.\n        ndim = len(input_shape)\n        reduction_axes = list(range(len(input_shape)))\n        del reduction_axes[self.axis]\n        broadcast_shape = [1] * len(input_shape)\n        broadcast_shape[self.axis] = input_shape[self.axis]\n        return K.reshape(self.gamma, broadcast_shape) * inputs + K.reshape(self.beta, broadcast_shape)\n\n    def get_config(self):\n        config = {\n            \'axis\': self.axis,\n            \'center\': self.center,\n            \'scale\': self.scale,\n        }\n        base_config = super(Scale, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape"""""")\n\n\n    def _layer_Affine(self):\n        self.add_body(0, \'\'\'\nfrom keras.engine import Layer, InputSpec\nfrom keras import initializers\nfrom keras  import backend as K\n\nclass Affine(Layer):\n    def __init__(self, scale, bias=None, **kwargs):\n        super(Affine, self).__init__(**kwargs)\n        self.gamma = scale\n        self.beta = bias\n\n    def call(self, inputs, training=None):\n        input_shape = K.int_shape(inputs)\n        # Prepare broadcasting shape.\n        return self.gamma * inputs + self.beta\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n        \'\'\')\n\n\n    def _layer_Split(self):\n        self.add_body(0, \'\'\'\ndef __split(input, split_num, axis):\n    return Lambda(lambda x: tf.split(x, split_num, axis))(input)\n        \'\'\')\n\n\n    def _layer_Unsqueeze(self):\n        self.add_body(0, \'\'\'\ndef __unsqueeze(input, axis):\n    return Lambda(lambda x: tf.expand_dims(x, axis))(input)\n        \'\'\')\n\n\n    def _layer_Fill(self):\n        self.add_body(0, \'\'\'\ndef __fill(input, value):\n    class Fill(keras.layers.Layer):\n        def call(self, input):\n            if keras.backend.backend() ==\'tensorflow\':\n                output = tf.fill(input, value)\n            else:\n                raise NotImplementedError\n            self.output_dim = [dim.value for dim in output.shape]\n            return output\n        \n        def compute_output_shape(self, input_shape):\n            return tuple(self.output_dim)\n    # output = Lambda(lambda x: tf.fill(x, value))(input)\n    output = Fill()(input)\n    # return output\n\n        \'\'\')\n\n\n    def _layer_Slice(self):\n        self.add_body(0, \'\'\'\ndef __slice(input, start, end, **kargs):\n    return Lambda(lambda x: tf.strided_slice(x, start, end, **kargs))(input)\n        \'\'\')\n\n\n    def _layer_Unstack(self):\n        self.add_body(0, \'\'\'\ndef __unstack(input, num, axis):\n    return Lambda(lambda x: tf.unstack(x, num, axis))(input)\n        \'\'\')\n\n\n    def _layer_Mul(self):\n        self.add_body(0, \'\'\'\nclass my_mul(keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(my_mul, self).__init__(**kwargs)\n    def call(self, inputs):\n        res = inputs[0] * inputs[1]\n        self.output_shapes = K.int_shape(res)\n        return res\n    \n    def compute_output_shape(self, input_shape):\n        return self.output_shapes\n\'\'\')\n\n\n    def _layer_Add(self):\n        self.add_body(0, \'\'\'\nclass my_add(keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(my_add, self).__init__(**kwargs)\n    def call(self, inputs):\n        res = inputs[0] + inputs[1]\n        self.output_shapes = K.int_shape(res)\n        return res\n    \n    def compute_output_shape(self, input_shape):\n        return self.output_shapes\n\'\'\')\n\n    def _layer_Sub(self):\n        self.add_body(0, \'\'\'\nclass my_sub(keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(my_sub, self).__init__(**kwargs)\n    def call(self, inputs):\n        res = inputs[0] - inputs[1]\n        self.output_shapes = K.int_shape(res)\n        return res\n    \n    def compute_output_shape(self, input_shape):\n        return self.output_shapes\n\'\'\')\n\n    def _layer_Shape(self):\n        self.add_body(0, \'\'\'\ndef __shape(input):\n    return Lambda(lambda x: tf.shape(x))(input)\n        \'\'\')\n\n#     def _layer_Constant(self):\n#         self.add_body(0, \'\'\'\n# class my_constant(keras.layers.Layer):\n#     def __init__(self, value, **kwargs):\n#         super(my_constant, self).__init__(**kwargs)\n#         self._value = value\n#     # the input is dummy, just for creating keras graph.\n#     def call(self, dummy):\n#         res = K.constant(self._value)\n#         self.output_shapes = K.int_shape(res)\n#         return res\n    \n#     def compute_output_shape(self, input_shape):\n#         return self.output_shapes\n# \'\'\')\n\n    def _layer_Mul_Constant(self):\n        self.add_body(0, \'\'\'\ndef mul_constant(weight_factor, layer_name):\n    weight = Lambda(lambda x: x*weight_factor)\n    weight(layer_name)\n    return weight.output\n\'\'\')'"
mmdnn/conversion/keras/keras2_graph.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\nimport os\nimport keras as _keras\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\n\n\nclass Keras2GraphNode(GraphNode):\n\n    def __init__(self, layer):\n        super(Keras2GraphNode, self).__init__(layer)\n\n\n    @property\n    def name(self):\n        return self.layer.name\n\n\n    @property\n    def type(self):\n        return self.layer.__class__.__name__\n\n\n    @property\n    def keras_layer(self):\n        return self.layer\n\n\n\nclass Keras2Graph(Graph):\n\n    def __init__(self, model):\n        # sanity check.\n        if not (type(model) == _keras.models.Sequential or type(model) == _keras.models.Model):\n            raise TypeError(""Keras layer of type %s is not supported."" % type(model))\n        super(Keras2Graph, self).__init__(model)\n        self.model = model\n\n\n    def build(self):\n        self.input_layers = list()\n        for i, layer in enumerate(self.model.layers):\n            self.layer_map[layer.name] = Keras2GraphNode(layer)\n            self.layer_name_map[layer.name] = layer.name\n            for node in layer._inbound_nodes:\n                for pred in node.inbound_layers:\n                    if pred.name not in self.layer_map:\n                        self.layer_map[pred.name] = Keras2GraphNode(pred)\n                        self.layer_name_map[pred.name] = pred.name\n                    self._make_connection(pred.name, layer.name)\n\n        # Kit: TODO\n        # Duplicate models for weight sharing\n        # Expand the sub-models\n        super(Keras2Graph, self).build()'"
mmdnn/conversion/keras/keras2_parser.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\nfrom six import string_types as _string_types\nimport keras as _keras\nfrom keras import backend as _K\n\nfrom mmdnn.conversion.keras.keras2_graph import Keras2Graph\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom mmdnn.conversion.common.utils import *\n\n\nclass Keras2Parser(Parser):\n\n    dtype_map = {\n        ""float16"" : graph_pb2.DT_FLOAT16,\n        ""float32"" : graph_pb2.DT_FLOAT32,\n        ""float64"" : graph_pb2.DT_FLOAT64,\n        ""int16""   : graph_pb2.DT_INT16,\n        ""int32""   : graph_pb2.DT_INT32,\n        ""int64""   : graph_pb2.DT_INT64,\n        ""uint8""   : graph_pb2.DT_UINT8,\n        ""uint16""  : graph_pb2.DT_UINT16\n    }\n\n    activation_map = {\n        ""relu""          : ""Relu"",\n        \'softmax\'       : ""Softmax"",\n        \'sigmoid\'       : ""Sigmoid"",\n        ""tanh""          : ""Tanh"",\n        ""elu""           : ""Elu"",\n        ""relu6""         : ""Relu6"",\n        \'softplus\'      : \'Softplus\',\n        \'softsign\'      : \'Softsign\',\n        \'hard_sigmoid\'  : \'HardSigmoid\'\n    }\n\n\n    def _load_model(self, model_network_path, model_weight_path):\n        """"""Load a keras model from disk\n\n        Parameters\n        ----------\n        model_network_path: str\n            Path where the model network path is (json file)\n\n        model_weight_path: str\n            Path where the model network weights are (hd5 file)\n\n        Returns\n        -------\n        model: A keras model\n        """"""\n        from keras.models import model_from_json\n\n        # Load the model network\n        json_file = open(model_network_path, \'r\')\n        loaded_model_json = json_file.read()\n        json_file.close()\n\n        # Load the model weights\n\n        try:\n            from keras.applications.mobilenet import relu6\n            from keras.applications.mobilenet import DepthwiseConv2D\n            loaded_model = model_from_json(loaded_model_json, custom_objects={\n                \'relu6\': _keras.applications.mobilenet.relu6,\n                \'DepthwiseConv2D\': _keras.applications.mobilenet.DepthwiseConv2D})\n        except:\n            import keras.layers as layers\n            loaded_model = model_from_json(loaded_model_json, custom_objects={\n                \'relu6\': layers.ReLU(6, name=\'relu6\'),\n                \'DepthwiseConv2D\': layers.DepthwiseConv2D})\n\n\n        if model_weight_path:\n            if os.path.isfile(model_weight_path):\n                loaded_model.load_weights(model_weight_path)\n                self.weight_loaded = True\n                print(""Network file [{}] and [{}] is loaded successfully."".format(model_network_path, model_weight_path))\n\n            else:\n                print(""Warning: Weights File [%s] is not found."" % (model_weight_path))\n\n        return loaded_model\n\n    @property\n    def src_graph(self):\n        return self.keras_graph\n\n\n    def __init__(self, model):\n        super(Keras2Parser, self).__init__()\n\n        # load model files into Keras graph\n        if isinstance(model, _string_types):\n            try:\n                # Keras 2.1.6\n                from keras.applications.mobilenet import relu6\n                from keras.applications.mobilenet import DepthwiseConv2D\n                model = _keras.models.load_model(\n                    model,\n                    custom_objects={\n                        \'relu6\': _keras.applications.mobilenet.relu6,\n                        \'DepthwiseConv2D\': _keras.applications.mobilenet.DepthwiseConv2D\n                    }\n                )\n            except:\n                # Keras. 2.2.2\n                import keras.layers as layers\n                model = _keras.models.load_model(\n                    model,\n                    custom_objects={\n                        \'relu6\': layers.ReLU(6, name=\'relu6\'),\n                        \'DepthwiseConv2D\': layers.DepthwiseConv2D\n                    }\n                )\n            self.weight_loaded = True\n\n        elif isinstance(model, tuple):\n            model = self._load_model(model[0], model[1])\n\n        else:\n            assert False\n\n        # _keras.utils.plot_model(model, ""model.png"", show_shapes = True)\n\n        # Build network graph\n        self.data_format = _keras.backend.image_data_format()\n        self.keras_graph = Keras2Graph(model)\n        self.keras_graph.build()\n        self.lambda_layer_count = 0\n\n\n    def gen_IR(self):\n        for layer in self.keras_graph.topological_sort:\n            current_node = self.keras_graph.get_node(layer)\n            node_type = current_node.type\n  \n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n            else:\n                print(""KerasParser has not supported operator [%s]."" % (node_type))\n                self.rename_UNKNOWN(current_node)\n\n        _K.clear_session()\n\n\n    @staticmethod\n    def _set_output_shape(source_node, IR_node):\n        shape = graph_pb2.TensorShape()\n        for dim in source_node.layer.output_shape:\n            new_dim = shape.dim.add()\n            new_dim.size = dim if dim else -1\n\n        IR_node.attr[""_output_shapes""].list.shape.extend([shape])\n\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op = None):\n        IR_node.name = source_node.name\n        IR_node.op = source_node.type if new_op == None else new_op\n\n        if hasattr(source_node.layer, ""dtype""):\n            IR_node.attr[""dtype""].type = Keras2Parser.dtype_map[source_node.layer.dtype]\n\n        Keras2Parser._set_output_shape(source_node, IR_node)\n\n\n    @staticmethod\n    def _copy_shape(source_node, target_node):\n        if hasattr(source_node, ""output_shape""):\n            for dim in source_node.output_shape:\n                new_dim = target_node.attr[""shape""].shape.dim.add()\n                new_dim.size = -1 if dim == None else dim\n\n        else:\n            target_node.attr[""shape""].shape.unknown_rank = True\n\n\n    @staticmethod\n    def _convert_dataformat(source_node, target_node):\n        if source_node.keras_layer.data_format == \'channels_last\':\n            target_node.attr[""data_format""].s = ""NHWC""\n        elif source_node.keras_layer.data_format == \'channels_first\':\n            target_node.attr[""data_format""].s = ""NCHW""\n        else:\n            print(""Warning: [%s] don\'t have data format info."" % (source_node.keras_layer.name))\n\n\n    @staticmethod\n    def _convert_padding(source_node, IR_node):\n        # TODO: Fused conv and pool with padding is different from defused operators\n        dims = len(source_node.layer.input_shape)\n        if source_node.layer.padding == \'valid\':\n            assign_IRnode_values(IR_node, {\'auto_pad\' : ""VALID"", \'pads\' : [0, 0] * dims})\n\n        elif source_node.layer.padding == \'same\':\n            kernel_shape = source_node.layer.kernel_size if hasattr(source_node.layer, \'kernel_size\') else source_node.layer.pool_size\n            padding = compute_tf_same_padding(\n                source_node.layer.input_shape,\n                kernel_shape,\n                list(source_node.layer.strides))\n            assign_IRnode_values(IR_node, {\'auto_pad\' : ""SAME_LOWER"", \'pads\' : padding})\n\n        else:\n            assert False\n\n\n    def _defuse_activation(self, source_node):\n        if source_node.layer.activation is None or source_node.layer.activation.__name__ == ""linear"":\n            return\n\n        IR_node = self.IR_graph.node.add()\n        IR_node.name = source_node.real_name + ""_activation""\n        IR_node.op = Keras2Parser.activation_map[source_node.layer.activation.__name__]\n        IR_node.input.append(source_node.real_name)\n        Keras2Parser._set_output_shape(source_node, IR_node)\n\n        # TODO: More activation functions\n        # for ELU\n        if hasattr(source_node.layer, \'alpha\'):\n            assign_attr_value(IR_node[\'alpha\'], source_node.layer.alpha)\n\n        source_node.real_name = IR_node.name\n\n\n    def _convert_convolution(self, source_node, dim):\n        IR_node = self.IR_graph.node.add()\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # name, op\n        if source_node.type.startswith(\'Separable\'):\n            Keras2Parser._copy_and_reop(source_node, IR_node, ""SeparableConv"")\n            if self.weight_loaded:\n                self.set_weight(source_node.name, \'depthwise_filter\', source_node.layer.get_weights()[0])\n                self.set_weight(source_node.name, \'pointwise_filter\', source_node.layer.get_weights()[1])\n\n        else:\n            if source_node.type.startswith(\'Conv\'):\n                if source_node.type.endswith(\'Transpose\'):\n                    Keras2Parser._copy_and_reop(source_node, IR_node, ""ConvTranspose"")\n                else:\n                    Keras2Parser._copy_and_reop(source_node, IR_node, ""Conv"")\n            elif source_node.type.startswith(\'Deconv\'):\n                Keras2Parser._copy_and_reop(source_node, IR_node, ""ConvTranspose"")\n\n            elif source_node.type.startswith(\'Depthwise\'):\n                Keras2Parser._copy_and_reop(source_node, IR_node, ""DepthwiseConv"")\n\n            else:\n                raise NotImplementedError(""Convolution layer [{}] is not supported."".format(source_node.type))\n\n            # weights\n            if self.weight_loaded:\n                self.set_weight(source_node.name, ""weights"", source_node.layer.get_weights()[0])\n                if source_node.layer.use_bias:\n                    self.set_weight(source_node.name, ""bias"", source_node.layer.get_weights()[1])\n\n        if isinstance(source_node.layer.kernel_size, int):\n            source_node.layer.kernel_size = (source_node.layer.kernel_size) * dim\n\n        if isinstance(source_node.layer.strides, int):\n            source_node.layer.strides = (source_node.layer.strides) * dim\n\n        if isinstance(source_node.layer.dilation_rate, int):\n            source_node.layer.dilation_rate = (source_node.layer.dilation_rate) * dim\n\n        kwargs = dict()\n\n        # pads\n        Keras2Parser._convert_padding(source_node, IR_node)\n\n        # filter\n        # [kd, kh, kw, channel_size, filter number]\n        in_channel = source_node.layer.input_shape[-1] if self.data_format == ""channels_last"" else source_node.layer.input_shape[1]\n        out_channel = source_node.layer.filters or source_node.layer.depth_multiplier\n\n        if source_node.type.startswith(""Deconv""):\n            kwargs[\'kernel_shape\'] = list(source_node.layer.kernel_size) + [out_channel, in_channel]\n        else:\n            kwargs[\'kernel_shape\'] = list(source_node.layer.kernel_size) + [in_channel, out_channel]\n\n        # use_bias\n        kwargs[\'use_bias\'] = source_node.keras_layer.use_bias\n\n        # strides\n        # [1, sd, sh, sw, 1]\n        kwargs[\'strides\'] = [1] + list(source_node.layer.strides) + [1]\n\n        # dilations\n        # [1, dd, dh, dw, 1]\n        kwargs[\'dilations\'] = [1] + list(source_node.layer.dilation_rate) + [1]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n        # activation\n        self._defuse_activation(source_node)\n\n\n    def _convert_pooling(self, source_node, dim, pooling_type, is_global):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node, ""Pool"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        kwargs = {}\n\n        kwargs[\'pooling_type\'] = pooling_type\n\n\n        if is_global:\n            kwargs[\'global_pooling\'] = True\n            kwargs[\'strides\'] = [1] * (dim + 2)\n        else:\n            if isinstance(source_node.layer.pool_size, int):\n                source_node.layer.pool_size = (source_node.layer.pool_size) * dim\n\n            if isinstance(source_node.layer.strides, int):\n                source_node.layer.strides = (source_node.layer.strides) * dim\n\n            # padding\n            self._convert_padding(source_node, IR_node)\n\n            # strides\n            # [1, sd, sh, sw, 1]\n            kwargs[\'strides\'] = [1] + list(source_node.layer.strides) + [1]\n\n            # window_shape\n            # [1, pd, ph, pw, 1]\n            kwargs[\'kernel_shape\'] = [1] + list(source_node.layer.pool_size) + [1]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n        if is_global:\n            flatten_node = self.IR_graph.node.add()\n            flatten_node.name = source_node.name + \'_flatten\'\n            flatten_node.op = \'Flatten\'\n            flatten_node.input.append(source_node.name)\n            Keras2Parser._set_output_shape(source_node, flatten_node)\n            source_node.real_name = flatten_node.name\n\n\n    def _convert_merge(self, source_node, new_name = None):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node, new_name)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # For concat axis\n        if hasattr(source_node.layer, \'axis\'):\n            axis = source_node.layer.axis\n            if int(axis) == -1:\n                axis = 3 if self.data_format == ""channels_last"" else 2\n            IR_node.attr[\'axis\'].i = axis\n\n        return IR_node\n\n\n    def _convert_padding_api(self, source_node, IR_node, mode):\n         # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node, ""Pad"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        kwargs = dict()\n        kwargs[\'mode\'] = mode\n\n        # padding\n        kwargs[\'pads\'] = [0, 0]\n        for padding_pair in source_node.layer.padding:\n            kwargs[\'pads\'].extend(padding_pair)\n        kwargs[\'pads\'] += [0, 0]\n        kwargs[\'pads\'] = convert_tf_pad_to_onnx(kwargs[\'pads\'])\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_UNKNOWN(self, source_node):\n        print (source_node.layer.get_config())\n\n        # only for training\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n\n    def rename_Activation(self, keras_node):\n        IR_node = self.IR_graph.node.add()\n        # name, op\n        try:\n            Keras2Parser._copy_and_reop(keras_node, IR_node, self.activation_map[keras_node.keras_layer.activation.__name__])\n        except:\n            Keras2Parser._copy_and_reop(keras_node, IR_node, self.activation_map[keras_node.keras_layer.activation.name])\n\n        # input edge\n        self.convert_inedge(keras_node, IR_node)\n\n\n    # Merge Layers\n    def rename_Add(self, source_node):\n        self._convert_merge(source_node)\n\n\n    def rename_Conv1D(self, source_node):\n        self._convert_convolution(source_node, 1)\n\n    def rename_Conv1DTranspose(self, source_node):\n        self._convert_convolution(source_node, 1)\n\n    def rename_Conv2D(self, source_node):\n        self._convert_convolution(source_node, 2)\n\n    def rename_Conv2DTranspose(self, source_node):\n        self._convert_convolution(source_node, 2)\n\n    def rename_Conv3D(self, source_node):\n        self._convert_convolution(source_node, 3)\n\n    def rename_Conv3DTranspose(self, source_node):\n        self._convert_convolution(source_node, 3)\n\n    def rename_InputLayer(self, source_node):\n        # only for training\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node, ""DataInput"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # shape\n        Keras2Parser._copy_shape(source_node.keras_layer, IR_node)\n\n\n\n    def rename_GlobalMaxPooling1D(self, source_node):\n        self._convert_pooling(source_node, 1, ""MAX"", True)\n\n\n    def rename_GlobalMaxPooling2D(self, source_node):\n        self._convert_pooling(source_node, 2, ""MAX"", True)\n\n\n    def rename_GlobalMaxPooling3D(self, source_node):\n        self._convert_pooling(source_node, 3, ""MAX"", True)\n\n\n    def rename_GlobalAveragePooling1D(self, source_node):\n        self._convert_pooling(source_node, 1, ""AVG"", True)\n\n\n    def rename_GlobalAveragePooling2D(self, source_node):\n        self._convert_pooling(source_node, 2, ""AVG"", True)\n\n\n    def rename_GlobalAveragePooling3D(self, source_node):\n        self._convert_pooling(source_node, 3, ""AVG"", True)\n\n\n    def rename_MaxPooling1D(self, source_node):\n        self._convert_pooling(source_node, 1, ""MAX"", False)\n\n\n    def rename_MaxPooling2D(self, source_node):\n        self._convert_pooling(source_node, 2, ""MAX"", False)\n\n\n    def rename_MaxPooling3D(self, source_node):\n        self._convert_pooling(source_node, 3, ""MAX"", False)\n\n\n    def rename_AveragePooling1D(self, source_node):\n        self._convert_pooling(source_node, 1, ""AVG"", False)\n\n\n    def rename_AveragePooling2D(self, source_node):\n        self._convert_pooling(source_node, 2, ""AVG"", False)\n\n\n    def rename_AveragePooling3D(self, source_node):\n        self._convert_pooling(source_node, 3, ""AVG"", False)\n\n\n    def rename_Dropout(self, source_node):\n        # only for training\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        IR_node.attr[""keep_prob""].f = source_node.keras_layer.rate\n        if source_node.keras_layer.seed != None:\n            IR_node.attr[""seed""].i = source_node.keras_layer.seed\n\n\n    # Core Layers\n    def rename_Dense(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node, ""FullyConnected"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # units\n        IR_node.attr[""units""].i = source_node.keras_layer.units\n\n        # use_bias\n        IR_node.attr[""use_bias""].b = source_node.keras_layer.use_bias\n\n        # weights\n        if self.weight_loaded == True:\n            self.set_weight(source_node.name, \'weights\', source_node.layer.get_weights()[0])\n            if IR_node.attr[""use_bias""].b == True:\n                self.set_weight(source_node.name, \'bias\', source_node.layer.get_weights()[1])\n\n        # activation\n        self._defuse_activation(source_node)\n\n\n    def rename_Flatten(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n    def rename_UpSampling2D(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # size\n        IR_node.attr[""scales""].list.i.extend(source_node.keras_layer.size)\n\n\n    def rename_Embedding(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # input_dim\n        IR_node.attr[""input_dim""].i = source_node.keras_layer.input_dim\n\n        # output_dim\n        IR_node.attr[""output_dim""].i = source_node.keras_layer.output_dim\n\n        # mask_zero\n        IR_node.attr[""mask_zero""].b = source_node.keras_layer.mask_zero\n\n        # weights\n        if self.weight_loaded:\n            self.set_weight(source_node.name, \'embedding_weights\', source_node.layer.get_weights()[0])\n\n\n    def rename_LSTM(self, keras_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(keras_node, IR_node)\n\n        # input edge\n        self.convert_inedge(keras_node, IR_node)\n\n        # units\n        IR_node.attr[""units""].i = keras_node.keras_layer.units\n\n        # use_bias\n        IR_node.attr[""use_bias""].b = keras_node.keras_layer.use_bias\n\n        # for Keras, drop_out and recurrent_dropout\n        IR_node.attr[""dropout""].f = keras_node.keras_layer.dropout\n        IR_node.attr[""recurrent_dropout""].f = keras_node.keras_layer.recurrent_dropout\n\n        # activation\n        self._defuse_activation(keras_node)\n\n\n    def rename_GRU(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # units\n        IR_node.attr[""units""].i = source_node.keras_layer.units\n\n        # activation\n        self._defuse_activation(source_node)\n\n        # weights\n        if self.weight_loaded:\n            self.set_weight(source_node.name, \'gru_weights\', source_node.layer.get_weights()[0])\n            self.set_weight(source_node.name, \'gru_recurrent_weights\', source_node.layer.get_weights()[1])\n            if source_node.layer.use_bias:\n                self.set_weight(source_node.name, ""gru_bias"", source_node.layer.get_weights()[2])\n\n\n    def rename_Multiply(self, source_node):\n        self._convert_merge(source_node, \'Mul\')\n\n\n    def rename_Average(self, source_node):\n        # Kit TODO : need to search the tf\n        self._convert_merge(source_node, \'Avg\')\n\n\n    def rename_Maximum(self, source_node):\n        self._convert_merge(source_node)\n\n\n    def rename_Concatenate(self, source_node):\n        IR_node = self._convert_merge(source_node, \'Concat\')\n\n\n    def rename_Reshape(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node, \'Reshape\')\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # for target shape\n        IR_node.attr[""shape""].list.i.append(-1)\n        IR_node.attr[""shape""].list.i.extend(source_node.layer.target_shape)\n\n\n    def rename_Lambda(self, source_node):\n        node_type = source_node.layer.name\n        if hasattr(self, ""rename_"" + node_type):\n            print (""Try to convert Lambda function [{}]"".format(source_node.layer.name))\n            func = getattr(self, ""rename_"" + node_type)\n            func(source_node)\n        else:\n            raise NotImplementedError(""Lambda layer [{}] in keras is not supported yet."".format(node_type))\n\n\n    def rename_BatchNormalization(self, keras_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(keras_node, IR_node, \'BatchNorm\')\n\n        # input edge\n        self.convert_inedge(keras_node, IR_node)\n\n        # axis\n        IR_node.attr[\'axis\'].i = keras_node.keras_layer.axis\n\n        IR_node.attr[\'scale\'].b = keras_node.keras_layer.scale\n\n        IR_node.attr[\'bias\'].b = keras_node.keras_layer.center\n\n        IR_node.attr[\'epsilon\'].f = keras_node.layer.epsilon\n\n        if self.weight_loaded:\n            # Parameter arrangement in Keras: gamma, beta, mean, variance\n            idx = 0\n\n            # scale\n            if IR_node.attr[\'scale\'].b:\n                self.set_weight(keras_node.name, ""scale"", keras_node.layer.get_weights()[idx])\n                idx += 1\n\n            # beta\n            if IR_node.attr[\'bias\'].b:\n                self.set_weight(keras_node.name, ""bias"", keras_node.layer.get_weights()[idx])\n                idx += 1\n\n            # mean\n            self.set_weight(keras_node.name, ""mean"", keras_node.layer.get_weights()[idx])\n\n            # var\n            self.set_weight(keras_node.name, ""var"", keras_node.layer.get_weights()[idx + 1])\n\n\n    def rename_ZeroPadding2D(self, keras_node):\n        IR_node = self.IR_graph.node.add()\n        self._convert_padding_api(keras_node, IR_node, ""constant"")\n\n\n    def rename_SeparableConv2D(self, source_node):\n        self._convert_convolution(source_node, 2)\n\n\n    def rename_DepthwiseConv2D(self, source_node):\n        self._convert_convolution(source_node, 2)\n\n\n    def custom_relu6(x):\n        return _keras.relu(x, max_value=6)\n\n\n    def _convert_crop(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        Keras2Parser._copy_and_reop(source_node, IR_node, ""Crop"")\n\n        self.convert_inedge(source_node, IR_node)\n\n        border = []\n        for i in source_node.layer.cropping:\n            for j in i:\n                border.append(j)\n\n        assign_IRnode_values(IR_node, {\'border\' : border})\n\n\n\n    def rename_Cropping1D(self, source_node):\n        self._convert_crop(source_node)\n\n\n    def rename_Cropping2D(self, source_node):\n        self._convert_crop(source_node)\n\n\n    def rename_Cropping3D(self, source_node):\n        self._convert_crop(source_node)\n\n\n    def rename_LeakyReLU(self, source_node):\n        IR_node = self.IR_graph.node.add()\n        Keras2Parser._copy_and_reop(source_node, IR_node, \'LeakyRelu\')\n        self.convert_inedge(source_node, IR_node)\n        assign_IRnode_values(IR_node, {\'alpha\' : source_node.layer.alpha.tolist()})\n\n\n    def rename_ReLU(self, source_node):\n        IR_node = self.IR_graph.node.add()\n        max_value = source_node.layer.max_value\n        if max_value == 6.0:\n            Keras2Parser._copy_and_reop(source_node, IR_node, \'Relu6\')\n        else:\n            Keras2Parser._copy_and_reop(source_node, IR_node, \'Relu\')\n\n        assign_IRnode_values(IR_node, {\'max_value\' : max_value})\n        self.convert_inedge(source_node, IR_node)\n\n\n    def rename_space_to_depth_x2(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        Keras2Parser._copy_and_reop(source_node, IR_node, \'SpaceToDepth\')\n        IR_node.name = ""Lambda_{}"".format(self.lambda_layer_count)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # for target shape\n        IR_node.attr[""blocksize""].i = 2\n        self.lambda_layer_count = self.lambda_layer_count + 1\n        source_node.real_name = IR_node.name\n'"
mmdnn/conversion/keras/saver.py,0,"b""def save_model(MainModel, network_filepath, weight_filepath, dump_filepath):\n    model = MainModel.KitModel(weight_filepath)\n    model.save(dump_filepath)\n    print('Keras model file is saved as [{}], generated by [{}.py] and [{}].'.format(\n        dump_filepath, network_filepath, weight_filepath))\n"""
mmdnn/conversion/mxnet/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/mxnet/mxnet_emitter.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\n\nimport math\nimport mxnet as mx\nimport numpy as np\nfrom mmdnn.conversion.common.IR.IR_graph import IRGraph, IRGraphNode\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.emitter import Emitter\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.rewriter.folder import Folder\n\nclass MXNetEmitter(Emitter):\n\n    dtype_map = {\n        graph_pb2.DT_FLOAT16    : ""float16"",\n        graph_pb2.DT_FLOAT32    : ""float32"",\n        graph_pb2.DT_FLOAT64    : ""float64"",\n        graph_pb2.DT_INT32      : ""int32"",\n        graph_pb2.DT_UINT8      : ""uint8""\n    }\n\n    activation_map = {\n        ""relu""      : ""Relu"",\n        ""sigmoid""   : ""Sigmoid"",\n        ""tanh""      : ""Tanh"",\n        ""elu""       : ""Elu""\n    }\n\n    transpose_map = {\n        1 : 2,\n        2 : 3,\n       -1 : 1\n    }\n\n    naive_scope_pattern = []\n\n    channels_last = [\'NDHWC\', \'NHWC\']\n\n    def __init__(self, model):\n        super(MXNetEmitter, self).__init__()\n        from six import string_types as _string_types\n\n        if isinstance(model, _string_types):\n            network_path = model\n            self.weight_loaded = False\n        elif len(model) == 3:\n            network_path = model[0]\n            weight_path = model[1]\n            self.output_weights_file = model[2]\n            self.output_weights = dict()\n            self._load_weights(weight_path)\n            self.weights = self.weights_dict\n        else:\n            raise ValueError(""the # of input arguments [{}] is not supported"" % len(model))\n\n        self.IR_graph = IRGraph(network_path)\n        self.IR_graph.build()\n\n        folder = Folder(self.IR_graph, self.weights)\n        folder.fold()\n\n    @property\n    def header_code(self):\n        return """"""import mxnet as mx\nimport numpy as np\nimport math\n\n# mxnet-cpu only support channel first, default convert the model and weight as channel first\n\ndef RefactorModel():\n""""""\n\n\n    def gen_code(self, phase):\n        self.IR_layer_map = dict()\n        self.add_body(0, self.header_code)\n        for layer in self.IR_graph.topological_sort:\n            self.IR_layer_map[layer] = self.IR_graph.get_node(layer)\n\n        shape = dict()\n        for layer in self.IR_graph.topological_sort:\n            current_node = self.IR_graph.get_node(layer)\n            node_type = current_node.type\n\n\n            if len(current_node.in_edges) == 0:\n                current_node.in_edges.append(\'data\')\n\n            if node_type.lower() in MXNetEmitter.activation_map:\n                func = getattr(self, ""emit_Activation"")\n                line = func(current_node, MXNetEmitter.activation_map[node_type.lower()].lower())\n                self.add_body(1, line)\n\n            elif hasattr(self, ""emit_"" + node_type):\n                func = getattr(self, ""emit_"" + node_type)\n                line = func(current_node)\n                if line != None:\n                    self.add_body(1, line)\n            else:\n                print(""MXNet Emitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(current_node)\n\n            if node_type == ""DataInput"":\n                cur_shape = list()\n                first = True\n                for dim in current_node.IR_layer.attr[""shape""].shape.dim:\n                    if dim.size == -1 and first:\n                        cur_shape.append(1)\n                        print(""Detect input layer [{}] using infer batch size, set it as default value [1]"".format(current_node.name))\n                    else:\n                        if dim.size == -1:\n                            print(""Warning: user should change input size manually"")\n                        cur_shape.append(dim.size)\n                    first = False\n\n                cur_shape.insert(1, cur_shape.pop())\n                shape[current_node.name] = \', \'.join(\'%s\' % i for i in cur_shape)\n                self.input_name_shape = {current_node.name: tuple(cur_shape)}\n\n\n        if self.weight_loaded:\n            fullpath = os.path.abspath(self.output_weights_file)\n            dirname = os.path.dirname(fullpath)\n            if not os.path.exists(dirname):\n                os.makedirs(dirname)\n            with open(self.output_weights_file, \'wb\') as outfile:\n                np.save(outfile, self.output_weights)\n\n        comment = ""\\n    # if a GPU is available, change mx.cpu() to mx.gpu()""\n        # We use the real_name for specifying the input layer in data_names\n        # since MXNet API wants the actual name of the layer. On the other\n        # hand, the module API wants the last symbol in the symbol chain, so\n        # for the output node we need to use the actual python variable name\n        # of the last layer (real_variable_name).\n        last_line = ""{:<15} = mx.mod.Module(symbol = {}, context = mx.cpu(), data_names = [\'{}\'])"".format(\n            ""model"",\n            \', \'.join([self.IR_graph.get_node(name).real_variable_name for name in self.IR_graph.output_layers if self.IR_graph.get_node(name).type !=\'Pack\' and self.IR_graph.get_node(name).type != \'Shape\']),\n            \', \'.join([self.IR_graph.get_node(name).real_name for name in self.IR_graph.input_layers if self.IR_graph.get_node(name).type != \'Const\']))\n\n        self.add_body(1, comment)\n        self.add_body(1, last_line)\n        self.add_body(1, ""return model"")\n\n\n        self.add_body(0, """")\n        for code in self.layers_codes.values():\n            self.add_body(0, code)\n\n        weight_code = """"\n        if not self.weight_loaded:\n            weight_code += ""# emitter does not detect any import weights, you may generate weights file manually\\n""\n\n        weight_code += self.gen_weight_code(shape, phase)\n\n        main_code = ""if __name__ == \'__main__\':\\n    model = RefactorModel()\\n""\n        if self.weight_loaded:\n            main_code += ""    # remember to adjust params path\\n    model = deploy_weight(model, \'{}\')\\n"".format(self.output_weights_file)\n\n        if phase == \'train\':\n            train_code = """"""def train(model):\n    import logging\n    logging.getLogger().setLevel(logging.DEBUG)\n    model.fit(train_iter, # train data\n            eval_data = val_iter, # validation data\n            optimizer = \'sgd\', # Defaults to \'sgd\'\n            optimizer_params = {\'learning_rate\':0.01}, # use fixed learning rate\n            eval_metric = \'acc\', # report accuracy during training, other possible predefined metrics are: \'ce\', \'f1\', \'mae\', \'mse\', \'rmse\', \'top_k_accuracy\'\n            batch_end_callback = mx.callback.Speedometer(batch_size, 100), # output progress for each 100 data batches\n            num_epoch = 10) # train for at most 10 dataset passes\\n\\n\n""""""\n            code = self.body_code + weight_code + train_code + main_code\n        else:\n            test_code = """"""from collections import namedtuple\nBatch = namedtuple(\'Batch\', [\'data\'])\n\n\ndef get_image(url, show=False):\n    import cv2\n    # download and show the image\n    fname = mx.test_utils.download(url)\n    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n    if img is None:\n        return None\n    if show:\n        import matplotlib.pyplot as plt\n        plt.imshow(img)\n        plt.axis(\'off\')\n    # convert into format (batch, RGB, width, height)\n    img = cv2.resize(img, (224, 224))\n    img = np.swapaxes(img, 0, 2)\n    img = np.swapaxes(img, 1, 2)\n    img = img[np.newaxis, :]\n    return img\n\n\ndef predict(model, labels, url):\n    # to show the image, change the argument show into True\n    img = get_image(url, show = False)\n    # compute the predict probabilities\n    model.forward(Batch([mx.nd.array(img)]))\n    prob = model.get_outputs()[0].asnumpy()\n    # print the top-5\n    prob = np.squeeze(prob)\n    a = np.argsort(prob)[::-1]\n    for i in a[0:5]:\n        print(\'prbability = %f, class = %s\' %(prob[i], labels[i]))\\n\\n\n""""""\n\n            main_code += """"""\n    # # call function predict\n    # with open(\'synset.txt\', \'r\') as f:\n    #     labels = [l.rstrip() for l in f]\n    # predict(model, labels, \'http://writm.com/wp-content/uploads/2016/08/Cat-hd-wallpapers.jpg\')\n""""""\n\n            code = self.body_code + weight_code + test_code + main_code\n\n        return code\n\n\n    def gen_weight_code(self, shape, phase):\n        str = ""def deploy_weight(model, weight_file):\\n""\n        str += """"""\n    if weight_file == None:\n        return\n\n    try:\n        weights_dict = np.load(weight_file, allow_pickle=True).item()\n    except:\n        weights_dict = np.load(weight_file, allow_pickle=True, encoding=\'bytes\').item()\n\n    arg_params = dict()\n    aux_params = dict()\n    for weight_name, weight_data in weights_dict.items():\n        weight_name = str(weight_name)\n        if ""moving"" in weight_name:\n            aux_params[weight_name] = mx.nd.array(weight_data)\n        else:\n            arg_params[weight_name] = mx.nd.array(weight_data)\n\n""""""\n        if phase == \'train\':\n            str += ""    model.bind(for_training = True, data_shapes = [""\n        else:\n            str += ""    model.bind(for_training = False, data_shapes = [""\n        first = True\n        for k, v in shape.items():\n            if not first:\n                str += "", ""\n            str += ""(\'"" + k + ""\', "" + ""("" + v + ""))""\n            first = False\n        str += ""])\\n""\n        str += ""    model.set_params(arg_params = arg_params, aux_params = aux_params, allow_missing = True, allow_extra=True)\\n\\n    return model\\n\\n\\n""\n        return str\n\n\n    @staticmethod\n    def calculate_same_pad(data_shape, kernel, stride):\n        if (data_shape % stride == 0):\n            pad = max(kernel - stride, 0)\n        else:\n            pad = max(kernel - (data_shape % stride), 0)\n        if pad % 2 == 0:\n            return False, pad\n        else:\n            return True, pad\n\n\n    @staticmethod\n    def transfer_pad(pad_list):\n        defuse_pad = False\n        pad = list()\n\n        assert len(pad_list) % 2 == 0\n        mid = int(len(pad_list)/2)\n        pad_first = pad_list[1:mid-1]\n        pad_second = pad_list[mid+1:-1]\n\n        for i in range(0, mid-2):\n            if not pad_first[i] == pad_second[i]:\n                defuse_pad = True\n\n        if defuse_pad:\n            pad.extend([0] * 4)\n            for i in range(0, mid-2):\n                pad.extend([pad_first[i], pad_second[i]])\n        else:\n            pad = pad_first\n\n        return defuse_pad, pad\n\n\n    @staticmethod\n    def transpose(data, dim):\n        if dim == 1:\n            data = data.transpose((2, 1, 0))\n        elif dim == 2:\n            data = data.transpose((3, 2, 0, 1))\n        elif dim == 3:\n            data = data.transpose((4, 3, 0, 1, 2))\n        else:\n            raise ValueError(""The weight of dim {} cannot transpose"" % dim)\n\n        return data\n\n\n    def set_pad(self, IR_node, code, pad, _max_pool):\n        if _max_pool:\n            constant_value = ""float(\'-inf\')""\n        else:\n            constant_value = ""0.0""\n\n        code = ""{:<15} = mx.sym.pad(data = {}, mode = \'constant\', pad_width={}, constant_value = {}, name = \'{}\')"".format(\n                IR_node.variable_name + ""_pad"",\n                self.parent_variable_name(IR_node),\n                tuple(pad),\n                constant_value,\n                IR_node.name + ""_pad"")\n\n        for e in IR_node.in_edges:\n            e = e.split(\':\')[0]\n            if e == \'data\':\n                continue\n            self.IR_layer_map[e].out_edges = [x if not self.IR_layer_map[x.split(\':\')[0]].name == IR_node.variable_name else IR_node.variable_name + ""_pad"" for x in self.IR_layer_map[e].out_edges]\n\n        return code\n\n\n    def emit_UNKNOWN(self, IR_node):\n        print(IR_node.name)\n\n\n    def emit_FullyConnected(self, IR_node):\n        if self.weight_loaded:\n            weight_dict = self.weights[IR_node.name]\n            parent = self.IR_graph.get_parent(IR_node.name, [0])\n            while parent.type == ""Flatten"" or parent.type == \'Dropout\':\n                parent = self.IR_graph.get_parent(parent.name, [0])\n            dim = len(parent.layer.attr[\'_output_shapes\'].list.shape[0].dim)\n            if dim > 2:\n                original_dims = weight_dict[\'weights\'].shape\n                dims = [i.size for i in parent.layer.attr[\'_output_shapes\'].list.shape[0].dim[1:]] + [-1]\n                weight_dict[\'weights\'] = np.reshape(weight_dict[\'weights\'], dims)\n                weight_dict[\'weights\'] = np.transpose(weight_dict[\'weights\'], [dim - 2] + list(range(0, dim - 2)) + [dim - 1])\n                weight_dict[\'weights\'] = np.reshape(weight_dict[\'weights\'], original_dims)\n            self.output_weights[IR_node.name + ""_weight""] = weight_dict[\'weights\'].transpose((1, 0))\n\n        num_hidden = IR_node.IR_layer.attr[""units""].i\n        no_bias = not IR_node.IR_layer.attr[""use_bias""].b\n        if not no_bias and self.weight_loaded:\n            self.output_weights[IR_node.name + ""_bias""] = weight_dict[\'bias\']\n\n        code = ""{:<15} = mx.sym.FullyConnected(data = {}, num_hidden = {}, no_bias = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                num_hidden,\n                no_bias,\n                IR_node.name)\n\n        return code\n\n\n    def _emit_convolution(self, IR_node, pattern):\n        if self.weight_loaded:\n            weight_dict = self.weights[IR_node.name]\n            weights = weight_dict[\'weights\']\n\n        dim = len(IR_node.IR_layer.attr[""kernel_shape""].list.i) - 2\n\n        kernel = list()\n        for idx in range(0, dim):\n            kernel.append(IR_node.IR_layer.attr[""kernel_shape""].list.i[idx])\n\n        stride = list()\n        for e in IR_node.IR_layer.attr[""strides""].list.i[1:-1]:\n            stride.append(e)\n\n        dilate = list()\n        for e in IR_node.IR_layer.attr[""dilations""].list.i[1:-1]:\n            dilate.append(e)\n        if dilate == []: dilate = [1, 1]\n        dilate = \', \'.join(\'%s\' % i for i in dilate)\n\n        defuse_pad = False\n        pad = list()\n        if ""pads"" in IR_node.IR_layer.attr:\n            output_shape = list()\n            for e in IR_node.IR_layer.attr[""_output_shapes""].list.shape[0].dim:\n                output_shape.append(e.size)\n\n            # print(""Warning: MXNet Convolution Layer pad does not match IR Convolution Layer pad"")\n            defuse_pad, pad = MXNetEmitter.transfer_pad(IR_node.IR_layer.attr[""pads""].list.i)\n\n        num_filter = 0\n        if pattern == ""Deconvolution"":\n            num_filter = IR_node.IR_layer.attr[""kernel_shape""].list.i[-2]\n        else:\n            num_filter = IR_node.IR_layer.attr[""kernel_shape""].list.i[-1]\n\n        use_bias = IR_node.get_attr(\'use_bias\', False)\n        if use_bias and self.weight_loaded:\n            self.output_weights[IR_node.name + ""_bias""] = weight_dict[\'bias\']\n\n        if pattern == ""DepthwiseConv"":\n            num_group = IR_node.IR_layer.attr[""kernel_shape""].list.i[-2]\n            num_filter = num_filter * num_group\n            pattern = ""Convolution""\n            if self.weight_loaded:\n                weights = np.swapaxes(weights, -1, -2)\n\n        else:\n            num_group = IR_node.get_attr(\'group\', 1)\n\n        # layout = IR_node.IR_layer.attr[""data_format""].s\n        if dim == 1:\n            layout = \'NCW\'\n        elif dim == 2:\n            layout = \'NCHW\'\n        elif dim == 3:\n            layout = \'NCDHW\'\n\n        if self.weight_loaded:\n            # if layout not in MXNetEmitter.channels_last:\n            weights = MXNetEmitter.transpose(weights, dim)\n            self.output_weights[IR_node.name + ""_weight""] = weights\n\n        code = """"\n        if not defuse_pad:\n            code += ""{:<15} = mx.sym.{}(data={}, kernel={}, stride={}, dilate = ({}), pad={}, num_filter = {}, num_group = {}, no_bias = {}, layout = \'{}\', name = \'{}\')"".format(\n                IR_node.variable_name,\n                pattern,\n                self.parent_variable_name(IR_node),\n                tuple(kernel),\n                tuple(stride),\n                dilate,\n                tuple(pad),\n                num_filter,\n                num_group,\n                not use_bias,\n                layout,\n                IR_node.name)\n        else:\n            code += self.set_pad(IR_node, code, pad, False)\n            code += ""\\n    {:<15} = mx.sym.{}(data={}, kernel={}, stride={}, dilate = ({}), num_filter = {}, num_group = {}, no_bias = {}, layout = \'{}\', name = \'{}\')"".format(\n                IR_node.variable_name,\n                pattern,\n                IR_node.variable_name + ""_pad"",\n                tuple(kernel),\n                tuple(stride),\n                dilate,\n                num_filter,\n                num_group,\n                not use_bias,\n                layout,\n                IR_node.name)\n\n        return code\n\n\n    def emit_Conv(self, IR_node):\n        return self._emit_convolution(IR_node, ""Convolution"")\n\n\n    def emit_DepthwiseConv(self, IR_node):\n        return self._emit_convolution(IR_node, ""DepthwiseConv"")\n\n\n    def emit_ConvTranspose(self, IR_node):\n        return self._emit_convolution(IR_node, ""Deconvolution"")\n\n\n    def emit_DataInput(self, IR_node):\n        shape = list()\n        shape.extend(IR_node.IR_layer.attr[""shape""].list.i)\n\n        code = ""{:<15} = mx.sym.var(\'{}\')"".format(IR_node.variable_name, IR_node.name)\n        return code\n\n\n    # Add LeakyReLU Elu(slope not support)\n    def emit_Activation(self, IR_node, act_type):\n\n        act_type = act_type\n        func_name = """"\n\n        if act_type == ""elu"":\n            func_name = ""LeakyReLU""\n        else:\n            func_name = ""Activation""\n\n        code = ""{:<15} = mx.sym.{}(data = {}, act_type = \'{}\', name = \'{}\')"".format(\n                IR_node.variable_name,\n                func_name,\n                self.parent_variable_name(IR_node),\n                act_type,\n                IR_node.name)\n\n        return code\n\n\n    def emit_BatchNorm(self, IR_node):\n        IR_node_after = self.IR_graph.get_son(IR_node.name, [0])\n        if IR_node_after.type == \'Scale\':\n            if self.weight_loaded:\n                weight_dict = self.weights[IR_node.name]\n                weight_dict_scale = self.weights[IR_node_after.name]\n\n            # axis = IR_node.IR_layer.attr[""axis""].i\n            axis = 1\n            eps = IR_node.IR_layer.attr[""epsilon""].f\n            momentum = IR_node.IR_layer.attr[""momentum""].f\n\n            fix_gamma = not IR_node.IR_layer.attr[""scale""].b\n\n            if self.weight_loaded:\n                if not fix_gamma:\n                #     self.output_weights[IR_node.name + ""_gamma""] = np.multiply(weight_dict[\'scale\'], weight_dict_scale[\'scale\'])\n                # self.output_weights[IR_node.name + ""_beta""] = np.multiply(weight_dict[\'bias\'], weight_dict_scale[\'scale\']) + weight_dict_scale[\'bias\']\n                    self.output_weights[IR_node.name + ""_gamma""] = weight_dict[\'scale\']\n                self.output_weights[IR_node.name + ""_beta""] = weight_dict[\'bias\']\n\n            # not supported yet\n            use_global_stats = ""False""\n            if self.weight_loaded:\n                self.output_weights[IR_node.name + ""_moving_var""] = weight_dict[\'var\']\n                self.output_weights[IR_node.name + ""_moving_mean""] = weight_dict[\'mean\']\n\n            code = ""{:<15} = mx.sym.BatchNorm(data = {}, axis = {}, eps = {}, momentum = {}, fix_gamma = {}, use_global_stats = {}, name = \'{}\')"".format(\n                    IR_node.variable_name,\n                    self.parent_variable_name(IR_node),\n                    axis,\n                    eps,\n                    momentum,\n                    fix_gamma,\n                    use_global_stats,\n                    IR_node.name)\n\n            return code\n\n        else:\n            if self.weight_loaded:\n                weight_dict = self.weights[IR_node.name]\n\n            # axis = IR_node.IR_layer.attr[""axis""].i\n            axis = 1\n            eps = IR_node.IR_layer.attr[""epsilon""].f\n            momentum = IR_node.IR_layer.attr[""momentum""].f\n\n            fix_gamma = not IR_node.IR_layer.attr[""scale""].b\n\n            if self.weight_loaded:\n                if not fix_gamma:\n                    self.output_weights[IR_node.name + ""_gamma""] = weight_dict[\'scale\']\n                self.output_weights[IR_node.name + ""_beta""] = weight_dict[\'bias\']\n\n            # not supported yet\n            use_global_stats = ""False""\n            if self.weight_loaded:\n                self.output_weights[IR_node.name + ""_moving_var""] = weight_dict[\'var\']\n                self.output_weights[IR_node.name + ""_moving_mean""] = weight_dict[\'mean\']\n\n            code = ""{:<15} = mx.sym.BatchNorm(data = {}, axis = {}, eps = {}, momentum = {}, fix_gamma = {}, use_global_stats = {}, name = \'{}\')"".format(\n                    IR_node.variable_name,\n                    self.parent_variable_name(IR_node),\n                    axis,\n                    eps,\n                    momentum,\n                    fix_gamma,\n                    use_global_stats,\n                    IR_node.name)\n\n            return code\n\n    def emit_Scale(self, IR_node):\n        if self.weight_loaded:\n            weight_dict = self.weights[IR_node.name]\n\n        # axis = IR_node.IR_layer.attr[""axis""].i\n        axis = 1\n        eps = 0.0\n        momentum = 0.0\n\n        fix_gamma = not IR_node.IR_layer.attr[""scale""].b\n\n        if self.weight_loaded:\n            if not fix_gamma:\n                self.output_weights[IR_node.name + ""_gamma""] = weight_dict[\'scale\']\n            self.output_weights[IR_node.name + ""_beta""] = weight_dict[\'bias\']\n\n        # not supported yet\n        use_global_stats = ""False""\n        if self.weight_loaded:\n            self.output_weights[IR_node.name + ""_moving_var""] = weight_dict[\'scale_var\']\n            self.output_weights[IR_node.name + ""_moving_mean""] = weight_dict[\'scale_mean\']\n\n        code = ""{:<15} = mx.sym.BatchNorm(data = {}, axis = {}, eps = {}, momentum = {}, fix_gamma = {}, use_global_stats = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                axis,\n                eps,\n                momentum,\n                fix_gamma,\n                use_global_stats,\n                IR_node.name)\n\n        return code\n\n\n\n    def emit_Pool(self, IR_node):\n\n        global_pool = IR_node.IR_layer.attr[""global_pooling""].b\n\n        kernel = list()\n        if global_pool:\n            kernel = [1] * (len(IR_node.IR_layer.attr[""strides""].list.i) - 2)\n        else:\n            for e in IR_node.IR_layer.attr[""kernel_shape""].list.i[1:-1]:\n                kernel.append(e)\n\n        pool_type = IR_node.get_attr(\'pooling_type\').lower()\n\n        stride = list()\n        for e in IR_node.IR_layer.attr[""strides""].list.i[1:-1]:\n            stride.append(e)\n\n        defuse_pad = False\n        pad = list()\n        if ""pads"" in IR_node.IR_layer.attr:\n            output_shape = list()\n            for e in IR_node.IR_layer.attr[""_output_shapes""].list.shape[0].dim:\n                output_shape.append(e.size)\n\n            # print(""Warning: MXNet Pooling Layer pad does not match IR Pooling Layer pad"")\n            defuse_pad, pad = MXNetEmitter.transfer_pad(IR_node.IR_layer.attr[""pads""].list.i)\n        code = """"\n        if not defuse_pad:\n            code += ""{:<15} = mx.sym.Pooling(data = {}, global_pool = {}, kernel={}, pool_type = \'{}\', stride={}, pad={}, name = \'{}\')"".format(\n                    IR_node.variable_name,\n                    self.parent_variable_name(IR_node),\n                    global_pool,\n                    tuple(kernel),\n                    pool_type,\n                    tuple(stride),\n                    tuple(pad),\n                    IR_node.name)\n        else:\n            code += self.set_pad(IR_node, code, pad, pool_type == ""max"")\n            code += ""\\n    {:<15} = mx.sym.Pooling(data = {}, global_pool = {}, kernel={}, pool_type = \'{}\', stride={}, name = \'{}\')"".format(\n                    IR_node.variable_name,\n                    IR_node.variable_name + ""_pad"",\n                    global_pool,\n                    tuple(kernel),\n                    pool_type,\n                    tuple(stride),\n                    IR_node.name)\n\n        return code\n\n\n    def emit_SoftmaxOutput(self, IR_node):\n\n        code = ""{:<15} = mx.sym.SoftmaxOutput(data = {}, name = \'softmax\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)\n        )\n\n        return code\n\n\n    def emit_Softmax(self, IR_node):\n\n        code = """"\n\n        if len(IR_node.out_edges) == 0:\n            code = ""{:<15} = mx.sym.SoftmaxOutput(data = {}, name = \'softmax\')"".format(\n                    IR_node.variable_name,\n                    self.parent_variable_name(IR_node))\n        else:\n            axis = IR_node.IR_layer.attr[""dim""].i\n            code = ""{:<15} = mx.sym.softmax(data = {}, axis = {}, name = \'{}\')"".format(\n                    IR_node.variable_name,\n                    self.parent_variable_name(IR_node),\n                    axis,\n                    IR_node.name)\n\n        return code\n\n\n    def emit_Squeeze(self, IR_node):\n        return self.emit_Flatten(IR_node)\n\n\n    # def emit_ConvTranspose(self, IR_node):\n    #     if self.weight_loaded:\n    #         weight_dict = self.weights[IR_node.name]\n    #         weights = weight_dict[\'weights\']\n\n    #     dim = len(IR_node.IR_layer.attr[""kernel_shape""].list.i) - 2\n\n    #     kernel = list()\n    #     for idx in range(0, dim):\n    #         kernel.append(IR_node.IR_layer.attr[""kernel_shape""].list.i[idx])\n\n    #     stride = list()\n    #     for e in IR_node.IR_layer.attr[""strides""].list.i[1:-1]:\n    #         stride.append(e)\n\n    #     dilate = list()\n    #     for e in IR_node.IR_layer.attr[""dilations""].list.i[1:-1]:\n    #         dilate.append(e)\n    #     dilate = \', \'.join(\'%s\' % i for i in dilate)\n\n    #     defuse_pad = False\n    #     pad = list()\n    #     if ""pads"" in IR_node.IR_layer.attr:\n    #         output_shape = list()\n    #         for e in IR_node.IR_layer.attr[""_output_shapes""].list.shape[0].dim:\n    #             output_shape.append(e.size)\n\n    #         # print(""Warning: MXNet Deconvolution Layer pad does not match IR Deconvolution Layer pad"")\n    #         defuse_pad, pad = MXNetEmitter.transfer_pad(IR_node.IR_layer.attr[""pads""].list.i)\n    #     pad = \', \'.join(\'%s\' % i for i in pad)\n\n    #     kernel = \', \'.join(\'%s\' % i for i in kernel)\n    #     stride = \', \'.join(\'%s\' % i for i in stride)\n\n    #     num_filter = IR_node.IR_layer.attr[""kernel_shape""].list.i[-2]\n    #     no_bias = not IR_node.IR_layer.attr[""use_bias""].b\n    #     if not no_bias and self.weight_loaded:\n    #         self.output_weights[IR_node.replace_scope(IR_node.name) + ""_bias""] = weight_dict[\'bias\']\n\n    #     # layout = IR_node.IR_layer.attr[""data_format""].s\n    #     if dim == 1:\n    #         layout = \'NCW\'\n    #     elif dim == 2:\n    #         layout = \'NCHW\'\n    #     elif dim == 3:\n    #         layout = \'NCDHW\'\n\n    #     if self.weight_loaded:\n    #         # if layout not in MXNetEmitter.channels_last:\n    #         weights = MXNetEmitter.transpose(weights, dim)\n    #         self.output_weights[IR_node.replace_scope(IR_node.name) + ""_weight""] = weights\n\n    #     code = """"\n    #     if not defuse_pad:\n    #         code = ""{:<15} = mx.sym.Deconvolution(data = {}, kernel = ({}), stride = ({}), dilate = ({}), pad = ({}), num_filter = {}, no_bias = {}, layout = \'{}\', name = \'{}\')"".format(\n    #                 IR_node.replace_scope(IR_node.name),\n    #                 IR_node.replace_scope(IR_node.in_edges[0]),\n    #                 kernel,\n    #                 stride,\n    #                 dilate,\n    #                 pad,\n    #                 num_filter,\n    #                 no_bias,\n    #                 layout,\n    #                 IR_node.replace_scope(IR_node.name))\n    #     else:\n    #         code = self.set_pad(IR_node, code, pad)\n    #         code += ""\\n    {:<15} = mx.sym.Deconvolution(data = {}, kernel = ({}), stride = ({}), dilate = ({}), num_filter = {}, no_bias = {}, layout = \'{}\', name = \'{}\')"".format(\n    #                 IR_node.replace_scope(IR_node.name), IR_node.replace_scope(IR_node.name) + ""_pad"", kernel, stride, dilate, num_filter, no_bias, layout, IR_node.replace_scope(IR_node.name))\n\n    #     return code\n\n\n    def emit_Embedding(self, IR_node):\n\n        input_dim = IR_node.IR_layer.attr[""input_dim""].i\n        output_dim = IR_node.IR_layer.attr[""output_dim""].i\n        dtype = MXNetEmitter.dtype_map.get(IR_node.layer.attr[""dtype""].type, ""float32"")\n\n        weight_dict = self.weights[IR_node.name]\n\n        if self.weight_loaded:\n            self.output_weights[IR_node.name + ""_weight""] = weight_dict[\'weights\']\n\n        code = ""{:<15} = mx.sym.Embedding(data = {}, input_dim = {}, output_dim = {}, dtype = \'{}\', name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                input_dim,\n                output_dim,\n                dtype,\n                IR_node.name)\n\n        return code\n\n\n    def emit_LeakyRelu(self, IR_node):\n        alpha = IR_node.IR_layer.attr[\'alpha\'].f\n        code = ""{:<15} = mx.sym.LeakyReLU(data = {}, slope = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                alpha,\n                IR_node.name\n        )\n        return code\n\n    def emit_PRelu(self, IR_node):\n        slope = IR_node.get_attr(\'gamma\')\n        code = ""{:<15} = mx.sym.LeakyReLU(data = {}, slope = {}, act_type = \'{}\', name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                slope,\n                \'prelu\',\n                IR_node.name\n        )\n        return code\n\n    def emit_Elu(self, IR_node):\n        alpha = IR_node.IR_layer.attr[\'alpha\'].f\n        code = ""{:<15} = mx.sym.LeakyReLU(data = {}, slope = {}, act_type = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                alpha,\n                \'elu\',\n                IR_node.name\n        )\n        return code\n\n    def emit_Dropout(self, IR_node):\n        p = IR_node.IR_layer.attr[""keep_prob""].f\n        mode = IR_node.IR_layer.attr[""mode""].s.lower().decode() if \'mode\' in IR_node.layer.attr else \'training\'\n        code = ""{:<15} = mx.sym.Dropout(data = {}, p = {}, mode = \'{}\', name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                p,\n                mode,\n                IR_node.name)\n\n        return code\n\n\n    # reverse cannot support yet\n    def emit_Reshape(self, IR_node):\n        shape = list()\n        for e in IR_node.IR_layer.attr[""shape""].list.i:\n            shape.append(e)\n        shape = \', \'.join(\'%s\' % i for i in shape)\n        reverse = False\n\n        code = ""{:<15} = mx.sym.reshape(data = {}, shape = ({}), reverse = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                shape,\n                reverse,\n                IR_node.name)\n\n        return code\n\n\n    def emit_Flatten(self, IR_node):\n        # code = ""{:<15} = mx.sym.transpose(data = {}, axes = (0, 2, 3, 1))\\n"".format(""trans"", self.parent_variable_name(IR_node))\n        code = ""{:<15} = mx.sym.flatten(data = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                IR_node.name)\n\n        return code\n\n\n    @staticmethod\n    def _convert_axis(IR_node, axis):\n        ndim = len(IR_node.layer.attr[\'_output_shapes\'].list.shape[0].dim)\n        if axis == 0:\n            return 0\n        elif axis == ndim - 1:\n            return 1\n        else:\n            return axis + 1\n\n\n    def emit_Concat(self, IR_node):\n        dim = MXNetEmitter._convert_axis(IR_node, IR_node.IR_layer.attr[""axis""].i)\n        code = ""{:<15} = mx.sym.concat({}, dim = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                \', \'.join(self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))),\n                dim,\n                IR_node.name)\n\n        return code\n\n\n    def emit_Cast(self, IR_node):\n        dtype = IR_node.IR_layer.attr[""dtype""].type\n        code = ""{:<15} = mx.sym.cast(data = {}, dtype = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                dtype,\n                IR_node.name)\n\n        return code\n\n\n    def emit_Expand_dims(self, IR_node):\n        axis = IR_node.IR_layer.attr[""axis""].i\n        code = ""{:<15} = mx.sym.expand_dims(data = {}, axis = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                axis,\n                IR_node.name)\n\n        return code\n\n\n    def emit_Pad(self, IR_node):\n        mode = IR_node.IR_layer.attr[""mode""].s.lower().decode()\n        pad_width = list()\n        pad_width.extend([0]*4)\n        padding = convert_onnx_pad_to_tf(IR_node.get_attr(""pads""))[1:-1]\n        for padding_pair in padding:\n            pad_width.extend(padding_pair)\n\n        pad_width = \', \'.join(\'%s\' % i for i in pad_width)\n\n        code = ""{:<15} = mx.sym.pad(data = {}, mode = \'{}\', pad_width = ({}), name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                mode,\n                pad_width,\n                IR_node.name)\n\n        return code\n\n\n    def emit_Add(self, IR_node):\n        code = ""{:<15} = mx.sym.broadcast_add({}, {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1]))\n\n        return code\n\n\n    def emit_Mul(self, IR_node):\n\n        code = ""{:<15} = mx.sym.broadcast_mul({}, {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1]))\n\n        return code\n\n\n    def emit_ReduceMean(self, IR_node):\n        axes = IR_node.layer.attr[\'axes\'].list.i[:]\n        axes = \',\'.join(\'%s\' % MXNetEmitter.transpose_map[i] for i in axes)\n\n        code = ""{:<15} = mx.sym.mean(data = {}, axis = ({}), keepdims = {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                axes,\n                IR_node.layer.attr[\'keepdims\'].b)\n\n        return code\n\n\n    def emit_LRN(self, IR_node):\n        output_name = IR_node.variable_name\n        input_name = self.parent_variable_name(IR_node)\n        IR_name = IR_node.name\n        alpha = IR_node.get_attr(\'alpha\')\n        beta = IR_node.get_attr(\'beta\')\n        bias = IR_node.get_attr(\'bias\')\n        size = IR_node.get_attr(\'size\')\n\n\n        code = ""{:<15} = mx.sym.LRN(data = {}, alpha = {}, beta = {}, knorm = {}, nsize = {}, name = \'{}\')"".format(\n                output_name,\n                input_name,\n                alpha,\n                beta,\n                bias,\n                size,\n                IR_name)\n\n        return code\n\n    def emit_Constant(self, IR_node):\n        # save the constant into weight dict\n        if IR_node.get_attr(\'value\'):\n            value = IR_node.get_attr(\'value\')\n        else:\n            value = self.weights[IR_node.name][\'value\']\n    \n        if not isinstance(value, list):\n            self.output_weights[IR_node.name + \'_weight\'] = [value] # mxnet\'s bug, it does not surpport scalar weight. \n            code = ""{:<15} = mx.sym.var(name = \'{}\', shape=(1,))"".format(IR_node.variable_name, IR_node.name+\'_weight\')\n        else:\n            shape = np.array(value).shape\n            self.output_weights[IR_node.name + \'_weight\'] = value\n\n            code = ""{:<15} = mx.sym.var(name = \'{}\', shape={})"".format(IR_node.variable_name, IR_node.name+\'_weight\', shape)\n\n        return code\n\n    def emit_Sub(self, IR_node):\n        code = ""{:<15} = mx.sym.broadcast_sub({}, {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node, [1]))\n\n        return code\n\n\n    def emit_Relu6(self, IR_node):\n        codes = list()\n        codes.append(self.emit_Activation(IR_node, \'relu\'))\n        old_name = IR_node.variable_name\n        IR_node.real_name = IR_node.real_name + ""_clip""\n        codes.append(""{:<15} = mx.sym.clip({}, a_min=0, a_max=6, name=\'{}\')"".format(\n            IR_node.real_variable_name,\n            old_name,\n            IR_node.real_name))\n\n        return codes\n\n\n    def emit_Slice(self, IR_node):\n\n        starts = IR_node.get_attr(\'starts\')\n        starts = [starts[0], starts[-1]] + starts[1:-1]\n        ends = IR_node.get_attr(\'ends\')\n        ends = [ends[0], ends[-1]] + ends[1:-1]\n        ends = [i if i else None for i in ends]\n        strides = IR_node.get_attr(\'strides\')\n        if strides:\n            strides = [strides[0], strides[-1]] + strides[1:-1]\n\n        code =  ""{:<15} = mx.sym.slice({}, begin={}, end={}, step={}, name=\'{}\')"".format(\n            IR_node.real_variable_name,\n            self.parent_variable_name(IR_node),\n            starts,\n            ends,\n            strides,\n            IR_node.name\n        )\n        return code\n\n    def emit_Const(self, IR_node):\n        pass\n\n    def emit_Shape(self, IR_node):\n        code = ""{:<15} = mx.sym.var(init = mx.init.Constant({}.infer_shape({}={})[1][0]), name=\'{}\')"".format(\n            IR_node.real_variable_name,\n            self.parent_variable_name(IR_node),\n            list(self.input_name_shape.keys())[0],\n            list(self.input_name_shape.values())[0],\n            IR_node.name\n        )\n        return code\n\n    def emit_Pack(self, IR_node):\n        pass\n\n    def emit_Unsqueeze(self, IR_node):\n        axis = IR_node.get_attr(\'axes\')[0]\n        code = ""{:<15} = mx.sym.expand_dims(data = {}, axis = {}, name = \'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                axis,\n                IR_node.name)\n\n        return code\n\n    def emit_Unstack(self, IR_node):\n        squeeze_axis = axis = IR_node.get_attr(\'axis\')\n        num = IR_node.get_attr(\'num\')\n        if num is None:\n            args_str = """"\n            for input_name in self.IR_graph.input_layers:\n                if self.IR_graph.get_node(input_name).type!=\'Const\':\n                    args_str += \'{}={}, \'.format(self.IR_graph.get_node(input_name).real_variable_name, self.data_input_shape[input_name])\n\n            args_str = args_str[:-2]\n            num_outputs = ""{}.infer_shape({})[1][0][{}]"".format(\n                IR_node.variable_name,\n                args_str,\n                axis\n            )\n        else:\n            num_outputs = num\n\n        code = ""{:<15} = mx.sym.split({}, num_outputs={}, axis={}, squeeze_axis={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            num_outputs,\n            axis,\n            squeeze_axis\n        )\n        return code\n\n    def emit_Fill(self, IR_node):\n        value = IR_node.get_attr(\'value\')\n        code = ""{:<15} = mx.sym.full({}, {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            value\n        )\n        return code\n\n    def emit_Split(self, IR_node):\n        axis = IR_node.get_attr(\'axis\')\n        num_outputs = IR_node.get_attr(\'split\')\n\n        if isinstance(num_outputs, list):\n            raise NotImplementedError()\n        code = ""{:<15} = mx.sym.split({}, num_outputs={}, axis={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            num_outputs,\n            axis)\n\n        return code\n\n\n    def emit_Sigmoid(self, IR_node):\n        code = ""{:<15} = mx.sym.sigmoid(data={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name\n        )\n        return code\n\n\n    def emit_Tanh(self, IR_node):\n        code = ""{:<15} = mx.sym.tanh(data={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name\n        )\n        return code\n\n\n    def emit_Maxmum(self, IR_node):\n        code = ""{:<15} = mx.sym.maxmum({}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]),\n            IR_node.name\n        )\n        return code\n\n\n    def emit_Minimum(self, IR_node):\n        code = ""{:<15} = mx.sym.minimum({}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]),\n            IR_node.name\n        )\n        return code\n\n\n    def emit_Scope(self, IR_node):\n        import re\n        pattern = IR_node.pattern\n        \n        if pattern not in self.naive_scope_pattern and re.sub(r\'(_\\d+)*$\', \'\', IR_node.pattern) not in self.naive_scope_pattern:\n            origi_pattern = re.sub(r\'(_\\d+)*$\', \'\', IR_node.pattern)\n            func = getattr(self, ""_emit_"" + origi_pattern)\n            code = func(IR_node)\n        else:\n            code = ""{:<15} = __{}({})"".format(\n                IR_node.real_variable_name,\n                IR_node.pattern,\n                \', \'.join(self.parent_variable_name(IR_node, s) for s in IR_node.in_edges))\n            self._gen_scope_code(IR_node)\n        return code\n\n\n    def _gen_scope_code(self, scope_node):\n\n        def _get_weight_related_op_name(node):\n            weight_related_ops = [\'Constant\', \'Conv\', \'FullyConnected\', \'BatchNorm\']\n            op_type = node.type\n            if op_type in weight_related_ops:\n                return op_type, node.name\n\n        def _scope_func(params, code, return_var):\n            code = """"""\n    def __call__(self, {}):\n{}\n        return {}\n    """""".format(params, code, \', \'.join(return_var))\n            return code\n\n        class_inits = dict()\n\n        body_code = str()\n        for node_name in scope_node.topology_list:\n            node = self.IR_graph.get_node(node_name)\n            node_type = node.type\n\n            if hasattr(self, ""emit_"" + node_type):\n                func = getattr(self, ""emit_"" + node_type)\n                line = func(node)\n                if line != None:\n                    body_code += ""        "" + line + \'\\n\'\n                    inits = _get_weight_related_op_name(node)\n                    if inits:\n                        if class_inits.get(inits[0], None):\n                            class_inits[inits[0]].append(inits[1])\n                        else:\n                            class_inits[inits[0]] = list([inits[1]])\n            else:\n                print(""MXNetEmitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(node)\n\n        # param_code does not need parameter slice.\n        param_code = \', \'.join(\'%s\'  %self.IR_graph.get_node(s).real_variable_name for s in scope_node.in_edges)\n        function_code = _scope_func(param_code, body_code, scope_node.return_variables)\n\n        return class_inits, function_code\n\n\n    def _emit_gru_cell(self, IR_node):\n        if not self.layers_codes.get(IR_node.pattern, None):\n            class_inits, func_code = self._gen_scope_code(IR_node)\n            variables, variable_codes, init_code, func_code = self.process_inits_func_code(class_inits, func_code)\n\n            states = [self.IR_graph.get_node(s).real_variable_name for s in IR_node.in_edges]\n            states.pop(0)\n            states_code = \', \'.join(states)\n\n            class_code =\'\'\'\nclass _{}(mx.rnn.BaseRNNCell):\n    def __init__(self, {}):\n\n{}\n\n{}\n\n            \'\'\'.format(IR_node.pattern,\n            \', \'.join(variables),\n            init_code,\n            func_code)\n            self.layers_codes[IR_node.pattern] = class_code\n\n            if not hasattr(self, \'pattern_variables\'):\n                self.pattern_variables = {IR_node.pattern: variables}\n            else:\n                self.pattern_variables[IR_node.pattern] = variables\n\n            code = variable_codes\n            code.append(""{:<15} = _{}({})({})"".format(\n                IR_node.real_variable_name,\n                IR_node.pattern,\n                \', \'.join(variables),\n                \', \'.join(self.parent_variable_name(IR_node, s) for s in IR_node.in_edges)))\n        else:\n            code = ""{:<15} = _{}({})({})"".format(\n                IR_node.real_variable_name,\n                IR_node.pattern,\n                \', \'.join(self.pattern_variables[IR_node.pattern]),\n                \', \'.join(self.parent_variable_name(IR_node, s) for s in IR_node.in_edges))\n\n        return code\n\n\n    def _emit_h_zero(self, IR_node):\n        code = ""{:<15} = mx.sym.full((1, {}), {})"".format(\n            IR_node.variable_name,\n            IR_node.get_attr(\'fill_size\'),\n            IR_node.get_attr(\'fill_value\')\n        )\n        return code\n    \n\n    def _emit_lstm_cell(self, IR_node):\n\n        if not self.layers_codes.get(IR_node.pattern, None):\n            class_inits, func_code = self._gen_scope_code(IR_node)\n            variables, variable_codes, init_code, func_code = self.process_inits_func_code(class_inits, func_code)\n\n            states = [self.IR_graph.get_node(s).real_variable_name for s in IR_node.in_edges]\n            states.pop(0)\n            states_code = \', \'.join(states)\n\n            class_code =\'\'\'\nclass _{}(mx.rnn.BaseRNNCell):\n    def __init__(self, {}):\n\n{}\n\n{}\n\n            \'\'\'.format(IR_node.pattern,\n            \', \'.join(variables),\n            init_code,\n            func_code)\n            self.layers_codes[IR_node.pattern] = class_code\n\n            if not hasattr(self, \'pattern_variables\'):\n                self.pattern_variables = {IR_node.pattern: variables}\n            else:\n                self.pattern_variables[IR_node.pattern] = variables\n\n            code = variable_codes\n            code.append(""{:<15} = _{}({})({})"".format(\n                IR_node.real_variable_name,\n                IR_node.pattern,\n                \', \'.join(variables),\n                \', \'.join(self.parent_variable_name(IR_node, s) for s in IR_node.in_edges)))\n        else:\n            code = ""{:<15} = _{}({})({})"".format(\n                IR_node.real_variable_name,\n                IR_node.pattern,\n                \', \'.join(self.pattern_variables[IR_node.pattern]),\n                \', \'.join(self.parent_variable_name(IR_node, s) for s in IR_node.in_edges))\n\n        return code\n\n\n    def process_inits_func_code(self, class_inits, func_code):\n        init_code = str()\n        variables = list()\n        variable_codes = list()\n        for k, v in class_inits.items():\n            if k == \'FullyConnected\':\n                for i, name in enumerate(class_inits[k]):\n                    variable_name = self.IR_graph.get_node(name).variable_name\n                    variables.append(""W_"" + variable_name)\n                    variable_codes.append(""W_{:<15} = mx.sym.var(name=\'{}_weight\')"".format(variable_name, name))\n                    init_code += ""        self.W_{} = W_{}\\n"".format(variable_name, variable_name)\n\n                    if self.weight_loaded and self.weights[name].get(\'bias\', None).any() != None:\n                        variable_codes.append(""B_{:<15} = mx.sym.var(name=\'{}_bias\')"".format(variable_name, name))\n                        variables.append(""B_"" + variable_name)\n                        init_code += ""        self.B_{} = B_{}\\n"".format(variable_name, variable_name)\n                        func_code = func_code.replace(""name = \'{}\'"".format(name), ""name = \'{}\', weight = self.W_{}, bias = self.B_{}"".format(name, variable_name, variable_name))\n                    else:\n                        func_code = func_code.replace(""name = \'{}\'"".format(name), ""name = \'{}\', weight = self.W_{}"".format(name, variable_name))\n            elif k == \'Constant\':\n                for name in class_inits[k]:\n                    variable_name = self.IR_graph.get_node(name.replace(\'_weight\', \'\')).variable_name\n                    variables.append(variable_name)\n                    constant_line = self.emit_Constant(self.IR_graph.get_node(name.replace(\'_weight\', \'\')))\n                    variable_codes.append(""{:<15} = {}"".format(variable_name, \'=\'.join(constant_line.split(\'=\')[1:])))\n                    init_code += ""        self.{} = {}\\n"".format(variable_name, variable_name)\n                    func_code = func_code.replace(constant_line, constant_line.split(\'=\')[0] + \' = self.\'+constant_line.split(\'=\')[0])\n            else:\n                raise NotImplementedError\n\n        return variables, variable_codes, init_code, func_code\n\n'"
mmdnn/conversion/mxnet/mxnet_graph.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\nimport mxnet as mx\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\n\nclass MXNetGraphNode(GraphNode):\n\n\n\n    def __init__(self, layer):\n        super(MXNetGraphNode, self).__init__(layer)\n\n        if ""attr"" in layer:\n            self.attr = layer[""attr""]\n        elif ""param"" in layer:\n            self.attr = layer[""param""]\n        elif ""attrs"" in layer:\n            self.attr = layer[""attrs""]\n        else:\n            self.attr = None\n\n\n    @property\n    def name(self):\n        return self.layer[""name""]\n\n\n    @property\n    def type(self):\n        return self.layer[""op""]\n\n\n    @property\n    def mx_layer(self):\n        return self.layer\n\n\n    def get_attr(self, name, default_value=None):\n        if self.attr:\n            if name in self.attr.keys():\n                return self.attr.get(name)\n            else:\n                return default_value\n        else:\n            return default_value\n\nclass MXNetGraph(Graph):\n\n    def __init__(self, model):\n        # sanity check non-sense always input module.Module\n        # if not (type(model) == mx.module.Module\n        #     or type(model) == mx.module.SequentialModule\n        #     or type(model) == mx.model)\n        #     raise TypeError(""MXNet layer of type %s is not supported."" % type(model))\n\n        super(MXNetGraph, self).__init__(model)\n\n\n    def build(self, json_data):\n\n        self.input_layers = list()\n        input_dict = dict() # dict{layer_num, layer_name}\n        layer_num = -1\n\n        import re\n\n        for layer in json_data:\n\n            layer_num += 1\n            # if layer[""op""] == ""null"":\n            #     continue\n\n            if re.search(""_(weight|bias|var|mean|gamma|beta|label)"", layer[""name""]) and layer[""op""] == ""null"":\n                continue\n\n            input_dict.update({layer_num: layer[""name""]})\n            self.layer_map[layer[""name""]] = MXNetGraphNode(layer)\n            self.layer_name_map[layer[""name""]] = layer[""name""]\n            for input_layer in layer[""inputs""]:\n                assert isinstance(input_layer, list)\n                if input_layer[0] in input_dict:\n                    pred = input_dict.get(input_layer[0])\n\n                    if pred not in self.layer_map:\n                        new_node = dict({\'op\': \'NoOp\', \'name\': pred, \'inputs\': list()})\n                        self.layer_map[pred] = MXNetGraphNode(new_node)\n                        self.layer_name_map[pred] = pred\n\n                    self._make_connection(pred, layer[""name""])\n\n        super(MXNetGraph, self).build()\n\n        # raise NotImplementedError(""Cannot support multi-input"")'"
mmdnn/conversion/mxnet/mxnet_parser.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\nimport sys\nimport math\nimport mxnet as mx\nimport numpy as np\nfrom mmdnn.conversion.mxnet.mxnet_graph import MXNetGraph\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom mmdnn.conversion.common.utils import *\n\nclass MXNetParser(Parser):\n\n    dtype_map = {\n        ""int8""      : graph_pb2.DT_INT8,\n        ""int16""     : graph_pb2.DT_INT16,\n        ""int32""     : graph_pb2.DT_INT32,\n        ""int64""     : graph_pb2.DT_INT64,\n        ""uint8""     : graph_pb2.DT_UINT8,\n        ""uint16""    : graph_pb2.DT_UINT16,\n        ""uint32""    : graph_pb2.DT_UINT32,\n        ""uint64""    : graph_pb2.DT_UINT64,\n        ""float16""   : graph_pb2.DT_FLOAT16,\n        ""float32""   : graph_pb2.DT_FLOAT32,\n        ""float64""   : graph_pb2.DT_FLOAT64\n    }\n\n    activation_map = {\n        ""relu""      : ""Relu"",\n        ""sigmoid""   : ""Sigmoid"",\n        ""tanh""      : ""Tanh"",\n        # Not support yet\n        # ""softrelu""  : ""SoftReLU""\n    }\n\n    channels_last = [\'NDHWC\', \'NHWC\', \'NWC\']\n    channels_first = [\'NCDHW\', \'NCHW\', \'NCW\']\n\n    @property\n    def src_graph(self):\n        return self.mxnet_graph\n\n    @staticmethod\n    def str2bool(v):\n        return v.lower() in (""1"", ""true"")\n\n\n    @staticmethod\n    def str2intList(v):\n        v = v.replace(""("", """")\n        v = v.replace("")"", """")\n        if v == """":\n            return list()\n        else:\n            return [int(s) for s in v.split(\',\')]\n\n\n    @staticmethod\n    def transpose(data, dim):\n        if dim == 1:\n            data = data.transpose((2, 1, 0))\n        elif dim == 2:\n            data = data.transpose((2, 3, 1, 0))\n        elif dim == 3:\n            data = data.transpose((2, 3, 4, 1, 0))\n        else:\n            print(""Warning: The weight of dim {0} cannot transpose"" % dim)\n\n        return data\n\n\n    @staticmethod\n    def _convert_axis(IR_node, axis):\n        ndim = len(IR_node.attr[\'_output_shapes\'].list.shape[0].dim)\n        if axis == 0:\n            return 0\n        elif axis == 1:\n            return ndim - 1\n        else:\n            return axis - 1\n\n\n    def trace_shape(self, source_node, IR_node):\n        input_node = self.IR_layer_map[IR_node.input[0]]\n        while len(input_node.attr[\'_output_shapes\'].list.shape[0].dim) <= 2:\n            IR_node = input_node\n            input_node = self.IR_layer_map[IR_node.input[0]]\n\n        input_shape = list()\n        for e in input_node.attr[""_output_shapes""].list.shape[0].dim:\n            input_shape.append(e.size)\n        C = input_shape.pop()\n        ret = [C] + input_shape[1:]\n        return ret\n\n\n    def check_pad_mode(self, source_node, IR_node):\n        kernel = MXNetParser.str2intList(source_node.get_attr(""kernel""))\n        dim = len(kernel)\n\n        pad = source_node.get_attr(""pad"", ""()"")\n        if pad == ""()"":\n            pad = list([0] * dim)\n        else:\n            pad = MXNetParser.str2intList(pad)\n\n        stride = source_node.get_attr(""stride"")\n        if stride == None:\n            stride = list([1] * dim)\n        else:\n            stride = MXNetParser.str2intList(stride)\n\n        dilate = source_node.get_attr(""dilate"")\n        if dilate == None:\n            dilate = list([1] * dim)\n        else:\n            dilate = MXNetParser.str2intList(dilate)\n\n        input_shape = list()\n        if len(source_node.in_edges) == 0 or IR_node.input[0] not in self.IR_layer_map:\n            input_shape = self.data_shape\n        else:\n            for e in self.IR_layer_map[IR_node.input[0]].attr[""_output_shapes""].list.shape[0].dim:\n                input_shape.append(e.size)\n\n        valid_flag = True\n        same_flag = True\n\n        for i in range(dim):\n            if not pad[i] == 0:\n                valid_flag = False\n            output_shape = int(math.floor(float(input_shape[i] + 2 * pad[i] - dilate[i] * (kernel[i] - 1) - 1) / float(stride[i])) + 1)\n            same_pad_shape = int(math.ceil(float(input_shape[i]) / float(stride[i])))\n            if not output_shape == same_pad_shape:\n                same_flag = False\n\n        if valid_flag:\n            return ""VALID""\n        elif same_flag:\n            return ""SAME""\n        else:\n            return ""None""\n\n\n    @staticmethod\n    def _load_model(weights, epoch):\n        """"""Load a mxnet model from disk\n\n        Parameters\n        ----------\n        model_path: str\n            Path where the model network/params path is (json/params file)\n\n        prefix: str\n            prefix for json file, e.g. prefix-symbol.json\n\n        epoch: int\n            save epoch number\n\n        Returns\n        -------\n        model: A mxnet model\n        params: A pair of dictionaries each mapping parameter names to NDArray values\n        """"""\n\n        # Load the model network and weights\n        sym, arg_params, aux_params = mx.model.load_checkpoint(weights, int(epoch))\n\n        # digraph = mx.viz.plot_network(sym, save_format=\'jpg\') # For debugging\n        # digraph.render()\n\n        model = mx.mod.Module(symbol = sym)\n        arg_params.update(aux_params)\n        return model, arg_params\n\n        \'\'\'\n        MXNet new api does not support load data without data_shapes\n        \'\'\'\n        # model.bind(data_shapes = data_shapes)\n        # model.init_params()\n\n        # mod.load(model_path, epoch_num)\n        # return mod.get_params()\n\n\n    @staticmethod\n    def _load_json_file(model_path):\n        """"""Load a mxnet network json file\n\n        Parameters\n        ----------\n        model_path: str\n            Path where the model network/params path is (json/params file)\n\n        (Deleted)\n        prefix: str\n            prefix for json file, e.g. prefix-symbol.json\n\n        Returns\n        -------\n        data[""nodes""]: all the layer information(including weights, bias) with format\n            data[""nodes""][layer_num][params = {""name"", ""op"", ""attr"", ""inputs""}]\n\n        """"""\n        import json\n\n        # load the model network\n        with open(model_path, \'r\') as data_file:\n            data = json.load(data_file)\n\n        # adjust the data format\n        assert isinstance(data[""nodes""], list)\n        return data[""nodes""]\n\n\n    def __init__(self, input_arg):\n        super(MXNetParser, self).__init__()\n\n        json_data = list()\n        self.data_shape = tuple()\n        # load model files into MXNet graph\n        # data_shape arguments added to calculate infer_shape(required)\n        # if isinstance(input_arg, basestring):\n        if len(input_arg) == 2:\n            with open(input_arg[0], \'r\') as input_json:\n                json_string = input_json.read()\n                symbol = mx.sym.load_json(json_string)\n                self.model = mx.mod.Module(symbol = symbol)\n            json_data = MXNetParser._load_json_file(input_arg[0])\n            self.data_shape = tuple([1] + list(map(int, input_arg[1])))\n\n        elif len(input_arg) == 4:\n            self.model, self.weight_data = MXNetParser._load_model(input_arg[1], input_arg[2])\n            json_data = MXNetParser._load_json_file(input_arg[0])\n            self.weight_loaded = True\n            assert isinstance(input_arg[3], list)\n            self.data_shape = tuple([1] + list(map(int, input_arg[3])))\n\n        else:\n            raise ValueError(""the # of input arguments [{}] is not supported"" % len(input_arg))\n\n        # Build network graph\n        self.data_format = \'None\'\n        self.mxnet_graph = MXNetGraph(self.model)\n        self.mxnet_graph.build(json_data)\n\n\n    def gen_IR(self):\n        self.IR_layer_map = dict()\n        for layer in self.mxnet_graph.topological_sort:\n            current_node = self.mxnet_graph.get_node(layer)\n            node_type = current_node.type\n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n\n            else:\n                self.rename_UNKNOWN(current_node)\n\n\n    def _copy_and_reop(self, source_node, IR_node, new_op = None):\n        new_op = source_node.type if new_op == None else new_op\n        if source_node.name.startswith(\'_\'):\n            source_node.real_name = source_node.name[1:]\n        IR_node.name = source_node.real_name\n        IR_node.op = new_op\n        self.IR_layer_map[IR_node.name] = IR_node\n\n\n    def set_output_shape(self, source_node, IR_node):\n        sym_group = self.model.symbol.get_internals()\n        for sym in sym_group:\n            if source_node.name == sym.name:\n                arg_shape, output_shape, aux_shape = sym.infer_shape(data = self.data_shape)\n                for idx in range(len(output_shape)):\n                    output_list = list(output_shape[idx])\n\n                    # transpose to channel last\n                    if not self.data_format in MXNetParser.channels_last:\n                        channel = output_list.pop(1)\n                        output_list.append(channel)\n\n                    if IR_node.op == ""DataInput"":\n                        MXNetParser._copy_shape(IR_node, [-1] + output_list[1:])\n\n                    shape = graph_pb2.TensorShape()\n                    for dim in output_list:\n                        new_dim = shape.dim.add()\n                        if dim == None:\n                            new_dim.size = -1\n                        else:\n                            new_dim.size = dim\n\n                    IR_node.attr[""_output_shapes""].list.shape.extend([shape])\n                break\n\n    def _convert_identity_operation(self, source_node, new_op=None):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        self._copy_and_reop(source_node, IR_node, new_op)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n        return IR_node\n\n    def _defuse_padding(self, source_node):\n        IR_node = self.IR_graph.node.add()\n        IR_node.name = source_node.name + ""_pad""\n        IR_node.op = ""Pad""\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        self.IR_layer_map[IR_node.name] = IR_node\n\n        # attr\n        assign_IRnode_values(IR_node, {\'mode\' : \'CONSTANT\'})\n        # print(""Warning: MXNet symbol pad does not support channel last"")\n\n        pad = MXNetParser.str2intList(source_node.get_attr(""pad""))\n        args[\'pads\'] = [0, 0]\n        for e in pad:\n            args[\'pads\'].extend([e, e])\n        args[\'pads\'] += [0, 0]\n        args[\'pads\'] = convert_tf_pad_to_onnx(args[\'pads\'])\n        IR_node.set_attrs(args)\n\n        # IR_node.attr[""pads""].list.i.extend([0, 0])\n        # for e in pad:\n        #     IR_node.attr[""pads""].list.i.extend([e, e])\n        # IR_node.attr[""pads""].list.i.extend([0, 0])\n\n        IR_node.attr[""constant_values""].f = 0.\n\n\n    @staticmethod\n    def _copy_shape(IR_node, output_list):\n        if not output_list == None:\n            for dim in output_list:\n                new_dim = IR_node.attr[""shape""].shape.dim.add()\n                if dim == None:\n                    new_dim.size = -1\n                else:\n                    new_dim.size = dim\n        else:\n            IR_node.attr[""shape""].shape.unknown_rank = True\n\n\n    def rename_UNKNOWN(self, source_node):\n        print(""Warning: MXNet Parser has not supported operator %s with name %s.""\n            % (source_node.type, source_node.name))\n        if source_node.type == ""null"" and source_node.name != \'label\':\n            print(""Warning: convert the null operator with name [%s] into input layer."" % source_node.name)\n            IR_node = self.IR_graph.node.add()\n\n            # name, op\n            self._copy_and_reop(source_node, IR_node, ""DataInput"")\n\n            # input edge\n            self.convert_inedge(source_node, IR_node)\n\n            self.set_output_shape(source_node, IR_node)\n\n        else:\n            raise NotImplementedError()\n\n\n\n    """"""\n    Here start with Neural Network Symbol\n    """"""\n\n    def rename_Pad(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        kwargs = dict()\n        pad = MXNetParser.str2intList(source_node.get_attr(""pad_width""))\n        pad += [pad.pop(2), pad.pop(3)]\n        kwargs[\'pads\'] = pad\n        kwargs[\'pads\'] = convert_tf_pad_to_onnx(kwargs[\'pads\'])\n        kwargs[\'mode\'] = \'CONSTANT\'\n        assign_IRnode_values(IR_node, kwargs)\n        IR_node.attr[""constant_values""].f = 0.\n\n\n    def rename_FullyConnected(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n\n        # units\n        IR_node.attr[""units""].i = int(source_node.get_attr(""num_hidden""))\n\n        # use bias (no_bias default = False)\n        IR_node.attr[""use_bias""].b = not MXNetParser.str2bool(source_node.get_attr(""no_bias"", ""False""))\n\n        # weights\n        if self.weight_loaded:\n            if self.data_format == \'NM\':\n                self.set_weight(source_node.name, ""weights"", self.weight_data.get(source_node.name + ""_weight"").asnumpy().transpose((1, 0)))\n            else:\n                weight = self.weight_data.get(source_node.name + ""_weight"").asnumpy().transpose((1, 0))\n                original_shape = weight.shape\n\n                channel_first_list = self.trace_shape(source_node, IR_node)\n                dim = len(channel_first_list) + 1\n                weight = weight.reshape(channel_first_list + [original_shape[1]])\n                assert dim > 2\n                weight = weight.transpose(list(range(1, dim-1)) + [0, dim-1])\n                weight = weight.reshape(original_shape)\n                self.set_weight(source_node.name, ""weights"", weight)\n\n            if IR_node.attr[""use_bias""].b:\n                self.set_weight(source_node.name, ""bias"", self.weight_data.get(source_node.name + ""_bias"").asnumpy())\n\n        if not self.data_format == \'NM\':\n            # print(""Warning: Layer [{}] has changed model data format from [{}] to [NM]"".format(source_node.name, self.data_format))\n            self.data_format = \'NM\'\n\n\n    def rename_Convolution(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n        dim = 0\n        layout = \'None\'\n\n        # kernel_shape\n        kernel = MXNetParser.str2intList(source_node.get_attr(""kernel""))\n        dim = len(kernel)\n        IR_node.attr[""kernel_shape""].list.i.extend(kernel)\n\n        layout = source_node.get_attr(""layout"")\n        if layout == None or layout == \'None\':\n            if dim == 1:\n                layout = ""NCW""\n            elif dim == 2:\n                layout = ""NCHW""\n            elif dim == 3:\n                layout = ""NCDHW""\n\n        if not self.data_format == layout:\n            # print(""Warning: Layer [{}] has changed model data format from [{}] to [{}]"".format(source_node.name, self.data_format, layout))\n            self.data_format = layout\n\n        # groups\n        group = int(source_node.get_attr(""num_group"", ""1""))\n        IR_node.attr[""group""].i = group\n        in_channel = self.IR_layer_map[IR_node.input[0]].attr[""_output_shapes""].list.shape[0].dim[-1].size\n\n        if group == in_channel:\n            self._copy_and_reop(source_node, IR_node, ""DepthwiseConv"")\n        else:\n            self._copy_and_reop(source_node, IR_node, ""Conv"")\n        # in_channel = in_channel // group\n\n        out_channel = int(source_node.get_attr(""num_filter""))\n\n        IR_node.attr[""kernel_shape""].list.i.extend([in_channel, out_channel])\n\n        # use_bias (no_bias default = False)\n        IR_node.attr[""use_bias""].b = not MXNetParser.str2bool(source_node.get_attr(""no_bias"", ""False""))\n\n        # strides\n        strides = source_node.get_attr(""stride"")\n        IR_node.attr[""strides""].list.i.append(1)\n        if not strides == None:\n            IR_node.attr[""strides""].list.i.extend(MXNetParser.str2intList(strides))\n        else:\n            IR_node.attr[""strides""].list.i.extend([1] * dim)\n        IR_node.attr[""strides""].list.i.append(1)\n\n        # dilations\n        dilate = source_node.get_attr(""dilate"")\n        IR_node.attr[""dilations""].list.i.append(1)\n        if not dilate == None:\n            IR_node.attr[""dilations""].list.i.extend(MXNetParser.str2intList(dilate))\n        else:\n            IR_node.attr[""dilations""].list.i.extend([1] * dim)\n        IR_node.attr[""dilations""].list.i.append(1)\n\n        # data_format\n        assign_IRnode_values(IR_node, {\'data_format\' : layout})\n\n        # padding\n        if ""pad"" in source_node.attr:\n            pad = MXNetParser.str2intList(source_node.get_attr(""pad""))\n            IR_node.attr[""pads""].list.i.extend(([0]+pad+[0])*2)\n        else:\n            IR_node.attr[""pads""].list.i.extend([0, 0] * (dim + 2))\n\n        # weights\n        if self.weight_loaded:\n            weight = self.weight_data.get(source_node.name + ""_weight"").asnumpy()\n            if not layout in MXNetParser.channels_last:\n                weight = MXNetParser.transpose(weight, dim)\n                if IR_node.op == ""DepthwiseConv"":\n                    weight = weight.transpose(0, 1, 3, 2)\n            self.set_weight(source_node.name, ""weights"", weight)\n\n            if IR_node.attr[""use_bias""].b:\n                self.set_weight(source_node.name, ""bias"", self.weight_data.get(source_node.name + ""_bias"").asnumpy())\n\n\n    def rename_Activation(self, source_node):\n        self._convert_identity_operation(source_node, new_op=MXNetParser.activation_map[source_node.get_attr(""act_type"")])\n\n\n    def rename_BatchNorm(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n\n        # axis\n        if self.data_format in MXNetParser.channels_first or self.data_format == \'None\':\n            IR_node.attr[""axis""].i = MXNetParser._convert_axis(IR_node, int(source_node.get_attr(""axis"", ""1"")))\n        else:\n            IR_node.attr[""axis""].i = int(source_node.get_attr(""axis"", ""1""))\n\n        # scale\n        IR_node.attr[""scale""].b = not MXNetParser.str2bool(source_node.get_attr(""fix_gamma"", ""True""))\n        IR_node.attr[""bias""].b = True\n        # epsilon\n        IR_node.attr[""epsilon""].f = float(source_node.get_attr(""eps"", ""0.001""))\n\n        # momentum\n        IR_node.attr[""momentum""].f = float(source_node.get_attr(""momentum"", ""0.9""))\n\n        # weights\n        if self.weight_loaded:\n            # gamma\n            if IR_node.attr[""scale""].b:\n                self.set_weight(source_node.name, ""scale"", self.weight_data.get(source_node.name + ""_gamma"").asnumpy())\n\n            # beta\n            if IR_node.attr[""bias""].b:\n                self.set_weight(source_node.name, ""bias"", self.weight_data.get(source_node.name + ""_beta"").asnumpy())\n\n            # mean\n            self.set_weight(source_node.name, ""mean"", self.weight_data.get(source_node.name + ""_moving_mean"").asnumpy())\n\n            # var\n            self.set_weight(source_node.name, ""var"", self.weight_data.get(source_node.name + ""_moving_var"").asnumpy())\n\n\n    def rename_Pooling(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        self._copy_and_reop(source_node, IR_node, ""Pool"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # pooling type (sum not allowed yet)\n        pool_type = source_node.get_attr(""pool_type"")\n        if pool_type == ""sum"":\n            print(""Warning: sum pooling is not supported yet."")\n        elif pool_type == ""max"":\n            assign_IRnode_values(IR_node, {\'pooling_type\' : \'MAX\'})\n        elif pool_type == ""avg"":\n            assign_IRnode_values(IR_node, {\'pooling_type\' : \'AVG\'})\n        else:\n            raise ValueError(""Error pool_type {}."".format(pool_type))\n\n        kernel_shape = MXNetParser.str2intList(source_node.get_attr(""kernel""))\n\n        if MXNetParser.str2bool(source_node.get_attr(""global_pool"", ""False"")):\n\n            IR_node.attr[\'global_pooling\'].b = True\n            IR_node.attr[""kernel_shape""].list.i[:] = [1] * (len(kernel_shape) + 2)\n            IR_node.attr[""strides""].list.i[:] = [1] * (len(kernel_shape) + 2)\n        else:\n            IR_node.attr[\'global_pooling\'].b = False\n\n            # strides\n            strides = source_node.get_attr(""stride"")\n            IR_node.attr[""strides""].list.i.append(1)\n            if not strides == None:\n                IR_node.attr[""strides""].list.i.extend(MXNetParser.str2intList(strides))\n            IR_node.attr[""strides""].list.i.append(1)\n\n            # kernel_shape\n            IR_node.attr[""kernel_shape""].list.i.append(1)\n            IR_node.attr[""kernel_shape""].list.i.extend(kernel_shape)\n            IR_node.attr[""kernel_shape""].list.i.append(1)\n\n            # padding\n            if ""pad"" in source_node.attr:\n                pad = MXNetParser.str2intList(source_node.get_attr(""pad""))\n                IR_node.attr[""pads""].list.i.extend(([0]+pad+[0])*2)\n            else:\n                IR_node.attr[""pads""].list.i.extend(([0])*8)\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n\n    def rename_SoftmaxOutput(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        self._copy_and_reop(source_node, IR_node, ""Softmax"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        if ""attr"" in source_node.layer or ""param"" in source_node.layer:\n            print(""Warning: SoftmaxOutput attrs are not supported in IR."")\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n\n    def rename_softmax(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Softmax\')\n\n        # dim\n        if self.data_format in MXNetParser.channels_first or self.data_format == \'None\':\n            IR_node.attr[""dim""].i = MXNetParser._convert_axis(IR_node, int(source_node.get_attr(""axis"", ""-1"")))\n        else:\n            IR_node.attr[""dim""].i = int(source_node.get_attr(""axis"", ""-1""))\n\n\n    # def rename_log_softmax(self, source_node):\n    #   raise NotImplementedError(""not support yet"")\n\n\n    # def rename_Correlation(self, source_node):\n    #   raise NotImplementedError(""not support yet"")\n\n\n    def rename_Deconvolution(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        self._copy_and_reop(source_node, IR_node, ""ConvTranspose"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        dim = 0\n        layout = \'None\'\n\n        # padding\n        if ""pad"" in source_node.attr:\n            pad = MXNetParser.str2intList(source_node.get_attr(""pad""))\n            IR_node.attr[""pads""].list.i.extend(([0]+pad+[0])*2)\n        else:\n            IR_node.attr[""pads""].list.i.extend([0, 0] * (dim + 2))\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n        # kernel_shape\n        kernel = MXNetParser.str2intList(source_node.get_attr(""kernel""))\n        dim = len(kernel)\n        IR_node.attr[""kernel_shape""].list.i.extend(kernel)\n\n        layout = source_node.get_attr(""layout"")\n        if layout == None or layout == \'None\':\n            if dim == 1:\n                layout = ""NCW""\n            elif dim == 2:\n                layout = ""NCHW""\n            elif dim == 3:\n                layout = ""NCDHW""\n\n        if not self.data_format == layout:\n            # print(""Warning: Layer [{}] has changed model data format from [{}] to [{}]"".format(source_node.name, self.data_format, layout))\n            self.data_format = layout\n\n        in_channel = self.IR_layer_map[IR_node.input[0]].attr[""_output_shapes""].list.shape[0].dim[-1].size\n\n        out_channel = int(source_node.get_attr(""num_filter""))\n\n        IR_node.attr[""kernel_shape""].list.i.extend([out_channel, in_channel])\n\n        # use_bias (no_bias default = False)\n        IR_node.attr[""use_bias""].b = not MXNetParser.str2bool(source_node.get_attr(""no_bias"", ""False""))\n\n        # strides\n        strides = source_node.get_attr(""strides"")\n        IR_node.attr[""strides""].list.i.append(1)\n        if not strides == None:\n            IR_node.attr[""strides""].list.i.extend(MXNetParser.str2intList(strides))\n        else:\n            IR_node.attr[""strides""].list.i.extend([1] * dim)\n        IR_node.attr[""strides""].list.i.append(1)\n\n        # dilations\n        dilate = source_node.get_attr(""dilate"")\n        IR_node.attr[""dilations""].list.i.append(1)\n        if not dilate == None:\n            IR_node.attr[""dilations""].list.i.extend(MXNetParser.str2intList(dilate))\n        else:\n            IR_node.attr[""dilations""].list.i.extend([1] * dim)\n        IR_node.attr[""dilations""].list.i.append(1)\n\n        # data_format\n        IR_node.attr[""data_format""].s = layout\n\n        # groups\n        IR_node.attr[""group""].i = int(source_node.get_attr(""num_group"", ""1""))\n\n        # weights\n        if self.weight_loaded:\n            weight = self.weight_data.get(source_node.name + ""_weight"").asnumpy()\n            if not layout in MXNetParser.channels_last:\n                weight = MXNetParser.transpose(weight, dim)\n            self.set_weight(source_node.name, ""weights"", weight)\n\n            if IR_node.attr[""use_bias""].b:\n                self.set_weight(source_node.name, ""bias"", self.weight_data.get(source_node.name + ""_bias"").asnumpy())\n\n\n    # def rename_RNN(self, source_node):\n    #   raise NotImplementedError(""RNN not support yet"")\n\n\n    def rename_Embedding(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        self._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # input_dim\n        IR_node.attr[""input_dim""].i = int(source_node.get_attr(""input_dim""))\n\n        # output_dim\n        IR_node.attr[""output_dim""].i = int(source_node.get_attr(""output_dim""))\n\n        # dtype\n        IR_node.attr[""dtype""].type = MXNetParser.dtype_map[source_node.get_attr(""dtype"", ""float32"")]\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n\n    # IR only support elu and prelu from {\'elu\', \'leaky\', \'prelu\', \'rrelu\'}\n    def rename_LeakyReLU(self, source_node):\n        act_type = source_node.get_attr(\'act_type\', None)\n        if act_type:\n            if not act_type == ""elu"" and not act_type == ""prelu"":\n                print(""Warning: Activation Type %s is not supported yet."" % act_type)\n                # return\n\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        if act_type == \'prelu\':\n            self._copy_and_reop(source_node, IR_node, ""PRelu"")\n\n            # gamma\n            self.set_weight(source_node.name, ""gamma"", self.weight_data.get(source_node.name + ""_gamma"").asnumpy())\n\n        else:  # All other cases set to \'Elu\'\n            self._copy_and_reop(source_node, IR_node, ""Elu"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # alpha [exp(x) - alpha], but mxnet attr slope [slope*(exp(x) - 1)] when x < 0\n        if ""slope"" in source_node.attr:\n            raise ValueError(""Attribute Slope is not supported in IR format"")\n        # IR_node.attr[""alpha""].f = float()\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n        # raise NotImplementedError(""slope cannot convert to alpha"")\n\n\n    # def rename_InstanceNorm(self, source_node):\n    #   raise NotImplementedError\n\n\n    # def rename_L2Normalization(self, source_node):\n    #   raise NotImplementedError\n\n\n    def rename_LRN(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        alpha = source_node.get_attr(""alpha"", ""0.0001"")\n        beta = source_node.get_attr(""beta"", ""0.75"")\n        bias = source_node.get_attr(""knorm"", ""2"")\n        size = source_node.get_attr(""nsize"")\n\n        IR_node.attr[""alpha""].f = alpha\n        IR_node.attr[""beta""].f = beta\n        IR_node.attr[""bias""].f = bias\n        IR_node.attr[""size""].i = size\n\n\n    def rename_ROIPooling(self, source_node):\n        raise NotImplementedError()\n\n\n    def rename_Dropout(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n\n        # keep_prob\n        IR_node.attr[""keep_prob""].f = float(source_node.get_attr(""p"", ""0.5""))\n\n        # mode\n        assign_IRnode_values(IR_node, {\'mode\' : \'training\'})\n\n\n    """"""\n    Here start with Symbol manipulation routines\n    """"""\n\n    # reverse cannot support yet\n    def rename_reshape(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Reshape\')\n\n        # old API target_shape not support yet\n        shape = source_node.get_attr(""shape"")\n        if not shape == None:\n            shape_list = MXNetParser.str2intList(shape)\n            for param in shape_list:\n                if param <= 0 and not param == -1:\n                    raise ValueError(""special value %d for Reshape is not pre-defined in IR."" % param)\n            IR_node.attr[""shape""].list.i.extend(shape_list)\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n        # raise NotImplementedError(""adjust output shape"")\n\n\n    def rename_Flatten(self, source_node):\n        self._convert_identity_operation(source_node, new_op=\'Flatten\')\n\n\n    def rename_Concat(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Concat\')\n\n        # dim\n        if self.data_format in MXNetParser.channels_first or self.data_format == \'None\':\n            IR_node.attr[""axis""].i = MXNetParser._convert_axis(IR_node, int(source_node.get_attr(""dim"", ""1"")))\n        else:\n            IR_node.attr[""axis""].i = int(source_node.get_attr(""dim"", ""1""))\n\n\n    def rename_cast(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Cast\')\n\n        # dtype\n        IR_node.attr[""dtype""].type = MXNetParser.dtype_map[source_node.get_attr(""dtype"")]\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n\n    def rename_expand_dims(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        self._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # output shape\n        self.set_output_shape(source_node, IR_node)\n\n        # axis\n        if self.data_format in MXNetParser.channels_first or self.data_format == \'None\':\n            IR_node.attr[""axis""].i = MXNetParser._convert_axis(IR_node, int(source_node.get_attr(""axis"")))\n        else:\n            IR_node.attr[""axis""].i = int(source_node.get_attr(""axis""))\n\n\n    def rename_elemwise_add(self, source_node):\n        self._convert_identity_operation(source_node, new_op=\'Add\')\n\n\n    def rename__Plus(self, source_node):\n        self._convert_identity_operation(source_node, new_op=\'Add\')\n\n\n    def rename_broadcast_add(self, source_node):\n        self._convert_identity_operation(source_node, new_op=\'Add\')\n\n\n    def rename_broadcast_mul(self, source_node):\n        self._convert_identity_operation(source_node, new_op=\'Mul\')\n\n\n    def rename__mul(self, source_node):\n        self._convert_identity_operation(source_node, new_op=\'Mul\')\n\n\n    def rename__copy(self, source_node):\n        self._convert_identity_operation(source_node)\n        # raise NotImplementedError(""No matching IR api"")\n\n\n    def _convert_scalar_operator(self, source_node, new_op):\n        value = source_node.get_attr(\'scalar\')\n        value_node = self.IR_graph.node.add()\n        value_node.name = source_node.real_name + ""_second""\n        # left strip the ""_"" at the beginning of the name\n        # Issue #85, #135\n        value_node.name = value_node.name.lstrip(\'_\')\n        value_node.op = \'Constant\'\n        self.set_weight(value_node.name, \'value\', np.array([value], np.float32))\n\n        IR_node = self._convert_identity_operation(source_node, new_op)\n        IR_node.input.append(value_node.name)\n        return IR_node\n\n\n    def rename__mul_scalar(self, source_node):\n        self._convert_scalar_operator(source_node, \'Mul\')\n\n\n    def rename__minus_scalar(self, source_node):\n        self._convert_scalar_operator(source_node, \'Sub\')\n\n    def rename__div_scalar(self, source_node):\n        self._convert_scalar_operator(source_node, \'Div\')\n\n    def rename__copy(self, source_node):\n        source_node.real_name = self.get_parent(source_node.name, [0]).real_name\n\n\n    def rename_BlockGrad(self, source_node):\n        return\n\n'"
mmdnn/conversion/mxnet/saver.py,0,"b""def save_model(MainModel, network_filepath, weight_filepath, dump_filepath):\n    model = MainModel.RefactorModel()\n    model = MainModel.deploy_weight(model, weight_filepath)\n    model.save_checkpoint(dump_filepath, 0)\n    print('MXNet checkpoint file is saved with prefix [{}] and iteration 0, generated by [{}.py] and [{}].'.format(\n        dump_filepath, network_filepath, weight_filepath))\n"""
mmdnn/conversion/onnx/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/onnx/onnx_emitter.py,0,"b'from mmdnn.conversion.common.DataStructure.emitter import Emitter\nfrom mmdnn.conversion.common.IR.IR_graph import IRGraph\nimport os.path\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nimport numpy as np\nimport sys\n\n\nclass OnnxEmitter(Emitter):\n    dtype_map = {\n        graph_pb2.DT_FLOAT32: ""TensorProto.FLOAT""\n    }\n\n    transpose_map = {\n        1: 2,\n        2: 3,\n        -1: 1\n    }\n\n    def __init__(self, architecture, weight):\n        super(OnnxEmitter, self).__init__()\n        if os.path.exists(architecture) == False:\n            raise ValueError(""IR architecture file [{}] is not found."".format(architecture))\n        else:\n            self.IR_graph = IRGraph(architecture)\n            self.IR_graph.build()\n\n        if os.path.exists(weight) == False:\n            raise ValueError(""IR weight file [{}] is not found."".format(weight))\n        else:\n            self._load_weights(weight)\n\n    @property\n    def header_code(self):\n        return """"""import numpy as np\nfrom onnx import helper, TensorProto\nimport onnx\n\n__weights_dict = dict()\n\ndef load_weights(weight_file):\n    if weight_file == None:\n        return\n\n    try:\n        weights_dict = np.load(weight_file, allow_pickle=True).item()\n    except:\n        weights_dict = np.load(weight_file, allow_pickle=True, encoding=\'bytes\').item()\n\n    return weights_dict\n\n\ndef KitModel(weight_file = None):\n    global __weights_dict\n    __weights_dict = load_weights(weight_file)\n\n""""""\n\n    def gen_code(self, phase):\n        self.phase = phase\n        self.add_body(0, self.header_code)\n\n        self.inputs = []\n        self.outputs = []\n        self.nodes = []\n        self.initializer = []\n\n        for layer in self.IR_graph.topological_sort:\n            current_node = self.IR_graph.get_node(layer)\n            node_type = current_node.type\n\n            if hasattr(self, ""emit_"" + node_type):\n                func = getattr(self, ""emit_"" + node_type)\n                func(current_node)\n            else:\n                print(""OnnxEmitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(current_node)\n\n        self._process_output_layers()\n\n        self.add_body(1, ""graph = helper.make_graph([{}], \'mmdnn\', [{}], [{}], [{}])"".format(\', \'.join(self.nodes),\n                                                                                             \', \'.join(self.inputs),\n                                                                                             \', \'.join(self.outputs),\n                                                                                             \', \'.join(\n                                                                                                 self.initializer))\n                      )\n        self.add_body(1, ""return helper.make_model(graph, opset_imports=[helper.make_opsetid(\'\', 6)])"")\n        return self.body_code\n\n    def run(self, dstNetworkPath, dstWeightPath=None, phase=\'test\'):\n        super(OnnxEmitter, self).run(dstNetworkPath, dstWeightPath, phase)\n        self.save_weights(self.weights_dict, dstWeightPath)\n\n    def check_if_need_transpose(self, IR_node):\n        parent = self.IR_graph.get_parent(IR_node.name, [0])\n        while parent.type == \'Flatten\' or parent.type == \'Dropout\':\n            parent = self.IR_graph.get_parent(parent.name, [0])\n        dim = len(parent.layer.attr[\'_output_shapes\'].list.shape[0].dim)\n        if dim > 2:\n            original_dims = self.weights_dict[IR_node.name][\'weights\'].shape\n            dims = [i.size for i in parent.layer.attr[\'_output_shapes\'].list.shape[0].dim[1:]] + [-1]\n            self.weights_dict[IR_node.name][\'weights\'] = self.weights_dict[IR_node.name][\'weights\']\n            self.weights_dict[IR_node.name][\'weights\'] = np.reshape(self.weights_dict[IR_node.name][\'weights\'], dims)\n            self.weights_dict[IR_node.name][\'weights\'] = np.transpose(self.weights_dict[IR_node.name][\'weights\'], [dim - 2] + list(range(0, dim - 2)) + [dim - 1])\n            self.weights_dict[IR_node.name][\'weights\'] = np.reshape(self.weights_dict[IR_node.name][\'weights\'], original_dims)\n\n    def _process_output_layers(self):\n        for name in self.IR_graph.output_layers:\n            IR_node = self.IR_graph.get_node(self.IR_graph.get_node(name).real_name)\n            # omit node of some type\n            if IR_node.type == \'Shape\' or IR_node.type == \'Pack\':\n                continue\n            shape_str = IRGraph.shapeToStr(IR_node.layer.attr[""_output_shapes""].list.shape[0])\n\n            if IR_node.layer.attr[\'dtype\'].type == graph_pb2.DT_UNDEFINED:\n                IR_node.layer.attr[\'dtype\'].type = graph_pb2.DT_FLOAT32\n            dtype_str = self.dtype_map[IR_node.layer.attr[\'dtype\'].type]\n            self.add_body(1, ""{:<15} = helper.make_tensor_value_info(\'{}\', {}, ({},))"".format(\n                IR_node.variable_name + \'_out\',\n                IR_node.variable_name,\n                dtype_str,\n                shape_str\n                ))\n            self.outputs.append(IR_node.variable_name + \'_out\')\n\n    def emit_DataInput(self, IR_node):\n        shape = [dim.size if dim.size != -1 else 1 for dim in IR_node.IR_layer.attr[""shape""].shape.dim]\n        shape_str = \', \'.join(\'%s\' % i for i in shape)\n        if IR_node.layer.attr[\'dtype\'].type == graph_pb2.DT_UNDEFINED:\n            IR_node.layer.attr[\'dtype\'].type = graph_pb2.DT_FLOAT32\n        dtype_str = self.dtype_map[IR_node.layer.attr[\'dtype\'].type]\n        self.add_body(1, ""{:<15} = helper.make_tensor_value_info(\'{}\', {}, ({},))"".format(\n            IR_node.variable_name + \'_orig\',\n            IR_node.variable_name + \'_orig\',\n            dtype_str,\n            shape_str))\n        self.add_body(1, ""{:15} = helper.make_node(\'Transpose\', inputs=[\'{}\'], outputs=[\'{}\'], perm=[0, 3, 1, 2], name=\'{}\')"".format(\n            IR_node.variable_name,\n            IR_node.variable_name + \'_orig\',\n            IR_node.variable_name,\n            IR_node.variable_name\n            ))\n        self.inputs.append(IR_node.variable_name + \'_orig\')\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Conv(self, IR_node):\n        kernel_shape = list(IR_node.get_attr(\'kernel_shape\'))[:-2]\n        dilations = list(IR_node.get_attr(\'dilations\', [1] * (len(kernel_shape) + 2)))[1:-1]\n        group = IR_node.get_attr(\'group\', 1)\n        if IR_node.type == \'DepthwiseConv\':\n            group = IR_node.IR_layer.attr[""kernel_shape""].list.i[-2]\n            self.weights_dict[IR_node.name][\'weights\'] = np.swapaxes(self.weights_dict[IR_node.name][\'weights\'], -1, -2)\n        pads = IR_node.get_attr(\'pads\')\n        pad_length = len(pads)\n        pads = pads[1:pad_length // 2 - 1] + pads[pad_length // 2 + 1:pad_length - 1]\n        strides = list(IR_node.get_attr(\'strides\'))[1:-1]\n        use_bias=IR_node.get_attr(\'use_bias\')\n        self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'weights\']"".format(\n            IR_node.variable_name + \'_weight_array\',\n            IR_node.name))\n        self.add_body(1, ""{} = {}.transpose([3,2,0,1])"".format(\n            IR_node.variable_name + \'_weight_array\',\n            IR_node.variable_name + \'_weight_array\'))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n                          IR_node.variable_name + \'_weight\',\n                          IR_node.variable_name + \'_weight\',\n                          IR_node.variable_name + \'_weight_array\',\n                          IR_node.variable_name + \'_weight_array\'))\n\n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                          IR_node.variable_name + \'_weight_init\',\n                          IR_node.variable_name + \'_weight\',\n                          IR_node.variable_name + \'_weight_array\',\n                          IR_node.variable_name + \'_weight_array\',\n                          IR_node.variable_name + \'_weight_array\'))\n\n        if use_bias:\n            self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'bias\'].squeeze()"".format(\n                IR_node.variable_name + \'_bias_array\',\n                IR_node.name))\n\n            self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n                            IR_node.variable_name + \'_bias\',\n                            IR_node.variable_name + \'_bias\',\n                            IR_node.variable_name + \'_bias_array\',\n                            IR_node.variable_name + \'_bias_array\'))\n\n            self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                              IR_node.variable_name + \'_bias_init\',\n                              IR_node.variable_name + \'_bias\',\n                              IR_node.variable_name + \'_bias_array\',\n                              IR_node.variable_name + \'_bias_array\',\n                              IR_node.variable_name + \'_bias_array\'))\n            self.add_body(1, ""{:15} = helper.make_node(\'Conv\', inputs=[\'{}\', \'{}\', \'{}\'],outputs=[\'{}\'], dilations={}, group={}, kernel_shape={}, pads={}, strides={}, name=\'{}\')"".format(\n                              IR_node.variable_name,\n                              self.parent_variable_name(IR_node),\n                              IR_node.variable_name + \'_weight\',\n                              IR_node.variable_name + \'_bias\',\n                              IR_node.variable_name,\n                              dilations,\n                              group,\n                              kernel_shape,\n                              pads,\n                              strides,\n                              IR_node.variable_name))\n            # self.nodes.append(IR_node.variable_name + \'_bias\')\n            self.initializer.append(IR_node.variable_name + \'_bias_init\')\n            self.inputs.append(IR_node.variable_name + \'_bias\')\n        else:\n            self.add_body(1, ""{:15} = helper.make_node(\'Conv\', inputs=[\'{}\', \'{}\'], outputs=[\'{}\'], dilations={}, group={}, kernel_shape={}, pads={}, strides={}, name=\'{}\')"".format(\n                              IR_node.variable_name,\n                              self.parent_variable_name(IR_node),\n                              IR_node.variable_name + \'_weight\',\n                              IR_node.variable_name,\n                              dilations,\n                              group,\n                              kernel_shape,\n                              pads,\n                              strides,\n                              IR_node.variable_name))\n        # self.nodes.append(IR_node.variable_name + \'_weight\')\n        self.initializer.append(IR_node.variable_name + \'_weight_init\')\n        self.inputs.append(IR_node.variable_name + \'_weight\')\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_BatchNorm(self, IR_node):\n        epsilon = IR_node.get_attr(\'epsilon\')\n        if IR_node.get_attr(\'scale\'):\n            self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'scale\'].squeeze()"".format(\n                IR_node.variable_name + \'_scale_array\',\n                IR_node.name))\n        else:\n            self.add_body(1, ""{:15} = np.ndarray(__weights_dict[\'{}\'][\'bias\'].shape, dtype=__weights_dict[\'{}\'][\'bias\'].dtype).squeeze()"".format(\n                              IR_node.variable_name + \'_scale_array\',\n                              IR_node.name,\n                              IR_node.name))\n            self.add_body(1, ""{:15}.fill(1)"".format(IR_node.variable_name + \'_scale_array\'))\n\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n            IR_node.variable_name + \'_scale\',\n            IR_node.variable_name + \'_scale\',\n            IR_node.variable_name + \'_scale_array\',\n            IR_node.variable_name + \'_scale_array\'))\n    \n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={})"".format(\n                          IR_node.variable_name + \'_scale_init\',\n                          IR_node.variable_name + \'_scale\',\n                          IR_node.variable_name + \'_scale_array\',\n                          IR_node.variable_name + \'_scale_array\',\n                          IR_node.variable_name + \'_scale_array\'))\n        self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'bias\'].squeeze()"".format(\n            IR_node.variable_name + \'_bias_array\',\n            IR_node.name))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n                        IR_node.variable_name + \'_bias\',\n                        IR_node.variable_name + \'_bias\',\n                        IR_node.variable_name + \'_bias_array\',\n                        IR_node.variable_name + \'_bias_array\'))\n\n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                            IR_node.variable_name + \'_bias_init\',\n                            IR_node.variable_name + \'_bias\',\n                            IR_node.variable_name + \'_bias_array\',\n                            IR_node.variable_name + \'_bias_array\',\n                            IR_node.variable_name + \'_bias_array\'))\n\n        self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'mean\'].squeeze()"".format(\n            IR_node.variable_name + \'_mean_array\',\n            IR_node.name))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n                        IR_node.variable_name + \'_mean\',\n                        IR_node.variable_name + \'_mean\',\n                        IR_node.variable_name + \'_mean_array\',\n                        IR_node.variable_name + \'_mean_array\'))\n\n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                            IR_node.variable_name + \'_mean_init\',\n                            IR_node.variable_name + \'_mean\',\n                            IR_node.variable_name + \'_mean_array\',\n                            IR_node.variable_name + \'_mean_array\',\n                            IR_node.variable_name + \'_mean_array\'))\n\n        self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'var\'].squeeze()"".format(\n                          IR_node.variable_name + \'_var_array\',\n                          IR_node.name))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n                            IR_node.variable_name + \'_var\',\n                            IR_node.variable_name + \'_var\',\n                            IR_node.variable_name + \'_var_array\',\n                            IR_node.variable_name + \'_var_array\'))\n    \n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                            IR_node.variable_name + \'_var_init\',\n                            IR_node.variable_name + \'_var\',\n                            IR_node.variable_name + \'_var_array\',\n                            IR_node.variable_name + \'_var_array\',\n                            IR_node.variable_name + \'_var_array\'))                         \n\n        self.add_body(1, ""{:15} = helper.make_node(\'BatchNormalization\', inputs=[\'{}\', \'{}\', \'{}\', \'{}\', \'{}\'],outputs=[\'{}\'], epsilon={}, is_test={}, name=\'{}\')"".format(\n                          IR_node.variable_name,\n                          self.parent_variable_name(IR_node),\n                          IR_node.variable_name + \'_scale\',\n                          IR_node.variable_name + \'_bias\',\n                          IR_node.variable_name + \'_mean\',\n                          IR_node.variable_name + \'_var\',\n                          IR_node.variable_name,\n                          epsilon,\n                          0 if self.phase == \'train\' else 1,\n                          IR_node.variable_name))\n        self.initializer.append(IR_node.variable_name + \'_scale_init\')\n        self.initializer.append(IR_node.variable_name + \'_bias_init\')\n        self.initializer.append(IR_node.variable_name + \'_mean_init\')\n        self.initializer.append(IR_node.variable_name + \'_var_init\')\n        self.inputs.append(IR_node.variable_name + \'_scale\')\n        self.inputs.append(IR_node.variable_name + \'_bias\')\n        self.inputs.append(IR_node.variable_name + \'_mean\')\n        self.inputs.append(IR_node.variable_name + \'_var\')\n        self.nodes.append(IR_node.variable_name)\n\n\n    def emit_Scale(self, IR_node):\n        dims = [i.size for i in IR_node.layer.attr[\'_output_shapes\'].list.shape[0].dim[1:]]\n        units = dims[-1]\n        epsilon = 1e-5\n        if IR_node.get_attr(\'scale\'):\n            self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'scale\'].squeeze()"".format(\n                IR_node.variable_name + \'_scale_array\',\n                IR_node.name))\n        else:\n            self.add_body(1, ""{:15} = np.ndarray(__weights_dict[\'{}\'][\'bias\'].shape, dtype=__weights_dict[\'{}\'][\'bias\'].dtype).squeeze()"".format(\n                              IR_node.variable_name + \'_scale_array\',\n                              IR_node.name,\n                              IR_node.name))\n            self.add_body(1, ""{:15}.fill(1)"".format(IR_node.variable_name + \'_scale_array\'))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n            IR_node.variable_name + \'_scale\',\n            IR_node.variable_name + \'_scale\',\n            IR_node.variable_name + \'_scale_array\',\n            IR_node.variable_name + \'_scale_array\'))\n    \n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={})"".format(\n                            IR_node.variable_name + \'_scale_init\',\n                            IR_node.variable_name + \'_scale\',\n                            IR_node.variable_name + \'_scale_array\',\n                            IR_node.variable_name + \'_scale_array\',\n                            IR_node.variable_name + \'_scale_array\'))\n        self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'bias\'].squeeze()"".format(\n            IR_node.variable_name + \'_bias_array\',\n            IR_node.name))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n            IR_node.variable_name + \'_bias\',\n            IR_node.variable_name + \'_bias\',\n            IR_node.variable_name + \'_bias_array\',\n            IR_node.variable_name + \'_bias_array\'))\n\n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                            IR_node.variable_name + \'_bias_init\',\n                            IR_node.variable_name + \'_bias\',\n                            IR_node.variable_name + \'_bias_array\',\n                            IR_node.variable_name + \'_bias_array\',\n                            IR_node.variable_name + \'_bias_array\'))\n        self.add_body(1, ""{:15} = np.zeros({}, dtype=np.float32)"".format(\n            IR_node.variable_name + \'_mean_array\',\n            units))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n            IR_node.variable_name + \'_mean\',\n            IR_node.variable_name + \'_mean\',\n            IR_node.variable_name + \'_mean_array\',\n            IR_node.variable_name + \'_mean_array\'))\n\n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                            IR_node.variable_name + \'_mean_init\',\n                            IR_node.variable_name + \'_mean\',\n                            IR_node.variable_name + \'_mean_array\',\n                            IR_node.variable_name + \'_mean_array\',\n                            IR_node.variable_name + \'_mean_array\'))\n        self.add_body(1, ""{:15} = np.ones({}, dtype=np.float32)"".format(\n                          IR_node.variable_name + \'_var_array\',\n                          units))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n                            IR_node.variable_name + \'_var\',\n                            IR_node.variable_name + \'_var\',\n                            IR_node.variable_name + \'_var_array\',\n                            IR_node.variable_name + \'_var_array\'))\n    \n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                            IR_node.variable_name + \'_var_init\',\n                            IR_node.variable_name + \'_var\',\n                            IR_node.variable_name + \'_var_array\',\n                            IR_node.variable_name + \'_var_array\',\n                            IR_node.variable_name + \'_var_array\'))   \n        self.add_body(1, ""{:15} = helper.make_node(\'BatchNormalization\', inputs=[\'{}\', \'{}\', \'{}\', \'{}\', \'{}\'],outputs=[\'{}\'], epsilon={}, is_test={}, name=\'{}\')"".format(\n                          IR_node.variable_name,\n                          self.parent_variable_name(IR_node),\n                          IR_node.variable_name + \'_scale\',\n                          IR_node.variable_name + \'_bias\',\n                          IR_node.variable_name + \'_mean\',\n                          IR_node.variable_name + \'_var\',\n                          IR_node.variable_name,\n                          epsilon,\n                          0 if self.phase == \'train\' else 1,\n                          IR_node.variable_name))\n        self.inputs.append(IR_node.variable_name + \'_scale\')\n        self.inputs.append(IR_node.variable_name + \'_bias\')\n        self.inputs.append(IR_node.variable_name + \'_mean\')\n        self.inputs.append(IR_node.variable_name + \'_var\')\n        self.initializer.append(IR_node.variable_name + \'_scale_init\')\n        self.initializer.append(IR_node.variable_name + \'_bias_init\')\n        self.initializer.append(IR_node.variable_name + \'_mean_init\')\n        self.initializer.append(IR_node.variable_name + \'_var_init\')\n        self.nodes.append(IR_node.variable_name)\n\n\n    def emit_Relu(self, IR_node):\n        self.add_body(1, ""{:15} = helper.make_node(\'Relu\', inputs=[\'{}\'], outputs=[\'{}\'], name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Add(self, IR_node):\n        input_layers = \', \'.join(\n            (""\'"" + self.IR_graph.get_parent(IR_node.name, [num]).real_variable_name) + ""\'"" for num in\n            range(0, len(IR_node.in_edges)))\n        self.add_body(1, ""{:15} = helper.make_node(\'Add\', inputs=[{}], outputs=[\'{}\'], name=\'{}\')"".format(\n            IR_node.variable_name,\n            input_layers,\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Pool(self, IR_node):\n        pooling_type = IR_node.get_attr(\'pooling_type\')\n        if IR_node.layer.attr[\'global_pooling\'].b:\n            if pooling_type == \'AVG\':\n                self.add_body(1, ""{:15} = helper.make_node(\'GlobalAveragePool\', inputs=[\'{}\'], outputs=[\'{}\'], name=\'{}\')"".format(\n                    IR_node.variable_name,\n                    self.parent_variable_name(IR_node),\n                    IR_node.variable_name,\n                    IR_node.variable_name))\n                self.nodes.append(IR_node.variable_name)\n            else:\n                print(""OnnxEmitter has not supported Global Pool type [%s]."" % (pooling_type))\n                self.emit_UNKNOWN(IR_node)\n        else:\n            if pooling_type in [\'AVG\', \'MAX\']:\n                if pooling_type == \'AVG\':\n                    op_name = \'AveragePool\'\n                elif pooling_type == \'MAX\':\n                    op_name = \'MaxPool\'\n                kernel_shape = list(IR_node.get_attr(\'kernel_shape\')[1:-1])\n                pads = IR_node.get_attr(\'pads\')\n                pad_length = len(pads)\n                pads = pads[1:pad_length // 2 - 1] + pads[pad_length // 2 + 1:pad_length - 1]\n                strides = list(IR_node.get_attr(\'strides\')[1:-1])\n                self.add_body(1, ""{:15} = helper.make_node(\'{}\', inputs=[\'{}\'],outputs=[\'{}\'], kernel_shape={}, pads={}, strides={}, name=\'{}\')"".format(\n                                  IR_node.variable_name,\n                                  op_name,\n                                  self.parent_variable_name(IR_node),\n                                  IR_node.variable_name,\n                                  kernel_shape,\n                                  pads,\n                                  strides,\n                                  IR_node.variable_name))\n                self.nodes.append(IR_node.variable_name)\n            else:\n                print(""OnnxEmitter has not supported Pool type [%s]."" % (pooling_type))\n                self.emit_UNKNOWN(IR_node)\n\n    def emit_FullyConnected(self, IR_node):\n        self.check_if_need_transpose(IR_node)\n        use_bias = IR_node.get_attr(\'use_bias\', True)\n        units = IR_node.get_attr(\'units\')\n\n        self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'weights\']"".format(\n            IR_node.variable_name + \'_weight_array\',\n            IR_node.name))\n\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n            IR_node.variable_name + \'_weight\',\n            IR_node.variable_name + \'_weight\',\n            IR_node.variable_name + \'_weight_array\',\n            IR_node.variable_name + \'_weight_array\'))\n\n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n            IR_node.variable_name + \'_weight_init\',\n            IR_node.variable_name + \'_weight\',\n            IR_node.variable_name + \'_weight_array\',\n            IR_node.variable_name + \'_weight_array\',\n            IR_node.variable_name + \'_weight_array\'))\n\n        if use_bias:\n            self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'bias\'].squeeze()"".format(\n                IR_node.variable_name + \'_bias_array\',\n                IR_node.name))\n        else:\n            self.add_body(1, ""{:15} = np.zeros({})"".format(\n                IR_node.variable_name + \'_bias_array\',\n                units))\n        self.add_body(1, ""{:15} = helper.make_tensor_value_info(\'{}\', onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], list({}.shape))"".format(\n            IR_node.variable_name + \'_bias\',\n            IR_node.variable_name + \'_bias\',\n            IR_node.variable_name + \'_bias_array\',\n            IR_node.variable_name + \'_bias_array\'))\n\n        self.add_body(1, ""{:15} = helper.make_tensor(name=\'{}\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float))"".format(\n                            IR_node.variable_name + \'_bias_init\',\n                            IR_node.variable_name + \'_bias\',\n                            IR_node.variable_name + \'_bias_array\',\n                            IR_node.variable_name + \'_bias_array\',\n                            IR_node.variable_name + \'_bias_array\'))\n        self.add_body(1, ""{:15} = helper.make_node(\'Gemm\', inputs=[\'{}\', \'{}\', \'{}\'], outputs=[\'{}\'], name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name + \'_weight\',\n            IR_node.variable_name + \'_bias\',\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.initializer.append(IR_node.variable_name + \'_weight_init\')\n        self.initializer.append(IR_node.variable_name + \'_bias_init\')\n        self.inputs.append(IR_node.variable_name + \'_weight\')\n        self.inputs.append(IR_node.variable_name + \'_bias\')\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Pad(self, IR_node):\n        mode = IR_node.layer.attr[\'mode\'].s.decode()\n        pads = IR_node.get_attr(\'pads\')\n        pad_length = len(pads)\n        pads = [0, 0] + pads[1:pad_length // 2 - 1] + [0, 0] + pads[pad_length // 2 + 1:pad_length - 1]\n        self.add_body(1, ""{:15} = helper.make_node(\'Pad\', inputs=[\'{}\'], outputs=[\'{}\'], mode=\'{}\', pads={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name,\n            mode,\n            pads,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Concat(self, IR_node):\n        axis = IR_node.get_attr(\'axis\') - 2\n        inputs = \', \'.join(""\'"" + self.IR_graph.get_node(i).real_variable_name + ""\'"" for i in IR_node.in_edges)\n        self.add_body(1, ""{:15} = helper.make_node(\'Concat\', inputs=[{}], outputs=[\'{}\'], axis={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            inputs,\n            IR_node.variable_name,\n            axis,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Flatten(self, IR_node):\n        self.add_body(1, ""{:15} = helper.make_node(\'Flatten\', inputs=[\'{}\'], outputs=[\'{}\'], name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Softmax(self, IR_node):\n        self.add_body(1, ""{:15} = helper.make_node(\'Softmax\', inputs=[\'{}\'], outputs=[\'{}\'], name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Constant(self, IR_node):\n        if IR_node.get_attr(\'value\'):\n            value = \'np.array({}, dtype=np.float32)\'.format(IR_node.get_attr(\'value\'))\n            self.add_body(1, ""{:15} = {}"".format(\n                IR_node.variable_name + \'_value_array\',\n                value))\n        else:\n            self.add_body(1, ""{:15} = __weights_dict[\'{}\'][\'value\']"".format(\n                IR_node.variable_name + \'_value_array\',\n                IR_node.name))\n        self.add_body(1, ""{:15} = helper.make_node(\'Constant\', inputs=[], outputs=[\'{}\'], value=helper.make_tensor(name=\'const_tensor\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}.flatten().astype(float)), name=\'{}\')"".format(\n                          IR_node.variable_name,\n                          IR_node.variable_name,\n                          IR_node.variable_name + \'_value_array\',\n                          IR_node.variable_name + \'_value_array\',\n                          IR_node.variable_name + \'_value_array\',\n                          IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Sub(self, IR_node):\n        inputs = \', \'.join(""\'"" + self.IR_graph.get_node(i).real_variable_name + ""\'"" for i in IR_node.in_edges)\n        self.add_body(1, ""{:15} = helper.make_node(\'Sub\', inputs=[{}], outputs=[\'{}\'], broadcast=1, name=\'{}\')"".format(\n            IR_node.variable_name,\n            inputs,\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Mul(self, IR_node):\n        inputs = \', \'.join(""\'"" + self.IR_graph.get_node(i).real_variable_name + ""\'"" for i in IR_node.in_edges)\n        \n        if IR_node.name in self.weights_dict and \'weights\' in self.weights_dict[IR_node.name]:\n            self.add_body(1,""{:15} = np.array([__weights_dict[\'{}\'][\'weights\']])"".format(\n                IR_node.variable_name+\'_weight_array\',\n                IR_node.name\n            ))\n            self.add_body(1, ""{:15} = helper.make_node(\'Constant\', inputs=[], outputs=[\'{}\'], value=helper.make_tensor(name=\'const_tensor\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}), name=\'{}\')"".format(\n                    IR_node.variable_name + \'_weight\',\n                    IR_node.variable_name + \'_weight\',\n                    IR_node.variable_name + \'_weight_array\',\n                    IR_node.variable_name + \'_weight_array\',\n                    IR_node.variable_name + \'_weight_array\',\n                    IR_node.variable_name + \'_weight\'\n                    ))\n            inputs += \', \'+\'\'.join(""\'""+IR_node.variable_name +""_weight\'"")\n            self.nodes.append(IR_node.variable_name+\'_weight\')\n\n        self.add_body(1, ""{:15} = helper.make_node(\'Mul\', inputs=[{}], outputs=[\'{}\'], broadcast=1, name=\'{}\')"".format(\n            IR_node.variable_name,\n            inputs,\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Dropout(self, IR_node):\n        self.add_body(1, ""{:15} = helper.make_node(\'Dropout\', inputs=[\'{}\'], outputs=[\'{}\'], is_test={}, ratio={}, name=\'{}\')"".format(\n                          IR_node.variable_name,\n                          self.parent_variable_name(IR_node),\n                          IR_node.variable_name,\n                          0 if self.phase == \'train\' else 1,\n                          1 - IR_node.get_attr(\'keep_prob\'),\n                          IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Squeeze(self, IR_node):\n        IR_node.real_name = self.IR_graph.get_node(IR_node.in_edges[0]).real_name\n\n    def emit_ReduceMean(self, IR_node):\n        axes = IR_node.layer.attr[\'axes\'].list.i[:]\n        axes = \',\'.join(\'%s\' % OnnxEmitter.transpose_map[i] for i in axes)\n        self.add_body(1, ""{:15} = helper.make_node(\'ReduceMean\', inputs=[\'{}\'], outputs=[\'{}\'], axes=[{}], keepdims={}, name=\'{}\')"".format(\n                          IR_node.variable_name,\n                          self.parent_variable_name(IR_node),\n                          IR_node.variable_name,\n                          axes,\n                          1 if IR_node.layer.attr[\'keepdims\'].b else 0,\n                          IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Reshape(self, IR_node):\n        shape = [item if item != -1 else 1 for item in IR_node.get_attr(\'shape\')]\n        if len(shape) == 4:\n            shape = [shape[i] for i in [0, 3, 1, 2]]\n        shape_str = \', \'.join(\'%s\' % i for i in shape)\n        self.add_body(1, ""{:15} = np.array([{}], dtype=np.int64)"".format(\n            IR_node.variable_name + \'_shape_array\',\n            shape_str\n        ))\n        self.add_body(1, ""{:15} = helper.make_node(\'Constant\', inputs=[], outputs=[\'{}\'], value=helper.make_tensor(name=\'const_tensor\', data_type=onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[{}.dtype], dims={}.shape, vals={}), name=\'{}\')"".format(\n                          IR_node.variable_name + \'_shape\',\n                          IR_node.variable_name + \'_shape\',\n                          IR_node.variable_name + \'_shape_array\',\n                          IR_node.variable_name + \'_shape_array\',\n                          IR_node.variable_name + \'_shape_array\',\n                          IR_node.variable_name + \'_shape\'))\n        self.add_body(1, ""{:15} = helper.make_node(\'Reshape\', inputs=[\'{}\', \'{}\'], outputs=[\'{}\'], name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name + \'_shape\',\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name + \'_shape\')\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_LRN(self, IR_node):\n        output_name = IR_node.variable_name\n        input_name = self.parent_variable_name(IR_node)\n        IR_name = IR_node.name\n        alpha = IR_node.get_attr(\'alpha\')\n        beta = IR_node.get_attr(\'beta\')\n        bias = IR_node.get_attr(\'bias\', 1.0)\n        size = IR_node.get_attr(\'size\')\n\n        self.add_body(1, ""{:15} = helper.make_node(\'LRN\', inputs=[\'{}\'], outputs=[\'{}\'], alpha={}, beta={}, bias={}, size={}, name=\'{}\')"".format(\n                          output_name,\n                          input_name,\n                          output_name,\n                          alpha,\n                          beta,\n                          bias,\n                          size,\n                          IR_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Relu6(self, IR_node):\n        self.add_body(1, ""{:15} = helper.make_node(\'Clip\', inputs=[\'{}\'], outputs=[\'{}\'], min=0.0, max=6.0, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_DepthwiseConv(self, IR_node):\n        self.emit_Conv(IR_node)\n\n    def emit_Slice(self, IR_node):\n        if self.IR_graph.get_parent(IR_node.name, [0]).type == \'Shape\':\n            pass\n        else:\n            starts = IR_node.get_attr(\'starts\')\n            starts = [starts[0], starts[-1]] + starts[1:-1]\n            ends = IR_node.get_attr(\'ends\')\n            ends = [ends[0], ends[-1]] + ends[1:-1]\n            ends = [i if i != 0 else sys.maxsize for i in ends]\n            self.add_body(1, ""{:15} = helper.make_node(\'Slice\', inputs=[\'{}\'], outputs=[\'{}\'], starts={}, ends={}, name=\'{}\')"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                IR_node.variable_name,\n                starts,\n                ends,\n                IR_node.variable_name))\n            self.nodes.append(IR_node.variable_name)\n\n    def emit_LeakyRelu(self, IR_node):\n        alpha = IR_node.get_attr(\'alpha\')\n        self.add_body(1, ""{:15} = helper.make_node(\'LeakyRelu\', inputs=[\'{}\'], outputs=[\'{}\'], alpha={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name,\n            alpha,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_PRelu(self, IR_node):\n      slope = IR_node.get_attr(\'gamma\')\n      self.add_body(1, ""{:15} = helper.make_node(\'PRelu\', inputs=[\'{}\'], outputs=[\'{}\'], slope={}, name=\'{}\')"".format(\n          IR_node.variable_name,\n          self.parent_variable_name(IR_node),\n          IR_node.variable_name,\n          slope,\n          IR_node.variable_name))\n      self.nodes.append(IR_node.variable_name)\n\n    def emit_SpaceToDepth(self, IR_node):\n        blocksize = IR_node.get_attr(\'blocksize\')\n        self.add_body(1, ""{:15} = helper.make_node(\'SpaceToDepth\', inputs=[\'{}\'], outputs=[\'{}\'], blocksize={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name,\n            blocksize,\n            IR_node.variable_name))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_Sigmoid(self, IR_node):\n        self.add_body(1, ""{: <15} = helper.make_node(\'Sigmoid\', inputs=[\'{}\'], outputs=[\'{}\'], name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.variable_name,\n            IR_node.variable_name\n        ))\n        self.nodes.append(IR_node.variable_name)\n\n    def emit_UNKNOWN(self, IR_node):\n        print(IR_node.IR_layer.name)\n'"
mmdnn/conversion/onnx/onnx_graph.py,0,"b'# ----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n# ----------------------------------------------------------------------------------------------\n\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\nfrom onnx import onnx_pb2\n\n\nclass ONNXGraphNode(GraphNode):\n    def __init__(self, layer):\n        super(ONNXGraphNode, self).__init__(layer)\n        self.weights = list()\n        self.inputs = list()\n        self.outputs = list()\n\n    @property\n    def name(self):\n        return self.layer.name\n\n    @property\n    def type(self):\n        return self.layer.op_type\n\n    @property\n    def onnx_layer(self):\n        return self.layer\n\n\n# node\n#  input\n#   edge(node a <-> node b)\n#\n\nclass ONNXGraph(Graph):\n    @staticmethod\n    def _generate_name(layer):\n        return """"\n\n    def __init__(self, model):\n        super(ONNXGraph, self).__init__(model)\n        self._graph = model.graph\n        # key is edge name, value is src/dst node name\n        self._edge_src = dict()\n        self._edge_dst = dict()\n        # key is initializer name, value is TensorProto\n        self._weights = dict()\n        self._inputs = dict()\n        self._outputs = dict()\n\n    def build(self):\n        for w in self._graph.initializer:\n            self._weights[w.name] = w\n        for s in self._graph.input:\n            self._inputs[s.name] = s\n        for s in self._graph.output:\n            self._outputs[s.name] = s\n\n        for i, layer in enumerate(self._graph.node):\n            if not layer.name:\n                layer.name = \'{0}_{1}\'.format(layer.op_type, i)\n            name = layer.name\n            # print(name)\n            # print(layer.op_type)\n            node = ONNXGraphNode(layer)\n            self.layer_map[name] = node\n            self.layer_name_map[name] = name\n            for n in layer.input:\n                if n in self._weights:\n                    # n is input data\n                    node.weights.append(n)\n                if n in self._inputs:\n                    node.inputs.append(n)\n                else:\n                    # n is input edge\n                    self._edge_dst[n] = name\n                    if n in self._edge_src:\n                        self._make_connection(self._edge_src[n], name)\n            for n in layer.output:\n                if n in self._outputs:\n                    node.outputs.append(n)\n                else:\n                    self._edge_src[n] = name\n                    if n in self._edge_dst:\n                        self._make_connection(name, self._edge_dst[n])\n\n        super(ONNXGraph, self).build()\n'"
mmdnn/conversion/onnx/onnx_parser.py,0,"b'# ----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n# ----------------------------------------------------------------------------------------------\n\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom mmdnn.conversion.onnx.onnx_graph import ONNXGraph\n\n\nclass ONNXParser(Parser):\n    skip_type = set()\n\n    @property\n    def src_graph(self):\n        return self.onnx_graph\n\n    @staticmethod\n    def _load_model(model_file):\n        """"""Load a ONNX model file from disk\n\n        Parameters\n        ----------\n        model_file: str\n            Path where the model file path is (protobuf file)\n\n        Returns\n        -------\n        model: A ONNX protobuf model\n        """"""\n        from onnx import onnx_pb2\n        from mmdnn.conversion.common.IR.IR_graph import load_protobuf_from_file\n\n        model = onnx_pb2.ModelProto()\n        load_protobuf_from_file(model, model_file)\n\n        print(""ONNX model file [%s] loaded successfully."" % model_file)\n        return model\n\n    def __init__(self, model_file):\n        super(ONNXParser, self).__init__()\n\n        model = ONNXParser._load_model(model_file)\n        self.onnx_graph = ONNXGraph(model)\n        self.onnx_graph.build()\n        self.weight_loaded = True\n\n    def rename_UNKNOWN(self, source_node):\n        if source_node.type in self.skip_type:\n            return\n        print(""ONNX has not supported operator [%s] with name [%s].""\n              % (source_node.type, source_node.name))\n        return\n\n    def gen_IR(self):\n        # if node len(in_edges), generate additional DataInput node\n\n        # print\n        for layer in self.src_graph.topological_sort:\n            current_node = self.src_graph.get_node(layer)\n            node_type = current_node.type\n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n            else:\n                self.rename_UNKNOWN(current_node)\n'"
mmdnn/conversion/onnx/saver.py,0,"b""import onnx\n\n\ndef save_model(MainModel, network_filepath, weight_filepath, dump_filepath):\n    model = MainModel.KitModel(weight_filepath)\n    onnx.save(model, dump_filepath)\n    print('ONNX model file is saved as [{}], generated by [{}.py] and [{}].'.format(\n        dump_filepath, network_filepath, weight_filepath))\n"""
mmdnn/conversion/onnx/shape_inference.py,0,"b'\ndef Add(shapeA, shapeB, axis = None, broadcast = None):\n    #do not deal\n    return shapeA\n\ndef AveragePool(shape, auto_pad = None, kernelShape = None, pads = None, strides = None):\n    #I don\'t want to deal with auto_pad\n   \n    if kernelShape is None:\n        kernelShape = [2 for _ in range(2)]\n\n    dim = len(kernelShape)\n\n    if pads is None:\n        pads = [1 for _ in range(dim * 2)]\n    if strides is None:\n        strides = [1 for _ in range(dim)]\n \n    retShape = shape[:-dim]\n    dimIdx = 0\n    for dimSize in shape[-dim:]:\n        padUpper = pads[dimIdx * 2]\n        padLower = pads[dimIdx * 2 + 1]\n        stride = strides[dimIdx]\n        kernelDimSize = kernelShape[dimIdx]\n        retShape.append((dimSize + padUpper + padLower - kernelDimSize) // stride + 1)\n        dimIdx = dimIdx + 1\n\n    return retShape\n\n\ndef BatchNormalization(shape, scale = None, B = None, mean = None, var = None):\n    return shape\n\ndef Concat(shapeList, axis):\n    newDimSize = sum([x[axis] for x in shapeList])\n    newShape = shapeList[0]  \n    newShape[axis] = newDimSize\n    return newShape\n\ndef Conv(shapeX, shapeW, auto_pad = None, dilations = None, group = None, kernel_shape = None, pads = None, strides = None):\n    #Don\'t support auto_pad current!\n    #                             2018-02-28\n    #if group is None:\n    #    group = 1\n    #  group is not support yet too.\n    kernelDim = len(shapeX) - 2\n    if kernel_shape is None:\n        kernel_shape = shapeW[2:] #[[1 for _ in range(kernelDimSize)] for _ in range(kernelDimSize)]\n    if pads is None:\n        [0 for _ in range(kernelDim * 2)]\n    if strides is None:\n        [1 for _ in range(kernelDim)]\n    if pads is None:\n        pads = [0 for _ in range(kernelDim * 2)]\n    if strides is None:\n        strides = [1 for _ in range(kernelDim)]\n    if dilations is None:\n        dilations = [1 for _ in range(kernelDim)]\n \n    retShape = [shapeX[0], shapeW[0]]  \n    dimIdx = 0\n    for dimSize in shapeX[2:]:\n        padUpper = pads[dimIdx * 2]\n        padLower = pads[dimIdx * 2 + 1]\n        stride = strides[dimIdx]\n        dilation = dilations[dimIdx]\n        kernelDimSize = (kernel_shape[dimIdx] - 1) // 2 * dilation * 2 + 1\n        retShape.append((dimSize + padUpper + padLower - kernelDimSize) // stride + 1)\n        dimIdx = dimIdx + 1\n    return retShape\n\ndef GlobalAveragePool(shapeX):\n    return shapeX[:2] + [1, 1]\n\ndef MaxPool(shape, auto_pad = None, kernelShape = None, pads = None, strides = None):\n    return AveragePool(shape, auto_pad, kernelShape, pads, strides)\n\ndef Mul(shapeX, shapeW, axis = None, broadcast = None):\n    return shapeX\n\ndef Relu(shape):\n    return shape\n\ndef FC(shapeX, shapeW, shapeB = None, axis = None, axis_w = None):\n    if axis is None:\n        axis = 1\n    if axis_w is None:\n        axis_w = 1\n    return [shapeX[0], shapeW[1]]\n\ndef Flatten(shapeT, axis = None):\n    if axis is None:\n        axis = 1\n\n    firstDim = 1\n    secondDim = 1\n    for i in range(len(shapeT)):\n        if i < axis:\n            firstDim *= shapeT[i]\n        else:\n            secondDim *= shapeT[i]\n    \n    if (axis > 0):\n        return [firstDim, secondDim]\n    else:\n        return [secondDim]\n\ninference_shape = {\n    \'Add\' : Add,\n    \'AveragePool\' : AveragePool,\n    \'BatchNormalization\' : BatchNormalization,\n    \'Concat\' : Concat,\n    \'Conv\' : Conv,\n    \'GlobalAveragePool\' : GlobalAveragePool,\n    \'MaxPool\' : MaxPool,\n    \'Mul\' : Mul,\n    \'Relu\' : Relu,\n    \'FC\' : FC,\n    \'Flatten\' : Flatten\n}\n\ndef testByLeNet(image_shape):\n    print(\'\\nLeNet output shape test:\')\n    print(\'input_image_shape is : \', image_shape)\n    convLay1 = [5, 5]\n    WLay1 = [6, -1, 5, 5]\n    outputLay1 = inference_shape[\'Conv\'](image_shape, WLay1, kernel_shape = convLay1)\n    print(\'1st Lay output shape is : \', outputLay1)  \n\n    poolLay2 = [2, 2]\n    stridesLay2 = [2, 2]\n    outputLay2 = inference_shape[\'AveragePool\'](outputLay1, strides = stridesLay2)\n    print(\'2nd Lay output shape is : \', outputLay2)\n\n    convLay3 = [5, 5]\n    WLay3 = [16, -1, 5, 5]\n    outputLay3 = inference_shape[\'Conv\'](outputLay2, WLay3, kernel_shape = convLay3)\n    print(\'3rd Lay output shape is : \', outputLay3)\n\n    poolLay4 = [2, 2]\n    stridesLay4 = [2, 2]\n    outputLay4 = inference_shape[\'AveragePool\'](outputLay3, strides = stridesLay4)\n    print(\'4th Lay output shape is : \', outputLay4)\n\n    convLay5 = [5, 5]\n    WLay5 = [120, -1, 5, 5]\n    outputLay5 = inference_shape[\'Conv\'](outputLay4, WLay5)\n    print(\'5th Lay output shape is : \', outputLay5)\n    \n    outputLay5Flatten = inference_shape[\'Flatten\'](outputLay5)\n    WLay6 = [-1, 84]\n    outputLay6 = inference_shape[\'FC\'](outputLay5Flatten, WLay6)\n    print(\'6th Lay output shape is : \', outputLay6)\n\n    WLay7 = [-1, 10]\n    outputLay7 = inference_shape[\'FC\'](outputLay6, WLay7)\n    print(\'7th Lay output shape is : \', outputLay7)\n    return outputLay7\n\n\nif __name__ == \'__main__\':\n\n    shape = [1, 9, 9, 9]\n\n    print(\'input shape is  : \', shape)\n    print(\'output shape is : \', AveragePool(shape, pads=[1,1,1,1], strides=[2,2]))\n    print(inference_shape[\'AveragePool\'](shape, pads=[1,1,1,1], kernelShape=[2,2], strides=[2,2]));\n\n    print(\'input shape is  : \', shape)\n    print(\'output shape is : \', AveragePool(shape, pads=[0,0,0,0], kernelShape=[3,3], strides=[3,3]))\n\n    shape = [3, 9, 9]\n    print(\'input shape is  : \', shape)\n    print(\'output shape is : \', AveragePool(shape))\n\n\n    x = [1, 1, 5, 5]\n    W = [1, 1, 3, 3]\n    print(\'input shapeX is :\', x, \'input shapeW is :\', W)\n    print(\'output shape is :\', Conv(x, W), ""without pads"")\n\n    W = [2, 1, 3, 3]\n    print(\'input shapeX is :\', x, \'input shapeW is :\', W)\n    print(\'output shape is :\', Conv(x, W, pads=[1,1,1,1]), \'pads is [1, 1, 1, 1]\')\n\n\n    shape1 = [1, 1, 3, 3]\n    shape2 = [1, 3, 3, 3]\n    shape3 = [1, 5, 3, 3]\n    print(\'output shape is :\', Concat([shape1, shape2, shape3], 1))\n\n    shape = [5, 5, 5, 5]\n    print(""output shape is :"", GlobalAveragePool(shape))\n    \n    print(\'LeNet-5 output shape is : \', testByLeNet(image_shape = [-1, 1, 32, 32]))\n    print(\'LeNet-5 output shape is : \', testByLeNet(image_shape = [5, 1, 32, 32]))\n\n\n\n'"
mmdnn/conversion/paddle/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/paddle/paddle_graph.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\nimport os\nimport paddle.v2 as paddle\nimport paddle.trainer_config_helpers.layers as layers\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\n\n\nclass PaddleGraphNode(GraphNode):\n\n    def __init__(self, layer):\n        super(PaddleGraphNode, self).__init__(layer)\n\n\n    @property\n    def name(self):\n        return self.layer.name\n\n\n    @property\n    def type(self):\n        return self.layer.type\n\n\n    @property\n    def paddle_layer(self):\n        return self.layer\n\n\n\nclass PaddleGraph(Graph):\n\n    def __init__(self, model):\n        from paddle.proto import ModelConfig_pb2\n        # sanity check.\n        if not isinstance(model, ModelConfig_pb2.ModelConfig):\n            raise TypeError(""PaddlePaddle layer of type %s is not supported."" % type(model))\n        super(PaddleGraph, self).__init__(model)\n        self.model = model\n\n\n    def build(self):\n        self.input_layers = list()\n        for layer in self.model.layers:\n            self.layer_map[layer.name] = PaddleGraphNode(layer)\n            self.layer_name_map[layer.name] = layer.name\n\n            for input_layer in layer.inputs:\n                self._make_connection(input_layer.input_layer_name, layer.name)\n\n        super(PaddleGraph, self).build()'"
mmdnn/conversion/paddle/paddle_parser.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\n\nimport os\nimport gzip\nfrom six import string_types as _string_types\nimport paddle.v2 as paddle\nimport paddle.trainer_config_helpers.layers as layers\nimport numpy as np\nfrom mmdnn.conversion.paddle.paddle_graph import PaddleGraph\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom mmdnn.conversion.common.utils import *\n\n\nclass PaddleParser(Parser):\n\n    dtype_map = {\n        ""float16"" : graph_pb2.DT_FLOAT16,\n        ""float32"" : graph_pb2.DT_FLOAT32,\n        ""float64"" : graph_pb2.DT_FLOAT64,\n        ""int16""   : graph_pb2.DT_INT16,\n        ""int32""   : graph_pb2.DT_INT32,\n        ""int64""   : graph_pb2.DT_INT64,\n        ""uint8""   : graph_pb2.DT_UINT8,\n        ""uint16""  : graph_pb2.DT_UINT16\n    }\n\n    activation_map = {\n        ""relu""          : ""Relu"",\n        \'softmax\'       : ""Softmax"",\n        \'sigmoid\'       : ""Sigmoid"",\n        ""tanh""          : ""Tanh"",\n        ""elu""           : ""Elu"",\n        ""relu6""         : ""Relu6"",\n        \'softplus\'      : \'Softplus\',\n        \'softsign\'      : \'Softsign\',\n        \'hard_sigmoid\'  : \'HardSigmoid\'\n    }\n\n    layer_map = {\n        ""data""          : ""InputLayer"",\n        ""exconv""        : ""Conv"",\n        ""addto""         : ""Add"",\n        ""batch_norm""    : ""BatchNormalization"",\n        ""pool""          : ""Pooling"",\n        ""fc""            : ""Dense"",\n        ""norm""          : ""LRN"",\n\n\n    }\n\n\n    def _load_model(self, model_network_path, model_weight_path):\n        """"""Load a paddle model from disk\n\n        Parameters\n        ----------\n        model_network_path: str\n            Path where the model network path is (json file)\n\n        model_weight_path: str\n            Path where the model network weights are (hd5 file)\n\n        Returns\n        -------\n        model: A paddle model\n        """"""\n        from paddle.proto import ModelConfig_pb2\n        from mmdnn.conversion.common.IR.IR_graph import load_protobuf_from_file\n\n        loaded_model = ModelConfig_pb2.ModelConfig()\n        load_protobuf_from_file(loaded_model, model_network_path)\n\n        if model_weight_path:\n            if os.path.isfile(model_weight_path):\n                parameters = paddle.parameters.Parameters.from_tar(gzip.open(model_weight_path, \'r\'))\n                self.weight_loaded = True\n                print(""Network file [{}] and [{}] is loaded successfully."".format(model_network_path, model_weight_path))\n\n            else:\n                print(""Warning: Weights File [%s] is not found."" % (model_weight_path))\n\n        return loaded_model, parameters\n\n    @property\n    def src_graph(self):\n        return self.paddle_graph\n\n\n    def __init__(self, model):\n        super(PaddleParser, self).__init__()\n\n        if isinstance(model, tuple):\n            model_network_path, model_weight_path = model\n\n        # Build network graph\n        model, parameters = self._load_model(model_network_path, model_weight_path)\n        self.paddle_graph = PaddleGraph(model)\n        self.paddle_graph.build()\n        self.parameters = parameters\n        self.shape_dict = dict()\n\n\n\n\n\n    def gen_IR(self):\n\n        for layer in self.paddle_graph.topological_sort:\n            current_node = self.paddle_graph.get_node(layer)\n            node_type = PaddleParser.layer_map[current_node.type]\n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n            else:\n                print(""PaddleParser has not supported operator [%s]."" % (node_type))\n                self.rename_UNKNOWN(current_node)\n\n\n\n    @staticmethod\n    def _set_output_shape(source_node, IR_node, output_shapes):\n        shape = graph_pb2.TensorShape()\n        for output_shape in output_shapes:\n            new_dim = shape.dim.add()\n            new_dim.size = output_shape\n        IR_node.attr[""_output_shapes""].list.shape.extend([shape])\n\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op = None):\n        IR_node.name = source_node.name.lstrip(\'_\')\n        IR_node.op = source_node.type if new_op == None else new_op\n\n        if hasattr(source_node.layer, ""dtype""):\n            IR_node.attr[""dtype""].type = PaddleParser.dtype_map[source_node.layer.dtype]\n\n        # PaddleParser._set_output_shape(source_node, IR_node)\n\n\n    @staticmethod\n    def _copy_shape(source_node, target_node, output_shapes):\n        for dim in output_shapes:\n            new_dim = target_node.attr[""shape""].shape.dim.add()\n            new_dim.size =  dim\n\n\n    @staticmethod\n    def _convert_dataformat(source_node, target_node):\n        if source_node.keras_layer.data_format == \'channels_last\':\n            target_node.attr[""data_format""].s = ""NHWC""\n        elif source_node.keras_layer.data_format == \'channels_first\':\n            target_node.attr[""data_format""].s = ""NCHW""\n        else:\n            print(""Warning: [%s] don\'t have data format info."" % (source_node.keras_layer.name))\n\n\n\n\n    def _defuse_activation(self, source_node):\n        src_spec = source_node.layer\n\n        IR_node = self.IR_graph.node.add()\n        IR_node.name = source_node.real_name.lstrip(\'_\') + ""_activation""\n        IR_node.op = PaddleParser.activation_map[src_spec.active_type.encode()]\n        IR_node.input.append(source_node.real_name.lstrip(\'_\'))\n\n        source_node.real_name = IR_node.name\n        return IR_node\n\n\n\n    def _convert_merge(self, source_node, new_name = None):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        PaddleParser._copy_and_reop(source_node, IR_node, new_name)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # For concat axis\n        if hasattr(source_node.layer, \'axis\'):\n            IR_node.attr[\'axis\'].i = -1\n        return IR_node\n\n\n\n    def rename_UNKNOWN(self, source_node):\n        print (source_node.layer.get_config())\n\n        # only for training\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        PaddleParser._copy_and_reop(source_node, IR_node)\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n\n    def rename_Conv(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # layer and spec\n        conv_spec = source_node.layer\n\n        spec = conv_spec.inputs[0].conv_conf\n\n        # width <=> x or height <=> y\n        width = spec.filter_size\n        height = spec.filter_size_y if spec.HasField(\'filter_size_y\') else spec.filter_size\n        inputchannel = spec.channels\n        outputchannel = conv_spec.num_filters\n        stride_x = spec.stride\n        stride_y = spec.stride_y if spec.HasField(\'stride_y\') else stride_x\n        padding_x = spec.padding\n        padding_y = spec.padding_y if spec.HasField(\'padding_y\') else padding_x\n        dilation_x = spec.dilation\n        dilation_y = spec.dilation_y if spec.HasField(\'dilation_y\') else dilation_x\n        output_x = spec.output_x\n        output_y = spec.output_y if spec.HasField(\'output_y\') else output_x\n        input_x = spec.img_size\n        input_y = spec.img_size_y if spec.HasField(\'img_size_y\') else input_x\n\n\n        # output shape\n        output_shapes = [-1, output_y, output_x, outputchannel]\n        self.shape_dict[source_node.name] = output_shapes\n        PaddleParser._set_output_shape(source_node, IR_node, output_shapes)\n\n\n        kwargs = dict()\n\n        if conv_spec.type == \'exconv\' or \'cudnn_conv\':\n            # name, op\n            PaddleParser._copy_and_reop(source_node, IR_node, ""Conv"")\n        else:\n            kwargs[\'isDeconvolution\'] = True\n            PaddleParser._copy_and_reop(source_node, IR_node, ""ConvTranspose"")\n\n\n        w_name = conv_spec.inputs[0].input_parameter_name\n        w = self.parameters.get(w_name)\n\n\n        self.set_weight(IR_node.name, \'weights\', w.reshape([outputchannel, inputchannel, height, width]).transpose([ 2, 3, 1, 0]))\n\n        #  it should be in the shape of height x width x inputchannel x outputchannel\n\n        # use_bias: TODO\n        kwargs[\'use_bias\'] = False\n        if conv_spec.HasField(\'bias_parameter_name\'):\n            bias_name = conv_spec.bias_parameter_name\n            bias = self.parameters.get(bias_name).squeeze()\n            self.set_weight(IR_node.name, ""bias"", bias)\n            kwargs[\'use_bias\'] = True\n\n\n\n        kwargs[\'kernel_shape\'] = [height, width, inputchannel, outputchannel]\n\n\n\n        # pad_dim\n        pad_dim = [0, 0, padding_x, padding_y, padding_x, padding_y, 0, 0]\n\n        # fail report because of auto_pad\n        # if dilation_x == 1 and dilation_y == 1:\n        #     if output_x * stride_x == input_x and output_y * stride_y == input_y:\n        #         auto_pad = ""SAME""\n        #         kwargs[\'auto_pad\'] = auto_pad\n        #     elif output_x * stride_x == input_x - width + 1 and output_y * stride_y == input_y - height + 1:\n        #         auto_pad = ""VALID""\n        #         kwargs[\'auto_pad\'] = auto_pad\n\n        if input_x == output_x and input_y == output_y:\n            auto_pad = ""SAME""\n        else:\n            auto_pad = ""SAME""\n\n        pad_dim = convert_tf_pad_to_onnx(pad_dim)\n        kwargs[\'pads\'] = pad_dim\n\n        kwargs[\'group\'] = spec.groups\n\n        kwargs[\'dilation\'] = [1, dilation_x, dilation_y, 1]\n\n        kwargs[\'strides\'] = [1, stride_x, stride_y, 1]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n        # defuse the activation layer\n\n        if conv_spec.HasField(\'active_type\') and  conv_spec.active_type != \'\':\n            IR_node_act = self._defuse_activation(source_node)\n            PaddleParser._set_output_shape(source_node, IR_node_act, output_shapes)\n\n\n    def rename_BatchNormalization(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        PaddleParser._copy_and_reop(source_node, IR_node, ""BatchNorm"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # layer and spec\n        bn_spec = source_node.layer\n\n\n\n        # output shape\n        if  bn_spec.inputs[0].HasField(""image_conf""):\n            img_conf = bn_spec.inputs[0].image_conf\n            output_x = img_conf.img_size\n            output_y = img_conf.img_size_y if img_conf.HasField(\'img_size_y\') else output_x\n            outputchannel = img_conf.channels\n\n            output_shapes = [-1, output_y, output_x, outputchannel]\n            self.shape_dict[source_node.name] = output_shapes\n            PaddleParser._set_output_shape(source_node, IR_node, output_shapes)\n\n\n        IR_node.attr[\'scale\'].b = True\n        IR_node.attr[\'bias\'].b = bn_spec.HasField(\'bias_parameter_name\')\n\n        w_name = bn_spec.inputs[0].input_parameter_name\n        mean_name = bn_spec.inputs[1].input_parameter_name\n        var_name = bn_spec.inputs[2].input_parameter_name\n        bias_name = bn_spec.bias_parameter_name\n\n        gamma = self.parameters.get(w_name)\n        mean = self.parameters.get(mean_name)\n        variance = self.parameters.get(var_name)\n        beta = self.parameters.get(bias_name)\n\n        # channels_first, then axis = 1\n        IR_node.attr[\'axis\'].i = -1\n\n        # epsilon\n        IR_node.attr[\'epsilon\'].f = bn_spec.epsilon\n\n        # compute adjusted parameters\n        # Reference: parameter transformation https://github.com/apple/coremltools/issues/153\n        f = 1.0 / np.sqrt(variance +  bn_spec.epsilon)\n        gamma1 = gamma*f\n        beta1 = beta - gamma*mean*f\n        mean[:] = 0.0 #mean\n        variance[:] = 1.0 - .00001 #stddev\n\n        # convert type because of tensorflow\n        gamma1 = gamma1.astype(np.float32)\n        beta1 = beta1.astype(np.float32)\n        mean = mean.astype(np.float32)\n        variance = variance.astype(np.float32)\n\n        # flatten\n        gamma1 = gamma1.flatten()\n        beta1 = beta1.flatten()\n        mean = mean.flatten()\n        variance = variance.flatten()\n\n\n\n        if IR_node.attr[\'scale\'].b:\n            self.set_weight(IR_node.name, ""scale"", gamma1)\n\n        if IR_node.attr[\'bias\'].b:\n            self.set_weight(IR_node.name, ""bias"", beta1)\n\n        # mean\n        self.set_weight(IR_node.name, ""mean"", mean)\n\n        # var\n        self.set_weight(IR_node.name, ""var"", variance)\n\n        # defuse the activation layer\n\n        if bn_spec.HasField(\'active_type\') and  bn_spec.active_type != \'\':\n            IR_node_act = self._defuse_activation(source_node)\n            if  bn_spec.inputs[0].HasField(""image_conf""):\n                PaddleParser._set_output_shape(source_node, IR_node_act, output_shapes)\n\n\n\n    def rename_Pooling(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        PaddleParser._copy_and_reop(source_node, IR_node, ""Pool"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # layer and spec\n        pool_spec = source_node.layer\n        spec = pool_spec.inputs[0].pool_conf\n\n\n\n        # assert False\n        kwargs = dict()\n\n        if spec.pool_type == \'max-projection\':\n            kwargs[\'pooling_type\'] = \'MAX\'\n        elif spec.pool_type == \'avg-projection\':\n            kwargs[\'pooling_type\'] = \'AVG\'\n        else:\n            kwargs[\'pooling_type\'] = \'MAX\'\n\n\n\n        width = spec.size_x\n        height = spec.size_y if spec.HasField(\'size_y\') else width\n        channel = spec.channels\n        stride_x = spec.stride\n        stride_y = spec.stride_y if spec.HasField(\'stride_y\') else stride_x\n        padding_x = spec.padding\n        padding_y = spec.padding_y if spec.HasField(\'padding_y\') else padding_x\n        output_x = spec.output_x\n        output_y = spec.output_y if spec.HasField(\'output_y\') else output_x\n        input_x = spec.img_size\n        input_y = spec.img_size_y if spec.HasField(\'img_size_y\') else input_x\n\n\n        # output shape\n        output_shapes = [-1, output_y, output_x, channel]\n        self.shape_dict[source_node.name] = output_shapes\n        PaddleParser._set_output_shape(source_node, IR_node, output_shapes)\n\n\n        kwargs[\'global_pooling\'] = False\n\n        kwargs[\'strides\'] = [1, stride_x, stride_y, 1]\n        kwargs[\'kernel_shape\'] = [1, width, height, 1]\n\n        # pad_dim\n        pad_dim = [0, 0, padding_x, padding_y, padding_x, padding_y, 0, 0]\n\n\n        # padding mode\n        # If padding == ""SAME"": output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])\n        # If padding == ""VALID"": output_spatial_shape[i] = ceil((input_spatial_shape[i] - (spatial_filter_shape[i]-1) * dilation_rate[i]) / strides[i]).\n\n        if output_x * stride_x == input_x and output_y * stride_y == input_y:\n            auto_pad = ""SAME""\n            kwargs[\'auto_pad\'] = auto_pad\n        elif output_x * stride_x == input_x - width + 1 and output_y * stride_y == input_y - height + 1:\n            auto_pad = ""VALID""\n            kwargs[\'auto_pad\'] = auto_pad\n\n        pad_dim = convert_tf_pad_to_onnx(pad_dim)\n        kwargs[\'pads\'] = pad_dim\n\n\n\n        assign_IRnode_values(IR_node, kwargs)\n\n        if pool_spec.HasField(\'active_type\') and  pool_spec.active_type != \'\':\n            IR_node_act = self._defuse_activation(source_node)\n            PaddleParser._set_output_shape(source_node, IR_node_act, output_shapes)\n\n\n    def rename_Dense(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        PaddleParser._copy_and_reop(source_node, IR_node, ""FullyConnected"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # layer and spec\n        fc_spec = source_node.layer\n\n\n        # units\n        IR_node.attr[\'units\'].i = fc_spec.size\n\n\n        # output shape\n        output_shapes = [-1, fc_spec.size]\n        self.shape_dict[source_node.name] = output_shapes\n        PaddleParser._set_output_shape(source_node, IR_node, output_shapes)\n\n\n        # use_bias\n        IR_node.attr[\'use_bias\'].b = fc_spec.HasField(\'bias_parameter_name\')\n\n        w_name = fc_spec.inputs[0].input_parameter_name\n        bias_name = fc_spec.bias_parameter_name\n\n        w = self.parameters.get(w_name)\n\n        bias = self.parameters.get(bias_name).flatten()\n\n        # Kit weight tranpose\n        # weight: N x M -> C x H x W x M -> H x W x C x M -> N x M\n        if self.weight_loaded:\n            parent = self.src_graph.get_parent(source_node.name, [0])\n            if len(self.shape_dict[parent.name]) == 4:\n                #\n                original_shape = w.shape\n                channel_first_list = self.shape_dict[parent.name][1:]\n                dim = len(channel_first_list) + 1\n                weight = w.reshape(channel_first_list + [original_shape[1]])\n                assert dim > 2\n                weight = weight.transpose(list(range(1, dim-1)) + [0, dim-1])\n                w = weight.reshape(original_shape)\n        if fc_spec.HasField(\'drop_rate\'):\n            w = w * fc_spec.drop_rate\n            if IR_node.attr[\'use_bias\'].b:\n                bias = bias * fc_spec.drop_rate\n\n\n        # weights\n        self.set_weight(IR_node.name, \'weights\', w)\n        if IR_node.attr[\'use_bias\'].b:\n            self.set_weight(IR_node.name, \'bias\', bias)\n\n        if fc_spec.HasField(\'active_type\') and  fc_spec.active_type != \'\':\n            IR_node_act = self._defuse_activation(source_node)\n            PaddleParser._set_output_shape(source_node, IR_node_act, output_shapes)\n\n\n\n\n\n\n    def rename_Add(self, source_node):\n        add_spec = source_node.layer\n        self._convert_merge(source_node, \'Add\')\n        if add_spec.HasField(\'active_type\') and  add_spec.active_type != \'\':\n            self._defuse_activation(source_node)\n\n\n    def rename_InputLayer(self, source_node):\n        # need the shape TODO\n\n        # only for training\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        PaddleParser._copy_and_reop(source_node, IR_node, ""DataInput"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        output_shapes = [-1, 224, 224, 3]\n        # shape\n        PaddleParser._copy_shape(source_node.layer, IR_node, output_shapes)\n\n\n    def rename_LRN(self, source_node):\n        IR_node = self.IR_graph.node.add()\n\n        # name, op\n        PaddleParser._copy_and_reop(source_node, IR_node, ""LRN"")\n\n        # input edge\n        self.convert_inedge(source_node, IR_node)\n\n        # layer and spec\n        lrn_spec = source_node.layer\n        spec = lrn_spec.inputs[0].norm_conf\n        channels = spec.channels\n        size = spec.size\n        alpha = spec.scale\n        beta = spec.pow\n        img_size_x = spec.img_size\n        img_size_y = spec.img_size_y if spec.HasField(\'img_size_y\') else img_size_x\n        output_x = spec.output_x\n        output_y = spec.output_y if spec.HasField(\'output_y\') else output_x\n\n\n        # output shape\n        output_shapes = [-1, output_y, output_x, channels]\n        self.shape_dict[source_node.name] = output_shapes\n        PaddleParser._set_output_shape(source_node, IR_node, output_shapes)\n\n        # alpha\n        IR_node.attr[""alpha""].f = alpha * size\n        # beta\n        IR_node.attr[""beta""].f = beta\n        # nsize\n        IR_node.attr[""size""].i = int(size)\n\n\n        if lrn_spec.HasField(\'active_type\') and  lrn_spec.active_type != \'\':\n            IR_node_act = self._defuse_activation(source_node)\n            PaddleParser._set_output_shape(source_node, IR_node_act, output_shapes)\n\n\n'"
mmdnn/conversion/pytorch/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/pytorch/pytorch_emitter.py,50,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\nimport numpy as np\nfrom six import string_types as _string_types\nfrom mmdnn.conversion.common.IR.IR_graph import IRGraph, IRGraphNode\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.emitter import Emitter\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.rewriter.folder import Folder\n\nclass PytorchEmitter(Emitter):\n\n    dtype_map = {\n        graph_pb2.DT_FLOAT16 : ""torch.float16"",\n        graph_pb2.DT_FLOAT32 : ""torch.float32"",\n        graph_pb2.DT_FLOAT64 : ""torch.float64"",\n        graph_pb2.DT_INT16 : ""torch.int16"",\n        graph_pb2.DT_INT32 : ""torch.int32"",\n        graph_pb2.DT_INT64 : ""torch.int64"",\n        graph_pb2.DT_UINT8 : ""torch.uint8"",\n        graph_pb2.DT_UINT16 : ""torch.uint16""\n    }\n\n    # Base Functions\n    def __init__(self, model):\n        super(PytorchEmitter, self).__init__()\n        if isinstance(model, _string_types):\n            network_path = model\n        else:\n            network_path = model[0]\n            weight_path = model[1]\n\n        self.init_code = str()\n        self.IR_graph = IRGraph(network_path)\n        self.IR_graph.build()\n        self._load_weights(weight_path)\n\n        folder = Folder(self.IR_graph, self.weights_dict)\n        folder.fold()\n\n    def run(self, dstNetworkPath, dstWeightPath = None, phase = \'test\'):\n        super(PytorchEmitter, self).run(dstNetworkPath, dstWeightPath, phase)\n        if self.weight_loaded:\n            self.save_weights(self.weights_dict, dstWeightPath)\n\n\n    def add_init(self, indent, codes):\n        if isinstance(codes, _string_types):\n            codes = [codes]\n        for code in codes:\n            self.init_code += (""    "" * indent) + code + \'\\n\'\n\n    def parent_variable_name(self, IR_node, path=[0], weight_type=\'weights\'):\n        if not IR_node.in_edges and IR_node.name in self.weights_dict.keys():\n            self.weights_dict[IR_node.name][weight_type] = self.weights_dict[IR_node.name][weight_type]\n            return ""torch.from_numpy(__weights_dict[\'{}\'][\'{}\'])"".format(IR_node.name, weight_type)\n\n        return super(PytorchEmitter, self).parent_variable_name(IR_node, path)\n\n\n    @property\n    def header_code(self):\n        return """"""import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n__weights_dict = dict()\n\ndef load_weights(weight_file):\n    if weight_file == None:\n        return\n\n    try:\n        weights_dict = np.load(weight_file, allow_pickle=True).item()\n    except:\n        weights_dict = np.load(weight_file, allow_pickle=True, encoding=\'bytes\').item()\n\n    return weights_dict\n\nclass KitModel(nn.Module):\n""""""\n\n    def gen_code(self, phase):\n        self.add_init(1, """"""\n    def __init__(self, weight_file):\n        super(KitModel, self).__init__()\n        global __weights_dict\n        __weights_dict = load_weights(weight_file)\n"""""")\n\n        self.add_body(1, ""def forward(self, x):"")\n\n        for layer in self.IR_graph.topological_sort:\n            current_node = self.IR_graph.get_node(layer)\n            node_type = current_node.type\n\n            if hasattr(self, ""emit_"" + node_type):\n                func = getattr(self, ""emit_"" + node_type)\n                line = func(current_node)\n                if line:\n                    self.add_body(2, line)\n\n            else:\n                print(""Pytorch Emitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(current_node)\n\n        self.add_body(2, ""return {}"".format(\n            \', \'.join([self.IR_graph.get_node(name).real_variable_name for name in self.IR_graph.output_layers if self.IR_graph.get_node(name).type != \'Pack\'])))\n\n        self.add_body(0, """")\n        for i in self.used_layers:\n            func = getattr(self, ""_layer_"" + i)\n            func()\n\n        self.add_body(0, """")\n        for code in self.layers_codes.values():\n            self.add_body(0, code)\n\n        return self.header_code + \'\\n\' + self.init_code + \'\\n\' + self.body_code\n\n\n    def _defuse_padding(self, IR_node, extra_str = """"):\n        input_node = self.parent_variable_name(IR_node)\n        if IR_node.get_attr(\'auto_pad\') == \'VALID\':\n            return input_node\n\n        if is_valid_padding(IR_node.get_attr(""pads"")) == True:\n            return input_node\n\n        padding = self._convert_padding(IR_node)\n        input_node = IR_node.variable_name + \'_pad\'\n        self.add_body(2, ""{:<15} = F.pad({}, {}{})"".format(\n            input_node,\n            self.parent_variable_name(IR_node),\n            padding,\n            extra_str\n        ))\n\n        return input_node\n\n\n    def emit_Conv(self, IR_node):\n        self.used_layers.add(\'Conv\')\n\n        dim = len(IR_node.get_attr(\'strides\')) - 2\n\n        in_channels = IR_node.get_attr(\'kernel_shape\')[-2]\n        filter = IR_node.get_attr(\'kernel_shape\')[-1]\n        kernel = IR_node.get_attr(\'kernel_shape\')[:-2]\n        strides = IR_node.get_attr(\'strides\')[1:-1]\n\n        if IR_node.type == \'DepthwiseConv\':\n            group = in_channels\n            filter *= group\n\n        else:\n            group = IR_node.get_attr(\'group\', 1)\n\n        self.add_init(2, ""self.{} = self.__conv({}, name=\'{}\', in_channels={}, out_channels={}, kernel_size={}, stride={}, groups={}, bias={})"".format(\n            IR_node.variable_name,\n            dim,\n            IR_node.name,\n            in_channels,\n            filter,\n            tuple(kernel),\n            tuple(strides),\n            # padding,\n            group,\n            IR_node.get_attr(\'use_bias\')))\n\n        input_node = self._defuse_padding(IR_node)\n\n        code = ""{:<15} = self.{}({})"".format(\n            IR_node.variable_name,\n            IR_node.variable_name,\n            input_node)\n\n        if self.weight_loaded:\n            if IR_node.type == \'DepthwiseConv\':\n                self.weights_dict[IR_node.name][\'weights\'] = np.swapaxes(self.weights_dict[IR_node.name][\'weights\'], -1, -2)\n            self.weights_dict[IR_node.name][\'weights\'] = np.transpose(self.weights_dict[IR_node.name][\'weights\'], [dim + 1, dim] + list(range(0, dim)))\n\n        return code\n\n\n    @staticmethod\n    def is_ceil_mode(pads):\n        lens = len(pads)\n        for i in range(lens // 2 + 1, lens - 1):\n            if pads[i] == pads[i - lens // 2]:\n                return False\n        else:\n            return True\n\n\n    def emit_Pool(self, IR_node):\n        dim = len(IR_node.get_attr(\'strides\')) - 2\n\n        if IR_node.get_attr(\'pooling_type\') == ""MAX"":\n            pool_name = ""max_pool{}d"".format(dim)\n            # exstr = "", value=float(\'-Inf\')""\n        elif IR_node.get_attr(\'pooling_type\') == ""AVG"":\n            pool_name = ""avg_pool{}d"".format(dim)\n            # exstr = """"\n        else:\n            raise ValueError()\n\n        if IR_node.layer.attr[\'global_pooling\'].b:\n            code = ""{:<15} = F.{}(input = {}, kernel_size = {}.size()[2:])"".format(\n                IR_node.variable_name,\n                pool_name,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node)\n            )\n            return code\n\n        else:\n            if IR_node.get_attr(\'pooling_type\') == ""MAX"":\n                # Change to padding defuse\n                input_node = self._defuse_padding(IR_node,"", value=float(\'-inf\')"")\n                for e in IR_node.get_attr(\'dilations\', []):\n                    assert e == 1\n\n                pool_size = IR_node.get_attr(\'kernel_shape\')[1:-1]\n                strides = IR_node.get_attr(\'strides\')[1:-1]\n\n                code = ""{}, {}_idx = F.{}({}, kernel_size={}, stride={}, padding={}, ceil_mode={}, return_indices={})"".format(\n                    IR_node.variable_name,\n                    IR_node.variable_name,\n                    pool_name,\n                    input_node,\n                    tuple(pool_size),\n                    tuple(strides),\n                    0,\n                    False,\n                    True\n                    )\n                return code\n\n            elif IR_node.get_attr(\'pooling_type\') == ""AVG"":\n\n                for e in IR_node.get_attr(\'dilations\', []):\n                    assert e == 1\n\n                pool_size = IR_node.get_attr(\'kernel_shape\')[1:-1]\n                strides = IR_node.get_attr(\'strides\')[1:-1]\n\n                padding = IR_node.get_attr(\'pads\')[1:dim]\n                ceil_mode = self.is_ceil_mode(IR_node.get_attr(\'pads\'))\n\n                # input_node = self._defuse_padding(IR_node, exstr)\n                code = ""{:<15} = F.{}({}, kernel_size={}, stride={}, padding={}, ceil_mode={}, count_include_pad=False)"".format(\n                    IR_node.variable_name,\n                    pool_name,\n                    self.parent_variable_name(IR_node),\n                    tuple(pool_size),\n                    tuple(strides),\n                    tuple(padding),\n                    ceil_mode\n                    )\n                return code\n            else:\n                raise ValueError()\n\n    def emit_Unpool(self, IR_node):\n        dim = len(IR_node.get_attr(\'strides\')) - 2\n\n        # Change to padding defuse\n        input_node = self.parent_variable_name(IR_node)\n        index_node = self.parent_variable_name(IR_node,[1])\n        pool_name = ""max_unpool{}d"".format(dim)\n        pool_size = IR_node.get_attr(\'kernel_shape\')[1:-1]\n        strides = IR_node.get_attr(\'strides\')[1:-1]\n\n        code = ""{:<15} = F.{}({},{}_idx, kernel_size={}, stride={}, padding={})"".format(\n            IR_node.variable_name,\n            pool_name,\n            input_node,\n            index_node,\n            tuple(pool_size),\n            tuple(strides),\n            0\n            )\n        return code\n\n\n    def emit_UNKNOWN(self, IR_node):\n        print(IR_node.name)\n\n\n    def emit_DataInput(self, IR_node):\n        # Ignore it in Pytorch\n        IR_node.real_name = \'x\'\n\n\n    def emit_Dropout(self, IR_node):\n        code = ""{:<15} = F.dropout(input = {}, p = {}, training = self.training, inplace = True)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.layer.attr[""keep_prob""].f)\n        return code\n\n\n    def check_if_need_transpose(self, IR_node):\n        parent = self.IR_graph.get_parent(IR_node.name, [0])\n        while parent.type == \'Flatten\' or parent.type == \'Dropout\':\n            parent = self.IR_graph.get_parent(parent.name, [0])\n        dim = len(parent.layer.attr[\'_output_shapes\'].list.shape[0].dim)\n        if dim > 2:\n            original_dims = self.weights_dict[IR_node.name][\'weights\'].shape\n            dims = [i.size for i in parent.layer.attr[\'_output_shapes\'].list.shape[0].dim[1:]] + [-1]\n            self.weights_dict[IR_node.name][\'weights\'] = np.reshape(self.weights_dict[IR_node.name][\'weights\'], dims)\n            self.weights_dict[IR_node.name][\'weights\'] = np.transpose(self.weights_dict[IR_node.name][\'weights\'], [dim - 2] + list(range(0, dim - 2)) + [dim - 1])\n            self.weights_dict[IR_node.name][\'weights\'] = np.reshape(self.weights_dict[IR_node.name][\'weights\'], original_dims)\n\n\n    def emit_FullyConnected(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        in_features = 1\n        for i in self.IR_graph.get_parent(IR_node.name, [0]).layer.attr[\'_output_shapes\'].list.shape[0].dim[1:]:\n            in_features *= i.size\n\n        if IR_node.get_attr(\'in_features\') != None:\n            in_features = IR_node.get_attr(\'in_features\')\n\n        self.add_init(2, ""self.{} = self.__dense(name = \'{}\', in_features = {}, out_features = {}, bias = {})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            in_features,\n            IR_node.layer.attr[""units""].i,\n            IR_node.IR_layer.attr[""use_bias""].b))\n\n        input_node = self.parent_variable_name(IR_node)\n        if len(self.IR_graph.get_parent(IR_node.name, [0]).get_attr(\'_output_shapes\')[0].dim) > 2:\n            input_node = ""{}.view({}.size(0), -1)"".format(input_node, input_node)\n        \n        code = ""{:<15} = self.{}({})"".format(\n            IR_node.variable_name,\n            IR_node.variable_name,\n            input_node)\n\n        if self.weight_loaded:\n            self.check_if_need_transpose(IR_node)\n            self.weights_dict[IR_node.name][\'weights\'] = np.transpose(self.weights_dict[IR_node.name][\'weights\'], (1, 0))\n\n        return code\n\n    def emit_Flatten(self, IR_node):\n        parent = self.IR_graph.get_parent(IR_node.name, [0]).real_variable_name\n        code = ""{:<15} = {}.view({}.size(0), -1)"".format(\n            IR_node.variable_name,\n            parent,\n            parent)\n        return code\n\n\n    def emit_Reshape(self, IR_node):\n        shape_list = IR_node.get_attr(\'shape\')\n        shape_str = \',\'.join([str(int(i)) for i in shape_list])\n        code = ""{:<15} = torch.reshape(input = {}, shape = ({}))"".format(\n            IR_node.variable_name,\n            self.IR_graph.get_node(IR_node.in_edges[0]).real_variable_name,\n            shape_str)\n        return code\n\n\n    def emit_Tanh(self, IR_node):\n        code = ""{:<15} = F.tanh({})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node, [0]))\n        return code\n\n\n    def emit_Relu(self, IR_node):\n        code = ""{:<15} = F.relu({})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node, [0]))\n        return code\n\n\n    def emit_LeakyRelu(self, IR_node):\n        code = ""{:<15} = F.leaky_relu({}, negative_slope={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node, [0]),\n            IR_node.get_attr(\'alpha\'))\n        return code\n\n\n    def emit_Relu6(self, IR_node):\n        code = ""{:<15} = F.relu6({})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node, [0]))\n        return code\n\n\n    def emit_Softmax(self, IR_node):\n        code = ""{:<15} = F.softmax({})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node, [0]))\n        return code\n\n\n    def emit_Sigmoid(self, IR_node):\n        code = ""{:<15} = F.sigmoid({})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)\n        )\n        return code\n\n\n    def emit_Embedding(self, IR_node):\n        self.used_layers.add(""Embedding"")\n        self.add_init(2, ""self.{} = self.__embedding(\'{}\', num_embeddings={}, embedding_dim={})"".format(\n            IR_node.variable_name,\n            IR_node.name,\n            IR_node.get_attr(\'input_dim\'),   #2-D\n            IR_node.get_attr(\'output_dim\')\n            ))\n        \n        code = ""{:<15} = self.{}({})"".format(\n            IR_node.variable_name,\n            IR_node.variable_name,\n            ""torch.LongTensor(np.array({}))"".format(self.parent_variable_name(IR_node))\n        )\n        return code\n\n\n    def emit_RNNs(self, IR_node, func):\n        raise NotImplementedError()\n        # for Keras\n        if ""dropout"" in IR_node.IR_layer.attr:\n            dropout_str = "",dropout = {}, recurrent_dropout = {}"".format(\n                    IR_node.IR_layer.attr[\'dropout\'].f,\n                    IR_node.IR_layer.attr[\'recurrent_dropout\'].f)\n        else:\n            dropout_str = """"\n\n        code = ""{:<15} = {}(units = {}, use_bias = {} {})({})"".format(\n                IR_node.name,\n                func,\n                IR_node.IR_layer.attr[\'units\'].i,\n                IR_node.IR_layer.attr[\'use_bias\'].b,\n                dropout_str,\n                IR_node.in_edges[0])\n\n        return code\n\n\n    def emit_LSTM(self, IR_node):\n        return self.emit_RNNs(IR_node, ""LSTM"")\n\n\n    def emit_GRU(self, IR_node):\n        return self.emit_RNNs(IR_node, ""GRU"")\n\n\n    def emit_Add(self, IR_node):\n        code = ""{:<15} = {} + {}"".format(\n            IR_node.variable_name,\n             self.parent_variable_name(IR_node),\n             self.parent_variable_name(IR_node, [1]))\n        return code\n\n\n    def emit_Sub(self, IR_node):\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            \' - \'.join(self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))))\n        return code\n\n\n    def emit_Mul(self, IR_node):\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            \' * \'.join(self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))))\n        return code\n\n\n    def emit_MatMul(self, IR_node):\n        code = ""{:<15} = torch.matmul({})"".format(\n            IR_node.variable_name,\n            \' , \'.join(\'%s\' % self.IR_graph.get_node(s).real_variable_name for s in IR_node.in_edges))\n        return code\n\n\n    def emit_Constant(self, IR_node):\n        if IR_node.get_attr(\'value\'):\n            value = IR_node.get_attr(\'value\')\n            if not isinstance(value, list):\n                value = [value]\n            code = ""self.{:<15} = torch.autograd.Variable(torch.Tensor({}), requires_grad=False)"".format(\n                IR_node.variable_name,\n                value)\n        else:\n            code = ""self.{:<15} = torch.autograd.Variable(torch.from_numpy(__weights_dict[\'{}\'][\'value\']), requires_grad=False)"".format(\n                IR_node.variable_name,\n                IR_node.name)\n        \n        # self.add_init(2, ""self.{:<15} = torch.from_numpy(__weights_dict[\'{}\'][\'value\'])"".format(\n        #     IR_node.variable_name,\n        #     IR_node.name))\n        IR_node.real_name = ""self."" + IR_node.variable_name\n        return code\n\n\n    def _convert_axis(self, IR_node, axis):\n        ndim = len(self.IR_graph.get_parent(IR_node.name, [0]).get_attr(\'_output_shapes\')[0].dim)\n        if axis == 0:\n            return 0\n        elif axis == ndim - 1:\n            return 1\n        else:\n            return axis + 1\n\n\n    def emit_Concat(self, IR_node):\n        axis = self._convert_axis(IR_node, IR_node.get_attr(\'axis\'))\n        code = ""{:<15} = torch.cat(({}), {})"".format(\n            IR_node.variable_name,\n            \', \'.join(self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))),\n            axis,\n        )\n        return code\n\n\n    def emit_BatchNorm(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        dim = len(IR_node.layer.attr[\'_output_shapes\'].list.shape[0].dim) - 2\n\n        output_shape = IR_node.layer.attr[\'_output_shapes\'].list.shape[0]\n        if IR_node.get_attr(\'data_format\', ""NHWC"") == ""NCHW"":\n            num_features = output_shape.dim[1].size\n        else:\n            num_features = output_shape.dim[-1].size\n\n        self.add_init(2, ""self.{} = self.__batch_normalization({}, \'{}\', num_features={}, eps={}, momentum={})"".format(\n             IR_node.variable_name,\n             dim,\n             IR_node.name,\n             num_features,\n             IR_node.layer.attr[\'epsilon\'].f,\n             IR_node.layer.attr[\'momentum\'].f,\n        ))\n\n        code = ""{:<15} = self.{}({})"".format(\n            IR_node.variable_name,\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)\n        )\n        return code\n\n\n    def emit_Scale(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        dim = len(IR_node.layer.attr[\'_output_shapes\'].list.shape[0].dim) - 2\n\n        self.add_init(2, ""self.{} = self.__scale({}, \'{}\', num_features={})"".format(\n             IR_node.variable_name,\n             dim,\n             IR_node.name,\n             IR_node.layer.attr[\'_output_shapes\'].list.shape[0].dim[-1].size\n        ))\n\n        code = ""{:<15} = self.{}({})"".format(\n            IR_node.variable_name,\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)\n        )\n        return code\n\n\n    def emit_Squeeze(self, IR_node):\n        code = ""{:<15} = torch.squeeze({})"".format(\n            IR_node.variable_name, self.parent_variable_name(IR_node)\n        )\n        return code\n\n\n    @staticmethod\n    def _convert_padding(IR_node):\n        padding = IR_node.get_attr(\'pads\')\n        padding = convert_onnx_pad_to_tf(padding)[1:-1]\n        new_padding = []\n        for pad in padding:\n            new_padding.insert(0, pad)\n        return tuple(np.array(new_padding).reshape(-1).tolist())\n\n\n    def emit_Pad(self, IR_node):\n        if IR_node.get_attr(\'mode\').lower() == \'constant\':\n            mode = ""mode = \'constant\', value = {}"".format(0)\n        elif IR_node.get_attr(\'mode\').lower() == \'reflect\':\n            mode = ""mode = \'reflect\'""\n        elif IR_node.get_attr(\'mode\').upper() == \'SYMMETRIC\':\n            mode = ""mode = \'replicate\'""\n        else:\n            assert False\n\n        padding = self._convert_padding(IR_node)\n        code = ""{:<15} = F.pad({}, {}, {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            padding,\n            mode)\n        return code\n\n\n    def emit_ReduceMean(self, IR_node):\n        axes = [self._convert_axis(IR_node, x) for x in IR_node.get_attr(\'axes\')]\n        input_node = self.parent_variable_name(IR_node)\n        codes = []\n        for axis in sorted(axes, reverse=True):\n            code = ""{:<15} = torch.mean({}, {}, {})"".format(\n                IR_node.variable_name,\n                input_node,\n                axis,\n                IR_node.get_attr(""keepdims"")\n            )\n            codes.append(code)\n            input_node = IR_node.variable_name\n        return codes\n\n\n    def emit_LRN(self, IR_node):\n        output_name = IR_node.variable_name\n        input_name = self.parent_variable_name(IR_node)\n        size = IR_node.get_attr(\'size\')\n        alpha = IR_node.get_attr(\'alpha\')\n        beta = IR_node.get_attr(\'beta\')\n        bias = IR_node.get_attr(\'bias\', 1)\n\n        code =  ""{:<15} = F.local_response_norm({}, size={}, alpha={}, beta={}, k={})"".format(\n            output_name,\n            input_name,\n            size,\n            alpha,\n            beta,\n            bias\n        )\n        return code\n\n\n    def emit_DepthwiseConv(self, IR_node):\n        return self.emit_Conv(IR_node)\n\n\n    def emit_Const(self, IR_node):\n        if \'dtype\' in IR_node.layer.attr:\n            dtype_str = ""dtype={}"".format(self.dtype_map[IR_node.layer.attr[\'dtype\'].type])\n            if \'int\' in dtype_str:\n                code = ""{:<15} = torch.tensor({}, {})"".format(\n                    IR_node.variable_name,\n                    IR_node.layer.attr[\'value\'].i,\n                    dtype_str)\n            else:\n                code = ""{:<15} = torch.tensor({}, {})"".format(\n                    IR_node.variable_name,\n                    IR_node.layer.attr[\'value\'].f,\n                    dtype_str)\n\n        else:\n            dtype_str = ""dtype=torch.float32""\n            code = ""{:<15} = torch.tensor({}, {})"".format(\n                IR_node.variable_name,\n                IR_node.layer.attr[\'value\'].f,\n                dtype_str)\n        return code\n\n\n    def emit_Shape(self, IR_node):\n        code = ""{:<15} = torch.Tensor(list({}.size()))"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node)\n            )\n        return code\n\n\n    def emit_Pack(self, IR_node):\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            \'[\' +  \',\'.join(\'%s\' % self.IR_graph.get_node(s).real_variable_name for s in IR_node.in_edges) + \']\',\n            )\n        return code\n\n\n    def emit_Slice(self, IR_node):\n        starts = IR_node.get_attr(\'starts\')\n        if len(starts) > 1:\n            starts = [starts[0], starts[-1]] + starts[1:-1]\n        ends = IR_node.get_attr(\'ends\')\n        if len(ends) > 1:\n            ends = [ends[0], ends[-1]] + ends[1:-1]\n        extra_str = """"\n        for idx, _ in enumerate(starts):\n            if idx:\n                extra_str += "", ""\n            extra_str += ""{}:"".format(starts[idx])\n            if ends[idx]:\n                extra_str += ""{}"".format(ends[idx])\n        \n        shrink_mask = IR_node.get_attr(\'shrink_axis_mask\')\n\n        if shrink_mask:\n            mask = [int(s) for s in bin(shrink_mask)[2:][::-1]]\n            shrink_str = \'[\' + \',\'.join(\':\' if bit==0 else \'0\' for bit in mask) + \']\'\n        else:\n            shrink_str = \'\'\n        code = ""{:<15} = {}[{}]{}"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            extra_str,\n            shrink_str\n        )\n        return code\n\n\n    def emit_Split(self, IR_node):\n\n        if isinstance(IR_node.get_attr(\'split\'), list):\n            split_str = IR_node.get_attr(\'split\')\n        else:\n            num_split = IR_node.get_attr(\'split\')\n            split_str = ""math.ceil({}.shape[{}]/{})"".format(\n                self.parent_variable_name(IR_node), \n                IR_node.get_attr(\'axis\'),\n                num_split)\n        code = ""{:<15} = torch.split({}, {}, dim={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            split_str,\n            IR_node.get_attr(\'axis\'),\n        )\n        return code\n\n\n    def emit_Unstack(self, IR_node):\n        code = ""{:<15} = torch.unbind({}, dim={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'axis\')\n        )\n        return code\n\n\n    def emit_Fill(self, IR_node):\n        code = ""{:<15} = torch.full({}.int().numpy().tolist(), {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'value\')\n        )\n        return code\n\n\n    def emit_Gather(self, IR_node):\n        pass\n\n\n    def emit_Unsqueeze(self, IR_node):\n        code = ""{:<15} = {}.unsqueeze({})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'axes\')[0]\n        )\n        return code\n\n\n    def emit_Transpose(self, IR_node):\n        code = ""{:<15} = {}.permute({})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]))\n        return code\n\n\n    def emit_Minimum(self, IR_node):\n        code = ""{:<15} = torch.min({}, {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]))\n        return code\n\n\n    def emit_Maxmum(self, IR_node):\n        code = ""{:<15} = torch.max({}, {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]))\n        return code\n\n\n    def emit_Square(self, IR_node):\n        code = ""{:<15} = {}.pow(2)"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_PRelu(self, IR_node):\n        code = ""{:<15} = F.prelu({}, torch.from_numpy(__weights_dict[\'{}\'][\'weights\']))"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node, [0]),\n            IR_node.name)\n        \n        if self.weight_loaded:\n            self.weights_dict[IR_node.name][\'weights\'] = self.weights_dict[IR_node.name][\'gamma\']\n        \n        return code\n\n\n    def emit_Cast(self, IR_node):\n        dstType = IR_node.get_attr(\'dstType\')\n\n        if dstType == \'float\':\n            dst = \'torch.FloatTensor\'\n        elif dstType == \'double\':\n            dst = \'torch.DoubleTensor\'\n        elif dstType == \'int\':\n            dst = \'torch.IntTensor\'\n        \n        code = ""{:<15} = {}.type({})"".format(\n            IR_node.real_variable_name,\n            self.parent_variable_name(IR_node),\n            dst)\n\n        return code\n\n\n    def emit_Scope(self, IR_node):\n        input_vars = [self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))]\n        code = ""{:<15} = self.__{}({})"".format(\n            IR_node.real_variable_name,\n            IR_node.pattern,\n            \', \'.join(input_vars))\n        self._gen_scope_code(IR_node)\n        return code\n\n\n    def _gen_scope_code(self, scope_node):\n\n        def _scope_func(scope_name, params, code, return_var):\n            code = """"""\n    def __{}({}):\n{}\n        return {}\n    """""".format(scope_name, params, code, \', \'.join(return_var))\n            return code\n\n        if not self.layers_codes.get(scope_node.pattern, None):\n            body_code = str()\n            for node_name in scope_node.topology_list:\n                node = self.IR_graph.get_node(node_name)\n                node_type = node.type\n\n                if hasattr(self, ""emit_"" + node_type):\n                    func = getattr(self, ""emit_"" + node_type)\n                    line = func(node)\n                    if line != None:\n                        body_code += ""        "" + line + \'\\n\'\n                else:\n                    print(""PytorchEmitter has not supported operator [%s]."" % (node_type))\n                    self.emit_UNKNOWN(node)\n\n            # param_code does not need parameter slice.\n            input_params = scope_node.input_params\n            input_params.insert(0, ""self"")\n            param_code = \', \'.join(input_params)\n            function_code = _scope_func(scope_node.pattern, param_code, body_code, scope_node.return_variables)\n\n            self.layers_codes[scope_node.pattern] = function_code\n\n\n    def _layer_Embedding(self):\n        self.add_body(0,""""""\n    @staticmethod\n    def __embedding(name, **kwargs):\n        layer = nn.Embedding(**kwargs) #shape\n        layer.state_dict()[\'weight\'].copy_(torch.from_numpy(__weights_dict[name][\'weights\']))\n        return layer\n        """""")\n\n\n    def _layer_Conv(self):\n        self.add_body(0, """"""\n    @staticmethod\n    def __conv(dim, name, **kwargs):\n        if   dim == 1:  layer = nn.Conv1d(**kwargs)\n        elif dim == 2:  layer = nn.Conv2d(**kwargs)\n        elif dim == 3:  layer = nn.Conv3d(**kwargs)\n        else:           raise NotImplementedError()\n\n        layer.state_dict()[\'weight\'].copy_(torch.from_numpy(__weights_dict[name][\'weights\']))\n        if \'bias\' in __weights_dict[name]:\n            layer.state_dict()[\'bias\'].copy_(torch.from_numpy(__weights_dict[name][\'bias\']))\n        return layer"""""")\n\n\n    def _layer_FullyConnected(self):\n        self.add_body(0, """"""\n    @staticmethod\n    def __dense(name, **kwargs):\n        layer = nn.Linear(**kwargs)\n        layer.state_dict()[\'weight\'].copy_(torch.from_numpy(__weights_dict[name][\'weights\']))\n        if \'bias\' in __weights_dict[name]:\n            layer.state_dict()[\'bias\'].copy_(torch.from_numpy(__weights_dict[name][\'bias\']))\n        return layer"""""")\n\n\n    def _layer_BatchNorm(self):\n        self.add_body(0, """"""\n    @staticmethod\n    def __batch_normalization(dim, name, **kwargs):\n        if   dim == 0 or dim == 1:  layer = nn.BatchNorm1d(**kwargs)\n        elif dim == 2:  layer = nn.BatchNorm2d(**kwargs)\n        elif dim == 3:  layer = nn.BatchNorm3d(**kwargs)\n        else:           raise NotImplementedError()\n\n        if \'scale\' in __weights_dict[name]:\n            layer.state_dict()[\'weight\'].copy_(torch.from_numpy(__weights_dict[name][\'scale\']))\n        else:\n            layer.weight.data.fill_(1)\n\n        if \'bias\' in __weights_dict[name]:\n            layer.state_dict()[\'bias\'].copy_(torch.from_numpy(__weights_dict[name][\'bias\']))\n        else:\n            layer.bias.data.fill_(0)\n\n        layer.state_dict()[\'running_mean\'].copy_(torch.from_numpy(__weights_dict[name][\'mean\']))\n        layer.state_dict()[\'running_var\'].copy_(torch.from_numpy(__weights_dict[name][\'var\']))\n        return layer"""""")\n\n\n    def _layer_Scale(self):\n        self.add_body(0, """"""\n    # from torch.nn.parameter import Parameter\n\n    class _Scale(nn.Module):\n\n        def __init__(self, num_features, affine=True):\n            super(KitModel._Scale, self).__init__()\n            self.num_features = num_features\n            self.affine = affine\n\n            self.running_mean = torch.zeros(num_features)\n            self.running_var = torch.ones(num_features)\n            self.training = False\n            self.eps = 1e-5\n            if self.affine:\n                self.weight = nn.Parameter(torch.Tensor(num_features))\n                self.bias = nn.Parameter(torch.Tensor(num_features))\n            else:\n                self.register_parameter(\'weight\', None)\n                self.register_parameter(\'bias\', None)\n            self.reset_parameters()\n\n\n        def reset_parameters(self):\n            if self.affine:\n                self.weight.data.uniform_()\n                self.bias.data.zero_()\n\n        def _check_input_dim(self, input):\n            raise NotImplementedError\n\n        def forward(self, input):\n            self._check_input_dim(input)\n\n            return F.batch_norm(\n                input, self.running_mean, self.running_var, self.weight, self.bias,\n                self.training,\n                0 , self.eps)\n\n\n    class Scale1d(_Scale):\n\n        def _check_input_dim(self, input):\n            if input.dim() != 2 and input.dim() != 3:\n                raise ValueError(\'expected 2D or 3D input (got {}D input)\'\n                                .format(input.dim()))\n\n\n\n    class Scale2d(_Scale):\n\n\n        def _check_input_dim(self, input):\n            if input.dim() != 4:\n                raise ValueError(\'expected 4D input (got {}D input)\'\n                                .format(input.dim()))\n\n\n    class Scale3d(_Scale):\n\n        def _check_input_dim(self, input):\n            if input.dim() != 5:\n                raise ValueError(\'expected 5D input (got {}D input)\'\n                                .format(input.dim()))\n\n\n    @staticmethod\n    def __scale(dim, name, **kwargs):\n        if   dim == 1:  layer = KitModel.Scale1d(**kwargs)\n        elif dim == 2:  layer = KitModel.Scale2d(**kwargs)\n        elif dim == 3:  layer = KitModel.Scale3d(**kwargs)\n        else:           raise NotImplementedError()\n\n        if \'scale\' in __weights_dict[name]:\n            layer.state_dict()[\'weight\'].copy_(torch.from_numpy(__weights_dict[name][\'scale\']))\n        else:\n            layer.weight.data.fill_(1)\n\n        if \'bias\' in __weights_dict[name]:\n            layer.state_dict()[\'bias\'].copy_(torch.from_numpy(__weights_dict[name][\'bias\']))\n        else:\n            layer.bias.data.fill_(0)\n\n        return layer"""""")\n'"
mmdnn/conversion/pytorch/pytorch_graph.py,18,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\nimport torch\nimport torch.jit\nimport torch.autograd\nimport torch.serialization\nimport contextlib\nfrom torch.jit import _unique_state_dict\n\n\n\nclass PytorchGraphNode(GraphNode):\n\n    def __init__(self, layer):\n        self._name = layer.scopeName()\n        self._kind = layer.kind()\n        import re\n        node_id = re.search(r""[\\d]+"", layer.__str__())\n        self.id = node_id.group(0)\n\n        super(PytorchGraphNode, self).__init__(layer)\n        self.attrs = {k : layer[k] for k in layer.attributeNames()}\n\n        self.weights_name = \'.\'.join(\n            re.findall(r\'\\[([\\w\\d.]+)\\]\', self._name)\n        )\n\n\n    @property\n    def name(self):\n        name = self._name + self.id\n        # Scopes created in a nested scope may have initial characters\n        # that are illegal as the initial character of an op name\n        # (viz. \'-\', \'\\\', \'/\', and \'_\').\n        name = name.replace(\'-\',\'n\').replace(\'\\\\\',\'n\').replace(\'/\',\'n\').replace(\'_\',\'n\').replace(\'[\',\'n\').replace(\']\',\'n\')\n        return name\n\n    @property\n    def type(self):\n        return self._kind\n\n    @property\n    def pytorch_layer(self):\n        return self.layer\n\n\n\n\nclass PytorchGraph(Graph):\n\n    def __init__(self, model):\n        # sanity check.\n        super(PytorchGraph, self).__init__(model)\n        self.model = model\n        self.state_dict = _unique_state_dict(self.model)\n        self.shape_dict = dict()\n\n\n    @staticmethod\n    def _optimize_graph(graph, aten, export_raw_ir=False):\n        # run dce first to eliminate dead parts of the graph that might have been\n        # left behind by things like symbolic_override\n\n        torch._C._jit_pass_dce(graph)\n        torch._C._jit_pass_lint(graph)\n\n        torch._C._jit_pass_peephole(graph)\n        torch._C._jit_pass_lint(graph)\n        if not export_raw_ir:\n            graph = torch._C._jit_pass_onnx(graph, aten)\n            torch._C._jit_pass_lint(graph)\n            torch._C._jit_pass_onnx_peephole(graph)\n            torch._C._jit_pass_lint(graph)\n        torch._C._jit_pass_dce(graph)\n        torch._C._jit_pass_lint(graph)\n        graph = torch._C._jit_pass_canonicalize(graph)\n        torch._C._jit_pass_lint(graph)\n        return graph\n\n\n    @staticmethod\n    def get_node_id(node):\n        import re\n        node_id = re.search(r""[\\d]+"", node.__str__())\n        return node_id.group(0)\n\n    @contextlib.contextmanager\n    def set_training(self, model, mode):\n        r""""""\n        A context manager to temporarily set the training mode of \'model\'\n        to \'mode\', resetting it when we exit the with-block.  A no-op if\n        mode is None.\n        """"""\n        if mode is None:\n            yield\n            return\n        old_mode = model.training\n        if old_mode != mode:\n            model.train(mode)\n        try:\n            yield\n        finally:\n            if old_mode != mode:\n                model.train(old_mode)\n\n\n    def build(self, shape):\n        """"""\n        build graph for pytorch 0.4.0\n        """"""\n\n        import re\n        # construct graph\n        dummy_input = torch.autograd.Variable(torch.randn(shape), requires_grad=False)\n\n\n        with self.set_training(self.model, False):\n            trace, output = torch.jit.get_trace_graph(self.model, (dummy_input, ))\n\n        trace.set_graph(PytorchGraph._optimize_graph(trace.graph(), False))\n        # nodes\n        nodes = list(trace.graph().nodes())\n\n\n        # input layer\n        # TODO\n\n\n\n        # build each layer\n        for node in nodes:\n\n            node_id = PytorchGraph.get_node_id(node)\n            node_scope = node.scopeName()\n            node_name = node_scope + node_id\n            node_name = node_name.replace(\'-\',\'n\').replace(\'\\\\\',\'n\').replace(\'/\',\'n\').replace(\'_\',\'n\').replace(\'[\',\'n\').replace(\']\',\'n\')\n            output_shape_str = re.findall(r\'[^()!]+\', node.__str__())[1]\n            output_shape = [int(x.replace(\'!\', \'\')) for x in output_shape_str.split(\',\')]\n\n\n            self.shape_dict[node_name] = output_shape\n            self.layer_map[node_name] = PytorchGraphNode(node)\n            self.layer_name_map[node_name] = node_name\n\n            # input\n            for node_input in list(node.inputs()):\n\n                if PytorchGraph.get_node_id(node_input.node()) and node_input.node().scopeName():\n                    node_input_name = node_input.node().scopeName() + PytorchGraph.get_node_id(node_input.node())\n                    node_input_name = node_input_name.replace(\'-\',\'n\').replace(\'\\\\\',\'n\').replace(\'/\',\'n\').replace(\'_\',\'n\').replace(\'[\',\'n\').replace(\']\',\'n\')\n                    self._make_connection(node_input_name, node_name)\n                    # print(node_input_name ,\'->\', node_name)\n\n\n        super(PytorchGraph, self).build()\n'"
mmdnn/conversion/pytorch/pytorch_parser.py,3,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\nimport numpy as np\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom mmdnn.conversion.pytorch.pytorch_graph import PytorchGraph\nimport torch\nimport torchvision\n\nclass PytorchParser(Parser):\n\n    layer_map = {\n    \'onnx::Conv\': \'Conv\',\n    \'onnx::Flatten\': \'Flatten\',\n    \'onnx::Gemm\': \'FullyConnected\',\n    \'onnx::MaxPool\': \'Maxpool\',\n    \'onnx::AveragePool\': \'Avgpool\',\n    \'onnx::Dropout\': \'Dropout\',\n    \'onnx::BatchNormalization\': \'BatchNormalization\',\n    \'onnx::Add\': \'Add\',\n    \'onnx::Concat\': \'Concat\',\n    \'onnx::Relu\': \'Relu\',\n    \'onnx::Tanh\': \'Tanh\',\n    \'onnx::Sigmoid\': \'Sigmoid\',\n    \'onnx::Mul\': \'Mul\'\n\n\n    # TODO\n    # \'max_pool2d\': convert_maxpool,\n    # \'onnx::Mul\': convert_elementwise_mul,\n    # \'onnx::Sub\': convert_elementwise_sub,\n    # \'onnx::ConvTranspose\': convert_convtranspose,\n    # \'onnx::LeakyRelu\': convert_lrelu,\n    # \'onnx::Sigmoid\': convert_sigmoid,\n    # \'onnx::Softmax\': convert_softmax,\n    # \'onnx::Selu\': convert_selu,\n    # \'onnx::Transpose\': convert_transpose,\n    # \'onnx::Reshape\': convert_reshape,\n    # \'onnx::MatMul\': convert_matmul,\n    # \'onnx::Gather\': convert_gather,\n    # \'onnx::ReduceSum\': convert_reduce_sum,\n    # \'onnx::Constant\': convert_constant,\n    # \'onnx::Upsample\': convert_upsample,\n    # \'onnx::Pad\': convert_padding,\n}\n\n\n    ############\n    # property #\n    ############\n\n    @property\n    def src_graph(self):\n        return self.pytorch_graph\n\n\n    ####################\n    # Public Functions #\n    ####################\n\n    def __init__(self, model_file_name, input_shape):\n        super(PytorchParser, self).__init__()\n        if not os.path.exists(model_file_name):\n            print(""Pytorch model file [{}] is not found."".format(model_file_name))\n            assert False\n        # test\n\n        # cpu: https://github.com/pytorch/pytorch/issues/5286\n        try:\n            model = torch.load(model_file_name)\n        except:\n            model = torch.load(model_file_name, map_location=\'cpu\')\n\n        self.weight_loaded = True\n\n        # Build network graph\n        self.pytorch_graph = PytorchGraph(model)\n        self.input_shape = tuple([1] + input_shape)\n        self.pytorch_graph.build(self.input_shape)\n        self.state_dict = self.pytorch_graph.state_dict\n        self.shape_dict = self.pytorch_graph.shape_dict\n\n\n    def gen_IR(self):\n\n        for layer in self.src_graph.topological_sort:\n            current_node = self.src_graph.get_node(layer)\n            onnx_node_type = current_node.type\n            node_type = PytorchParser.layer_map[onnx_node_type]\n\n\n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n\n            else:\n                self.rename_UNKNOWN(current_node)\n\n        self.gen_Input()\n\n\n\n    def _set_output_shape(self, source_node, IR_node):\n\n        shape = graph_pb2.TensorShape()\n\n\n        layer_name = source_node.name\n\n        shape_pytorch = self.shape_dict[layer_name]\n\n\n        new_dim = shape.dim.add()\n\n        # (batch, C, H, W)  & NHWC\n        if len(shape_pytorch) == 4:\n\n            if shape_pytorch[0] == 1:\n                new_dim.size = -1\n            else:\n                new_dim.size = shape_pytorch[0]\n            for index in [2, 3, 1]:\n                new_dim = shape.dim.add()\n                dim = shape_pytorch[index]\n                new_dim.size = dim if dim else -1\n        elif len(shape_pytorch) == 2:\n            if shape_pytorch[0] == 1:\n                new_dim.size = -1\n            else:\n                new_dim.size = shape_pytorch[0]\n            for _ in range(2):\n                new_dim = shape.dim.add()\n                new_dim.size = 1\n            new_dim = shape.dim.add()\n            dim = shape_pytorch[1]\n            new_dim.size = dim if dim else -1\n\n\n        IR_node.attr[""_output_shapes""].list.shape.extend([shape])\n\n    ##########\n    # Layers #\n    ##########\n    def rename_UNKNOWN(self, source_node):\n        print (source_node.layer)\n        print (source_node.layer.data.size())\n        assert False\n        print(""PyTorch parser has not supported operator [%s] with name [%s].""\n              % (source_node.type, source_node.name))\n\n    def gen_Input(self):\n        IR_node = self.IR_graph.node.add()\n        IR_node.name = \'input\'\n        IR_node.op = ""DataInput""\n\n        for node in self.IR_graph.node:\n            if node.name in self.src_graph.input_layers:\n                node.input.append(\'input\')\n\n        assert len(self.input_shape) == 4\n        new_dim = IR_node.attr[""shape""].shape.dim.add()\n        if self.input_shape[0] == 1:\n            new_dim.size = -1\n        else:\n            new_dim.size = self.input_shape[0]\n        for index in [2, 3, 1]:\n            new_dim = IR_node.attr[""shape""].shape.dim.add()\n            new_dim.size = self.input_shape[index]\n\n        shape = graph_pb2.TensorShape()\n        new_dim = shape.dim.add()\n        shape_pytorch = self.input_shape\n\n        if len(shape_pytorch) == 4:\n\n            if shape_pytorch[0] == 1:\n                new_dim.size = -1\n            else:\n                new_dim.size = shape_pytorch[0]\n            for index in [2, 3, 1]:\n                new_dim = shape.dim.add()\n                dim = shape_pytorch[index]\n                new_dim.size = dim if dim else -1\n        elif len(shape_pytorch) == 2:\n            if shape_pytorch[0] == 1:\n                new_dim.size = -1\n            else:\n                new_dim.size = shape_pytorch[0]\n            for _ in range(2):\n                new_dim = shape.dim.add()\n                new_dim.size = 1\n            new_dim = shape.dim.add()\n            dim = shape_pytorch[1]\n            new_dim.size = dim if dim else -1\n\n\n        IR_node.attr[""_output_shapes""].list.shape.extend([shape])\n\n\n    def rename_Conv(self, source_node):\n\n        attr = source_node.attrs\n        kwargs = dict()\n\n        # dilation\n        if \'dilations\' in attr:\n            kwargs[\'dilations\'] = [1] + attr[\'dilations\'] + [1]\n        else:\n            kwargs[\'dilations\'] = [1] + [1, 1] + [1]\n\n        if len(attr[\'pads\']) == 4:\n            kwargs[\'pads\'] = [0] + attr[\'pads\'][0:2] + [0, 0] + attr[\'pads\'][2:] + [0]\n        elif len(attr[\'pads\']) == 2:\n            kwargs[\'pads\'] = ( [0] + attr[\'pads\'][0:2] + [0] ) *2\n\n        if \'strides\' not in attr:\n            kwargs[\'strides\'] = [1] + [1, 1] + [1]\n        else:\n            kwargs[\'strides\'] = [1] + attr[\'strides\'] + [1]\n\n        kwargs[\'group\'] = attr[\'group\']\n\n\n\n        bias_name = \'{0}.bias\'.format(source_node.weights_name)\n        weights_name = \'{0}.weight\'.format(source_node.weights_name)\n\n        weight = self.state_dict[weights_name]\n\n        weight = weight.numpy()\n        dim = weight.ndim - 2\n\n\n        IR_node = self._convert_identity_operation(source_node, new_op=""Conv"")\n        weight = np.transpose(weight, list(range(2, dim + 2)) + [1, 0])\n\n        self.set_weight(source_node.name, \'weights\', weight)\n        kwargs[\'kernel_shape\'] = list(weight.shape)\n\n\n        # handle bias\n        if bias_name in self.state_dict:\n            bias = self.state_dict[bias_name].numpy()\n            self.set_weight(source_node.name, \'bias\', bias)\n            kwargs[\'use_bias\'] = True\n        else:\n            kwargs[\'use_bias\'] = False\n\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_BatchNormalization(self, source_node):\n        # TODO\n        # output_shape\n\n        IR_node = self._convert_identity_operation(source_node, new_op=""BatchNorm"")\n\n\n        attr = source_node.attrs\n        # epsilon\n        IR_node.attr[\'epsilon\'].f = attr[\'epsilon\']\n\n\n        bias_name = \'{0}.bias\'.format(source_node.weights_name)\n        weights_name = \'{0}.weight\'.format(source_node.weights_name)\n        mean_name = \'{0}.running_mean\'.format(source_node.weights_name)\n        var_name = \'{0}.running_var\'.format(source_node.weights_name)\n\n\n\n        if bias_name in self.state_dict:\n            beta = self.state_dict[bias_name].numpy()\n            IR_node.attr[\'bias\'].b = True\n        else:\n            IR_node.attr[\'bias\'].b = False\n\n        if weights_name in self.state_dict:\n            gamma = self.state_dict[weights_name].numpy()\n            IR_node.attr[\'scale\'].b = True\n        else:\n            IR_node.attr[\'scale\'].b = False\n\n        mean = self.state_dict[mean_name].numpy()\n        variance = self.state_dict[var_name].numpy()\n\n\n\n        if IR_node.attr[\'scale\'].b:\n            self.set_weight(source_node.name, ""scale"", gamma)\n\n        if IR_node.attr[\'bias\'].b:\n            self.set_weight(source_node.name, ""bias"", beta)\n\n        # mean\n        self.set_weight(source_node.name, ""mean"", mean)\n\n        # var\n        self.set_weight(source_node.name, ""var"", variance)\n\n    def rename_Relu(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=""Relu"")\n\n    def rename_Tanh(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=""Tanh"")\n\n    def rename_Sigmoid(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=""Sigmoid"")\n\n    def rename_Mul(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=""Mul"")\n\n    def rename_Maxpool(self, source_node):\n        attr = source_node.attrs\n        kwargs = dict()\n        kwargs[\'strides\'] = [1] + attr[\'strides\'] + [1]\n        if \'dilations\' not in attr:\n            kwargs[\'dilations\'] = [1] + [1, 1] + [1]\n        else:\n            kwargs[\'dilations\'] = [1] + attr[\'dilations\'] + [1]\n        kwargs[\'pads\'] = [0] + attr[\'pads\'][0:2] + [0, 0] + attr[\'pads\'][2:] + [0]\n        kwargs[\'kernel_shape\'] = [1] + attr[\'kernel_shape\'] + [1]\n        IR_node = self._convert_identity_operation(source_node, new_op=""Pool"")\n\n        kwargs[\'pooling_type\'] = \'MAX\'\n\n        assign_IRnode_values(IR_node, kwargs)\n\n    def rename_Avgpool(self, source_node):\n        attr = source_node.attrs\n        kwargs = dict()\n        kwargs[\'strides\'] = [1] + attr[\'strides\'] + [1]\n        if \'dilations\' not in attr:\n            kwargs[\'dilations\'] = [1] + [1, 1] + [1]\n        else:\n            kwargs[\'dilations\'] = [1] + attr[\'dilations\'] + [1]\n        kwargs[\'pads\'] = [0] + attr[\'pads\'][0:2] + [0, 0] + attr[\'pads\'][2:] + [0]\n        kwargs[\'kernel_shape\'] = [1] + attr[\'kernel_shape\'] + [1]\n        IR_node = self._convert_identity_operation(source_node, new_op=""Pool"")\n\n        kwargs[\'pooling_type\'] = \'AVG\'\n\n        assign_IRnode_values(IR_node, kwargs)\n\n    def rename_Flatten(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=""Flatten"")\n\n    def rename_FullyConnected(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=""FullyConnected"")\n\n        bias_name = \'{0}.bias\'.format(source_node.weights_name)\n        weights_name = \'{0}.weight\'.format(source_node.weights_name)\n\n\n        W = self.state_dict[weights_name].numpy().transpose()\n        input_channels, output_channels = W.shape\n\n        # Kit weight tranpose\n        # weight: N x M -> C x H x W x M -> H x W x C x M -> N x M\n        if self.weight_loaded:\n            parent = self.src_graph.get_parent(source_node.name, [0])\n            while parent.type == \'onnx::Flatten\' or parent.type == \'onnx::Dropout\':\n                parent = self.src_graph.get_parent(parent.name, [0])\n            if len(self.shape_dict[parent.name]) == 4:\n                #\n                original_shape = W.shape\n                channel_first_list = self.shape_dict[parent.name][1:]\n                dim = len(channel_first_list) + 1\n                weight = W.reshape(channel_first_list + [original_shape[1]])\n                assert dim > 2\n                weight = weight.transpose(list(range(1, dim-1)) + [0, dim-1])\n                W = weight.reshape(original_shape)\n\n        # weights\n        self.set_weight(source_node.name, \'weights\', W )\n\n        # use_bias\n        if bias_name in self.state_dict:\n            IR_node.attr[\'use_bias\'].b = True\n            bias = self.state_dict[bias_name].numpy()\n            self.set_weight(source_node.name, \'bias\', bias )\n        else:\n            IR_node.attr[\'use_bias\'].b = False\n\n        # units\n        IR_node.attr[\'units\'].i = output_channels\n\n\n    def rename_Dropout(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Dropout\')\n        IR_node.attr[\'keep_prob\'].f = source_node.attrs[\'ratio\']\n\n    def rename_Concat(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Concat\')\n\n        if source_node.attrs[\'axis\'] == 1:\n            IR_node.attr[\'axis\'].i = len(self.shape_dict[source_node.name]) - 1\n        else:\n            IR_node.attr[\'axis\'].i = source_node.attrs[\'axis\']\n\n    def rename_Add(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Add\')\n\n\n    def rename_MaxPool2d(self, source_node):\n        self._convert_pooling(source_node)\n\n\n    def rename_View(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Reshape\')\n        assign_IRnode_values(IR_node, {\'shape\' : list(source_node.get_attr(\'new_sizes\'))[1:]})\n\n\n    def rename_Addmm(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'FullyConnected\')\n        kwargs = dict()\n\n        # handle weight\n        weight = source_node.get_attr(\'next_functions\')[2][0].next_functions[0][0].variable.data.numpy()\n        weight = np.transpose(weight)\n        kwargs[\'units\'] = weight.shape[1]\n        self.set_weight(source_node.name, \'weights\', weight)\n\n        # handle bias\n        if source_node.get_attr(\'next_functions\')[0][0]:\n            bias = source_node.get_attr(\'next_functions\')[0][0].variable.data.numpy()\n            kwargs[\'use_bias\'] = True\n            self.set_weight(source_node.name, \'bias\', weight)\n\n        assign_IRnode_values(IR_node, kwargs)\n\n        print(IR_node)\n\n\n    ####################\n    # Helper Functions #\n    ####################\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op = None):\n        if new_op == None: new_op = source_node.type\n        IR_node.name = source_node.name\n        IR_node.op = new_op\n\n\n    def _convert_identity_operation(self, source_node, in_edge_count = None, new_op = None):\n        IR_node = self.IR_graph.node.add()\n        PytorchParser._copy_and_reop(source_node, IR_node, new_op)\n        self.convert_inedge(source_node, IR_node, 0, in_edge_count)\n        self._set_output_shape(source_node, IR_node)\n        return IR_node\n\n    def _convert_pooling(self, source_node):\n        kwargs = dict()\n        kwargs[\'strides\'] = [1] + list(source_node.get_attr(\'stride\')) + [1]\n        kwargs[\'dilations\'] = [1] + list(source_node.get_attr(\'dilation\')) + [1]\n        kwargs[\'pads\'] = ([0] + list(source_node.get_attr(\'padding\')) + [0]) * 2\n        kwargs[\'kernel_shape\'] = [1] + list(source_node.get_attr(\'kernel_size\')) + [1]\n        IR_node = self._convert_identity_operation(source_node, new_op=""Pool"")\n\n        if source_node.name.startswith(\'Max\'):\n            kwargs[\'pooling_type\'] = \'MAX\'\n        elif source_node.name.startswith(\'Avg\'):\n            kwargs[\'pooling_type\'] = \'AVG\'\n        else:\n            raise ValueError(\'Unknown pooling type\')\n\n        assign_IRnode_values(IR_node, kwargs)\n'"
mmdnn/conversion/pytorch/saver.py,1,"b""import torch\n\n\ndef save_model(MainModel, network_filepath, weight_filepath, dump_filepath):\n    model = MainModel.KitModel(weight_filepath)\n    model.eval()\n    torch.save(model, dump_filepath)\n    print('PyTorch model file is saved as [{}], generated by [{}.py] and [{}]. Notice that you may need [{}.py] to load the model back.'.format(\n        dump_filepath, network_filepath, weight_filepath, network_filepath))\n"""
mmdnn/conversion/pytorch/torch_to_np.py,0,"b'import torchfile\nimport numpy as np\n\nmodel = torchfile.load(\'kit.model\')\n\nweights = dict()\n\nparams = [\'weight\', \'bias\', \'running_mean\', \'running_var\']\n\nrecursive = [\'conv_nets\']\n\ndef save_weight(name, node, level):\n    weights[name] = dict()\n    current_layer = weights[name]\n    for p in params:\n        if hasattr(node, p):\n            func = getattr(node, p)\n            arr = np.array(func)\n            if arr.ndim >= 1:\n                current_layer[p] = arr\n                print (""    "" * level + ""{}.{} shape {} {}"".format(name, p, current_layer[p].shape, current_layer[p].dtype))\n\n    for p in recursive:\n        if hasattr(node, p):\n            func = getattr(node, p)\n            if func != None:\n                for idx, subnode in enumerate(func):\n                    new_name = name + "":{}:{}"".format(p, idx)\n                    save_weight(new_name, subnode, level + 1)\n\n\nfor idx, data in enumerate(model.modules):\n    if data != None:\n        print (""Find layer #{} : {}"".format(idx, data._typename))\n        if hasattr(data, \'search_flag\'):\n            print (""    name = {}"".format(data.search_flag))\n        if data.modules != None:\n            print (""    submodule = {}#"".format(len(data.modules)))\n            for idx_j, sub in enumerate(data.modules):\n                print (""        layer [{}]"".format(sub._typename))\n                name = data.search_flag + "":"" + str(idx_j)\n                save_weight(name, sub, 2)\n                print (""\\n"")\n        else:\n            pass\n            #print (dir(data))\n\n        print (""\\n"")\n\nwith open(""stylebank.npy"", \'wb\') as of:\n    np.save(of, weights)\n\nprint (""-------------------------------------------------"")\n\nload_weight = np.load(\'stylebank.npy\').item()\nfor i in load_weight:\n    #print (i)\n    for j in load_weight[i]:\n        pass\n        #print (""    {} with shape {}"".format(j, load_weight[i][j].shape))'"
mmdnn/conversion/rewriter/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function'
mmdnn/conversion/rewriter/folder.py,0,"b'from mmdnn.conversion.common.IR.IR_graph import *\nimport sys\nimport re\nimport numpy as np\nimport collections\n\n\nclass Folder(object):\n    """"""A floder to fold a graph\' nodes which has same scope into one node.""""""\n\n    def __init__(self, graph, weights_dict, init_level=0, fold_level_num=0, scope_names=None):\n        """"""\n        Initializes a Folder.\n\n        Args:\n          graph: the graph to be folded.\n          init_level: the start scope level to be folded.\n          fold_level_num: the number of level from init_level to be folded. For example,\n            there are three nodes, whose scope are A/B/X, A/B/Y, A/C/Z. If init_level=0 and fold_level_num=1,\n            then the fold result is A/B and A/C.\n        """"""\n        self._graph = graph\n        self._weights_dict = weights_dict\n        self._init_level = init_level\n        self._fold_level_num = fold_level_num\n        self._scope_names = scope_names\n\n\n    """"""fold the graph by compressing the nodes which have same scope into one scope node.""""""\n    \n    def fold(self):\n        self.scope_level_name_map = self._get_scope_level_name_dict()  # level: scope_name set\n\n        if self._scope_names:\n            scope_names = self._scope_names\n        else:\n            if not self.scope_level_name_map:\n                return\n            scope_names = self.scope_level_name_map[0]\n\n        for scope_name in scope_names:\n            level = self._init_level\n            sub_fold_level = self._fold_level_num\n            while sub_fold_level >= 0:\n                self._fold(self._graph.topological_sort,\n                           scope_name, level, level + sub_fold_level)\n                sub_fold_level -= 1\n\n        # check the same pattern scope node whether have same inputs, outputs and weights. \n        # For those don\'t have, rename their scope names.\n        self.check_scope()\n        self.check_weights()\n\n        # clear out scope node, typically input constant node.\n        self._graph.clear_out_scope_node()\n\n\n    \'\'\'\n    fold the given node list by squash the nodes whose scope is given scope into one scope node.\n    Args:\n      scope_list: scope node topology list\n      scope_name: the scope name need to be folded\n      level: the scope\'s level\n      fold_level: the scope\'s sub scope level need to be folded.\n    \'\'\'\n    \n    def _fold(self, scope_list, scope_name, level, sub_level):\n        top_node = None\n        # get sub_scopes\n        if not self.scope_level_name_map.get(sub_level, 0):\n            raise ValueError(""The fold level exceed maxium scope level."")\n        sub_scopes = self.scope_level_name_map[sub_level]\n\n        for sub_scope in sub_scopes:\n            sub_scope_node_name_list = self._get_scope_name_dict(self._graph.topological_sort, top_level=level,\n                                                                 top_scope=scope_name, sub_level=sub_level, sub_scope=sub_scope)\n            for scope_list in sub_scope_node_name_list.values():\n                top_node = self._graph.get_node(scope_list[-1])\n                self._create_scope_node(\n                    sub_scope, scope_list, top_node)\n\n\n    \'\'\'get scope_level_name_dict.  {level: scope name list(without suffix number)}\'\'\'\n    \n    def _get_scope_level_name_dict(self):\n        scope_level_name = collections.OrderedDict()\n        for node in self._graph.get_nodes():\n            if not node.get_attr(\'scope\'):\n                continue\n            for i, scope_name in enumerate(node.get_attr(\'scope\').split(\'/\')):\n                # decline the suffix number\n                import re\n                if re.search(r\'\\d\', scope_name.split(\'_\')[-1]):\n                    scope_name = \'_\'.join(scope_name.split(\'_\')[:-1])\n                if scope_name == \'top\':\n                    continue\n                if scope_level_name.get(i, None):\n                    if scope_name not in scope_level_name[i]:\n                        scope_level_name[i].append(scope_name)\n                else:\n                    scope_level_name[i] = list([scope_name]) # use list to keep sort.\n\n        return scope_level_name\n\n\n    \'\'\'\n    get the dict from required node_list by appointed scope_name and level\n\n    Args:\n    node_list: current self.topology_sort\n    scope_name_dict: scope_no: node_name, a dict like {scope_name_no: a set of scope node\' name}\n    \'\'\'\n    def _get_scope_name_dict(self, node_list, top_level=0, top_scope=None, sub_level=2, sub_scope=None):\n        scope_node_names = collections.OrderedDict()\n\n        def _insert_scope_node_names_dict(scope_no, node_name):\n            if scope_node_names.get(scope_no, None):\n                scope_node_names[scope_no].append(node_name)\n            else:\n                scope_node_names[scope_no] = list([node_name])\n\n        def _get_scope_name_dict_by_cond(cond_top, cond_sub):\n            for node_name in node_list:\n                node = self._graph.get_node(node_name)\n                if not node.get_attr(\'scope\'):\n                    continue\n                node_scope = node.get_attr(\'scope\')\n                if cond_top(top_scope, node_scope) and cond_sub(sub_scope, node_scope):\n                    if \'True\' in cond_top.__name__ and \'True\' not in cond_sub.__name__:\n                        scope_no = node_scope.split(\'/\')[sub_level]\n                    elif \'True\' not in cond_top.__name__ and \'True\' in cond_sub.__name__:\n                        scope_no = node_scope.split(\'/\')[top_level]\n                    else:  # both not equal True\n                        scope_no = node_scope.split(\n                            \'/\')[top_level] + \'_\' + node_scope.split(\'/\')[sub_level]\n                    _insert_scope_node_names_dict(scope_no, node.name)\n\n        def cond_x_in_y(x, y): return x in y\n\n        def cond_True(x, y): return True\n\n        # Obtain nodes where the scope name that satisfies top_level is top_scope and sub_level is sub_scope\n        if top_scope and sub_scope:\n            _get_scope_name_dict_by_cond(cond_x_in_y, cond_x_in_y)\n        # Obtain nodes where the scope name that satisfies in sub_level is sub_scope\n        elif not top_scope and sub_scope:\n            _get_scope_name_dict_by_cond(cond_True, cond_x_in_y)\n        # Obtain nodes where the scope name that satisfies in top_level is top_scope\n        elif top_scope and not sub_scope:\n            _get_scope_name_dict_by_cond(cond_x_in_y, cond_True)\n        # Obtain all nodes grouped by sub_level sub_scope\n        elif top_scope is None and sub_scope is None:\n            top_scopes = self.scope_level_name_map[top_level]\n            for top_scope in top_scopes:  # this top_scope will replace the input top_scope\n                _get_scope_name_dict_by_cond(cond_x_in_y, cond_True)\n\n        return scope_node_names\n\n\n    \'\'\'get the node names\' topology sort of scope nodes\'\'\'\n    \n    def _get_scope_nodes_topology_list(self, scope_node_name_set):\n\n        temp_dict = {}\n        for index, name in enumerate(scope_node_name_set):\n            # cover the node\n            self._graph.get_node(name).covered = True\n            # store idx, node into a dict and sort it later to keep its topology sort.\n            index = self._graph.topological_sort.index(name)\n            temp_dict[name] = index\n\n        temp_dict = sorted(\n            temp_dict.items(), key=lambda item: item[1])\n\n        return [x[0] for x in temp_dict]\n\n\n    \'\'\' rebuild the conncetion of the edge around this scope node.\'\'\'\n    \n    def _rebuild_scope_edges_and_get_ret_vars(self, scope_node):\n        \n        def _get_index(node ,name):\n            for idx, in_edge in enumerate(node.in_edges):\n                if in_edge.split(\':\')[0] == name:\n                    return idx\n\n        return_nodes = list()\n        return_variable_names = list()\n\n        for n_name in scope_node.topology_list:\n            n = self._graph.get_node(n_name)\n            for in_edge in n.in_edges:\n\n                if not in_edge.split(\':\')[0] in scope_node.topology_list:\n                    if not in_edge in scope_node.in_edges:\n                        scope_node.in_edges.append(in_edge)\n\n                    # in_node\'s out edges replace n_name with scope node name.\n                    in_node = self._graph.get_node(in_edge)\n                    if n_name in in_node.out_edges:\n                        idx = in_node.out_edges.index(n_name)\n                        in_node.out_edges.remove(n_name)\n                        if scope_node.name not in in_node.out_edges:\n                            in_node.out_edges.insert(idx, scope_node.name)\n\n            for out_edge in n.out_edges:\n\n                if not out_edge in scope_node.topology_list:\n                    out_node = self._graph.get_node(out_edge)\n                    parent_node_variable_name = self._graph.get_parent_variable_name(out_edge.split(\n                        \':\')[0], [_get_index(self._graph.get_node(out_edge), n_name)])\n\n                    if parent_node_variable_name not in return_variable_names:\n                        return_nodes.append(self._graph.get_node(n_name))\n                        return_variable_names.append(parent_node_variable_name)\n                    scope_node.out_edges.append(out_edge)\n\n        # no out nodes means the last node in scope nodes should be returned\n        if not return_nodes:\n            return_nodes.append(self._graph.get_node(\n                scope_node.topology_list[-1]))\n            return_variable_names.append(self._graph.get_node(\n                scope_node.topology_list[-1]).real_variable_name)\n\n        ret_idx = 0\n        for ret_node, ret_variable_name in zip(return_nodes, return_variable_names):\n\n            subscript = \'\' if len(ret_variable_name.split(\n                \'[\')) == 1 else \':\'+ret_variable_name.split(\'[\')[1].split(\']\')[0]\n\n            for out_name in ret_node.out_edges:\n                if not out_name in scope_node.topology_list:\n                    out_node = self._graph.get_node(out_name)\n\n                    ret_name = ret_node.name + subscript\n                    if ret_name in out_node.in_edges:\n                        insert_pos = out_node.in_edges.index(ret_name)\n                        insert_name = scope_node.name + \\\n                            \':{}\'.format(str(ret_idx)) if len(\n                                return_variable_names) > 1 else scope_node.name\n                        out_node.in_edges.remove(ret_name)\n                        out_node.in_edges.insert(insert_pos, insert_name)\n\n                        # if out_node is scope node, replace the scope node\'s inner topology list node.\n                        if out_node.type == \'Scope\':\n                            for n in out_node.topology_list:\n                                n = self._graph.get_node(n)\n                                if ret_name in n.in_edges:\n                                    idx = n.in_edges.index(ret_name)\n                                    n.in_edges.remove(ret_name)\n                                    n.in_edges.insert(idx, insert_name)\n            ret_idx += 1\n\n        return return_variable_names\n\n\n    \'\'\' if the input params include tensor which is multi-output type(e.g. unstack), then we need \n    to check whether this scope function body uses only one of the outputs or multi outputs. if it is \n    the former, feed the selected one(e.g. unstack[0]), otherwise feed all. \'\'\'\n    \n    def _check_and_get_input_params(self, scope_node):\n\n        def wipe_in_egde_idx(in_name, node):\n            for idx, in_edge in enumerate(node.in_edges):\n                if in_name in in_edge:\n                    node.in_edges[idx] = in_edge.split(\':\')[0]\n            node.in_edges = sorted(set(node.in_edges), key=node.in_edges.index)\n\n        input_params = list()\n        in_name_dict = collections.OrderedDict()\n        for in_name in scope_node.in_edges:\n\n            if self._graph.get_node(in_name).variable_name not in input_params:\n                input_params.append(self._graph.get_node(\n                    in_name).variable_name)\n            if \':\' not in in_name:\n                continue\n\n            if in_name_dict.get(in_name.split(\':\')[0], None):\n                in_name_dict[in_name.split(\':\')[0]].add(\n                    in_name.split(\':\')[1])\n            else:\n                in_name_dict[in_name.split(\':\')[0]] = set(\n                    [in_name.split(\':\')[1]])\n\n        for in_name, subscript_set in in_name_dict.items():\n            # the input parameter shoule be sliced when call func.\n            if len(subscript_set) == 1:\n\n                # modify the in_edges in scope inner nodes. decline the :idx.\n                for n in scope_node.topology_list:\n                    n = self._graph.get_node(n)\n                    wipe_in_egde_idx(in_name, n)\n            else:  # >2\n                wipe_in_egde_idx(in_name, scope_node)\n\n        return input_params\n\n\n    \'\'\'\n    create a scope node.\n\n    Args:\n    scope_name: the name of this scope, will be assigned to scope pattern.\n    scope_node_names: node names involved by this scope. \n    top_node: the top node in these scope nodes.\n    \'\'\'\n    \n    def _create_scope_node(self, scope_name, scope_node_names, top_node):\n        # 1. initilize scope node\n        scope_node = self._initialize_scope_node(top_node)\n\n        # 2. get scope nodes\' topology list.\n        scope_node.topology_list = self._get_scope_nodes_topology_list(\n            scope_node_names)\n        scope_node.pattern = scope_name\n\n        # 3. rebuild the edges connection after folding these scope nodes into one node and \n        # get this scope node\'s return variables.\n        scope_node.return_variables = self._rebuild_scope_edges_and_get_ret_vars(\n            scope_node)\n\n        # 4. rebuild graph.\n        self._graph.layer_map[scope_node.name] = scope_node\n        self._graph.layer_name_map[scope_node.name] = scope_node.name\n        self._graph.rebuild()\n\n\n    \'\'\'initialize a scope node by copying source_node\'s attrs.\'\'\'\n    \n    def _initialize_scope_node(self, source_node):\n        scope_node = self._graph.model.node.add()\n        scope_node.name = source_node.name + \'_scope\'\n        scope_node.op = \'Scope\'\n        scope_node = IRGraphNode(scope_node)\n\n        kwargs = {}\n        kwargs[\'scope\'] = source_node.get_attr(\'scope\')\n\n        if \'data_format\' in source_node.layer.attr:\n            kwargs[\'data_format\'] = source_node.get_attr(\'data_format\')\n\n        if \'_output_shapes\' in source_node.layer.attr:\n            scope_node.layer.attr[""_output_shapes""].MergeFromString(\n                source_node.layer.attr[\'_output_shapes\'].SerializeToString())\n        if \'value\' in source_node.layer.attr:\n            kwargs[\'value\'] = source_node.get_attr(\'value\')\n        # RNN-related attrs.\n        if \'input_size\' in source_node.layer.attr:\n            kwargs[\'input_size\'] = source_node.get_attr(\'input_size\')\n        if \'num_units\' in source_node.layer.attr:\n            kwargs[\'num_units\'] = source_node.get_attr(\'num_units\')\n        if \'fill_size\' in source_node.layer.attr:\n            kwargs[\'fill_size\'] = source_node.get_attr(\'fill_size\')\n        if \'fill_value\' in source_node.layer.attr:\n            kwargs[\'fill_value\'] = source_node.get_attr(\'fill_value\')\n\n        assign_IRnode_values(scope_node.layer, kwargs)\n        return scope_node\n\n\n    \'\'\'\n    check whether same pattern scope node has same inputs and outputs.\n    For thoese do not have, rename it\'s pattern by adding serial number suffix.\n    \'\'\'\n    \n    def check_scope(self):\n        name_no_dict = collections.OrderedDict()\n        name_inp_out_dict = collections.OrderedDict()\n\n        for name, ir_node in self._graph.layer_map.items():\n            if ir_node.type == \'Scope\':\n                #get input params\n                ir_node.input_params = self._check_and_get_input_params(ir_node)\n                origi_pattern = re.sub(r\'(_\\d+)*$\', \'\', ir_node.pattern)\n                if name_inp_out_dict.get(origi_pattern, None):\n                    inps_and_outs = name_inp_out_dict[origi_pattern]\n                    exist_Equal = False\n                    for inp_out in inps_and_outs:\n                        if len(ir_node.input_params) == len(inp_out[0]) and len(ir_node.return_variables)== len(inp_out[1]):\n                            exist_Equal = True\n                            if inp_out[2]:\n                                ir_node.pattern = ir_node.pattern + \'_\' + str(inp_out[2])\n\n                    if not exist_Equal:\n                        name_inp_out_dict[origi_pattern].append([ir_node.input_params, ir_node.return_variables, name_no_dict.get(origi_pattern, 1)])\n                        ir_node.pattern = ir_node.pattern + \'_\' + str(name_no_dict.get(origi_pattern, 1))\n                        name_no_dict[origi_pattern] = name_no_dict.get(origi_pattern, 1) + 1\n\n                else:\n                    name_inp_out_dict[origi_pattern] = [[ir_node.input_params, ir_node.return_variables, 0]]\n                    name_no_dict[ir_node.pattern] = name_no_dict.get(origi_pattern, 0) + 1\n    \n\n    \'\'\'\n    check whether same pattern scope node has same weights.\n    For thoese do not have, rename it\'s pattern by adding serial number suffix.\n    \'\'\'\n    \n    def check_weights(self):\n        weight_related_ops = [\'FullyConnected\']\n        pattern_weight_op = collections.OrderedDict()\n        name_no_dict = collections.OrderedDict()\n        pattern_weights = collections.OrderedDict()\n\n        for ir_node_name in self._graph.topological_sort:\n            ir_node = self._graph.get_node(ir_node_name)\n            if ir_node.type == \'Scope\':\n                for inner_name in ir_node.topology_list:\n                    if self._graph.get_node(inner_name).type in weight_related_ops:\n                        if pattern_weight_op.get(ir_node.pattern, None):\n                            if self._weights_dict[inner_name][\'weights\'].any() and pattern_weights.get(ir_node.pattern, None):\n                                inner_weights = self._weights_dict[inner_name][\'weights\']\n                                isExist = False\n                                for idx, it in enumerate(pattern_weights[ir_node.pattern]):                                        \n                                    if np.array_equal(inner_weights, it[\'weights\']):\n                                        ir_node.pattern = ir_node.pattern + \'_\'+ str(idx)\n                                        isExist = True\n                                        break\n                                if isExist:\n                                    continue\n                            pattern_weight_op[ir_node.pattern].add(inner_name)\n                            pattern_weights[ir_node.pattern].append(self._weights_dict[inner_name])\n                            ir_node.pattern = ir_node.pattern + \'_\'+ str(len(pattern_weights[ir_node.pattern])-1)\n\n                        else:\n                            pattern_weight_op[ir_node.pattern] = set([inner_name])\n                            if self._weights_dict.get(inner_name, None):\n                                pattern_weights[ir_node.pattern] = [self._weights_dict[inner_name]]\n                                ir_node.pattern = ir_node.pattern + \'_\'+ str(name_no_dict.get(ir_node.pattern, 0))\n\n'"
mmdnn/conversion/rewriter/graph_matcher.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Utilities that match patterns in a Graph.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport abc\nimport itertools\n\nfrom mmdnn.conversion.common.DataStructure.graph import Graph\n\n\n\nclass Pattern(object):\n  """"""The parent class of all patterns (e.g. OpTypePattern and OneofPattern).""""""\n\n  @abc.abstractmethod\n  def match(self, op, tensor):\n    """"""Returns the result of matching op/tensor against this pattern.""""""\n    raise NotImplementedError(\'Method ""match"" not implemented.\')\n\n\nclass OpTypePattern(Pattern):\n  """"""A tree pattern that matches TF expressions with certain op types.""""""\n\n  def __init__(self, op_type, name=None, inputs=None, ordered_inputs=True):\n    """"""Initializes an OpTypePattern.\n\n    Args:\n      op_type: string that specifies the allowed types of the root. It can be\n        (1) an op type, e.g. \'Conv2D\',\n        (2) \'*\', i.e. wildcard, or\n        (3) multiple op types separated by \'|\', e.g., \'Relu|Relu6\'.\n        We could use regex strings, which might be worthwhile when we have many\n        similar TF op types.\n      name: Optional string. The name of the pattern that can be looked up in\n        MatchResult.\n      inputs: Optional list of `Pattern`s or strings that specify the\n        patterns for the inputs of a matching op. If None, this pattern accepts\n        any inputs of a matching op.\n      ordered_inputs: Defaults to True. If False, will match any op that\n        matches a permutation of the inputs.\n\n    Raises:\n      ValueError: if too many inputs are provided when order_inputs is False.\n    """"""\n    self._op_type = op_type\n    self._name = name\n    if inputs is None:\n      inputs = []\n    if len(inputs) > 8:\n      raise ValueError(\n          \'Only < 8 inputs are allowed when ordered_inputs is False.\')\n    self._inputs = [\n        input_pattern\n        if isinstance(input_pattern, Pattern) else OpTypePattern(input_pattern)\n        for input_pattern in inputs\n    ]\n    self._ordered_inputs = ordered_inputs\n\n\n  @property\n  def name(self):\n    return self._name\n\n  @property\n  def scope_ids(self):\n    return self._scope_ids\n\n  @property\n  def inputs(self):\n    return self._inputs\n\n  @property\n  def type(self):\n    return self._op_type\n\n  def set_op_scope(self, op, scope):\n    op.scope = scope\n\n\n  def match(self, op):\n    if self._op_type != \'*\':\n      if op.type not in self._op_type.split(\'|\'):\n        return None\n    \n    match_result = MatchResult()\n    match_result.add(self, op)\n\n    if not self._inputs:\n      # If pattern.inputs is empty, skips the rest and accepts all the inputs.\n      return match_result\n\n    if len(op.in_edges) != len(self._inputs):\n      return None\n\n    input_patterns_list = [self._inputs]\n    # If order doesn\'t matter for the inputs, then make sure we match at least\n    # one permutation of the inputs.\n    if not self._ordered_inputs:\n      input_patterns_list = list(itertools.permutations(self._inputs))\n\n    for input_patterns in input_patterns_list:\n      match_failed = False\n\n      for input_op, input_pattern in zip(op.in_nodes, input_patterns):\n        input_match_result = input_pattern.match(input_op)\n        if input_match_result is None:\n          match_failed = True\n          break\n        match_result.merge_from(input_match_result)\n      if not match_failed:\n        return match_result\n    return None\n\n\nclass OneofPattern(Pattern):\n  """"""Matches one of the given sub-patterns.""""""\n\n  def __init__(self, sub_patterns):\n    self._sub_patterns = sub_patterns\n\n  def match(self, op):\n    for sub_pattern in self._sub_patterns:\n      match_result = sub_pattern.match(op)\n      if match_result is not None:\n        return match_result\n    return None\n\n\nclass MatchResult(object):\n  r""""""Encapsulates the result of a match done by GraphMatcher.\n\n  MatchResult contains a map from Pattern to the matching op and tensor.\n  When the matching op has multiple output tensors, the matching tensor is the\n  output tensor used by the matching op of the parent pattern. E.g., when we\n  match graph\n\n      -         +\n     / \\y0   y1/ \\\n    x    split    z\n          |\n          y         (nodes are ops; edges are going up)\n\n  against add_pattern defined as\n\n    y1_pattern = OpTypePattern(\'*\')\n    z_pattern = OpTypePattern(\'*\')\n    add_pattern = OpTypePattern(\'+\', inputs=[y1_pattern, z_pattern])\n\n  the matching op of `y1_pattern` is `split`, and the matching tensor of\n  `y1_pattern`\n  is `y1` not `y0`.\n  """"""\n\n  def __init__(self):\n    self._pattern_to_op = {}\n    self._name_to_pattern = {}\n\n\n  def add(self, pattern, op):\n    self._pattern_to_op[pattern] = op\n    if pattern.name is not None:\n      if pattern.name in self._name_to_pattern:\n        raise ValueError(\n            \'Name %s is already bound to another pattern\' % pattern.name)\n      self._name_to_pattern[pattern.name] = pattern\n\n\n  def _to_pattern(self, pattern_or_name):\n    if isinstance(pattern_or_name, Pattern):\n      return pattern_or_name\n\n    if isinstance(pattern_or_name, str):\n      if pattern_or_name not in self._name_to_pattern:\n        return None\n      return self._name_to_pattern[pattern_or_name]\n\n    raise ValueError(\'pattern_or_name has type %s. Expect Pattern or str.\' %\n                     type(pattern_or_name))\n\n  def _get_op_tensor(self, pattern_or_name):\n    pattern = self._to_pattern(pattern_or_name)\n    if pattern is None:\n      return None\n\n    if pattern not in self._pattern_to_op:\n      return None\n\n    return self._pattern_to_op[pattern]\n\n  def get_op(self, pattern_or_name):\n    op_tensor = self._get_op_tensor(pattern_or_name)\n    return op_tensor if op_tensor else None\n\n  # def get_tensor(self, pattern_or_name):\n  #   op_tensor = self._get_op_tensor(pattern_or_name)\n  #   return op_tensor[1] if op_tensor else None\n\n  def merge_from(self, other_match_result):\n    # pylint: disable=protected-access\n    self._pattern_to_op.update(other_match_result._pattern_to_op)\n    self._name_to_pattern.update(other_match_result._name_to_pattern)\n    # pylint: enable=protected-access\n\n\nclass GraphMatcher(object):\n  """"""Checks if a particular subgraph matches a given pattern.""""""\n\n  def __init__(self, pattern):\n    """"""Initializes a GraphMatcher.\n\n    Args:\n      pattern: The `Pattern` against which `GraphMatcher` matches\n        subgraphs.\n    """"""\n    self._pattern = pattern\n\n  def _match_pattern(self, pattern, op):\n    """"""Returns whether an TF expression rooted at `op` matches `pattern`.\n\n    If there is a match, adds to `self._match_result` the matching op and tensor\n    with key `pattern`.\n\n    Args:\n      pattern: An `Pattern`.\n      op: A `tf.Operation` to match against the pattern.\n      tensor: the output `tf.Tensor` of `op` that is used by the matching op of\n        `pattern`\'s parent. Can be None if `pattern` is already the root of the\n        pattern tree.\n\n    Returns:\n      True if an TF expression rooted at `op` matches `pattern`.\n    """"""\n    match_result = pattern.match(op)\n    if match_result is None:\n      return False\n    self._match_result.merge_from(match_result)\n    return True\n\n  def match_op(self, op):\n    """"""Matches `op` against `self._pattern`.\n\n    Args:\n      op: `tf.Operation` to match against the pattern.\n\n    Returns:\n      Returns a `MatchResult` if `op` matches the pattern; otherwise, returns\n      None.\n    """"""\n    self._match_result = MatchResult()\n    if not self._match_pattern(self._pattern, op):\n      return None\n    return self._match_result\n\n  def match_ops(self, ops):\n    """"""Matches each operation in `ops` against `self._pattern`.\n\n    Args:\n      ops: collection of `tf.Operation` to match against the pattern.\n\n    Yields:\n      `MatchResult` for each `tf.Operation` that matches the pattern.\n    """"""\n    for op in ops:\n      match_result = self.match_op(op)\n      if match_result:\n        yield match_result\n\n  def match_graph(self, graph):\n    """"""Matches each operation in `graph` against `self._pattern`.\n\n    Args:\n      graph: `tf.Graph` containing operations to match.\n\n    Yields:\n      `MatchResult` for each `tf.Operation` in `graph` that matches the pattern.\n    """"""\n    # Python 3.3.2+ implements `yield from`, but for now:\n    for match_result in self.match_ops(graph.get_nodes()):\n      yield match_result\n'"
mmdnn/conversion/rewriter/rewriter.py,0,"b""from __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nimport tensorflow\nfrom tensorflow.python.framework import tensor_util\nfrom tensorflow.core.framework import attr_value_pb2\n\nimport sys\n\nfrom mmdnn.conversion.tensorflow.tensorflow_graph import *\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.rewriter.graph_matcher import *\n\nfrom mmdnn.conversion.common.DataStructure import *\nfrom tensorflow.core.framework.node_def_pb2 import NodeDef\nfrom mmdnn.conversion.rewriter.rnn_utils import *\n\n\nclass UnitRewriterBase(object):\n\n\n    def __init__(self, graph, weights_dict):\n        self._graph = graph\n        self._weights_dict = weights_dict\n\n    def _rewrite_graph_by_pattern(self, pattern_name, graph_type):\n        pattern = rnn_patterns[graph_type][pattern_name]\n        matcher = GraphMatcher(pattern)\n        match_results = list(matcher.match_ops(self._graph.get_nodes()))\n        scope_names_dict = dict() # name: No.\n\n        for i in range(len(match_results)):\n            result = match_results[i]\n            top_pattern_name = pattern_name + '_' + str(i)\n\n            top_pattern = result._name_to_pattern[pattern_name]\n            self.create_scope(result, top_pattern, scope_names_dict)\n\n            top_op = result._pattern_to_op[top_pattern]\n            top_op.scope = top_op.scope + '/top'\n\n            # self.store_const_to_top(result)\n            # self.set_top_node_prop(result, pattern_name)\n            self.process_match_result(result, pattern_name)\n\n\n    def rewrite_graph(self, pattern_names, graph_type):\n        from six import string_types as _string_types\n        if isinstance(pattern_names, _string_types):\n            pattern_names = [pattern_names]\n        elif not isinstance(pattern_names, list):\n            raise ValueError\n        for pattern_name in pattern_names:\n            self._rewrite_graph_by_pattern(pattern_name, graph_type)\n\n    def run(self, pattern_names, graph_type):\n        self.rewrite_graph(pattern_names, graph_type)\n    \n    def store_const_to_top(self, match_result):\n        top_node = list(match_result._pattern_to_op.values())[0]\n        kwargs = dict()\n        for pattern, op in match_result._pattern_to_op.items():\n            if pattern.name and pattern.type == 'Const':\n                if tensor_util.MakeNdarray(op.get_attr('value')).shape == (1, ):\n                    kwargs[pattern.name] = np.asscalar(tensor_util.MakeNdarray(op.get_attr('value')))\n                else:\n                    kwargs[pattern.name] = np.squeeze(tensor_util.MakeNdarray(op.get_attr('value')))\n        if hasattr(top_node, 'kwargs'):\n            top_node.kwargs.update(kwargs)\n        else:\n            top_node.kwargs = kwargs\n\n    def create_scope(self, result, pattern, scope_names_dict, parent_scope_name=''):\n        op = result._pattern_to_op[pattern]\n\n        if pattern.name:\n            # Do not include input op.\n            if 'input' in pattern.name.split('/')[-1]:\n                return\n            else:\n                no = scope_names_dict.get(pattern.name, 0)\n                scope_names_dict[pattern.name] = no + 1\n                if parent_scope_name:\n                    current_scope_name = '/'.join([parent_scope_name, pattern.name]) + '_' + str(no)\n                else:\n                    current_scope_name = pattern.name + '_' + str(no)\n        else:\n            current_scope_name = parent_scope_name\n        op.scope = current_scope_name\n        for sub_pattern in pattern.inputs:\n            self.create_scope(result, sub_pattern, scope_names_dict, current_scope_name)\n\n    def set_top_node_prop(self, match_result):\n        raise NotImplementedError\n\n\n    def process_match_result(self, match_result, pattern_name):\n        raise NotImplementedError\n"""
mmdnn/conversion/rewriter/rnn_utils.py,0,"b'from mmdnn.conversion.rewriter.graph_matcher import *\nfrom mmdnn.conversion.tensorflow.tensorflow_graph import *\nimport numpy as np\n\n\n\'\'\'batch size pattern in tensorflow. Note: do not include _number in name\'\'\'\nstatic_rnn_batch_size_pattern = OpTypePattern(\'ExpandDims\', name=\'static_rnn_batch_size\', inputs=[\n    OpTypePattern(\'StridedSlice\', inputs=[\n        OpTypePattern(\'Shape\', inputs=[\n            OpTypePattern(\'*\', name=\'input\')\n        ]),\n        OpTypePattern(\'Const\'),\n        OpTypePattern(\'Const\'),\n        OpTypePattern(\'Const\')\n    ]),\n    OpTypePattern(\'Const\')\n])\n\n\'\'\'rnn h zero pattern in tensorflow.\'\'\'\nstatic_rnn_h_zero_pattern = OpTypePattern(\'Fill\', name=\'h_zero\', inputs=[\n    OpTypePattern(\'ConcatV2|Concat\', inputs=[\n        OpTypePattern(\'*\', name=\'input\'),\n        OpTypePattern(\'Const\', name=\'fill_size\'),\n        OpTypePattern(\'Const\')\n    ]),\n    OpTypePattern(\'Const\', name=\'fill_value\')\n])\n\n\'\'\'\'split pattern in gru cell in tensorflow\'\'\'\ngru_xc_pattern = OpTypePattern(\'Split\', name=\'xc\', inputs=[\n    OpTypePattern(""Const""), # axis for split\n    OpTypePattern(""Sigmoid"", inputs=[\n        OpTypePattern(""BiasAdd"", name=""bias_add"", inputs=[\n            OpTypePattern(""MatMul"", inputs=[\n                OpTypePattern(""ConcatV2|Concat"", name=""xh""),\n                OpTypePattern(""Identity"", name=\'cell_kernel\')\n            ]),\n        OpTypePattern(""Identity"", name=\'cell_bias\')\n    ])]),\n])\n\n\'\'\'split pattern in lstm cell in tensorflow\'\'\'\nlstm_xc_pattern = OpTypePattern(\'Split\', inputs=[\n    OpTypePattern(""Const""), # axis for split\n    OpTypePattern(""BiasAdd"", name=""bias_add"", inputs=[\n        OpTypePattern(""MatMul"", inputs=[\n            OpTypePattern(""ConcatV2|Concat"", name=""xh""),\n            OpTypePattern(""*"", name=""cell_kernel""),\n        ]),\n        OpTypePattern(""*"", name=""cell_bias""),\n    ]),\n])\n\n\'\'\'\'gru cell pattern in tensorflow\'\'\'\ngrucell_pattern = \\\n    OpTypePattern(\'Add\', name=\'gru_cell\', inputs=[\n        OpTypePattern(\'Mul\', inputs=[\n            gru_xc_pattern,\n            OpTypePattern(\'*\', name=\'input\')\n        ]),\n        OpTypePattern(\'Mul\', inputs=[\n            OpTypePattern(\'Sub\', inputs=[\n                OpTypePattern(\'Const\'),\n                gru_xc_pattern\n            ]),\n            OpTypePattern(\'Tanh\', inputs=[\n                OpTypePattern(\'BiasAdd\', inputs=[\n                    OpTypePattern(\'MatMul\', name=\'FullyConnect\', inputs=[\n                        OpTypePattern(\'Concat|ConcatV2\', inputs=[\n                            OpTypePattern(\'*\', name=\'input\'),\n                            OpTypePattern(\'Mul\', inputs=[\n                                gru_xc_pattern,\n                                OpTypePattern(\'*\', name=\'input\')\n                            ]),\n                            OpTypePattern(\'Const\'),\n                        ]),\n\n                        OpTypePattern(\'Identity\', name=\'candidate_kernel\')\n                    ]),\n                    OpTypePattern(\'Identity\', name=\'candidate_bias\')\n                ])\n            ])\n        ])\n    ])\n\n\n\'\'\'\'lstm cell pattern in tensorflow\'\'\'\nlstmcell_pattern = \\\n    OpTypePattern(\'Mul\', name=\'lstm_cell\', inputs=[\n        OpTypePattern(""Sigmoid"", name=""ot"", inputs=[lstm_xc_pattern]),\n        OpTypePattern(\'Tanh\', inputs=[\n            OpTypePattern(""Add"", name=""ct"", inputs=[\n                OpTypePattern(""Mul"", inputs=[\n                    OpTypePattern(""Sigmoid"", name=""ft"", inputs=[\n                        OpTypePattern(""Add"", inputs=[\n                            lstm_xc_pattern,\n                            OpTypePattern(""*"", name=""ft_bias""),\n                        ]),\n                    ]),\n                    OpTypePattern(""*"", name=\'input\'),\n                ]),\n                OpTypePattern(""Mul"", inputs=[\n                    OpTypePattern(""Sigmoid"", name=""it"", inputs=[lstm_xc_pattern]),\n                    OpTypePattern(""Tanh"", name=""gt"", inputs=[lstm_xc_pattern]),\n                ]),\n            ]),\n        ]),\n    ])\n\n\nrnn_patterns = {\n    \'tensorflow\': {\n        \'gru_cell\': grucell_pattern,\n        \'lstm_cell\': lstmcell_pattern,\n        \'h_zero\': static_rnn_h_zero_pattern,\n        \'static_rnn_batch_size\': static_rnn_batch_size_pattern\n    }\n    # TODO: pytorch, mxnet, keras, cntk\n}'"
mmdnn/conversion/rewriter/utils.py,0,"b'from mmdnn.conversion.rewriter.rewriter import UnitRewriterBase\nfrom mmdnn.conversion.tensorflow.rewriter.gru_rewriter import GRURewriter\nfrom mmdnn.conversion.tensorflow.rewriter.lstm_rewriter import LSTMRewriter\n\ndef process_graph(graph, weights):\n    rewriter_list = [GRURewriter, LSTMRewriter]\n\n    for rewriter in rewriter_list:\n        rewriter(graph, weights).run()'"
mmdnn/conversion/tensorflow/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/tensorflow/saver.py,0,"b""import tensorflow as tf\n\n\ndef save_model(MainModel, network_filepath, weight_filepath, dump_filepath, dump_tag = 'SERVING'):\n    if dump_tag == 'SERVING':\n        tag_list = [tf.saved_model.tag_constants.SERVING]\n    else:\n        tag_list = [tf.saved_model.tag_constants.TRAINING]\n    res = MainModel.KitModel(weight_filepath)\n    input = res[0]\n    model = res[1:]\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n\n        builder = tf.saved_model.builder.SavedModelBuilder(dump_filepath)\n\n        tensor_info_input = tf.saved_model.utils.build_tensor_info(input)\n        outputs = {'output{}'.format(i): tf.saved_model.utils.build_tensor_info(model[i]) for i in range(len(model))}\n        prediction_signature = (\n            tf.saved_model.signature_def_utils.build_signature_def(\n                inputs={'input': tensor_info_input},\n                outputs=outputs,\n                method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n            )\n        )\n\n        builder.add_meta_graph_and_variables(\n            sess,\n            tag_list,\n            signature_def_map={\n                tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_signature\n            }\n        )\n\n        save_path = builder.save()\n\n    print('Tensorflow file is saved as [{}], generated by [{}.py] and [{}].'.format(\n        save_path, network_filepath, weight_filepath))\n"""
mmdnn/conversion/tensorflow/tensorflow_emitter.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\n\nfrom mmdnn.conversion.common.IR.IR_graph import IRGraph, IRGraphNode\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.DataStructure.emitter import Emitter\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.rewriter.folder import Folder\n\n\nclass TensorflowEmitter(Emitter):\n\n    dtype_map = {\n        graph_pb2.DT_FLOAT16 : ""tf.float16"",\n        graph_pb2.DT_FLOAT32 : ""tf.float32"",\n        graph_pb2.DT_FLOAT64 : ""tf.float64"",\n        graph_pb2.DT_INT16 : ""tf.int16"",\n        graph_pb2.DT_INT32 : ""tf.int32"",\n        graph_pb2.DT_INT64 : ""tf.int64"",\n        graph_pb2.DT_UINT8 : ""tf.uint8"",\n        graph_pb2.DT_UINT16 : ""tf.uint16""\n    }\n\n\n    @property\n    def header_code(self):\n        return """"""import tensorflow as tf\n\n__weights_dict = dict()\n\nis_train = {}\n\ndef load_weights(weight_file):\n    import numpy as np\n\n    if weight_file == None:\n        return\n\n    try:\n        weights_dict = np.load(weight_file, allow_pickle=True).item()\n    except:\n        weights_dict = np.load(weight_file, allow_pickle=True, encoding=\'bytes\').item()\n\n    return weights_dict\n\n\ndef KitModel(weight_file = None):\n    global __weights_dict\n    __weights_dict = load_weights(weight_file)\n"""""".format(self.trainable)\n\n\n    def __init__(self, model):\n        super(TensorflowEmitter, self).__init__()\n\n        from six import string_types as _string_types\n        if isinstance(model, _string_types):\n            network_path = model\n        else:\n            network_path = model[0]\n            self._load_weights(model[1])\n\n        self.IR_graph = IRGraph(network_path)\n        super(TensorflowEmitter, self)._build()\n        \n        folder = Folder(self.IR_graph, self.weights_dict)\n        folder.fold()\n\n    def gen_code(self, phase):\n        self.trainable = (phase == \'train\')\n        self.add_body(0, self.header_code)\n\n        for layer in self.IR_graph.topological_sort:\n            current_node = self.IR_graph.get_node(layer)\n            node_type = current_node.type\n\n            if hasattr(self, ""emit_"" + node_type):\n                func = getattr(self, ""emit_"" + node_type)\n                line = func(current_node)\n                if line != None:\n                    self.add_body(1, line)\n            else:\n                print(""TensorflowEmitter has not supported operator [%s]."" % (node_type))\n                self.emit_UNKNOWN(current_node)\n\n\n        self.add_body(1, ""return {}, {}"".format(\n            \', \'.join([self.IR_graph.get_node(name).real_variable_name for name in self.IR_graph.input_layers if self.IR_graph.get_node(name).type != \'Const\' and not self.IR_graph.get_node(name).get_attr(\'feed_weights\')]),\n            \', \'.join([self.IR_graph.get_node(name).real_variable_name for name in self.IR_graph.output_layers if self.IR_graph.get_node(name).type != \'Pack\' and  self.IR_graph.get_node(name).type !=\'Shape\'])))\n\n\n\n        self.add_body(0, """")\n        for i in self.used_layers:\n            func = getattr(self, ""_layer_"" + i)\n            func()\n\n        self.add_body(0, """")\n        for code in self.layers_codes.values():\n            self.add_body(0, code)\n\n        return self.body_code\n\n\n    def parent_variable_name(self, IR_node, path=[0]):\n        if not IR_node.in_edges and IR_node.name in self.weights_dict.keys():\n            return ""tf.constant(__weights_dict[\'{}\'][\'weights\'], name=\'{}\')"".format(\n                IR_node.name,\n                IR_node.name)\n        return super(TensorflowEmitter, self).parent_variable_name(IR_node, path)\n\n\n    @staticmethod\n    def _shapeToStr(shapes):\n        ret = [dim.size if dim.size != -1 else \'None\' for dim in shapes.dim]\n        return \', \'.join(\'%s\' % i for i in ret)\n\n\n    def emit_Conv(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        strides_str = \', \'.join(\'%s\' % i for i in IR_node.get_attr(\'strides\')[1:-1])\n        input_node, padding = self._defuse_padding(IR_node)\n        data_format = IR_node.get_attr(\'data_format\')\n        code = ""{:<15} = convolution({}, group={}, strides=[{}], padding=\'{}\', name=\'{}\')"".format(\n            IR_node.variable_name,\n            input_node,\n            IR_node.get_attr(\'group\', 1),\n            strides_str,\n            padding,\n            IR_node.name)\n        return code\n\n    def _defuse_padding(self, IR_node, extra_str=""""):\n        auto_pad = IR_node.get_attr(\'auto_pad\')\n        if auto_pad:\n            input_node = self.parent_variable_name(IR_node)\n            if auto_pad == \'VALID\':\n                padding = \'VALID\'\n            elif auto_pad.startswith(""SAME""):\n                padding = \'SAME\'\n            else:\n                raise ValueError(""Unknown padding type [{}]."".format(auto_pad))\n\n            return input_node, padding\n\n        else:\n            padding = IR_node.get_attr(""pads"")\n            padding = convert_onnx_pad_to_tf(padding)\n            if not is_valid_padding(padding):\n                input_node = IR_node.variable_name + \'_pad\'\n                self.add_body(1, ""{:<15} = tf.pad({}, paddings = {}{})"".format(\n                    input_node,\n                    self.parent_variable_name(IR_node),\n                    padding,\n                    extra_str\n                    ))\n            else:\n                input_node = self.parent_variable_name(IR_node)\n\n            return input_node, \'VALID\'\n\n\n    def emit_Constant(self, IR_node):\n        if \'dtype\' in IR_node.layer.attr:\n            dtype_str = ""{}"".format(self.dtype_map[IR_node.layer.attr[\'dtype\'].type])\n        else:\n            dtype_str = ""tf.float32""\n        code = ""{:<15} = tf.constant({}, dtype={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            ""__weights_dict[\'{}\'][\'value\']"".format(IR_node.name) if IR_node.get_attr(\'value\')== None else IR_node.get_attr(\'value\'),\n            dtype_str,\n            IR_node.name)\n\n        return code\n\n\n    def emit_Pool(self, IR_node):\n        pooling_type = IR_node.get_attr(\'pooling_type\')\n        if pooling_type == \'MAX\':\n            op = \'max_pool\'\n            padding_const = "", constant_values=float(\'-Inf\')""\n        elif pooling_type == \'AVG\':\n            op = \'avg_pool\'\n            padding_const = """"\n        else:\n            raise ValueError(""unknown pooling type [{}]."".format(pooling_type))\n\n        arrlen = len(IR_node.get_attr(\'strides\'))\n        dim_str = \'3d\' if arrlen == 5 else """"\n\n        if IR_node.layer.attr[\'global_pooling\'].b:\n            code = ""{:<15} = tf.nn.{}{}({}, [1] + {}.get_shape().as_list()[1:-1] + [1], strides = [1] * {}, padding = \'VALID\', name = \'{}\')"".format(\n                IR_node.variable_name,\n                op,\n                dim_str,\n                self.parent_variable_name(IR_node),\n                self.parent_variable_name(IR_node),\n                arrlen,\n                IR_node.name)\n        else:\n            dim = len(IR_node.get_attr(""strides"")) - 2\n            dilations = IR_node.get_attr(\'dilations\')\n            if dilations:\n                for e in IR_node.get_attr(\'dilations\'):\n                    assert e == 1\n\n            pool_size = IR_node.get_attr(\'kernel_shape\')[1:-1]\n            strides = IR_node.get_attr(\'strides\')[1:-1]\n            padding = IR_node.get_attr(\'pads\')[1:dim]\n\n            if pooling_type == ""AVG"" and pool_size.count(pool_size[0]) == len(pool_size) and strides[0] == 1 and strides.count(strides[0]) == len(strides) and padding.count(padding[0]) == len(padding) and pool_size[0] == padding[0]*2 + 1:\n                kernel_shape_str = \', \'.join(\'%s\' % i for i in IR_node.get_attr(\'kernel_shape\'))\n                strides_str = \', \'.join(\'%s\' % i for i in IR_node.get_attr(\'strides\'))\n\n                code = ""{:<15} = tf.nn.{}{}({}, [{}], [{}], padding=\'{}\', name=\'{}\')"".format(\n                    IR_node.variable_name,\n                    op,\n                    dim_str,\n                    self.parent_variable_name(IR_node),\n                    kernel_shape_str,\n                    strides_str,\n                    \'SAME\',\n                    IR_node.name)\n            else:\n                kernel_shape_str = \', \'.join(\'%s\' % i for i in IR_node.get_attr(\'kernel_shape\'))\n                strides_str = \', \'.join(\'%s\' % i for i in IR_node.get_attr(\'strides\'))\n                input_node, padding = self._defuse_padding(IR_node, padding_const)\n                code = ""{:<15} = tf.nn.{}{}({}, [{}], [{}], padding=\'{}\', name=\'{}\')"".format(\n                    IR_node.variable_name,\n                    op,\n                    dim_str,\n                    input_node,\n                    kernel_shape_str,\n                    strides_str,\n                    padding,\n                    IR_node.name)\n\n        return code\n\n    def emit_UNKNOWN(self, IR_node):\n        print(IR_node.name)\n\n    def emit_Add(self, IR_node):\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            \' + \'.join(\'%s\' % self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))))\n\n        return code\n\n    def emit_DataInput(self, IR_node):\n        assert not IR_node.in_edges\n        shape_str = self._shapeToStr(IR_node.layer.attr[""shape""].shape)\n\n        if \'dtype\' in IR_node.layer.attr:\n            dtype_str = ""{}, "".format(self.dtype_map[IR_node.layer.attr[\'dtype\'].type])\n        else:\n            dtype_str = ""tf.float32,""\n\n        code = ""{:<15} = tf.placeholder({} shape = ({}), name = \'{}\')"".format(\n            IR_node.variable_name, dtype_str, shape_str, IR_node.name\n        )\n        return code\n\n    def emit_Dropout(self, IR_node):\n        parent = self.IR_graph.get_parent(IR_node.name, [0])\n        if self.trainable:\n            self.add_body(1, ""{:<15} = Dropout(name = \'{}\', dropout_rate = {})({})"".format(\n                IR_node.variable_name,\n                IR_node.name,\n                1 - IR_node.IR_layer.attr[""keep_prob""].f,\n                parent.real_variable_name))\n        else:\n            IR_node.real_name = parent.real_name\n\n\n    def emit_FullyConnected(self, IR_node):\n        if IR_node.name in self.weights_dict and \'weights\' in self.weights_dict[IR_node.name]:\n            kernel_str = ""kernel_initializer = tf.constant_initializer(__weights_dict[\'{}\'][\'weights\']), "".format(IR_node.name)\n        else: kernel_str = """"\n\n        if IR_node.name in self.weights_dict and \'bias\' in self.weights_dict[IR_node.name]:\n            bias_str = ""bias_initializer = tf.constant_initializer(__weights_dict[\'{}\'][\'bias\']), "".format(IR_node.name)\n        else: bias_str = """"\n\n        # check whether flatten operator should be added\n        parent = self.IR_graph.get_parent(IR_node.name, [0])\n        parent_shape = shape_to_list(parent.get_attr(\'_output_shapes\')[0])\n        if len(parent_shape) > 2:\n            # flatten is needed\n            self.add_body(1, ""{:<15} = tf.contrib.layers.flatten({})"".format(\n                IR_node.variable_name + \'_flatten\',\n                self.parent_variable_name(IR_node)))\n\n            code = ""{:<15} = tf.layers.dense({}, {}, {}{}use_bias = {})"".format(\n                IR_node.variable_name,\n                IR_node.variable_name + \'_flatten\',\n                IR_node.layer.attr[\'units\'].i,\n                kernel_str,\n                bias_str,\n                IR_node.layer.attr[\'use_bias\'].b)\n            return code\n\n        else:\n            code = ""{:<15} = tf.layers.dense({}, {}, {}{}use_bias = {})"".format(\n                IR_node.variable_name,\n                self.parent_variable_name(IR_node),\n                IR_node.layer.attr[\'units\'].i,\n                kernel_str,\n                bias_str,\n                IR_node.layer.attr[\'use_bias\'].b)\n            return code\n\n\n    def emit_UpSampling2D(self, IR_node):\n        scales = IR_node.get_attr(\'scales\')\n        scales = tuple(scales)\n\n        code = ""{:<15} = tf.keras.layers.UpSampling2D(size={})({})"".format(\n            IR_node.variable_name,\n            scales,\n            self.parent_variable_name(IR_node))\n        return code\n\n    def emit_Flatten(self, IR_node):\n        #self._emit_unary_operation(IR_node, ""contrib.layers.flatten"")\n        code = ""{:<15} = tf.contrib.layers.flatten({})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node))\n        return code\n\n\n    def emit_Mul(self, IR_node):\n\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            \' * \'.join(\'%s\' % self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))))\n        return code\n\n\n    def emit_Const(self, IR_node):\n        if \'dtype\' in IR_node.layer.attr:\n            dtype_str = ""dtype={}"".format(self.dtype_map[IR_node.layer.attr[\'dtype\'].type])\n            if \'int\' in dtype_str:\n                code = ""{:<15} = tf.constant({}, {}, shape=(1,))"".format(\n                    IR_node.variable_name,\n                    IR_node.layer.attr[\'value\'].i,\n                    dtype_str)\n            else:\n                code = ""{:<15} = tf.constant({}, {}, shape=(1,))"".format(\n                    IR_node.variable_name,\n                    IR_node.layer.attr[\'value\'].f,\n                    dtype_str)\n        else:\n            dtype_str = ""dtype=tf.float32""\n            code =""{:<15} = tf.constant({}, {}, shape=(1,))"".format(\n                IR_node.variable_name,\n                IR_node.layer.attr[\'value\'].f,\n                dtype_str)\n\n        return code\n\n    def emit_Transpose(self, IR_node):\n        code =""{:<15} = tf.transpose(a = {}, perm = {})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node, [0]),\n            self.parent_variable_name(IR_node, [1]))\n        \n        return code\n\n    def emit_Gather(self, IR_node):\n        variable_str = ""tf.convert_to_tensor(__weights_dict[\'{}\'][\'weights\'])"".format(IR_node.name)\n\n        code = ""{:<15} = tf.gather(params = {}, indices = {}, axis = {})"".format(\n            IR_node.variable_name,\n            variable_str,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'axis\')\n            )\n        \n        return code\n\n    def emit_Unstack(self, IR_node):\n        code = ""{:<15} = tf.unstack(value={}, num={}, axis={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'num\'),\n            IR_node.get_attr(\'axis\')\n        )\n        return code\n\n    def emit_Reshape(self, IR_node):\n        code = ""{:<15} = tf.reshape({}, [{}], \'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            \', \'.join(\'%s\' % i for i in IR_node.get_attr(\'shape\')),\n            IR_node.name)\n        \n        return code\n\n\n    def emit_Sub(self, IR_node):\n        code = ""{:<15} = {}"".format(\n            IR_node.variable_name,\n            \' - \'.join(\'%s\' % self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))))\n        \n        return code\n\n    def emit_Div(self, IR_node):\n        code = ""{:<15} = tf.div({}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]),\n            IR_node.name\n        )\n        return code\n\n    def _emit_unary_operation(self, IR_node, op_name):\n        code = ""{:<15} = tf.{}({}, name = \'{}\')"".format(\n            IR_node.variable_name,\n            op_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name)\n        return code\n\n    def emit_Tanh(self, IR_node):\n        code = self._emit_unary_operation(IR_node, \'tanh\')\n        return code\n\n    def emit_Elu(self, IR_node):\n        return self._emit_unary_operation(IR_node, \'nn.elu\')\n\n\n    def emit_Relu(self, IR_node):\n        return self._emit_unary_operation(IR_node, \'nn.relu\')\n\n\n    def emit_Relu6(self, IR_node):\n        return self._emit_unary_operation(IR_node, \'nn.relu6\')\n\n\n    def emit_CRelu(self, IR_node):\n        return self._emit_unary_operation(IR_node, \'nn.crelu\')\n\n\n    def emit_PRelu(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        code = ""{:<15} = prelu({}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name)\n        return code\n\n    def emit_LeakyRelu(self, IR_node):\n        self.add_body(1, ""{:<15} = tf.nn.leaky_relu({}, alpha={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'alpha\'),\n            IR_node.name\n        ))\n\n\n    def emit_Softmax(self, IR_node):\n        return self._emit_unary_operation(IR_node, \'nn.softmax\')\n\n\n    def emit_Sigmoid(self, IR_node):\n        code = self._emit_unary_operation(IR_node, \'sigmoid\')\n        return code\n\n    def emit_Embedding(self, IR_node):\n        variable_str = ""tf.convert_to_tensor(__weights_dict[\'{}\'][\'weights\'])"".format(IR_node.name)\n        code = ""{:<15} = tf.nn.embedding_lookup(params = {}, ids = {})"".format(\n            IR_node.variable_name,\n            variable_str,\n            self.parent_variable_name(IR_node))\n        return code\n\n    def emit_LSTM(self, IR_node):\n        return self.emit_RNNs(IR_node, ""LSTM"")\n\n\n    def emit_GRU(self, IR_node):\n        return self.emit_RNNs(IR_node, ""GRU"")\n\n\n    def emit_Concat(self, IR_node):\n        \n        code = ""{:<15} = tf.concat([{}], {}, name = \'{}\')"".format(\n            IR_node.variable_name,\n            \', \'.join(self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))),\n            IR_node.layer.attr[\'axis\'].i,\n            IR_node.name)\n\n        return code\n\n    def emit_BatchNorm(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        code = ""{:<15} = batch_normalization({}, variance_epsilon={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'epsilon\'),\n            IR_node.name)\n        return code\n\n    def emit_Scale(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        code = ""{:<15} = scale({}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name)\n        return code\n\n    def emit_Pad(self, IR_node):\n        padding = IR_node.get_attr(\'pads\')\n        padding = convert_onnx_pad_to_tf(padding)\n\n        mode = IR_node.get_attr(\'mode\', \'constant\')\n        mode = mode.lower()\n        if mode == \'constant\' or mode == \'reflect\':\n            mode = mode.upper()\n        elif mode == \'edge\':\n            mode = \'SYMMETRIC\'\n        else:\n            raise NotImplementedError(""Not support padding mode {}."".format(mode))\n        code = ""{:<15} = tf.pad({}, {}, \'{}\', name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            padding,\n            mode,\n            IR_node.variable_name)\n        return code\n\n    def emit_Squeeze(self, IR_node):\n        code = ""{:<15} = tf.squeeze({}, [{}], name = \'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            \', \'.join(\'%s\' % axis for axis in IR_node.layer.attr[\'axes\'].list.i),\n            IR_node.name)\n        return code\n\n\n    def emit_ReduceMean(self, IR_node):\n        code = ""{:<15} = tf.reduce_mean({}, [{}], {}, name = \'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            \',\'.join(\'%s\' % i for i in IR_node.get_attr(\'axes\')),\n            IR_node.get_attr(\'keepdims\'),\n            IR_node.name)\n        return code\n\n    def emit_LRN(self, IR_node):\n        input_name = IR_node.variable_name\n        output_name = self.parent_variable_name(IR_node)\n        IR_name = IR_node.name\n        size = IR_node.get_attr(\'size\')\n        depth_radius = int(IR_node.get_attr(\'size\') / 2)\n        bias = IR_node.get_attr(\'bias\', 1)\n        alpha = IR_node.get_attr(\'alpha\') / size\n        beta = IR_node.get_attr(\'beta\')\n\n        code = ""{:<15} = tf.nn.lrn({}, depth_radius={}, bias={}, alpha={}, beta={}, name=\'{}\')"".format(\n            input_name,\n            output_name,\n            depth_radius,\n            bias,\n            alpha,\n            beta,\n            IR_name)\n        return code\n\n    def emit_SeparableConv(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        strides_str = \', \'.join(\'%s\' % i for i in IR_node.get_attr(\'strides\'))\n        input_node, padding = self._defuse_padding(IR_node)\n        code = ""{:<15} = separable_convolution({}, strides = [{}], padding = \'{}\', name = \'{}\')"".format(\n            IR_node.variable_name,\n            input_node,\n            strides_str,\n            padding,\n            IR_node.name)\n        return code\n\n\n    def emit_DepthwiseConv(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        strides_str = \', \'.join(\'%s\' % i for i in IR_node.layer.attr[\'strides\'].list.i)\n        input_node, padding = self._defuse_padding(IR_node)\n        code = ""{:<15} = depthwise_convolution({}, strides = [{}], padding = \'{}\', name = \'{}\')"".format(\n            IR_node.variable_name,\n            input_node,\n            strides_str,\n            padding,\n            IR_node.name)\n        return code\n\n    def emit_Crop(self, IR_node):\n        border = IR_node.get_attr(\'border\')\n        assert len(border) == 4\n\n        output_shape = IR_node.get_attr(\'_output_shapes\')[0]\n        output_shape = shape_to_list(output_shape)\n\n        code = ""{:<15} = tf.image.crop_to_bounding_box({}, offset_height={}, offset_width={}, target_height={}, target_width={})"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            border[0],\n            border[1],\n            output_shape[1],\n            output_shape[2])\n        \n        return code\n\n    def emit_ConvTranspose(self, IR_node):\n        self.used_layers.add(IR_node.type)\n        output_shape = [1] + shape_to_list(IR_node.get_attr(\'_output_shapes\')[0])[1:]\n        input_node, padding = self._defuse_padding(IR_node)\n        code = ""{:<15} = convolution_transpose({}, output_shape={}, strides={}, padding=\'{}\', name=\'{}\')"".format(\n            IR_node.variable_name,\n            input_node,\n            output_shape,\n            IR_node.get_attr(\'strides\'),\n            padding,\n            IR_node.name)\n        return code\n\n    def emit_Slice(self, IR_node):\n        extra_str = """"\n        if IR_node.get_attr(\'begin_mask\'):\n            extra_str += "", begin_mask={}"".format(IR_node.get_attr(\'begin_mask\'))\n        if IR_node.get_attr(\'end_mask\') != None:\n            extra_str += "", end_mask={}"".format(IR_node.get_attr(\'end_mask\'))\n        if IR_node.get_attr(\'shrink_axis_mask\') != None:\n            extra_str += "", shrink_axis_mask={}"".format(IR_node.get_attr(\'shrink_axis_mask\'))\n        if IR_node.get_attr(\'new_axis_mask\')!= None:\n            extra_str += "", new_axis_mask={}"".format(IR_node.get_attr(\'new_axis_mask\'))\n\n        if IR_node.get_attr(\'starts\') != None:\n            starts = IR_node.get_attr(\'starts\')\n        else:\n            starts = self.parent_variable_name(IR_node, [1])\n        \n        if IR_node.get_attr(\'ends\') != None:\n            ends = IR_node.get_attr(\'ends\')\n        else:\n            ends = self.parent_variable_name(IR_node, [2])\n        \n        if IR_node.get_attr(\'strides\') != None:\n            strides = IR_node.get_attr(\'strides\')\n        else:\n            strides = self.parent_variable_name(IR_node, [3])\n\n        code = ""{:<15} = tf.strided_slice({}, {}, {}, {} {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            starts,\n            ends,\n            strides,\n            extra_str,\n            IR_node.name)\n        \n        return code\n\n\n    def emit_Shape(self, IR_node):\n        code = ""{:<15} = tf.shape({}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.name)\n        return code\n\n    def emit_Pack(self, IR_node):\n        code = ""{:<15} = tf.stack({}, axis={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            \'[\' +  \',\'.join(\'%s\' % self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))) + \']\',\n            IR_node.get_attr(\'axis\'),\n            IR_node.name)\n        return code\n\n    def emit_Split(self, IR_node):\n        code = ""{:<15} = tf.split({}, {}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'split\'),\n            IR_node.get_attr(\'axis\'),\n            IR_node.name)\n        return code\n\n    def emit_Unsqueeze(self, IR_node):\n        code = ""{:<15} = tf.expand_dims({}, axis={}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'axes\')[0],\n            IR_node.name)\n        return code\n\n    def emit_Fill(self, IR_node):\n        code = ""{:<15} = tf.fill({}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            IR_node.get_attr(\'value\'),\n            IR_node.name)\n        return code\n\n    def emit_Maximum(self, IR_node):\n        code = ""{:<15} = tf.maximum({}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]),\n            IR_node.name\n        )\n        return code\n\n    def emit_Minimum(self, IR_node):\n        code = ""{:<15} = tf.minimum({}, {}, name=\'{}\')"".format(\n            IR_node.variable_name,\n            self.parent_variable_name(IR_node),\n            self.parent_variable_name(IR_node, [1]),\n            IR_node.name\n        )\n        return code\n\n    def emit_Scope(self, IR_node):\n        input_vars = [self.parent_variable_name(IR_node, [idx]) for idx in range(len(IR_node.in_edges))]\n        input_vars.append(\'__weights_dict\')\n        code = ""{:<15} = _{}({})"".format(\n            IR_node.real_variable_name,\n            IR_node.pattern,\n            \', \'.join(input_vars))\n        self._gen_scope_code(IR_node)\n        return code\n\n\n    def _gen_scope_code(self, scope_node):\n\n        def _scope_func(scope_name, params, code, return_var):\n            code = """"""\ndef _{}({}):\n{}\n    return {}\n    """""".format(scope_name, params, code, \', \'.join(return_var))\n            return code\n\n        if not self.layers_codes.get(scope_node.pattern, None):\n            body_code = str()\n            for node_name in scope_node.topology_list:\n                node = self.IR_graph.get_node(node_name)\n                node_type = node.type\n\n                if hasattr(self, ""emit_"" + node_type):\n                    func = getattr(self, ""emit_"" + node_type)\n                    line = func(node)\n                    if line != None:\n                        body_code += ""    "" + line + \'\\n\'\n                else:\n                    print(""TensorflowEmitter has not supported operator [%s]."" % (node_type))\n                    self.emit_UNKNOWN(node)\n\n            # param_code does not need parameter slice.\n            input_params = scope_node.input_params\n            input_params.append(""__weights_dict"")\n            param_code = \', \'.join(input_params)\n            function_code = _scope_func(scope_node.pattern, param_code, body_code, scope_node.return_variables)\n\n            self.layers_codes[scope_node.pattern] = function_code\n\n\n\n    def _layer_Conv(self):\n        self.add_body(0, """"""\ndef convolution(input, name, group, **kwargs):\n    w = tf.Variable(__weights_dict[name][\'weights\'], trainable=is_train, name=name + ""_weight"")\n    if group == 1:\n        layer = tf.nn.convolution(input, w, name=name, **kwargs)\n    else:\n        weight_groups = tf.split(w, num_or_size_splits=group, axis=-1)\n        xs = tf.split(input, num_or_size_splits=group, axis=-1)\n        convolved = [tf.nn.convolution(x, weight, name=name, **kwargs) for\n                    (x, weight) in zip(xs, weight_groups)]\n        layer = tf.concat(convolved, axis=-1)\n\n    if \'bias\' in __weights_dict[name]:\n        b = tf.Variable(__weights_dict[name][\'bias\'], trainable=is_train, name=name + ""_bias"")\n        layer = layer + b\n    return layer"""""")\n\n\n    def _layer_PRelu(self):\n        self.add_body(0, """"""\ndef prelu(input, name):\n    gamma = tf.Variable(__weights_dict[name][\'gamma\'], name=name + ""_gamma"", trainable=is_train)\n    return tf.maximum(0.0, input) + gamma * tf.minimum(0.0, input)\n    """""")\n\n\n    def _layer_BatchNorm(self):\n        self.add_body(0, """"""\ndef batch_normalization(input, name, **kwargs):\n    mean = tf.Variable(__weights_dict[name][\'mean\'], name = name + ""_mean"", trainable = is_train)\n    variance = tf.Variable(__weights_dict[name][\'var\'], name = name + ""_var"", trainable = is_train)\n    offset = tf.Variable(__weights_dict[name][\'bias\'], name = name + ""_bias"", trainable = is_train) if \'bias\' in __weights_dict[name] else None\n    scale = tf.Variable(__weights_dict[name][\'scale\'], name = name + ""_scale"", trainable = is_train) if \'scale\' in __weights_dict[name] else None\n    return tf.nn.batch_normalization(input, mean, variance, offset, scale, name = name, **kwargs)\n"""""")\n\n\n    def _layer_Scale(self):\n        self.add_body(0, """"""\ndef scale(input, name, **kwargs):\n    mean = tf.Variable(__weights_dict[name][\'scale_mean\'], name = name + ""_mean"", trainable = is_train)\n    variance = tf.Variable(__weights_dict[name][\'scale_var\'], name = name + ""_var"", trainable = is_train)\n    offset = tf.Variable(__weights_dict[name][\'bias\'], name = name + ""_bias"", trainable = is_train) if \'bias\' in __weights_dict[name] else None\n    scale = tf.Variable(__weights_dict[name][\'scale\'], name = name + ""_scale"", trainable = is_train) if \'scale\' in __weights_dict[name] else None\n    return tf.nn.batch_normalization(input, mean, variance, offset, scale, variance_epsilon = 0, name = name)\n"""""")\n\n\n    def _layer_SeparableConv(self):\n        self.add_body(0, """"""\ndef separable_convolution(input, name, **kwargs):\n    depthwise = tf.Variable(__weights_dict[name][\'depthwise_filter\'], trainable = is_train, name = name + ""_df"")\n    pointwise = tf.Variable(__weights_dict[name][\'pointwise_filter\'], trainable = is_train, name = name + ""_pf"")\n    layer = tf.nn.separable_conv2d(input, depthwise, pointwise, **kwargs)\n    if \'bias\' in __weights_dict[name]:\n        b = tf.Variable(__weights_dict[name][\'bias\'], trainable = is_train, name = name + ""_bias"")\n        layer = layer + b\n    return layer"""""")\n\n\n    def _layer_DepthwiseConv(self):\n        self.add_body(0, """"""\ndef depthwise_convolution(input, name, **kwargs):\n    depthwise = tf.Variable(__weights_dict[name][\'weights\'], trainable = is_train, name = name + ""_df"")\n    layer = tf.nn.depthwise_conv2d(input, depthwise, **kwargs)\n    if \'bias\' in __weights_dict[name]:\n        b = tf.Variable(__weights_dict[name][\'bias\'], trainable = is_train, name = name + ""_bias"")\n        layer = layer + b\n    return layer"""""")\n\n\n    def _layer_ConvTranspose(self):\n        self.add_body(0, """"""\ndef convolution_transpose(input, name, **kwargs):\n    w = tf.Variable(__weights_dict[name][\'weights\'], trainable=is_train, name=name + ""_weight"")\n    dim = __weights_dict[name][\'weights\'].ndim - 2\n    if dim == 2:\n        layer = tf.nn.conv2d_transpose(input, w, **kwargs)\n    elif dim == 3:\n        layer = tf.nn.conv3d_transpose(input, w, **kwargs)\n    else:\n        raise ValueError(""Error dim number {} in ConvTranspose"".format(dim))\n\n    if \'bias\' in __weights_dict[name]:\n        b = tf.Variable(__weights_dict[name][\'bias\'], trainable=is_train, name=name + ""_bias"")\n        layer = layer + b\n    return layer"""""")\n'"
mmdnn/conversion/tensorflow/tensorflow_frozenparser.py,0,"b'import numpy as np\nimport tensorflow\nfrom tensorflow.python.framework import tensor_util\nfrom tensorflow.core.framework import attr_value_pb2\nfrom mmdnn.conversion.tensorflow.tensorflow_graph import TensorflowGraph\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom distutils.version import LooseVersion\nimport tempfile\nimport os\nimport shutil\n\n\nclass TensorflowParser2(Parser):\n\n    # skip_prefix = [\n    #     ""^"",\n    #     ""train_op"",\n    #     ""save"",\n    #     ""gradients"",\n    #     ""init"",\n    #     ""global_step"",\n    #     ""distort_image"",\n    #     ""Adagrad"",\n    # ]\n    skip_prefix = [\n    ]\n\n    skip_scope = [\n        ""random_uniform"",\n        ""Initializer"",\n        ""optimizer"",\n        ""weight_loss"",\n        ""parallel_read"",\n        ""case""\n    ]\n\n    skip_type = set([\n        ""L2Loss"",\n        ""VariableV2"",\n        ""Const"",\n        ""Assign"",\n        ""RandomUniform"",\n        ""FIFOQueueV2"",\n        ""Assert"",\n        ""Unpack"",\n        ""NextIteration"",\n        ""TensorArrayV3"",\n        ""Range"",\n        ""TensorArrayScatterV3"",\n        ""TensorArrayReadV3"",\n        ""TensorArrayWriteV3"",\n        # ""Switch""\n        ""Dequantize"",\n        # ""RequantizationRange"",\n        # ""Requantize"",\n        ""ExpandDims"",\n        # ""Identity"",\n        # ""Mean"",\n        # ""Cast""\n        ""Pack"",\n        ""CheckNumerics"",\n        ""Where""\n    ])\n\n\n    q_type = set([\n        ""Dequantize"",\n        ""QuantizeV2"",\n        ""QuantizedConv2D"",\n        ""QuantizedReshape"",\n        ""RequantizationRange""\n    ])\n\n    dtype_map = {\n        0 : graph_pb2.DT_UNDEFINED,\n        1 : graph_pb2.DT_FLOAT32,\n        2 : graph_pb2.DT_FLOAT64,\n        3 : graph_pb2.DT_INT32,\n        4 : graph_pb2.DT_UINT8,\n        5 : graph_pb2.DT_INT16,\n        6 : graph_pb2.DT_INT8,\n        7 : graph_pb2.DT_STRING,\n        9 : graph_pb2.DT_INT64,\n        10: graph_pb2.DT_BOOL\n    }\n\n    tf_dtype_map = {\n        0: tensorflow.float32,  # set default to be float\n        1: tensorflow.float32,\n        2: tensorflow.float64,\n        3: tensorflow.int32,\n        4: tensorflow.uint8,\n        5: tensorflow.int16,\n        6: tensorflow.int8,\n        7: tensorflow.string,\n        9: tensorflow.int64,\n        10: tensorflow.bool\n    }\n\n\n    @property\n    def src_graph(self):\n        return self.tf_graph\n\n    def __init__(self, frozen_file, inputshape, in_nodes, dest_nodes):\n        if LooseVersion(tensorflow.__version__) < LooseVersion(\'1.8.0\'):\n            raise ImportError(\n                \'Your TensorFlow version %s is outdated. \'\n                \'MMdnn requires tensorflow>=1.8.0\' % tensorflow.__version__)\n\n        super(TensorflowParser2, self).__init__()\n\n        self.weight_loaded = True\n        # load model files into TensorFlow graph\n        with open(frozen_file, \'rb\') as f:\n            serialized = f.read()\n        tensorflow.reset_default_graph()\n        original_gdef = tensorflow.GraphDef()\n\n        original_gdef.ParseFromString(serialized)\n\n        in_type_list = {}\n        for n in original_gdef.node:\n            if n.name in in_nodes:\n                in_type_list[n.name] = n.attr[\'dtype\'].type\n\n        from tensorflow.python.tools import strip_unused_lib\n        from tensorflow.python.framework import dtypes\n        from tensorflow.python.platform import gfile\n        original_gdef = strip_unused_lib.strip_unused(\n                input_graph_def = original_gdef,\n                input_node_names = in_nodes,\n                output_node_names = dest_nodes,\n                placeholder_type_enum = dtypes.float32.as_datatype_enum)\n        # Save it to an output file\n        tempdir = tempfile.mkdtemp()\n        frozen_model_file = os.path.join(tempdir, \'frozen.pb\')\n        with gfile.GFile(frozen_model_file, ""wb"") as f:\n            f.write(original_gdef.SerializeToString())\n        with open(frozen_model_file, \'rb\') as f:\n            serialized = f.read()\n        shutil.rmtree(tempdir)\n\n        tensorflow.reset_default_graph()\n        model = tensorflow.GraphDef()\n        model.ParseFromString(serialized)\n\n        output_shape_map = dict()\n        input_shape_map = dict()\n        dtype = tensorflow.float32\n\n        with tensorflow.Graph().as_default() as g:\n            input_map = {}\n            for i in range(len(inputshape)):\n                dtype = TensorflowParser2.tf_dtype_map[in_type_list[in_nodes[i]]]\n                if in_type_list[in_nodes[i]] in (0, 1, 2):\n                    x = tensorflow.placeholder(dtype, shape=[None] + inputshape[i])\n                elif in_type_list[in_nodes[i]] in (3, 4, 5, 6, 7):\n                    x = tensorflow.placeholder(dtype, shape=inputshape[i])\n                elif in_type_list[in_nodes[i]] == 10:\n                    x = tensorflow.placeholder(dtype)\n                else:\n                    raise NotImplementedError\n\n                input_map[in_nodes[i] + \':0\'] = x\n\n            tensorflow.import_graph_def(model, name=\'\', input_map=input_map)\n\n        with tensorflow.Session(graph = g) as sess:\n\n            tempdir = tempfile.mkdtemp()\n            meta_graph_def = tensorflow.train.export_meta_graph(filename=os.path.join(tempdir, \'my-model.meta\'))\n            model = meta_graph_def.graph_def\n            shutil.rmtree((tempdir))\n\n        self.tf_graph = TensorflowGraph(model)\n        self.tf_graph.build()\n\n\n    @staticmethod\n    def _get_scopes(layer_name):\n        return layer_name.split(\'/\')\n\n\n    def check_const(self, node):\n        while node:\n            if node.type == ""Const"":\n                return node\n            elif node.type == ""NoOp"":\n                return None\n            else:\n                node =  self.get_parent(node.name, [0])\n\n\n    def _convert_reduction_operators(self, source_node, new_op = None):\n        IR_node = self._convert_identity_operation(source_node, 1, new_op)\n\n        # keep dims\n        IR_node.attr[\'keepdims\'].b = source_node.layer.attr[\'keep_dims\'].b\n\n        # axes\n        axes = self.get_parent(source_node.name, [1]).layer.attr[\'value\'].tensor\n        axes = tensor_util.MakeNdarray(axes)\n        IR_node.attr[\'axes\'].list.i.extend(axes)\n\n\n    def _convert_layers_batchnorm(self, source_node):\n        IR_node = self.IR_graph.node.add()\n        TensorflowParser2._copy_and_reop(source_node, IR_node, \'BatchNorm\')\n\n        is_transformed = False\n        test = self.get_parent(source_node.name, [0])\n\n        if test.type == \'Mul\':\n            is_transformed = True\n\n        # ssd model is transformed\n        if is_transformed:\n            # Ax - (Au - b)\n\n            # A\n            input_mul_A = self.get_parent(source_node.name, [0, 1])\n            tensor_content = input_mul_A.get_attr(\'value\')\n            A_content = tensor_util.MakeNdarray(tensor_content)\n            self.set_weight(source_node.name, \'A\', A_content)\n\n            # b\n            input_sub = self.get_parent(source_node.name, [1])\n            tensor_content = input_sub.get_attr(\'value\')\n            sub_content = tensor_util.MakeNdarray(tensor_content)\n            # print(sub_content)\n            self.set_weight(source_node.name, \'b\', sub_content)\n\n            input_node = self.get_parent(source_node.name, [0])\n            IR_node.input.append(input_node.real_name)\n            IR_node.attr[""_output_shapes""].list.shape.pop()\n            IR_node.attr[""_output_shapes""].MergeFromString(input_node.layer.attr[\'_output_shapes\'].SerializeToString())\n\n        else:\n            # epsilon\n            epsilon = self.get_parent(source_node.name, [1])\n            IR_node.attr[\'epsilon\'].f = epsilon.layer.attr[\'value\'].tensor.float_val[0]\n\n            # moving variance (var) /read\n            moving_variance = self.get_parent(source_node.name, [0])\n\n            if moving_variance.type == \'Identity\':\n                moving_variance_read = self.src_graph.get_parent(moving_variance.name, [0])\n                tensor_content = moving_variance_read.get_attr(\'value\')\n                moving_variance_content = tensor_util.MakeNdarray(tensor_content)\n                self.set_weight(source_node.name, \'var\', moving_variance_content)\n\n            else:\n                print(moving_variance.layer)\n                assert False\n\n            # gamma (scale)\n            Rsqrt = self.get_son(source_node.name, [0], True)\n            # print(Rsqrt.out_edges)\n\n            if len(Rsqrt.out_edges) == 2:\n                IR_node.attr[\'scale\'].b = False\n                output_node = self.get_son(Rsqrt.name, [0, 0], True)\n                if output_node.type == \'Sub\':\n                    output_node = self.get_son(Rsqrt.name, [1, 0], True)\n                    Mul = self.get_son(Rsqrt.name, [0], True)\n                else:\n                    Mul = self.get_son(Rsqrt.name, [1], True)\n            else:\n                IR_node.attr[\'scale\'].b = True\n                son = self.get_son(Rsqrt.name, [0, 0], True)\n                gamma_from = self.get_parent(son.name, [1, 1], True)\n                gamma = self.check_const(gamma_from)\n                gamma_tensor = gamma.get_attr(\'value\')\n                scale = tensor_util.MakeNdarray(gamma_tensor)\n                self.set_weight(source_node.name, \'scale\', scale)\n                output_node = self.get_son(source_node.name, [0, 0, 0, 0], True)\n                if output_node.type == \'Sub\':\n                    output_node = self.get_son(source_node.name, [0, 0, 0, 0, 0], True)\n                    Mul = self.get_son(Rsqrt.name, [0, 0], True)\n                else:\n                    Mul = self.get_son(Rsqrt.name, [0, 1], True)\n\n            # beta  (bias)\n            beta = self.get_parent(output_node.name, [1, 0, 0], True).get_attr(\'value\')\n            bias = tensor_util.MakeNdarray(beta)\n            IR_node.attr[\'bias\'].b = True\n            self.set_weight(source_node.name, \'bias\', bias)\n\n            # moving mean (mean)\n            moving_mean = self.get_parent(Mul.name, [0, 0]).get_attr(\'value\')\n            mean = tensor_util.MakeNdarray(moving_mean)\n            self.set_weight(source_node.name, \'mean\', mean)\n\n            # input node\n            assert output_node.type == \'Add\'\n            input_node = self.get_parent(output_node.name, [0, 0])\n            IR_node.input.append(input_node.real_name)\n            IR_node.attr[""_output_shapes""].list.shape.pop()\n            IR_node.attr[""_output_shapes""].MergeFromString(input_node.layer.attr[\'_output_shapes\'].SerializeToString())\n            output_node.real_name = source_node.name\n\n\n    def _convert_layers_instancenorm(self, source_node):\n        IR_node = self.IR_graph.node.add()\n        TensorflowParser2._copy_and_reop(source_node, IR_node, \'InstanceNorm\')\n\n        # epsilon\n        epsilon = self.get_parent(source_node.name, [1])\n        epsilon_value = epsilon.get_attr(\'value\').float_val[0]\n        IR_node.attr[\'epsilon\'].f = epsilon_value\n\n        # beta\n        output_node = self.get_son(source_node.name, [0, 0, 0, 0], True)\n        beta = self.get_parent(output_node.name, [1, 0, 0, 0, 0, 1], True)\n        beta_tensor = beta.get_attr(\'value\')\n        beta = tensor_util.MakeNdarray(beta_tensor)\n        self.set_weight(source_node.name, \'bias\', beta)\n\n\n        # gamma (scale)\n        IR_node.attr[\'scale\'].b = True\n        son = self.get_son(source_node.name, [0, 0, 0], True)\n        gamma = self.get_parent(son.name, [1, 1, 0, 0, 0, 1], True)\n        gamma_tensor = gamma.get_attr(\'value\')\n        scale = tensor_util.MakeNdarray(gamma_tensor)\n        self.set_weight(source_node.name, \'scale\', scale)\n        # output_node = self.get_son(source_node.name, [0, 0, 0, 0], True)\n\n        assert output_node.type == \'Add\'\n        input_node = self.get_parent(output_node.name, [0, 0])\n        IR_node.input.append(input_node.real_name)\n\n        output_node.real_name = source_node.name\n\n        # assert False\n\n\n    @classmethod\n    def _skip_node(cls, source_node):\n        if source_node.covered:\n            return True\n\n        for prefix in cls.skip_prefix:\n            if source_node.name.startswith(prefix):\n                return True\n\n        scopes = TensorflowParser2._get_scopes(source_node.name)\n\n        for s in scopes:\n            if s in cls.skip_scope:\n                return True\n\n        return False\n\n\n    def _add_constant_node(self, source_node):\n        parent_ids=range(len(source_node.in_edges))\n        for idx in parent_ids:\n            s = source_node.in_edges[idx]\n            parent_node = self.tf_graph.get_node(s)\n            if parent_node.type == \'Const\':\n                self._rename_Const(parent_node)\n\n    def _rename_Const(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=0, new_op=\'Constant\') # Constant\n        value = source_node.get_attr(\'value\')\n        if value.float_val:\n            value = value.float_val[0]\n        elif value.int_val:\n            value = value.int_val[0]\n        else:\n            value = tensor_util.MakeNdarray(value).tolist()\n        kwargs = {\'value\': value}\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def gen_IR(self):\n\n        for layer in self.src_graph.topological_sort:\n            current_node = self.src_graph.get_node(layer)\n\n            if self._skip_node(current_node):\n                continue\n\n            node_type = current_node.type\n\n            if hasattr(self, ""rename_"" + node_type):\n\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n            else:\n\n                self.rename_UNKNOWN(current_node)\n\n\n    @staticmethod\n    def tensor_shape_to_list(shapes):\n        if isinstance(shapes, attr_value_pb2.AttrValue):\n            return [dim.size for dim in shapes.shape.dim]\n\n        else:\n            ret = []\n            for shape in shapes:\n                this_one = [dim.size for dim in shape.dim]\n                ret.append(this_one)\n            return ret\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op = None):\n        if new_op == None: new_op = source_node.type\n        IR_node.name = source_node.name\n        IR_node.op = new_op\n\n        kwargs = {}\n        if \'data_format\' in source_node.layer.attr:\n            kwargs[\'data_format\'] = source_node.get_attr(\'data_format\')\n\n        if \'T\' in source_node.layer.attr:\n            if source_node.type not in TensorflowParser2.q_type:\n                if source_node.type == \'Enter\':\n                    IR_node.attr[""dtype""].type = TensorflowParser2.dtype_map[6]\n                else:\n                    assert source_node.layer.attr[\'T\'].type in TensorflowParser2.dtype_map, \'type [{}] is unknown.\'.format(source_node.layer.attr[\'dtype\'].type)\n                    IR_node.attr[""dtype""].type = TensorflowParser2.dtype_map[source_node.layer.attr[\'T\'].type]\n            else:\n                # Quantized model type\n                IR_node.attr[""dtype""].type = TensorflowParser2.dtype_map[6]\n\n        if \'_output_shapes\' in source_node.layer.attr:\n            IR_node.attr[""_output_shapes""].MergeFromString(source_node.layer.attr[\'_output_shapes\'].SerializeToString())\n\n        if \'paddings\' in source_node.layer.attr:\n            IR_node.attr[""paddings""].MergeFromString(source_node.layer.attr[\'paddings\'].SerializeToString())\n\n        assign_IRnode_values(IR_node, kwargs)\n\n    def _convert_inedge(self, source_node, IR_node, start_idx = 0, end_idx = None):\n        if end_idx == None: end_idx = len(source_node.in_edges)\n        for idx in range(start_idx, end_idx):\n            IR_node.input.append(self.src_graph.get_node(source_node.in_edges[idx]).real_name)\n\n    @staticmethod\n    def _copy_shape(source_node, IR_node):\n        assert \'shape\' in source_node.layer.attr\n        if source_node.layer.attr[\'shape\'].list.shape:\n            IR_node.attr[\'shape\'].shape.MergeFromString(source_node.layer.attr[\'shape\'].list.shape[0].SerializeToString())\n        else:\n            IR_node.attr[\'shape\'].shape.MergeFromString(source_node.layer.attr[\'shape\'].shape.SerializeToString())\n\n    def rename_UNKNOWN(self, source_node):\n        if source_node.type in self.skip_type:\n            return\n        print(""Tensorflow has not supported operator [%s] with name [%s].""\n              % (source_node.type, source_node.name))\n        assert False\n\n    def rename_NoOp(self, source_node):\n        return\n\n    def _convert_padding(self, source_node, IR_node, kernel_size):\n        # TODO: Fused conv and pool with padding is different from defused operators\n        input_node = self.get_parent(source_node.name, [0])\n        input_shape = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        if source_node.get_attr(\'padding\') == \'VALID\':\n            dims = len(input_shape)\n            assign_IRnode_values(IR_node, {\'auto_pad\' : ""VALID"", \'pads\' : [0, 0] * dims})\n\n        elif source_node.get_attr(\'padding\') == \'SAME\':\n            padding = compute_tf_same_padding(\n                input_shape,\n                kernel_size,\n                source_node.get_attr(\'strides\'))\n            assign_IRnode_values(IR_node, {\'auto_pad\' : ""SAME_LOWER"", \'pads\' : padding})\n\n        else:\n            assert False\n\n\n    def _get_bias(self, source_node, IR_node):\n        if not source_node.out_edges:\n            return\n\n        add_node = self.tf_graph.get_node(source_node.out_edges[0])\n        if add_node.type != ""Add"" and add_node.type != ""BiasAdd"":\n            return\n\n        variable = self.check_const(self.tf_graph.get_node(add_node.in_edges[1])) #add_bias node\n        if not variable or variable.type != \'Const\':\n            return\n\n\n        bias_value = variable.get_attr(\'value\')\n        bias = tensor_util.MakeNdarray(bias_value)\n\n        # assert variable.get_attr(\'_output_shapes\')[0].dim[0].size == IR_node.attr[\'kernel_shape\'].list.i[-1]\n\n\n        add_node.real_name = IR_node.name\n        add_node.covered = True\n        IR_node.attr[\'use_bias\'].b = True\n        current_layer = self.weights[source_node.name]\n        current_layer[\'bias\'] = bias\n\n\n    def _convert_pooling(self, source_node, pool_type):\n\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Pool\')\n        kwargs = {}\n\n        # strides\n        kwargs[\'strides\'] = source_node.get_attr(\'strides\')\n\n        # window_shape\n        kwargs[\'kernel_shape\'] = source_node.get_attr(\'ksize\')\n\n        # pool type\n        kwargs[\'pooling_type\'] = pool_type\n\n        # padding\n        self._convert_padding(source_node, IR_node, kwargs[\'kernel_shape\'][1:-1])\n\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def _convert_identity_operation(self, source_node, start_idx = 0, end_idx = None, new_op = None):\n        IR_node = self.IR_graph.node.add()\n        TensorflowParser2._copy_and_reop(source_node, IR_node, new_op)\n        self._convert_inedge(source_node, IR_node, start_idx, end_idx)\n        return IR_node\n\n\n    def rename_Relu6(self, source_node):\n        self._convert_identity_operation(source_node, new_op = \'Relu6\')\n\n\n    def rename_Merge(self, source_node):\n        # In facenet or other newtwork using slim.batch_norm,\n        # There are two BN(train, test) skip switch and merge.\n        source_node.real_name =  self.src_graph.get_node(source_node.in_edges[0]).real_name\n\n\n    def rename_DepthwiseConv2dNative(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx = 1, new_op = \'DepthwiseConv\')\n        kwargs = {}\n        kwargs[\'strides\'] = source_node.get_attr(\'strides\')\n        input_node = self.src_graph.get_parent(source_node.name, [1])\n        kwargs[\'kernel_shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        self._convert_padding(source_node, IR_node, kwargs[\'kernel_shape\'][:-2])\n\n\n        weight_node = self.src_graph.get_parent(source_node.name, [1])\n        weight = self.check_const(weight_node).get_attr(\'value\')\n        weight_content = tensor_util.MakeNdarray(weight)\n        self.set_weight(source_node.name, \'weights\', weight_content)\n        assign_IRnode_values(IR_node, kwargs)\n        self._get_bias(source_node, IR_node)\n\n\n    def rename_BatchNormWithGlobalNormalization(self, source_node):\n\n        IR_node = self._convert_identity_operation(source_node, start_idx=0, end_idx=1, new_op=\'BatchNorm\')\n        # epsilon\n        IR_node.attr[\'epsilon\'].f = source_node.get_attr(\'variance_epsilon\')\n\n        # moving variance (var) /read\n        moving_variance = self.get_parent(source_node.name, [2])\n        tensor_variance = moving_variance.get_attr(\'value\')\n        moving_variance_content = tensor_util.MakeNdarray(tensor_variance)\n        self.set_weight(source_node.name, \'var\', moving_variance_content)\n\n        # gamma (scale)\n        gamma = self.get_parent(source_node.name, [4])\n        gamma_value = gamma.get_attr(\'value\')\n        gamma = tensor_util.MakeNdarray(gamma_value)\n        self.set_weight(source_node.name, \'scale\', gamma)\n        IR_node.attr[\'scale\'].b = True\n\n        # beta  (bias)\n        beta = self.get_parent(source_node.name, [3])\n        beta_value = beta.get_attr(\'value\')\n        beta = tensor_util.MakeNdarray(beta_value)\n        self.set_weight(source_node.name, \'bias\', beta)\n        IR_node.attr[\'use_bias\'].b = True\n\n        # moving mean (mean)\n        mean = self.get_parent(source_node.name, [1])\n        mean_value = mean.get_attr(\'value\')\n        mean = tensor_util.MakeNdarray(mean_value)\n        self.set_weight(source_node.name, \'mean\', mean)\n\n    def rename_Placeholder(self, source_node):\n        if source_node.layer.attr[""shape""].shape.unknown_rank == True:\n            return\n        IR_node = self._convert_identity_operation(source_node, new_op=\'DataInput\')\n        TensorflowParser2._copy_shape(source_node, IR_node)\n        IR_node.attr[\'shape\'].shape.dim[0].size = -1\n        IR_node.attr[\'_output_shapes\'].list.shape[0].dim[0].size = -1\n\n\n    def rename_Mean(self, source_node):\n        # ReduceMean\n        IR_node = self._convert_identity_operation(source_node, start_idx = 0, end_idx = 1, new_op=\'ReduceMean\')\n        # keep dims\n        IR_node.attr[\'keepdims\'].b = source_node.layer.attr[\'keep_dims\'].b\n\n        # axes\n        axes = self.get_parent(source_node.name, [1]).layer.attr[\'value\'].tensor\n        axes = tensor_util.MakeNdarray(axes)\n        IR_node.attr[\'axes\'].list.i.extend(axes)\n\n\n    def rename_Reshape(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx = 1)\n        kwargs = {\'shape\' : self.tensor_shape_to_list(source_node.get_attr(\'_output_shapes\'))[0]}\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_MirrorPad(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'MirrorPad\')\n        input_node = self.src_graph.get_parent(source_node.name, [1])\n\n        tensor_content = tensor_util.MakeNdarray(input_node.get_attr(\'value\')).reshape(-1)\n        kwargs = {}\n        kwargs[\'mode\'] = source_node.get_attr(\'mode\')\n        kwargs[\'pads\'] = tensor_content.tolist()\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Min(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, start_idx=0, end_idx=1, new_op = \'Min\')\n        kwargs = {}\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs[\'shape_0\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        input_node = self.src_graph.get_parent(source_node.name, [1])\n        kwargs[\'shape_1\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Max(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, start_idx=0, end_idx=1, new_op = \'Max\')\n        kwargs = {}\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs[\'shape_0\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        input_node = self.src_graph.get_parent(source_node.name, [1])\n        kwargs[\'shape_1\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Mul(self, source_node):\n        scopes = self._get_scopes(source_node.name)\n\n        if len(scopes) >= 2:\n            if scopes[-2] == ""batchnorm"" or scopes[-2].startswith(""Assign""):\n                return\n        self._add_constant_node(source_node)\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Add(self, source_node):\n        scopes = self._get_scopes(source_node.name)\n        if len(scopes) > 2:\n            if scopes[-2] == \'batchnorm\':\n                if scopes[-3] == \'BatchNorm\' or scopes[-3] == \'batch_normalization\':\n                    self._convert_layers_batchnorm(source_node)\n                elif scopes[-3] == \'InstanceNorm\':\n                    self._convert_layers_instancenorm(source_node)\n            else:\n                IR_node = self._convert_identity_operation(source_node, new_op = ""Add"")\n        else:\n            IR_node = self._convert_identity_operation(source_node, new_op = ""Add"")\n\n    def rename_AddV2(self, source_node):\n        self.rename_Add(source_node)\n\n    def rename_Fill(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=""Fill"")\n\n\n    def rename_Sub(self, source_node):\n        scopes = self._get_scopes(source_node.name)\n        if len(scopes) > 2:\n            if scopes[-2].startswith(\'Assign\') or scopes[-1].startswith(\'Assign\'):\n                return\n        IR_node = self._convert_identity_operation(source_node, end_idx=2, new_op = ""Sub"")\n\n\n    def rename_Sum(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, start_idx=0, end_idx=1, new_op = \'Sum\')\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs = {}\n        kwargs[\'cal_shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        input_node_indices = self.src_graph.get_parent(source_node.name, [1])\n        indice_value = input_node_indices.get_attr(\'value\')\n        if indice_value.tensor_content:\n            shapes = tensor_util.MakeNdarray(indice_value)\n            c = shapes.tolist()\n            kwargs[\'sum_indices\'] = c\n        else:\n            kwargs[\'sum_indices\'] = input_node_indices.get_attr(\'value\').int_val[0]\n        assign_IRnode_values(IR_node, kwargs)\n\n    def rename_Rsqrt(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = ""Rsqrt"")\n\n        kwargs = {}\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n    def rename_Square(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Square\')\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs = {}\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Sigmoid(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n\n        kwargs = {}\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n    def rename_Reciprocal(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, start_idx=0, end_idx=1, new_op = \'Reciprocal\')\n\n\n    def rename_Minimum(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Minimum\')\n\n    def rename_Maximum(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Maximum\')\n\n    def rename_RealDiv(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'RealDiv\')\n\n    def rename_Enter(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Enter\')\n\n    def rename_Switch(self, source_node):\n        # Skip the node as merge\n        source_node.real_name =  self.src_graph.get_node(source_node.in_edges[0]).real_name\n\n\n    def rename_Identity(self, source_node):\n        source_node.real_name =  self.src_graph.get_node(source_node.in_edges[0]).real_name\n\n\n    def rename_Exp(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Exp\')\n\n    def rename_ResizeBilinear(self, source_node):\n        IR_node = self._convert_identity_operation(source_node,end_idx=1, new_op = \'ResizeBilinear\')\n\n\n    def rename_Cast(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Cast\')\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs = {}\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Prod(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Prod\')\n\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs = {}\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        input_node_const = self.src_graph.get_parent(source_node.name, [1])\n\n        kwargs[\'const\'] = input_node_const.get_attr(\'value\').int_val[0]\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Shape(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Shape\')\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs = {}\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Squeeze(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Squeeze\')\n\n\n    def rename_Gather(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Embedding\')\n\n        W = self.src_graph.get_parent(source_node.name, [0])\n        W = self.src_graph.get_parent(W.name, [0])\n\n        self.set_weight(source_node.name, ""weights"", self.ckpt_data[W.name])\n\n        kwargs = {\n            \'input_dim\' : self.ckpt_data[W.name].shape[0],\n            \'output_dim\' : self.ckpt_data[W.name].shape[1],\n            \'mask_zero\' : False\n        }\n        kwargs[\'axis\'] = 0  # add default\n        assign_IRnode_values(IR_node, kwargs)\n\n        return IR_node\n\n    def rename_GatherV2(self, source_node):\n\n        IR_node = self.rename_Gather(source_node)\n\n        kwargs = {}\n        kwargs[\'axis\'] = source_node.layer.attr[\'axis\'].i\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_StridedSlice(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'Slice\')\n        kwargs = {}\n        kwargs = {\n            \'begin_mask\' : source_node.get_attr(\'begin_mask\'),\n            \'end_mask\'   : source_node.get_attr(\'end_mask\'),\n        }\n\n        starts = self.get_parent(source_node.name, [1]).layer.attr[\'value\'].tensor\n        starts = tensor_util.MakeNdarray(starts).tolist()\n        kwargs[\'starts\'] = starts\n\n        ends = self.get_parent(source_node.name, [2]).layer.attr[\'value\'].tensor\n        ends = tensor_util.MakeNdarray(ends).tolist()\n        kwargs[\'ends\'] = ends\n\n        if self.get_parent(source_node.name, [3]) != None:\n            strides = self.get_parent(source_node.name, [3]).layer.attr[\'value\'].tensor\n            strides = tensor_util.MakeNdarray(strides).tolist()\n            kwargs[\'strides\'] = strides\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_ResizeNearestNeighbor(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        kwargs = {}\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        input_node_size = self.src_graph.get_parent(source_node.name, [1])\n        kwargs[\'size\'] = self.tensor_shape_to_list(input_node_size.get_attr(\'_output_shapes\'))[0]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Conv2D(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'Conv\')\n        kwargs = {}\n        kwargs[\'strides\'] = source_node.get_attr(\'strides\')\n        kwargs[\'padding\'] = source_node.get_attr(\'padding\')\n\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        # weights\n        input_node_weight = self.src_graph.get_parent(source_node.name, [1])\n        tensor_content = self.check_const(input_node_weight).get_attr(\'value\')\n        W = tensor_util.MakeNdarray(tensor_content)\n\n        kwargs[\'kernel_shape\'] = self.tensor_shape_to_list(input_node_weight.get_attr(\'_output_shapes\'))[0]\n\n        self.set_weight(source_node.name, \'weights\', W)\n\n        self._convert_padding(source_node, IR_node, kwargs[\'kernel_shape\'][:-2])\n\n        assign_IRnode_values(IR_node, kwargs)\n        self._get_bias(source_node, IR_node)\n\n\n    def rename_Relu(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        kwargs = {\'shape\' : self.tensor_shape_to_list(source_node.get_attr(\'_output_shapes\'))[0]}\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_MaxPool(self, source_node):\n        self._convert_pooling(source_node, b\'MAX\')\n\n\n    def rename_AvgPool(self, source_node):\n        self._convert_pooling(source_node, b\'AVG\')\n\n\n    def rename_LRN(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        size = source_node.get_attr(\'depth_radius\') * 2 + 1\n        alpha = source_node.get_attr(\'alpha\') * size\n        beta = source_node.get_attr(\'beta\')\n        bias = source_node.get_attr(\'bias\')\n\n        IR_node.attr[""alpha""].f = alpha\n        IR_node.attr[""beta""].f = beta\n        IR_node.attr[""size""].i = size\n        IR_node.attr[""bias""].f = bias\n\n\n    def rename_Concat(self, source_node):\n        n = len(source_node.in_edges)\n        IR_node = self._convert_identity_operation(source_node, start_idx=1, end_idx=n, new_op=\'Concat\')\n        axis = self.tf_graph.get_parent(source_node.name, [0])\n        IR_node.attr[""axis""].i = axis.get_attr(\'value\').int_val[0]\n\n\n    def rename_ConcatV2(self, source_node):\n        n = len(source_node.in_edges)\n        IR_node = self._convert_identity_operation(source_node, start_idx=0, end_idx=n-1, new_op=\'Concat\')\n        axis = self.tf_graph.get_parent(source_node.name, [n-1])\n        IR_node.attr[""axis""].i = axis.get_attr(\'value\').int_val[0]\n\n\n    def rename_MatMul(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1)\n        input_weight_node = self.src_graph.get_parent(source_node.name, [1])\n        weightnode = self.check_const(input_weight_node)\n        weight_value = weightnode.get_attr(\'value\')\n\n        weight = tensor_util.MakeNdarray(weight_value)\n        self.set_weight(source_node.name, \'weights\', weight)\n\n        units = source_node.layer.attr[\'_output_shapes\'].list.shape[-1].dim[-1].size\n        IR_node.attr[\'units\'].i = units\n\n        if source_node.out_edges and self.tf_graph.get_node(source_node.out_edges[0]).type == \'BiasAdd\':\n            add_node = self.tf_graph.get_node(source_node.out_edges[0])\n            add_node.covered = True\n            add_node.real_name = source_node.real_name\n\n            TensorflowParser2._copy_and_reop(source_node, IR_node, \'FullyConnected\')\n            variable = self.tf_graph.get_node(add_node.in_edges[1]) #add_bias node\n            biasnode = self.check_const(variable)\n            bias_value = biasnode.get_attr(\'value\')\n            bias = tensor_util.MakeNdarray(bias_value)\n            self.set_weight(source_node.name, \'bias\', bias)\n            IR_node.attr[\'use_bias\'].b = True\n\n\n    def rename_Softmax(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        kwargs = {\'shape\' : self.tensor_shape_to_list(source_node.get_attr(\'_output_shapes\'))[0]}\n        IR_node.attr[""dim""].i = 1\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_BiasAdd(self, source_node):\n        # Skip BiasAdd\n        source_node.real_name =  self.src_graph.get_node(source_node.in_edges[0]).real_name\n\n\n    def rename_QuantizeV2(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'QuantizeV2\')\n        TensorflowParser2._copy_shape(source_node, IR_node)\n\n\n    def rename_QuantizedRelu(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = ""QuantizedRelu"")\n        kwargs = {\'shape\' : self.tensor_shape_to_list(source_node.get_attr(\'_output_shapes\'))[0]}\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_QuantizedReshape(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx = 1)\n        kwargs = {\'shape\' : self.tensor_shape_to_list(source_node.get_attr(\'_output_shapes\'))[0]}\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_QuantizedConv2D(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'QConv\')\n        kwargs = {}\n        kwargs[\'strides\'] = source_node.get_attr(\'strides\')\n        kwargs[\'padding\'] = source_node.get_attr(\'padding\')\n\n        # weights\n        input_node = self.src_graph.get_parent(source_node.name, [1])\n        tensor_content = input_node.get_attr(\'value\')\n        W = tensor_util.MakeNdarray(tensor_content)\n        W = W.astype(np.uint8)\n\n        kwargs[\'kernel_shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        input_node_minw = self.src_graph.get_parent(source_node.name, [4])\n        min_W = input_node_minw.get_attr(\'value\').float_val[0]\n        input_node_maxw = self.src_graph.get_parent(source_node.name, [5])\n        max_W = input_node_maxw.get_attr(\'value\').float_val[0]\n\n        if source_node.get_attr(\'Tfilter\') == tensorflow.quint8:\n            W = ((max_W - min_W)/255.0) * W + min_W\n        else:\n            assert False, (\'Only uint8 weights handled currently by the converter\')\n\n        self.set_weight(source_node.name, \'kernel_weights\', W)\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Requantize(self, source_node):\n        input_node = self.get_parent(source_node.name, [0])\n        son_node = self.get_son(source_node.name, [0])\n\n        son_node.real_name = source_node.name\n\n    def rename_RequantizationRange(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'RequantizationRange\')\n        TensorflowParser2._copy_shape(source_node, IR_node)\n\n\n    def rename_ZerosLike(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'ZerosLike\')\n\n\n    def rename_Rank(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Rank\')\n\n\n    def rename_Transpose(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'Transpose\')\n\n        input_node_perm = self.get_parent(source_node.name, [1])\n        # input_node_perm = self.check_const(self.get_parent(source_node.name, [1], True))\n        tensor_content = input_node_perm.get_attr(\'value\')\n        perm = tensor_util.MakeNdarray(tensor_content).tolist()\n        assign_IRnode_values(IR_node, {\'perm\' : perm})\n\n    def rename_GreaterEqual(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'GreaterEqual\')\n\n\n    def rename_Greater(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'Greater\')\n\n\n    def rename_Equal(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Equal\')\n\n\n    def rename_All(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'All\')\n\n\n    def rename_LogicalAnd(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Mul\')\n\n\n    def rename_Pad(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'Pad\')\n        kwargs = {}\n        kwargs[\'mode\'] = \'constant\'\n\n        # paddings\n        padding = self.get_parent(source_node.name, [1]).layer.attr[\'value\'].tensor\n        shapes = tensor_util.MakeNdarray(padding)\n        kwargs[\'pads\'] = convert_tf_pad_to_onnx(shapes)\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_FusedBatchNorm(self, source_node):\n        scalenode = self.check_const(self.get_parent(source_node.name, [1], True))\n        if \':\' in source_node.in_edges[1]: # ?\n            scalenode = None\n\n        if scalenode:\n            scale_value = scalenode.get_attr(\'value\')\n            IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'BatchNorm\')\n            # for attr.shape >= 2\n            for i in range(len(IR_node.attr[""_output_shapes""].list.shape)-1):\n                IR_node.attr[""_output_shapes""].list.shape.pop()\n\n        else:\n            # For models built by slim.batch_norm, remove duplicate BN (eg.facenet)\n            return\n\n        scale = tensor_util.MakeNdarray(scale_value)\n        self.set_weight(source_node.name, \'scale\', scale)\n        IR_node.attr[\'scale\'].b = True\n\n\n        IR_node.attr[\'epsilon\'].f = source_node.get_attr(\'epsilon\', 0)\n        biasnode = self.check_const(self.get_parent(source_node.name, [2], True))\n        if biasnode:\n            bias_value = biasnode.get_attr(\'value\')\n        else:\n            innode = self.get_parent(source_node.name, [2], True)\n            name = innode.name.split(\':\')[0]\n            bias_value = self.check_const(self.src_graph.layer_map[name]).get_attr(\'value\')\n        bias = tensor_util.MakeNdarray(bias_value)\n        self.set_weight(source_node.name, \'bias\', bias)\n        IR_node.attr[\'bias\'].b = True\n\n        meannode = self.check_const(self.get_parent(source_node.name, [3], True))\n        mean_value = meannode.get_attr(\'value\')\n        mean = tensor_util.MakeNdarray(mean_value)\n        self.set_weight(source_node.name, \'mean\', mean)\n\n        variancenode = self.check_const(self.get_parent(source_node.name, [4], True))\n        variance_value = variancenode.get_attr(\'value\')\n        variance = tensor_util.MakeNdarray(variance_value)\n        self.set_weight(source_node.name, \'var\', variance)\n\n    def rename_FusedBatchNormV3(self, source_node):\n        self.rename_FusedBatchNorm(source_node)\n\n\n    def rename_SpaceToBatchND(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'SpaceToBatchND\')\n\n\n    def rename_BatchToSpaceND(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'BatchToSpaceND\')\n\n\n    def rename_ArgMax(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, end_idx=1, new_op = \'ArgMax\')\n\n\n    def rename_Slice(self, source_node):\n        input_node_begin = self.get_parent(source_node.name, [1])\n        input_node_size = self.get_parent(source_node.name, [2])\n\n        begin = tensor_util.MakeNdarray(input_node_begin.layer.attr[\'value\'].tensor)\n        size = tensor_util.MakeNdarray(input_node_size.layer.attr[\'value\'].tensor)\n\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Slice\')\n\n        # TODO:  only for 1D\n        end = size + begin\n        kwargs = {\n            \'starts\': begin,\n            \'ends\': end\n        }\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Split(self, source_node):\n        if source_node.get_attr(\'num_split\') == 1:\n            source_node.real_name = self.get_parent(source_node.name, [1]).real_name\n\n        else:\n            IR_node = self._convert_identity_operation(source_node, start_idx=1, new_op = \'Split\')\n            kwargs = {\n                \'axis\' : self.get_parent(source_node.name, [0]).layer.attr[\'value\'].tensor.int_val[0],\n                \'split\' : source_node.get_attr(\'num_split\')\n            }\n            assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Tile(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Tile\')\n\n\n    def rename_Sqrt(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Sqrt\')\n\n\n    def rename_Tanh(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n\n        kwargs = {}\n        input_node = self.src_graph.get_parent(source_node.name, [0])\n        kwargs[\'shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        assign_IRnode_values(IR_node, kwargs)\n\n    def rename_Log(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op = \'Log\')'"
mmdnn/conversion/tensorflow/tensorflow_graph.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\nfrom tensorflow.core.framework.node_def_pb2 import NodeDef\nfrom tensorflow.core.framework import attr_value_pb2\n\n\nclass TensorflowGraphNode(GraphNode):\n\n    def __init__(self, layer):\n        super(TensorflowGraphNode, self).__init__(layer)\n        self.in_nodes = list()\n        self.out_nodes = list()\n        self._scope = str()\n\n\n    @property\n    def scope(self):\n        return self._scope\n\n    @scope.setter\n    def scope(self, scope):\n        self._scope = scope\n\n\n    @property\n    def name(self):\n        return self.layer.name\n\n\n    @property\n    def type(self):\n        return self.layer.op\n\n\n    @property\n    def tf_layer(self):\n        return self.layer\n\n\n    def get_attr(self, name, default_value = None):\n        if name in self.layer.attr:\n            attr = self.layer.attr[name]\n            field = attr.WhichOneof(\'value\')\n            val = getattr(attr, field) if field else default_value\n            if isinstance(val, attr_value_pb2.AttrValue.ListValue):\n                return list(val.ListFields()[0][1])\n            else:\n                return val.decode(\'utf-8\') if isinstance(val, bytes) else val\n        else:\n            return default_value\n\n\nclass TensorflowGraph(Graph):\n\n    multi_tensor_type = [\n        ""Slice"",\n        ""Split"",\n        ""Unpack""\n    ]\n\n\n    def __init__(self, model):\n        # sanity check.\n        pass\n\n        super(TensorflowGraph, self).__init__(model)\n        self.model = model\n\n\n    def build(self):\n        for i, layer in enumerate(self.model.node):\n            self.layer_map[layer.name] = TensorflowGraphNode(layer)\n            self.layer_name_map[layer.name] = layer.name\n            for pred in layer.input:\n                if pred not in self.layer_map:\n                    if not pred.split(\':\')[0] in self.layer_map: #test\n                        new_node = NodeDef()\n                        new_node.name = pred\n                        new_node.op = ""NoOp""\n                        self.layer_map[pred] = TensorflowGraphNode(new_node)\n                        self.layer_name_map[pred] = pred\n\n                self.tf_make_connection(pred, layer.name)\n\n        super(TensorflowGraph, self).build()\n\n\n    def tf_make_connection(self, src, dst):\n\n        if \':\' not in src and self.get_node(src).type in self.multi_tensor_type:\n            src += \':0\'\n\n        self._make_connection(src, dst)\n        src_node = self.get_node(src.split(\':\')[0])\n        dst_node = self.get_node(dst.split(\':\')[0])\n\n        if not src_node in self.layer_map[dst.split(\':\')[0]].in_nodes:\n            self.layer_map[dst.split(\':\')[0]].in_nodes.append(src_node)\n        if not dst_node in self.layer_map[src.split(\':\')[0]].out_nodes:\n            self.layer_map[src.split(\':\')[0]].out_nodes.append(dst_node)\n'"
mmdnn/conversion/tensorflow/tensorflow_parser.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport numpy as np\nimport tensorflow\nfrom tensorflow.python.framework import tensor_util\nfrom tensorflow.core.framework import attr_value_pb2\nfrom mmdnn.conversion.tensorflow.tensorflow_graph import TensorflowGraph\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom tensorflow.tools.graph_transforms import TransformGraph\nfrom mmdnn.conversion.rewriter.utils import *\nimport tempfile\nimport os\nimport shutil\n\n\nclass TensorflowParser(Parser):\n\n    skip_prefix = [\n        ""^"",\n        ""train_op"",\n        ""save"",\n        ""gradients"",\n        ""global_step"",\n        ""distort_image"",\n        ""Adagrad"",\n    ]\n\n    skip_scope = [\n        ""random_uniform"",\n        ""Initializer"",\n        ""optimizer"",\n        ""weight_loss"",\n        ""parallel_read"",\n        ""case""\n    ]\n\n    skip_type = set([\n        ""L2Loss"",\n        ""VariableV2"",\n        ""Const"",\n        ""Assign"",\n        ""RandomUniform"",\n        ""FIFOQueueV2""\n    ])\n\n    dtype_map = {\n        0  : graph_pb2.DT_UNDEFINED,\n        1  : graph_pb2.DT_FLOAT32,\n        2  : graph_pb2.DT_FLOAT64,\n        3  : graph_pb2.DT_INT32,\n        4  : graph_pb2.DT_UINT8,\n        5  : graph_pb2.DT_INT16,\n        6  : graph_pb2.DT_INT8,\n        7  : graph_pb2.DT_STRING,\n        9  : graph_pb2.DT_INT64,\n        10 : graph_pb2.DT_BOOL,\n        19 : graph_pb2.DT_FLOAT16\n    }\n\n\n    @property\n    def src_graph(self):\n        return self.tf_graph\n\n\n    @staticmethod\n    def _shapeToStr(shapes):\n        return [dim.size if dim.size > 0 else 1 for dim in shapes.dim]\n\n\n    @staticmethod\n    def _load_meta(model_network_path):\n        """"""Load a tensorflow meta file from disk\n\n        Parameters\n        ----------\n        model_network_path: str\n            Path where the model network path is (protobuf meta file)\n\n        Returns\n        -------\n        model: A tensorflow protobuf file\n        """"""\n        from tensorflow.core.protobuf import meta_graph_pb2\n        from mmdnn.conversion.common.IR.IR_graph import load_protobuf_from_file\n\n        meta_graph = meta_graph_pb2.MetaGraphDef()\n        load_protobuf_from_file(meta_graph, model_network_path)\n        graph = meta_graph.graph_def\n\n        print (""Tensorflow model file [%s] loaded successfully."" % model_network_path)\n        return graph\n\n\n    @staticmethod\n    def _load_weights(model_weight_path):\n        """"""Load a tensorflow checkpoint file from disk\n\n        Parameters\n        ----------\n        model_weight_path: str\n            Path where the weight path is (checkpoint file)\n\n        Returns\n        -------\n        model: tensor name --> ndarry\n        """"""\n        reader = tensorflow.train.NewCheckpointReader(model_weight_path)\n        var_to_shape_map = reader.get_variable_to_shape_map()\n        data = dict()\n        for name in var_to_shape_map:\n            tensor = reader.get_tensor(name)\n            name_seg = name.split(""/"")\n            if name_seg[-1] == ""ExponentialMovingAverage"":\n                name = ""/"".join(name_seg[:-1])\n            data[name] = tensor\n\n        print (""Tensorflow checkpoint file [%s] loaded successfully. [%d] variables loaded."" % (model_weight_path, len(data)))\n        return data\n\n\n    @staticmethod\n    def _get_scopes(layer_name):\n        return layer_name.split(\'/\')\n\n\n    def check_const(self, node):\n        while node:\n            if node.type == ""Const"":\n                return node\n            elif node.type == ""NoOp"":\n                return None\n            else:\n                node =  self.get_parent(node.name, [0])\n\n    def _add_constant_node(self, source_node):\n        parent_ids=range(len(source_node.in_edges))\n        for idx in parent_ids:\n            parent_node = self.tf_graph.get_node(source_node.in_edges[idx])\n            if parent_node.type == \'Const\':\n                self._rename_Const(parent_node)\n    \n    def _rename_Const(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count=0, new_op=\'Constant\') # Constant\n        value = source_node.get_attr(\'value\')\n        if value.float_val:\n            shape = tuple(self.tensor_shape_to_list(value.tensor_shape))\n            value = np.full(shape, value.float_val[0])\n        elif value.int_val:\n            shape = tuple(self.tensor_shape_to_list(value.tensor_shape))\n            value = np.full(shape, value.int_val[0])\n        else:\n            value = np.array(tensor_util.MakeNdarray(value).tolist())\n        \n        if value.ndim > 1:\n            self.set_weight(source_node.name, \'value\', value)\n        else:\n            kwargs = {\'value\': value}\n            assign_IRnode_values(IR_node, kwargs)\n\n\n    def _convert_reduction_operators(self, source_node, new_op = None):\n        IR_node = self._convert_identity_operation(source_node, 0, 1, new_op)\n\n        # keep dims\n        IR_node.attr[\'keepdims\'].b = source_node.layer.attr[\'keep_dims\'].b\n\n        # axes\n        axes = self.get_parent(source_node.name, [1]).layer.attr[\'value\'].tensor\n        axes = tensor_util.MakeNdarray(axes)\n        IR_node.attr[\'axes\'].list.i.extend(axes)\n\n\n    def _convert_layers_batchnorm(self, source_node):\n        # name, op\n        IR_node = self.IR_graph.node.add()\n        TensorflowParser._copy_and_reop(source_node, IR_node, \'BatchNorm\')\n\n        # epsilon\n        epsilon = self.get_parent(source_node.name, [1])\n        IR_node.attr[\'epsilon\'].f = epsilon.layer.attr[\'value\'].tensor.float_val[0]\n\n        # moving variance (var)\n        moving_variance = self.get_parent(source_node.name, [0, 0])\n        # print(moving_variance.name)\n        if self.weight_loaded and moving_variance.name in self.ckpt_data.keys():\n            self.set_weight(source_node.name, \'var\', self.ckpt_data[moving_variance.name])\n\n        # gamma (scale)\n        gamma = self.get_son(source_node.name, [0, 0], True)\n        gamma = self.get_parent(gamma.name, [1, 0], True)\n        if gamma is None or not gamma.type.startswith(\'Variable\'):\n            IR_node.attr[\'scale\'].b = False\n            output_node = self.get_son(source_node.name, [0, 0, 0], True)\n        else:\n            IR_node.attr[\'scale\'].b = True\n            if self.weight_loaded:\n                self.set_weight(source_node.name, \'scale\', self.ckpt_data[gamma.name])\n            output_node = self.get_son(source_node.name, [0, 0, 0, 0], True)\n            if output_node.type == \'Sub\':\n                output_node = self.get_son(source_node.name, [0, 0, 1, 0], True)\n\n        # mean\n        mean = self.get_parent(output_node.name, [1, 1, 0, 0], True)\n        if self.weight_loaded and mean.name in self.ckpt_data.keys():\n            self.set_weight(source_node.name, \'mean\', self.ckpt_data[mean.name])\n\n        # bias\n        bias = self.get_parent(output_node.name, [1, 0, 0], True)\n        if bias is None or not bias.type.startswith(\'Variable\'):\n            IR_node.attr[\'bias\'].b = False\n        else:\n            IR_node.attr[\'bias\'].b = True\n            if self.weight_loaded:\n                self.set_weight(source_node.name, \'bias\', self.ckpt_data[bias.name])\n\n        # input node\n        assert output_node.type == \'Add\'\n        input_node = self.get_parent(output_node.name, [0, 0])\n        IR_node.input.append(input_node.real_name)\n\n        # output node\n        output_node.real_name = source_node.name\n\n\n    def __init__(self, meta_file, checkpoint_file, dest_nodes, inputShape = None, in_nodes = None):\n        super(TensorflowParser, self).__init__()\n\n        # load model files into TensorFlow graph\n        if meta_file:\n            model = TensorflowParser._load_meta(meta_file)\n\n        if checkpoint_file:\n            self.ckpt_data = TensorflowParser._load_weights(checkpoint_file)\n            self.weight_loaded = True\n\n        # extract subgraph using in_nodes and dest_nodes\n        if in_nodes != None and inputShape != None:\n            from tensorflow.python.tools import strip_unused_lib\n            from tensorflow.python.framework import dtypes\n            from tensorflow.python.platform import gfile\n            model = strip_unused_lib.strip_unused(\n                    input_graph_def = model,\n                    input_node_names = in_nodes,\n                    output_node_names = dest_nodes,\n                    placeholder_type_enum = dtypes.float32.as_datatype_enum)\n\n            input_list = [None]\n            for i in range(len(inputShape)):\n                input_list.append(tensorflow.Dimension(inputShape[i]))\n            tensor_input = tensorflow.TensorShape(input_list)\n            # Build network graph\n            self.tf_graph = TensorflowGraph(model)\n            for node in self.tf_graph.model.node:\n                if node.name in in_nodes:\n                    node.attr[\'shape\'].shape.CopyFrom(tensor_input.as_proto())\n                    node.attr[\'_output_shapes\'].list.shape.pop()  #unknown_rank pop\n                    node.attr[\'_output_shapes\'].list.shape.extend([tensor_input.as_proto()])\n\n        # extract subgraph using dest_nodes\n        elif dest_nodes != None:\n            from tensorflow.python.framework.graph_util import extract_sub_graph\n            model = extract_sub_graph(model, dest_nodes)\n\n        #  Get input node name\n        if not in_nodes:\n            in_nodes = []\n            for node in model.node:\n                if node.op == \'Placeholder\':\n                    in_nodes.append(node.name)\n\n        # Graph Transform\n        transforms = [""fold_constants(ignore_errors=true)""]\n        transformed_graph_def = TransformGraph(model, in_nodes,\n                                                dest_nodes, transforms)\n        in_type_list = {}\n        in_shape_list = {}\n\n        for n in transformed_graph_def.node:\n            if n.name in in_nodes:\n                in_type_list[n.name] = n.attr[\'dtype\'].type\n                in_node_shape = n.attr[\'shape\'].shape\n                in_node_shape_str = self._shapeToStr(in_node_shape)\n                in_shape_list[n.name] = in_node_shape_str\n\n        dtype = tensorflow.float32\n        with tensorflow.Graph().as_default() as g:\n            input_map = {}\n            for in_node in in_nodes:\n                if in_type_list[in_node] == 1 or in_type_list[in_node] == 0:\n                    dtype = tensorflow.float32\n\n                elif in_type_list[in_node] == 3:\n                    dtype = tensorflow.int32\n\n                elif in_type_list[in_node] == 10:\n                    dtype = tensorflow.bool\n                \n                x = tensorflow.placeholder(dtype, shape = in_shape_list[in_node])\n                input_map[in_node] = x\n\n            tensorflow.import_graph_def(transformed_graph_def, name=\'\', input_map=input_map)\n\n        with tensorflow.Session(graph = g) as sess:\n            tempdir = tempfile.mkdtemp()\n            meta_graph_def = tensorflow.train.export_meta_graph(filename=os.path.join(tempdir, \'my-model.meta\'))\n            model = meta_graph_def.graph_def\n            shutil.rmtree(tempdir)\n\n        self.tf_graph = TensorflowGraph(model)\n        self.tf_graph.build()\n\n        process_graph(self.tf_graph, self.ckpt_data)\n\n    @classmethod\n    def _skip_node(cls, source_node):\n        if source_node.covered:\n            return True\n\n        for prefix in cls.skip_prefix:\n            if source_node.name.startswith(prefix):\n                return True\n\n        scopes = TensorflowParser._get_scopes(source_node.name)\n\n        for s in scopes:\n            if s in cls.skip_scope:\n                return True\n\n        return False\n\n    @staticmethod\n    def tensor_shape_to_list(shapes):\n        if isinstance(shapes, attr_value_pb2.AttrValue):\n            return [dim.size for dim in shapes.shape.dim]\n        elif isinstance(shapes, attr_value_pb2.tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2.TensorShapeProto):\n            return [dim.size for dim in shapes.dim]\n        else:\n            ret = []\n            for shape in shapes:\n                this_one = [dim.size for dim in shape.dim]\n                ret.append(this_one)\n            return ret\n\n    \'\'\'\n    check current source_node wether has input weights. If it has, set the weights into weight dict and remove the input edge.\n    return edges\' index which do not include edge connecting weights \n    \'\'\'\n    def _check_weights(self, source_node, start_edge_id = 0, in_edge_count = None):\n        if in_edge_count == None: in_edge_count = len(source_node.in_edges) - start_edge_id\n        valid_pre_ids = []\n\n        for pre_idx in range(start_edge_id, start_edge_id + in_edge_count):\n            pre_node = self.get_parent(source_node.name, [pre_idx])\n            if pre_node.type == \'Identity\' and pre_node.name.split(\'/\')[-1] == \'read\':\n                weight_node = self.get_parent(pre_node.name, [0])\n                assert \'Variable\' in weight_node.type\n                self.set_weight(source_node.name, \'weights\', self.ckpt_data[weight_node.name])\n                source_node.feed_weights = True\n            else:\n                valid_pre_ids.append(pre_idx)\n\n        return valid_pre_ids\n\n    def _convert_padding(self, source_node, IR_node, kernel_size):\n        # TODO: Fused conv and pool with padding is different from defused operators\n        input_node = self.get_parent(source_node.name, [0])\n        input_shape = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        if source_node.get_attr(\'padding\') == \'VALID\':\n            dims = len(input_shape)\n            assign_IRnode_values(IR_node, {\'auto_pad\' : ""VALID"", \'pads\' : [0, 0] * dims})\n\n        elif source_node.get_attr(\'padding\') == \'SAME\':\n            padding = compute_tf_same_padding(\n                input_shape,\n                kernel_size,\n                source_node.get_attr(\'strides\'))\n            assign_IRnode_values(IR_node, {\'auto_pad\' : ""SAME_UPPER"", \'pads\' : padding})\n\n        else:\n            assert False\n\n\n    def _convert_pooling(self, source_node, pool_type):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Pool\')\n        kwargs = {}\n\n        # strides\n        kwargs[\'strides\'] = source_node.get_attr(\'strides\')\n\n        # window_shape\n        kwargs[\'kernel_shape\'] = source_node.get_attr(\'ksize\')\n\n        # pool type\n        kwargs[\'pooling_type\'] = pool_type\n\n        # padding\n        self._convert_padding(source_node, IR_node, kwargs[\'kernel_shape\'][1:-1])\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def gen_IR(self):\n        for layer in self.src_graph.topological_sort:\n            current_node = self.src_graph.get_node(layer)\n\n            if self._skip_node(current_node):\n                continue\n\n            node_type = current_node.type\n\n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n            else:\n                self.rename_UNKNOWN(current_node)\n\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op = None):\n        if new_op == None: new_op = source_node.type\n        IR_node.name = source_node.name\n        IR_node.op = new_op\n\n        kwargs = {}\n        if \'data_format\' in source_node.layer.attr:\n            kwargs[""data_format""] = source_node.get_attr(\'data_format\')\n\n        if \'dtype\' in source_node.layer.attr:\n            assert source_node.layer.attr[\'dtype\'].type in TensorflowParser.dtype_map, \'type [{}] is unknown.\'.format(source_node.layer.attr[\'dtype\'].type)\n            IR_node.attr[""dtype""].type = TensorflowParser.dtype_map[source_node.layer.attr[\'dtype\'].type]\n\n        if \'_output_shapes\' in source_node.layer.attr:\n            IR_node.attr[""_output_shapes""].MergeFromString(source_node.layer.attr[\'_output_shapes\'].SerializeToString())\n\n        if hasattr(source_node, \'feed_weights\'):\n            kwargs[""feed_weights""] = True\n\n        if hasattr(source_node, \'kwargs\'):\n            kwargs.update(source_node.kwargs)\n\n        kwargs[\'scope\'] = source_node.scope\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def _convert_inedge(self, source_node, IR_node, start_idx = 0, end_idx = None, in_ids=None):\n        if end_idx == None: end_idx = len(source_node.in_edges) - start_idx\n        if not in_ids:\n            in_ids = range(start_idx, end_idx + start_idx)\n\n        for idx in in_ids:\n            if \':\' in source_node.in_edges[idx]:\n                input_tensor = self.src_graph.get_node(source_node.in_edges[idx]).real_name + \':\' + source_node.in_edges[idx].split(\':\')[1]\n            else:\n                input_tensor = self.src_graph.get_node(source_node.in_edges[idx]).real_name\n\n            IR_node.input.append(input_tensor)\n\n\n\n\n    def _get_bias(self, source_node, IR_node):\n        if not source_node.out_edges:\n            return\n\n        add_node = self.tf_graph.get_node(source_node.out_edges[0])\n        if add_node.type != ""Add"" and add_node.type != ""BiasAdd"":\n            return\n\n        variable = self.tf_graph.get_node(add_node.in_edges[1])\n        if variable.type != ""Identity"":\n            return\n        variable = self.tf_graph.get_node(variable.in_edges[0])\n\n        assert variable.layer.attr[\'shape\'].shape.dim[0].size == IR_node.attr[\'kernel_shape\'].list.i[-1]\n\n        if self.weight_loaded:\n            assert variable.name in self.ckpt_data\n            current_layer = self.weights[source_node.name]\n            current_layer[\'bias\'] = self.ckpt_data[variable.name]\n\n        add_node.real_name = IR_node.name\n        add_node.covered = True\n        IR_node.attr[\'use_bias\'].b = True\n\n\n    @staticmethod\n    def _copy_shape(source_node, IR_node):\n        assert \'shape\' in source_node.layer.attr\n        if source_node.layer.attr[\'shape\'].list.shape:\n            IR_node.attr[\'shape\'].shape.MergeFromString(source_node.layer.attr[\'shape\'].list.shape[0].SerializeToString())\n        else:\n            IR_node.attr[\'shape\'].shape.MergeFromString(source_node.layer.attr[\'shape\'].shape.SerializeToString())\n\n\n    def rename_UNKNOWN(self, source_node):\n        if source_node.type in self.skip_type:\n            return\n        print(""TensorflowEmitter has not supported operator [%s] with name [%s].""\n              % (source_node.type, source_node.name))\n        return\n\n\n    def rename_Placeholder(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'DataInput\')\n        # shape\n        TensorflowParser._copy_shape(source_node, IR_node)\n        if len(IR_node.attr[\'shape\'].shape.dim)>0 and len(IR_node.attr[\'_output_shapes\'].list.shape)>0 and len(IR_node.attr[\'_output_shapes\'].list.shape[0].dim)>0:\n            IR_node.attr[\'shape\'].shape.dim[0].size = -1\n            IR_node.attr[\'_output_shapes\'].list.shape[0].dim[0].size = -1\n\n\n    def rename_Conv2D(self, source_node):\n        """"""\n        weights: name_weights, name_bias\n        """"""\n        IR_node = self._convert_identity_operation(source_node, 0, 1, \'Conv\')\n\n        kwargs = {}\n\n        # strides\n        kwargs[\'strides\'] = source_node.get_attr(\'strides\')\n\n        # input[1] : W\n        # filter\n        W = self.tf_graph.get_node(source_node.layer.input[1])\n        if W.type == \'Const\':\n            kwargs[\'kernel_shape\'] = tensor_shape = self.tensor_shape_to_list(W.layer.attr[\'value\'].tensor.tensor_shape)\n        else:\n            W = self.tf_graph.get_node(W.layer.input[0]).layer\n            kwargs[\'kernel_shape\'] = self.tensor_shape_to_list(W.attr[\'shape\'])\n\n        # padding\n        self._convert_padding(source_node, IR_node, kwargs[\'kernel_shape\'][:-2])\n\n        if self.weight_loaded:\n             self.set_weight(source_node.name, \'weights\', self.ckpt_data[W.name])\n\n        assign_IRnode_values(IR_node, kwargs)\n        # output[0] : B\n        self._get_bias(source_node, IR_node)\n\n\n    def _convert_identity_operation(self, source_node, start_edge_id = 0, in_edge_count = None, new_op = None):\n        IR_node = self.IR_graph.node.add()\n        in_ids = self._check_weights(source_node, start_edge_id, in_edge_count)\n        TensorflowParser._copy_and_reop(source_node, IR_node, new_op)\n        self._convert_inedge(source_node, IR_node, start_edge_id, in_edge_count, in_ids)\n        return IR_node\n\n\n    def rename_Relu(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Softmax(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Relu6(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Add(self, source_node):\n        if not source_node.covered:\n            scopes = self._get_scopes(source_node.name)\n            if len(scopes) < 3:\n                self._convert_identity_operation(source_node,new_op=\'Add\')\n\n            elif scopes[-2] == \'dropout\':\n                # converted [dropout]\n                pass\n\n            elif scopes[-2] == \'batchnorm\':\n                # convert [tf.contrib.layers.batch_norm]\n                self._convert_layers_batchnorm(source_node)\n\n            else:\n                # normal Add\n                self._add_constant_node(source_node)\n                self._convert_identity_operation(source_node,new_op=\'Add\')\n\n    def rename_AddV2(self, source_node):\n        self.rename_Add(source_node)\n\n    def rename_Sub(self, source_node):\n        self._add_constant_node(source_node)\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Reshape(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count = 1)\n        kwargs = {\'shape\' : self.tensor_shape_to_list(source_node.get_attr(\'_output_shapes\'))[0]}\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Abs(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count = 1, new_op = \'Abs\')\n\n\n    def rename_Square(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count = 1, new_op = \'Square\')\n\n\n    def rename_MatMul(self, source_node):\n\n        W = self.tf_graph.get_node(self.tf_graph.get_node(source_node.in_edges[1]).in_edges[0])\n\n        if \'Variable\' in W.type:\n\n            """"""\n            weights: name_weights, name_bias\n            """"""\n            IR_node = self._convert_identity_operation(source_node, in_edge_count = 1)\n\n            # units\n            units = source_node.layer.attr[\'_output_shapes\'].list.shape[-1].dim[-1].size\n            IR_node.attr[\'units\'].i = units\n\n            # Weights\n            W = self.tf_graph.get_node(self.tf_graph.get_node(source_node.in_edges[1]).in_edges[0])\n            if self.weight_loaded:\n                self.set_weight(source_node.name, \'weights\', self.ckpt_data[W.name])\n\n            if source_node.out_edges and (self.tf_graph.get_node(source_node.out_edges[0]).type == \'Add\' or self.tf_graph.get_node(source_node.out_edges[0]).type == \'BiasAdd\'):\n                add_node = self.tf_graph.get_node(source_node.out_edges[0])\n                add_node.covered = True\n                add_node.real_name = source_node.real_name\n                # FullyConnected Layer\n                # name, op\n                TensorflowParser._copy_and_reop(source_node, IR_node, \'FullyConnected\')\n\n                # get Bias\n                B = self.tf_graph.get_node(self.tf_graph.get_node(source_node.out_edges[0]).in_edges[1]).in_edges[0]\n                if self.weight_loaded:\n                    self.set_weight(source_node.name, \'bias\', self.ckpt_data[B])\n                IR_node.attr[\'use_bias\'].b = True\n\n            else:\n                # Matmul Layer\n                TensorflowParser._copy_and_reop(source_node, IR_node, \'FullyConnected\')\n                assign_IRnode_values(IR_node, {\'use_bias\' : False})\n        else:\n            self._convert_identity_operation(source_node, new_op=\'MatMul\')\n\n\n    def rename_RealDiv(self, source_node):\n        scopes = self._get_scopes(source_node.name)\n\n        # Deal Dropout\n        if len(scopes) > 1 and scopes[-2][:7] == \'dropout\':\n            IR_node = self._convert_identity_operation(source_node, in_edge_count = 1, new_op = \'Dropout\')\n\n            # keep prob\n            if \'value\' in self.tf_graph.get_node(source_node.layer.input[1]).layer.attr:\n                IR_node.attr[\'keep_prob\'].f = self.tf_graph.get_node(source_node.layer.input[1]).layer.attr[\'value\'].tensor.float_val[0]\n            else:\n                IR_node.attr[\'keep_prob\'].f = 1.0\n\n            # Remove nodes\n            # Mul\n            mul_node = self.tf_graph.get_node(source_node.out_edges[0])\n            assert mul_node.type == ""Mul""\n            mul_node.covered = True\n            mul_node.real_name = source_node.name\n\n            # Floor\n            floor_node = self.tf_graph.get_node(mul_node.in_edges[1])\n            assert floor_node.type == ""Floor""\n            floor_node.covered = True\n\n        else:\n            # print (source_node)\n            # print (source_node.layer)\n            # assert False\n            self._convert_identity_operation(source_node, new_op=\'Div\')\n\n\n    def rename_Floor(self, source_node):\n        scopes = self._get_scopes(source_node.name)\n        assert scopes[-2] == \'dropout\'\n\n\n    def rename_MaxPool(self, source_node):\n        self._convert_pooling(source_node, b\'MAX\')\n\n\n    def rename_AvgPool(self, source_node):\n        self._convert_pooling(source_node, b\'AVG\')\n\n\n    def rename_Identity(self, source_node):\n        source_node.real_name =  self.src_graph.get_node(source_node.in_edges[0]).real_name\n\n\n    def rename_Squeeze(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        IR_node.attr[\'axes\'].MergeFromString(source_node.layer.attr[\'squeeze_dims\'].SerializeToString())\n\n    def rename_QueueDequeueUpToV2(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count = 0, new_op = \'DataInput\')\n        IR_node.attr[\'shape\'].shape.MergeFromString(source_node.layer.attr[\'_output_shapes\'].list.shape[0].SerializeToString())\n        IR_node.attr[\'shape\'].shape.dim[0].size = -1\n        IR_node.attr[\'dtype\'].type = self.dtype_map[source_node.layer.attr[\'component_types\'].list.type[0]]\n\n\n\n    def rename_QueueDequeueManyV2(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count = 0, new_op = \'DataInput\')\n        IR_node.attr[\'shape\'].shape.MergeFromString(source_node.layer.attr[\'_output_shapes\'].list.shape[0].SerializeToString())\n        IR_node.attr[\'shape\'].shape.dim[0].size = -1\n        IR_node.attr[\'dtype\'].type = self.dtype_map[source_node.layer.attr[\'component_types\'].list.type[0]]\n\n    # def rename_RandomShuffleQueueV2(self, source_node):\n    #     # print(source_node.layer)\n    #     IR_node = self._convert_identity_operation(source_node, in_edge_count = 0, new_op = \'DataInput\')\n    #     # IR_node.attr[\'shape\'].shape.MergeFromString(source_node.layer.attr[\'_output_shapes\'].list.shape[0].SerializeToString())\n    #     # IR_node.attr[\'shape\'].shape.dim[0].size = -1\n    #     IR_node.attr[\'dtype\'].type = self.dtype_map[source_node.layer.attr[\'component_types\'].list.type[0]]\n\n\n    def rename_Pad(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count = 1, new_op = \'Pad\')\n        kwargs = {}\n        kwargs[\'mode\'] = \'constant\'\n        kwargs[\'constant_values\'] = 0.0\n\n        # paddings\n        padding = self.get_parent(source_node.name, [1]).layer.attr[\'value\'].tensor\n        shapes = tensor_util.MakeNdarray(padding)\n        kwargs[\'pads\'] = convert_tf_pad_to_onnx(shapes)\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Mean(self, source_node):\n        self._convert_reduction_operators(source_node, new_op = \'ReduceMean\')\n\n\n    def rename_ConcatV2(self, source_node):\n        n = len(source_node.in_edges) - 1\n        self._add_constant_node(source_node)\n        IR_node = self._convert_identity_operation(source_node, in_edge_count = n, new_op = \'Concat\')\n        axis = self.tf_graph.get_parent(source_node.name, [n])\n        IR_node.attr[\'axis\'].i = axis.layer.attr[\'value\'].tensor.int_val[0]\n\n\n    def rename_DepthwiseConv2dNative(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count=1, new_op=\'DepthwiseConv\')\n        kwargs = {}\n        kwargs[\'strides\'] = source_node.get_attr(\'strides\')\n\n        input_node = self.src_graph.get_parent(source_node.name, [1])\n        kwargs[\'kernel_shape\'] = self.tensor_shape_to_list(input_node.get_attr(\'_output_shapes\'))[0]\n\n        self._convert_padding(source_node, IR_node, kwargs[\'kernel_shape\'][:-2])\n\n        if self.weight_loaded:\n            weight = self.src_graph.get_parent(source_node.name, [1, 0])\n            self.set_weight(source_node.name, \'weights\', self.ckpt_data[weight.name])\n\n        assign_IRnode_values(IR_node, kwargs)\n        self._get_bias(source_node, IR_node)\n\n\n    def rename_FusedBatchNorm(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count=1, new_op=\'BatchNorm\')\n        IR_node.attr[\'epsilon\'].f = source_node.get_attr(\'epsilon\', 0)\n\n        # gamma (scale)\n        scale = self.get_parent(source_node.name, [1], True)\n\n        if scale.type == \'Const\':\n            value = scale.get_attr(\'value\')\n            shape = value.tensor_shape\n            assert len(shape.dim) == 1\n            shape = shape.dim[0].size\n\n            assert len(value.float_val) == 1\n            value = value.float_val[0]\n\n            if np.isclose(value, 1.0):\n                IR_node.attr[\'scale\'].b = False\n            else:\n                IR_node.attr[\'scale\'].b = True\n                if self.weight_loaded:\n                    self.set_weight(source_node.name, \'scale\', np.array([value] * shape))\n\n        else:\n            scale = self.get_parent(scale.name, [0], True)\n            if self.weight_loaded:\n                self.set_weight(source_node.name, \'scale\', self.ckpt_data[scale.name])\n            IR_node.attr[\'scale\'].b = True\n\n        # bias\n        bias = self.get_parent(source_node.name, [2, 0], True)\n        IR_node.attr[\'bias\'].b = True\n\n        # Mean\n        mean = self.get_parent(source_node.name, [3, 0], True)\n\n        # Var\n        var = self.get_parent(source_node.name, [4, 0], True)\n\n        if self.weight_loaded:\n            self.set_weight(source_node.name, \'bias\', self.ckpt_data[bias.name])\n            self.set_weight(source_node.name, \'mean\', self.ckpt_data[mean.name])\n            self.set_weight(source_node.name, \'var\', self.ckpt_data[var.name])\n\n    def rename_FusedBatchNormV3(self, source_node):\n        self.rename_FusedBatchNorm(source_node)\n\n    def rename_Shape(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, in_edge_count=1, new_op=\'Shape\')\n\n    def rename_Pack(self, source_node):\n        N = len(source_node.layer.input)\n        for i in range(N):\n            this_node = self.get_parent(source_node.name, [i])\n            if this_node.type == \'Const\':\n\n                IR_node = self.IR_graph.node.add()\n                TensorflowParser._copy_and_reop(this_node, IR_node, \'Constant\')\n                kwargs = {\n                    \'value\' : this_node.layer.attr[\'value\'].tensor.int_val[0],\n                }\n                assign_IRnode_values(IR_node, kwargs)\n\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Pack\')\n        kwargs = {\n            \'axis\' : source_node.layer.attr[\'axis\'].i,\n            \'N\'    : source_node.layer.attr[\'N\'].i\n        }\n        assign_IRnode_values(IR_node, kwargs)\n\n    def rename_Gather(self, source_node):\n\n        W = self.src_graph.get_parent(source_node.name, [0])\n        W = self.src_graph.get_parent(W.name, [0])\n\n        if \'Variable\' in W.type:\n            IR_node = self._convert_identity_operation(source_node, new_op=\'Embedding\')\n\n            self.set_weight(source_node.name, ""weights"", self.ckpt_data[W.name])\n\n            kwargs = {\n                \'input_dim\' : self.ckpt_data[W.name].shape[0],\n                \'output_dim\' : self.ckpt_data[W.name].shape[1],\n                \'mask_zero\' : False\n            }\n            kwargs[\'axis\'] = 0  # add default\n            assign_IRnode_values(IR_node, kwargs)\n        else:\n            IR_node = self._convert_identity_operation(source_node, new_op=\'Gather\')\n\n        return IR_node\n\n    def rename_GatherV2(self, source_node):\n        \n        IR_node = self.rename_Gather(source_node)\n\n        kwargs = {}\n        kwargs[\'axis\'] = source_node.layer.attr[\'axis\'].i\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Transpose(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n\n\n\n    def rename_Sigmoid(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_Mul(self, source_node):\n        scale1 = self.get_parent(source_node.name, [1], True)\n        scale2 = self.get_parent(source_node.name, [0], True)\n\n        if scale1.type == \'Const\' or scale2.type == \'Const\':\n            self._add_constant_node(source_node)\n            self._convert_identity_operation(source_node)\n\n        elif scale2.type == \'Identity\':\n            scale2 = self.get_parent(scale2.name, [0], True)\n            assert scale2.type == ""VariableV2""\n            self.set_weight(source_node.name, \'alpha\', self.ckpt_data[scale2.name])\n            self._convert_identity_operation(source_node)\n\n        else:\n            self._convert_identity_operation(source_node)\n\n\n    \'\'\'\n    tf.unpack has been deprecated with replaced tf.unstack\n    \'\'\'\n    def rename_Unpack(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Unstack\')\n        kwargs = {\n            \'axis\' : source_node.get_attr(\'axis\'),\n            \'num\'  : source_node.get_attr(\'num\')\n        }\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Split(self, source_node):\n        if source_node.get_attr(\'num_split\') == 1:            \n            for n in source_node.out_nodes:\n                for idx, e in enumerate(n.in_edges):\n                    if source_node.name in e:\n                        n.in_edges[idx] = e.split(\':\')[0]\n\n            source_node.real_name = self.get_parent(source_node.name, [1]).real_name\n\n        else:\n            IR_node = self._convert_identity_operation(source_node, 1, 1)\n            kwargs = {\n                \'axis\' : self.get_parent(source_node.name, [0]).layer.attr[\'value\'].tensor.int_val[0],\n                \'split\' : source_node.get_attr(\'num_split\')\n            }\n            assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_StridedSlice(self, source_node):\n        # TODO: Current it is only for slice\n\n        if self.get_parent(source_node.name, [1]).type != \'Const\':\n            self._add_constant_node(source_node)\n            IR_node = self._convert_identity_operation(source_node, new_op=\'Slice\')\n            return\n\n        IR_node = self._convert_identity_operation(source_node, in_edge_count=1, new_op=\'Slice\')\n        kwargs = {\n            \'begin_mask\' : source_node.get_attr(\'begin_mask\'),\n            \'end_mask\'   : source_node.get_attr(\'end_mask\'),\n            \'shrink_axis_mask\': source_node.get_attr(\'shrink_axis_mask\'),\n            \'new_axis_mask\' :source_node.get_attr(\'new_axis_mask\')\n        }\n\n        starts = self.get_parent(source_node.name, [1]).layer.attr[\'value\'].tensor\n        starts = tensor_util.MakeNdarray(starts).tolist()\n        kwargs[\'starts\'] = starts\n\n        ends = self.get_parent(source_node.name, [2]).layer.attr[\'value\'].tensor\n        ends = tensor_util.MakeNdarray(ends).tolist()\n        kwargs[\'ends\'] = ends\n\n        if self.get_parent(source_node.name, [3]) != None:\n            strides = self.get_parent(source_node.name, [3]).layer.attr[\'value\'].tensor\n            strides = tensor_util.MakeNdarray(strides).tolist()\n            kwargs[\'strides\'] = strides\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Slice(self, source_node):\n        input_node_begin = self.get_parent(source_node.name, [1])\n        input_node_size = self.get_parent(source_node.name, [2])\n\n        begin = tensor_util.MakeNdarray(input_node_begin.layer.attr[\'value\'].tensor)\n        size = tensor_util.MakeNdarray(input_node_size.layer.attr[\'value\'].tensor)\n\n        IR_node = self._convert_identity_operation(source_node, in_edge_count=1, new_op=\'Slice\')\n\n        # TODO:  axis\n        end = size + begin\n        kwargs = {\n            \'starts\' : begin,\n            \'ends\' : end\n        }\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_LRN(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        size = source_node.get_attr(\'depth_radius\') * 2 + 1\n        alpha = source_node.get_attr(\'alpha\') * size\n        beta = source_node.get_attr(\'beta\')\n        bias = source_node.get_attr(\'bias\')\n\n        kwargs = {\n            ""alpha"" : alpha,\n            ""beta"" : beta,\n            ""bias"" : bias,\n            \'size\' : size,\n        }\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Tanh(self, source_node):\n        self._convert_identity_operation(source_node)\n\n\n    def rename_ExpandDims(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, 0, 1, new_op=\'Unsqueeze\')\n        \n        ax_node = self.get_parent(source_node.name, [1])\n        kwargs = {\n            \'axes\': [ax_node.layer.attr[\'value\'].tensor.int_val[0]]\n        }\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Fill(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, 0, 1, new_op=\'Fill\')\n\n        value_node = self.get_parent(source_node.name, [1])\n        if value_node.layer.attr[\'value\'].tensor.float_val:\n            IR_node.attr[\'value\'].f = value_node.layer.attr[\'value\'].tensor.float_val[0]\n        elif value_node.layer.attr[\'value\'].tensor.int_val:\n            IR_node.attr[\'value\'].i = value_node.layer.attr[\'value\'].tensor.int_val[0]\n        else:\n            raise NotImplementedError()\n\n\n    def rename_Conv2DBackpropInput(self, source_node):\n        """"""\n        weights: name_weights, name_bias\n        """"""\n        IR_node = self._convert_identity_operation(source_node, new_op = \'ConvTranspose\')\n\n        kwargs = {}\n\n        # strides\n        kwargs[\'strides\'] = source_node.get_attr(\'strides\')\n\n        # input[1] : W\n        # filter\n        W = self.tf_graph.get_node(source_node.layer.input[1])\n        W = self.tf_graph.get_node(W.layer.input[0]).layer\n        kwargs[\'kernel_shape\'] = self.tensor_shape_to_list(W.attr[\'shape\'])\n\n        # padding\n        self._convert_padding(source_node, IR_node, kwargs[\'kernel_shape\'][:-2])\n\n        if self.weight_loaded:\n            self.set_weight(source_node.name, \'weights\', self.ckpt_data[W.name])\n\n        assign_IRnode_values(IR_node, kwargs)\n        # output[0] : B\n        self._get_bias(source_node, IR_node)\n    \n    def rename_Minimum(self, source_node):\n        self._add_constant_node(source_node)\n        self._convert_identity_operation(source_node)\n\n    def rename_Maximum(self, source_node):\n        self._add_constant_node(source_node)\n        self._convert_identity_operation(source_node)\n\n    def rename_Cast(self, source_node):\n        IR_node = self._convert_identity_operation(source_node)\n        dst = source_node.get_attr(\'DstT\')\n        if dst == 1:\n            dst = \'float\'\n        elif dst == 3:\n            dst = \'int\'\n        else:\n            raise NotImplementedError\n\n        kwargs = {\'dstType\' : dst}\n        assign_IRnode_values(IR_node, kwargs)\n'"
mmdnn/conversion/torch/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/torch/torch_graph.py,4,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom mmdnn.conversion.common.DataStructure.graph import GraphNode, Graph\nfrom tensorflow.core.framework.node_def_pb2 import NodeDef\nfrom tensorflow.core.framework import attr_value_pb2\nimport torch\n\n\nclass TorchGraphNode(GraphNode):\n\n    def __init__(self, layer, id):\n        # self._type = layer.__class__.__name__.replace(\'Backward\', \'\')\n        # self._name = ""{}_{}"".format(self.type, id)\n        # TODO\n        super(PyTorchGraphNode, self).__init__(layer)\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def type(self):\n        return self._type\n\n\n    @property\n    def torch_layer(self):\n        return self.layer\n\n\nclass TorchGraph(Graph):\n\n    def __init__(self, model):\n        super(TorchGraph, self).__init__(model)\n        self.model = model\n\n\n    def build(self, shape):\n        print (self.model)\n        print (dir(self.model))\n\n        output_shapes = self._infer_torch_output_shapes(\n            self.model,\n            shape\n        )\n        print (output_shapes)\n\n        # """"""\n        # build graph for pytorch 0.2.0\n        # """"""\n        # dummy_input = torch.autograd.Variable(torch.randn(shape))\n        # output_node = self.model(dummy_input)\n\n        # search_queue = [output_node.grad_fn]\n        # tmp_node = PyTorchGraphNode(output_node.grad_fn, 0)\n        # self.layer_map[tmp_node.name] = tmp_node\n        # visited = {output_node.grad_fn : self.layer_map[tmp_node.name]}\n\n        # idx = 0\n        # node_count = 1\n        # while (idx < len(search_queue)):\n        #     current_node = search_queue[idx]\n        #     current_type = visited[current_node].type\n        #     if hasattr(current_node, \'next_functions\'):\n        #         for parent, _ in current_node.next_functions:\n        #             parent_type = parent.__class__.__name__.replace(\'Backward\', \'\')\n        #             if parent_type != \'AccumulateGrad\' and \\\n        #                (parent_type != \'Transpose\' or current_type != \'Addmm\'):\n        #                 if not parent in visited:\n        #                     tmp_node = PyTorchGraphNode(parent, node_count)\n        #                     self.layer_map[tmp_node.name] = tmp_node\n        #                     node_count += 1\n        #                     visited[parent] = tmp_node\n        #                     search_queue.append(parent)\n        #                 self._make_connection(visited[parent].name, visited[current_node].name)\n        #     idx += 1\n\n        super(TorchGraph, self).build()\n\n\n    @staticmethod\n    def _infer_torch_output_shapes(torch_model, input_shapes):\n        """"""\n        Forward torch model to infer output shape\n        """"""\n        return TorchGraph._forward_torch_random_input(\n                torch_model,\n                input_shapes,\n                is_batch=False)\n\n        # try:\n        #     return TorchGraph._forward_torch_random_input(\n        #         torch_model,\n        #         input_shapes,\n        #         is_batch=False\n        #     )\n        # except:\n        #     # try batch mode\n        #     # return TorchGraph._forward_torch_random_input(\n        #     #     torch_model,\n        #     #     input_shapes,\n        #     #     is_batch=True\n        #     # )\n        #     pass\n\n    @staticmethod\n    def _forward_torch_random_input(torch_model, input_shapes, is_batch=False):\n        input_tensors = []\n        for shape in input_shapes:\n            if is_batch:\n                tensor = torch.rand(1, *shape).float()\n            else:\n                tensor = torch.randn(shape)\n                # tensor = torch.rand(*shape).float()\n            input_tensors.append(tensor)\n\n        print (input_tensors[0].shape)\n        if len(input_tensors) == 1:\n            result = torch_model.forward(input_tensors[0])\n        else:\n            result = torch_model.forward(input_tensors)\n\n        print (""result"", result)\n        if isinstance(result, list):\n            # multi output\n            output_shapes = []\n            for tensor in result:\n                shape = tensor.numpy().shape\n                if is_batch:\n                    shape = shape[1:]\n                output_shapes.append(shape)\n            return output_shapes\n        else:\n            # single output\n            output_shape = result.numpy().shape\n            if is_batch:\n                return [output_shape[1:]]\n            else:\n                return [output_shape]'"
mmdnn/conversion/torch/torch_parser.py,2,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport os\nimport numpy as np\nfrom torch.utils.serialization import load_lua\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.common.DataStructure.parser import Parser\nfrom mmdnn.conversion.torch.torch_graph import TorchGraph\n\n\nclass TorchParser(Parser):\n\n    ############\n    # property #\n    ############\n\n    @property\n    def src_graph(self):\n        return self.torch_graph\n\n\n    ####################\n    # Public Functions #\n    ####################\n\n    def __init__(self, model_file_name, input_shape):\n        super(TorchParser, self).__init__()\n        if not os.path.exists(model_file_name):\n            raise ValueError(""Torch7 model file [{}] is not found."".format(model_file_name))\n        model = load_lua(model_file_name)\n        if type(model).__name__==\'hashable_uniq_dict\':\n            model = model.model\n        model.evaluate()\n        self.weight_loaded = True\n\n        # Build network graph\n        self.torch_graph = TorchGraph(model)\n        self.torch_graph.build([[1] + list(map(int, input_shape))])\n\n\n    def gen_IR(self):\n        print (""OK"")\n        assert False\n        print (self.torch_graph.model.childrens())\n        for layer in self.src_graph.topological_sort:\n            current_node = self.src_graph.get_node(layer)\n            node_type = current_node.type\n\n            if hasattr(self, ""rename_"" + node_type):\n                func = getattr(self, ""rename_"" + node_type)\n                func(current_node)\n\n            else:\n                self.rename_UNKNOWN(current_node)\n\n    ##########\n    # Layers #\n    ##########\n    def rename_UNKNOWN(self, source_node):\n        print (source_node.layer)\n        print (source_node.layer.data.size())\n        assert False\n        print(""PyTorch parser has not supported operator [%s] with name [%s].""\n              % (source_node.type, source_node.name))\n\n    def rename_NoneType(self, source_node):\n        assert source_node.name in self.src_graph.input_layers\n        IR_node = self._convert_identity_operation(source_node, new_op=""DataInput"")\n        for dim in self.input_shape:\n            new_dim = IR_node.attr[""shape""].shape.dim.add()\n            if dim == None:\n                new_dim.size = -1\n            else:\n                new_dim.size = dim\n\n\n    def rename_ConvNd(self, source_node):\n        kwargs = dict()\n        kwargs[\'dilations\'] = [1] + list(source_node.get_attr(\'dilation\')) + [1]\n        kwargs[\'pads\'] = ([0] + list(source_node.get_attr(\'padding\')) + [0]) * 2\n        kwargs[\'strides\'] = [1] + list(source_node.get_attr(\'stride\')) + [1]\n        kwargs[\'group\'] = source_node.get_attr(\'groups\')\n\n        # handle weight\n        weight = source_node.get_attr(\'next_functions\')[1][0].variable.data.numpy()\n        dim = weight.ndim - 2\n\n        if source_node.get_attr(\'transposed\'):\n            IR_node = self._convert_identity_operation(source_node, new_op=""ConvTranpose"")\n            weight = np.transpose(weight, list(range(2, dim + 2)) + [0, 1])\n        else:\n            IR_node = self._convert_identity_operation(source_node, new_op=""Conv"")\n            weight = np.transpose(weight, list(range(2, dim + 2)) + [1, 0])\n\n        self.set_weight(source_node.name, \'weights\', weight)\n        kwargs[\'kernel_shape\'] = list(weight.shape)\n\n        # handle bias\n        if source_node.get_attr(\'next_functions\')[2][0]:\n            bias = source_node.get_attr(\'next_functions\')[2][0].variable.data.numpy()\n            self.set_weight(source_node.name, \'bias\', weight)\n            kwargs[\'use_bias\'] = True\n        else:\n            kwargs[\'use_bias\'] = False\n\n        assign_IRnode_values(IR_node, kwargs)\n\n\n    def rename_Threshold(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Relu\')\n\n\n    def rename_MaxPool2d(self, source_node):\n        self._convert_pooling(source_node)\n\n\n    def rename_View(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'Reshape\')\n        assign_IRnode_values(IR_node, {\'shape\' : list(source_node.get_attr(\'new_sizes\'))[1:]})\n\n\n    def rename_Addmm(self, source_node):\n        IR_node = self._convert_identity_operation(source_node, new_op=\'FullyConnected\')\n        kwargs = dict()\n\n        # handle weight\n        weight = source_node.get_attr(\'next_functions\')[2][0].next_functions[0][0].variable.data.numpy()\n        weight = np.transpose(weight)\n        kwargs[\'units\'] = weight.shape[1]\n        self.set_weight(source_node.name, \'weights\', weight)\n\n        # handle bias\n        if source_node.get_attr(\'next_functions\')[0][0]:\n            bias = source_node.get_attr(\'next_functions\')[0][0].variable.data.numpy()\n            kwargs[\'use_bias\'] = True\n            self.set_weight(source_node.name, \'bias\', weight)\n\n        assign_IRnode_values(IR_node, kwargs)\n\n        print(IR_node)\n\n\n    ####################\n    # Helper Functions #\n    ####################\n\n    @staticmethod\n    def _copy_and_reop(source_node, IR_node, new_op = None):\n        if new_op == None: new_op = source_node.type\n        IR_node.name = source_node.name\n        IR_node.op = new_op\n\n\n    def _convert_identity_operation(self, source_node, in_edge_count = None, new_op = None):\n        IR_node = self.IR_graph.node.add()\n        PyTorchParser._copy_and_reop(source_node, IR_node, new_op)\n        self.convert_inedge(source_node, IR_node, 0, in_edge_count)\n        return IR_node\n\n    def _convert_pooling(self, source_node):\n        kwargs = dict()\n        kwargs[\'strides\'] = [1] + list(source_node.get_attr(\'stride\')) + [1]\n        kwargs[\'dilations\'] = [1] + list(source_node.get_attr(\'dilation\')) + [1]\n        kwargs[\'pads\'] = ([0] + list(source_node.get_attr(\'padding\')) + [0]) * 2\n        kwargs[\'kernel_shape\'] = [1] + list(source_node.get_attr(\'kernel_size\')) + [1]\n        IR_node = self._convert_identity_operation(source_node, new_op=""Pool"")\n\n        if source_node.name.startswith(\'Max\'):\n            kwargs[\'pooling_type\'] = \'MAX\'\n        elif source_node.name.startswith(\'Avg\'):\n            kwargs[\'pooling_type\'] = \'MAX\'\n        else:\n            raise ValueError(\'Unknown pooling type\')\n\n        assign_IRnode_values(IR_node, kwargs)\n'"
mmdnn/conversion/common/DataStructure/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/common/DataStructure/emitter.py,0,"b'# ----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n# ----------------------------------------------------------------------------------------------\nfrom six import string_types as _string_types\n\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\n\n\nclass Emitter(object):\n\n    def __init__(self):\n        self.body_code = str()\n        self.weights_dict = dict()\n        self.used_layers = set()\n        self.weight_loaded = False\n        self.layers_codes = dict()\n\n    def run(self, dstNetworkPath, dstWeightPath=None, phase=\'test\'):\n        self.save_code(dstNetworkPath, phase)\n\n    # share functions\n    def add_body(self, indent, codes):\n        if isinstance(codes, _string_types):\n            codes = [codes]\n        for code in codes:\n            self.body_code += (""    "" * indent) + code + \'\\n\'\n\n    def _load_weights(self, file_name=None):\n        import numpy as np\n        self.weight_loaded = True\n        try:\n            self.weights_dict = np.load(file_name,\n                                        allow_pickle=True).item()  # made default False in response to CVE-2019-6446\n        except:\n            self.weights_dict = np.load(file_name, encoding=\'bytes\', allow_pickle=True).item()\n\n    def parent_variable_name(self, IR_node, path_or_name=[0]):\n        if isinstance(path_or_name, _string_types):\n            path = [IR_node.in_edges.index(path_or_name)]\n        elif isinstance(path_or_name, list):\n            path = path_or_name\n        else:\n            raise ValueError\n        return self.IR_graph.get_parent_variable_name(IR_node.name, path)\n\n    def _build(self):\n        self.IR_graph.build()\n\n    def gen_code(self, phase):\n        raise NotImplementedError(""do not use base emitter class."")\n\n    def save_code(self, filepath, phase):\n        code = self.gen_code(phase)\n        with open(filepath, \'w\') as fout:\n            fout.write(code)\n        print(""Target network code snippet is saved as [{}]."".format(filepath))\n\n    @staticmethod\n    def save_weights(weights, filename):\n        import numpy as np\n        with open(filename, \'wb\') as of:\n            np.save(of, weights)\n        print(""Target weights are saved as [{}]."".format(filename))\n\n    @staticmethod\n    def _image_in_transpose_str(dim):\n        dims = [dim]\n        dims.extend(range(dim))\n        return \',\'.join(\'%s\' % id for id in dims)\n\n    @staticmethod\n    def _image_out_transpose_str(dim):\n        dims = list(range(1, dim + 1))\n        dims.append(0)\n        return \',\'.join(\'%s\' % id for id in dims)\n\n    @staticmethod\n    def _conv_kernel_transpose_str(dim):\n        dims = [dim + 1, dim]\n        dims.extend(range(dim))\n        return \',\'.join(\'%s\' % id for id in dims)\n'"
mmdnn/conversion/common/DataStructure/graph.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport  collections\n\nclass GraphNode(object):\n\n    def __init__(self, layer):\n        self.in_edges = list()\n        self.out_edges = list()\n        self.layer = layer\n        self.covered = False\n        self.real_name = self.name\n\n    @property\n    def name(self):\n        assert False\n\n    @property\n    def variable_name(self):\n        return self.real_name.replace(\'/\', \'_\').replace(\'-\', \'_\').replace(\'[\',\'_\').replace(\']\',\'_\')\n\n    @property\n    def real_variable_name(self):\n        return self.real_name.replace(\'/\', \'_\').replace(\'-\', \'_\').replace(\'[\',\'_\').replace(\']\',\'_\')\n\n\n\nclass Graph(object):\n\n    def __init__(self, model):\n        # key: layer_name    value: keras layer\n        self.layer_map = collections.OrderedDict()\n        self.input_layers = list()\n        self.output_layers = list()\n        self.layer_name_map = collections.OrderedDict()\n        self.topological_sort = list()\n        self.model = model\n\n\n    def build(self):\n        self._make_input_layers()\n        self._make_output_layers()\n        self._get_topological_sort()\n\n\n    def rebuild(self):\n        self._make_input_layers(True)\n        self._make_output_layers()\n        self._get_topological_sort()\n\n    def _make_input_layers(self, rebuild=False):\n        for name, layer in self.layer_map.items():\n            layer.left_in_edges = len(layer.in_edges)\n            if len(layer.in_edges) == 0:\n                if rebuild:\n                    if not layer.get_attr(\'scope\'):\n                        self.input_layers.append(name)\n                else:\n                    self.input_layers.append(name)\n\n\n    def _make_output_layers(self):\n        for name, layer in self.layer_map.items():\n            if len(layer.out_edges) == 0:\n                self.output_layers.append(name)\n\n\n    \'\'\'get node by its name or tensor name\'\'\'\n    def get_node(self, name):\n        if not name.split(\':\')[0] in self.layer_map:\n            raise IOError(""Graph doesn\'t have node [%s]."" % name.split(\':\')[0])\n            return None\n        else:\n            return self.layer_map[name.split(\':\')[0]]\n\n\n    def get_nodes(self):\n        return self.layer_map.values()\n\n\n    def get_son(self, name, path, set_flag = False):\n        if name == None: return None\n        current_node = self.get_node(name)\n        for idx in path:\n            if len(current_node.out_edges) <= idx: return None\n            son_name = current_node.out_edges[idx].split(\':\')[0]\n            current_node = self.get_node(son_name)\n            if set_flag:\n                current_node.covered = True\n        return current_node\n\n\n    def get_parent(self, name, path, set_flag = False):\n        if name == None: return None\n        current_node = self.get_node(name)\n        for idx in path:\n            if len(current_node.in_edges) <= idx: return None\n            parent_name = current_node.in_edges[idx].split(\':\')[0]\n            current_node = self.get_node(parent_name)\n            if set_flag:\n                current_node.covered = True\n        return current_node\n\n    def get_real_parent_name(self, name, path, set_flag = False):\n        if name == None: return None\n        current_node = self.get_node(name)\n        for idx in path:\n            if len(current_node.in_edges) <= idx: return None\n            parent_name = current_node.in_edges[idx].split(\':\')[0]\n            current_node = self.get_node(parent_name)\n            if set_flag:\n                current_node.covered = True\n        return self.layer_name_map[current_node.name]\n\n\n    def get_parent_variable_name(self, name, path, set_flag = False):\n        if name == None: return None\n        current_node = self.get_node(name)\n        for idx in path:\n            if len(current_node.in_edges) <= idx: return None\n            parent_name = current_node.in_edges[idx].split(\':\')[0]\n            current_subscriptor = \'\' if len(current_node.in_edges[idx].split(\':\'))==1 else \'[{}]\'.format(current_node.in_edges[idx].split(\':\')[1])\n            current_node = self.get_node(parent_name)\n            if set_flag:\n                current_node.covered = True\n\n        return current_node.real_variable_name + current_subscriptor\n\n\n    # private functions\n    def _get_topological_sort(self):\n        self.topological_sort = self.input_layers[:]\n        idx = 0\n        while idx < len(self.topological_sort):\n            current_node = self.get_node(self.topological_sort[idx])\n            for next_node in current_node.out_edges:\n                next_node_info = self.get_node(next_node)\n                next_node_info.left_in_edges -= self._check_left_in_edges_num(current_node.name, next_node_info) # one node may connect another node by more than one edge. \n                # next_node_info.left_in_edges -= 1\n                if next_node_info.left_in_edges == 0:\n                    self.topological_sort.append(next_node)\n            idx += 1\n\n\n    def _make_connection(self, src, dst):\n        if (src == dst) or (src not in self.layer_map) or (dst not in self.layer_map):\n            if src.split(\':\')[0] not in self.layer_map:\n                print (""Warning: Graph Construct a self-loop node {}. Ignored."".format(src))\n                return\n\n        # print (\'{} --> {}\'.format(src, dst))\n        if not dst in self.layer_map[src.split(\':\')[0]].out_edges:\n            self.layer_map[src.split(\':\')[0]].out_edges.append(dst)\n        if not src in self.layer_map[dst].in_edges:\n            self.layer_map[dst.split(\':\')[0]].in_edges.append(src)\n\n\n    def _check_left_in_edges_num(self, in_node_name, node):\n        count = 0\n        for in_edge in node.in_edges:\n            if in_node_name == in_edge.split(\':\')[0]:\n                count += 1\n        return count'"
mmdnn/conversion/common/DataStructure/parser.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport numpy as np\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.IR.graph_pb2 import NodeDef, GraphDef, DataType\n\n\nclass Parser(object):\n\n    def __init__(self):\n        self.IR_graph = GraphDef()\n        self.weight_loaded = False\n\n        # name --> (weight_name --> ndarray)\n        self.weights = dict()\n\n\n    def run(self, dest_path):\n        self.gen_IR()\n        self.save_to_json(dest_path + "".json"")\n        self.save_to_proto(dest_path + "".pb"")\n        self.save_weights(dest_path + "".npy"")\n\n\n    @property\n    def src_graph(self):\n        raise NotImplementedError\n\n\n    def get_son(self, name, path, set_flag = False):\n        return self.src_graph.get_son(name, path, set_flag)\n\n\n    def get_parent(self, name, path, set_flag = False):\n        return self.src_graph.get_parent(name, path, set_flag)\n\n\n    def set_weight(self, layer_name, weight_name, data):\n        if not layer_name in self.weights:\n            self.weights[layer_name] = dict()\n        layer = self.weights[layer_name]\n        layer[weight_name] = data\n\n\n    def save_to_json(self, filename):\n        import google.protobuf.json_format as json_format\n        json_str = json_format.MessageToJson(self.IR_graph, preserving_proto_field_name = True)\n\n        with open(filename, ""w"") as of:\n            of.write(json_str)\n\n        print (""IR network structure is saved as [{}]."".format(filename))\n\n        return json_str\n\n\n    def save_to_proto(self, filename):\n        proto_str = self.IR_graph.SerializeToString()\n        with open(filename, \'wb\') as of:\n            of.write(proto_str)\n\n        print (""IR network structure is saved as [{}]."".format(filename))\n\n        return proto_str\n\n\n    def save_weights(self, filename):\n        if self.weight_loaded:\n            with open(filename, \'wb\') as of:\n                np.save(of, self.weights)\n            print (""IR weights are saved as [{}]."".format(filename))\n\n        else:\n            print (""Warning: weights are not loaded."")\n\n\n    def convert_inedge(self, source_node, IR_node, start_idx = 0, end_idx = None):\n        if end_idx == None: end_idx = len(source_node.in_edges)\n        for idx in range(start_idx, end_idx):\n            IR_node.input.append(self.src_graph.get_node(source_node.in_edges[idx]).real_name.lstrip(\'_\'))\n\n\n    @staticmethod\n    def channel_first_conv_kernel_to_IR(tensor):\n        dim = tensor.ndim\n        tensor = np.transpose(tensor, list(range(2, dim)) + [1, 0])\n        return tensor\n\n\n    @staticmethod\n    def channel_first_shape_to_IR(shape):\n        return [shape[0]] + list(shape[2:]) + [shape[1]]\n\n    @staticmethod\n    def channel_first_axis_to_IR(index):\n        if index == 0:\n            return 0\n        elif index == 1:\n            return -1\n        else:\n            return index - 1\n'"
mmdnn/conversion/common/IR/IR_graph.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport mmdnn.conversion.common.IR.graph_pb2 as graph_pb2\nfrom mmdnn.conversion.common.utils import *\nfrom mmdnn.conversion.common.IR.graph_pb2 import TensorShape, AttrValue\nfrom mmdnn.conversion.common.DataStructure.graph import Graph, GraphNode\n\n\ndef load_protobuf_from_file(container, filename):\n    with open(filename, \'rb\') as fin:\n        file_content = fin.read()\n\n    # First try to read it as a binary file.\n    try:\n        container.ParseFromString(file_content)\n        print(""Parse file [%s] with binary format successfully."" % (filename))\n        return container\n\n    except Exception as e:  # pylint: disable=broad-except\n        print (""Info: Trying to parse file [%s] with binary format but failed with error [%s]."" % (filename, str(e)))\n\n    # Next try to read it as a text file.\n    try:\n        from google.protobuf import text_format\n        text_format.Parse(file_content.decode(\'UTF-8\'), container, allow_unknown_extension=True)\n        print(""Parse file [%s] with text format successfully."" % (filename))\n    except text_format.ParseError as e:\n        raise IOError(""Cannot parse file %s: %s."" % (filename, str(e)))\n\n    return container\n\n\nclass IRGraphNode(GraphNode):\n\n    @staticmethod\n    def replace_scope(name):\n        return name.replace(\'/\', \'_\')\n\n    @property\n    def IR_layer(self):\n        return self.layer\n\n    @property\n    def name(self):\n        return self.layer.name\n\n    @property\n    def type(self):\n        return self.layer.op\n\n    def set_attrs(self, attrs):\n        assign_IRnode_values(self.layer, attrs)\n\n\n    def get_attr(self, name, default_value = None):\n        if name in self.layer.attr:\n            attr = self.layer.attr[name]\n            field = attr.WhichOneof(\'value\')\n            val = getattr(attr, field) if field else default_value\n            if not val:\n                return val\n            if isinstance(val, AttrValue.ListValue):\n                if val.ListFields():\n                    return list(val.ListFields()[0][1])\n                else:\n                    return val.ListFields()\n            else:\n                return val.decode(\'utf-8\') if isinstance(val, bytes) else val\n        else:\n            return default_value\n\n\nclass IRGraph(Graph):\n\n    @staticmethod\n    def shapeToStr(tensor_shape, keep_minus_one = False):\n        ret = """"\n        first = True\n        for e in tensor_shape.dim:\n            if e.size != -1 or keep_minus_one:\n                if first == False:\n                    ret += "", ""\n                ret += str(e.size)\n                first = False\n        return ret\n\n\n    def __init__(self, filename):\n        model = graph_pb2.GraphDef()\n        load_protobuf_from_file(model, filename)\n        super(IRGraph, self).__init__(model)\n\n\n    def filter_node(self):\n        self.layer_map = dict(filter(lambda layer: layer[1].in_edges or layer[1].out_edges, self.layer_map.items()))\n\n\n    def build(self):\n        for layer in self.model.node:\n            self.layer_map[layer.name] = IRGraphNode(layer)\n            self.layer_name_map[layer.name] = layer.name\n\n        for i, layer in enumerate(self.model.node):\n            for pred in layer.input:\n                self._make_connection(pred, layer.name)\n\n        self.filter_node()\n        super(IRGraph, self).build()\n        self.input_layers = list(filter(lambda x: self.layer_map[x].type != \'Constant\', self.input_layers))\n\n\n    def rebuild(self):\n        self.input_layers.clear()\n        self.output_layers.clear()\n        self.topological_sort.clear()\n        self.filter_node()\n        super(IRGraph, self).build()\n        self.input_layers = list(filter(lambda x: self.layer_map[x].type != \'Constant\', self.input_layers))\n\n\n    def clear_out_scope_node(self):\n\n        def _clear_list_out_scope(list_):\n            for idx in range(len(list_) -1, -1, -1):\n                node = self.get_node(list_[idx])\n                if node.type != \'Scope\' and node.get_attr(\'scope\'):\n                    del list_[idx]\n\n        _clear_list_out_scope(self.input_layers)\n        _clear_list_out_scope(self.topological_sort)\n        _clear_list_out_scope(self.output_layers)\n\n'"
mmdnn/conversion/common/IR/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/common/IR/graph_pb2.py,0,"b'# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# source: graph.proto\n\nimport sys\n_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode(\'latin1\'))\nfrom google.protobuf.internal import enum_type_wrapper\nfrom google.protobuf import descriptor as _descriptor\nfrom google.protobuf import message as _message\nfrom google.protobuf import reflection as _reflection\nfrom google.protobuf import symbol_database as _symbol_database\nfrom google.protobuf import descriptor_pb2\n# @@protoc_insertion_point(imports)\n\n_sym_db = _symbol_database.Default()\n\n\n\n\nDESCRIPTOR = _descriptor.FileDescriptor(\n  name=\'graph.proto\',\n  package=\'\',\n  syntax=\'proto3\',\n  serialized_pb=_b(\'\\n\\x0bgraph.proto\\""3\\n\\x08GraphDef\\x12\\x16\\n\\x04node\\x18\\x01 \\x03(\\x0b\\x32\\x08.NodeDef\\x12\\x0f\\n\\x07version\\x18\\x02 \\x01(\\x05\\""\\x8d\\x01\\n\\x07NodeDef\\x12\\x0c\\n\\x04name\\x18\\x01 \\x01(\\t\\x12\\n\\n\\x02op\\x18\\x02 \\x01(\\t\\x12\\r\\n\\x05input\\x18\\x03 \\x03(\\t\\x12 \\n\\x04\\x61ttr\\x18\\x04 \\x03(\\x0b\\x32\\x12.NodeDef.AttrEntry\\x1a\\x37\\n\\tAttrEntry\\x12\\x0b\\n\\x03key\\x18\\x01 \\x01(\\t\\x12\\x19\\n\\x05value\\x18\\x02 \\x01(\\x0b\\x32\\n.AttrValue:\\x02\\x38\\x01\\""\\xea\\x02\\n\\tAttrValue\\x12$\\n\\x04list\\x18\\x01 \\x01(\\x0b\\x32\\x14.AttrValue.ListValueH\\x00\\x12\\x0b\\n\\x01s\\x18\\x02 \\x01(\\x0cH\\x00\\x12\\x0b\\n\\x01i\\x18\\x03 \\x01(\\x03H\\x00\\x12\\x0b\\n\\x01\\x66\\x18\\x04 \\x01(\\x02H\\x00\\x12\\x0b\\n\\x01\\x62\\x18\\x05 \\x01(\\x08H\\x00\\x12\\x19\\n\\x04type\\x18\\x06 \\x01(\\x0e\\x32\\t.DataTypeH\\x00\\x12\\x1d\\n\\x05shape\\x18\\x07 \\x01(\\x0b\\x32\\x0c.TensorShapeH\\x00\\x12 \\n\\x06tensor\\x18\\x08 \\x01(\\x0b\\x32\\x0e.LiteralTensorH\\x00\\x1a\\x9d\\x01\\n\\tListValue\\x12\\t\\n\\x01s\\x18\\x02 \\x03(\\x0c\\x12\\r\\n\\x01i\\x18\\x03 \\x03(\\x03\\x42\\x02\\x10\\x01\\x12\\r\\n\\x01\\x66\\x18\\x04 \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\r\\n\\x01\\x62\\x18\\x05 \\x03(\\x08\\x42\\x02\\x10\\x01\\x12\\x1b\\n\\x04type\\x18\\x06 \\x03(\\x0e\\x32\\t.DataTypeB\\x02\\x10\\x01\\x12\\x1b\\n\\x05shape\\x18\\x07 \\x03(\\x0b\\x32\\x0c.TensorShape\\x12\\x1e\\n\\x06tensor\\x18\\x08 \\x03(\\x0b\\x32\\x0e.LiteralTensorB\\x07\\n\\x05value\\""e\\n\\x0bTensorShape\\x12\\x1d\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32\\x10.TensorShape.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\t\\""\\xb0\\x02\\n\\rLiteralTensor\\x12\\x18\\n\\x05\\x64type\\x18\\x01 \\x01(\\x0e\\x32\\t.DataType\\x12\\""\\n\\x0ctensor_shape\\x18\\x02 \\x01(\\x0b\\x32\\x0c.TensorShape\\x12\\x16\\n\\x0eversion_number\\x18\\x03 \\x01(\\x05\\x12\\x16\\n\\x0etensor_content\\x18\\x04 \\x01(\\x0c\\x12\\x13\\n\\x07int_val\\x18\\x05 \\x03(\\x05\\x42\\x02\\x10\\x01\\x12\\x14\\n\\x08uint_val\\x18\\x06 \\x03(\\x05\\x42\\x02\\x10\\x01\\x12\\x15\\n\\tint64_val\\x18\\x07 \\x03(\\x03\\x42\\x02\\x10\\x01\\x12\\x16\\n\\nuint64_val\\x18\\x08 \\x03(\\x03\\x42\\x02\\x10\\x01\\x12\\x15\\n\\tfloat_val\\x18\\t \\x03(\\x02\\x42\\x02\\x10\\x01\\x12\\x16\\n\\ndouble_val\\x18\\n \\x03(\\x01\\x42\\x02\\x10\\x01\\x12\\x14\\n\\x08\\x62ool_val\\x18\\x0b \\x03(\\x08\\x42\\x02\\x10\\x01\\x12\\x12\\n\\nstring_val\\x18\\x0c \\x03(\\x0c*\\xff\\x01\\n\\x08\\x44\\x61taType\\x12\\x10\\n\\x0c\\x44T_UNDEFINED\\x10\\x00\\x12\\x0b\\n\\x07\\x44T_INT8\\x10\\x01\\x12\\x0c\\n\\x08\\x44T_INT16\\x10\\x02\\x12\\x0c\\n\\x08\\x44T_INT32\\x10\\x03\\x12\\x0c\\n\\x08\\x44T_INT64\\x10\\x04\\x12\\x0c\\n\\x08\\x44T_UINT8\\x10\\x05\\x12\\r\\n\\tDT_UINT16\\x10\\x06\\x12\\r\\n\\tDT_UINT32\\x10\\x07\\x12\\r\\n\\tDT_UINT64\\x10\\x08\\x12\\x0e\\n\\nDT_FLOAT16\\x10\\t\\x12\\x0e\\n\\nDT_FLOAT32\\x10\\n\\x12\\x0e\\n\\nDT_FLOAT64\\x10\\x0b\\x12\\x10\\n\\x0c\\x44T_COMPLEX64\\x10\\x0c\\x12\\x11\\n\\rDT_COMPLEX128\\x10\\r\\x12\\x0b\\n\\x07\\x44T_BOOL\\x10\\x0e\\x12\\r\\n\\tDT_STRING\\x10\\x0f\\x62\\x06proto3\')\n)\n\n_DATATYPE = _descriptor.EnumDescriptor(\n  name=\'DataType\',\n  full_name=\'DataType\',\n  filename=None,\n  file=DESCRIPTOR,\n  values=[\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_UNDEFINED\', index=0, number=0,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_INT8\', index=1, number=1,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_INT16\', index=2, number=2,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_INT32\', index=3, number=3,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_INT64\', index=4, number=4,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_UINT8\', index=5, number=5,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_UINT16\', index=6, number=6,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_UINT32\', index=7, number=7,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_UINT64\', index=8, number=8,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_FLOAT16\', index=9, number=9,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_FLOAT32\', index=10, number=10,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_FLOAT64\', index=11, number=11,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_COMPLEX64\', index=12, number=12,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_COMPLEX128\', index=13, number=13,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_BOOL\', index=14, number=14,\n      options=None,\n      type=None),\n    _descriptor.EnumValueDescriptor(\n      name=\'DT_STRING\', index=15, number=15,\n      options=None,\n      type=None),\n  ],\n  containing_type=None,\n  options=None,\n  serialized_start=988,\n  serialized_end=1243,\n)\n_sym_db.RegisterEnumDescriptor(_DATATYPE)\n\nDataType = enum_type_wrapper.EnumTypeWrapper(_DATATYPE)\nDT_UNDEFINED = 0\nDT_INT8 = 1\nDT_INT16 = 2\nDT_INT32 = 3\nDT_INT64 = 4\nDT_UINT8 = 5\nDT_UINT16 = 6\nDT_UINT32 = 7\nDT_UINT64 = 8\nDT_FLOAT16 = 9\nDT_FLOAT32 = 10\nDT_FLOAT64 = 11\nDT_COMPLEX64 = 12\nDT_COMPLEX128 = 13\nDT_BOOL = 14\nDT_STRING = 15\n\n\n\n_GRAPHDEF = _descriptor.Descriptor(\n  name=\'GraphDef\',\n  full_name=\'GraphDef\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'node\', full_name=\'GraphDef.node\', index=0,\n      number=1, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'version\', full_name=\'GraphDef.version\', index=1,\n      number=2, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=15,\n  serialized_end=66,\n)\n\n\n_NODEDEF_ATTRENTRY = _descriptor.Descriptor(\n  name=\'AttrEntry\',\n  full_name=\'NodeDef.AttrEntry\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'key\', full_name=\'NodeDef.AttrEntry.key\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'value\', full_name=\'NodeDef.AttrEntry.value\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b(\'8\\001\')),\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=155,\n  serialized_end=210,\n)\n\n_NODEDEF = _descriptor.Descriptor(\n  name=\'NodeDef\',\n  full_name=\'NodeDef\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'NodeDef.name\', index=0,\n      number=1, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'op\', full_name=\'NodeDef.op\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'input\', full_name=\'NodeDef.input\', index=2,\n      number=3, type=9, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'attr\', full_name=\'NodeDef.attr\', index=3,\n      number=4, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[_NODEDEF_ATTRENTRY, ],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=69,\n  serialized_end=210,\n)\n\n\n_ATTRVALUE_LISTVALUE = _descriptor.Descriptor(\n  name=\'ListValue\',\n  full_name=\'AttrValue.ListValue\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'s\', full_name=\'AttrValue.ListValue.s\', index=0,\n      number=2, type=12, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'i\', full_name=\'AttrValue.ListValue.i\', index=1,\n      number=3, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'f\', full_name=\'AttrValue.ListValue.f\', index=2,\n      number=4, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'b\', full_name=\'AttrValue.ListValue.b\', index=3,\n      number=5, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'AttrValue.ListValue.type\', index=4,\n      number=6, type=14, cpp_type=8, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'AttrValue.ListValue.shape\', index=5,\n      number=7, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tensor\', full_name=\'AttrValue.ListValue.tensor\', index=6,\n      number=8, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=409,\n  serialized_end=566,\n)\n\n_ATTRVALUE = _descriptor.Descriptor(\n  name=\'AttrValue\',\n  full_name=\'AttrValue\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'list\', full_name=\'AttrValue.list\', index=0,\n      number=1, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'s\', full_name=\'AttrValue.s\', index=1,\n      number=2, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'i\', full_name=\'AttrValue.i\', index=2,\n      number=3, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'f\', full_name=\'AttrValue.f\', index=3,\n      number=4, type=2, cpp_type=6, label=1,\n      has_default_value=False, default_value=float(0),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'b\', full_name=\'AttrValue.b\', index=4,\n      number=5, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'type\', full_name=\'AttrValue.type\', index=5,\n      number=6, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'shape\', full_name=\'AttrValue.shape\', index=6,\n      number=7, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tensor\', full_name=\'AttrValue.tensor\', index=7,\n      number=8, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[_ATTRVALUE_LISTVALUE, ],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n    _descriptor.OneofDescriptor(\n      name=\'value\', full_name=\'AttrValue.value\',\n      index=0, containing_type=None, fields=[]),\n  ],\n  serialized_start=213,\n  serialized_end=575,\n)\n\n\n_TENSORSHAPE_DIM = _descriptor.Descriptor(\n  name=\'Dim\',\n  full_name=\'TensorShape.Dim\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'size\', full_name=\'TensorShape.Dim.size\', index=0,\n      number=1, type=3, cpp_type=2, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'name\', full_name=\'TensorShape.Dim.name\', index=1,\n      number=2, type=9, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b("""").decode(\'utf-8\'),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=645,\n  serialized_end=678,\n)\n\n_TENSORSHAPE = _descriptor.Descriptor(\n  name=\'TensorShape\',\n  full_name=\'TensorShape\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dim\', full_name=\'TensorShape.dim\', index=0,\n      number=2, type=11, cpp_type=10, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'unknown_rank\', full_name=\'TensorShape.unknown_rank\', index=1,\n      number=3, type=8, cpp_type=7, label=1,\n      has_default_value=False, default_value=False,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[_TENSORSHAPE_DIM, ],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=577,\n  serialized_end=678,\n)\n\n\n_LITERALTENSOR = _descriptor.Descriptor(\n  name=\'LiteralTensor\',\n  full_name=\'LiteralTensor\',\n  filename=None,\n  file=DESCRIPTOR,\n  containing_type=None,\n  fields=[\n    _descriptor.FieldDescriptor(\n      name=\'dtype\', full_name=\'LiteralTensor.dtype\', index=0,\n      number=1, type=14, cpp_type=8, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tensor_shape\', full_name=\'LiteralTensor.tensor_shape\', index=1,\n      number=2, type=11, cpp_type=10, label=1,\n      has_default_value=False, default_value=None,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'version_number\', full_name=\'LiteralTensor.version_number\', index=2,\n      number=3, type=5, cpp_type=1, label=1,\n      has_default_value=False, default_value=0,\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'tensor_content\', full_name=\'LiteralTensor.tensor_content\', index=3,\n      number=4, type=12, cpp_type=9, label=1,\n      has_default_value=False, default_value=_b(""""),\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n    _descriptor.FieldDescriptor(\n      name=\'int_val\', full_name=\'LiteralTensor.int_val\', index=4,\n      number=5, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'uint_val\', full_name=\'LiteralTensor.uint_val\', index=5,\n      number=6, type=5, cpp_type=1, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'int64_val\', full_name=\'LiteralTensor.int64_val\', index=6,\n      number=7, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'uint64_val\', full_name=\'LiteralTensor.uint64_val\', index=7,\n      number=8, type=3, cpp_type=2, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'float_val\', full_name=\'LiteralTensor.float_val\', index=8,\n      number=9, type=2, cpp_type=6, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'double_val\', full_name=\'LiteralTensor.double_val\', index=9,\n      number=10, type=1, cpp_type=5, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'bool_val\', full_name=\'LiteralTensor.bool_val\', index=10,\n      number=11, type=8, cpp_type=7, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))),\n    _descriptor.FieldDescriptor(\n      name=\'string_val\', full_name=\'LiteralTensor.string_val\', index=11,\n      number=12, type=12, cpp_type=9, label=3,\n      has_default_value=False, default_value=[],\n      message_type=None, enum_type=None, containing_type=None,\n      is_extension=False, extension_scope=None,\n      options=None),\n  ],\n  extensions=[\n  ],\n  nested_types=[],\n  enum_types=[\n  ],\n  options=None,\n  is_extendable=False,\n  syntax=\'proto3\',\n  extension_ranges=[],\n  oneofs=[\n  ],\n  serialized_start=681,\n  serialized_end=985,\n)\n\n_GRAPHDEF.fields_by_name[\'node\'].message_type = _NODEDEF\n_NODEDEF_ATTRENTRY.fields_by_name[\'value\'].message_type = _ATTRVALUE\n_NODEDEF_ATTRENTRY.containing_type = _NODEDEF\n_NODEDEF.fields_by_name[\'attr\'].message_type = _NODEDEF_ATTRENTRY\n_ATTRVALUE_LISTVALUE.fields_by_name[\'type\'].enum_type = _DATATYPE\n_ATTRVALUE_LISTVALUE.fields_by_name[\'shape\'].message_type = _TENSORSHAPE\n_ATTRVALUE_LISTVALUE.fields_by_name[\'tensor\'].message_type = _LITERALTENSOR\n_ATTRVALUE_LISTVALUE.containing_type = _ATTRVALUE\n_ATTRVALUE.fields_by_name[\'list\'].message_type = _ATTRVALUE_LISTVALUE\n_ATTRVALUE.fields_by_name[\'type\'].enum_type = _DATATYPE\n_ATTRVALUE.fields_by_name[\'shape\'].message_type = _TENSORSHAPE\n_ATTRVALUE.fields_by_name[\'tensor\'].message_type = _LITERALTENSOR\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'list\'])\n_ATTRVALUE.fields_by_name[\'list\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'s\'])\n_ATTRVALUE.fields_by_name[\'s\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'i\'])\n_ATTRVALUE.fields_by_name[\'i\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'f\'])\n_ATTRVALUE.fields_by_name[\'f\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'b\'])\n_ATTRVALUE.fields_by_name[\'b\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'type\'])\n_ATTRVALUE.fields_by_name[\'type\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'shape\'])\n_ATTRVALUE.fields_by_name[\'shape\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_ATTRVALUE.oneofs_by_name[\'value\'].fields.append(\n  _ATTRVALUE.fields_by_name[\'tensor\'])\n_ATTRVALUE.fields_by_name[\'tensor\'].containing_oneof = _ATTRVALUE.oneofs_by_name[\'value\']\n_TENSORSHAPE_DIM.containing_type = _TENSORSHAPE\n_TENSORSHAPE.fields_by_name[\'dim\'].message_type = _TENSORSHAPE_DIM\n_LITERALTENSOR.fields_by_name[\'dtype\'].enum_type = _DATATYPE\n_LITERALTENSOR.fields_by_name[\'tensor_shape\'].message_type = _TENSORSHAPE\nDESCRIPTOR.message_types_by_name[\'GraphDef\'] = _GRAPHDEF\nDESCRIPTOR.message_types_by_name[\'NodeDef\'] = _NODEDEF\nDESCRIPTOR.message_types_by_name[\'AttrValue\'] = _ATTRVALUE\nDESCRIPTOR.message_types_by_name[\'TensorShape\'] = _TENSORSHAPE\nDESCRIPTOR.message_types_by_name[\'LiteralTensor\'] = _LITERALTENSOR\nDESCRIPTOR.enum_types_by_name[\'DataType\'] = _DATATYPE\n_sym_db.RegisterFileDescriptor(DESCRIPTOR)\n\nGraphDef = _reflection.GeneratedProtocolMessageType(\'GraphDef\', (_message.Message,), dict(\n  DESCRIPTOR = _GRAPHDEF,\n  __module__ = \'graph_pb2\'\n  # @@protoc_insertion_point(class_scope:GraphDef)\n  ))\n_sym_db.RegisterMessage(GraphDef)\n\nNodeDef = _reflection.GeneratedProtocolMessageType(\'NodeDef\', (_message.Message,), dict(\n\n  AttrEntry = _reflection.GeneratedProtocolMessageType(\'AttrEntry\', (_message.Message,), dict(\n    DESCRIPTOR = _NODEDEF_ATTRENTRY,\n    __module__ = \'graph_pb2\'\n    # @@protoc_insertion_point(class_scope:NodeDef.AttrEntry)\n    ))\n  ,\n  DESCRIPTOR = _NODEDEF,\n  __module__ = \'graph_pb2\'\n  # @@protoc_insertion_point(class_scope:NodeDef)\n  ))\n_sym_db.RegisterMessage(NodeDef)\n_sym_db.RegisterMessage(NodeDef.AttrEntry)\n\nAttrValue = _reflection.GeneratedProtocolMessageType(\'AttrValue\', (_message.Message,), dict(\n\n  ListValue = _reflection.GeneratedProtocolMessageType(\'ListValue\', (_message.Message,), dict(\n    DESCRIPTOR = _ATTRVALUE_LISTVALUE,\n    __module__ = \'graph_pb2\'\n    # @@protoc_insertion_point(class_scope:AttrValue.ListValue)\n    ))\n  ,\n  DESCRIPTOR = _ATTRVALUE,\n  __module__ = \'graph_pb2\'\n  # @@protoc_insertion_point(class_scope:AttrValue)\n  ))\n_sym_db.RegisterMessage(AttrValue)\n_sym_db.RegisterMessage(AttrValue.ListValue)\n\nTensorShape = _reflection.GeneratedProtocolMessageType(\'TensorShape\', (_message.Message,), dict(\n\n  Dim = _reflection.GeneratedProtocolMessageType(\'Dim\', (_message.Message,), dict(\n    DESCRIPTOR = _TENSORSHAPE_DIM,\n    __module__ = \'graph_pb2\'\n    # @@protoc_insertion_point(class_scope:TensorShape.Dim)\n    ))\n  ,\n  DESCRIPTOR = _TENSORSHAPE,\n  __module__ = \'graph_pb2\'\n  # @@protoc_insertion_point(class_scope:TensorShape)\n  ))\n_sym_db.RegisterMessage(TensorShape)\n_sym_db.RegisterMessage(TensorShape.Dim)\n\nLiteralTensor = _reflection.GeneratedProtocolMessageType(\'LiteralTensor\', (_message.Message,), dict(\n  DESCRIPTOR = _LITERALTENSOR,\n  __module__ = \'graph_pb2\'\n  # @@protoc_insertion_point(class_scope:LiteralTensor)\n  ))\n_sym_db.RegisterMessage(LiteralTensor)\n\n\n_NODEDEF_ATTRENTRY.has_options = True\n_NODEDEF_ATTRENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b(\'8\\001\'))\n_ATTRVALUE_LISTVALUE.fields_by_name[\'i\'].has_options = True\n_ATTRVALUE_LISTVALUE.fields_by_name[\'i\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_ATTRVALUE_LISTVALUE.fields_by_name[\'f\'].has_options = True\n_ATTRVALUE_LISTVALUE.fields_by_name[\'f\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_ATTRVALUE_LISTVALUE.fields_by_name[\'b\'].has_options = True\n_ATTRVALUE_LISTVALUE.fields_by_name[\'b\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_ATTRVALUE_LISTVALUE.fields_by_name[\'type\'].has_options = True\n_ATTRVALUE_LISTVALUE.fields_by_name[\'type\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_LITERALTENSOR.fields_by_name[\'int_val\'].has_options = True\n_LITERALTENSOR.fields_by_name[\'int_val\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_LITERALTENSOR.fields_by_name[\'uint_val\'].has_options = True\n_LITERALTENSOR.fields_by_name[\'uint_val\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_LITERALTENSOR.fields_by_name[\'int64_val\'].has_options = True\n_LITERALTENSOR.fields_by_name[\'int64_val\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_LITERALTENSOR.fields_by_name[\'uint64_val\'].has_options = True\n_LITERALTENSOR.fields_by_name[\'uint64_val\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_LITERALTENSOR.fields_by_name[\'float_val\'].has_options = True\n_LITERALTENSOR.fields_by_name[\'float_val\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_LITERALTENSOR.fields_by_name[\'double_val\'].has_options = True\n_LITERALTENSOR.fields_by_name[\'double_val\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n_LITERALTENSOR.fields_by_name[\'bool_val\'].has_options = True\n_LITERALTENSOR.fields_by_name[\'bool_val\']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b(\'\\020\\001\'))\n# @@protoc_insertion_point(module_scope)\n'"
mmdnn/conversion/examples/caffe/__init__.py,0,b''
mmdnn/conversion/examples/caffe/extract_model.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport os\nfrom six import text_type as _text_type\nfrom mmdnn.conversion.common.utils import download_file\n\nBASE_MODEL_URL = \'http://data.mxnet.io/models/imagenet/test/caffe/\'\n# pylint: disable=line-too-long\nDEFAULT_MODEL_INFO = {\n    \'alexnet\'       : {\'prototxt\'   : \'https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_alexnet/deploy.prototxt\',\n                       \'caffemodel\' : \'http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel\'},\n    \'inception_v1\'  : {\'prototxt\'   : \'https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_googlenet/deploy.prototxt\',\n                       \'caffemodel\' : \'http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel\'},\n    \'vgg16\'         : {\'prototxt\'   : \'https://gist.githubusercontent.com/ksimonyan/211839e770f7b538e2d8/raw/c3ba00e272d9f48594acef1f67e5fd12aff7a806/VGG_ILSVRC_16_layers_deploy.prototxt\',\n                       \'caffemodel\' : \'http://data.mxnet.io/models/imagenet/test/caffe/VGG_ILSVRC_16_layers.caffemodel\'},\n    \'vgg19\'         : {\'prototxt\'   : \'https://gist.githubusercontent.com/ksimonyan/3785162f95cd2d5fee77/raw/bb2b4fe0a9bb0669211cf3d0bc949dfdda173e9e/VGG_ILSVRC_19_layers_deploy.prototxt\',\n                       \'caffemodel\' : \'http://data.mxnet.io/models/imagenet/test/caffe/VGG_ILSVRC_19_layers.caffemodel\'},\n    \'resnet50\'      : {\'prototxt\'   : BASE_MODEL_URL + \'ResNet-50-deploy.prototxt\',\n                       \'caffemodel\' : BASE_MODEL_URL + \'ResNet-50-model.caffemodel\'},\n    \'resnet101\'     : {\'prototxt\'   : BASE_MODEL_URL + \'ResNet-101-deploy.prototxt\',\n                       \'caffemodel\' : BASE_MODEL_URL + \'ResNet-101-model.caffemodel\'},\n    \'resnet152\'     : {\'prototxt\'   : BASE_MODEL_URL + \'ResNet-152-deploy.prototxt\',\n                       \'caffemodel\' : BASE_MODEL_URL + \'ResNet-152-model.caffemodel\'},\n    \'squeezenet\'    : {\'prototxt\' : ""https://raw.githubusercontent.com/DeepScale/SqueezeNet/master/SqueezeNet_v1.1/deploy.prototxt"",\n                       \'caffemodel\' : ""https://github.com/DeepScale/SqueezeNet/raw/master/SqueezeNet_v1.1/squeezenet_v1.1.caffemodel""}\n}\n# pylint: enable=line-too-long\n\n\ndef _main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'-n\', \'--network\', type=_text_type, help=\'Model Type\', required=True,\n                        choices=DEFAULT_MODEL_INFO.keys())\n\n    parser.add_argument(\'-i\', \'--image\', default=None,\n                        type=_text_type, help=\'Test Image Path\')\n\n    parser.add_argument(\'-o\', \'--output_dir\', default=\'./\',\n                        type=_text_type, help=\'Caffe Checkpoint file name\')\n\n    args = parser.parse_args()\n\n    arch_fn = download_file(DEFAULT_MODEL_INFO[args.network][\'prototxt\'], directory=args.output_dir)\n    if not arch_fn:\n        return -1\n\n    weight_fn = download_file(DEFAULT_MODEL_INFO[args.network][\'caffemodel\'], directory=args.output_dir)\n    if not weight_fn:\n        return -1\n\n    print(""Model {} saved."".format(args.network))\n\n    if args.image:\n        import caffe\n        import numpy as np\n        from mmdnn.conversion.examples.imagenet_test import TestKit\n\n        net = caffe.Net(arch_fn.encode(""utf-8""), weight_fn.encode(""utf-8""), caffe.TEST)\n        # net = caffe.Net(arch_fn, weight_fn, caffe.TEST)\n        func = TestKit.preprocess_func[\'caffe\'][args.network]\n        img = func(args.image)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, 0)\n        net.blobs[\'data\'].data[...] = img\n        predict = np.squeeze(net.forward()[\'prob\'][0])\n        predict = np.squeeze(predict)\n        top_indices = predict.argsort()[-5:][::-1]\n        result = [(i, predict[i]) for i in top_indices]\n        print(result)\n        print(np.sum(result))\n\n    return 0\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/examples/caffe/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nimport os\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\n\n\nclass caffe_extractor(base_extractor):\n\n    BASE_MODEL_URL = \'http://data.mxnet.io/models/imagenet/test/caffe/\'\n    MMDNN_BASE_URL = \'http://mmdnn.eastasia.cloudapp.azure.com:89/models/\'\n\n    architecture_map = {\n## Image Classification\n        \'alexnet\'       : {\'prototxt\'   : \'https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_alexnet/deploy.prototxt\',\n                        \'caffemodel\' : \'http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel\'},\n        \'inception_v1\'  : {\'prototxt\'   : \'https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_googlenet/deploy.prototxt\',\n                        \'caffemodel\' : \'http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel\'},\n        \'vgg16\'         : {\'prototxt\'   : \'https://gist.githubusercontent.com/ksimonyan/211839e770f7b538e2d8/raw/c3ba00e272d9f48594acef1f67e5fd12aff7a806/VGG_ILSVRC_16_layers_deploy.prototxt\',\n                        \'caffemodel\' : \'http://data.mxnet.io/models/imagenet/test/caffe/VGG_ILSVRC_16_layers.caffemodel\'},\n        \'vgg19\'         : {\'prototxt\'   : \'https://gist.githubusercontent.com/ksimonyan/3785162f95cd2d5fee77/raw/bb2b4fe0a9bb0669211cf3d0bc949dfdda173e9e/VGG_ILSVRC_19_layers_deploy.prototxt\',\n                        \'caffemodel\' : \'http://data.mxnet.io/models/imagenet/test/caffe/VGG_ILSVRC_19_layers.caffemodel\'},\n        \'resnet50\'      : {\'prototxt\'   : BASE_MODEL_URL + \'ResNet-50-deploy.prototxt\',\n                        \'caffemodel\' : BASE_MODEL_URL + \'ResNet-50-model.caffemodel\'},\n        \'resnet101\'     : {\'prototxt\'   : BASE_MODEL_URL + \'ResNet-101-deploy.prototxt\',\n                        \'caffemodel\' : BASE_MODEL_URL + \'ResNet-101-model.caffemodel\'},\n        \'resnet152\'     : {\'prototxt\'   : BASE_MODEL_URL + \'ResNet-152-deploy.prototxt\',\n                        \'caffemodel\' : BASE_MODEL_URL + \'ResNet-152-model.caffemodel\'},\n        \'squeezenet\'    : {\'prototxt\' : ""https://raw.githubusercontent.com/DeepScale/SqueezeNet/master/SqueezeNet_v1.1/deploy.prototxt"",\n                           \'caffemodel\' : ""https://github.com/DeepScale/SqueezeNet/raw/master/SqueezeNet_v1.1/squeezenet_v1.1.caffemodel""},\n        \'xception\'      : {\'prototxt\' : MMDNN_BASE_URL + ""caffe/xception_deploy.prototxt"",\n                           \'caffemodel\' : MMDNN_BASE_URL + ""caffe/xception.caffemodel""},\n        \'inception_v4\'  : {\'prototxt\' : MMDNN_BASE_URL + \'caffe/inception-v4_deploy.prototxt\',\n                           \'caffemodel\' : MMDNN_BASE_URL + \'caffe/inception-v4.caffemodel\'},\n## Semantic Segmentation\n        \'voc-fcn8s\'     : {\'prototxt\' : \'https://raw.githubusercontent.com/shelhamer/fcn.berkeleyvision.org/master/voc-fcn8s/deploy.prototxt\',\n                           \'caffemodel\' : \'http://dl.caffe.berkeleyvision.org/fcn8s-heavy-pascal.caffemodel\'},\n        \'voc-fcn16s\'    : {\'prototxt\' : \'https://raw.githubusercontent.com/linmajia/mmdnn-models/master/caffe/voc-fcn16s-deploy.prototxt\',\n                           \'caffemodel\' : \'http://dl.caffe.berkeleyvision.org/fcn16s-heavy-pascal.caffemodel\'},\n        \'voc-fcn32s\'    : {\'prototxt\' : \'https://raw.githubusercontent.com/linmajia/mmdnn-models/master/caffe/voc-fcn32s-deploy.prototxt\',\n                           \'caffemodel\' : \'http://dl.caffe.berkeleyvision.org/fcn32s-heavy-pascal.caffemodel\'},\n        \'trailnet_sresnet\': {\'prototxt\': \'https://raw.githubusercontent.com/NVIDIA-AI-IOT/redtail/master/models/pretrained/TrailNet_SResNet-18.prototxt\',\n                            \'caffemodel\': \'https://raw.githubusercontent.com/NVIDIA-AI-IOT/redtail/master/models/pretrained/TrailNet_SResNet-18.caffemodel\'}\n    }\n\n\n    @classmethod\n    def download(cls, architecture, path=""./""):\n        if cls.sanity_check(architecture):\n            prototxt_name = architecture + ""-deploy.prototxt""\n            architecture_file = download_file(cls.architecture_map[architecture][\'prototxt\'], directory=path, local_fname=prototxt_name)\n            if not architecture_file:\n                return None\n\n            weight_name = architecture + "".caffemodel""\n            weight_file = download_file(cls.architecture_map[architecture][\'caffemodel\'], directory=path, local_fname=weight_name)\n            if not weight_file:\n                return None\n\n\n            print(""Caffe Model {} saved as [{}] and [{}]."".format(architecture, architecture_file, weight_file))\n            return (architecture_file, weight_file)\n\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture_name, architecture, path, image_path):\n        if cls.sanity_check(architecture_name):\n            import caffe\n            import numpy as np\n            net = caffe.Net(architecture[0], architecture[1], caffe.TEST)\n\n            func = TestKit.preprocess_func[\'caffe\'][architecture_name]\n            img = func(image_path)\n            img = np.transpose(img, (2, 0, 1))\n            img = np.expand_dims(img, 0)\n            net.blobs[\'data\'].data[...] = img\n            predict = np.squeeze(net.forward()[net._output_list[-1]][0])\n            predict = np.squeeze(predict)\n            return predict\n\n        else:\n            return None\n'"
mmdnn/conversion/examples/caffe/imagenet_test.py,0,"b""#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport numpy as np\nimport sys\nimport os\nfrom six import text_type as _text_type\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nimport caffe\n\n\nclass TestCaffe(TestKit):\n\n    def __init__(self):\n        super(TestCaffe, self).__init__()\n\n        self.truth['caffe']['alexnet'] = [(657, 0.41121054), (744, 0.20789708), (847, 0.086725503), (821, 0.05908291), (595, 0.058017164)]\n\n        if self.args.dump:\n            self.dump_net = self.args.dump + '.prototxt'\n            self.dump_weight = self.args.dump + '.caffemodel'\n        else:\n            self.dump_net = 'tmp.prototxt'\n            self.dump_weight = 'tmp.caffemodel'\n\n        self.MainModel.make_net(self.dump_net)\n        self.MainModel.gen_weight(self.args.w, self.dump_weight, self.dump_net)\n        self.model = caffe.Net(self.dump_net, self.dump_weight, caffe.TEST)\n\n    def preprocess(self, image_path):\n        x = super(TestCaffe, self).preprocess(image_path)\n        # caffe uses NCHW\n        x = np.transpose(x, [2, 0, 1])\n        self.data = np.expand_dims(x, 0)\n\n\n    def print_result(self):\n        self.model.blobs['input'].data[...] = self.data\n        predict = self.model.forward()[self.model._layer_names[-1]][0]\n        super(TestCaffe, self).print_result(predict)\n\n\n    def print_intermediate_result(self, layer_name, if_transpose = False):\n        intermediate_output = self.model.blobs[layer_name].data[0]\n        super(TestCaffe, self).print_intermediate_result(intermediate_output, if_transpose)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n\n        self.print_result()\n\n        # self.print_intermediate_result('pooling0', False)\n\n        self.test_truth()\n\n        # delete tmp model files\n        if os.path.isfile(self.dump_net):\n            os.remove(self.dump_net)\n        if os.path.isfile(self.dump_weight):\n            os.remove(self.dump_weight)\n\n\n    def dump(self):\n        print ('Caffe model files are saved as [{}] and [{}], generated by [{}.py] and [{}].'.format(\n            self.dump_net, self.dump_weight, self.args.n, self.args.w))\n\n\nif __name__=='__main__':\n    tester = TestCaffe()\n    if tester.args.dump:\n        tester.dump()\n    else:\n        tester.inference(tester.args.image)\n"""
mmdnn/conversion/examples/cntk/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/cntk/extract_model.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport os\nfrom six import text_type as _text_type\nimport cntk as C\nfrom mmdnn.conversion.common.utils import download_file\n\nBASE_MODEL_URL = \'https://www.cntk.ai/Models/CNTK_Pretrained/\'\n# pylint: disable=line-too-long\nMODEL_URL = {\n    \'alexnet\'              : BASE_MODEL_URL + \'AlexNet_ImageNet_CNTK.model\',\n    \'inception_v3\'         : BASE_MODEL_URL + \'InceptionV3_ImageNet_CNTK.model\',\n    \'resnet18\'             : BASE_MODEL_URL + \'ResNet18_ImageNet_CNTK.model\',\n    \'resnet50\'             : BASE_MODEL_URL + \'ResNet50_ImageNet_CNTK.model\',\n    \'resnet101\'            : BASE_MODEL_URL + \'ResNet101_ImageNet_CNTK.model\',\n    \'resnet152\'            : BASE_MODEL_URL + \'ResNet152_ImageNet_CNTK.model\',\n    \'Fast-RCNN_grocery100\' : \'https://www.cntk.ai/Models/FRCN_Grocery/Fast-RCNN_grocery100.model\',\n    \'Fast-RCNN_Pascal\'     : \'https://www.cntk.ai/Models/FRCN_Pascal/Fast-RCNN.model\'\n}\n# pylint: enable=line-too-long\n\n\ndef _main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'-n\', \'--network\', type=_text_type, help=\'Model Type\', required=True,\n                        choices=MODEL_URL.keys())\n\n    parser.add_argument(\'-i\', \'--image\', default=None,\n                        type=_text_type, help=\'Test Image Path\')\n\n    parser.add_argument(\'-o\', \'--output_dir\', default=\'./\',\n                        type=_text_type, help=\'CNTK Checkpoint file name\')\n\n    args = parser.parse_args()\n\n    fn = download_file(MODEL_URL[args.network], directory=args.output_dir)\n    if not fn:\n        return -1\n\n    model = C.Function.load(fn)\n\n    if len(model.outputs) > 1:\n        for idx, output in enumerate(model.outputs):\n            if len(output.shape) > 0:\n                eval_node = idx\n                break\n\n        model = C.as_composite(model[eval_node].owner)\n        model.save(fn)\n\n        print(""Model {} is saved as {}."".format(args.network, fn))\n\n    if args.image:\n        import numpy as np\n        from mmdnn.conversion.examples.imagenet_test import TestKit\n        func = TestKit.preprocess_func[\'cntk\'][args.network]\n        img = func(args.image)\n        img = np.transpose(img, (2, 0, 1))\n        predict = model.eval({model.arguments[0]:[img]})\n        predict = np.squeeze(predict)\n        top_indices = predict.argsort()[-5:][::-1]\n        result = [(i, predict[i]) for i in top_indices]\n        print(result)\n        print(np.sum(result))\n\n    return 0\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/examples/cntk/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nimport cntk as C\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\n\n\nclass cntk_extractor(base_extractor):\n\n    BASE_MODEL_URL = \'https://www.cntk.ai/Models/CNTK_Pretrained/\'\n\n    architecture_map = {\n        \'alexnet\'              : BASE_MODEL_URL + \'AlexNet_ImageNet_CNTK.model\',\n        \'inception_v3\'         : BASE_MODEL_URL + \'InceptionV3_ImageNet_CNTK.model\',\n        \'resnet18\'             : BASE_MODEL_URL + \'ResNet18_ImageNet_CNTK.model\',\n        \'resnet50\'             : BASE_MODEL_URL + \'ResNet50_ImageNet_CNTK.model\',\n        \'resnet101\'            : BASE_MODEL_URL + \'ResNet101_ImageNet_CNTK.model\',\n        \'resnet152\'            : BASE_MODEL_URL + \'ResNet152_ImageNet_CNTK.model\',\n        \'Fast-RCNN_grocery100\' : \'https://www.cntk.ai/Models/FRCN_Grocery/Fast-RCNN_grocery100.model\',\n        \'Fast-RCNN_Pascal\'     : \'https://www.cntk.ai/Models/FRCN_Pascal/Fast-RCNN.model\'\n    }\n\n\n    @classmethod\n    def download(cls, architecture, path=""./""):\n        if cls.sanity_check(architecture):\n            architecture_file = download_file(cls.architecture_map[architecture], directory=path)\n            model = C.Function.load(architecture_file)\n            if len(model.outputs) > 1:\n                for idx, output in enumerate(model.outputs):\n                    if len(output.shape) > 0:\n                        eval_node = idx\n                        break\n\n                model = C.as_composite(model[eval_node].owner)\n                model.save(architecture_file)\n                print(""Cntk Model {} saved as [{}]."".format(architecture, architecture_file))\n            return architecture_file\n\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture_name, architecture_path, image_path):\n        if cls.sanity_check(architecture_name):\n            import numpy as np\n            func = TestKit.preprocess_func[\'cntk\'][architecture_name]\n            img = func(image_path)\n            img = np.transpose(img, (2, 0, 1))\n            model = C.Function.load(architecture_path)\n            predict = model.eval({model.arguments[0]:[img]})\n            predict = np.squeeze(predict)\n\n            top_indices = predict.argsort()[-5:][::-1]\n            return predict\n\n        else:\n            return None\n'"
mmdnn/conversion/examples/cntk/imagenet_test.py,0,"b'# Copyright (c) Microsoft. All rights reserved.\n\n# Licensed under the MIT license. See LICENSE.md file in the project root\n# for full license information.\n# ==============================================================================\n\nimport argparse\nimport numpy as np\nimport sys\nimport os\nimport cntk as C\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\n\nclass TestCNTK(TestKit):\n\n    def __init__(self):\n        super(TestCNTK, self).__init__()\n\n        self.truth[\'mxnet\'][\'inception_bn\'] = [(21, 0.84820729), (144, 0.06263639), (677, 0.015408826), (973, 0.014532777), (562, 0.0053690737)]\n\n        self.truth[\'keras\'][\'resnet\'] = [(144, 0.77398175), (23, 0.10650793), (21, 0.081077583), (146, 0.0092755388), (562, 0.0089645367)]\n        self.truth[\'tensorflow\'][\'resnet\'] = [(22, 13.370872), (147, 8.8040094), (24, 5.6983061), (90, 5.6143088), (95, 4.8060427)]\n\n        self.model = self.MainModel.KitModel(self.args.w)\n        # self.model, self.testop = self.MainModel.KitModel(self.args.w)\n\n\n    def preprocess(self, image_path):\n        self.data = super(TestCNTK, self).preprocess(image_path)\n\n\n    def print_result(self):\n        predict = self.model.eval({self.model.arguments[0]:[self.data]})\n        super(TestCNTK, self).print_result(predict)\n\n\n    def print_intermediate_result(self, layer_name, if_transpose = False):\n        test_arr = self.testop.eval({self.testop.arguments[0]:[self.data]})\n        super(TestCNTK, self).print_intermediate_result(test_arr, if_transpose)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n\n        # self.print_intermediate_result(None, False)\n\n        self.print_result()\n\n        self.test_truth()\n\n    def dump(self, path = None):\n        if path is None: path = self.args.dump\n        self.model.save(path)\n        print (\'CNTK model file is saved as [{}], generated by [{}.py] and [{}].\'.format(\n            path, self.args.n, self.args.w))\n\n    def detect(self, image_path, path = None):\n        self.preprocess(image_path)\n        print(""Found {} outputs"".format(len(self.model)))\n        for output in self.model:\n            predict = output.eval({output.arguments[0]:[self.data/255.]})\n            predict.dump(""finalconv_{}.npy"".format(str(predict.shape[1])))\n            print (\'The output of CNTK model file is saved as [finalconv_{}.npy].\'.format(\n            str(predict.shape[1])))\n\n        print(\'generated by [{}.py], [{}] and [{}].\'.format(self.args.n, self.args.w, image_path))\n\nif __name__==\'__main__\':\n    tester = TestCNTK()\n    if tester.args.dump:\n        tester.dump()\n    elif tester.args.detect:\n        tester.detect(tester.args.image, tester.args.detect)\n    else:\n        tester.inference(tester.args.image)\n'"
mmdnn/conversion/examples/coreml/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/coreml/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nimport os\nimport coremltools\nfrom coremltools.models import MLModel\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\n\n\nclass coreml_extractor(base_extractor):\n\n    _base_model_url = ""https://docs-assets.developer.apple.com/coreml/models/""\n\n    # from collections import namedtuple\n    # Batch = namedtuple(\'Batch\', [\'data\'])\n\n    # TODO\n    # Apple has published some of their own models. They can be downloaded from https://developer.apple.com/machine-learning/.\n    # Those published models are: SqueezeNet, Places205-GoogLeNet, ResNet50, Inception v3, VGG16\n    architecture_map = {\n        \'inception_v3\'      : ""https://docs-assets.developer.apple.com/coreml/models/Inceptionv3.mlmodel"",\n        \'vgg16\'             : ""https://docs-assets.developer.apple.com/coreml/models/VGG16.mlmodel"",\n        \'vgg19\'             : None,\n        \'resnet50\'            : ""https://docs-assets.developer.apple.com/coreml/models/Resnet50.mlmodel"",  # resnet50\n        \'mobilenet\'         : ""https://docs-assets.developer.apple.com/coreml/models/MobileNet.mlmodel"",\n        \'xception\'          : None,\n        \'inception_resnet\'  : None,\n        \'densenet\'          : None,\n        \'nasnet\'            : None,\n        \'tinyyolo\'          : ""https://s3-us-west-2.amazonaws.com/coreml-models/TinyYOLO.mlmodel""\n\n    }\n\n\n\n    @classmethod\n    def download(cls, architecture, path = \'./\'):\n        if cls.sanity_check(architecture):\n            architecture_file = download_file(cls.architecture_map[architecture], directory = path)\n            if not architecture_file:\n                return None\n\n\n            print(\'Coreml model {} is saved in [{}]\'.format(architecture, path))\n            return architecture_file\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture, model_path, image_path):\n        # TODO\n        from PIL import Image\n        import numpy as np\n        from coremltools.models._infer_shapes_nn_mlmodel import infer_shapes\n        if cls.sanity_check(architecture):\n            func = TestKit.preprocess_func[\'coreml\'][architecture]\n\n\n            import inspect\n            funcstr = inspect.getsource(func)\n\n            if len(funcstr.split(\',\')) == 3:\n                size = int(funcstr.split(\'path,\')[1].split(\')\')[0])\n            else:\n                size = int(funcstr.split(\'path,\')[1].split(\',\')[0])\n\n\n\n            img = Image.open(image_path)\n            img = img.resize((size, size))\n\n            # load model\n            model = MLModel(model_path)\n            spec = model.get_spec()\n\n            # TODO: Multiple inputs\n            input_name = spec.description.input[0].name\n\n            # TODO: Multiple outputs\n            output_name = spec.description.output[0].name\n\n            # inference\n            input_data = img\n            coreml_input = {input_name: img}\n            coreml_output = model.predict(coreml_input)\n\n\n            prob = coreml_output[output_name]\n            if isinstance(prob, dict):\n                prob = list(coreml_output[output_name].values())\n            prob = np.array(prob).squeeze()\n\n            return prob\n\n        else:\n            return None\n\n\n\n'"
mmdnn/conversion/examples/coreml/imagenet_test.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport numpy as np\nimport sys\nimport os\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nimport coremltools\n\nclass TestCoreML(TestKit):\n\n    def __init__(self):\n        from six import text_type as _text_type\n        parser = argparse.ArgumentParser()\n\n        parser.add_argument(\'-p\', \'--preprocess\', type=_text_type, help=\'Model Preprocess Type\')\n\n        parser.add_argument(\'--model\', \'-n\', \'-w\', type=_text_type,\n                            required=True, help=\'CoreML Model path.\')\n\n        parser.add_argument(\'-s\', type=_text_type, help=\'Source Framework Type\',\n                            choices=self.truth.keys())\n\n        parser.add_argument(\'--image\', \'-i\',\n                            type=_text_type, help=\'Test image path.\',\n                            default=""mmdnn/conversion/examples/data/seagull.jpg"")\n\n        parser.add_argument(\'-input\', type=_text_type,\n                            required=True, help=\'CoreML Input Node\')\n\n        parser.add_argument(\'-output\', type=_text_type,\n                            required=True, help=\'CoreML Output Node\')\n\n        parser.add_argument(\'-size\', type=int,\n            default=224, help=\'CoreML Input Image Size\')\n\n\n        self.args = parser.parse_args()\n\n        print(""Loading model [{}]."".format(self.args.model))\n\n        self.model = coremltools.models.MLModel(self.args.model.encode())\n\n        print(""Model loading success."")\n\n    def preprocess(self, image_path):\n        from PIL import Image as pil_image\n        img = pil_image.open(image_path)\n        img = img.resize((self.args.size, self.args.size))\n        self.data = img\n\n    def print_result(self):\n        coreml_inputs = {self.args.input: self.data}\n        self.coreml_output = self.model.predict(coreml_inputs, useCPUOnly=False)\n        predict = self.coreml_output[self.args.output]\n        super(TestCoreML, self).print_result(predict)\n\n\n    def print_intermediate_result(self, layer_name, if_transpose = False):\n        super(TestCoreML, self).print_intermediate_result(self.coreml_output[layer_name], if_transpose)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n\n        self.print_result()\n\n        # self.print_intermediate_result(\'conv1_7x7_s2_1\', True)\n\n        # self.test_truth()\n\nif __name__==\'__main__\':\n    tester = TestCoreML()\n    tester.inference(tester.args.image)\n'"
mmdnn/conversion/examples/coreml/test_tfcoreml.py,0,"b'import unittest\nimport urllib\nimport os\nimport tarfile\nimport zipfile\nimport numpy as np\nimport PIL.Image\nimport tensorflow as tf\nfrom tensorflow.core.framework import graph_pb2\nimport tfcoreml as tf_converter\n\nTMP_MODEL_DIR = \'/Users/kit/tmp/tfcoreml\'\nTEST_IMAGE = \'/Users/kit/github/MMdnn/mmdnn/conversion/examples/data/seagull.jpg\'\n\ndef _download_file(url):\n  """"""Download the file.\n  url - The URL address of the frozen file\n  fname - Filename of the frozen TF graph in the url.\n  """"""\n  dir_path = TMP_MODEL_DIR\n  if not os.path.exists(dir_path):\n      os.makedirs(dir_path)\n\n  k = url.rfind(\'/\')\n  fname = url[k+1:]\n  fpath = os.path.join(dir_path, fname)\n\n  ftype = None\n  if url.endswith("".tar.gz"") or url.endswith("".tgz""):\n    ftype = \'tgz\'\n  elif url.endswith(\'.zip\'):\n    ftype = \'zip\'\n\n  if not os.path.exists(fpath):\n    urllib.urlretrieve(url, fpath)\n  if ftype == \'tgz\':\n    tar = tarfile.open(fpath)\n    tar.extractall(dir_path)\n    tar.close()\n  elif ftype == \'zip\':\n    zip_ref = zipfile.ZipFile(fpath, \'r\')\n    zip_ref.extractall(dir_path)\n    zip_ref.close()\n\ndef _compute_max_relative_error(x,y):\n  rerror = 0\n  index = 0\n  for i in range(len(x)):\n    den = max(1.0, np.abs(x[i]), np.abs(y[i]))\n    if np.abs(x[i]/den - y[i]/den) > rerror:\n      rerror = np.abs(x[i]/den - y[i]/den)\n      index = i\n  return rerror, index\n\ndef _compute_SNR(x,y):\n  noise = x - y\n  noise_var = np.sum(noise ** 2)/len(noise) + 1e-7\n  signal_energy = np.sum(y ** 2)/len(y)\n  max_signal_energy = np.amax(y ** 2)\n  SNR = 10 * np.log10(signal_energy/noise_var)\n  PSNR = 10 * np.log10(max_signal_energy/noise_var)\n  return SNR, PSNR\n\ndef _load_image(path, resize_to=None):\n  img = PIL.Image.open(path)\n  if resize_to is not None:\n    img = img.resize(resize_to, PIL.Image.ANTIALIAS)\n  img_np = np.array(img).astype(np.float32)\n  return img_np, img\n\ndef _generate_data(input_shape, mode = \'random\',\n                   scale = 2.0/255, bias = -1,\n                   img_size = 256):\n  """"""\n  Generate some random data according to a shape.\n  """"""\n  if input_shape is None or len(input_shape) == 0:\n    return 0.5\n  if mode == \'zeros\':\n    X = np.zeros(input_shape)\n  elif mode == \'ones\':\n    X = np.ones(input_shape)\n  elif mode == \'linear\':\n    X = np.array(range(np.product(input_shape))).reshape(input_shape)*1.0\n  elif mode == \'random\':\n    X = np.random.rand(*input_shape)\n  elif mode == \'random_zero_mean\':\n    X = np.random.rand(*input_shape)-0.5\n  elif mode == \'image\':\n    # Load a real image and do default tf imageNet preprocessing\n    img_np, _ = _load_image(TEST_IMAGE ,resize_to=(img_size, img_size))\n    img_tf = np.expand_dims(img_np, axis = 0)\n    X = img_tf * scale + bias\n  elif mode == \'onehot_0\':\n    X = np.zeros(input_shape)\n    X[0] = 1\n  return X\n\ndef _tf_transpose(x, is_sequence=False):\n  if not hasattr(x, ""shape""):\n    return x\n  if len(x.shape) == 4:\n    # [Batch, Height, Width, Channels] --> [Batch, Channels, Height, Width]\n    x = np.transpose(x, [0,3,1,2])\n    return np.expand_dims(x, axis=0)\n  elif len(x.shape) == 3:\n    # We only deal with non-recurrent networks for now\n    # (H,W,C) --> (C,H,W)\n    return np.transpose(x, [2,0,1])\n  elif len(x.shape) == 2:\n    if is_sequence:  # (N,S) --> (S,N,1,)\n      return x.reshape(x.shape[::-1] + (1,))\n    else:  # (N,C) --> (N,C,1,1)\n      return x.reshape((1, ) + x.shape) # Dense\n  elif len(x.shape) == 1:\n    if is_sequence: # (S) --> (S,N,1,1,1)\n      return x.reshape((x.shape[0], 1, 1, 1, 1))\n    else:\n      return x\n  else:\n    return x\n\nclass CorrectnessTest(unittest.TestCase):\n\n  @classmethod\n  def setUpClass(self):\n    """""" Set up the unit test by loading common utilities.\n    """"""\n    self.err_thresh = 0.15\n    self.snr_thresh = 12\n    self.psnr_thresh = 30\n    self.red_bias = -1\n    self.blue_bias = -1\n    self.green_bias = -1\n    self.image_scale = 2.0/255\n\n  def _compare_tf_coreml_outputs(self, tf_out, coreml_out):\n    self.assertEquals(len(tf_out), len(coreml_out))\n    error, ind = _compute_max_relative_error(coreml_out, tf_out)\n    SNR, PSNR = _compute_SNR(coreml_out, tf_out)\n    self.assertGreater(SNR, self.snr_thresh)\n    self.assertGreater(PSNR, self.psnr_thresh)\n    self.assertLess(error, self.err_thresh)\n\n\n  def _test_tf_model(self, tf_model_path, coreml_model, input_tensors,\n      output_tensor_names, data_modes = \'random\', delta = 1e-2,\n      use_cpu_only = False, scale = 2.0/255, bias = -1,\n      img_size = None, sequence_inputs = None):\n    """""" Common entry to testing routine (Tensors in, tensors out).\n    tf_model_path - frozen TF model path\n    coreml_model - MLModel object\n    input_tensors -  list of (name,shape) for each input (placeholder)\n    output_tensor_names - output_tensor_names, a list of strings\n    sequence_inputs - dict of input names that are sequences for CoreML input\n    """"""\n    # Load TensorFlow model\n    tf.reset_default_graph()\n    graph_def = graph_pb2.GraphDef()\n    with open(tf_model_path, ""rb"") as f:\n        graph_def.ParseFromString(f.read())\n    g = tf.import_graph_def(graph_def)\n\n    if type(data_modes) is str:\n      data_modes = [data_modes] * len(input_tensors)\n\n    with tf.Session(graph = g) as sess:\n      # Prepare inputs\n      feed_dict = {}\n      for idx, in_tensor in enumerate(input_tensors):\n        ts_name, ts_shape = in_tensor\n        ts_name = \'import/\' + ts_name\n        feed_dict[ts_name] = _generate_data(ts_shape,\n                                  mode = data_modes[idx],\n                                  scale = scale, bias = bias,\n                                  img_size = img_size)\n      # Run TF session\n      out_tf_names = []\n      for out_name in output_tensor_names:\n        out_tf_names.append(\'import/\' + out_name)\n      result = sess.run(out_tf_names, feed_dict=feed_dict)\n\n    # Evaluate coreml model\n    coreml_inputs = {}\n    for idx, in_tensor in enumerate(input_tensors):\n      in_tensor_name, in_shape = in_tensor\n      coreml_in_name = in_tensor_name.replace(\':\', \'__\').replace(\'/\', \'__\')\n      if in_tensor_name in sequence_inputs:\n        coreml_inputs[coreml_in_name] = _tf_transpose(\n            feed_dict[\'import/\'+in_tensor_name], is_sequence=True).copy()\n      else:\n        coreml_inputs[coreml_in_name] = _tf_transpose(\n          feed_dict[\'import/\'+in_tensor_name]).copy()\n\n    coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=use_cpu_only)\n\n    for idx, out_name in enumerate(output_tensor_names):\n      out_tensor_name = out_name.replace(\':\', \'__\').replace(\'/\', \'__\')\n      tp = _tf_transpose(result[idx]).flatten()\n      cp = coreml_output[out_tensor_name].flatten()\n      error, index = _compute_max_relative_error(tp, cp)\n      snr, psnr = _compute_SNR(tp, cp)\n      self._compare_tf_coreml_outputs(tp, cp)\n\n\n  def _test_coreml_model_image_input(self, tf_model_path, coreml_model,\n      input_tensor_name, output_tensor_name, img_size, useCPUOnly = False):\n    """"""Test single image input conversions.\n    tf_model_path - the TF model\n    coreml_model - converted CoreML model\n    input_tensor_name - the input image tensor name\n    output_tensor_name - the output tensor name\n    img_size - size of the image\n    """"""\n\n    img_np, img = _load_image(TEST_IMAGE ,resize_to=(img_size, img_size))\n    img_tf = np.expand_dims(img_np, axis = 0)\n    img_tf[:,:,:,0] = self.image_scale * img_tf[:,:,:,0] + self.red_bias\n    img_tf[:,:,:,1] = self.image_scale * img_tf[:,:,:,1] + self.green_bias\n    img_tf[:,:,:,2] = self.image_scale * img_tf[:,:,:,2] + self.blue_bias\n\n    #evaluate the TF model\n    tf.reset_default_graph()\n    graph_def = graph_pb2.GraphDef()\n    with open(tf_model_path, ""rb"") as f:\n        graph_def.ParseFromString(f.read())\n    g = tf.import_graph_def(graph_def)\n    with tf.Session(graph=g) as sess:\n      image_input_tensor = sess.graph.get_tensor_by_name(\'import/\' + input_tensor_name)\n      output = sess.graph.get_tensor_by_name(\'import/\' + output_tensor_name)\n      tf_out = sess.run(output,feed_dict={image_input_tensor: img_tf})\n    if len(tf_out.shape) == 4:\n      tf_out = np.transpose(tf_out, (0,3,1,2))\n    tf_out_flatten = tf_out.flatten()\n\n    #evaluate CoreML\n    coreml_input_name = input_tensor_name.replace(\':\', \'__\').replace(\'/\', \'__\')\n    coreml_output_name = output_tensor_name.replace(\':\', \'__\').replace(\'/\', \'__\')\n    coreml_input = {coreml_input_name: img}\n\n    #Test the default CoreML evaluation\n    coreml_out = coreml_model.predict(coreml_input, useCPUOnly = useCPUOnly)[coreml_output_name]\n    coreml_out_flatten = coreml_out.flatten()\n    self._compare_tf_coreml_outputs(tf_out_flatten, coreml_out_flatten)\n\nclass TestModels(CorrectnessTest):\n\n  def test_inception_v3_slim(self):\n    #Download model\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'inception_v3_2016_08_28_frozen.pb\')\n\n    #Convert to coreml\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'inception_v3_2016_08_28.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'InceptionV3/Predictions/Softmax:0\'],\n        input_name_shape_dict = {\'input:0\':[1,299,299,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'InceptionV3/Predictions/Softmax:0\',\n        img_size = 299)\n\n  def test_googlenet_v1_nonslim(self):\n    #Download model\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'tensorflow_inception_graph.pb\')\n\n    #Convert to coreml\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'googlenet_v1_nonslim.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'softmax2:0\'],\n        input_name_shape_dict = {\'input:0\':[1,224,224,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'softmax2:0\',\n        img_size = 224)\n\n  def test_googlenet_resnet_v2(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/inception_resnet_v2_2016_08_30_frozen.pb.tar.gz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'inception_resnet_v2_2016_08_30_frozen.pb\')\n\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'inception_resnet_v2_2016_08_30_frozen.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'InceptionResnetV2/Logits/Predictions:0\'],\n        input_name_shape_dict = {\'input:0\':[1,299,299,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'InceptionResnetV2/Logits/Predictions:0\',\n        img_size = 299)\n\n  def test_googlenet_v1_slim(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'inception_v1_2016_08_28_frozen.pb\')\n\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'inception_v1_2016_08_28_frozen.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'InceptionV1/Logits/Predictions/Softmax:0\'],\n        input_name_shape_dict = {\'input:0\':[1,244,224,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'InceptionV1/Logits/Predictions/Softmax:0\',\n        img_size = 224)\n\n  def test_googlenet_v2_slim(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/inception_v2_2016_08_28_frozen.pb.tar.gz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'inception_v2_2016_08_28_frozen.pb\')\n\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'inception_v2_2016_08_28_frozen.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'InceptionV2/Predictions/Softmax:0\'],\n        input_name_shape_dict = {\'input:0\':[1,244,224,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'InceptionV2/Predictions/Softmax:0\',\n        img_size = 224)\n\n  def test_googlenet_v4_slim(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/inception_v4_2016_09_09_frozen.pb.tar.gz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'inception_v4_2016_09_09_frozen.pb\')\n\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'inception_v4_2016_09_09_frozen.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'InceptionV4/Logits/Predictions:0\'],\n        input_name_shape_dict = {\'input:0\':[1,299,299,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'InceptionV4/Logits/Predictions:0\',\n        img_size = 299)\n\n\n  def test_mobilenet_v1_100_224(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'mobilenet_v1_1.0_224/frozen_graph.pb\')\n\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'mobilenet_v1_1.0_224.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'MobilenetV1/Predictions/Softmax:0\'],\n        input_name_shape_dict = {\'input:0\':[1,224,224,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'MobilenetV1/Predictions/Softmax:0\',\n        img_size = 224)\n\n  def test_mobilenet_v2_100_224(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'mobilenet_v1_1.0_224/frozen_graph.pb\')\n\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'mobilenet_v1_1.0_224.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'MobilenetV1/Predictions/Softmax:0\'],\n        input_name_shape_dict = {\'input:0\':[1,224,224,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'MobilenetV1/Predictions/Softmax:0\',\n        img_size = 224)\n\n\n  def test_mobilenet_v1_75_192(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.75_192_frozen.tgz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'mobilenet_v1_0.75_192/frozen_graph.pb\')\n\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'mobilenet_v1_0.75_192.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'MobilenetV1/Predictions/Softmax:0\'],\n        input_name_shape_dict = {\'input:0\':[1,192,192,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'MobilenetV1/Predictions/Softmax:0\',\n        img_size = 192)\n\n  def test_mobilenet_v1_50_160(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_0.50_160_frozen.tgz\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'mobilenet_v1_0.50_160/frozen_graph.pb\')\n\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'mobilenet_v1_0.50_160.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'MobilenetV1/Predictions/Softmax:0\'],\n        input_name_shape_dict = {\'input:0\':[1,160,160,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    self._test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'MobilenetV1/Predictions/Softmax:0\',\n        img_size = 160)\n\n  #@unittest.skip(""Failing GPU backend: related to https://github.com/tf-coreml/tf-coreml/issues/26"")\n  def test_style_transfer(self):\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/stylize_v1.zip\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'stylize_quantized.pb\')\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'stylize_quantized.mlmodel\')\n    # ? style transfer image size and style number?\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'Squeeze:0\'],\n        input_name_shape_dict = {\'input:0\':[1,256,256,3], \'style_num:0\':[26]})\n\n    # Test predictions on an image\n    input_tensors = [(\'input:0\',[1,256,256,3]),\n                     (\'style_num:0\',[26])]\n\n    self.err_thresh = 0.5\n    self._test_tf_model(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensors = input_tensors,\n        output_tensor_names = [\'Squeeze:0\'],\n        data_modes = [\'image\', \'onehot_0\'],\n        delta = 1e-2,\n        use_cpu_only = True,\n        scale = 1,\n        bias = 0,\n        img_size = 256,\n        sequence_inputs = {\'style_num:0\'})\n\ndef _test_coreml_model_image_input(tf_model_path, coreml_model,\n      input_tensor_name, output_tensor_name, img_size, useCPUOnly = False):\n    """"""Test single image input conversions.\n    tf_model_path - the TF model\n    coreml_model - converted CoreML model\n    input_tensor_name - the input image tensor name\n    output_tensor_name - the output tensor name\n    img_size - size of the image\n    """"""\n\n    img_np, img = _load_image(TEST_IMAGE ,resize_to=(img_size, img_size))\n    img_tf = np.expand_dims(img_np, axis = 0)\n    img_tf[:,:,:,0] = 2.0/255 * img_tf[:,:,:,0] - 1\n    img_tf[:,:,:,1] = 2.0/255 * img_tf[:,:,:,1] - 1\n    img_tf[:,:,:,2] = 2.0/255 * img_tf[:,:,:,2] - 1\n\n    #evaluate the TF model\n    tf.reset_default_graph()\n    graph_def = graph_pb2.GraphDef()\n    with open(tf_model_path, ""rb"") as f:\n        graph_def.ParseFromString(f.read())\n    g = tf.import_graph_def(graph_def)\n    with tf.Session(graph=g) as sess:\n      image_input_tensor = sess.graph.get_tensor_by_name(\'import/\' + input_tensor_name)\n      output = sess.graph.get_tensor_by_name(\'import/\' + output_tensor_name)\n      tf_out = sess.run(output,feed_dict={image_input_tensor: img_tf})\n    if len(tf_out.shape) == 4:\n      tf_out = np.transpose(tf_out, (0,3,1,2))\n    tf_out_flatten = tf_out.flatten()\n\n    #evaluate CoreML\n    coreml_input_name = input_tensor_name.replace(\':\', \'__\').replace(\'/\', \'__\')\n    coreml_output_name = output_tensor_name.replace(\':\', \'__\').replace(\'/\', \'__\')\n    coreml_input = {coreml_input_name: img}\n\n    #Test the default CoreML evaluation\n    coreml_out = coreml_model.predict(coreml_input, useCPUOnly = useCPUOnly)[coreml_output_name]\n    coreml_out_flatten = coreml_out.flatten()\n    print (coreml_out_flatten)\n    # compare_tf_coreml_outputs(tf_out_flatten, coreml_out_flatten)\n\n\n\n\n\nif __name__==\'__main__\':\n    # #Download model\n    # url = \'https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\'\n    # tf_model_dir = _download_file(url = url)\n    # tf_model_path = os.path.join(TMP_MODEL_DIR, \'inception_v3_2016_08_28_frozen.pb\')\n\n    # #Convert to coreml\n    # mlmodel_path = os.path.join(TMP_MODEL_DIR, \'inception_v3_2016_08_28.mlmodel\')\n    # mlmodel = tf_converter.convert(\n    #     tf_model_path = tf_model_path,\n    #     mlmodel_path = mlmodel_path,\n    #     output_feature_names = [\'InceptionV3/Predictions/Softmax:0\'],\n    #     input_name_shape_dict = {\'input:0\':[1,299,299,3]},\n    #     image_input_names = [\'input:0\'],\n    #     red_bias = -1,\n    #     green_bias = -1,\n    #     blue_bias = -1,\n    #     image_scale = 2.0/255.0)\n\n    # #Test predictions on an image\n    # _test_coreml_model_image_input(\n    #     tf_model_path = tf_model_path,\n    #     coreml_model = mlmodel,\n    #     input_tensor_name = \'input:0\',\n    #     output_tensor_name = \'InceptionV3/Predictions/Softmax:0\',\n    #     img_size = 299)\n\n    #Download model\n    url = \'https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\'\n    tf_model_dir = _download_file(url = url)\n    tf_model_path = os.path.join(TMP_MODEL_DIR, \'tensorflow_inception_graph.pb\')\n\n    #Convert to coreml\n    mlmodel_path = os.path.join(TMP_MODEL_DIR, \'googlenet_v1_nonslim.mlmodel\')\n    mlmodel = tf_converter.convert(\n        tf_model_path = tf_model_path,\n        mlmodel_path = mlmodel_path,\n        output_feature_names = [\'softmax2:0\'],\n        input_name_shape_dict = {\'input:0\':[1,224,224,3]},\n        image_input_names = [\'input:0\'],\n        red_bias = -1,\n        green_bias = -1,\n        blue_bias = -1,\n        image_scale = 2.0/255.0)\n\n    #Test predictions on an image\n    _test_coreml_model_image_input(\n        tf_model_path = tf_model_path,\n        coreml_model = mlmodel,\n        input_tensor_name = \'input:0\',\n        output_tensor_name = \'softmax2:0\',\n        img_size = 224)\n\n\n    print(""convert ok!"")\n'"
mmdnn/conversion/examples/darknet/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/darknet/darknet.py,0,"b'from ctypes import *\nimport math\nimport random\n\ndef sample(probs):\n    s = sum(probs)\n    probs = [a/s for a in probs]\n    r = random.uniform(0, 1)\n    for i in range(len(probs)):\n        r = r - probs[i]\n        if r <= 0:\n            return i\n    return len(probs)-1\n\ndef c_array(ctype, values):\n    arr = (ctype*len(values))()\n    arr[:] = values\n    return arr\n\nclass BOX(Structure):\n    _fields_ = [(""x"", c_float),\n                (""y"", c_float),\n                (""w"", c_float),\n                (""h"", c_float)]\n\nclass DETECTION(Structure):\n    _fields_ = [(""bbox"", BOX),\n                (""classes"", c_int),\n                (""prob"", POINTER(c_float)),\n                (""mask"", POINTER(c_float)),\n                (""objectness"", c_float),\n                (""sort_class"", c_int)]\n\n\nclass IMAGE(Structure):\n    _fields_ = [(""w"", c_int),\n                (""h"", c_int),\n                (""c"", c_int),\n                (""data"", POINTER(c_float))]\n\nclass METADATA(Structure):\n    _fields_ = [(""classes"", c_int),\n                (""names"", POINTER(c_char_p))]\n\n\n\nlib = CDLL(""./mmdnn/conversion/examples/darknet/libdarknet.so"", RTLD_GLOBAL)\nlib.network_width.argtypes = [c_void_p]\nlib.network_width.restype = c_int\nlib.network_height.argtypes = [c_void_p]\nlib.network_height.restype = c_int\n\npredict = lib.network_predict\npredict.argtypes = [c_void_p, POINTER(c_float)]\npredict.restype = POINTER(c_float)\n\nset_gpu = lib.cuda_set_device\nset_gpu.argtypes = [c_int]\n\nmake_image = lib.make_image\nmake_image.argtypes = [c_int, c_int, c_int]\nmake_image.restype = IMAGE\n\nget_network_boxes = lib.get_network_boxes\nget_network_boxes.argtypes = [c_void_p, c_int, c_int, c_float, c_float, POINTER(c_int), c_int, POINTER(c_int)]\nget_network_boxes.restype = POINTER(DETECTION)\n\nmake_network_boxes = lib.make_network_boxes\nmake_network_boxes.argtypes = [c_void_p]\nmake_network_boxes.restype = POINTER(DETECTION)\n\nfree_detections = lib.free_detections\nfree_detections.argtypes = [POINTER(DETECTION), c_int]\n\nfree_ptrs = lib.free_ptrs\nfree_ptrs.argtypes = [POINTER(c_void_p), c_int]\n\nnetwork_predict = lib.network_predict\nnetwork_predict.argtypes = [c_void_p, POINTER(c_float)]\n\nreset_rnn = lib.reset_rnn\nreset_rnn.argtypes = [c_void_p]\n\nload_net = lib.load_network\nload_net.argtypes = [c_char_p, c_char_p, c_int]\nload_net.restype = c_void_p\n\ndo_nms_obj = lib.do_nms_obj\ndo_nms_obj.argtypes = [POINTER(DETECTION), c_int, c_int, c_float]\n\ndo_nms_sort = lib.do_nms_sort\ndo_nms_sort.argtypes = [POINTER(DETECTION), c_int, c_int, c_float]\n\nfree_image = lib.free_image\nfree_image.argtypes = [IMAGE]\n\nletterbox_image = lib.letterbox_image\nletterbox_image.argtypes = [IMAGE, c_int, c_int]\nletterbox_image.restype = IMAGE\n\nload_meta = lib.get_metadata\nlib.get_metadata.argtypes = [c_char_p]\nlib.get_metadata.restype = METADATA\n\nload_image = lib.load_image_color\nload_image.argtypes = [c_char_p, c_int, c_int]\nload_image.restype = IMAGE\n\nrgbgr_image = lib.rgbgr_image\nrgbgr_image.argtypes = [IMAGE]\n\npredict_image = lib.network_predict_image\npredict_image.argtypes = [c_void_p, IMAGE]\npredict_image.restype = POINTER(c_float)\n\ndef classify(net, meta, im):\n    out = predict_image(net, im)\n    res = []\n    r = []\n    for i in range(meta.classes):\n        # print(i)\n        r.append(out[i])\n        res.append((meta.names[i], out[i]))\n    res = sorted(res, key=lambda x: -x[1])\n    return res, r\n\ndef detect(net, meta, image, thresh=.5, hier_thresh=.5, nms=.45):\n    im = load_image(image, 0, 0)\n    num = c_int(0)\n    pnum = pointer(num)\n    predict_image(net, im)\n    dets = get_network_boxes(net, im.w, im.h, thresh, hier_thresh, None, 0, pnum)\n    num = pnum[0]\n    if (nms): do_nms_obj(dets, num, meta.classes, nms)\n\n    res = []\n    for j in range(num):\n        for i in range(meta.classes):\n            if dets[j].prob[i] > 0:\n                b = dets[j].bbox\n                res.append((meta.names[i], dets[j].prob[i], (b.x, b.y, b.w, b.h)))\n    res = sorted(res, key=lambda x: -x[1])\n    free_image(im)\n    free_detections(dets, num)\n    return res\n\n\n'"
mmdnn/conversion/examples/darknet/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nimport os\nfrom mmdnn.conversion.examples.darknet import darknet as cdarknet\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\n\n\nclass darknet_extractor(base_extractor):\n\n    _base_model_url = ""https://raw.githubusercontent.com/pjreddie/darknet/master/""\n\n    architecture_map = {\n        \'yolov3\'          : {\n            \'config\'           : _base_model_url + ""cfg/yolov3.cfg"",\n            \'weights\'          : ""https://pjreddie.com/media/files/yolov3.weights""\n        },\n\n        \'yolov2\'          :{\n            \'config\'           : _base_model_url + ""cfg/yolov2.cfg"",\n            \'weights\'          : ""https://pjreddie.com/media/files/yolov2.weights""\n        }\n\n    }\n\n\n    @classmethod\n    def download(cls, architecture, path = \'./\'):\n\n        if cls.sanity_check(architecture):\n            cfg_name = architecture + "".cfg""\n            architecture_file = download_file(cls.architecture_map[architecture][\'config\'], directory=path, local_fname=cfg_name)\n            if not architecture_file:\n                return None\n\n            weight_name = architecture + "".weights""\n            weight_file = download_file(cls.architecture_map[architecture][\'weights\'], directory=path, local_fname=weight_name)\n            if not weight_file:\n                return None\n\n            print(""Darknet Model {} saved as [{}] and [{}]."".format(architecture, architecture_file, weight_file))\n            return (architecture_file, weight_file)\n\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture, files, model_path, image_path):\n        import numpy as np\n\n        if cls.sanity_check(architecture):\n            download_file(cls._base_model_url + ""cfg/coco.data"", directory=\'./\')\n            download_file(cls._base_model_url + ""data/coco.names"", directory=\'./data/\')\n\n            print(files)\n            net = cdarknet.load_net(files[0].encode(), files[1].encode(), 0)\n            meta = cdarknet.load_meta(""coco.data"".encode())\n\n\n            r = cdarknet.detect(net, meta, image_path.encode())\n            # print(r)\n            return r\n\n        else:\n            return None\n\n\n\n# d = darknet_extractor()\n# model_filename = d.download(\'yolov3\')\n# print(model_filename)\n\n# image_path = ""./mmdnn/conversion/examples/data/dog.jpg""\n# model_path = ""./""\n# d = darknet_extractor()\n# result = d.inference(\'yolov3\', model_filename, model_path, image_path = image_path)\n# print(result)\n'"
mmdnn/conversion/examples/keras/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/keras/extract_model.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nfrom six import text_type as _text_type\nimport keras\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\n\nnetworks_map = {\n    \'inception_v3\'      : lambda : keras.applications.inception_v3.InceptionV3(input_shape=(299, 299, 3)),\n    \'vgg16\'             : lambda : keras.applications.vgg16.VGG16(),\n    \'vgg19\'             : lambda : keras.applications.vgg19.VGG19(),\n    \'resnet\'            : lambda : keras.applications.resnet50.ResNet50(),\n    \'mobilenet\'         : lambda : keras.applications.mobilenet.MobileNet(),\n    \'xception\'          : lambda : keras.applications.xception.Xception(input_shape=(299, 299, 3)),\n    \'inception_resnet\'  : lambda : keras.applications.inception_resnet_v2.InceptionResNetV2()\n}\n\nimage_size = {\n    \'inception_v3\'      : 299,\n    \'vgg16\'             : 224,\n    \'vgg19\'             : 224,\n    \'resnet\'            : 224,\n    \'mobilenet\'         : 224,\n    \'xception\'          : 299,\n    \'inception_resnet\'  : 299\n}\n\ndef _main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'-n\', \'--network\',\n                        type=_text_type, help=\'Model Type\', required=True,\n                        choices=networks_map.keys())\n\n    parser.add_argument(\'-i\', \'--image\',\n                        type=_text_type, help=\'Test Image Path\')\n\n    args = parser.parse_args()\n\n    model = networks_map.get(args.network)\n    if model is None:\n        raise NotImplementedError(""Unknown keras application [{}]"".format(args.network))\n\n    model = model()\n    # save network structure as JSON\n    json_string = model.to_json()\n    with open(""imagenet_{}.json"".format(args.network), ""w"") as of:\n        of.write(json_string)\n\n    print(""Network structure is saved as [imagenet_{}.json]."".format(args.network))\n\n    model.save_weights(\'imagenet_{}.h5\'.format(args.network))\n\n    print(""Network weights are saved as [imagenet_{}.h5]."".format(args.network))\n\n    if args.image:\n        import numpy as np\n        func = TestKit.preprocess_func[\'keras\'][args.network]\n        img = func(args.image)\n        img = np.expand_dims(img, axis=0)\n        predict = model.predict(img)\n        predict = np.squeeze(predict)\n        top_indices = predict.argsort()[-5:][::-1]\n        result = [(i, predict[i]) for i in top_indices]\n        print(result)\n\n        # layer_name = \'block2_pool\'\n        # intermediate_layer_model = keras.Model(inputs=model.input,\n        #                                  outputs=model.get_layer(layer_name).output)\n        # intermediate_output = intermediate_layer_model.predict(img)\n        # print (intermediate_output)\n        # print (intermediate_output.shape)\n        # print (""%.30f"" % np.sum(intermediate_output))\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/examples/keras/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nimport os\nimport keras\nfrom keras import backend as K\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\n\n\nclass keras_extractor(base_extractor):\n\n    MMDNN_BASE_URL = \'http://mmdnn.eastasia.cloudapp.azure.com:89/models/\'\n\n    architecture_map = {\n        \'inception_v3\'        : lambda : keras.applications.inception_v3.InceptionV3(input_shape=(299, 299, 3)),\n        \'vgg16\'               : lambda : keras.applications.vgg16.VGG16(),\n        \'vgg19\'               : lambda : keras.applications.vgg19.VGG19(),\n        \'resnet50\'            : lambda : keras.applications.resnet50.ResNet50(),\n        \'mobilenet\'           : lambda : keras.applications.mobilenet.MobileNet(),\n        \'xception\'            : lambda : keras.applications.xception.Xception(input_shape=(299, 299, 3)),\n        \'inception_resnet_v2\' : lambda : keras.applications.inception_resnet_v2.InceptionResNetV2(input_shape=(299, 299, 3)),\n        \'densenet\'            : lambda : keras.applications.densenet.DenseNet201(),\n        \'nasnet\'              : lambda : keras.applications.nasnet.NASNetLarge(),\n    }\n\n    thirdparty_map = {\n        \'yolo2\'    : MMDNN_BASE_URL + \'keras/yolo2.h5\',\n    }\n\n    image_size = {\n        \'inception_v3\'      : 299,\n        \'vgg16\'             : 224,\n        \'vgg19\'             : 224,\n        \'resnet\'            : 224,\n        \'mobilenet\'         : 224,\n        \'xception\'          : 299,\n        \'inception_resnet\'  : 299,\n        \'densenet\'          : 224,\n        \'nasnet\'            : 331,\n    }\n\n    @classmethod\n    def help(cls):\n        print (\'Support frameworks: {}\'.format(set().union(cls.architecture_map.keys(), cls.thirdparty_map.keys())))\n\n\n    @classmethod\n    def download(cls, architecture, path=""./""):\n        if architecture in cls.thirdparty_map:\n            weight_file = download_file(cls.thirdparty_map[architecture], directory=path)\n            return weight_file\n\n        elif cls.sanity_check(architecture):\n            output_filename = path + \'imagenet_{}.h5\'.format(architecture)\n            if os.path.exists(output_filename) == False:\n                model = cls.architecture_map[architecture]()\n                model.save(output_filename)\n                print(""Keras model {} is saved in [{}]"".format(architecture, output_filename))\n                K.clear_session()\n                del model\n                return output_filename\n\n            else:\n                print(""File [{}] existed, skip download."".format(output_filename))\n                return output_filename\n\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture, files, path, image_path):\n        if architecture in cls.thirdparty_map:\n            model = keras.models.load_model(files)\n\n        elif cls.sanity_check(architecture):\n            model = cls.architecture_map[architecture]()\n\n        else:\n            model = None\n\n        if model:\n            import numpy as np\n            func = TestKit.preprocess_func[\'keras\'][architecture]\n            img = func(image_path)\n            img = np.expand_dims(img, axis=0)\n            predict = model.predict(img)\n            predict = np.squeeze(predict)\n            K.clear_session()\n            del model\n            return predict\n\n        else:\n            return None\n'"
mmdnn/conversion/examples/keras/imagenet_test.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport numpy as np\nimport sys\nimport os\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\n\nimport colorsys\nfrom keras import backend as K\nfrom PIL import Image, ImageFont, ImageDraw\nfrom mmdnn.conversion.examples.keras.utils import yolo_eval\n\n\nclass TestKeras(TestKit):\n\n    def __init__(self):\n\n        # self.anchors = np.array([[10,13], [16,30],[33,23],[30,61],[62,45], [59,119],[116,90],[156,198],[373,326]])\n        self.class_names = [\'person\', \'bicycle\', \'car\', \'motorbike\', \'aeroplane\', \'bus\', \'train\', \'truck\', \'boat\',\n        \'traffic light\', \'fire hydrant\', \'stop sign\', \'parking meter\', \'bench\', \'bird\', \'cat\', \'dog\', \'horse\', \'sheep\', \'cow\',\n        \'elephant\', \'bear\', \'zebra\', \'giraffe\', \'backpack\', \'umbrella\', \'handbag\', \'tie\', \'suitcase\', \'frisbee\', \'skis\', \'snowboard\',\n        \'sports ball\', \'kite\', \'baseball bat\', \'baseball glove\', \'skateboard\', \'surfboard\', \'tennis racket\', \'bottle\', \'wine glass\', \'cup\',\n        \'fork\', \'knife\', \'spoon\', \'bowl\', \'banana\', \'apple\', \'sandwich\', \'orange\', \'broccoli\', \'carrot\', \'hot dog\', \'pizza\', \'donut\',\n        \'cake\', \'chair\', \'sofa\', \'pottedplant\', \'bed\', \'diningtable\', \'toilet\', \'tvmonitor\', \'laptop\', \'mouse\', \'remote\', \'keyboard\',\n        \'cell phone\', \'microwave\', \'oven\', \'toaster\', \'sink\', \'refrigerator\', \'book\', \'clock\', \'vase\', \'scissors\', \'teddy bear\', \'hair drier\', \'toothbrush\']\n        super(TestKeras, self).__init__()\n        self.model = self.MainModel.KitModel(self.args.w)\n\n\n    def preprocess(self, image_path):\n        x = super(TestKeras, self).preprocess(image_path)\n        self.data = np.expand_dims(x, 0)\n\n    def print_result(self):\n        predict = self.model.predict(self.data)\n        super(TestKeras, self).print_result(predict)\n\n    def generate(self):\n        self.input_image_shape = K.placeholder(shape=(2, ))\n        output = self.model.output\n        output.sort(key=lambda x: int(x.shape[1]))\n        # print(output)\n\n        boxes, scores, classes = yolo_eval(output, self.anchors,\n                    len(self.class_names), self.input_image_shape,\n                    score_threshold=self.score_threshold, iou_threshold=self.iou_threshold)\n        return boxes, scores, classes\n\n    def yolo_result(self, path):\n        image = Image.fromarray(np.uint8(np.squeeze(self.data)))\n\n        self.sess = K.get_session()\n        self.boxes, self.scores, self.classes = self.generate()\n        out_boxes, out_scores, out_classes = self.sess.run(\n            [self.boxes, self.scores, self.classes],\n            feed_dict={\n                self.model.input: self.data/255.,\n                self.input_image_shape: [608, 608],\n                K.learning_phase(): 0\n            })\n        # print(out_boxes, out_scores, out_classes)\n        print(\'Found {} boxes for {}\'.format(len(out_boxes), \'img\'))\n\n        thickness = (image.size[0] + image.size[1]) // 300\n\n        for i, c in reversed(list(enumerate(out_classes))):\n            predicted_class = self.class_names[c]\n            box = out_boxes[i]\n            score = out_scores[i]\n\n            label = \'{} {:.2f}\'.format(predicted_class, score)\n            draw = ImageDraw.Draw(image)\n            label_size = draw.textsize(label)\n\n            top, left, bottom, right = box\n            top = max(0, np.floor(top + 0.5).astype(\'int32\'))\n            left = max(0, np.floor(left + 0.5).astype(\'int32\'))\n            bottom = min(image.size[1], np.floor(bottom + 0.5).astype(\'int32\'))\n            right = min(image.size[0], np.floor(right + 0.5).astype(\'int32\'))\n            print(label, (left, top), (right, bottom))\n\n            if top - label_size[1] >= 0:\n                text_origin = np.array([left, top - label_size[1]])\n            else:\n                text_origin = np.array([left, top + 1])\n\n            # get random colors\n            self.colors = []\n            C = list(np.random.random_integers(255, size=(len(self.class_names),3)))\n            for i in C:\n                self.colors.append(tuple(i))\n\n            # My kingdom for a good redistributable image drawing library.\n            for i in range(thickness):\n                draw.rectangle(\n                    [left + i, top + i, right - i, bottom - i],\n                    outline=self.colors[c])\n            draw.rectangle(\n                [tuple(text_origin), tuple(text_origin + label_size)],\n                fill=self.colors[c])\n            draw.text(tuple(text_origin), label, fill=(0, 0, 0))\n            del draw\n        image.save(""{}.jpg"".format(path), ""JPEG"")\n\n\n    def print_intermediate_result(self, layer_name, if_transpose = False):\n        from keras.models import Model\n        intermediate_layer_model = Model(inputs = self.model.input,\n                                         outputs = self.model.get_layer(layer_name).output)\n        intermediate_output = intermediate_layer_model.predict(self.data)\n        super(TestKeras, self).print_intermediate_result(intermediate_output, if_transpose)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n\n        print(self.data.shape)\n        # self.print_intermediate_result(\'conv1_7x7_s2_1\', True)\n\n        self.print_result()\n\n        self.test_truth()\n\n    def dump(self, path = None):\n        if path is None: path = self.args.dump\n\n        self.model.save(path)\n        print (\'Keras model file is saved as [{}], generated by [{}.py] and [{}].\'.format(\n            path, self.args.n, self.args.w))\n\n    def detect(self, image_path, path = None):\n        self.yolo_parameter = self.MainModel.yolo_parameter()\n        # yolov3 80 classes\n        assert self.yolo_parameter[1] == 80\n        self.anchors = []\n        for i in range(len(self.yolo_parameter[0])):\n            if i%2:\n                tmp = [self.yolo_parameter[0][i-1], self.yolo_parameter[0][i]]\n                self.anchors.append(tmp)\n        self.anchors = np.array(self.anchors)\n        self.score_threshold = self.yolo_parameter[2]\n        self.iou_threshold = self.yolo_parameter[3]\n\n        self.preprocess(image_path)\n\n        self.yolo_result(path)\n\n        print (\'Keras yolo model result file is saved as [{}.jpg], generated by [{}.py] and [{}].\'.format(\n            path, self.args.n, self.args.w))\n\n\nif __name__==\'__main__\':\n    tester = TestKeras()\n    if tester.args.dump:\n        tester.dump()\n    elif tester.args.detect:\n        tester.detect(tester.args.image, tester.args.detect)\n    else:\n        tester.inference(tester.args.image)\n'"
mmdnn/conversion/examples/keras/utils.py,0,"b'import tensorflow as tf\nfrom keras import backend as K\nfrom PIL import Image\n\ndef letterbox_image(image, size):\n    \'\'\'resize image with unchanged aspect ratio using padding\'\'\'\n    image_w, image_h = image.size\n    w, h = size\n    new_w = int(image_w * min(w/image_w, h/image_h))\n    new_h = int(image_h * min(w/image_w, h/image_h))\n    resized_image = image.resize((new_w,new_h), Image.BICUBIC)\n\n    boxed_image = Image.new(\'RGB\', size, (128,128,128))\n    boxed_image.paste(resized_image, ((w-new_w)//2,(h-new_h)//2))\n    return boxed_image\n\ndef yolo_head(feats, anchors, num_classes, input_shape):\n    """"""Convert final layer features to bounding box parameters.""""""\n    num_anchors = len(anchors)\n    # Reshape to batch, height, width, num_anchors, box_params.\n    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n\n    conv_dims = K.shape(feats)[1:3]\n    conv_height_index = K.arange(0, stop=conv_dims[1])\n    conv_width_index = K.arange(0, stop=conv_dims[0])\n    conv_height_index = K.tile(conv_height_index, [conv_dims[0]])\n\n    conv_width_index = K.tile(\n        K.expand_dims(conv_width_index, 0), [conv_dims[1], 1])\n    conv_width_index = K.flatten(K.transpose(conv_width_index))\n    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n    conv_index = K.cast(conv_index, K.dtype(feats))\n\n    feats = K.reshape(\n        feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n    conv_dims = K.cast(conv_dims[::-1], K.dtype(feats))\n\n    box_xy = K.sigmoid(feats[..., :2])\n    box_wh = K.exp(feats[..., 2:4])\n    box_confidence = K.sigmoid(feats[..., 4:5])\n    box_class_probs = K.sigmoid(feats[..., 5:])\n\n    # Adjust preditions to each spatial grid point and anchor size.\n    # Note: YOLO iterates over height index before width index.\n    # TODO: It works with +1, don\'t know why.\n    box_xy = (box_xy + conv_index + 1) / conv_dims\n    box_wh = box_wh * anchors_tensor / K.cast(input_shape[::-1], K.dtype(box_wh))\n\n    return box_xy, box_wh, box_confidence, box_class_probs\n\n\ndef yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape):\n    \'\'\'Get corrected boxes\'\'\'\n    box_yx = box_xy[..., ::-1]\n    box_hw = box_wh[..., ::-1]\n    input_shape = K.cast(input_shape, K.dtype(box_yx))\n    image_shape = K.cast(image_shape, K.dtype(box_yx))\n    new_shape = K.round(image_shape * K.min(input_shape/image_shape))\n    offset = (input_shape-new_shape)/2./input_shape\n    scale = input_shape/new_shape\n    box_yx = (box_yx - offset) * scale\n    box_hw *= scale\n\n    box_mins = box_yx - (box_hw / 2.)\n    box_maxes = box_yx + (box_hw / 2.)\n    boxes =  K.concatenate([\n        box_mins[..., 0:1],  # y_min\n        box_mins[..., 1:2],  # x_min\n        box_maxes[..., 0:1],  # y_max\n        box_maxes[..., 1:2]  # x_max\n    ])\n\n    # Scale boxes back to original image shape.\n    boxes *= K.concatenate([image_shape, image_shape])\n    return boxes\n\ndef yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n    \'\'\'Process Conv layer output\'\'\'\n    # print(""feats,anchors, num_classes, input_shape"", feats, anchors, num_classes, input_shape)\n    box_xy, box_wh, box_confidence, box_class_probs = yolo_head(feats,\n        anchors, num_classes, input_shape)\n    # print(box_xy, box_wh, box_confidence, box_class_probs)\n    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)\n    boxes = K.reshape(boxes, [-1, 4])\n    box_scores = box_confidence * box_class_probs\n    box_scores = K.reshape(box_scores, [-1, num_classes])\n    return boxes, box_scores\n\n\ndef yolo_eval(yolo_outputs,\n        anchors,\n        num_classes,\n        image_shape,\n        max_boxes=20,\n        score_threshold=.6,\n        iou_threshold=.5):\n    """"""Evaluate YOLO model on given input and return filtered boxes.""""""\n    # yolo_outputs order 13,26,52\n\n    input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n\n    for i in range(0,3):\n        _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[i],\n            anchors[6-3*i:9-3*i], num_classes, input_shape, image_shape)\n        if i==0:\n            boxes, box_scores = _boxes, _box_scores\n        else:\n            boxes = K.concatenate([boxes,_boxes], axis=0)\n            box_scores = K.concatenate([box_scores,_box_scores], axis=0)\n\n    mask = box_scores >= score_threshold\n    max_boxes_tensor = K.constant(max_boxes, dtype=\'int32\')\n    for i in range(num_classes):\n        # TODO: use keras backend instead of tf.\n        class_boxes = tf.boolean_mask(boxes, mask[:, i])\n        class_box_scores = tf.boolean_mask(box_scores[:, i], mask[:, i])\n        nms_index = tf.image.non_max_suppression(\n            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)\n        class_boxes = K.gather(class_boxes, nms_index)\n        class_box_scores = K.gather(class_box_scores, nms_index)\n        classes = K.ones_like(class_box_scores, \'int32\') * i\n        if i==0:\n            boxes_, scores_, classes_ = class_boxes, class_box_scores, classes\n        else:\n            boxes_ = K.concatenate([boxes_,class_boxes], axis=0)\n            scores_ = K.concatenate([scores_,class_box_scores], axis=0)\n            classes_ = K.concatenate([classes_,classes], axis=0)\n    return boxes_, scores_, classes_'"
mmdnn/conversion/examples/mxnet/__init__.py,0,b''
mmdnn/conversion/examples/mxnet/extract_model.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nfrom six import text_type as _text_type\nimport mxnet as mx\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.common.utils import download_file\nfrom collections import namedtuple\nBatch = namedtuple(\'Batch\', [\'data\'])\n\nnetwork_name_key = [\'resnet\', \'vgg19\', \'squeezenet\', \'inception-bn\', \'resnext\']\n\n_base_model_url = \'http://data.mxnet.io/models/\'\n_default_model_info = {\n    \'imagenet1k-inception-bn\'           : {\'symbol\'     : _base_model_url+\'imagenet/inception-bn/Inception-BN-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/inception-bn/Inception-BN-0126.params\',\n                                           \'image_size\' : 224},\n    \'imagenet1k-resnet-18\'              : {\'symbol\'     : _base_model_url+\'imagenet/resnet/18-layers/resnet-18-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/resnet/18-layers/resnet-18-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet1k-resnet-34\'              : {\'symbol\'     : _base_model_url+\'imagenet/resnet/34-layers/resnet-34-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/resnet/34-layers/resnet-34-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet1k-resnet-50\'              : {\'symbol\'     : _base_model_url+\'imagenet/resnet/50-layers/resnet-50-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/resnet/50-layers/resnet-50-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet1k-resnet-101\'             : {\'symbol\'     : _base_model_url+\'imagenet/resnet/101-layers/resnet-101-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/resnet/101-layers/resnet-101-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet1k-resnet-152\'             : {\'symbol\'     : _base_model_url+\'imagenet/resnet/152-layers/resnet-152-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/resnet/152-layers/resnet-152-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet1k-resnext-50\'             : {\'symbol\'     : _base_model_url+\'imagenet/resnext/50-layers/resnext-50-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/resnext/50-layers/resnext-50-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet1k-resnext-101\'            : {\'symbol\'     : _base_model_url+\'imagenet/resnext/101-layers/resnext-101-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/resnext/101-layers/resnext-101-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet1k-resnext-101-64x4d\'      : {\'symbol\'     : _base_model_url+\'imagenet/resnext/101-layers/resnext-101-64x4d-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/resnext/101-layers/resnext-101-64x4d-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet11k-resnet-152\'            : {\'symbol\'     : _base_model_url+\'imagenet-11k/resnet-152/resnet-152-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet-11k/resnet-152/resnet-152-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet11k-place365ch-resnet-152\' : {\'symbol\'     : _base_model_url+\'imagenet-11k-place365-ch/resnet-152-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet-11k-place365-ch/resnet-152-0000.params\',\n                                           \'image_size\' : 224},\n    \'imagenet11k-place365ch-resnet-50\'  : {\'symbol\'     : _base_model_url+\'imagenet-11k-place365-ch/resnet-50-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet-11k-place365-ch/resnet-50-0000.params\',\n                                           \'image_size\' : 224},\n    \'vgg19\'                             : {\'symbol\'     : _base_model_url+\'imagenet/vgg/vgg19-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/vgg/vgg19-0000.params\',\n                                           \'image_size\' : 224},\n    \'vgg16\'                             : {\'symbol\'     : _base_model_url+\'imagenet/vgg/vgg16-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/vgg/vgg16-0000.params\',\n                                           \'image_size\' : 224},\n    \'squeezenet_v1.0\'                   : {\'symbol\'     : _base_model_url+\'imagenet/squeezenet/squeezenet_v1.0-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/squeezenet/squeezenet_v1.0-0000.params\',\n                                           \'image_size\' : 224},\n    \'squeezenet_v1.1\'                   : {\'symbol\'     : _base_model_url+\'imagenet/squeezenet/squeezenet_v1.1-symbol.json\',\n                                           \'params\'     : _base_model_url+\'imagenet/squeezenet/squeezenet_v1.1-0000.params\',\n                                           \'image_size\' : 224}\n}\n\n\ndef _search_preprocess_key(original_network_name):\n    import re\n    for key in network_name_key:\n        if re.search(key, original_network_name):\n            return key\n    raise ValueError(\'preprocess module cannot support [{}]\'.format(original_network_name))\n\n\ndef _main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'-n\', \'--network\', type=_text_type, help=\'Model Type\', required=True,\n                        choices=_default_model_info.keys())\n\n    parser.add_argument(\'-i\', \'--image\', default=None,\n                        type=_text_type, help=\'Test Image Path\')\n\n    parser.add_argument(\'-o\', \'--output_dir\', default=\'./\',\n                        type=_text_type, help=\'Tensorflow Checkpoint file name\')\n\n    args = parser.parse_args()\n\n    if not download_file(_default_model_info[args.network][\'symbol\'], directory=args.output_dir):\n        return -1\n\n    if not download_file(_default_model_info[args.network][\'params\'], directory=args.output_dir):\n        return -1\n\n    print(""Model {} saved."".format(args.network))\n\n    file_name = _default_model_info[args.network][\'params\'].split(\'/\')[-1]\n    prefix, epoch_num = file_name[:-7].rsplit(\'-\', 1)\n\n    sym, arg_params, aux_params = mx.model.load_checkpoint(args.output_dir + prefix, int(epoch_num))\n    model = mx.mod.Module(symbol=sym)\n    model.bind(for_training=False,\n               data_shapes=[(\'data\', (1, 3, _default_model_info[args.network][\'image_size\'],\n                                      _default_model_info[args.network][\'image_size\']))])\n    model.set_params(arg_params, aux_params, allow_missing=True, allow_extra=True)\n\n    if args.image:\n        import numpy as np\n\n        # need to be updated\n        network = _search_preprocess_key(args.network)\n\n        func = TestKit.preprocess_func[\'mxnet\'][network]\n        img = func(args.image)\n        img = np.swapaxes(img, 0, 2)\n        img = np.swapaxes(img, 1, 2)\n        img = np.expand_dims(img, axis=0)\n\n        model.forward(Batch([mx.nd.array(img)]))\n        predict = model.get_outputs()[0].asnumpy()\n        predict = np.squeeze(predict)\n        top_indices = predict.argsort()[-5:][::-1]\n        result = [(i, predict[i]) for i in top_indices]\n        print(result)\n\n    return 0\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/examples/mxnet/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\n\n\nclass mxnet_extractor(base_extractor):\n\n    _base_model_url = \'http://data.mxnet.io/models/\'\n\n    _image_size     = 224\n\n    from collections import namedtuple\n    Batch = namedtuple(\'Batch\', [\'data\'])\n\n    architecture_map = {\n        \'imagenet1k-inception-bn\' : {\'symbol\' : _base_model_url+\'imagenet/inception-bn/Inception-BN-symbol.json\',\n                                     \'params\' : _base_model_url+\'imagenet/inception-bn/Inception-BN-0126.params\'},\n        \'imagenet1k-resnet-18\' : {\'symbol\' : _base_model_url+\'imagenet/resnet/18-layers/resnet-18-symbol.json\',\n                                  \'params\' : _base_model_url+\'imagenet/resnet/18-layers/resnet-18-0000.params\'},\n        \'imagenet1k-resnet-34\' : {\'symbol\' : _base_model_url+\'imagenet/resnet/34-layers/resnet-34-symbol.json\',\n                                  \'params\' : _base_model_url+\'imagenet/resnet/34-layers/resnet-34-0000.params\'},\n        \'imagenet1k-resnet-50\' : {\'symbol\' : _base_model_url+\'imagenet/resnet/50-layers/resnet-50-symbol.json\',\n                                  \'params\' : _base_model_url+\'imagenet/resnet/50-layers/resnet-50-0000.params\'},\n        \'imagenet1k-resnet-101\' : {\'symbol\' : _base_model_url+\'imagenet/resnet/101-layers/resnet-101-symbol.json\',\n                                   \'params\' : _base_model_url+\'imagenet/resnet/101-layers/resnet-101-0000.params\'},\n        \'imagenet1k-resnet-152\' : {\'symbol\' : _base_model_url+\'imagenet/resnet/152-layers/resnet-152-symbol.json\',\n                                   \'params\' : _base_model_url+\'imagenet/resnet/152-layers/resnet-152-0000.params\'},\n        \'imagenet1k-resnext-50\' : {\'symbol\' : _base_model_url+\'imagenet/resnext/50-layers/resnext-50-symbol.json\',\n                                   \'params\' : _base_model_url+\'imagenet/resnext/50-layers/resnext-50-0000.params\'},\n        \'imagenet1k-resnext-101\' : {\'symbol\' : _base_model_url+\'imagenet/resnext/101-layers/resnext-101-symbol.json\',\n                                    \'params\' : _base_model_url+\'imagenet/resnext/101-layers/resnext-101-0000.params\'},\n        \'imagenet1k-resnext-101-64x4d\' : {\'symbol\' : _base_model_url+\'imagenet/resnext/101-layers/resnext-101-64x4d-symbol.json\',\n                                          \'params\' : _base_model_url+\'imagenet/resnext/101-layers/resnext-101-64x4d-0000.params\'},\n        \'imagenet11k-resnet-152\' : {\'symbol\' : _base_model_url+\'imagenet-11k/resnet-152/resnet-152-symbol.json\',\n                                    \'params\' : _base_model_url+\'imagenet-11k/resnet-152/resnet-152-0000.params\'},\n        \'imagenet11k-place365ch-resnet-152\' : {\'symbol\' : _base_model_url+\'imagenet-11k-place365-ch/resnet-152-symbol.json\',\n                                               \'params\' : _base_model_url+\'imagenet-11k-place365-ch/resnet-152-0000.params\'},\n        \'imagenet11k-place365ch-resnet-50\' : {\'symbol\' : _base_model_url+\'imagenet-11k-place365-ch/resnet-50-symbol.json\',\n                                              \'params\' : _base_model_url+\'imagenet-11k-place365-ch/resnet-50-0000.params\'},\n        \'vgg19\' : {\'symbol\' : _base_model_url+\'imagenet/vgg/vgg19-symbol.json\',\n                   \'params\' : _base_model_url+\'imagenet/vgg/vgg19-0000.params\'},\n        \'vgg16\' : {\'symbol\' : _base_model_url+\'imagenet/vgg/vgg16-symbol.json\',\n                   \'params\' : _base_model_url+\'imagenet/vgg/vgg16-0000.params\'},\n        \'squeezenet_v1.0\' : {\'symbol\' : _base_model_url+\'imagenet/squeezenet/squeezenet_v1.0-symbol.json\',\n                             \'params\' : _base_model_url+\'imagenet/squeezenet/squeezenet_v1.0-0000.params\'},\n        \'squeezenet_v1.1\' : {\'symbol\' : _base_model_url+\'imagenet/squeezenet/squeezenet_v1.1-symbol.json\',\n                             \'params\' : _base_model_url+\'imagenet/squeezenet/squeezenet_v1.1-0000.params\'}\n    }\n\n\n    @classmethod\n    def download(cls, architecture, path=""./""):\n        if cls.sanity_check(architecture):\n            architecture_file = download_file(cls.architecture_map[architecture][\'symbol\'], directory=path)\n            if not architecture_file:\n                return None\n\n            weight_file = download_file(cls.architecture_map[architecture][\'params\'], directory=path)\n            if not weight_file:\n                return None\n\n            print(""MXNet Model {} saved as [{}] and [{}]."".format(architecture, architecture_file, weight_file))\n            return (architecture_file, weight_file)\n\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture, files, path, image_path):\n        import mxnet as mx\n        import numpy as np\n        if cls.sanity_check(architecture):\n            file_name = cls.architecture_map[architecture][\'params\'].split(\'/\')[-1]\n            prefix, epoch_num = file_name[:-7].rsplit(\'-\', 1)\n\n            sym, arg_params, aux_params = mx.model.load_checkpoint(path + prefix, int(epoch_num))\n            model = mx.mod.Module(symbol=sym)\n            model.bind(for_training=False,\n                       data_shapes=[(\'data\', (1, 3, cls._image_size, cls._image_size))])\n            model.set_params(arg_params, aux_params, allow_missing=True, allow_extra=True)\n\n            func = TestKit.preprocess_func[\'mxnet\'][architecture]\n            img = func(image_path)\n            img = np.transpose(img, [2, 0, 1])\n            img = np.expand_dims(img, axis=0)\n\n            model.forward(cls.Batch([mx.nd.array(img)]))\n            predict = model.get_outputs()[0].asnumpy()\n            predict = np.squeeze(predict)\n\n            del model\n            return predict\n\n        else:\n            return None\n'"
mmdnn/conversion/examples/mxnet/imagenet_test.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom collections import namedtuple\nimport numpy as np\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nimport mxnet as mx\n\nBatch = namedtuple(\'Batch\', [\'data\'])\n\n\nclass TestMXNet(TestKit):\n\n    def __init__(self):\n        super(TestMXNet, self).__init__()\n\n        self.truth[\'tensorflow\'][\'inception_v3\'] = [(22, 9.6691055), (24, 4.3524752), (25, 3.5957956), (132, 3.5657482), (23, 3.3462858)]\n        self.truth[\'keras\'][\'inception_v3\'] = [(21, 0.93430501), (23, 0.0028834261), (131, 0.0014781745), (24, 0.0014518937), (22, 0.0014435325)]\n\n        self.model = self.MainModel.RefactorModel()\n        self.model = self.MainModel.deploy_weight(self.model, self.args.w)\n\n\n    def preprocess(self, image_path):\n        self.data = super(TestMXNet, self).preprocess(image_path)\n        self.data = np.swapaxes(self.data, 0, 2)\n        self.data = np.swapaxes(self.data, 1, 2)\n        self.data = np.expand_dims(self.data, 0)\n\n\n    def print_result(self):\n        self.model.forward(Batch([mx.nd.array(self.data)]))\n        prob = self.model.get_outputs()[0].asnumpy()\n        super(TestMXNet, self).print_result(prob)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n\n        # self.print_intermediate_result(\'pooling0\', False)\n\n        self.print_result()\n\n        self.test_truth()\n\n\n    def print_intermediate_result(self, layer_name, if_transpose = False):\n        internals = self.model.symbol.get_internals()\n        intermediate_output = internals[layer_name + ""_output""]\n        test_model = mx.mod.Module(symbol=intermediate_output, context=mx.cpu(), data_names=[\'data\'])\n        if self.args.preprocess == \'vgg19\' or self.args.preprocess == \'inception_v1\':\n            test_model.bind(for_training=False, data_shapes = [(\'data\', (1, 3, 224, 224))])\n        elif \'resnet\' in self.args.preprocess or self.args.preprocess == \'inception_v3\':\n            test_model.bind(for_training=False, data_shapes = [(\'data\', (1, 3, 299, 299))])\n        else:\n            assert False\n\n        arg_params, aux_params = self.model.get_params()\n\n        test_model.set_params(arg_params = arg_params, aux_params = aux_params, allow_missing = True, allow_extra = True)\n        test_model.forward(Batch([mx.nd.array(self.data)]))\n        intermediate_output = test_model.get_outputs()[0].asnumpy()\n\n        super(TestMXNet, self).print_intermediate_result(intermediate_output, if_transpose)\n\n\n    def dump(self, path = None):\n        if path is None: path = self.args.dump\n        self.model.save_checkpoint(path, 0)\n        print (\'MXNet checkpoint file is saved with prefix [{}] and iteration 0, generated by [{}.py] and [{}].\'.format(\n            path, self.args.n, self.args.w))\n\n\nif __name__ == \'__main__\':\n    tester = TestMXNet()\n    if tester.args.dump:\n        tester.dump()\n    else:\n        tester.inference(tester.args.image)\n'"
mmdnn/conversion/examples/onnx/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/onnx/imagenet_test.py,0,"b""#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport numpy as np\nimport sys\nimport os\nimport tensorflow as tf\nfrom onnx_tf.backend import prepare\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\n\nclass TestONNX(TestKit):\n\n    def __init__(self):\n        super(TestONNX, self).__init__()\n        self.model = prepare(self.MainModel.KitModel(self.args.w))\n        # self.input, self.model, self.testop = self.MainModel.KitModel(self.args.w)\n\n\n    def preprocess(self, image_path):\n        x = super(TestONNX, self).preprocess(image_path)\n        self.data = np.expand_dims(x, 0)\n\n\n    def print_result(self):\n        predict = self.model.run(self.data)[0]\n        super(TestONNX, self).print_result(predict)\n\n\n    def print_intermediate_result(self, layer_name, if_transpose = False):\n        # testop = tf.get_default_graph().get_operation_by_name(layer_name)\n        testop = self.testop\n        with tf.Session() as sess:\n            init = tf.global_variables_initializer()\n            sess.run(init)\n            intermediate_output = sess.run(testop, feed_dict = {self.input : self.data})\n\n        super(TestONNX, self).print_intermediate_result(intermediate_output, if_transpose)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n\n        # self.print_intermediate_result('conv1_7x7_s2_1', True)\n\n        self.print_result()\n\n        self.test_truth()\n\nif __name__=='__main__':\n    tester = TestONNX()\n    if tester.args.dump:\n        tester.dump()\n    else:\n        tester.inference(tester.args.image)\n"""
mmdnn/conversion/examples/paddle/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/paddle/extract_model.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport os\nfrom six import text_type as _text_type\nfrom mmdnn.conversion.common.utils import download_file\nimport paddle.v2 as paddle\nimport gzip\nfrom paddle.trainer_config_helpers.config_parser_utils import \\\n    reset_parser\n\nBASE_MODEL_URL = \'http://cloud.dlnel.org/filepub/?uuid=\'\n# pylint: disable=line-too-long\nMODEL_URL = {\n    \'resnet50\'             : BASE_MODEL_URL + \'f63f237a-698e-4a22-9782-baf5bb183019\',\n    \'resnet101\'            : BASE_MODEL_URL + \'3d5fb996-83d0-4745-8adc-13ee960fc55c\',\n    \'vgg16\'                : BASE_MODEL_URL + \'aa0e397e-474a-4cc1-bd8f-65a214039c2e\',\n}\n# pylint: enable=line-too-long\nIMG_SIZE = 224\nCLASS_DIMS = {\n        \'resnet50\'             : 1000,\n        \'resnet101\'            : 1000,\n        \'vgg16\'                : 1001, # work at 1001, but fail at 1000\n        \'alexnet\'              : 1001,\n}\n\ndef dump_v2_config(topology, save_path, binary=False):\n    import collections\n\n    from paddle.trainer_config_helpers.layers import LayerOutput\n    from paddle.v2.layer import parse_network\n    from paddle.proto import TrainerConfig_pb2\n    """""" Dump the network topology to a specified file.\n    This function is only used to dump network defined by using PaddlePaddle V2\n    API.\n    :param topology: The output layers in the entire network.\n    :type topology: LayerOutput|List|Tuple\n    :param save_path: The path to save the dump network topology.\n    :type save_path: str\n    :param binary: Whether to dump the serialized network topology. The default\n                value is false.\n    :type binary: bool.\n    """"""\n\n    if isinstance(topology, LayerOutput):\n        topology = [topology]\n    elif isinstance(topology, collections.Sequence):\n        for out_layer in topology:\n            assert isinstance(out_layer, LayerOutput), (\n                ""The type of each element in the parameter topology ""\n                ""should be LayerOutput."")\n    else:\n        raise RuntimeError(""Error input type for parameter topology."")\n\n    model_str = parse_network(topology)\n    with open(save_path, ""w"") as fout:\n        if binary:\n            fout.write(model_str.SerializeToString())\n        else:\n            fout.write(str(model_str))\n\ndef _main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'-n\', \'--network\', type=_text_type, help=\'Model Type\', required=True,\n                        choices=MODEL_URL.keys())\n\n    parser.add_argument(\'-i\', \'--image\', default=None,\n                        type=_text_type, help=\'Test Image Path\')\n\n    parser.add_argument(\'-o\', \'--output_dir\', default=\'./\',\n                        type=_text_type, help=\'Paddlepaddle parameters file name\')\n\n    args = parser.parse_args()\n\n    fn = download_file(MODEL_URL[args.network], local_fname = architecture + \'.tar.gz\', directory=args.output_dir)\n    if not fn:\n        return -1\n\n\n    DATA_DIM = 3 * IMG_SIZE * IMG_SIZE  # Use 3 * 331 * 331 or 3 * 299 * 299 for Inception-ResNet-v2.\n    CLASS_DIM = CLASS_DIMS[args.network]\n\n    # refer to https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/tests/test_rnn_layer.py#L35\n    reset_parser()\n\n    # refer to https://github.com/PaddlePaddle/Paddle/issues/7403\n    paddle.init(use_gpu=False, trainer_count=1)\n\n    image = paddle.layer.data(\n        name=""image"", type=paddle.data_type.dense_vector(DATA_DIM))\n    if \'resnet\' in architecture:\n        from mmdnn.conversion.examples.paddle.models import resnet\n        depth = int(architecture.strip(\'resnet\'))\n        out = resnet.resnet_imagenet(image, class_dim=CLASS_DIM, depth=depth)\n    elif architecture == \'vgg16\':\n        from mmdnn.conversion.examples.paddle.models import vgg\n        out = vgg.vgg16(image, class_dim=CLASS_DIM)\n    else:\n        print(""Not support for {} yet."", architecture)\n        return None\n\n    dump_v2_config(out, args.output_dir + architecture + \'.bin\')\n\n\n    print(""Model {} is saved as {} and {}."".format(args.network,  args.output_dir + architecture + \'.bin\', fn))\n\n    if args.image:\n\n        import numpy as np\n        from mmdnn.conversion.examples.imagenet_test import TestKit\n        func = TestKit.preprocess_func[\'paddle\'][args.network]\n        img = func(args.image)\n        img = np.transpose(img, (2, 0, 1))\n        test_data = [(img.flatten(),)]\n\n        with gzip.open(parameters_file, \'r\') as f:\n            parameters = paddle.parameters.Parameters.from_tar(f)\n\n        predict = paddle.infer(output_layer = out, parameters=parameters, input=test_data)\n        predict = np.squeeze(predict)\n        top_indices = predict.argsort()[-5:][::-1]\n        result = [(i, predict[i]) for i in top_indices]\n        print(result)\n        print(np.sum(result))\n\n    return 0\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/examples/paddle/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\nimport paddle.v2 as paddle\nimport gzip\nfrom paddle.trainer_config_helpers.config_parser_utils import \\\n    reset_parser\n\n\nclass paddle_extractor(base_extractor):\n\n    _base_model_url = \'http://cloud.dlnel.org/filepub/?uuid=\'\n\n    _image_size     = 224\n\n\n    architecture_map = {\n            \'resnet50\'             : {\'params\' : _base_model_url + \'f63f237a-698e-4a22-9782-baf5bb183019\',},\n            \'resnet101\'            : {\'params\' : _base_model_url + \'3d5fb996-83d0-4745-8adc-13ee960fc55c\',},\n            \'vgg16\'                : {\'params\': _base_model_url + \'aa0e397e-474a-4cc1-bd8f-65a214039c2e\',},\n\n    }\n\n    class_dim_map = {\n            \'resnet50\'             : 1000,\n            \'resnet101\'            : 1000,\n            \'vgg16\'                : 1001, # work at 1001, but fail at 1000\n            \'alexnet\'              : 1001,\n    }\n\n\n\n\n    @classmethod\n    def dump_v2_config(cls, topology, save_path, binary=False):\n        import collections\n\n        from paddle.trainer_config_helpers.layers import LayerOutput\n        from paddle.v2.layer import parse_network\n        from paddle.proto import TrainerConfig_pb2\n        """""" Dump the network topology to a specified file.\n        This function is only used to dump network defined by using PaddlePaddle V2\n        API.\n        :param topology: The output layers in the entire network.\n        :type topology: LayerOutput|List|Tuple\n        :param save_path: The path to save the dump network topology.\n        :type save_path: str\n        :param binary: Whether to dump the serialized network topology. The default\n                    value is false.\n        :type binary: bool.\n        """"""\n\n        if isinstance(topology, LayerOutput):\n            topology = [topology]\n        elif isinstance(topology, collections.Sequence):\n            for out_layer in topology:\n                assert isinstance(out_layer, LayerOutput), (\n                    ""The type of each element in the parameter topology ""\n                    ""should be LayerOutput."")\n        else:\n            raise RuntimeError(""Error input type for parameter topology."")\n\n        model_str = parse_network(topology)\n        with open(save_path, ""w"") as fout:\n            if binary:\n                fout.write(model_str.SerializeToString())\n            else:\n                fout.write(str(model_str))\n\n\n    @classmethod\n    def download(cls, architecture, path=""./""):\n        if cls.sanity_check(architecture):\n            reset_parser()\n\n\n            DATA_DIM = 3 * paddle_extractor._image_size * paddle_extractor._image_size  # Use 3 * 331 * 331 or 3 * 299 * 299 for Inception-ResNet-v2.\n            CLASS_DIM = paddle_extractor.class_dim_map[architecture]\n\n            image = paddle.layer.data(\n                name=""image"", type=paddle.data_type.dense_vector(DATA_DIM))\n            if \'resnet\' in architecture:\n                from mmdnn.conversion.examples.paddle.models import resnet\n                depth = int(architecture.strip(\'resnet\'))\n                out = resnet.resnet_imagenet(image, class_dim=CLASS_DIM, depth=depth)\n            elif architecture == \'vgg16\':\n                from mmdnn.conversion.examples.paddle.models import vgg\n                out = vgg.vgg16(image, class_dim=CLASS_DIM)\n            else:\n                print(""Not support for {} yet."", architecture)\n                return None\n            architecture_file = path + architecture + \'.bin\'\n            paddle_extractor.dump_v2_config(out, architecture_file, True)\n\n            weight_file = download_file(cls.architecture_map[architecture][\'params\'], directory=path, local_fname= architecture +\'.tar.gz\')\n            if not weight_file:\n                return None\n\n            print(""MXNet Model {} saved as [{}] and [{}]."".format(architecture, architecture_file, weight_file))\n            return (architecture_file, weight_file)\n\n\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture, files, path, image_path):\n\n        import numpy as np\n        if cls.sanity_check(architecture):\n            # refer to https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/v2/tests/test_rnn_layer.py#L35\n            reset_parser()\n\n            # refer to https://github.com/PaddlePaddle/Paddle/issues/7403\n            paddle.init(use_gpu=False, trainer_count=1)\n\n            DATA_DIM = 3 * paddle_extractor._image_size * paddle_extractor._image_size  # Use 3 * 331 * 331 or 3 * 299 * 299 for Inception-ResNet-v2.\n            CLASS_DIM = paddle_extractor.class_dim_map[architecture]\n            image = paddle.layer.data(\n                name=""image"", type=paddle.data_type.dense_vector(DATA_DIM))\n\n            if \'resnet\' in architecture:\n                from mmdnn.conversion.examples.paddle.models import resnet\n                depth = int(architecture.strip(\'resnet\'))\n                out = resnet.resnet_imagenet(image, class_dim=CLASS_DIM, depth=depth)\n            elif architecture == \'vgg16\':\n                from mmdnn.conversion.examples.paddle.models import vgg\n                out = vgg.vgg16(image, class_dim=CLASS_DIM)\n            else:\n                print(""Not support for {} yet."", architecture)\n                return None\n\n            _, parameters_file = files\n\n\n            with gzip.open(parameters_file, \'r\') as f:\n                parameters = paddle.parameters.Parameters.from_tar(f)\n\n\n            func = TestKit.preprocess_func[\'paddle\'][architecture]\n            img = func(image_path)\n            img = np.transpose(img, [2, 0, 1])\n            test_data = [(img.flatten(),)]\n\n            predict = paddle.infer(output_layer = out, parameters=parameters, input=test_data)\n            predict = np.squeeze(predict)\n\n            return predict\n\n\n        else:\n            return None\n'"
mmdnn/conversion/examples/paddle/imagenet_test.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport numpy as np\nimport sys\nimport os\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nimport paddle.v2 as paddle\nimport gzip\nfrom paddle.trainer_config_helpers.config_parser_utils import \\\n    reset_parser\n\n\nclass TestPaddle(TestKit):\n\n    def __init__(self):\n        from six import text_type as _text_type\n        parser = argparse.ArgumentParser()\n\n        parser.add_argument(\'-p\', \'--preprocess\', type=_text_type, help=\'Model Preprocess Type\')\n\n        parser.add_argument(\'--model\', \'-n\', \'-w\', type=_text_type,\n                            required=True, help=\'Paddle Model path.\')\n\n        parser.add_argument(\'-s\', type=_text_type, help=\'Source Framework Type\',\n                            choices=self.truth.keys())\n\n        parser.add_argument(\'--image\', \'-i\',\n                            type=_text_type, help=\'Test image path.\',\n                            default=""mmdnn/conversion/examples/data/seagull.jpg"")\n\n        parser.add_argument(\'-input\', type=_text_type,\n                            required=True, help=\'Paddle Input Node\')\n\n        parser.add_argument(\'-output\', type=_text_type,\n                            required=True, help=\'Paddle Output Node\')\n\n        parser.add_argument(\'-size\', type=int,\n            default=224, help=\'Paddle Input Image Size\')\n\n\n\n\n        self.args = parser.parse_args()\n\n        print(""Loading model [{}]."".format(self.args.model))\n\n        # import self.model\n        # self.model\n\n        # how the model can not load from `***.bin`\n\n        print(""Model loading success."")\n\n    def preprocess(self, image_path):\n        from PIL import Image as pil_image\n        img = pil_image.open(image_path)\n        img = img.resize((self.args.size, self.args.size))\n        self.data = img\n\n    def print_result(self):\n        reset_parser()\n        img = np.transpose(self.data, (2, 0, 1))\n        test_data = [(img.flatten(),)]\n\n        parameters_file = self.args.w\n        with gzip.open(parameters_file, \'r\') as f:\n            parameters = paddle.parameters.Parameters.from_tar(f)\n\n\n        predict = paddle.infer(output_layer = self.model, parameters=parameters, input=test_data)\n        predict = np.squeeze(predict)\n\n        super(TestPaddle, self).print_result(predict)\n\n\n    def print_intermediate_result(self, layer_name, if_transpose = False):\n        super(TestPaddle, self).print_intermediate_result(self.model.name, if_transpose)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n        self.print_result()\n\n\nif __name__==\'__main__\':\n    tester = TestPaddle()\n    tester.inference(tester.args.image)\n'"
mmdnn/conversion/examples/pytorch/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/pytorch/extract_model.py,4,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport os\nfrom six import text_type as _text_type\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nimport torch\nimport torchvision.models as models\n\n\nNETWORKS_MAP = {\n    \'inception_v3\'      : lambda : models.inception_v3(pretrained=True),\n    \'vgg16\'             : lambda : models.vgg16(pretrained=True),\n    \'vgg19\'             : lambda : models.vgg19(pretrained=True),\n    \'resnet152\'         : lambda : models.resnet152(pretrained=True),\n    \'densenet\'          : lambda : models.densenet201(pretrained=True),\n    \'squeezenet\'        : lambda : models.squeezenet1_1(pretrained=True)\n}\n\n\ndef _main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'-n\', \'--network\',\n                        type=_text_type, help=\'Model Type\', required=True,\n                        choices=NETWORKS_MAP.keys())\n\n    parser.add_argument(\'-i\', \'--image\', type=_text_type, help=\'Test Image Path\')\n\n    args = parser.parse_args()\n\n    file_name = ""imagenet_{}.pth"".format(args.network)\n    if not os.path.exists(file_name):\n        model = NETWORKS_MAP.get(args.network)\n        model = model()\n        torch.save(model, file_name)\n        print(""PyTorch pretrained model is saved as [{}]."".format(file_name))\n    else:\n        print(""File [{}] existed!"".format(file_name))\n        model = torch.load(file_name)\n\n    if args.image:\n        import numpy as np\n        func = TestKit.preprocess_func[\'pytorch\'][args.network]\n        img = func(args.image)\n        img = np.transpose(img, (2, 0, 1))\n        img = np.expand_dims(img, 0).copy()\n        data = torch.from_numpy(img)\n        data = torch.autograd.Variable(data, requires_grad=False)\n\n        model.eval()\n        predict = model(data).data.numpy()\n        predict = np.squeeze(predict)\n        top_indices = predict.argsort()[-5:][::-1]\n        result = [(i, predict[i]) for i in top_indices]\n        print(result)\n\n        # layer_name = \'block2_pool\'\n        # intermediate_layer_model = keras.Model(inputs=model.input,\n        #                                  outputs=model.get_layer(layer_name).output)\n        # intermediate_output = intermediate_layer_model.predict(img)\n        # print (intermediate_output)\n        # print (intermediate_output.shape)\n        # print (""%.30f"" % np.sum(intermediate_output))\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/examples/pytorch/extractor.py,4,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\n\nimport os\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\nimport torch\nimport torchvision.models as models\n\nclass pytorch_extractor(base_extractor):\n\n    architecture_map = sorted(name for name in models.__dict__\n        if name.islower() and not name.startswith(""__"")\n        and callable(models.__dict__[name]))\n\n\n    @classmethod\n    def help(cls):\n        print (\'Support frameworks: {}\'.format(cls.architecture_map))\n\n\n    @classmethod\n    def download(cls, architecture, path=""./""):\n        if cls.sanity_check(architecture):\n            architecture_file = path + ""imagenet_{}.pth"".format(architecture)\n            if not os.path.exists(architecture_file):\n                kwargs = {}\n                if architecture == \'inception_v3\':\n                    kwargs[\'transform_input\'] = False\n                model = models.__dict__[architecture](pretrained=True, **kwargs)\n                torch.save(model, architecture_file)\n                print(""PyTorch pretrained model is saved as [{}]."".format(architecture_file))\n            else:\n                print(""File [{}] existed!"".format(architecture_file))\n\n            return architecture_file\n\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture, path, image_path):\n        model = torch.load(path)\n\n        model.eval()\n\n        import numpy as np\n        func = TestKit.preprocess_func[\'pytorch\'][architecture]\n        img = func(image_path)\n        img = np.transpose(img, (2, 0, 1))\n\n        img = np.expand_dims(img, 0).copy()\n\n        data = torch.from_numpy(img)\n        data = torch.autograd.Variable(data, requires_grad=False)\n\n        predict = model(data).data.numpy()\n        predict = np.squeeze(predict)\n\n        return predict\n'"
mmdnn/conversion/examples/pytorch/imagenet_test.py,3,"b""#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport numpy as np\nimport sys\nimport os\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nimport torch\n\n\nclass TestTorch(TestKit):\n\n    def __init__(self):\n        super(TestTorch, self).__init__()\n\n        self.truth['tensorflow']['inception_v3'] = [(22, 9.6691055), (24, 4.3524747), (25, 3.5957973), (132, 3.5657473), (23, 3.346283)]\n        self.truth['keras']['inception_v3'] = [(21, 0.93430489), (23, 0.002883445), (131, 0.0014781791), (24, 0.0014518998), (22, 0.0014435351)]\n\n        self.model = self.MainModel.KitModel(self.args.w)\n        self.model.eval()\n\n    def preprocess(self, image_path):\n        x = super(TestTorch, self).preprocess(image_path)\n        x = np.transpose(x, (2, 0, 1))\n        x = np.expand_dims(x, 0).copy()\n        self.data = torch.from_numpy(x)\n        self.data = torch.autograd.Variable(self.data, requires_grad = False)\n\n\n    def print_result(self):\n        predict = self.model(self.data)\n        predict = predict.data.numpy()\n        super(TestTorch, self).print_result(predict)\n\n\n    def print_intermediate_result(self, layer_name, if_transpose=False):\n        intermediate_output = self.model.test.data.numpy()\n        super(TestTorch, self).print_intermediate_result(intermediate_output, if_transpose)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n\n        self.print_result()\n\n        # self.print_intermediate_result(None, False)\n\n        self.test_truth()\n\n\n    def dump(self, path=None):\n        if path is None: path = self.args.dump\n        torch.save(self.model, path)\n        print('PyTorch model file is saved as [{}], generated by [{}.py] and [{}].'.format(\n              path, self.args.n, self.args.w))\n\n\nif __name__=='__main__':\n    tester = TestTorch()\n    if tester.args.dump:\n        tester.dump()\n    else:\n        tester.inference(tester.args.image)\n"""
mmdnn/conversion/examples/tensorflow/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/tensorflow/extract_model.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nfrom six import text_type as _text_type\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.python.slim.nets import vgg\nfrom tensorflow.contrib.slim.python.slim.nets import inception\nfrom tensorflow.contrib.slim.python.slim.nets import resnet_v1\nfrom tensorflow.contrib.slim.python.slim.nets import resnet_v2\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\n\nslim = tf.contrib.slim\n\ninput_layer_map = {\n    \'vgg16\'         : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n    \'vgg19\'         : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n    \'inception_v1\'  : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n    \'inception_v2\'  : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n    \'inception_v3\'  : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n    \'resnet50\'      : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n    \'resnet_v1_101\' : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n    \'resnet101\'     : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n    \'resnet152\'     : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n    \'resnet200\'     : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n}\n\narg_scopes_map = {\n    \'vgg16\'         : vgg.vgg_arg_scope,\n    \'vgg19\'         : vgg.vgg_arg_scope,\n    \'inception_v1\'  : inception.inception_v3_arg_scope,\n    \'inception_v2\'  : inception.inception_v3_arg_scope,\n    \'inception_v3\'  : inception.inception_v3_arg_scope,\n    \'resnet50\'      : resnet_v2.resnet_arg_scope,\n    \'resnet_v1_101\' : resnet_v2.resnet_arg_scope,\n    \'resnet101\'     : resnet_v2.resnet_arg_scope,\n    \'resnet152\'     : resnet_v2.resnet_arg_scope,\n    \'resnet200\'     : resnet_v2.resnet_arg_scope,\n    # \'mobilenet_v1\': mobilenet_v1.mobilenet_v1_arg_scope,\n}\n\nnetworks_map = {\n    \'vgg16\'         : lambda : vgg.vgg_16,\n    \'vgg19\'         : lambda : vgg.vgg_19,\n    \'inception_v1\'  : lambda : inception.inception_v1,\n    \'inception_v2\'  : lambda : inception.inception_v2,\n    \'inception_v3\'  : lambda : inception.inception_v3,\n    \'resnet_v1_101\' : lambda : resnet_v1.resnet_v1_101,\n    \'resnet50\'      : lambda : resnet_v2.resnet_v2_50,\n    \'resnet101\'     : lambda : resnet_v2.resnet_v2_101,\n    \'resnet152\'     : lambda : resnet_v2.resnet_v2_152,\n    \'resnet200\'     : lambda : resnet_v2.resnet_v2_200,\n    #\'mobilenet_v1\' : mobilenet_v1.mobilenet_v1,\n}\n\ndef _main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'-n\', \'--network\', type=_text_type, help=\'Model Type\', required=True,\n        choices = input_layer_map.keys())\n\n    parser.add_argument(\'-i\', \'--image\',\n        type=_text_type, help=\'Test Image Path\')\n\n    parser.add_argument(\'-ckpt\', \'--checkpoint\',\n        type=_text_type, help=\'Tensorflow Checkpoint file name\', required=True)\n\n    args = parser.parse_args()\n\n    num_classes = 1000 if args.network in (\'vgg16\', \'vgg19\', \'resnet_v1_101\') else 1001\n\n    with slim.arg_scope(arg_scopes_map[args.network]()):\n        data_input = input_layer_map[args.network]()\n        logits, endpoints = networks_map[args.network]()(data_input, num_classes=num_classes, is_training=False)\n        labels = tf.squeeze(logits)\n\n    init = tf.global_variables_initializer()\n\n    with tf.Session() as sess:\n        writer = tf.summary.FileWriter(\'./graphs\', sess.graph)\n        writer.close()\n        sess.run(init)\n        saver = tf.train.Saver()\n        saver.restore(sess, args.checkpoint)\n        save_path = saver.save(sess, ""./imagenet_{}.ckpt"".format(args.network))\n        print(""Model saved in file: %s"" % save_path)\n\n        if args.image:\n            import numpy as np\n            func = TestKit.preprocess_func[\'tensorflow\'][args.network]\n            img = func(args.image)\n            img = np.expand_dims(img, axis = 0)\n            predict = sess.run(logits, feed_dict = {data_input : img})\n            predict = np.squeeze(predict)\n            top_indices = predict.argsort()[-5:][::-1]\n            result = [(i, predict[i]) for i in top_indices]\n            print (result)\n\n\nif __name__==\'__main__\':\n    _main()\n'"
mmdnn/conversion/examples/tensorflow/extractor.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nfrom __future__ import absolute_import\n\nimport os\nimport tensorflow as tf\n\nfrom tensorflow.contrib.slim.nets import vgg\nfrom tensorflow.contrib.slim.nets import inception\nfrom tensorflow.contrib.slim.nets import resnet_v1\nfrom tensorflow.contrib.slim.nets import resnet_v2\nfrom mmdnn.conversion.examples.tensorflow.models import inception_resnet_v2\nfrom mmdnn.conversion.examples.tensorflow.models import mobilenet_v1\nfrom mmdnn.conversion.examples.tensorflow.models import nasnet\nfrom mmdnn.conversion.examples.tensorflow.models.mobilenet import mobilenet_v2\nfrom mmdnn.conversion.examples.tensorflow.models import inception_resnet_v1\nfrom mmdnn.conversion.examples.tensorflow.models import test_rnn\nslim = tf.contrib.slim\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\nfrom mmdnn.conversion.examples.extractor import base_extractor\nfrom mmdnn.conversion.common.utils import download_file\n\n\nclass tensorflow_extractor(base_extractor):\n\n    MMDNN_BASE_URL = \'http://mmdnn.eastasia.cloudapp.azure.com:89/models/\'\n\n    architecture_map = {\n        \'vgg16\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\',\n            \'filename\'    : \'vgg_16.ckpt\',\n            \'builder\'     : lambda : vgg.vgg_16,\n            \'arg_scope\'   : vgg.vgg_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n            \'num_classes\' : 1000,\n        },\n        \'vgg19\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz\',\n            \'filename\'    : \'vgg_19.ckpt\',\n            \'builder\'     : lambda : vgg.vgg_19,\n            \'arg_scope\'   : vgg.vgg_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n            \'num_classes\' : 1000,\n        },\n        \'inception_v1\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz\',\n            \'filename\'    : \'inception_v1.ckpt\',\n            \'builder\'     : lambda : inception.inception_v1,\n            \'arg_scope\'   : inception.inception_v3_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'inception_v1_frozen\' : {\n            \'url\'         : \'https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz\',\n            \'filename\'    : \'inception_v1_2016_08_28_frozen.pb\',\n            \'tensor_out\'  : [\'InceptionV1/Logits/Predictions/Reshape_1:0\'],\n            \'tensor_in\'   : [\'input:0\'],\n            \'input_shape\' : [[224, 224, 3]],  # input_shape of the elem in tensor_in\n            \'feed_dict\'   :lambda img: {\'input:0\':img},\n            \'num_classes\' : 1001,\n        },\n        \'inception_v3\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\',\n            \'filename\'    : \'inception_v3.ckpt\',\n            \'builder\'     : lambda : inception.inception_v3,\n            \'arg_scope\'   : inception.inception_v3_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'inception_v3_frozen\' : {\n            \'url\'         : \'https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\',\n            \'filename\'    : \'inception_v3_2016_08_28_frozen.pb\',\n            \'tensor_out\'  : [\'InceptionV3/Predictions/Softmax:0\'],\n            \'tensor_in\'   : [\'input:0\'],\n            \'input_shape\' : [[299, 299, 3]], # input_shape of the elem in tensor_in\n            \'feed_dict\'   :lambda img: {\'input:0\':img},\n            \'num_classes\' : 1001,\n        },\n        \'resnet_v1_50\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz\',\n            \'filename\'    : \'resnet_v1_50.ckpt\',\n            \'builder\'     : lambda : resnet_v1.resnet_v1_50,\n            \'arg_scope\'   : resnet_v2.resnet_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n            \'num_classes\' : 1000,\n        },\n        \'resnet_v1_152\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/resnet_v1_152_2016_08_28.tar.gz\',\n            \'filename\'    : \'resnet_v1_152.ckpt\',\n            \'builder\'     : lambda : resnet_v1.resnet_v1_152,\n            \'arg_scope\'   : resnet_v2.resnet_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n            \'num_classes\' : 1000,\n        },\n        \'resnet_v2_50\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz\',\n            \'filename\'    : \'resnet_v2_50.ckpt\',\n            \'builder\'     : lambda : resnet_v2.resnet_v2_50,\n            \'arg_scope\'   : resnet_v2.resnet_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'resnet_v2_101\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/resnet_v2_101_2017_04_14.tar.gz\',\n            \'filename\'    : \'resnet_v2_101.ckpt\',\n            \'builder\'     : lambda : resnet_v2.resnet_v2_101,\n            \'arg_scope\'   : resnet_v2.resnet_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'resnet_v2_152\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/resnet_v2_152_2017_04_14.tar.gz\',\n            \'filename\'    : \'resnet_v2_152.ckpt\',\n            \'builder\'     : lambda : resnet_v2.resnet_v2_152,\n            \'arg_scope\'   : resnet_v2.resnet_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'resnet_v2_200\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/resnet_v2_200_2017_04_14.tar.gz\',\n            \'filename\'    : \'resnet_v2_200.ckpt\',\n            \'builder\'     : lambda : resnet_v2.resnet_v2_200,\n            \'arg_scope\'   : resnet_v2.resnet_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'mobilenet_v1_1.0\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/mobilenet_v1_1.0_224_2017_06_14.tar.gz\',\n            \'filename\'    : \'mobilenet_v1_1.0_224.ckpt\',\n            \'builder\'     : lambda : mobilenet_v1.mobilenet_v1,\n            \'arg_scope\'   : mobilenet_v1.mobilenet_v1_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'mobilenet_v1_1.0_frozen\' : {\n            \'url\'         : \'https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz\',\n            \'filename\'    : \'mobilenet_v1_1.0_224/frozen_graph.pb\',\n            \'tensor_out\'  : [\'MobilenetV1/Predictions/Softmax:0\'],\n            \'tensor_in\'   : [\'input:0\'],\n            \'input_shape\' : [[224, 224, 3]], # input_shape of the elem in tensor_in\n            \'feed_dict\'   :lambda img: {\'input:0\':img},\n            \'num_classes\' : 1001,\n        },\n        \'mobilenet_v2_1.0_224\':{\n            \'url\'         : \'https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz\',\n            \'filename\'    : \'mobilenet_v2_1.0_224.ckpt\',\n            \'builder\'     : lambda : mobilenet_v2.mobilenet,\n            \'arg_scope\'   : mobilenet_v2.training_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 224, 224, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'inception_resnet_v2\' : {\n            \'url\'         : \'http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz\',\n            \'filename\'    : \'inception_resnet_v2_2016_08_30.ckpt\',\n            \'builder\'     : lambda : inception_resnet_v2.inception_resnet_v2,\n            \'arg_scope\'   : inception_resnet_v2.inception_resnet_v2_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 299, 299, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'nasnet-a_large\' : {\n            \'url\'         : \'https://storage.googleapis.com/download.tensorflow.org/models/nasnet-a_large_04_10_2017.tar.gz\',\n            \'filename\'    : \'model.ckpt\',\n            \'builder\'     : lambda : nasnet.build_nasnet_large,\n            \'arg_scope\'   : nasnet.nasnet_large_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 331, 331, 3]),\n            \'num_classes\' : 1001,\n        },\n        \'facenet\' : {\n            \'url\'         : MMDNN_BASE_URL + \'tensorflow/facenet/20180408-102900.zip\',\n            \'filename\'    : \'20180408-102900/model-20180408-102900.ckpt-90\',\n            \'builder\'     : lambda : inception_resnet_v1.inception_resnet_v1,\n            \'arg_scope\'   : inception_resnet_v1.inception_resnet_v1_arg_scope,\n            \'input\'       : lambda : tf.placeholder(name=\'input\', dtype=tf.float32, shape=[None, 160, 160, 3]),\n            \'feed_dict\'   : lambda img: {\'input:0\':img,\'phase_train:0\':False},\n            \'num_classes\' : 0,\n        },\n        \'facenet_frozen\' : {\n            \'url\'         : MMDNN_BASE_URL + \'tensorflow/facenet/20180408-102900.zip\',\n            \'filename\'    : \'20180408-102900/20180408-102900.pb\',\n            \'tensor_out\'  : [\'InceptionResnetV1/Logits/AvgPool_1a_8x8/AvgPool:0\'],\n            \'tensor_in\'   : [\'input:0\',\'phase_train:0\'],\n            \'input_shape\' : [[160, 160, 3],1], # input_shape of the elem in tensor_in\n            \'feed_dict\'   : lambda img: {\'input:0\':img,\'phase_train:0\':False},\n            \'num_classes\' : 0,\n        },\n        \'rnn_lstm_gru_stacked\': {\n            \'url\'         : MMDNN_BASE_URL + \'tensorflow/tf_rnn/tf_rnn.zip\',  # Note this is just a model used for test, not a standard rnn model.\n            \'filename\'    :\'tf_rnn/tf_lstm_gru_stacked.ckpt\',\n            \'builder\'     :lambda: test_rnn.create_symbol,\n            \'arg_scope\'   :test_rnn.dummy_arg_scope,\n            \'input\'       :lambda: tf.placeholder(name=\'input\', dtype=tf.int32, shape=[None, 150]),\n            \'feed_dict\'   :lambda x:{\'input:0\': x},\n            \'num_classes\' : 0\n        }\n    }\n\n\n    @classmethod\n    def handle_checkpoint(cls, architecture, path):\n        with slim.arg_scope(cls.architecture_map[architecture][\'arg_scope\']()):\n            data_input = cls.architecture_map[architecture][\'input\']()\n            logits, endpoints = cls.architecture_map[architecture][\'builder\']()(\n                data_input,\n                num_classes=cls.architecture_map[architecture][\'num_classes\'],\n                is_training=False)\n\n            if logits.op.type == \'Squeeze\':\n                labels = tf.identity(logits, name=\'MMdnn_Output\')\n            else:\n                labels = tf.squeeze(logits, name=\'MMdnn_Output\')\n        \n\n        init = tf.global_variables_initializer()\n        with tf.Session() as sess:\n            sess.run(init)\n            saver = tf.train.Saver()\n            saver.restore(sess, path + cls.architecture_map[architecture][\'filename\'])\n            save_path = saver.save(sess, path + ""imagenet_{}.ckpt"".format(architecture))\n            print(""Model saved in file: %s"" % save_path)\n\n        import tensorflow.contrib.keras as keras\n        keras.backend.clear_session()\n\n\n    @classmethod\n    def handle_frozen_graph(cls, architecture, path):\n        return\n        # raise NotImplementedError()\n\n    @classmethod\n    def get_frozen_para(cls, architecture):\n        frozenname = architecture + \'_frozen\'\n        tensor_in =  list(map(lambda x:x.split(\':\')[0], cls.architecture_map[frozenname][\'tensor_in\']))\n        tensor_out = list(map(lambda x:x.split(\':\')[0], cls.architecture_map[frozenname][\'tensor_out\']))\n        return cls.architecture_map[frozenname][\'filename\'], cls.architecture_map[frozenname][\'input_shape\'], tensor_in, tensor_out\n\n\n    @classmethod\n    def download(cls, architecture, path=""./""):\n        if cls.sanity_check(architecture):\n            architecture_file = download_file(cls.architecture_map[architecture][\'url\'], directory=path, auto_unzip=True)\n            if not architecture_file:\n                return None\n\n            tf.reset_default_graph()\n\n            if \'ckpt\' in cls.architecture_map[architecture][\'filename\']:\n                cls.handle_checkpoint(architecture, path)\n\n            elif cls.architecture_map[architecture][\'filename\'].endswith(\'pb\'):\n                cls.handle_frozen_graph(architecture, path)\n            \n            else:\n                raise ValueError(""Unknown file name [{}]."".format(cls.architecture_map[architecture][\'filename\']))\n\n            return architecture_file\n\n        else:\n            return None\n\n\n    @classmethod\n    def inference(cls, architecture, files, path, test_input_path, is_frozen=False):\n        if is_frozen:\n            architecture_ = architecture + ""_frozen""\n        else:\n            architecture_ = architecture\n\n        if cls.download(architecture_, path):\n            import numpy as np\n            if \'rnn\' not in architecture_:\n                func = TestKit.preprocess_func[\'tensorflow\'][architecture]\n                img = func(test_input_path)\n                img = np.expand_dims(img, axis=0)\n                input_data = img\n            else:\n                input_data = np.load(test_input_path)\n\n            if is_frozen:\n                tf_model_path = cls.architecture_map[architecture_][\'filename\']\n                with open(path + tf_model_path, \'rb\') as f:\n                    serialized = f.read()\n                tf.reset_default_graph()\n                original_gdef = tf.GraphDef()\n                original_gdef.ParseFromString(serialized)\n                tf_output_name =  cls.architecture_map[architecture_][\'tensor_out\']\n                tf_input_name =  cls.architecture_map[architecture_][\'tensor_in\']\n                feed_dict = cls.architecture_map[architecture_][\'feed_dict\']\n\n                with tf.Graph().as_default() as g:\n                    tf.import_graph_def(original_gdef, name=\'\')\n                with tf.Session(graph = g) as sess:\n                    tf_out = sess.run(tf_output_name[0], feed_dict=feed_dict(input_data)) # temporarily think the num of out nodes is one\n                predict = np.squeeze(tf_out)\n                return predict\n\n            else:\n                with slim.arg_scope(cls.architecture_map[architecture][\'arg_scope\']()):\n                    data_input = cls.architecture_map[architecture][\'input\']()\n                    logits, endpoints = cls.architecture_map[architecture][\'builder\']()(\n                        data_input,\n                        num_classes=cls.architecture_map[architecture][\'num_classes\'],\n                        is_training=False)\n                    labels = tf.squeeze(logits)\n\n                init = tf.global_variables_initializer()\n                with tf.Session() as sess:\n                    sess.run(init)\n                    saver = tf.train.Saver()\n                    saver.restore(sess, path + cls.architecture_map[architecture][\'filename\'])\n                    predict = sess.run(logits, feed_dict = {data_input : input_data})\n\n                import tensorflow.contrib.keras as keras\n                keras.backend.clear_session()\n\n                predict = np.squeeze(predict)\n                return predict\n\n        else:\n            return None\n\n'"
mmdnn/conversion/examples/tensorflow/imagenet_test.py,0,"b'#----------------------------------------------------------------------------------------------\n#  Copyright (c) Microsoft Corporation. All rights reserved.\n#  Licensed under the MIT License. See License.txt in the project root for license information.\n#----------------------------------------------------------------------------------------------\n\nimport argparse\nimport numpy as np\nimport sys\nimport os\nimport tensorflow as tf\nfrom mmdnn.conversion.examples.imagenet_test import TestKit\n\nclass TestTF(TestKit):\n\n    def __init__(self):\n        super(TestTF, self).__init__()\n\n        self.truth[\'mxnet\'][\'resnet152-11k\'] = [(1278, 0.49070787), (1277, 0.21392652), (282, 0.12979421), (1282, 0.066355646), (1224, 0.022040566)]\n\n        self.input, self.model = self.MainModel.KitModel(self.args.w)\n        # self.input, self.model, self.testop = self.MainModel.KitModel(self.args.w)\n\n\n    def preprocess(self, image_path):\n        x = super(TestTF, self).preprocess(image_path)\n        self.data = np.expand_dims(x, 0)\n\n\n    def print_result(self):\n        with tf.Session() as sess:\n            init = tf.global_variables_initializer()\n            sess.run(init)\n            predict = sess.run(self.model, feed_dict = {self.input : self.data})\n\n        super(TestTF, self).print_result(predict)\n\n\n    def print_intermediate_result(self, layer_name, if_transpose = False):\n        # testop = tf.get_default_graph().get_operation_by_name(layer_name)\n        testop = self.testop\n        with tf.Session() as sess:\n            init = tf.global_variables_initializer()\n            sess.run(init)\n            intermediate_output = sess.run(testop, feed_dict = {self.input : self.data})\n\n        super(TestTF, self).print_intermediate_result(intermediate_output, if_transpose)\n\n\n    def inference(self, image_path):\n        self.preprocess(image_path)\n\n        # self.print_intermediate_result(\'conv1_7x7_s2_1\', True)\n\n        self.print_result()\n\n        self.test_truth()\n\n\n    def dump(self, path = None):\n        dump_tag = self.args.dump_tag\n        if dump_tag == \'SERVING\':\n            tag_list = [tf.saved_model.tag_constants.SERVING]\n        else:\n            tag_list = [tf.saved_model.tag_constants.TRAINING]\n\n        if path is None: path = self.args.dump\n        with tf.Session() as sess:\n            sess.run(tf.global_variables_initializer())\n\n            builder = tf.saved_model.builder.SavedModelBuilder(path)\n\n            tensor_info_input = tf.saved_model.utils.build_tensor_info(self.input)\n            tensor_info_output = tf.saved_model.utils.build_tensor_info(self.model)\n\n            prediction_signature = (\n                tf.saved_model.signature_def_utils.build_signature_def(\n                    inputs={\'input\': tensor_info_input},\n                    outputs={\'output\': tensor_info_output},\n                    method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n                )\n            )\n\n            builder.add_meta_graph_and_variables(\n                sess,\n                tag_list,\n                signature_def_map={\n                    tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_signature\n                }\n            )\n\n            save_path = builder.save()\n\n            print (\'Tensorflow file is saved as [{}], generated by [{}.py] and [{}].\'.format(\n                save_path, self.args.n, self.args.w))\n\n\nif __name__==\'__main__\':\n    tester = TestTF()\n    if tester.args.dump:\n        if tester.args.dump_tag:\n            tester.dump()\n        else:\n            raise ValueError(""Need to provide the model type of Tensorflow model."")\n    else:\n        tester.inference(tester.args.image)\n'"
mmdnn/conversion/examples/tensorflow/vis_meta.py,0,"b'import tensorflow as tf\nfrom tensorflow.python.platform import gfile\nimport os\nimport os.path\nimport shutil\nimport sys\nimport argparse\n\n\ndef _get_parser():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        \'--ckpt\',\n        required=True,\n        help=\'Path to the checkpoint meta file (.ckpt.meta).\'\n        )\n    parser.add_argument(\n        \'--logdir\',\n        required=True,\n        help=\'Path to the log directory for writing the graph summary for visualization.\'\n        )\n\n    return parser\n\n\ndef visualize(ckpt, logdir):\n    with tf.Session() as sess:\n        tf.train.import_meta_graph(ckpt)\n        train_writer = tf.summary.FileWriter(logdir)\n        train_writer.add_graph(sess.graph)\n        train_writer.close()\n\n\ndef _main():\n    """"""\n    Visualize the frozen TF graph using tensorboard.\n\n    Arguments\n    ----------\n    --ckpt: path to the checkpoint meta file (.ckpt.meta)\n    --logdir: path to the log directory for writing graph summary for visualization\n\n    Usage\n    ----------\n    python vis_meta.py --ckpt=model.ckpt.meta --logdir=/tmp/pb\n\n\n    To kill a previous tensorboard process, use the following commands in the terminal\n    ps aux | grep tensorboard\n    kill PID\n    """"""\n\n    parser = _get_parser()\n    args, unknown_args = parser.parse_known_args()\n\n    if not os.path.isfile(args.ckpt):\n        print(\'The checkpoint meta file does not exist.\')\n        exit(1)\n\n    if not os.path.isdir(args.logdir):\n        print(\'The log directory does not exist.\')\n        exit(1)\n\n    # Load file\n    visualize(args.ckpt, args.logdir)\n\n    # Run TensorBoard\n    cmd = \'tensorboard --logdir={} {}\'.format(\n        args.logdir,\n        \' \'.join(unknown_args)\n    )\n    #print(cmd)\n    os.system(cmd)\n\n\nif __name__ == \'__main__\':\n    _main()\n'"
mmdnn/conversion/tensorflow/rewriter/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function'
mmdnn/conversion/tensorflow/rewriter/gru_rewriter.py,0,"b'from mmdnn.conversion.rewriter.rewriter import UnitRewriterBase\nimport numpy as np\nimport re\n\nclass GRURewriter(UnitRewriterBase):\n\n    def __init__(self, graph, weights_dict):\n        return super(GRURewriter, self).__init__(graph, weights_dict)\n    \n    def process_gru_cell(self, match_result):\n        if \'gru_cell\' not in match_result._pattern_to_op.keys():\n            return\n        kwargs = dict()\n        top_node = match_result._pattern_to_op[match_result._name_to_pattern[\'gru_cell\']]\n\n        w_e = match_result.get_op(""cell_kernel"")\n        w = self._weights_dict[w_e.name.replace(\'/read\', \'\')]\n\n        num_units = w.shape[1]//2\n        input_size = w.shape[0] - num_units\n\n        kwargs[\'num_units\'] = num_units\n        kwargs[\'input_size\'] = input_size\n\n        if hasattr(top_node, \'kwargs\'):\n            top_node.kwargs.update(kwargs)\n        else:\n            top_node.kwargs = kwargs\n\n\n    def process_rnn_h_zero(self, match_result):\n        if \'h_zero\' not in match_result._name_to_pattern.keys():\n            return\n        kwargs = dict()\n        top_node = match_result._pattern_to_op[match_result._name_to_pattern[\'h_zero\']]\n\n        fill_size = match_result.get_op(\'fill_size\')\n        fill_value = match_result.get_op(\'fill_value\')\n\n        kwargs[\'fill_size\'] = fill_size.get_attr(\'value\').int_val[0]\n        kwargs[\'fill_value\'] = fill_value.get_attr(\'value\').float_val[0]\n\n        if hasattr(top_node, \'kwargs\'):\n            top_node.kwargs.update(kwargs)\n        else:\n            top_node.kwargs = kwargs\n\n\n    def process_match_result(self, match_result, pattern_name):\n        if pattern_name == \'gru_cell\':\n            self.process_gru_cell(match_result)\n        elif pattern_name == \'h_zero\':\n            if self.check_match_scope(match_result, \'GRUCellZeroState\'):\n                self.process_rnn_h_zero(match_result)\n\n    \'\'\'For some short pattern, to avoid match other pattern, check it\'s scope\'\'\'\n    def check_match_scope(self, match_result, scope_name):\n        ops = match_result._pattern_to_op.values()\n\n        for op in ops:\n            op_name_splits = op.name.split(\'/\')\n            if len(op_name_splits) < 2:\n                return False\n            if re.sub(r\'(_\\d+)*$\', \'\', op_name_splits[-2]) != scope_name:\n                if len(op_name_splits) > 2:\n                    if re.sub(r\'(_\\d+)*$\', \'\', op_name_splits[-3]) != scope_name:\n                        return False\n                else:\n                    return False\n        return True\n\n\n    def run(self):\n        return super(GRURewriter, self).run([\'gru_cell\', \'h_zero\'], \'tensorflow\')'"
mmdnn/conversion/tensorflow/rewriter/lstm_rewriter.py,0,"b'from mmdnn.conversion.rewriter.rewriter import UnitRewriterBase\nimport numpy as np\nimport re\n\n\nclass LSTMRewriter(UnitRewriterBase):\n\n    def __init__(self, graph, weights_dict):\n        return super(LSTMRewriter, self).__init__(graph, weights_dict)\n\n\n    def process_lstm_cell(self, match_result):\n        if \'lstm_cell\' not in match_result._pattern_to_op.keys():\n            return\n        kwargs = dict()\n\n        top_node = match_result._pattern_to_op[match_result._name_to_pattern[\'lstm_cell\']]\n\n        w_e = match_result.get_op(""cell_kernel"")\n        w = self._weights_dict[w_e.name.replace(\'/read\', \'\')]\n\n        num_units = w.shape[1]//4\n        [wx, wh] = np.split(w, [-1 * num_units])\n        input_size = wx.shape[0]\n\n        kwargs[\'num_units\'] = num_units\n        kwargs[\'input_size\'] = input_size\n\n        if hasattr(top_node, \'kwargs\'):\n            top_node.kwargs.update(kwargs)\n        else:\n            top_node.kwargs = kwargs\n\n\n    def process_rnn_h_zero(self, match_result):\n        if \'h_zero\' not in match_result._name_to_pattern.keys():\n            return\n        kwargs = dict()\n        top_node = match_result._pattern_to_op[match_result._name_to_pattern[\'h_zero\']]\n        \n        fill_size = match_result.get_op(\'fill_size\')\n        fill_value = match_result.get_op(\'fill_value\')\n\n        kwargs[\'fill_size\'] = fill_size.get_attr(\'value\').int_val[0]\n        kwargs[\'fill_value\'] = fill_value.get_attr(\'value\').float_val[0]\n\n        if hasattr(top_node, \'kwargs\'):\n            top_node.kwargs.update(kwargs)\n        else:\n            top_node.kwargs = kwargs\n\n\n    def process_match_result(self, match_result, pattern_name):\n        if pattern_name == \'lstm_cell\':\n            self.process_lstm_cell(match_result)\n        elif pattern_name == \'h_zero\':\n            if self.check_match_scope(match_result, \'LSTMCellZeroState\'):\n                self.process_rnn_h_zero(match_result)\n\n\n    \'\'\'For some short pattern, to avoid match other pattern, check it\'s scope\'\'\'\n    def check_match_scope(self, match_result, scope_name):\n        ops = match_result._pattern_to_op.values()\n\n        for op in ops:\n            op_name_splits = op.name.split(\'/\')\n            if len(op_name_splits) < 2:\n                return False\n            if re.sub(r\'(_\\d+)*$\', \'\', op_name_splits[-2]) != scope_name:\n                if len(op_name_splits) > 2:\n                    if re.sub(r\'(_\\d+)*$\', \'\', op_name_splits[-3]) != scope_name:\n                        return False\n                else:\n                    return False\n        return True\n\n\n    def run(self):\n        return super(LSTMRewriter, self).run([\'lstm_cell\', \'h_zero\'], \'tensorflow\')'"
mmdnn/conversion/examples/paddle/models/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/paddle/models/alexnet.py,0,"b""import paddle.v2 as paddle\n\n__all__ = ['alexnet']\n\n\ndef alexnet(input, class_dim):\n    conv1 = paddle.layer.img_conv(\n        input=input,\n        filter_size=11,\n        num_channels=3,\n        num_filters=96,\n        stride=4,\n        padding=1)\n    cmrnorm1 = paddle.layer.img_cmrnorm(\n        input=conv1, size=5, scale=0.0001, power=0.75)\n    pool1 = paddle.layer.img_pool(input=cmrnorm1, pool_size=3, stride=2)\n\n    conv2 = paddle.layer.img_conv(\n        input=pool1,\n        filter_size=5,\n        num_filters=256,\n        stride=1,\n        padding=2,\n        groups=1)\n    cmrnorm2 = paddle.layer.img_cmrnorm(\n        input=conv2, size=5, scale=0.0001, power=0.75)\n    pool2 = paddle.layer.img_pool(input=cmrnorm2, pool_size=3, stride=2)\n\n    pool3 = paddle.networks.img_conv_group(\n        input=pool2,\n        pool_size=3,\n        pool_stride=2,\n        conv_num_filter=[384, 384, 256],\n        conv_filter_size=3,\n        pool_type=paddle.pooling.Max())\n\n    fc1 = paddle.layer.fc(input=pool3,\n                          size=4096,\n                          act=paddle.activation.Relu(),\n                          layer_attr=paddle.attr.Extra(drop_rate=0.5))\n    fc2 = paddle.layer.fc(input=fc1,\n                          size=4096,\n                          act=paddle.activation.Relu(),\n                          layer_attr=paddle.attr.Extra(drop_rate=0.5))\n\n    out = paddle.layer.fc(input=fc2,\n                          size=class_dim,\n                          act=paddle.activation.Softmax())\n    return out\n"""
mmdnn/conversion/examples/paddle/models/resnet.py,0,"b""import paddle.v2 as paddle\n\n__all__ = ['resnet_imagenet', 'resnet_cifar10']\n\n\ndef conv_bn_layer(input,\n                  ch_out,\n                  filter_size,\n                  stride,\n                  padding,\n                  active_type=paddle.activation.Relu(),\n                  ch_in=None):\n    tmp = paddle.layer.img_conv(\n        input=input,\n        filter_size=filter_size,\n        num_channels=ch_in,\n        num_filters=ch_out,\n        stride=stride,\n        padding=padding,\n        act=paddle.activation.Linear(),\n        bias_attr=False)\n    return paddle.layer.batch_norm(input=tmp, act=active_type)\n\n\ndef shortcut(input, ch_out, stride):\n    if input.num_filters != ch_out:\n        return conv_bn_layer(input, ch_out, 1, stride, 0,\n                             paddle.activation.Linear())\n    else:\n        return input\n\n\ndef basicblock(input, ch_out, stride):\n    short = shortcut(input, ch_out, stride)\n    conv1 = conv_bn_layer(input, ch_out, 3, stride, 1)\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1, paddle.activation.Linear())\n    return paddle.layer.addto(\n        input=[short, conv2], act=paddle.activation.Relu())\n\n\ndef bottleneck(input, ch_out, stride):\n    short = shortcut(input, ch_out * 4, stride)\n    conv1 = conv_bn_layer(input, ch_out, 1, stride, 0)\n    conv2 = conv_bn_layer(conv1, ch_out, 3, 1, 1)\n    conv3 = conv_bn_layer(conv2, ch_out * 4, 1, 1, 0,\n                          paddle.activation.Linear())\n    return paddle.layer.addto(\n        input=[short, conv3], act=paddle.activation.Relu())\n\n\ndef layer_warp(block_func, input, ch_out, count, stride):\n    conv = block_func(input, ch_out, stride)\n    for i in range(1, count):\n        conv = block_func(conv, ch_out, 1)\n    return conv\n\n\ndef resnet_imagenet(input, class_dim, depth=50):\n    cfg = {\n        18: ([2, 2, 2, 1], basicblock),\n        34: ([3, 4, 6, 3], basicblock),\n        50: ([3, 4, 6, 3], bottleneck),\n        101: ([3, 4, 23, 3], bottleneck),\n        152: ([3, 8, 36, 3], bottleneck)\n    }\n    stages, block_func = cfg[depth]\n    conv1 = conv_bn_layer(\n        input, ch_in=3, ch_out=64, filter_size=7, stride=2, padding=3)\n    pool1 = paddle.layer.img_pool(input=conv1, pool_size=3, stride=2)\n    res1 = layer_warp(block_func, pool1, 64, stages[0], 1)\n    res2 = layer_warp(block_func, res1, 128, stages[1], 2)\n    res3 = layer_warp(block_func, res2, 256, stages[2], 2)\n    res4 = layer_warp(block_func, res3, 512, stages[3], 2)\n    pool2 = paddle.layer.img_pool(\n        input=res4, pool_size=7, stride=1, pool_type=paddle.pooling.Avg())\n    out = paddle.layer.fc(input=pool2,\n                          size=class_dim,\n                          act=paddle.activation.Softmax())\n    return out\n\n\ndef resnet_cifar10(input, class_dim, depth=32):\n    # depth should be one of 20, 32, 44, 56, 110, 1202\n    assert (depth - 2) % 6 == 0\n    n = (depth - 2) / 6\n    nStages = {16, 64, 128}\n    conv1 = conv_bn_layer(\n        input, ch_in=3, ch_out=16, filter_size=3, stride=1, padding=1)\n    res1 = layer_warp(basicblock, conv1, 16, n, 1)\n    res2 = layer_warp(basicblock, res1, 32, n, 2)\n    res3 = layer_warp(basicblock, res2, 64, n, 2)\n    pool = paddle.layer.img_pool(\n        input=res3, pool_size=8, stride=1, pool_type=paddle.pooling.Avg())\n    out = paddle.layer.fc(input=pool,\n                          size=class_dim,\n                          act=paddle.activation.Softmax())\n    return out\n"""
mmdnn/conversion/examples/paddle/models/vgg.py,0,"b""import paddle.v2 as paddle\n\n__all__ = ['vgg13', 'vgg16', 'vgg19']\n\n\ndef vgg(input, nums, class_dim):\n    def conv_block(input, num_filter, groups, num_channels=None):\n        return paddle.networks.img_conv_group(\n            input=input,\n            num_channels=num_channels,\n            pool_size=2,\n            pool_stride=2,\n            conv_num_filter=[num_filter] * groups,\n            conv_filter_size=3,\n            conv_act=paddle.activation.Relu(),\n            pool_type=paddle.pooling.Max())\n\n    assert len(nums) == 5\n    # the channel of input feature is 3\n    conv1 = conv_block(input, 64, nums[0], 3)\n    conv2 = conv_block(conv1, 128, nums[1])\n    conv3 = conv_block(conv2, 256, nums[2])\n    conv4 = conv_block(conv3, 512, nums[3])\n    conv5 = conv_block(conv4, 512, nums[4])\n\n    fc_dim = 4096\n    fc1 = paddle.layer.fc(input=conv5,\n                          size=fc_dim,\n                          act=paddle.activation.Relu(),\n                          layer_attr=paddle.attr.Extra(drop_rate=0.5))\n    fc2 = paddle.layer.fc(input=fc1,\n                          size=fc_dim,\n                          act=paddle.activation.Relu(),\n                          layer_attr=paddle.attr.Extra(drop_rate=0.5))\n    out = paddle.layer.fc(input=fc2,\n                          size=class_dim,\n                          act=paddle.activation.Softmax())\n    return out\n\n\ndef vgg13(input, class_dim):\n    nums = [2, 2, 2, 2, 2]\n    return vgg(input, nums, class_dim)\n\n\ndef vgg16(input, class_dim):\n    nums = [2, 2, 3, 3, 3]\n    return vgg(input, nums, class_dim)\n\n\ndef vgg19(input, class_dim):\n    nums = [2, 2, 4, 4, 4]\n    return vgg(input, nums, class_dim)\n"""
mmdnn/conversion/examples/tensorflow/models/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/tensorflow/models/inception_resnet_v1.py,0,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""Contains the definition of the Inception Resnet V1 architecture.\nAs described in http://arxiv.org/abs/1602.07261.\n  Inception-v4, Inception-ResNet and the Impact of Residual Connections\n    on Learning\n  Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\n# Inception-Resnet-A\ndef block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n    """"""Builds the 35x35 resnet block.""""""\n    with tf.variable_scope(scope, \'Block35\', [net], reuse=reuse):\n        with tf.variable_scope(\'Branch_0\'):\n            tower_conv = slim.conv2d(net, 32, 1, scope=\'Conv2d_1x1\')\n        with tf.variable_scope(\'Branch_1\'):\n            tower_conv1_0 = slim.conv2d(net, 32, 1, scope=\'Conv2d_0a_1x1\')\n            tower_conv1_1 = slim.conv2d(tower_conv1_0, 32, 3, scope=\'Conv2d_0b_3x3\')\n        with tf.variable_scope(\'Branch_2\'):\n            tower_conv2_0 = slim.conv2d(net, 32, 1, scope=\'Conv2d_0a_1x1\')\n            tower_conv2_1 = slim.conv2d(tower_conv2_0, 32, 3, scope=\'Conv2d_0b_3x3\')\n            tower_conv2_2 = slim.conv2d(tower_conv2_1, 32, 3, scope=\'Conv2d_0c_3x3\')\n        mixed = tf.concat([tower_conv, tower_conv1_1, tower_conv2_2], 3)\n        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                         activation_fn=None, scope=\'Conv2d_1x1\')\n        net += scale * up\n        if activation_fn:\n            net = activation_fn(net)\n    return net\n\n# Inception-Resnet-B\ndef block17(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n    """"""Builds the 17x17 resnet block.""""""\n    with tf.variable_scope(scope, \'Block17\', [net], reuse=reuse):\n        with tf.variable_scope(\'Branch_0\'):\n            tower_conv = slim.conv2d(net, 128, 1, scope=\'Conv2d_1x1\')\n        with tf.variable_scope(\'Branch_1\'):\n            tower_conv1_0 = slim.conv2d(net, 128, 1, scope=\'Conv2d_0a_1x1\')\n            tower_conv1_1 = slim.conv2d(tower_conv1_0, 128, [1, 7],\n                                        scope=\'Conv2d_0b_1x7\')\n            tower_conv1_2 = slim.conv2d(tower_conv1_1, 128, [7, 1],\n                                        scope=\'Conv2d_0c_7x1\')\n        mixed = tf.concat([tower_conv, tower_conv1_2], 3)\n        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                         activation_fn=None, scope=\'Conv2d_1x1\')\n        net += scale * up\n        if activation_fn:\n            net = activation_fn(net)\n    return net\n\n\n# Inception-Resnet-C\ndef block8(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n    """"""Builds the 8x8 resnet block.""""""\n    with tf.variable_scope(scope, \'Block8\', [net], reuse=reuse):\n        with tf.variable_scope(\'Branch_0\'):\n            tower_conv = slim.conv2d(net, 192, 1, scope=\'Conv2d_1x1\')\n        with tf.variable_scope(\'Branch_1\'):\n            tower_conv1_0 = slim.conv2d(net, 192, 1, scope=\'Conv2d_0a_1x1\')\n            tower_conv1_1 = slim.conv2d(tower_conv1_0, 192, [1, 3],\n                                        scope=\'Conv2d_0b_1x3\')\n            tower_conv1_2 = slim.conv2d(tower_conv1_1, 192, [3, 1],\n                                        scope=\'Conv2d_0c_3x1\')\n        mixed = tf.concat([tower_conv, tower_conv1_2], 3)\n        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                         activation_fn=None, scope=\'Conv2d_1x1\')\n        net += scale * up\n        if activation_fn:\n            net = activation_fn(net)\n    return net\n  \ndef reduction_a(net, k, l, m, n):\n    with tf.variable_scope(\'Branch_0\'):\n        tower_conv = slim.conv2d(net, n, 3, stride=2, padding=\'VALID\',\n                                 scope=\'Conv2d_1a_3x3\')\n    with tf.variable_scope(\'Branch_1\'):\n        tower_conv1_0 = slim.conv2d(net, k, 1, scope=\'Conv2d_0a_1x1\')\n        tower_conv1_1 = slim.conv2d(tower_conv1_0, l, 3,\n                                    scope=\'Conv2d_0b_3x3\')\n        tower_conv1_2 = slim.conv2d(tower_conv1_1, m, 3,\n                                    stride=2, padding=\'VALID\',\n                                    scope=\'Conv2d_1a_3x3\')\n    with tf.variable_scope(\'Branch_2\'):\n        tower_pool = slim.max_pool2d(net, 3, stride=2, padding=\'VALID\',\n                                     scope=\'MaxPool_1a_3x3\')\n    net = tf.concat([tower_conv, tower_conv1_2, tower_pool], 3)\n    return net\n\ndef reduction_b(net):\n    with tf.variable_scope(\'Branch_0\'):\n        tower_conv = slim.conv2d(net, 256, 1, scope=\'Conv2d_0a_1x1\')\n        tower_conv_1 = slim.conv2d(tower_conv, 384, 3, stride=2,\n                                   padding=\'VALID\', scope=\'Conv2d_1a_3x3\')\n    with tf.variable_scope(\'Branch_1\'):\n        tower_conv1 = slim.conv2d(net, 256, 1, scope=\'Conv2d_0a_1x1\')\n        tower_conv1_1 = slim.conv2d(tower_conv1, 256, 3, stride=2,\n                                    padding=\'VALID\', scope=\'Conv2d_1a_3x3\')\n    with tf.variable_scope(\'Branch_2\'):\n        tower_conv2 = slim.conv2d(net, 256, 1, scope=\'Conv2d_0a_1x1\')\n        tower_conv2_1 = slim.conv2d(tower_conv2, 256, 3,\n                                    scope=\'Conv2d_0b_3x3\')\n        tower_conv2_2 = slim.conv2d(tower_conv2_1, 256, 3, stride=2,\n                                    padding=\'VALID\', scope=\'Conv2d_1a_3x3\')\n    with tf.variable_scope(\'Branch_3\'):\n        tower_pool = slim.max_pool2d(net, 3, stride=2, padding=\'VALID\',\n                                     scope=\'MaxPool_1a_3x3\')\n    net = tf.concat([tower_conv_1, tower_conv1_1,\n                        tower_conv2_2, tower_pool], 3)\n    return net\n\n\ndef inception_resnet_v1_arg_scope(weight_decay=0.0,\n                                  activation_fn=tf.nn.relu):\n    batch_norm_params = {\n        # Decay for the moving averages.\n        \'decay\': 0.995,\n        # epsilon to prevent 0s in variance.\n        \'epsilon\': 0.001,\n        # force in-place updates of mean and variance estimates\n        \'updates_collections\': None,\n        # Moving averages ends up in the trainable variables collection\n        \'variables_collections\': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\n    }\n    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n                        weights_initializer=slim.initializers.xavier_initializer(), \n                        weights_regularizer=slim.l2_regularizer(weight_decay),\n                        normalizer_fn=slim.batch_norm,\n                        normalizer_params=batch_norm_params) as sc:\n        return sc\n        \n \n\ndef inception_resnet_v1(inputs, num_classes,is_training=True,\n                        dropout_keep_prob=0.8,\n                        bottleneck_layer_size=512,\n                        reuse=None, \n                        scope=\'InceptionResnetV1\'):\n    """"""Creates the Inception Resnet V1 model.\n    Args:\n      inputs: a 4-D tensor of size [batch_size, height, width, 3].\n      num_classes: number of predicted classes.\n      is_training: whether is training or not.\n      dropout_keep_prob: float, the fraction to keep before final layer.\n      reuse: whether or not the network and its variables should be reused. To be\n        able to reuse \'scope\' must be given.\n      scope: Optional variable_scope.\n    Returns:\n      logits: the logits outputs of the model.\n      end_points: the set of end_points from the inception model.\n    """"""\n    end_points = {}\n  \n    with tf.variable_scope(scope, \'InceptionResnetV1\', [inputs], reuse=reuse):\n        with slim.arg_scope([slim.batch_norm, slim.dropout],\n                            is_training=is_training):\n            with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n                                stride=1, padding=\'SAME\'):\n      \n                # 149 x 149 x 32\n                net = slim.conv2d(inputs, 32, 3, stride=2, padding=\'VALID\',\n                                  scope=\'Conv2d_1a_3x3\')\n                end_points[\'Conv2d_1a_3x3\'] = net\n                # 147 x 147 x 32\n                net = slim.conv2d(net, 32, 3, padding=\'VALID\',\n                                  scope=\'Conv2d_2a_3x3\')\n                end_points[\'Conv2d_2a_3x3\'] = net\n                # 147 x 147 x 64\n                net = slim.conv2d(net, 64, 3, scope=\'Conv2d_2b_3x3\')\n                end_points[\'Conv2d_2b_3x3\'] = net\n                # 73 x 73 x 64\n                net = slim.max_pool2d(net, 3, stride=2, padding=\'VALID\',\n                                      scope=\'MaxPool_3a_3x3\')\n                end_points[\'MaxPool_3a_3x3\'] = net\n                # 73 x 73 x 80\n                net = slim.conv2d(net, 80, 1, padding=\'VALID\',\n                                  scope=\'Conv2d_3b_1x1\')\n                end_points[\'Conv2d_3b_1x1\'] = net\n                # 71 x 71 x 192\n                net = slim.conv2d(net, 192, 3, padding=\'VALID\',\n                                  scope=\'Conv2d_4a_3x3\')\n                end_points[\'Conv2d_4a_3x3\'] = net\n                # 35 x 35 x 256\n                net = slim.conv2d(net, 256, 3, stride=2, padding=\'VALID\',\n                                  scope=\'Conv2d_4b_3x3\')\n                end_points[\'Conv2d_4b_3x3\'] = net\n                \n                # 5 x Inception-resnet-A\n                net = slim.repeat(net, 5, block35, scale=0.17)\n                end_points[\'Mixed_5a\'] = net\n        \n                # Reduction-A\n                with tf.variable_scope(\'Mixed_6a\'):\n                    net = reduction_a(net, 192, 192, 256, 384)\n                end_points[\'Mixed_6a\'] = net\n                \n                # 10 x Inception-Resnet-B\n                net = slim.repeat(net, 10, block17, scale=0.10)\n                end_points[\'Mixed_6b\'] = net\n                \n                # Reduction-B\n                with tf.variable_scope(\'Mixed_7a\'):\n                    net = reduction_b(net)\n                end_points[\'Mixed_7a\'] = net\n                \n                # 5 x Inception-Resnet-C\n                net = slim.repeat(net, 5, block8, scale=0.20)\n                end_points[\'Mixed_8a\'] = net\n                \n                net = block8(net, activation_fn=None)\n                end_points[\'Mixed_8b\'] = net\n                \n                with tf.variable_scope(\'Logits\'):\n                    end_points[\'PrePool\'] = net\n                    #pylint: disable=no-member\n                    net = slim.avg_pool2d(net, net.get_shape()[1:3], padding=\'VALID\',\n                                          scope=\'AvgPool_1a_8x8\')\n                    net = slim.flatten(net)\n          \n                    net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n                                       scope=\'Dropout\')\n          \n                    end_points[\'PreLogitsFlatten\'] = net\n                \n                # net = slim.fully_connected(net, bottleneck_layer_size, activation_fn=None, \n                #         scope=\'Bottleneck\', reuse=False)\n  \n    return net, end_points'"
mmdnn/conversion/examples/tensorflow/models/inception_resnet_v2.py,0,"b'# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Contains the definition of the Inception Resnet V2 architecture.\n\nAs described in http://arxiv.org/abs/1602.07261.\n\n  Inception-v4, Inception-ResNet and the Impact of Residual Connections\n    on Learning\n  Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\n\ndef block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n  """"""Builds the 35x35 resnet block.""""""\n  with tf.variable_scope(scope, \'Block35\', [net], reuse=reuse):\n    with tf.variable_scope(\'Branch_0\'):\n      tower_conv = slim.conv2d(net, 32, 1, scope=\'Conv2d_1x1\')\n    with tf.variable_scope(\'Branch_1\'):\n      tower_conv1_0 = slim.conv2d(net, 32, 1, scope=\'Conv2d_0a_1x1\')\n      tower_conv1_1 = slim.conv2d(tower_conv1_0, 32, 3, scope=\'Conv2d_0b_3x3\')\n    with tf.variable_scope(\'Branch_2\'):\n      tower_conv2_0 = slim.conv2d(net, 32, 1, scope=\'Conv2d_0a_1x1\')\n      tower_conv2_1 = slim.conv2d(tower_conv2_0, 48, 3, scope=\'Conv2d_0b_3x3\')\n      tower_conv2_2 = slim.conv2d(tower_conv2_1, 64, 3, scope=\'Conv2d_0c_3x3\')\n    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_1, tower_conv2_2])\n    up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                     activation_fn=None, scope=\'Conv2d_1x1\')\n    scaled_up = up * scale\n    if activation_fn == tf.nn.relu6:\n      # Use clip_by_value to simulate bandpass activation.\n      scaled_up = tf.clip_by_value(scaled_up, -6.0, 6.0)\n\n    net += scaled_up\n    if activation_fn:\n      net = activation_fn(net)\n  return net\n\n\ndef block17(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n  """"""Builds the 17x17 resnet block.""""""\n  with tf.variable_scope(scope, \'Block17\', [net], reuse=reuse):\n    with tf.variable_scope(\'Branch_0\'):\n      tower_conv = slim.conv2d(net, 192, 1, scope=\'Conv2d_1x1\')\n    with tf.variable_scope(\'Branch_1\'):\n      tower_conv1_0 = slim.conv2d(net, 128, 1, scope=\'Conv2d_0a_1x1\')\n      tower_conv1_1 = slim.conv2d(tower_conv1_0, 160, [1, 7],\n                                  scope=\'Conv2d_0b_1x7\')\n      tower_conv1_2 = slim.conv2d(tower_conv1_1, 192, [7, 1],\n                                  scope=\'Conv2d_0c_7x1\')\n    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_2])\n    up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                     activation_fn=None, scope=\'Conv2d_1x1\')\n\n    scaled_up = up * scale\n    if activation_fn == tf.nn.relu6:\n      # Use clip_by_value to simulate bandpass activation.\n      scaled_up = tf.clip_by_value(scaled_up, -6.0, 6.0)\n\n    net += scaled_up\n    if activation_fn:\n      net = activation_fn(net)\n  return net\n\n\ndef block8(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n  """"""Builds the 8x8 resnet block.""""""\n  with tf.variable_scope(scope, \'Block8\', [net], reuse=reuse):\n    with tf.variable_scope(\'Branch_0\'):\n      tower_conv = slim.conv2d(net, 192, 1, scope=\'Conv2d_1x1\')\n    with tf.variable_scope(\'Branch_1\'):\n      tower_conv1_0 = slim.conv2d(net, 192, 1, scope=\'Conv2d_0a_1x1\')\n      tower_conv1_1 = slim.conv2d(tower_conv1_0, 224, [1, 3],\n                                  scope=\'Conv2d_0b_1x3\')\n      tower_conv1_2 = slim.conv2d(tower_conv1_1, 256, [3, 1],\n                                  scope=\'Conv2d_0c_3x1\')\n    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_2])\n    up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                     activation_fn=None, scope=\'Conv2d_1x1\')\n\n    scaled_up = up * scale\n    if activation_fn == tf.nn.relu6:\n      # Use clip_by_value to simulate bandpass activation.\n      scaled_up = tf.clip_by_value(scaled_up, -6.0, 6.0)\n\n    net += scaled_up\n    if activation_fn:\n      net = activation_fn(net)\n  return net\n\n\ndef inception_resnet_v2_base(inputs,\n                             final_endpoint=\'Conv2d_7b_1x1\',\n                             output_stride=16,\n                             align_feature_maps=False,\n                             scope=None,\n                             activation_fn=tf.nn.relu):\n  """"""Inception model from  http://arxiv.org/abs/1602.07261.\n\n  Constructs an Inception Resnet v2 network from inputs to the given final\n  endpoint. This method can construct the network up to the final inception\n  block Conv2d_7b_1x1.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    final_endpoint: specifies the endpoint to construct the network up to. It\n      can be one of [\'Conv2d_1a_3x3\', \'Conv2d_2a_3x3\', \'Conv2d_2b_3x3\',\n      \'MaxPool_3a_3x3\', \'Conv2d_3b_1x1\', \'Conv2d_4a_3x3\', \'MaxPool_5a_3x3\',\n      \'Mixed_5b\', \'Mixed_6a\', \'PreAuxLogits\', \'Mixed_7a\', \'Conv2d_7b_1x1\']\n    output_stride: A scalar that specifies the requested ratio of input to\n      output spatial resolution. Only supports 8 and 16.\n    align_feature_maps: When true, changes all the VALID paddings in the network\n      to SAME padding so that the feature maps are aligned.\n    scope: Optional variable_scope.\n    activation_fn: Activation function for block scopes.\n\n  Returns:\n    tensor_out: output tensor corresponding to the final_endpoint.\n    end_points: a set of activations for external use, for example summaries or\n                losses.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n      or if the output_stride is not 8 or 16, or if the output_stride is 8 and\n      we request an end point after \'PreAuxLogits\'.\n  """"""\n  if output_stride != 8 and output_stride != 16:\n    raise ValueError(\'output_stride must be 8 or 16.\')\n\n  padding = \'SAME\' if align_feature_maps else \'VALID\'\n\n  end_points = {}\n\n  def add_and_check_final(name, net):\n    end_points[name] = net\n    return name == final_endpoint\n\n  with tf.variable_scope(scope, \'InceptionResnetV2\', [inputs]):\n    with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n                        stride=1, padding=\'SAME\'):\n      # 149 x 149 x 32\n      net = slim.conv2d(inputs, 32, 3, stride=2, padding=padding,\n                        scope=\'Conv2d_1a_3x3\')\n      if add_and_check_final(\'Conv2d_1a_3x3\', net): return net, end_points\n\n      # 147 x 147 x 32\n      net = slim.conv2d(net, 32, 3, padding=padding,\n                        scope=\'Conv2d_2a_3x3\')\n      if add_and_check_final(\'Conv2d_2a_3x3\', net): return net, end_points\n      # 147 x 147 x 64\n      net = slim.conv2d(net, 64, 3, scope=\'Conv2d_2b_3x3\')\n      if add_and_check_final(\'Conv2d_2b_3x3\', net): return net, end_points\n      # 73 x 73 x 64\n      net = slim.max_pool2d(net, 3, stride=2, padding=padding,\n                            scope=\'MaxPool_3a_3x3\')\n      if add_and_check_final(\'MaxPool_3a_3x3\', net): return net, end_points\n      # 73 x 73 x 80\n      net = slim.conv2d(net, 80, 1, padding=padding,\n                        scope=\'Conv2d_3b_1x1\')\n      if add_and_check_final(\'Conv2d_3b_1x1\', net): return net, end_points\n      # 71 x 71 x 192\n      net = slim.conv2d(net, 192, 3, padding=padding,\n                        scope=\'Conv2d_4a_3x3\')\n      if add_and_check_final(\'Conv2d_4a_3x3\', net): return net, end_points\n      # 35 x 35 x 192\n      net = slim.max_pool2d(net, 3, stride=2, padding=padding,\n                            scope=\'MaxPool_5a_3x3\')\n      if add_and_check_final(\'MaxPool_5a_3x3\', net): return net, end_points\n\n      # 35 x 35 x 320\n      with tf.variable_scope(\'Mixed_5b\'):\n        with tf.variable_scope(\'Branch_0\'):\n          tower_conv = slim.conv2d(net, 96, 1, scope=\'Conv2d_1x1\')\n        with tf.variable_scope(\'Branch_1\'):\n          tower_conv1_0 = slim.conv2d(net, 48, 1, scope=\'Conv2d_0a_1x1\')\n          tower_conv1_1 = slim.conv2d(tower_conv1_0, 64, 5,\n                                      scope=\'Conv2d_0b_5x5\')\n        with tf.variable_scope(\'Branch_2\'):\n          tower_conv2_0 = slim.conv2d(net, 64, 1, scope=\'Conv2d_0a_1x1\')\n          tower_conv2_1 = slim.conv2d(tower_conv2_0, 96, 3,\n                                      scope=\'Conv2d_0b_3x3\')\n          tower_conv2_2 = slim.conv2d(tower_conv2_1, 96, 3,\n                                      scope=\'Conv2d_0c_3x3\')\n        with tf.variable_scope(\'Branch_3\'):\n          tower_pool = slim.avg_pool2d(net, 3, stride=1, padding=\'SAME\',\n                                       scope=\'AvgPool_0a_3x3\')\n          tower_pool_1 = slim.conv2d(tower_pool, 64, 1,\n                                     scope=\'Conv2d_0b_1x1\')\n        net = tf.concat(\n            [tower_conv, tower_conv1_1, tower_conv2_2, tower_pool_1], 3)\n\n      if add_and_check_final(\'Mixed_5b\', net): return net, end_points\n      # TODO(alemi): Register intermediate endpoints\n      net = slim.repeat(net, 10, block35, scale=0.17,\n                        activation_fn=activation_fn)\n\n      # 17 x 17 x 1088 if output_stride == 8,\n      # 33 x 33 x 1088 if output_stride == 16\n      use_atrous = output_stride == 8\n\n      with tf.variable_scope(\'Mixed_6a\'):\n        with tf.variable_scope(\'Branch_0\'):\n          tower_conv = slim.conv2d(net, 384, 3, stride=1 if use_atrous else 2,\n                                   padding=padding,\n                                   scope=\'Conv2d_1a_3x3\')\n        with tf.variable_scope(\'Branch_1\'):\n          tower_conv1_0 = slim.conv2d(net, 256, 1, scope=\'Conv2d_0a_1x1\')\n          tower_conv1_1 = slim.conv2d(tower_conv1_0, 256, 3,\n                                      scope=\'Conv2d_0b_3x3\')\n          tower_conv1_2 = slim.conv2d(tower_conv1_1, 384, 3,\n                                      stride=1 if use_atrous else 2,\n                                      padding=padding,\n                                      scope=\'Conv2d_1a_3x3\')\n        with tf.variable_scope(\'Branch_2\'):\n          tower_pool = slim.max_pool2d(net, 3, stride=1 if use_atrous else 2,\n                                       padding=padding,\n                                       scope=\'MaxPool_1a_3x3\')\n        net = tf.concat([tower_conv, tower_conv1_2, tower_pool], 3)\n\n      if add_and_check_final(\'Mixed_6a\', net): return net, end_points\n\n      # TODO(alemi): register intermediate endpoints\n      with slim.arg_scope([slim.conv2d], rate=2 if use_atrous else 1):\n        net = slim.repeat(net, 20, block17, scale=0.10,\n                          activation_fn=activation_fn)\n      if add_and_check_final(\'PreAuxLogits\', net): return net, end_points\n\n      if output_stride == 8:\n        # TODO(gpapan): Properly support output_stride for the rest of the net.\n        raise ValueError(\'output_stride==8 is only supported up to the \'\n                         \'PreAuxlogits end_point for now.\')\n\n      # 8 x 8 x 2080\n      with tf.variable_scope(\'Mixed_7a\'):\n        with tf.variable_scope(\'Branch_0\'):\n          tower_conv = slim.conv2d(net, 256, 1, scope=\'Conv2d_0a_1x1\')\n          tower_conv_1 = slim.conv2d(tower_conv, 384, 3, stride=2,\n                                     padding=padding,\n                                     scope=\'Conv2d_1a_3x3\')\n        with tf.variable_scope(\'Branch_1\'):\n          tower_conv1 = slim.conv2d(net, 256, 1, scope=\'Conv2d_0a_1x1\')\n          tower_conv1_1 = slim.conv2d(tower_conv1, 288, 3, stride=2,\n                                      padding=padding,\n                                      scope=\'Conv2d_1a_3x3\')\n        with tf.variable_scope(\'Branch_2\'):\n          tower_conv2 = slim.conv2d(net, 256, 1, scope=\'Conv2d_0a_1x1\')\n          tower_conv2_1 = slim.conv2d(tower_conv2, 288, 3,\n                                      scope=\'Conv2d_0b_3x3\')\n          tower_conv2_2 = slim.conv2d(tower_conv2_1, 320, 3, stride=2,\n                                      padding=padding,\n                                      scope=\'Conv2d_1a_3x3\')\n        with tf.variable_scope(\'Branch_3\'):\n          tower_pool = slim.max_pool2d(net, 3, stride=2,\n                                       padding=padding,\n                                       scope=\'MaxPool_1a_3x3\')\n        net = tf.concat(\n            [tower_conv_1, tower_conv1_1, tower_conv2_2, tower_pool], 3)\n\n      if add_and_check_final(\'Mixed_7a\', net): return net, end_points\n\n      # TODO(alemi): register intermediate endpoints\n      net = slim.repeat(net, 9, block8, scale=0.20, activation_fn=activation_fn)\n      net = block8(net, activation_fn=None)\n\n      # 8 x 8 x 1536\n      net = slim.conv2d(net, 1536, 1, scope=\'Conv2d_7b_1x1\')\n      if add_and_check_final(\'Conv2d_7b_1x1\', net): return net, end_points\n\n    raise ValueError(\'final_endpoint (%s) not recognized\', final_endpoint)\n\n\ndef inception_resnet_v2(inputs, num_classes=1001, is_training=True,\n                        dropout_keep_prob=0.8,\n                        reuse=None,\n                        scope=\'InceptionResnetV2\',\n                        create_aux_logits=True,\n                        activation_fn=tf.nn.relu):\n  """"""Creates the Inception Resnet V2 model.\n\n  Args:\n    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n      Dimension batch_size may be undefined. If create_aux_logits is false,\n      also height and width may be undefined.\n    num_classes: number of predicted classes. If 0 or None, the logits layer\n      is omitted and the input features to the logits layer (before  dropout)\n      are returned instead.\n    is_training: whether is training or not.\n    dropout_keep_prob: float, the fraction to keep before final layer.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse \'scope\' must be given.\n    scope: Optional variable_scope.\n    create_aux_logits: Whether to include the auxilliary logits.\n    activation_fn: Activation function for conv2d.\n\n  Returns:\n    net: the output of the logits layer (if num_classes is a non-zero integer),\n      or the non-dropped-out input to the logits layer (if num_classes is 0 or\n      None).\n    end_points: the set of end_points from the inception model.\n  """"""\n  end_points = {}\n\n  with tf.variable_scope(scope, \'InceptionResnetV2\', [inputs],\n                         reuse=reuse) as scope:\n    with slim.arg_scope([slim.batch_norm, slim.dropout],\n                        is_training=is_training):\n\n      net, end_points = inception_resnet_v2_base(inputs, scope=scope,\n                                                 activation_fn=activation_fn)\n\n      if create_aux_logits and num_classes:\n        with tf.variable_scope(\'AuxLogits\'):\n          aux = end_points[\'PreAuxLogits\']\n          aux = slim.avg_pool2d(aux, 5, stride=3, padding=\'VALID\',\n                                scope=\'Conv2d_1a_3x3\')\n          aux = slim.conv2d(aux, 128, 1, scope=\'Conv2d_1b_1x1\')\n          aux = slim.conv2d(aux, 768, aux.get_shape()[1:3],\n                            padding=\'VALID\', scope=\'Conv2d_2a_5x5\')\n          aux = slim.flatten(aux)\n          aux = slim.fully_connected(aux, num_classes, activation_fn=None,\n                                     scope=\'Logits\')\n          end_points[\'AuxLogits\'] = aux\n\n      with tf.variable_scope(\'Logits\'):\n        # TODO(sguada,arnoegw): Consider adding a parameter global_pool which\n        # can be set to False to disable pooling here (as in resnet_*()).\n        kernel_size = net.get_shape()[1:3]\n        if kernel_size.is_fully_defined():\n          net = slim.avg_pool2d(net, kernel_size, padding=\'VALID\',\n                                scope=\'AvgPool_1a_8x8\')\n        else:\n          net = tf.reduce_mean(net, [1, 2], keep_dims=True, name=\'global_pool\')\n        end_points[\'global_pool\'] = net\n        if not num_classes:\n          return net, end_points\n        net = slim.flatten(net)\n        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n                           scope=\'Dropout\')\n        end_points[\'PreLogitsFlatten\'] = net\n        logits = slim.fully_connected(net, num_classes, activation_fn=None,\n                                      scope=\'Logits\')\n        end_points[\'Logits\'] = logits\n        end_points[\'Predictions\'] = tf.nn.softmax(logits, name=\'Predictions\')\n\n    return logits, end_points\ninception_resnet_v2.default_image_size = 299\n\n\ndef inception_resnet_v2_arg_scope(weight_decay=0.00004,\n                                  batch_norm_decay=0.9997,\n                                  batch_norm_epsilon=0.001,\n                                  activation_fn=tf.nn.relu):\n  """"""Returns the scope with the default parameters for inception_resnet_v2.\n\n  Args:\n    weight_decay: the weight decay for weights variables.\n    batch_norm_decay: decay for the moving average of batch_norm momentums.\n    batch_norm_epsilon: small float added to variance to avoid dividing by zero.\n    activation_fn: Activation function for conv2d.\n\n  Returns:\n    a arg_scope with the parameters needed for inception_resnet_v2.\n  """"""\n  # Set weight_decay for weights in conv2d and fully_connected layers.\n  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n                      weights_regularizer=slim.l2_regularizer(weight_decay),\n                      biases_regularizer=slim.l2_regularizer(weight_decay)):\n\n    batch_norm_params = {\n        \'decay\': batch_norm_decay,\n        \'epsilon\': batch_norm_epsilon,\n        \'fused\': None,  # Use fused batch norm if possible.\n    }\n    # Set activation_fn and parameters for batch_norm.\n    with slim.arg_scope([slim.conv2d], activation_fn=activation_fn,\n                        normalizer_fn=slim.batch_norm,\n                        normalizer_params=batch_norm_params) as scope:\n      return scope\n'"
mmdnn/conversion/examples/tensorflow/models/mobilenet_v1.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n""""""MobileNet v1.\n\nMobileNet is a general architecture and can be used for multiple use cases.\nDepending on the use case, it can use different input layer size and different\nhead (for example: embeddings, localization and classification).\n\nAs described in https://arxiv.org/abs/1704.04861.\n\n  MobileNets: Efficient Convolutional Neural Networks for\n    Mobile Vision Applications\n  Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang,\n    Tobias Weyand, Marco Andreetto, Hartwig Adam\n\n100% Mobilenet V1 (base) with input size 224x224:\n\nSee mobilenet_v1()\n\nLayer                                                     params           macs\n--------------------------------------------------------------------------------\nMobilenetV1/Conv2d_0/Conv2D:                                 864      10,838,016\nMobilenetV1/Conv2d_1_depthwise/depthwise:                    288       3,612,672\nMobilenetV1/Conv2d_1_pointwise/Conv2D:                     2,048      25,690,112\nMobilenetV1/Conv2d_2_depthwise/depthwise:                    576       1,806,336\nMobilenetV1/Conv2d_2_pointwise/Conv2D:                     8,192      25,690,112\nMobilenetV1/Conv2d_3_depthwise/depthwise:                  1,152       3,612,672\nMobilenetV1/Conv2d_3_pointwise/Conv2D:                    16,384      51,380,224\nMobilenetV1/Conv2d_4_depthwise/depthwise:                  1,152         903,168\nMobilenetV1/Conv2d_4_pointwise/Conv2D:                    32,768      25,690,112\nMobilenetV1/Conv2d_5_depthwise/depthwise:                  2,304       1,806,336\nMobilenetV1/Conv2d_5_pointwise/Conv2D:                    65,536      51,380,224\nMobilenetV1/Conv2d_6_depthwise/depthwise:                  2,304         451,584\nMobilenetV1/Conv2d_6_pointwise/Conv2D:                   131,072      25,690,112\nMobilenetV1/Conv2d_7_depthwise/depthwise:                  4,608         903,168\nMobilenetV1/Conv2d_7_pointwise/Conv2D:                   262,144      51,380,224\nMobilenetV1/Conv2d_8_depthwise/depthwise:                  4,608         903,168\nMobilenetV1/Conv2d_8_pointwise/Conv2D:                   262,144      51,380,224\nMobilenetV1/Conv2d_9_depthwise/depthwise:                  4,608         903,168\nMobilenetV1/Conv2d_9_pointwise/Conv2D:                   262,144      51,380,224\nMobilenetV1/Conv2d_10_depthwise/depthwise:                 4,608         903,168\nMobilenetV1/Conv2d_10_pointwise/Conv2D:                  262,144      51,380,224\nMobilenetV1/Conv2d_11_depthwise/depthwise:                 4,608         903,168\nMobilenetV1/Conv2d_11_pointwise/Conv2D:                  262,144      51,380,224\nMobilenetV1/Conv2d_12_depthwise/depthwise:                 4,608         225,792\nMobilenetV1/Conv2d_12_pointwise/Conv2D:                  524,288      25,690,112\nMobilenetV1/Conv2d_13_depthwise/depthwise:                 9,216         451,584\nMobilenetV1/Conv2d_13_pointwise/Conv2D:                1,048,576      51,380,224\n--------------------------------------------------------------------------------\nTotal:                                                 3,185,088     567,716,352\n\n\n75% Mobilenet V1 (base) with input size 128x128:\n\nSee mobilenet_v1_075()\n\nLayer                                                     params           macs\n--------------------------------------------------------------------------------\nMobilenetV1/Conv2d_0/Conv2D:                                 648       2,654,208\nMobilenetV1/Conv2d_1_depthwise/depthwise:                    216         884,736\nMobilenetV1/Conv2d_1_pointwise/Conv2D:                     1,152       4,718,592\nMobilenetV1/Conv2d_2_depthwise/depthwise:                    432         442,368\nMobilenetV1/Conv2d_2_pointwise/Conv2D:                     4,608       4,718,592\nMobilenetV1/Conv2d_3_depthwise/depthwise:                    864         884,736\nMobilenetV1/Conv2d_3_pointwise/Conv2D:                     9,216       9,437,184\nMobilenetV1/Conv2d_4_depthwise/depthwise:                    864         221,184\nMobilenetV1/Conv2d_4_pointwise/Conv2D:                    18,432       4,718,592\nMobilenetV1/Conv2d_5_depthwise/depthwise:                  1,728         442,368\nMobilenetV1/Conv2d_5_pointwise/Conv2D:                    36,864       9,437,184\nMobilenetV1/Conv2d_6_depthwise/depthwise:                  1,728         110,592\nMobilenetV1/Conv2d_6_pointwise/Conv2D:                    73,728       4,718,592\nMobilenetV1/Conv2d_7_depthwise/depthwise:                  3,456         221,184\nMobilenetV1/Conv2d_7_pointwise/Conv2D:                   147,456       9,437,184\nMobilenetV1/Conv2d_8_depthwise/depthwise:                  3,456         221,184\nMobilenetV1/Conv2d_8_pointwise/Conv2D:                   147,456       9,437,184\nMobilenetV1/Conv2d_9_depthwise/depthwise:                  3,456         221,184\nMobilenetV1/Conv2d_9_pointwise/Conv2D:                   147,456       9,437,184\nMobilenetV1/Conv2d_10_depthwise/depthwise:                 3,456         221,184\nMobilenetV1/Conv2d_10_pointwise/Conv2D:                  147,456       9,437,184\nMobilenetV1/Conv2d_11_depthwise/depthwise:                 3,456         221,184\nMobilenetV1/Conv2d_11_pointwise/Conv2D:                  147,456       9,437,184\nMobilenetV1/Conv2d_12_depthwise/depthwise:                 3,456          55,296\nMobilenetV1/Conv2d_12_pointwise/Conv2D:                  294,912       4,718,592\nMobilenetV1/Conv2d_13_depthwise/depthwise:                 6,912         110,592\nMobilenetV1/Conv2d_13_pointwise/Conv2D:                  589,824       9,437,184\n--------------------------------------------------------------------------------\nTotal:                                                 1,800,144     106,002,432\n\n""""""\n\n# Tensorflow mandates these.\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom collections import namedtuple\nimport functools\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\n# Conv and DepthSepConv namedtuple define layers of the MobileNet architecture\n# Conv defines 3x3 convolution layers\n# DepthSepConv defines 3x3 depthwise convolution followed by 1x1 convolution.\n# stride is the stride of the convolution\n# depth is the number of channels or filters in a layer\nConv = namedtuple(\'Conv\', [\'kernel\', \'stride\', \'depth\'])\nDepthSepConv = namedtuple(\'DepthSepConv\', [\'kernel\', \'stride\', \'depth\'])\n\n# _CONV_DEFS specifies the MobileNet body\n_CONV_DEFS = [\n    Conv(kernel=[3, 3], stride=2, depth=32),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=64),\n    DepthSepConv(kernel=[3, 3], stride=2, depth=128),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=128),\n    DepthSepConv(kernel=[3, 3], stride=2, depth=256),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=256),\n    DepthSepConv(kernel=[3, 3], stride=2, depth=512),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n    DepthSepConv(kernel=[3, 3], stride=2, depth=1024),\n    DepthSepConv(kernel=[3, 3], stride=1, depth=1024)\n]\n\n\ndef mobilenet_v1_base(inputs,\n                      final_endpoint=\'Conv2d_13_pointwise\',\n                      min_depth=8,\n                      depth_multiplier=1.0,\n                      conv_defs=None,\n                      output_stride=None,\n                      scope=None):\n  """"""Mobilenet v1.\n\n  Constructs a Mobilenet v1 network from inputs to the given final endpoint.\n\n  Args:\n    inputs: a tensor of shape [batch_size, height, width, channels].\n    final_endpoint: specifies the endpoint to construct the network up to. It\n      can be one of [\'Conv2d_0\', \'Conv2d_1_pointwise\', \'Conv2d_2_pointwise\',\n      \'Conv2d_3_pointwise\', \'Conv2d_4_pointwise\', \'Conv2d_5\'_pointwise,\n      \'Conv2d_6_pointwise\', \'Conv2d_7_pointwise\', \'Conv2d_8_pointwise\',\n      \'Conv2d_9_pointwise\', \'Conv2d_10_pointwise\', \'Conv2d_11_pointwise\',\n      \'Conv2d_12_pointwise\', \'Conv2d_13_pointwise\'].\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    conv_defs: A list of ConvDef namedtuples specifying the net architecture.\n    output_stride: An integer that specifies the requested ratio of input to\n      output spatial resolution. If not None, then we invoke atrous convolution\n      if necessary to prevent the network from reducing the spatial resolution\n      of the activation maps. Allowed values are 8 (accurate fully convolutional\n      mode), 16 (fast fully convolutional mode), 32 (classification mode).\n    scope: Optional variable_scope.\n\n  Returns:\n    tensor_out: output tensor corresponding to the final_endpoint.\n    end_points: a set of activations for external use, for example summaries or\n                losses.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n                or depth_multiplier <= 0, or the target output_stride is not\n                allowed.\n  """"""\n  depth = lambda d: max(int(d * depth_multiplier), min_depth)\n  end_points = {}\n\n  # Used to find thinned depths for each layer.\n  if depth_multiplier <= 0:\n    raise ValueError(\'depth_multiplier is not greater than zero.\')\n\n  if conv_defs is None:\n    conv_defs = _CONV_DEFS\n\n  if output_stride is not None and output_stride not in [8, 16, 32]:\n    raise ValueError(\'Only allowed output_stride values are 8, 16, 32.\')\n\n  with tf.variable_scope(scope, \'MobilenetV1\', [inputs]):\n    with slim.arg_scope([slim.conv2d, slim.separable_conv2d], padding=\'SAME\'):\n      # The current_stride variable keeps track of the output stride of the\n      # activations, i.e., the running product of convolution strides up to the\n      # current network layer. This allows us to invoke atrous convolution\n      # whenever applying the next convolution would result in the activations\n      # having output stride larger than the target output_stride.\n      current_stride = 1\n\n      # The atrous convolution rate parameter.\n      rate = 1\n\n      net = inputs\n      for i, conv_def in enumerate(conv_defs):\n        end_point_base = \'Conv2d_%d\' % i\n\n        if output_stride is not None and current_stride == output_stride:\n          # If we have reached the target output_stride, then we need to employ\n          # atrous convolution with stride=1 and multiply the atrous rate by the\n          # current unit\'s stride for use in subsequent layers.\n          layer_stride = 1\n          layer_rate = rate\n          rate *= conv_def.stride\n        else:\n          layer_stride = conv_def.stride\n          layer_rate = 1\n          current_stride *= conv_def.stride\n\n        if isinstance(conv_def, Conv):\n          end_point = end_point_base\n          net = slim.conv2d(net, depth(conv_def.depth), conv_def.kernel,\n                            stride=conv_def.stride,\n                            normalizer_fn=slim.batch_norm,\n                            scope=end_point)\n          end_points[end_point] = net\n          if end_point == final_endpoint:\n            return net, end_points\n\n        elif isinstance(conv_def, DepthSepConv):\n          end_point = end_point_base + \'_depthwise\'\n\n          # By passing filters=None\n          # separable_conv2d produces only a depthwise convolution layer\n          net = slim.separable_conv2d(net, None, conv_def.kernel,\n                                      depth_multiplier=1,\n                                      stride=layer_stride,\n                                      rate=layer_rate,\n                                      normalizer_fn=slim.batch_norm,\n                                      scope=end_point)\n\n          end_points[end_point] = net\n          if end_point == final_endpoint:\n            return net, end_points\n\n          end_point = end_point_base + \'_pointwise\'\n\n          net = slim.conv2d(net, depth(conv_def.depth), [1, 1],\n                            stride=1,\n                            normalizer_fn=slim.batch_norm,\n                            scope=end_point)\n\n          end_points[end_point] = net\n          if end_point == final_endpoint:\n            return net, end_points\n        else:\n          raise ValueError(\'Unknown convolution type %s for layer %d\'\n                           % (conv_def.ltype, i))\n  raise ValueError(\'Unknown final endpoint %s\' % final_endpoint)\n\n\ndef mobilenet_v1(inputs,\n                 num_classes=1000,\n                 dropout_keep_prob=0.999,\n                 is_training=True,\n                 min_depth=8,\n                 depth_multiplier=1.0,\n                 conv_defs=None,\n                 prediction_fn=tf.contrib.layers.softmax,\n                 spatial_squeeze=True,\n                 reuse=None,\n                 scope=\'MobilenetV1\',\n                 global_pool=False):\n  """"""Mobilenet v1 model for classification.\n\n  Args:\n    inputs: a tensor of shape [batch_size, height, width, channels].\n    num_classes: number of predicted classes. If 0 or None, the logits layer\n      is omitted and the input features to the logits layer (before dropout)\n      are returned instead.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    is_training: whether is training or not.\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    conv_defs: A list of ConvDef namedtuples specifying the net architecture.\n    prediction_fn: a function to get predictions out of logits.\n    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse \'scope\' must be given.\n    scope: Optional variable_scope.\n    global_pool: Optional boolean flag to control the avgpooling before the\n      logits layer. If false or unset, pooling is done with a fixed window\n      that reduces default-sized inputs to 1x1, while larger inputs lead to\n      larger outputs. If true, any input size is pooled down to 1x1.\n\n  Returns:\n    net: a 2D Tensor with the logits (pre-softmax activations) if num_classes\n      is a non-zero integer, or the non-dropped-out input to the logits layer\n      if num_classes is 0 or None.\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n\n  Raises:\n    ValueError: Input rank is invalid.\n  """"""\n  input_shape = inputs.get_shape().as_list()\n  if len(input_shape) != 4:\n    raise ValueError(\'Invalid input tensor rank, expected 4, was: %d\' %\n                     len(input_shape))\n\n  with tf.variable_scope(scope, \'MobilenetV1\', [inputs], reuse=reuse) as scope:\n    with slim.arg_scope([slim.batch_norm, slim.dropout],\n                        is_training=is_training):\n      net, end_points = mobilenet_v1_base(inputs, scope=scope,\n                                          min_depth=min_depth,\n                                          depth_multiplier=depth_multiplier,\n                                          conv_defs=conv_defs)\n      with tf.variable_scope(\'Logits\'):\n        if global_pool:\n          # Global average pooling.\n          net = tf.reduce_mean(net, [1, 2], keep_dims=True, name=\'global_pool\')\n          end_points[\'global_pool\'] = net\n        else:\n          # Pooling with a fixed kernel size.\n          kernel_size = _reduced_kernel_size_for_small_input(net, [7, 7])\n          net = slim.avg_pool2d(net, kernel_size, padding=\'VALID\',\n                                scope=\'AvgPool_1a\')\n          end_points[\'AvgPool_1a\'] = net\n        if not num_classes:\n          return net, end_points\n        # 1 x 1 x 1024\n        net = slim.dropout(net, keep_prob=dropout_keep_prob, scope=\'Dropout_1b\')\n        logits = slim.conv2d(net, num_classes, [1, 1], activation_fn=None,\n                             normalizer_fn=None, scope=\'Conv2d_1c_1x1\')\n        if spatial_squeeze:\n          logits = tf.squeeze(logits, [1, 2], name=\'SpatialSqueeze\')\n      end_points[\'Logits\'] = logits\n      if prediction_fn:\n        end_points[\'Predictions\'] = prediction_fn(logits, scope=\'Predictions\')\n  return logits, end_points\n\nmobilenet_v1.default_image_size = 224\n\n\ndef wrapped_partial(func, *args, **kwargs):\n  partial_func = functools.partial(func, *args, **kwargs)\n  functools.update_wrapper(partial_func, func)\n  return partial_func\n\n\nmobilenet_v1_075 = wrapped_partial(mobilenet_v1, depth_multiplier=0.75)\nmobilenet_v1_050 = wrapped_partial(mobilenet_v1, depth_multiplier=0.50)\nmobilenet_v1_025 = wrapped_partial(mobilenet_v1, depth_multiplier=0.25)\n\n\ndef _reduced_kernel_size_for_small_input(input_tensor, kernel_size):\n  """"""Define kernel size which is automatically reduced for small input.\n\n  If the shape of the input images is unknown at graph construction time this\n  function assumes that the input images are large enough.\n\n  Args:\n    input_tensor: input tensor of size [batch_size, height, width, channels].\n    kernel_size: desired kernel size of length 2: [kernel_height, kernel_width]\n\n  Returns:\n    a tensor with the kernel size.\n  """"""\n  shape = input_tensor.get_shape().as_list()\n  if shape[1] is None or shape[2] is None:\n    kernel_size_out = kernel_size\n  else:\n    kernel_size_out = [min(shape[1], kernel_size[0]),\n                       min(shape[2], kernel_size[1])]\n  return kernel_size_out\n\n\ndef mobilenet_v1_arg_scope(is_training=True,\n                           weight_decay=0.00004,\n                           stddev=0.09,\n                           regularize_depthwise=False):\n  """"""Defines the default MobilenetV1 arg scope.\n\n  Args:\n    is_training: Whether or not we\'re training the model.\n    weight_decay: The weight decay to use for regularizing the model.\n    stddev: The standard deviation of the trunctated normal weight initializer.\n    regularize_depthwise: Whether or not apply regularization on depthwise.\n\n  Returns:\n    An `arg_scope` to use for the mobilenet v1 model.\n  """"""\n  batch_norm_params = {\n      \'is_training\': is_training,\n      \'center\': True,\n      \'scale\': True,\n      \'decay\': 0.9997,\n      \'epsilon\': 0.001,\n  }\n\n  # Set weight_decay for weights in Conv and DepthSepConv layers.\n  weights_init = tf.truncated_normal_initializer(stddev=stddev)\n  regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n  if regularize_depthwise:\n    depthwise_regularizer = regularizer\n  else:\n    depthwise_regularizer = None\n  with slim.arg_scope([slim.conv2d, slim.separable_conv2d],\n                      weights_initializer=weights_init,\n                      activation_fn=tf.nn.relu6, normalizer_fn=slim.batch_norm):\n    with slim.arg_scope([slim.batch_norm], **batch_norm_params):\n      with slim.arg_scope([slim.conv2d], weights_regularizer=regularizer):\n        with slim.arg_scope([slim.separable_conv2d],\n                            weights_regularizer=depthwise_regularizer) as sc:\n          return sc\n'"
mmdnn/conversion/examples/tensorflow/models/nasnet.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Contains the definition for the NASNet classification networks.\n\nPaper: https://arxiv.org/abs/1707.07012\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\nfrom . import nasnet_utils\n\narg_scope = tf.contrib.framework.arg_scope\nslim = tf.contrib.slim\n\n\n# Notes for training NASNet Cifar Model\n# -------------------------------------\n# batch_size: 32\n# learning rate: 0.025\n# cosine (single period) learning rate decay\n# auxiliary head loss weighting: 0.4\n# clip global norm of all gradients by 5\ndef _cifar_config(is_training=True):\n  drop_path_keep_prob = 1.0 if not is_training else 0.6\n  return tf.contrib.training.HParams(\n      stem_multiplier=3.0,\n      drop_path_keep_prob=drop_path_keep_prob,\n      num_cells=18,\n      use_aux_head=1,\n      num_conv_filters=32,\n      dense_dropout_keep_prob=1.0,\n      filter_scaling_rate=2.0,\n      num_reduction_layers=2,\n      data_format=\'NHWC\',\n      skip_reduction_layer_input=0,\n      # 600 epochs with a batch size of 32\n      # This is used for the drop path probabilities since it needs to increase\n      # the drop out probability over the course of training.\n      total_training_steps=937500,\n  )\n\n\n# Notes for training large NASNet model on ImageNet\n# -------------------------------------\n# batch size (per replica): 16\n# learning rate: 0.015 * 100\n# learning rate decay factor: 0.97\n# num epochs per decay: 2.4\n# sync sgd with 100 replicas\n# auxiliary head loss weighting: 0.4\n# label smoothing: 0.1\n# clip global norm of all gradients by 10\ndef _large_imagenet_config(is_training=True):\n  drop_path_keep_prob = 1.0 if not is_training else 0.7\n  return tf.contrib.training.HParams(\n      stem_multiplier=3.0,\n      dense_dropout_keep_prob=0.5,\n      num_cells=18,\n      filter_scaling_rate=2.0,\n      num_conv_filters=168,\n      drop_path_keep_prob=drop_path_keep_prob,\n      use_aux_head=1,\n      num_reduction_layers=2,\n      data_format=\'NHWC\',\n      skip_reduction_layer_input=1,\n      total_training_steps=250000,\n  )\n\n\n# Notes for training the mobile NASNet ImageNet model\n# -------------------------------------\n# batch size (per replica): 32\n# learning rate: 0.04 * 50\n# learning rate scaling factor: 0.97\n# num epochs per decay: 2.4\n# sync sgd with 50 replicas\n# auxiliary head weighting: 0.4\n# label smoothing: 0.1\n# clip global norm of all gradients by 10\ndef _mobile_imagenet_config():\n  return tf.contrib.training.HParams(\n      stem_multiplier=1.0,\n      dense_dropout_keep_prob=0.5,\n      num_cells=12,\n      filter_scaling_rate=2.0,\n      drop_path_keep_prob=1.0,\n      num_conv_filters=44,\n      use_aux_head=1,\n      num_reduction_layers=2,\n      data_format=\'NHWC\',\n      skip_reduction_layer_input=0,\n      total_training_steps=250000,\n  )\n\n\ndef nasnet_cifar_arg_scope(weight_decay=5e-4,\n                           batch_norm_decay=0.9,\n                           batch_norm_epsilon=1e-5):\n  """"""Defines the default arg scope for the NASNet-A Cifar model.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n    batch_norm_decay: Decay for batch norm moving average.\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\n      in batch norm.\n\n  Returns:\n    An `arg_scope` to use for the NASNet Cifar Model.\n  """"""\n  batch_norm_params = {\n      # Decay for the moving averages.\n      \'decay\': batch_norm_decay,\n      # epsilon to prevent 0s in variance.\n      \'epsilon\': batch_norm_epsilon,\n      \'scale\': True,\n      \'fused\': True,\n  }\n  weights_regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n  weights_initializer = tf.contrib.layers.variance_scaling_initializer(\n      mode=\'FAN_OUT\')\n  with arg_scope([slim.fully_connected, slim.conv2d, slim.separable_conv2d],\n                 weights_regularizer=weights_regularizer,\n                 weights_initializer=weights_initializer):\n    with arg_scope([slim.fully_connected],\n                   activation_fn=None, scope=\'FC\'):\n      with arg_scope([slim.conv2d, slim.separable_conv2d],\n                     activation_fn=None, biases_initializer=None):\n        with arg_scope([slim.batch_norm], **batch_norm_params) as sc:\n          return sc\n\n\ndef nasnet_mobile_arg_scope(weight_decay=4e-5,\n                            batch_norm_decay=0.9997,\n                            batch_norm_epsilon=1e-3):\n  """"""Defines the default arg scope for the NASNet-A Mobile ImageNet model.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n    batch_norm_decay: Decay for batch norm moving average.\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\n      in batch norm.\n\n  Returns:\n    An `arg_scope` to use for the NASNet Mobile Model.\n  """"""\n  batch_norm_params = {\n      # Decay for the moving averages.\n      \'decay\': batch_norm_decay,\n      # epsilon to prevent 0s in variance.\n      \'epsilon\': batch_norm_epsilon,\n      \'scale\': True,\n      \'fused\': True,\n  }\n  weights_regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n  weights_initializer = tf.contrib.layers.variance_scaling_initializer(\n      mode=\'FAN_OUT\')\n  with arg_scope([slim.fully_connected, slim.conv2d, slim.separable_conv2d],\n                 weights_regularizer=weights_regularizer,\n                 weights_initializer=weights_initializer):\n    with arg_scope([slim.fully_connected],\n                   activation_fn=None, scope=\'FC\'):\n      with arg_scope([slim.conv2d, slim.separable_conv2d],\n                     activation_fn=None, biases_initializer=None):\n        with arg_scope([slim.batch_norm], **batch_norm_params) as sc:\n          return sc\n\n\ndef nasnet_large_arg_scope(weight_decay=5e-5,\n                           batch_norm_decay=0.9997,\n                           batch_norm_epsilon=1e-3):\n  """"""Defines the default arg scope for the NASNet-A Large ImageNet model.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n    batch_norm_decay: Decay for batch norm moving average.\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\n      in batch norm.\n\n  Returns:\n    An `arg_scope` to use for the NASNet Large Model.\n  """"""\n  batch_norm_params = {\n      # Decay for the moving averages.\n      \'decay\': batch_norm_decay,\n      # epsilon to prevent 0s in variance.\n      \'epsilon\': batch_norm_epsilon,\n      \'scale\': True,\n      \'fused\': True,\n  }\n  weights_regularizer = tf.contrib.layers.l2_regularizer(weight_decay)\n  weights_initializer = tf.contrib.layers.variance_scaling_initializer(\n      mode=\'FAN_OUT\')\n  with arg_scope([slim.fully_connected, slim.conv2d, slim.separable_conv2d],\n                 weights_regularizer=weights_regularizer,\n                 weights_initializer=weights_initializer):\n    with arg_scope([slim.fully_connected],\n                   activation_fn=None, scope=\'FC\'):\n      with arg_scope([slim.conv2d, slim.separable_conv2d],\n                     activation_fn=None, biases_initializer=None):\n        with arg_scope([slim.batch_norm], **batch_norm_params) as sc:\n          return sc\n\n\ndef _build_aux_head(net, end_points, num_classes, hparams, scope):\n  """"""Auxiliary head used for all models across all datasets.""""""\n  with tf.variable_scope(scope):\n    aux_logits = tf.identity(net)\n    with tf.variable_scope(\'aux_logits\'):\n      aux_logits = slim.avg_pool2d(\n          aux_logits, [5, 5], stride=3, padding=\'VALID\')\n      aux_logits = slim.conv2d(aux_logits, 128, [1, 1], scope=\'proj\')\n      aux_logits = slim.batch_norm(aux_logits, scope=\'aux_bn0\')\n      aux_logits = tf.nn.relu(aux_logits)\n      # Shape of feature map before the final layer.\n      shape = aux_logits.shape\n      if hparams.data_format == \'NHWC\':\n        shape = shape[1:3]\n      else:\n        shape = shape[2:4]\n      aux_logits = slim.conv2d(aux_logits, 768, shape, padding=\'VALID\')\n      aux_logits = slim.batch_norm(aux_logits, scope=\'aux_bn1\')\n      aux_logits = tf.nn.relu(aux_logits)\n      aux_logits = tf.contrib.layers.flatten(aux_logits)\n      aux_logits = slim.fully_connected(aux_logits, num_classes)\n      end_points[\'AuxLogits\'] = aux_logits\n\n\ndef _imagenet_stem(inputs, hparams, stem_cell):\n  """"""Stem used for models trained on ImageNet.""""""\n  num_stem_cells = 2\n\n  # 149 x 149 x 32\n  num_stem_filters = int(32 * hparams.stem_multiplier)\n  net = slim.conv2d(\n      inputs, num_stem_filters, [3, 3], stride=2, scope=\'conv0\',\n      padding=\'VALID\')\n  net = slim.batch_norm(net, scope=\'conv0_bn\')\n\n  # Run the reduction cells\n  cell_outputs = [None, net]\n  filter_scaling = 1.0 / (hparams.filter_scaling_rate**num_stem_cells)\n  for cell_num in range(num_stem_cells):\n    net = stem_cell(\n        net,\n        scope=\'cell_stem_{}\'.format(cell_num),\n        filter_scaling=filter_scaling,\n        stride=2,\n        prev_layer=cell_outputs[-2],\n        cell_num=cell_num)\n    cell_outputs.append(net)\n    filter_scaling *= hparams.filter_scaling_rate\n  return net, cell_outputs\n\n\ndef _cifar_stem(inputs, hparams):\n  """"""Stem used for models trained on Cifar.""""""\n  num_stem_filters = int(hparams.num_conv_filters * hparams.stem_multiplier)\n  net = slim.conv2d(\n      inputs,\n      num_stem_filters,\n      3,\n      scope=\'l1_stem_3x3\')\n  net = slim.batch_norm(net, scope=\'l1_stem_bn\')\n  return net, [None, net]\n\n\ndef build_nasnet_cifar(\n    images, num_classes, is_training=True):\n  """"""Build NASNet model for the Cifar Dataset.""""""\n  hparams = _cifar_config(is_training=is_training)\n\n  if tf.test.is_gpu_available() and hparams.data_format == \'NHWC\':\n    tf.logging.info(\'A GPU is available on the machine, consider using NCHW \'\n                    \'data format for increased speed on GPU.\')\n\n  if hparams.data_format == \'NCHW\':\n    images = tf.transpose(images, [0, 3, 1, 2])\n\n  # Calculate the total number of cells in the network\n  # Add 2 for the reduction cells\n  total_num_cells = hparams.num_cells + 2\n\n  normal_cell = nasnet_utils.NasNetANormalCell(\n      hparams.num_conv_filters, hparams.drop_path_keep_prob,\n      total_num_cells, hparams.total_training_steps)\n  reduction_cell = nasnet_utils.NasNetAReductionCell(\n      hparams.num_conv_filters, hparams.drop_path_keep_prob,\n      total_num_cells, hparams.total_training_steps)\n  with arg_scope([slim.dropout, nasnet_utils.drop_path, slim.batch_norm],\n                 is_training=is_training):\n    with arg_scope([slim.avg_pool2d,\n                    slim.max_pool2d,\n                    slim.conv2d,\n                    slim.batch_norm,\n                    slim.separable_conv2d,\n                    nasnet_utils.factorized_reduction,\n                    nasnet_utils.global_avg_pool,\n                    nasnet_utils.get_channel_index,\n                    nasnet_utils.get_channel_dim],\n                   data_format=hparams.data_format):\n      return _build_nasnet_base(images,\n                                normal_cell=normal_cell,\n                                reduction_cell=reduction_cell,\n                                num_classes=num_classes,\n                                hparams=hparams,\n                                is_training=is_training,\n                                stem_type=\'cifar\')\nbuild_nasnet_cifar.default_image_size = 32\n\n\ndef build_nasnet_mobile(images, num_classes,\n                        is_training=True,\n                        final_endpoint=None):\n  """"""Build NASNet Mobile model for the ImageNet Dataset.""""""\n  hparams = _mobile_imagenet_config()\n\n  if tf.test.is_gpu_available() and hparams.data_format == \'NHWC\':\n    tf.logging.info(\'A GPU is available on the machine, consider using NCHW \'\n                    \'data format for increased speed on GPU.\')\n\n  if hparams.data_format == \'NCHW\':\n    images = tf.transpose(images, [0, 3, 1, 2])\n\n  # Calculate the total number of cells in the network\n  # Add 2 for the reduction cells\n  total_num_cells = hparams.num_cells + 2\n  # If ImageNet, then add an additional two for the stem cells\n  total_num_cells += 2\n\n  normal_cell = nasnet_utils.NasNetANormalCell(\n      hparams.num_conv_filters, hparams.drop_path_keep_prob,\n      total_num_cells, hparams.total_training_steps)\n  reduction_cell = nasnet_utils.NasNetAReductionCell(\n      hparams.num_conv_filters, hparams.drop_path_keep_prob,\n      total_num_cells, hparams.total_training_steps)\n  with arg_scope([slim.dropout, nasnet_utils.drop_path, slim.batch_norm],\n                 is_training=is_training):\n    with arg_scope([slim.avg_pool2d,\n                    slim.max_pool2d,\n                    slim.conv2d,\n                    slim.batch_norm,\n                    slim.separable_conv2d,\n                    nasnet_utils.factorized_reduction,\n                    nasnet_utils.global_avg_pool,\n                    nasnet_utils.get_channel_index,\n                    nasnet_utils.get_channel_dim],\n                   data_format=hparams.data_format):\n      return _build_nasnet_base(images,\n                                normal_cell=normal_cell,\n                                reduction_cell=reduction_cell,\n                                num_classes=num_classes,\n                                hparams=hparams,\n                                is_training=is_training,\n                                stem_type=\'imagenet\',\n                                final_endpoint=final_endpoint)\nbuild_nasnet_mobile.default_image_size = 224\n\n\ndef build_nasnet_large(images, num_classes,\n                       is_training=True,\n                       final_endpoint=None):\n  """"""Build NASNet Large model for the ImageNet Dataset.""""""\n  hparams = _large_imagenet_config(is_training=is_training)\n\n  if tf.test.is_gpu_available() and hparams.data_format == \'NHWC\':\n    tf.logging.info(\'A GPU is available on the machine, consider using NCHW \'\n                    \'data format for increased speed on GPU.\')\n\n  if hparams.data_format == \'NCHW\':\n    images = tf.transpose(images, [0, 3, 1, 2])\n\n  # Calculate the total number of cells in the network\n  # Add 2 for the reduction cells\n  total_num_cells = hparams.num_cells + 2\n  # If ImageNet, then add an additional two for the stem cells\n  total_num_cells += 2\n\n  normal_cell = nasnet_utils.NasNetANormalCell(\n      hparams.num_conv_filters, hparams.drop_path_keep_prob,\n      total_num_cells, hparams.total_training_steps)\n  reduction_cell = nasnet_utils.NasNetAReductionCell(\n      hparams.num_conv_filters, hparams.drop_path_keep_prob,\n      total_num_cells, hparams.total_training_steps)\n  with arg_scope([slim.dropout, nasnet_utils.drop_path, slim.batch_norm],\n                 is_training=is_training):\n    with arg_scope([slim.avg_pool2d,\n                    slim.max_pool2d,\n                    slim.conv2d,\n                    slim.batch_norm,\n                    slim.separable_conv2d,\n                    nasnet_utils.factorized_reduction,\n                    nasnet_utils.global_avg_pool,\n                    nasnet_utils.get_channel_index,\n                    nasnet_utils.get_channel_dim],\n                   data_format=hparams.data_format):\n      return _build_nasnet_base(images,\n                                normal_cell=normal_cell,\n                                reduction_cell=reduction_cell,\n                                num_classes=num_classes,\n                                hparams=hparams,\n                                is_training=is_training,\n                                stem_type=\'imagenet\',\n                                final_endpoint=final_endpoint)\nbuild_nasnet_large.default_image_size = 331\n\n\ndef _build_nasnet_base(images,\n                       normal_cell,\n                       reduction_cell,\n                       num_classes,\n                       hparams,\n                       is_training,\n                       stem_type,\n                       final_endpoint=None):\n  """"""Constructs a NASNet image model.""""""\n\n  end_points = {}\n  def add_and_check_endpoint(endpoint_name, net):\n    end_points[endpoint_name] = net\n    return final_endpoint and (endpoint_name == final_endpoint)\n\n  # Find where to place the reduction cells or stride normal cells\n  reduction_indices = nasnet_utils.calc_reduction_layers(\n      hparams.num_cells, hparams.num_reduction_layers)\n  stem_cell = reduction_cell\n\n  if stem_type == \'imagenet\':\n    stem = lambda: _imagenet_stem(images, hparams, stem_cell)\n  elif stem_type == \'cifar\':\n    stem = lambda: _cifar_stem(images, hparams)\n  else:\n    raise ValueError(\'Unknown stem_type: \', stem_type)\n  net, cell_outputs = stem()\n  if add_and_check_endpoint(\'Stem\', net): return net, end_points\n\n  # Setup for building in the auxiliary head.\n  aux_head_cell_idxes = []\n  if len(reduction_indices) >= 2:\n    aux_head_cell_idxes.append(reduction_indices[1] - 1)\n\n  # Run the cells\n  filter_scaling = 1.0\n  # true_cell_num accounts for the stem cells\n  true_cell_num = 2 if stem_type == \'imagenet\' else 0\n  for cell_num in range(hparams.num_cells):\n    stride = 1\n    if hparams.skip_reduction_layer_input:\n      prev_layer = cell_outputs[-2]\n    if cell_num in reduction_indices:\n      filter_scaling *= hparams.filter_scaling_rate\n      net = reduction_cell(\n          net,\n          scope=\'reduction_cell_{}\'.format(reduction_indices.index(cell_num)),\n          filter_scaling=filter_scaling,\n          stride=2,\n          prev_layer=cell_outputs[-2],\n          cell_num=true_cell_num)\n      if add_and_check_endpoint(\n          \'Reduction_Cell_{}\'.format(reduction_indices.index(cell_num)), net):\n        return net, end_points\n      true_cell_num += 1\n      cell_outputs.append(net)\n    if not hparams.skip_reduction_layer_input:\n      prev_layer = cell_outputs[-2]\n    net = normal_cell(\n        net,\n        scope=\'cell_{}\'.format(cell_num),\n        filter_scaling=filter_scaling,\n        stride=stride,\n        prev_layer=prev_layer,\n        cell_num=true_cell_num)\n\n    if add_and_check_endpoint(\'Cell_{}\'.format(cell_num), net):\n      return net, end_points\n    true_cell_num += 1\n    if (hparams.use_aux_head and cell_num in aux_head_cell_idxes and\n        num_classes and is_training):\n      aux_net = tf.nn.relu(net)\n      _build_aux_head(aux_net, end_points, num_classes, hparams,\n                      scope=\'aux_{}\'.format(cell_num))\n    cell_outputs.append(net)\n\n  # Final softmax layer\n  with tf.variable_scope(\'final_layer\'):\n    net = tf.nn.relu(net)\n    net = nasnet_utils.global_avg_pool(net)\n    if add_and_check_endpoint(\'global_pool\', net) or num_classes is None:\n      return net, end_points\n    net = slim.dropout(net, hparams.dense_dropout_keep_prob, scope=\'dropout\')\n    logits = slim.fully_connected(net, num_classes)\n\n    if add_and_check_endpoint(\'Logits\', logits):\n      return net, end_points\n\n    predictions = tf.nn.softmax(logits, name=\'predictions\')\n    if add_and_check_endpoint(\'Predictions\', predictions):\n      return net, end_points\n  return logits, end_points\n'"
mmdnn/conversion/examples/tensorflow/models/nasnet_utils.py,0,"b'# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""A custom module for some common operations used by NASNet.\n\nFunctions exposed in this file:\n- calc_reduction_layers\n- get_channel_index\n- get_channel_dim\n- global_avg_pool\n- factorized_reduction\n- drop_path\n\nClasses exposed in this file:\n- NasNetABaseCell\n- NasNetANormalCell\n- NasNetAReductionCell\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n\narg_scope = tf.contrib.framework.arg_scope\nslim = tf.contrib.slim\n\nDATA_FORMAT_NCHW = \'NCHW\'\nDATA_FORMAT_NHWC = \'NHWC\'\nINVALID = \'null\'\n\n\ndef calc_reduction_layers(num_cells, num_reduction_layers):\n  """"""Figure out what layers should have reductions.""""""\n  reduction_layers = []\n  for pool_num in range(1, num_reduction_layers + 1):\n    layer_num = (float(pool_num) / (num_reduction_layers + 1)) * num_cells\n    layer_num = int(layer_num)\n    reduction_layers.append(layer_num)\n  return reduction_layers\n\n\n@tf.contrib.framework.add_arg_scope\ndef get_channel_index(data_format=INVALID):\n  assert data_format != INVALID\n  axis = 3 if data_format == \'NHWC\' else 1\n  return axis\n\n\n@tf.contrib.framework.add_arg_scope\ndef get_channel_dim(shape, data_format=INVALID):\n  assert data_format != INVALID\n  assert len(shape) == 4\n  if data_format == \'NHWC\':\n    return int(shape[3])\n  elif data_format == \'NCHW\':\n    return int(shape[1])\n  else:\n    raise ValueError(\'Not a valid data_format\', data_format)\n\n\n@tf.contrib.framework.add_arg_scope\ndef global_avg_pool(x, data_format=INVALID):\n  """"""Average pool away the height and width spatial dimensions of x.""""""\n  assert data_format != INVALID\n  assert data_format in [\'NHWC\', \'NCHW\']\n  assert x.shape.ndims == 4\n  if data_format == \'NHWC\':\n    return tf.reduce_mean(x, [1, 2])\n  else:\n    return tf.reduce_mean(x, [2, 3])\n\n\n@tf.contrib.framework.add_arg_scope\ndef factorized_reduction(net, output_filters, stride, data_format=INVALID):\n  """"""Reduces the shape of net without information loss due to striding.""""""\n  assert output_filters % 2 == 0, (\n      \'Need even number of filters when using this factorized reduction.\')\n  assert data_format != INVALID\n  if stride == 1:\n    net = slim.conv2d(net, output_filters, 1, scope=\'path_conv\')\n    net = slim.batch_norm(net, scope=\'path_bn\')\n    return net\n  if data_format == \'NHWC\':\n    stride_spec = [1, stride, stride, 1]\n  else:\n    stride_spec = [1, 1, stride, stride]\n\n  # Skip path 1\n  path1 = tf.nn.avg_pool(\n      net, [1, 1, 1, 1], stride_spec, \'VALID\', data_format=data_format)\n  path1 = slim.conv2d(path1, int(output_filters / 2), 1, scope=\'path1_conv\')\n\n  # Skip path 2\n  # First pad with 0\'s on the right and bottom, then shift the filter to\n  # include those 0\'s that were added.\n  if data_format == \'NHWC\':\n    pad_arr = [[0, 0], [0, 1], [0, 1], [0, 0]]\n    path2 = tf.pad(net, pad_arr)[:, 1:, 1:, :]\n    concat_axis = 3\n  else:\n    pad_arr = [[0, 0], [0, 0], [0, 1], [0, 1]]\n    path2 = tf.pad(net, pad_arr)[:, :, 1:, 1:]\n    concat_axis = 1\n\n  path2 = tf.nn.avg_pool(\n      path2, [1, 1, 1, 1], stride_spec, \'VALID\', data_format=data_format)\n  path2 = slim.conv2d(path2, int(output_filters / 2), 1, scope=\'path2_conv\')\n\n  # Concat and apply BN\n  final_path = tf.concat(values=[path1, path2], axis=concat_axis)\n  final_path = slim.batch_norm(final_path, scope=\'final_path_bn\')\n  return final_path\n\n\n@tf.contrib.framework.add_arg_scope\ndef drop_path(net, keep_prob, is_training=True):\n  """"""Drops out a whole example hiddenstate with the specified probability.""""""\n  if is_training:\n    batch_size = tf.shape(net)[0]\n    noise_shape = [batch_size, 1, 1, 1]\n    random_tensor = keep_prob\n    random_tensor += tf.random_uniform(noise_shape, dtype=tf.float32)\n    binary_tensor = tf.floor(random_tensor)\n    net = tf.div(net, keep_prob) * binary_tensor\n  return net\n\n\ndef _operation_to_filter_shape(operation):\n  splitted_operation = operation.split(\'x\')\n  filter_shape = int(splitted_operation[0][-1])\n  assert filter_shape == int(\n      splitted_operation[1][0]), \'Rectangular filters not supported.\'\n  return filter_shape\n\n\ndef _operation_to_num_layers(operation):\n  splitted_operation = operation.split(\'_\')\n  if \'x\' in splitted_operation[-1]:\n    return 1\n  return int(splitted_operation[-1])\n\n\ndef _operation_to_info(operation):\n  """"""Takes in operation name and returns meta information.\n\n  An example would be \'separable_3x3_4\' -> (3, 4).\n\n  Args:\n    operation: String that corresponds to convolution operation.\n\n  Returns:\n    Tuple of (filter shape, num layers).\n  """"""\n  num_layers = _operation_to_num_layers(operation)\n  filter_shape = _operation_to_filter_shape(operation)\n  return num_layers, filter_shape\n\n\ndef _stacked_separable_conv(net, stride, operation, filter_size):\n  """"""Takes in an operations and parses it to the correct sep operation.""""""\n  num_layers, kernel_size = _operation_to_info(operation)\n  for layer_num in range(num_layers - 1):\n    net = tf.nn.relu(net)\n    net = slim.separable_conv2d(\n        net,\n        filter_size,\n        kernel_size,\n        depth_multiplier=1,\n        scope=\'separable_{0}x{0}_{1}\'.format(kernel_size, layer_num + 1),\n        stride=stride)\n    net = slim.batch_norm(\n        net, scope=\'bn_sep_{0}x{0}_{1}\'.format(kernel_size, layer_num + 1))\n    stride = 1\n  net = tf.nn.relu(net)\n  net = slim.separable_conv2d(\n      net,\n      filter_size,\n      kernel_size,\n      depth_multiplier=1,\n      scope=\'separable_{0}x{0}_{1}\'.format(kernel_size, num_layers),\n      stride=stride)\n  net = slim.batch_norm(\n      net, scope=\'bn_sep_{0}x{0}_{1}\'.format(kernel_size, num_layers))\n  return net\n\n\ndef _operation_to_pooling_type(operation):\n  """"""Takes in the operation string and returns the pooling type.""""""\n  splitted_operation = operation.split(\'_\')\n  return splitted_operation[0]\n\n\ndef _operation_to_pooling_shape(operation):\n  """"""Takes in the operation string and returns the pooling kernel shape.""""""\n  splitted_operation = operation.split(\'_\')\n  shape = splitted_operation[-1]\n  assert \'x\' in shape\n  filter_height, filter_width = shape.split(\'x\')\n  assert filter_height == filter_width\n  return int(filter_height)\n\n\ndef _operation_to_pooling_info(operation):\n  """"""Parses the pooling operation string to return its type and shape.""""""\n  pooling_type = _operation_to_pooling_type(operation)\n  pooling_shape = _operation_to_pooling_shape(operation)\n  return pooling_type, pooling_shape\n\n\ndef _pooling(net, stride, operation):\n  """"""Parses operation and performs the correct pooling operation on net.""""""\n  padding = \'SAME\'\n  pooling_type, pooling_shape = _operation_to_pooling_info(operation)\n  if pooling_type == \'avg\':\n    net = slim.avg_pool2d(net, pooling_shape, stride=stride, padding=padding)\n  elif pooling_type == \'max\':\n    net = slim.max_pool2d(net, pooling_shape, stride=stride, padding=padding)\n  else:\n    raise NotImplementedError(\'Unimplemented pooling type: \', pooling_type)\n  return net\n\n\nclass NasNetABaseCell(object):\n  """"""NASNet Cell class that is used as a \'layer\' in image architectures.\n\n  Args:\n    num_conv_filters: The number of filters for each convolution operation.\n    operations: List of operations that are performed in the NASNet Cell in\n      order.\n    used_hiddenstates: Binary array that signals if the hiddenstate was used\n      within the cell. This is used to determine what outputs of the cell\n      should be concatenated together.\n    hiddenstate_indices: Determines what hiddenstates should be combined\n      together with the specified operations to create the NASNet cell.\n  """"""\n\n  def __init__(self, num_conv_filters, operations, used_hiddenstates,\n               hiddenstate_indices, drop_path_keep_prob, total_num_cells,\n               total_training_steps):\n    self._num_conv_filters = num_conv_filters\n    self._operations = operations\n    self._used_hiddenstates = used_hiddenstates\n    self._hiddenstate_indices = hiddenstate_indices\n    self._drop_path_keep_prob = drop_path_keep_prob\n    self._total_num_cells = total_num_cells\n    self._total_training_steps = total_training_steps\n\n  def _reduce_prev_layer(self, prev_layer, curr_layer):\n    """"""Matches dimension of prev_layer to the curr_layer.""""""\n    # Set the prev layer to the current layer if it is none\n    if prev_layer is None:\n      return curr_layer\n    curr_num_filters = self._filter_size\n    prev_num_filters = get_channel_dim(prev_layer.shape)\n    curr_filter_shape = int(curr_layer.shape[2])\n    prev_filter_shape = int(prev_layer.shape[2])\n    if curr_filter_shape != prev_filter_shape:\n      prev_layer = tf.nn.relu(prev_layer)\n      prev_layer = factorized_reduction(\n          prev_layer, curr_num_filters, stride=2)\n    elif curr_num_filters != prev_num_filters:\n      prev_layer = tf.nn.relu(prev_layer)\n      prev_layer = slim.conv2d(\n          prev_layer, curr_num_filters, 1, scope=\'prev_1x1\')\n      prev_layer = slim.batch_norm(prev_layer, scope=\'prev_bn\')\n    return prev_layer\n\n  def _cell_base(self, net, prev_layer):\n    """"""Runs the beginning of the conv cell before the predicted ops are run.""""""\n    num_filters = self._filter_size\n\n    # Check to be sure prev layer stuff is setup correctly\n    prev_layer = self._reduce_prev_layer(prev_layer, net)\n\n    net = tf.nn.relu(net)\n    net = slim.conv2d(net, num_filters, 1, scope=\'1x1\')\n    net = slim.batch_norm(net, scope=\'beginning_bn\')\n    split_axis = get_channel_index()\n    net = tf.split(\n        axis=split_axis, num_or_size_splits=1, value=net)\n    for split in net:\n      assert int(split.shape[split_axis] == int(self._num_conv_filters *\n                                                self._filter_scaling))\n    net.append(prev_layer)\n    return net\n\n  def __call__(self, net, scope=None, filter_scaling=1, stride=1,\n               prev_layer=None, cell_num=-1):\n    """"""Runs the conv cell.""""""\n    self._cell_num = cell_num\n    self._filter_scaling = filter_scaling\n    self._filter_size = int(self._num_conv_filters * filter_scaling)\n\n    i = 0\n    with tf.variable_scope(scope):\n      net = self._cell_base(net, prev_layer)\n      for iteration in range(5):\n        with tf.variable_scope(\'comb_iter_{}\'.format(iteration)):\n          left_hiddenstate_idx, right_hiddenstate_idx = (\n              self._hiddenstate_indices[i],\n              self._hiddenstate_indices[i + 1])\n          original_input_left = left_hiddenstate_idx < 2\n          original_input_right = right_hiddenstate_idx < 2\n          h1 = net[left_hiddenstate_idx]\n          h2 = net[right_hiddenstate_idx]\n\n          operation_left = self._operations[i]\n          operation_right = self._operations[i+1]\n          i += 2\n          # Apply conv operations\n          with tf.variable_scope(\'left\'):\n            h1 = self._apply_conv_operation(h1, operation_left,\n                                            stride, original_input_left)\n          with tf.variable_scope(\'right\'):\n            h2 = self._apply_conv_operation(h2, operation_right,\n                                            stride, original_input_right)\n\n          # Combine hidden states using \'add\'.\n          with tf.variable_scope(\'combine\'):\n            h = h1 + h2\n\n          # Add hiddenstate to the list of hiddenstates we can choose from\n          net.append(h)\n\n      with tf.variable_scope(\'cell_output\'):\n        net = self._combine_unused_states(net)\n\n      return net\n\n  def _apply_conv_operation(self, net, operation,\n                            stride, is_from_original_input):\n    """"""Applies the predicted conv operation to net.""""""\n    # Dont stride if this is not one of the original hiddenstates\n    if stride > 1 and not is_from_original_input:\n      stride = 1\n    input_filters = get_channel_dim(net.shape)\n    filter_size = self._filter_size\n    if \'separable\' in operation:\n      net = _stacked_separable_conv(net, stride, operation, filter_size)\n    elif operation in [\'none\']:\n      # Check if a stride is needed, then use a strided 1x1 here\n      if stride > 1 or (input_filters != filter_size):\n        net = tf.nn.relu(net)\n        net = slim.conv2d(net, filter_size, 1, stride=stride, scope=\'1x1\')\n        net = slim.batch_norm(net, scope=\'bn_1\')\n    elif \'pool\' in operation:\n      net = _pooling(net, stride, operation)\n      if input_filters != filter_size:\n        net = slim.conv2d(net, filter_size, 1, stride=1, scope=\'1x1\')\n        net = slim.batch_norm(net, scope=\'bn_1\')\n    else:\n      raise ValueError(\'Unimplemented operation\', operation)\n\n    if operation != \'none\':\n      net = self._apply_drop_path(net)\n    return net\n\n  def _combine_unused_states(self, net):\n    """"""Concatenate the unused hidden states of the cell.""""""\n    used_hiddenstates = self._used_hiddenstates\n\n    final_height = int(net[-1].shape[2])\n    final_num_filters = get_channel_dim(net[-1].shape)\n    assert len(used_hiddenstates) == len(net)\n    for idx, used_h in enumerate(used_hiddenstates):\n      curr_height = int(net[idx].shape[2])\n      curr_num_filters = get_channel_dim(net[idx].shape)\n\n      # Determine if a reduction should be applied to make the number of\n      # filters match.\n      should_reduce = final_num_filters != curr_num_filters\n      should_reduce = (final_height != curr_height) or should_reduce\n      should_reduce = should_reduce and not used_h\n      if should_reduce:\n        stride = 2 if final_height != curr_height else 1\n        with tf.variable_scope(\'reduction_{}\'.format(idx)):\n          net[idx] = factorized_reduction(\n              net[idx], final_num_filters, stride)\n\n    states_to_combine = (\n        [h for h, is_used in zip(net, used_hiddenstates) if not is_used])\n\n    # Return the concat of all the states\n    concat_axis = get_channel_index()\n    net = tf.concat(values=states_to_combine, axis=concat_axis)\n    return net\n\n  def _apply_drop_path(self, net):\n    """"""Apply drop_path regularization to net.""""""\n    drop_path_keep_prob = self._drop_path_keep_prob\n    if drop_path_keep_prob < 1.0:\n      # Scale keep prob by layer number\n      assert self._cell_num != -1\n      # The added 2 is for the reduction cells\n      num_cells = self._total_num_cells\n      layer_ratio = (self._cell_num + 1)/float(num_cells)\n      with tf.device(\'/cpu:0\'):\n        tf.summary.scalar(\'layer_ratio\', layer_ratio)\n      drop_path_keep_prob = 1 - layer_ratio * (1 - drop_path_keep_prob)\n      # Decrease the keep probability over time\n      current_step = tf.cast(tf.train.get_or_create_global_step(),\n                             tf.float32)\n      drop_path_burn_in_steps = self._total_training_steps\n      current_ratio = (\n          current_step / drop_path_burn_in_steps)\n      current_ratio = tf.minimum(1.0, current_ratio)\n      with tf.device(\'/cpu:0\'):\n        tf.summary.scalar(\'current_ratio\', current_ratio)\n      drop_path_keep_prob = (\n          1 - current_ratio * (1 - drop_path_keep_prob))\n      with tf.device(\'/cpu:0\'):\n        tf.summary.scalar(\'drop_path_keep_prob\', drop_path_keep_prob)\n      net = drop_path(net, drop_path_keep_prob)\n    return net\n\n\nclass NasNetANormalCell(NasNetABaseCell):\n  """"""NASNetA Normal Cell.""""""\n\n  def __init__(self, num_conv_filters, drop_path_keep_prob, total_num_cells,\n               total_training_steps):\n    operations = [\'separable_5x5_2\',\n                  \'separable_3x3_2\',\n                  \'separable_5x5_2\',\n                  \'separable_3x3_2\',\n                  \'avg_pool_3x3\',\n                  \'none\',\n                  \'avg_pool_3x3\',\n                  \'avg_pool_3x3\',\n                  \'separable_3x3_2\',\n                  \'none\']\n    used_hiddenstates = [1, 0, 0, 0, 0, 0, 0]\n    hiddenstate_indices = [0, 1, 1, 1, 0, 1, 1, 1, 0, 0]\n    super(NasNetANormalCell, self).__init__(num_conv_filters, operations,\n                                            used_hiddenstates,\n                                            hiddenstate_indices,\n                                            drop_path_keep_prob,\n                                            total_num_cells,\n                                            total_training_steps)\n\n\nclass NasNetAReductionCell(NasNetABaseCell):\n  """"""NASNetA Reduction Cell.""""""\n\n  def __init__(self, num_conv_filters, drop_path_keep_prob, total_num_cells,\n               total_training_steps):\n    operations = [\'separable_5x5_2\',\n                  \'separable_7x7_2\',\n                  \'max_pool_3x3\',\n                  \'separable_7x7_2\',\n                  \'avg_pool_3x3\',\n                  \'separable_5x5_2\',\n                  \'none\',\n                  \'avg_pool_3x3\',\n                  \'separable_3x3_2\',\n                  \'max_pool_3x3\']\n    used_hiddenstates = [1, 1, 1, 0, 0, 0, 0]\n    hiddenstate_indices = [0, 1, 0, 1, 0, 1, 3, 2, 2, 0]\n    super(NasNetAReductionCell, self).__init__(num_conv_filters, operations,\n                                               used_hiddenstates,\n                                               hiddenstate_indices,\n                                               drop_path_keep_prob,\n                                               total_num_cells,\n                                               total_training_steps)\n'"
mmdnn/conversion/examples/tensorflow/models/test_rnn.py,0,"b""import numpy as np\nimport os\nimport sys\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\ndef create_symbol(X, num_classes=0, is_training=False, CUDNN=False, \n                  maxf=30000, edim=125, nhid=100, batchs=64):\n    word_vectors = tf.contrib.layers.embed_sequence(X, vocab_size=maxf, embed_dim=edim)\n    \n\n    word_list = tf.unstack(word_vectors, axis=1)\n    \n    if not CUDNN:\n        cell1 = tf.contrib.rnn.LSTMCell(nhid)\n        cell2 = tf.contrib.rnn.GRUCell(nhid)\n        stacked_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n        outputs, states = tf.nn.static_rnn(stacked_cell, word_list, dtype=tf.float32)\n        logits = tf.layers.dense(outputs[-1], 2, activation=None, name='output')\n    else:\n        # Using cuDNN since vanilla RNN\n        from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n        cudnn_cell = cudnn_rnn_ops.CudnnGRU(num_layers=1, \n                                            num_units=nhid, \n                                            input_size=edim, \n                                            input_mode='linear_input')\n        params_size_t = cudnn_cell.params_size()\n        params = tf.Variable(tf.random_uniform([params_size_t], -0.1, 0.1), validate_shape=False)   \n        input_h = tf.Variable(tf.zeros([1, batchs, nhid]))\n        outputs, states = cudnn_cell(input_data=word_list,\n                                     input_h=input_h,\n                                     params=params)\n        logits = tf.layers.dense(outputs[-1], 2, activation=None, name='output')\n    \n    return logits, logits\n\ndef dummy_arg_scope():\n    with slim.arg_scope([]) as sc:\n        return sc"""
mmdnn/conversion/examples/tensorflow/models/mobilenet/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n'
mmdnn/conversion/examples/tensorflow/models/mobilenet/conv_blocks.py,0,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Convolution blocks for mobilenet.""""""\nimport contextlib\nimport functools\n\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\n\ndef _fixed_padding(inputs, kernel_size, rate=1):\n  """"""Pads the input along the spatial dimensions independently of input size.\n\n  Pads the input such that if it was used in a convolution with \'VALID\' padding,\n  the output would have the same dimensions as if the unpadded input was used\n  in a convolution with \'SAME\' padding.\n\n  Args:\n    inputs: A tensor of size [batch, height_in, width_in, channels].\n    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n    rate: An integer, rate for atrous convolution.\n\n  Returns:\n    output: A tensor of size [batch, height_out, width_out, channels] with the\n      input, either intact (if kernel_size == 1) or padded (if kernel_size > 1).\n  """"""\n  kernel_size_effective = [kernel_size[0] + (kernel_size[0] - 1) * (rate - 1),\n                           kernel_size[0] + (kernel_size[0] - 1) * (rate - 1)]\n  pad_total = [kernel_size_effective[0] - 1, kernel_size_effective[1] - 1]\n  pad_beg = [pad_total[0] // 2, pad_total[1] // 2]\n  pad_end = [pad_total[0] - pad_beg[0], pad_total[1] - pad_beg[1]]\n  padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg[0], pad_end[0]],\n                                  [pad_beg[1], pad_end[1]], [0, 0]])\n  return padded_inputs\n\n\ndef _make_divisible(v, divisor, min_value=None):\n  if min_value is None:\n    min_value = divisor\n  new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n  # Make sure that round down does not go down by more than 10%.\n  if new_v < 0.9 * v:\n    new_v += divisor\n  return new_v\n\n\ndef _split_divisible(num, num_ways, divisible_by=8):\n  """"""Evenly splits num, num_ways so each piece is a multiple of divisible_by.""""""\n  assert num % divisible_by == 0\n  assert num / num_ways >= divisible_by\n  # Note: want to round down, we adjust each split to match the total.\n  base = num // num_ways // divisible_by * divisible_by\n  result = []\n  accumulated = 0\n  for i in range(num_ways):\n    r = base\n    while accumulated + r < num * (i + 1) / num_ways:\n      r += divisible_by\n    result.append(r)\n    accumulated += r\n  assert accumulated == num\n  return result\n\n\n@contextlib.contextmanager\ndef _v1_compatible_scope_naming(scope):\n  if scope is None:  # Create uniqified separable blocks.\n    with tf.variable_scope(None, default_name=\'separable\') as s, \\\n         tf.name_scope(s.original_name_scope):\n      yield \'\'\n  else:\n    # We use scope_depthwise, scope_pointwise for compatibility with V1 ckpts.\n    # which provide numbered scopes.\n    scope += \'_\'\n    yield scope\n\n\n@slim.add_arg_scope\ndef split_separable_conv2d(input_tensor,\n                           num_outputs,\n                           scope=None,\n                           normalizer_fn=None,\n                           stride=1,\n                           rate=1,\n                           endpoints=None,\n                           use_explicit_padding=False):\n  """"""Separable mobilenet V1 style convolution.\n\n  Depthwise convolution, with default non-linearity,\n  followed by 1x1 depthwise convolution.  This is similar to\n  slim.separable_conv2d, but differs in tha it applies batch\n  normalization and non-linearity to depthwise. This  matches\n  the basic building of Mobilenet Paper\n  (https://arxiv.org/abs/1704.04861)\n\n  Args:\n    input_tensor: input\n    num_outputs: number of outputs\n    scope: optional name of the scope. Note if provided it will use\n    scope_depthwise for deptwhise, and scope_pointwise for pointwise.\n    normalizer_fn: which normalizer function to use for depthwise/pointwise\n    stride: stride\n    rate: output rate (also known as dilation rate)\n    endpoints: optional, if provided, will export additional tensors to it.\n    use_explicit_padding: Use \'VALID\' padding for convolutions, but prepad\n      inputs so that the output dimensions are the same as if \'SAME\' padding\n      were used.\n\n  Returns:\n    output tesnor\n  """"""\n\n  with _v1_compatible_scope_naming(scope) as scope:\n    dw_scope = scope + \'depthwise\'\n    endpoints = endpoints if endpoints is not None else {}\n    kernel_size = [3, 3]\n    padding = \'SAME\'\n    if use_explicit_padding:\n      padding = \'VALID\'\n      input_tensor = _fixed_padding(input_tensor, kernel_size, rate)\n    net = slim.separable_conv2d(\n        input_tensor,\n        None,\n        kernel_size,\n        depth_multiplier=1,\n        stride=stride,\n        rate=rate,\n        normalizer_fn=normalizer_fn,\n        padding=padding,\n        scope=dw_scope)\n\n    endpoints[dw_scope] = net\n\n    pw_scope = scope + \'pointwise\'\n    net = slim.conv2d(\n        net,\n        num_outputs, [1, 1],\n        stride=1,\n        normalizer_fn=normalizer_fn,\n        scope=pw_scope)\n    endpoints[pw_scope] = net\n  return net\n\n\ndef expand_input_by_factor(n, divisible_by=8):\n  return lambda num_inputs, **_: _make_divisible(num_inputs * n, divisible_by)\n\n\n@slim.add_arg_scope\ndef expanded_conv(input_tensor,\n                  num_outputs,\n                  expansion_size=expand_input_by_factor(6),\n                  stride=1,\n                  rate=1,\n                  kernel_size=(3, 3),\n                  residual=True,\n                  normalizer_fn=None,\n                  split_projection=1,\n                  split_expansion=1,\n                  expansion_transform=None,\n                  depthwise_location=\'expansion\',\n                  depthwise_channel_multiplier=1,\n                  endpoints=None,\n                  use_explicit_padding=False,\n                  padding=\'SAME\',\n                  scope=None):\n  """"""Depthwise Convolution Block with expansion.\n\n  Builds a composite convolution that has the following structure\n  expansion (1x1) -> depthwise (kernel_size) -> projection (1x1)\n\n  Args:\n    input_tensor: input\n    num_outputs: number of outputs in the final layer.\n    expansion_size: the size of expansion, could be a constant or a callable.\n      If latter it will be provided \'num_inputs\' as an input. For forward\n      compatibility it should accept arbitrary keyword arguments.\n      Default will expand the input by factor of 6.\n    stride: depthwise stride\n    rate: depthwise rate\n    kernel_size: depthwise kernel\n    residual: whether to include residual connection between input\n      and output.\n    normalizer_fn: batchnorm or otherwise\n    split_projection: how many ways to split projection operator\n      (that is conv expansion->bottleneck)\n    split_expansion: how many ways to split expansion op\n      (that is conv bottleneck->expansion) ops will keep depth divisible\n      by this value.\n    expansion_transform: Optional function that takes expansion\n      as a single input and returns output.\n    depthwise_location: where to put depthwise covnvolutions supported\n      values None, \'input\', \'output\', \'expansion\'\n    depthwise_channel_multiplier: depthwise channel multiplier:\n    each input will replicated (with different filters)\n    that many times. So if input had c channels,\n    output will have c x depthwise_channel_multpilier.\n    endpoints: An optional dictionary into which intermediate endpoints are\n      placed. The keys ""expansion_output"", ""depthwise_output"",\n      ""projection_output"" and ""expansion_transform"" are always populated, even\n      if the corresponding functions are not invoked.\n    use_explicit_padding: Use \'VALID\' padding for convolutions, but prepad\n      inputs so that the output dimensions are the same as if \'SAME\' padding\n      were used.\n    padding: Padding type to use if `use_explicit_padding` is not set.\n    scope: optional scope.\n\n  Returns:\n    Tensor of depth num_outputs\n\n  Raises:\n    TypeError: on inval\n  """"""\n  with tf.variable_scope(scope, default_name=\'expanded_conv\') as s, \\\n       tf.name_scope(s.original_name_scope):\n    prev_depth = input_tensor.get_shape().as_list()[3]\n    if  depthwise_location not in [None, \'input\', \'output\', \'expansion\']:\n      raise TypeError(\'%r is unknown value for depthwise_location\' %\n                      depthwise_location)\n    if use_explicit_padding:\n      if padding != \'SAME\':\n        raise TypeError(\'`use_explicit_padding` should only be used with \'\n                        \'""SAME"" padding.\')\n      padding = \'VALID\'\n    depthwise_func = functools.partial(\n        slim.separable_conv2d,\n        num_outputs=None,\n        kernel_size=kernel_size,\n        depth_multiplier=depthwise_channel_multiplier,\n        stride=stride,\n        rate=rate,\n        normalizer_fn=normalizer_fn,\n        padding=padding,\n        scope=\'depthwise\')\n    # b1 -> b2 * r -> b2\n    #   i -> (o * r) (bottleneck) -> o\n    input_tensor = tf.identity(input_tensor, \'input\')\n    net = input_tensor\n\n    if depthwise_location == \'input\':\n      if use_explicit_padding:\n        net = _fixed_padding(net, kernel_size, rate)\n      net = depthwise_func(net, activation_fn=None)\n\n    if callable(expansion_size):\n      inner_size = expansion_size(num_inputs=prev_depth)\n    else:\n      inner_size = expansion_size\n\n    if inner_size > net.shape[3]:\n      net = split_conv(\n          net,\n          inner_size,\n          num_ways=split_expansion,\n          scope=\'expand\',\n          stride=1,\n          normalizer_fn=normalizer_fn)\n      net = tf.identity(net, \'expansion_output\')\n    if endpoints is not None:\n      endpoints[\'expansion_output\'] = net\n\n    if depthwise_location == \'expansion\':\n      if use_explicit_padding:\n        net = _fixed_padding(net, kernel_size, rate)\n      net = depthwise_func(net)\n\n    net = tf.identity(net, name=\'depthwise_output\')\n    if endpoints is not None:\n      endpoints[\'depthwise_output\'] = net\n    if expansion_transform:\n      net = expansion_transform(expansion_tensor=net, input_tensor=input_tensor)\n    # Note in contrast with expansion, we always have\n    # projection to produce the desired output size.\n    net = split_conv(\n        net,\n        num_outputs,\n        num_ways=split_projection,\n        stride=1,\n        scope=\'project\',\n        normalizer_fn=normalizer_fn,\n        activation_fn=tf.identity)\n    if endpoints is not None:\n      endpoints[\'projection_output\'] = net\n    if depthwise_location == \'output\':\n      if use_explicit_padding:\n        net = _fixed_padding(net, kernel_size, rate)\n      net = depthwise_func(net, activation_fn=None)\n\n    if callable(residual):  # custom residual\n      net = residual(input_tensor=input_tensor, output_tensor=net)\n    elif (residual and\n          # stride check enforces that we don\'t add residuals when spatial\n          # dimensions are None\n          stride == 1 and\n          # Depth matches\n          net.get_shape().as_list()[3] ==\n          input_tensor.get_shape().as_list()[3]):\n      net += input_tensor\n    return tf.identity(net, name=\'output\')\n\n\ndef split_conv(input_tensor,\n               num_outputs,\n               num_ways,\n               scope,\n               divisible_by=8,\n               **kwargs):\n  """"""Creates a split convolution.\n\n  Split convolution splits the input and output into\n  \'num_blocks\' blocks of approximately the same size each,\n  and only connects $i$-th input to $i$ output.\n\n  Args:\n    input_tensor: input tensor\n    num_outputs: number of output filters\n    num_ways: num blocks to split by.\n    scope: scope for all the operators.\n    divisible_by: make sure that every part is divisiable by this.\n    **kwargs: will be passed directly into conv2d operator\n  Returns:\n    tensor\n  """"""\n  b = input_tensor.get_shape().as_list()[3]\n\n  if num_ways == 1 or min(b // num_ways,\n                          num_outputs // num_ways) < divisible_by:\n    # Don\'t do any splitting if we end up with less than 8 filters\n    # on either side.\n    return slim.conv2d(input_tensor, num_outputs, [1, 1], scope=scope, **kwargs)\n\n  outs = []\n  input_splits = _split_divisible(b, num_ways, divisible_by=divisible_by)\n  output_splits = _split_divisible(\n      num_outputs, num_ways, divisible_by=divisible_by)\n  inputs = tf.split(input_tensor, input_splits, axis=3, name=\'split_\' + scope)\n  base = scope\n  for i, (input_tensor, out_size) in enumerate(zip(inputs, output_splits)):\n    scope = base + \'_part_%d\' % (i,)\n    n = slim.conv2d(input_tensor, out_size, [1, 1], scope=scope, **kwargs)\n    n = tf.identity(n, scope + \'_output\')\n    outs.append(n)\n  return tf.concat(outs, 3, name=scope + \'_concat\')\n'"
mmdnn/conversion/examples/tensorflow/models/mobilenet/mobilenet.py,0,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Mobilenet Base Class.""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport collections\nimport contextlib\nimport copy\nimport os\n\nimport tensorflow as tf\n\n\nslim = tf.contrib.slim\n\n\n@slim.add_arg_scope\ndef apply_activation(x, name=None, activation_fn=None):\n  return activation_fn(x, name=name) if activation_fn else x\n\n\ndef _fixed_padding(inputs, kernel_size, rate=1):\n  """"""Pads the input along the spatial dimensions independently of input size.\n\n  Pads the input such that if it was used in a convolution with \'VALID\' padding,\n  the output would have the same dimensions as if the unpadded input was used\n  in a convolution with \'SAME\' padding.\n\n  Args:\n    inputs: A tensor of size [batch, height_in, width_in, channels].\n    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n    rate: An integer, rate for atrous convolution.\n\n  Returns:\n    output: A tensor of size [batch, height_out, width_out, channels] with the\n      input, either intact (if kernel_size == 1) or padded (if kernel_size > 1).\n  """"""\n  kernel_size_effective = [kernel_size[0] + (kernel_size[0] - 1) * (rate - 1),\n                           kernel_size[0] + (kernel_size[0] - 1) * (rate - 1)]\n  pad_total = [kernel_size_effective[0] - 1, kernel_size_effective[1] - 1]\n  pad_beg = [pad_total[0] // 2, pad_total[1] // 2]\n  pad_end = [pad_total[0] - pad_beg[0], pad_total[1] - pad_beg[1]]\n  padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg[0], pad_end[0]],\n                                  [pad_beg[1], pad_end[1]], [0, 0]])\n  return padded_inputs\n\n\ndef _make_divisible(v, divisor, min_value=None):\n  if min_value is None:\n    min_value = divisor\n  new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n  # Make sure that round down does not go down by more than 10%.\n  if new_v < 0.9 * v:\n    new_v += divisor\n  return new_v\n\n\n@contextlib.contextmanager\ndef _set_arg_scope_defaults(defaults):\n  """"""Sets arg scope defaults for all items present in defaults.\n\n  Args:\n    defaults: dictionary/list of pairs, containing a mapping from\n    function to a dictionary of default args.\n\n  Yields:\n    context manager where all defaults are set.\n  """"""\n  if hasattr(defaults, \'items\'):\n    items = list(defaults.items())\n  else:\n    items = defaults\n  if not items:\n    yield\n  else:\n    func, default_arg = items[0]\n    with slim.arg_scope(func, **default_arg):\n      with _set_arg_scope_defaults(items[1:]):\n        yield\n\n\n@slim.add_arg_scope\ndef depth_multiplier(output_params,\n                     multiplier,\n                     divisible_by=8,\n                     min_depth=8,\n                     **unused_kwargs):\n  if \'num_outputs\' not in output_params:\n    return\n  d = output_params[\'num_outputs\']\n  output_params[\'num_outputs\'] = _make_divisible(d * multiplier, divisible_by,\n                                                 min_depth)\n\n\n_Op = collections.namedtuple(\'Op\', [\'op\', \'params\', \'multiplier_func\'])\n\n\ndef op(opfunc, **params):\n  multiplier = params.pop(\'multiplier_transorm\', depth_multiplier)\n  return _Op(opfunc, params=params, multiplier_func=multiplier)\n\n\nclass NoOpScope(object):\n  """"""No-op context manager.""""""\n\n  def __enter__(self):\n    return None\n\n  def __exit__(self, exc_type, exc_value, traceback):\n    return False\n\n\ndef safe_arg_scope(funcs, **kwargs):\n  """"""Returns `slim.arg_scope` with all None arguments removed.\n\n  Arguments:\n    funcs: Functions to pass to `arg_scope`.\n    **kwargs: Arguments to pass to `arg_scope`.\n\n  Returns:\n    arg_scope or No-op context manager.\n\n  Note: can be useful if None value should be interpreted as ""do not overwrite\n    this parameter value"".\n  """"""\n  filtered_args = {name: value for name, value in kwargs.items()\n                   if value is not None}\n  if filtered_args:\n    return slim.arg_scope(funcs, **filtered_args)\n  else:\n    return NoOpScope()\n\n\n@slim.add_arg_scope\ndef mobilenet_base(  # pylint: disable=invalid-name\n    inputs,\n    conv_defs,\n    multiplier=1.0,\n    final_endpoint=None,\n    output_stride=None,\n    use_explicit_padding=False,\n    scope=None,\n    is_training=False):\n  """"""Mobilenet base network.\n\n  Constructs a network from inputs to the given final endpoint. By default\n  the network is constructed in inference mode. To create network\n  in training mode use:\n\n  with slim.arg_scope(mobilenet.training_scope()):\n     logits, endpoints = mobilenet_base(...)\n\n  Args:\n    inputs: a tensor of shape [batch_size, height, width, channels].\n    conv_defs: A list of op(...) layers specifying the net architecture.\n    multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    final_endpoint: The name of last layer, for early termination for\n    for V1-based networks: last layer is ""layer_14"", for V2: ""layer_20""\n    output_stride: An integer that specifies the requested ratio of input to\n      output spatial resolution. If not None, then we invoke atrous convolution\n      if necessary to prevent the network from reducing the spatial resolution\n      of the activation maps. Allowed values are 1 or any even number, excluding\n      zero. Typical values are 8 (accurate fully convolutional mode), 16\n      (fast fully convolutional mode), and 32 (classification mode).\n\n      NOTE- output_stride relies on all consequent operators to support dilated\n      operators via ""rate"" parameter. This might require wrapping non-conv\n      operators to operate properly.\n\n    use_explicit_padding: Use \'VALID\' padding for convolutions, but prepad\n      inputs so that the output dimensions are the same as if \'SAME\' padding\n      were used.\n    scope: optional variable scope.\n    is_training: How to setup batch_norm and other ops. Note: most of the time\n      this does not need be set directly. Use mobilenet.training_scope() to set\n      up training instead. This parameter is here for backward compatibility\n      only. It is safe to set it to the value matching\n      training_scope(is_training=...). It is also safe to explicitly set\n      it to False, even if there is outer training_scope set to to training.\n      (The network will be built in inference mode). If this is set to None,\n      no arg_scope is added for slim.batch_norm\'s is_training parameter.\n\n  Returns:\n    tensor_out: output tensor.\n    end_points: a set of activations for external use, for example summaries or\n                losses.\n\n  Raises:\n    ValueError: depth_multiplier <= 0, or the target output_stride is not\n                allowed.\n  """"""\n  if multiplier <= 0:\n    raise ValueError(\'multiplier is not greater than zero.\')\n\n  # Set conv defs defaults and overrides.\n  conv_defs_defaults = conv_defs.get(\'defaults\', {})\n  conv_defs_overrides = conv_defs.get(\'overrides\', {})\n  if use_explicit_padding:\n    conv_defs_overrides = copy.deepcopy(conv_defs_overrides)\n    conv_defs_overrides[\n        (slim.conv2d, slim.separable_conv2d)] = {\'padding\': \'VALID\'}\n\n  if output_stride is not None:\n    if output_stride == 0 or (output_stride > 1 and output_stride % 2):\n      raise ValueError(\'Output stride must be None, 1 or a multiple of 2.\')\n\n  # a) Set the tensorflow scope\n  # b) set padding to default: note we might consider removing this\n  # since it is also set by mobilenet_scope\n  # c) set all defaults\n  # d) set all extra overrides.\n  with _scope_all(scope, default_scope=\'Mobilenet\'), \\\n      safe_arg_scope([slim.batch_norm], is_training=is_training), \\\n      _set_arg_scope_defaults(conv_defs_defaults), \\\n      _set_arg_scope_defaults(conv_defs_overrides):\n    # The current_stride variable keeps track of the output stride of the\n    # activations, i.e., the running product of convolution strides up to the\n    # current network layer. This allows us to invoke atrous convolution\n    # whenever applying the next convolution would result in the activations\n    # having output stride larger than the target output_stride.\n    current_stride = 1\n\n    # The atrous convolution rate parameter.\n    rate = 1\n\n    net = inputs\n    # Insert default parameters before the base scope which includes\n    # any custom overrides set in mobilenet.\n    end_points = {}\n    scopes = {}\n    for i, opdef in enumerate(conv_defs[\'spec\']):\n      params = dict(opdef.params)\n      opdef.multiplier_func(params, multiplier)\n      stride = params.get(\'stride\', 1)\n      if output_stride is not None and current_stride == output_stride:\n        # If we have reached the target output_stride, then we need to employ\n        # atrous convolution with stride=1 and multiply the atrous rate by the\n        # current unit\'s stride for use in subsequent layers.\n        layer_stride = 1\n        layer_rate = rate\n        rate *= stride\n      else:\n        layer_stride = stride\n        layer_rate = 1\n        current_stride *= stride\n      # Update params.\n      params[\'stride\'] = layer_stride\n      # Only insert rate to params if rate > 1.\n      if layer_rate > 1:\n        params[\'rate\'] = layer_rate\n      # Set padding\n      if use_explicit_padding:\n        if \'kernel_size\' in params:\n          net = _fixed_padding(net, params[\'kernel_size\'], layer_rate)\n        else:\n          params[\'use_explicit_padding\'] = True\n\n      end_point = \'layer_%d\' % (i + 1)\n      try:\n        net = opdef.op(net, **params)\n      except Exception:\n        print(\'Failed to create op %i: %r params: %r\' % (i, opdef, params))\n        raise\n      end_points[end_point] = net\n      scope = os.path.dirname(net.name)\n      scopes[scope] = end_point\n      if final_endpoint is not None and end_point == final_endpoint:\n        break\n\n    # Add all tensors that end with \'output\' to\n    # endpoints\n    for t in net.graph.get_operations():\n      scope = os.path.dirname(t.name)\n      bn = os.path.basename(t.name)\n      if scope in scopes and t.name.endswith(\'output\'):\n        end_points[scopes[scope] + \'/\' + bn] = t.outputs[0]\n    return net, end_points\n\n\n@contextlib.contextmanager\ndef _scope_all(scope, default_scope=None):\n  with tf.variable_scope(scope, default_name=default_scope) as s,\\\n       tf.name_scope(s.original_name_scope):\n    yield s\n\n\n@slim.add_arg_scope\ndef mobilenet(inputs,\n              num_classes=1001,\n              prediction_fn=slim.softmax,\n              reuse=None,\n              scope=\'Mobilenet\',\n              base_only=False,\n              **mobilenet_args):\n  """"""Mobilenet model for classification, supports both V1 and V2.\n\n  Note: default mode is inference, use mobilenet.training_scope to create\n  training network.\n\n\n  Args:\n    inputs: a tensor of shape [batch_size, height, width, channels].\n    num_classes: number of predicted classes. If 0 or None, the logits layer\n      is omitted and the input features to the logits layer (before dropout)\n      are returned instead.\n    prediction_fn: a function to get predictions out of logits\n      (default softmax).\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse \'scope\' must be given.\n    scope: Optional variable_scope.\n    base_only: if True will only create the base of the network (no pooling\n    and no logits).\n    **mobilenet_args: passed to mobilenet_base verbatim.\n      - conv_defs: list of conv defs\n      - multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n      - output_stride: will ensure that the last layer has at most total stride.\n      If the architecture calls for more stride than that provided\n      (e.g. output_stride=16, but the architecture has 5 stride=2 operators),\n      it will replace output_stride with fractional convolutions using Atrous\n      Convolutions.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, num_classes]\n    end_points: a dictionary from components of the network to the corresponding\n      activation tensor.\n\n  Raises:\n    ValueError: Input rank is invalid.\n  """"""\n  is_training = mobilenet_args.get(\'is_training\', False)\n  input_shape = inputs.get_shape().as_list()\n  if len(input_shape) != 4:\n    raise ValueError(\'Expected rank 4 input, was: %d\' % len(input_shape))\n\n  with tf.variable_scope(scope, \'Mobilenet\', reuse=reuse) as scope:\n    inputs = tf.identity(inputs, \'input\')\n    net, end_points = mobilenet_base(inputs, scope=scope, **mobilenet_args)\n    if base_only:\n      return net, end_points\n\n    net = tf.identity(net, name=\'embedding\')\n\n    with tf.variable_scope(\'Logits\'):\n      net = global_pool(net)\n      end_points[\'global_pool\'] = net\n      if not num_classes:\n        return net, end_points\n      net = slim.dropout(net, scope=\'Dropout\', is_training=is_training)\n      # 1 x 1 x num_classes\n      # Note: legacy scope name.\n      logits = slim.conv2d(\n          net,\n          num_classes, [1, 1],\n          activation_fn=None,\n          normalizer_fn=None,\n          biases_initializer=tf.zeros_initializer(),\n          scope=\'Conv2d_1c_1x1\')\n\n      logits = tf.squeeze(logits, [1, 2])\n\n      logits = tf.identity(logits, name=\'output\')\n    end_points[\'Logits\'] = logits\n    if prediction_fn:\n      end_points[\'Predictions\'] = prediction_fn(logits, \'Predictions\')\n  return logits, end_points\n\n\ndef global_pool(input_tensor, pool_op=tf.nn.avg_pool):\n  """"""Applies avg pool to produce 1x1 output.\n\n  NOTE: This function is funcitonally equivalenet to reduce_mean, but it has\n  baked in average pool which has better support across hardware.\n\n  Args:\n    input_tensor: input tensor\n    pool_op: pooling op (avg pool is default)\n  Returns:\n    a tensor batch_size x 1 x 1 x depth.\n  """"""\n  shape = input_tensor.get_shape().as_list()\n  if shape[1] is None or shape[2] is None:\n    kernel_size = tf.convert_to_tensor(\n        [1, tf.shape(input_tensor)[1],\n         tf.shape(input_tensor)[2], 1])\n  else:\n    kernel_size = [1, shape[1], shape[2], 1]\n  output = pool_op(\n      input_tensor, ksize=kernel_size, strides=[1, 1, 1, 1], padding=\'VALID\')\n  # Recover output shape, for unknown shape.\n  output.set_shape([None, 1, 1, None])\n  return output\n\n\ndef training_scope(is_training=True,\n                   weight_decay=0.00004,\n                   stddev=0.09,\n                   dropout_keep_prob=0.8,\n                   bn_decay=0.997):\n  """"""Defines Mobilenet training scope.\n\n  Usage:\n     with tf.contrib.slim.arg_scope(mobilenet.training_scope()):\n       logits, endpoints = mobilenet_v2.mobilenet(input_tensor)\n\n     # the network created will be trainble with dropout/batch norm\n     # initialized appropriately.\n  Args:\n    is_training: if set to False this will ensure that all customizations are\n      set to non-training mode. This might be helpful for code that is reused\n      across both training/evaluation, but most of the time training_scope with\n      value False is not needed. If this is set to None, the parameters is not\n      added to the batch_norm arg_scope.\n\n    weight_decay: The weight decay to use for regularizing the model.\n    stddev: Standard deviation for initialization, if negative uses xavier.\n    dropout_keep_prob: dropout keep probability (not set if equals to None).\n    bn_decay: decay for the batch norm moving averages (not set if equals to\n      None).\n\n  Returns:\n    An argument scope to use via arg_scope.\n  """"""\n  # Note: do not introduce parameters that would change the inference\n  # model here (for example whether to use bias), modify conv_def instead.\n  batch_norm_params = {\n      \'decay\': bn_decay,\n      \'is_training\': is_training\n  }\n  if stddev < 0:\n    weight_intitializer = slim.initializers.xavier_initializer()\n  else:\n    weight_intitializer = tf.truncated_normal_initializer(stddev=stddev)\n\n  # Set weight_decay for weights in Conv and FC layers.\n  with slim.arg_scope(\n      [slim.conv2d, slim.fully_connected, slim.separable_conv2d],\n      weights_initializer=weight_intitializer,\n      normalizer_fn=slim.batch_norm), \\\n      slim.arg_scope([mobilenet_base, mobilenet], is_training=is_training),\\\n      safe_arg_scope([slim.batch_norm], **batch_norm_params), \\\n      safe_arg_scope([slim.dropout], is_training=is_training,\n                     keep_prob=dropout_keep_prob), \\\n      slim.arg_scope([slim.conv2d], \\\n                     weights_regularizer=slim.l2_regularizer(weight_decay)), \\\n      slim.arg_scope([slim.separable_conv2d], weights_regularizer=None) as s:\n    return s\n'"
mmdnn/conversion/examples/tensorflow/models/mobilenet/mobilenet_v2.py,0,"b'# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n""""""Implementation of Mobilenet V2.\n\nArchitecture: https://arxiv.org/abs/1801.04381\n\nThe base model gives 72.2% accuracy on ImageNet, with 300MMadds,\n3.4 M parameters.\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport copy\n\nimport tensorflow as tf\n\nfrom mmdnn.conversion.examples.tensorflow.models.mobilenet import conv_blocks as ops\nfrom mmdnn.conversion.examples.tensorflow.models.mobilenet import mobilenet as lib\n\nslim = tf.contrib.slim\nop = lib.op\n\nexpand_input = ops.expand_input_by_factor\n\n# pyformat: disable\n# Architecture: https://arxiv.org/abs/1801.04381\nV2_DEF = dict(\n    defaults={\n        # Note: these parameters of batch norm affect the architecture\n        # that\'s why they are here and not in training_scope.\n        (slim.batch_norm,): {\'center\': True, \'scale\': True},\n        (slim.conv2d, slim.fully_connected, slim.separable_conv2d): {\n            \'normalizer_fn\': slim.batch_norm, \'activation_fn\': tf.nn.relu6\n        },\n        (ops.expanded_conv,): {\n            \'expansion_size\': expand_input(6),\n            \'split_expansion\': 1,\n            \'normalizer_fn\': slim.batch_norm,\n            \'residual\': True\n        },\n        (slim.conv2d, slim.separable_conv2d): {\'padding\': \'SAME\'}\n    },\n    spec=[\n        op(slim.conv2d, stride=2, num_outputs=32, kernel_size=[3, 3]),\n        op(ops.expanded_conv,\n           expansion_size=expand_input(1, divisible_by=1),\n           num_outputs=16),\n        op(ops.expanded_conv, stride=2, num_outputs=24),\n        op(ops.expanded_conv, stride=1, num_outputs=24),\n        op(ops.expanded_conv, stride=2, num_outputs=32),\n        op(ops.expanded_conv, stride=1, num_outputs=32),\n        op(ops.expanded_conv, stride=1, num_outputs=32),\n        op(ops.expanded_conv, stride=2, num_outputs=64),\n        op(ops.expanded_conv, stride=1, num_outputs=64),\n        op(ops.expanded_conv, stride=1, num_outputs=64),\n        op(ops.expanded_conv, stride=1, num_outputs=64),\n        op(ops.expanded_conv, stride=1, num_outputs=96),\n        op(ops.expanded_conv, stride=1, num_outputs=96),\n        op(ops.expanded_conv, stride=1, num_outputs=96),\n        op(ops.expanded_conv, stride=2, num_outputs=160),\n        op(ops.expanded_conv, stride=1, num_outputs=160),\n        op(ops.expanded_conv, stride=1, num_outputs=160),\n        op(ops.expanded_conv, stride=1, num_outputs=320),\n        op(slim.conv2d, stride=1, kernel_size=[1, 1], num_outputs=1280)\n    ],\n)\n# pyformat: enable\n\n\n@slim.add_arg_scope\ndef mobilenet(input_tensor,\n              num_classes=1001,\n              depth_multiplier=1.0,\n              scope=\'MobilenetV2\',\n              conv_defs=None,\n              finegrain_classification_mode=False,\n              min_depth=None,\n              divisible_by=None,\n              **kwargs):\n  """"""Creates mobilenet V2 network.\n\n  Inference mode is created by default. To create training use training_scope\n  below.\n\n  with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope()):\n     logits, endpoints = mobilenet_v2.mobilenet(input_tensor)\n\n  Args:\n    input_tensor: The input tensor\n    num_classes: number of classes\n    depth_multiplier: The multiplier applied to scale number of\n    channels in each layer. Note: this is called depth multiplier in the\n    paper but the name is kept for consistency with slim\'s model builder.\n    scope: Scope of the operator\n    conv_defs: Allows to override default conv def.\n    finegrain_classification_mode: When set to True, the model\n    will keep the last layer large even for small multipliers. Following\n    https://arxiv.org/abs/1801.04381\n    suggests that it improves performance for ImageNet-type of problems.\n      *Note* ignored if final_endpoint makes the builder exit earlier.\n    min_depth: If provided, will ensure that all layers will have that\n    many channels after application of depth multiplier.\n    divisible_by: If provided will ensure that all layers # channels\n    will be divisible by this number.\n    **kwargs: passed directly to mobilenet.mobilenet:\n      prediction_fn- what prediction function to use.\n      reuse-: whether to reuse variables (if reuse set to true, scope\n      must be given).\n  Returns:\n    logits/endpoints pair\n\n  Raises:\n    ValueError: On invalid arguments\n  """"""\n  if conv_defs is None:\n    conv_defs = V2_DEF\n  if \'multiplier\' in kwargs:\n    raise ValueError(\'mobilenetv2 doesn\\\'t support generic \'\n                     \'multiplier parameter use ""depth_multiplier"" instead.\')\n  if finegrain_classification_mode:\n    conv_defs = copy.deepcopy(conv_defs)\n    if depth_multiplier < 1:\n      conv_defs[\'spec\'][-1].params[\'num_outputs\'] /= depth_multiplier\n\n  depth_args = {}\n  # NB: do not set depth_args unless they are provided to avoid overriding\n  # whatever default depth_multiplier might have thanks to arg_scope.\n  if min_depth is not None:\n    depth_args[\'min_depth\'] = min_depth\n  if divisible_by is not None:\n    depth_args[\'divisible_by\'] = divisible_by\n\n  with slim.arg_scope((lib.depth_multiplier,), **depth_args):\n    return lib.mobilenet(\n        input_tensor,\n        num_classes=num_classes,\n        conv_defs=conv_defs,\n        scope=scope,\n        multiplier=depth_multiplier,\n        **kwargs)\n\n\n@slim.add_arg_scope\ndef mobilenet_base(input_tensor, depth_multiplier=1.0, **kwargs):\n  """"""Creates base of the mobilenet (no pooling and no logits) .""""""\n  return mobilenet(input_tensor,\n                   depth_multiplier=depth_multiplier,\n                   base_only=True, **kwargs)\n\n\ndef training_scope(**kwargs):\n  """"""Defines MobilenetV2 training scope.\n\n  Usage:\n     with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope()):\n       logits, endpoints = mobilenet_v2.mobilenet(input_tensor)\n\n  with slim.\n\n  Args:\n    **kwargs: Passed to mobilenet.training_scope. The following parameters\n    are supported:\n      weight_decay- The weight decay to use for regularizing the model.\n      stddev-  Standard deviation for initialization, if negative uses xavier.\n      dropout_keep_prob- dropout keep probability\n      bn_decay- decay for the batch norm moving averages.\n\n  Returns:\n    An `arg_scope` to use for the mobilenet v2 model.\n  """"""\n  return lib.training_scope(**kwargs)\n\n\n__all__ = [\'training_scope\', \'mobilenet_base\', \'mobilenet\', \'V2_DEF\']\n'"
