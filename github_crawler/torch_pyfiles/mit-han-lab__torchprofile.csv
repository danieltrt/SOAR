file_path,api_count,code
setup.py,0,"b""from setuptools import find_packages, setup\nfrom torchprofile import __version__\n\nsetup(\n    name='torchprofile',\n    version=__version__,\n    packages=find_packages(exclude=['examples']),\n    install_requires=[\n        'numpy>=1.14',\n        'torch>=1.4',\n        'torchvision>=0.4',\n    ],\n    url='https://github.com/mit-han-lab/torchprofile/',\n    license='MIT',\n)\n"""
examples/profile_torchvision.py,2,"b""import torch\nfrom torchprofile import profile_macs\nfrom torchvision import models\n\nif __name__ == '__main__':\n    for name, model in models.__dict__.items():\n        if not name.islower() or name.startswith('__') or not callable(model):\n            continue\n\n        model = model().eval()\n        if 'inception' not in name:\n            inputs = torch.randn(1, 3, 224, 224)\n        else:\n            inputs = torch.randn(1, 3, 299, 299)\n\n        macs = profile_macs(model, inputs)\n        print('{}: {:.4g} G'.format(name, macs / 1e9))\n"""
examples/profile_transformer.py,3,"b""import torch\nfrom torch.nn.modules.transformer import Transformer\nfrom torchprofile import profile_macs\n\nif __name__ == '__main__':\n    embed_size = 512\n    num_tokens = 30\n\n    model = Transformer(embed_size)\n    inputs = (\n        torch.randn(num_tokens, 1, embed_size),\n        torch.randn(num_tokens, 1, embed_size),\n    )\n\n    macs = profile_macs(model, inputs)\n    print('transformer: {:.4g} G'.format(macs / 1e9))\n"""
examples/trace_linear.py,2,"b""import torch\nimport torch.nn as nn\nfrom torchprofile.utils.trace import trace\n\nif __name__ == '__main__':\n    in_features = 16\n    out_features = 32\n\n    model = nn.Linear(in_features, out_features)\n    inputs = torch.randn(1, in_features)\n\n    graph = trace(model, inputs)\n    print(graph)\n"""
torchprofile/__init__.py,0,b'from .profile import profile_macs\nfrom .version import __version__\n'
torchprofile/handlers.py,0,"b""from .utils import math\n\n__all__ = ['handlers']\n\n\ndef addmm(node):\n    # [n, p] = aten::addmm([n, p], [n, m], [m, p], *, *)\n    n, m = node.inputs[1].shape\n    m, p = node.inputs[2].shape\n    return n * m * p\n\n\ndef addmv(node):\n    # [n] = aten::addmv([n], [n, m], [m], *, *)\n    n, m = node.inputs[1].shape\n    return n * m\n\n\ndef bmm(node):\n    # [b, n, p] = aten::bmm([b, n, m], [b, m, p])\n    b, n, m = node.inputs[0].shape\n    b, m, p = node.inputs[1].shape\n    return b * n * m * p\n\n\ndef matmul(node):\n    if node.inputs[0].ndim == 1 and node.inputs[1].ndim == 1:\n        # [] = aten::matmul([n], [n])\n        n = node.inputs[0].shape[0]\n        return n\n    elif node.inputs[0].ndim == 1 and node.inputs[1].ndim == 2:\n        # [m] = aten::matmul([n], [n, m])\n        n, m = node.inputs[1].shape\n        return n * m\n    elif node.inputs[0].ndim == 2 and node.inputs[1].ndim == 1:\n        # [n] = aten::matmul([n, m], [m])\n        n, m = node.inputs[0].shape\n        return n * m\n    elif node.inputs[0].ndim == 2 and node.inputs[1].ndim == 2:\n        # [n, p] = aten::matmul([n, m], [m, p])\n        n, m = node.inputs[0].shape\n        m, p = node.inputs[1].shape\n        return n * m * p\n    elif node.inputs[0].ndim == 1:\n        # [..., m] = aten::matmul([n], [..., n, m])\n        *b, n, m = node.inputs[1].shape\n        return math.prod(b) * n * m\n    elif node.inputs[1].ndim == 1:\n        # [..., n] = aten::matmul([..., n, m], [m])\n        *b, n, m = node.inputs[0].shape\n        return math.prod(b) * n * m\n    else:\n        # [..., n, p] = aten::matmul([..., n, m], [..., m, p])\n        *b, n, p = node.outputs[0].shape\n        *_, n, m = node.inputs[0].shape\n        *_, m, p = node.inputs[1].shape\n        return math.prod(b) * n * m * p\n\n\ndef mul(node):\n    os = node.outputs[0].shape\n    return math.prod(os)\n\n\ndef convolution(node):\n    if node.outputs[0].shape[1] == node.inputs[1].shape[0]:\n        oc, ic, *ks = node.inputs[1].shape\n    else:\n        ic, oc, *ks = node.inputs[1].shape\n    os = node.outputs[0].shape\n    return math.prod(os) * ic * math.prod(ks)\n\n\ndef batch_norm(node):\n    # TODO: provide an option to not fuse `batch_norm` into `linear` or `conv`\n    return 0\n\n\ndef instance_norm_or_layer_norm(node):\n    os = node.outputs[0].shape\n    return math.prod(os)\n\n\ndef avg_pool_or_mean(node):\n    os = node.outputs[0].shape\n    return math.prod(os)\n\n\nhandlers = (\n    ('aten::addmm', addmm), ('aten::addmv', addmv), ('aten::bmm', bmm),\n    ('aten::matmul', matmul), (('aten::mul', 'aten::mul_'), mul),\n    ('aten::_convolution', convolution), ('aten::batch_norm', batch_norm),\n    (('aten::instance_norm', 'aten::layer_norm'),\n     instance_norm_or_layer_norm),\n    (('aten::adaptive_avg_pool1d', 'aten::adaptive_avg_pool2d',\n      'aten::adaptive_avg_pool3d', 'aten::avg_pool1d', 'aten::avg_pool2d',\n      'aten::avg_pool3d', 'aten::mean'), avg_pool_or_mean),\n    (('aten::adaptive_max_pool1d', 'aten::adaptive_max_pool2d',\n      'aten::adaptive_max_pool3d', 'aten::add', 'aten::add_',\n      'aten::alpha_dropout', 'aten::cat', 'aten::chunk', 'aten::clamp',\n      'aten::clone', 'aten::constant_pad_nd', 'aten::contiguous', 'aten::div',\n      'aten::div_', 'aten::dropout', 'aten::dropout_', 'aten::embedding',\n      'aten::eq', 'aten::feature_dropout', 'aten::flatten', 'aten::gt',\n      'aten::hardtanh_', 'aten::int', 'aten::lt', 'aten::log_softmax',\n      'aten::max_pool1d', 'aten::max_pool1d_with_indices', 'aten::max_pool2d',\n      'aten::max_pool2d_with_indices', 'aten::max_pool3d',\n      'aten::max_pool3d_with_indices', 'aten::max_unpool1d',\n      'aten::max_unpool2d', 'aten::max_unpool3d', 'aten::ne',\n      'aten::reflection_pad1d', 'aten::reflection_pad2d',\n      'aten::reflection_pad3d', 'aten::relu', 'aten::relu_',\n      'aten::replication_pad1d', 'aten::replication_pad2d',\n      'aten::replication_pad3d', 'aten::rsub', 'aten::select', 'aten::sigmoid',\n      'aten::size', 'aten::slice', 'aten::softmax', 'aten::softshrink',\n      'aten::squeeze', 'aten::sub', 'aten::sum', 'aten::t', 'aten::tanh',\n      'aten::threshold', 'aten::transpose', 'aten::view', 'aten::zeros',\n      'prim::constant', 'prim::listconstruct', 'prim::listunpack',\n      'prim::numtotensor', 'prim::tupleconstruct'), None))\n"""
torchprofile/profile.py,0,"b'import warnings\n\nfrom .handlers import handlers\nfrom .utils.trace import trace\n\n__all__ = [\'profile_macs\']\n\n\ndef profile_macs(model, args=(), kwargs=None, reduction=sum):\n    results = dict()\n\n    graph = trace(model, args, kwargs)\n    for node in graph.nodes:\n        for operators, func in handlers:\n            if isinstance(operators, str):\n                operators = [operators]\n            if node.operator in operators:\n                if func is not None:\n                    results[node] = func(node)\n                break\n        else:\n            warnings.warn(\'No handlers found: ""{}"". Skipped.\'.format(\n                node.operator))\n\n    if reduction is not None:\n        return reduction(results.values())\n    else:\n        return results\n'"
torchprofile/version.py,0,"b""__version__ = '0.0.1'\n"""
torchprofile/utils/__init__.py,0,b''
torchprofile/utils/flatten.py,2,"b""from collections import deque\n\nimport torch\nimport torch.nn as nn\n\n__all__ = ['flatten', 'Flatten']\n\n\ndef flatten(inputs):\n    queue = deque([inputs])\n    outputs = []\n    while queue:\n        x = queue.popleft()\n        if isinstance(x, (list, tuple)):\n            queue.extend(x)\n        elif isinstance(x, dict):\n            queue.extend(x.values())\n        elif isinstance(x, torch.Tensor):\n            outputs.append(x)\n    return outputs\n\n\nclass Flatten(nn.Module):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    def forward(self, *args, **kwargs):\n        outputs = self.model(*args, **kwargs)\n        return flatten(outputs)\n"""
torchprofile/utils/math.py,0,"b""import operator\nfrom functools import reduce\n\n__all__ = ['prod']\n\n\ndef prod(iterable):\n    return reduce(operator.mul, iterable, 1)\n"""
torchprofile/utils/trace.py,2,"b""import warnings\n\nimport torch\nimport torch.jit\n\nfrom .flatten import Flatten\nfrom .ir import Graph, Node, Variable\n\n__all__ = ['trace']\n\n\ndef trace(model, args=(), kwargs=None):\n    assert kwargs is None, 'Keyword arguments are not supported for now. ' \\\n                           'Please use positional arguments instead!'\n\n    with warnings.catch_warnings(record=True):\n        graph, _ = torch.jit._get_trace_graph(Flatten(model), args, kwargs)\n\n    variables = dict()\n    for x in graph.nodes():\n        for v in list(x.inputs()) + list(x.outputs()):\n            if 'tensor' in v.type().kind().lower():\n                variables[v] = Variable(\n                    name=v.debugName(),\n                    dtype=v.type().scalarType(),\n                    shape=v.type().sizes(),\n                )\n            else:\n                variables[v] = Variable(\n                    name=v.debugName(),\n                    dtype=str(v.type()),\n                )\n\n    nodes = []\n    for x in graph.nodes():\n        node = Node(\n            operator=x.kind(),\n            attributes={\n                s: getattr(x, x.kindOf(s))(s)\n                for s in x.attributeNames()\n            },\n            inputs=[variables[v] for v in x.inputs() if v in variables],\n            outputs=[variables[v] for v in x.outputs() if v in variables],\n            scope=x.scopeName() \\\n                .replace('Flatten/', '', 1) \\\n                .replace('Flatten', '', 1),\n        )\n        nodes.append(node)\n\n    graph = Graph(\n        name=model.__class__.__module__ + '.' + model.__class__.__name__,\n        variables=[v for v in variables.values()],\n        inputs=[variables[v] for v in graph.inputs() if v in variables],\n        outputs=[variables[v] for v in graph.outputs() if v in variables],\n        nodes=nodes,\n    )\n    return graph\n"""
torchprofile/utils/ir/__init__.py,0,b'from .graph import Graph\nfrom .node import Node\nfrom .variable import Variable\n'
torchprofile/utils/ir/graph.py,0,"b""__all__ = ['Graph']\n\n\nclass Graph:\n    def __init__(self, name, variables, inputs, outputs, nodes):\n        self.name = name\n        self.variables = variables\n        self.inputs = inputs\n        self.outputs = outputs\n        self.nodes = nodes\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        self._name = name\n\n    @property\n    def variables(self):\n        return self._variables\n\n    @variables.setter\n    def variables(self, variables):\n        self._variables = variables\n\n    @property\n    def inputs(self):\n        return self._inputs\n\n    @inputs.setter\n    def inputs(self, inputs):\n        self._inputs = inputs\n\n    @property\n    def outputs(self):\n        return self._outputs\n\n    @outputs.setter\n    def outputs(self, outputs):\n        self._outputs = outputs\n\n    @property\n    def nodes(self):\n        return self._nodes\n\n    @nodes.setter\n    def nodes(self, nodes):\n        self._nodes = nodes\n\n    def __repr__(self):\n        text = self.name\n        text += ' (' + '\\n'\n        text += ',\\n'.join(['\\t' + str(v) for v in self.inputs]) + '\\n'\n        text += '):' + '\\n'\n        text += '\\n'.join(['\\t' + str(x) for x in self.nodes]) + '\\n'\n        text += '\\t' + 'return ' + ', '.join([str(v) for v in self.outputs])\n        return text\n"""
torchprofile/utils/ir/node.py,0,"b""__all__ = ['Node']\n\n\nclass Node:\n    def __init__(self, operator, attributes, inputs, outputs, scope):\n        self.operator = operator\n        self.attributes = attributes\n        self.inputs = inputs\n        self.outputs = outputs\n        self.scope = scope\n\n    @property\n    def operator(self):\n        return self._operator\n\n    @operator.setter\n    def operator(self, operator):\n        self._operator = operator.lower()\n\n    @property\n    def attributes(self):\n        return self._attributes\n\n    @attributes.setter\n    def attributes(self, attributes):\n        self._attributes = attributes\n\n    @property\n    def inputs(self):\n        return self._inputs\n\n    @inputs.setter\n    def inputs(self, inputs):\n        self._inputs = inputs\n\n    @property\n    def outputs(self):\n        return self._outputs\n\n    @outputs.setter\n    def outputs(self, outputs):\n        self._outputs = outputs\n\n    @property\n    def scope(self):\n        return self._scope\n\n    @scope.setter\n    def scope(self, scope):\n        self._scope = scope\n\n    def __repr__(self):\n        text = ', '.join([str(v) for v in self.outputs])\n        text += ' = ' + self.operator\n        if self.attributes:\n            text += '[' + ', '.join(\n                [str(k) + ' = ' + str(v)\n                 for k, v in self.attributes.items()]) + ']'\n        text += '(' + ', '.join([str(v) for v in self.inputs]) + ')'\n        return text\n"""
torchprofile/utils/ir/variable.py,0,"b""__all__ = ['Variable']\n\n\nclass Variable:\n    def __init__(self, name, dtype, shape=None):\n        self.name = name\n        self.dtype = dtype\n        self.shape = shape\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        self._name = name\n\n    @property\n    def dtype(self):\n        return self._dtype\n\n    @dtype.setter\n    def dtype(self, dtype):\n        self._dtype = dtype.lower()\n\n    @property\n    def shape(self):\n        return self._shape\n\n    @shape.setter\n    def shape(self, shape):\n        self._shape = shape\n\n    @property\n    def ndim(self):\n        return len(self.shape)\n\n    def size(self):\n        return self.shape\n\n    def dim(self):\n        return self.ndim\n\n    def __repr__(self):\n        text = '%' + self.name + ': ' + self.dtype\n        if self.shape is not None:\n            text += '[' + ', '.join([str(x) for x in self.shape]) + ']'\n        return text\n"""
