file_path,api_count,code
__init__.py,0,"b'__authors__ = [""Mo\'men"", ""Hager""]\n'"
main.py,0,"b'""""""\n__author__ = ""Hager Rady and Mo\'men AbdelRazek""\n\nMain\n-Capture the config file\n-Process the json config passed\n-Create an agent instance\n-Run the agent\n""""""\n\nimport argparse\nfrom utils.config import *\n\nfrom agents import *\n\n\ndef main():\n    # parse the path of the json config file\n    arg_parser = argparse.ArgumentParser(description="""")\n    arg_parser.add_argument(\n        \'config\',\n        metavar=\'config_json_file\',\n        default=\'None\',\n        help=\'The Configuration file in json format\')\n    args = arg_parser.parse_args()\n\n    # parse the config json file\n    config = process_config(args.config)\n\n    # Create the Agent and pass all the configuration to it then run it..\n    agent_class = globals()[config.agent]\n    agent = agent_class(config)\n    agent.run()\n    agent.finalize()\n\n\nif __name__ == \'__main__\':\n    main()\n'"
agents/__init__.py,0,"b""import os\nimport sys\n\npath = os.path.dirname(os.path.abspath(__file__))\n\nfor py in [f[:-3] for f in os.listdir(path) if f.endswith('.py') and f != '__init__.py']:\n    mod = __import__('.'.join([__name__, py]), fromlist=[py])\n    classes = [getattr(mod, x) for x in dir(mod) if isinstance(getattr(mod, x), type)]\n    for cls in classes:\n        setattr(sys.modules[__name__], cls.__name__, cls)"""
agents/base.py,0,"b'""""""\nThe Base Agent class, where all other agents inherit from, that contains definitions for all the necessary functions\n""""""\nimport logging\n\n\nclass BaseAgent:\n    """"""\n    This base class will contain the base functions to be overloaded by any agent you will implement.\n    """"""\n\n    def __init__(self, config):\n        self.config = config\n        self.logger = logging.getLogger(""Agent"")\n\n    def load_checkpoint(self, file_name):\n        """"""\n        Latest checkpoint loader\n        :param file_name: name of the checkpoint file\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def save_checkpoint(self, file_name=""checkpoint.pth.tar"", is_best=0):\n        """"""\n        Checkpoint saver\n        :param file_name: name of the checkpoint file\n        :param is_best: boolean flag to indicate whether current checkpoint\'s metric is the best so far\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def run(self):\n        """"""\n        The main operator\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def train(self):\n        """"""\n        Main training loop\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def train_one_epoch(self):\n        """"""\n        One epoch of training\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def validate(self):\n        """"""\n        One cycle of model validation\n        :return:\n        """"""\n        raise NotImplementedError\n\n    def finalize(self):\n        """"""\n        Finalizes all the operations of the 2 Main classes of the process, the operator and the data loader\n        :return:\n        """"""\n        raise NotImplementedError\n'"
agents/condensenet.py,11,"b'""""""\nMain Agent for CondenseNet\n""""""\nimport numpy as np\n\nfrom tqdm import tqdm\nimport shutil\n\nimport torch\nfrom torch import nn\nfrom torch.backends import cudnn\nfrom torch.autograd import Variable\n\nfrom agents.base import BaseAgent\nfrom graphs.models.condensenet import CondenseNet\nfrom graphs.losses.cross_entropy import CrossEntropyLoss\nfrom datasets.cifar10 import Cifar10DataLoader\n\nfrom tensorboardX import SummaryWriter\nfrom utils.metrics import AverageMeter, AverageMeterList, cls_accuracy\nfrom utils.misc import print_cuda_statistics\nfrom utils.train_utils import adjust_learning_rate\n\ncudnn.benchmark = True\n\n\nclass CondenseNetAgent(BaseAgent):\n    def __init__(self, config):\n        super().__init__(config)\n        # Create an instance from the Model\n        self.model = CondenseNet(self.config)\n        # Create an instance from the data loader\n        self.data_loader = Cifar10DataLoader(self.config)\n        # Create instance from the loss\n        self.loss = CrossEntropyLoss()\n        # Create instance from the optimizer\n        self.optimizer = torch.optim.SGD(self.model.parameters(),\n                                         lr=self.config.learning_rate,\n                                         momentum=float(self.config.momentum),\n                                         weight_decay=self.config.weight_decay,\n                                         nesterov=True)\n        # initialize my counters\n        self.current_epoch = 0\n        self.current_iteration = 0\n        self.best_valid_acc = 0\n        # Check is cuda is available or not\n        self.is_cuda = torch.cuda.is_available()\n        # Construct the flag and make sure that cuda is available\n        self.cuda = self.is_cuda & self.config.cuda\n\n        if self.cuda:\n            self.device = torch.device(""cuda"")\n            torch.cuda.manual_seed_all(self.config.seed)\n            torch.cuda.set_device(self.config.gpu_device)\n            self.logger.info(""Operation will be on *****GPU-CUDA***** "")\n            print_cuda_statistics()\n        else:\n            self.device = torch.device(""cpu"")\n            torch.manual_seed(self.config.seed)\n            self.logger.info(""Operation will be on *****CPU***** "")\n\n        self.model = self.model.to(self.device)\n        self.loss = self.loss.to(self.device)\n        # Model Loading from the latest checkpoint if not found start from scratch.\n        self.load_checkpoint(self.config.checkpoint_file)\n        # Tensorboard Writer\n        self.summary_writer = SummaryWriter(log_dir=self.config.summary_dir, comment=\'CondenseNet\')\n\n    def save_checkpoint(self, filename=\'checkpoint.pth.tar\', is_best=0):\n        """"""\n        Saving the latest checkpoint of the training\n        :param filename: filename which will contain the state\n        :param is_best: flag is it is the best model\n        :return:\n        """"""\n        state = {\n            \'epoch\': self.current_epoch,\n            \'iteration\': self.current_iteration,\n            \'state_dict\': self.model.state_dict(),\n            \'optimizer\': self.optimizer.state_dict(),\n        }\n        # Save the state\n        torch.save(state, self.config.checkpoint_dir + filename)\n        # If it is the best copy it to another file \'model_best.pth.tar\'\n        if is_best:\n            shutil.copyfile(self.config.checkpoint_dir + filename,\n                            self.config.checkpoint_dir + \'model_best.pth.tar\')\n\n    def load_checkpoint(self, filename):\n        filename = self.config.checkpoint_dir + filename\n        try:\n            self.logger.info(""Loading checkpoint \'{}\'"".format(filename))\n            checkpoint = torch.load(filename)\n\n            self.current_epoch = checkpoint[\'epoch\']\n            self.current_iteration = checkpoint[\'iteration\']\n            self.model.load_state_dict(checkpoint[\'state_dict\'])\n            self.optimizer.load_state_dict(checkpoint[\'optimizer\'])\n\n            self.logger.info(""Checkpoint loaded successfully from \'{}\' at (epoch {}) at (iteration {})\\n""\n                             .format(self.config.checkpoint_dir, checkpoint[\'epoch\'], checkpoint[\'iteration\']))\n        except OSError as e:\n            self.logger.info(""No checkpoint exists from \'{}\'. Skipping..."".format(self.config.checkpoint_dir))\n            self.logger.info(""**First time to train**"")\n\n    def run(self):\n        """"""\n        This function will the operator\n        :return:\n        """"""\n        try:\n            if self.config.mode == \'test\':\n                self.validate()\n            else:\n                self.train()\n\n        except KeyboardInterrupt:\n            self.logger.info(""You have entered CTRL+C.. Wait to finalize"")\n\n    def train(self):\n        """"""\n        Main training function, with per-epoch model saving\n        """"""\n        for epoch in range(self.current_epoch, self.config.max_epoch):\n            self.current_epoch = epoch\n            self.train_one_epoch()\n\n            valid_acc = self.validate()\n            is_best = valid_acc > self.best_valid_acc\n            if is_best:\n                self.best_valid_acc = valid_acc\n            self.save_checkpoint(is_best=is_best)\n\n    def train_one_epoch(self):\n        """"""\n        One epoch training function\n        """"""\n        # Initialize tqdm\n        tqdm_batch = tqdm(self.data_loader.train_loader, total=self.data_loader.train_iterations,\n                          desc=""Epoch-{}-"".format(self.current_epoch))\n        # Set the model to be in training mode\n        self.model.train()\n        # Initialize your average meters\n        epoch_loss = AverageMeter()\n        top1_acc = AverageMeter()\n        top5_acc = AverageMeter()\n\n        current_batch = 0\n        for x, y in tqdm_batch:\n            if self.cuda:\n                x, y = x.cuda(async=self.config.async_loading), y.cuda(async=self.config.async_loading)\n\n            # current iteration over total iterations\n            progress = float(self.current_epoch * self.data_loader.train_iterations + current_batch) / (\n                    self.config.max_epoch * self.data_loader.train_iterations)\n            # progress = float(self.current_iteration) / (self.config.max_epoch * self.data_loader.train_iterations)\n            x, y = Variable(x), Variable(y)\n            lr = adjust_learning_rate(self.optimizer, self.current_epoch, self.config, batch=current_batch,\n                                      nBatch=self.data_loader.train_iterations)\n            # model\n            pred = self.model(x, progress)\n            # loss\n            cur_loss = self.loss(pred, y)\n            if np.isnan(float(cur_loss.item())):\n                raise ValueError(\'Loss is nan during training...\')\n            # optimizer\n            self.optimizer.zero_grad()\n            cur_loss.backward()\n            self.optimizer.step()\n\n            top1, top5 = cls_accuracy(pred.data, y.data, topk=(1, 5))\n\n            epoch_loss.update(cur_loss.item())\n            top1_acc.update(top1.item(), x.size(0))\n            top5_acc.update(top5.item(), x.size(0))\n\n            self.current_iteration += 1\n            current_batch += 1\n\n            self.summary_writer.add_scalar(""epoch/loss"", epoch_loss.val, self.current_iteration)\n            self.summary_writer.add_scalar(""epoch/accuracy"", top1_acc.val, self.current_iteration)\n        tqdm_batch.close()\n\n        self.logger.info(""Training at epoch-"" + str(self.current_epoch) + "" | "" + ""loss: "" + str(\n            epoch_loss.val) + ""- Top1 Acc: "" + str(top1_acc.val) + ""- Top5 Acc: "" + str(top5_acc.val))\n\n    def validate(self):\n        """"""\n        One epoch validation\n        :return:\n        """"""\n        tqdm_batch = tqdm(self.data_loader.valid_loader, total=self.data_loader.valid_iterations,\n                          desc=""Valiation at -{}-"".format(self.current_epoch))\n\n        # set the model in training mode\n        self.model.eval()\n\n        epoch_loss = AverageMeter()\n        top1_acc = AverageMeter()\n        top5_acc = AverageMeter()\n\n        for x, y in tqdm_batch:\n            if self.cuda:\n                x, y = x.cuda(async=self.config.async_loading), y.cuda(async=self.config.async_loading)\n\n            x, y = Variable(x), Variable(y)\n            # model\n            pred = self.model(x)\n            # loss\n            cur_loss = self.loss(pred, y)\n            if np.isnan(float(cur_loss.item())):\n                raise ValueError(\'Loss is nan during validation...\')\n\n            top1, top5 = cls_accuracy(pred.data, y.data, topk=(1, 5))\n            epoch_loss.update(cur_loss.item())\n            top1_acc.update(top1.item(), x.size(0))\n            top5_acc.update(top5.item(), x.size(0))\n\n        self.logger.info(""Validation results at epoch-"" + str(self.current_epoch) + "" | "" + ""loss: "" + str(\n            epoch_loss.avg) + ""- Top1 Acc: "" + str(top1_acc.val) + ""- Top5 Acc: "" + str(top5_acc.val))\n\n        tqdm_batch.close()\n\n        return top1_acc.avg\n\n    def finalize(self):\n        """"""\n        Finalize all the operations of the 2 Main classes of the process the operator and the data loader\n        :return:\n        """"""\n        self.logger.info(""Please wait while finalizing the operation.. Thank you"")\n        self.save_checkpoint()\n        self.summary_writer.export_scalars_to_json(""{}all_scalars.json"".format(self.config.summary_dir))\n        self.summary_writer.close()\n        self.data_loader.finalize()\n'"
agents/dcgan.py,16,"b'""""""\nMain Agent for DCGAN\n""""""\nimport numpy as np\n\nfrom tqdm import tqdm\nimport shutil\nimport random\n\nimport torch\nfrom torch import nn\nfrom torch.backends import cudnn\nfrom torch.autograd import Variable\nimport torchvision.utils as vutils\n\nfrom agents.base import BaseAgent\nfrom graphs.models.dcgan_generator import Generator\nfrom graphs.models.dcgan_discriminator import Discriminator\nfrom graphs.losses.bce import BinaryCrossEntropy\nfrom datasets.celebA import CelebADataLoader\n\nfrom tensorboardX import SummaryWriter\nfrom utils.metrics import AverageMeter, AverageMeterList\nfrom utils.misc import print_cuda_statistics\n\ncudnn.benchmark = True\n\n\nclass DCGANAgent(BaseAgent):\n\n    def __init__(self, config):\n        super().__init__(config)\n        # define models ( generator and discriminator)\n        self.netG = Generator(self.config)\n        self.netD = Discriminator(self.config)\n        # define dataloader\n        self.dataloader = CelebADataLoader(self.config)\n\n        # define loss\n        self.loss = BinaryCrossEntropy()\n\n        # define optimizers for both generator and discriminator\n        self.optimG = torch.optim.Adam(self.netG.parameters(), lr=self.config.learning_rate, betas=(self.config.beta1, self.config.beta2))\n        self.optimD = torch.optim.Adam(self.netD.parameters(), lr=self.config.learning_rate, betas=(self.config.beta1, self.config.beta2))\n\n        # initialize counter\n        self.current_epoch = 0\n        self.current_iteration = 0\n        self.best_valid_mean_iou = 0\n\n        self.fixed_noise = Variable(torch.randn(self.config.batch_size, self.config.g_input_size, 1, 1))\n        self.real_label = 1\n        self.fake_label = 0\n\n        # set cuda flag\n        self.is_cuda = torch.cuda.is_available()\n        if self.is_cuda and not self.config.cuda:\n            self.logger.info(""WARNING: You have a CUDA device, so you should probably enable CUDA"")\n\n        self.cuda = self.is_cuda & self.config.cuda\n        # set the manual seed for torch\n        #if not self.config.seed:\n        self.manual_seed = random.randint(1, 10000)\n        #self.manual_seed = self.config.seed\n        self.logger.info (""seed: "" , self.manual_seed)\n        random.seed(self.manual_seed)\n        if self.cuda:\n            self.device = torch.device(""cuda"")\n            torch.cuda.set_device(self.config.gpu_device)\n            torch.cuda.manual_seed_all(self.manual_seed)\n            self.logger.info(""Program will run on *****GPU-CUDA***** "")\n            print_cuda_statistics()\n        else:\n            self.device = torch.device(""cpu"")\n            torch.manual_seed(self.manual_seed)\n            self.logger.info(""Program will run on *****CPU***** "")\n\n        self.netG = self.netG.to(self.device)\n        self.netD = self.netD.to(self.device)\n        self.loss = self.loss.to(self.device)\n        self.fixed_noise = self.fixed_noise.to(self.device)\n        # Model Loading from the latest checkpoint if not found start from scratch.\n        self.load_checkpoint(self.config.checkpoint_file)\n\n        # Summary Writer\n        self.summary_writer = SummaryWriter(log_dir=self.config.summary_dir, comment=\'DCGAN\')\n\n    def load_checkpoint(self, file_name):\n        filename = self.config.checkpoint_dir + file_name\n        try:\n            self.logger.info(""Loading checkpoint \'{}\'"".format(filename))\n            checkpoint = torch.load(filename)\n\n            self.current_epoch = checkpoint[\'epoch\']\n            self.current_iteration = checkpoint[\'iteration\']\n            self.netG.load_state_dict(checkpoint[\'G_state_dict\'])\n            self.optimG.load_state_dict(checkpoint[\'G_optimizer\'])\n            self.netD.load_state_dict(checkpoint[\'D_state_dict\'])\n            self.optimD.load_state_dict(checkpoint[\'D_optimizer\'])\n            self.fixed_noise = checkpoint[\'fixed_noise\']\n            self.manual_seed = checkpoint[\'manual_seed\']\n\n            self.logger.info(""Checkpoint loaded successfully from \'{}\' at (epoch {}) at (iteration {})\\n""\n                  .format(self.config.checkpoint_dir, checkpoint[\'epoch\'], checkpoint[\'iteration\']))\n        except OSError as e:\n            self.logger.info(""No checkpoint exists from \'{}\'. Skipping..."".format(self.config.checkpoint_dir))\n            self.logger.info(""**First time to train**"")\n\n    def save_checkpoint(self, file_name=""checkpoint.pth.tar"", is_best = 0):\n        state = {\n            \'epoch\': self.current_epoch,\n            \'iteration\': self.current_iteration,\n            \'G_state_dict\': self.netG.state_dict(),\n            \'G_optimizer\': self.optimG.state_dict(),\n            \'D_state_dict\': self.netD.state_dict(),\n            \'D_optimizer\': self.optimD.state_dict(),\n            \'fixed_noise\': self.fixed_noise,\n            \'manual_seed\': self.manual_seed\n        }\n        # Save the state\n        torch.save(state, self.config.checkpoint_dir + file_name)\n        # If it is the best copy it to another file \'model_best.pth.tar\'\n        if is_best:\n            shutil.copyfile(self.config.checkpoint_dir + file_name,\n                            self.config.checkpoint_dir + \'model_best.pth.tar\')\n\n    def run(self):\n        """"""\n        This function will the operator\n        :return:\n        """"""\n        try:\n            self.train()\n\n        except KeyboardInterrupt:\n            self.logger.info(""You have entered CTRL+C.. Wait to finalize"")\n\n    def train(self):\n        for epoch in range(self.current_epoch, self.config.max_epoch):\n            self.current_epoch = epoch\n            self.train_one_epoch()\n            self.save_checkpoint()\n\n    def train_one_epoch(self):\n        # initialize tqdm batch\n        tqdm_batch = tqdm(self.dataloader.loader, total=self.dataloader.num_iterations, desc=""epoch-{}-"".format(self.current_epoch))\n\n        self.netG.train()\n        self.netD.train()\n\n        epoch_lossG = AverageMeter()\n        epoch_lossD = AverageMeter()\n\n\n        for curr_it, x in enumerate(tqdm_batch):\n            #y = torch.full((self.batch_size,), self.real_label)\n            x = x[0]\n            y = torch.randn(x.size(0), )\n            fake_noise = torch.randn(x.size(0), self.config.g_input_size, 1, 1)\n\n            if self.cuda:\n                x = x.cuda(async=self.config.async_loading)\n                y = y.cuda(async=self.config.async_loading)\n                fake_noise = fake_noise.cuda(async=self.config.async_loading)\n\n            x = Variable(x)\n            y = Variable(y)\n            fake_noise = Variable(fake_noise)\n            ####################\n            # Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n            # train with real\n            self.netD.zero_grad()\n            D_real_out = self.netD(x)\n            y.fill_(self.real_label)\n            loss_D_real = self.loss(D_real_out, y)\n            loss_D_real.backward()\n\n            # train with fake\n            G_fake_out = self.netG(fake_noise)\n            y.fill_(self.fake_label)\n\n            D_fake_out = self.netD(G_fake_out.detach())\n\n            loss_D_fake = self.loss(D_fake_out, y)\n            loss_D_fake.backward()\n            #D_mean_fake_out = D_fake_out.mean().item()\n\n            loss_D = loss_D_fake + loss_D_real\n            self.optimD.step()\n\n            ####################\n            # Update G network: maximize log(D(G(z)))\n            self.netG.zero_grad()\n            y.fill_(self.real_label)\n            D_out = self.netD(G_fake_out)\n            loss_G = self.loss(D_out, y)\n            loss_G.backward()\n\n            #D_G_mean_out = D_out.mean().item()\n\n            self.optimG.step()\n\n            epoch_lossD.update(loss_D.item())\n            epoch_lossG.update(loss_G.item())\n\n            self.current_iteration += 1\n\n            self.summary_writer.add_scalar(""epoch/Generator_loss"", epoch_lossG.val, self.current_iteration)\n            self.summary_writer.add_scalar(""epoch/Discriminator_loss"", epoch_lossD.val, self.current_iteration)\n\n        gen_out = self.netG(self.fixed_noise)\n        out_img = self.dataloader.plot_samples_per_epoch(gen_out.data, self.current_iteration)\n        self.summary_writer.add_image(\'train/generated_image\', out_img, self.current_iteration)\n\n        tqdm_batch.close()\n\n        self.logger.info(""Training at epoch-"" + str(self.current_epoch) + "" | "" + ""Discriminator loss: "" + str(\n            epoch_lossD.val) + "" - Generator Loss-: "" + str(epoch_lossG.val))\n\n    def validate(self):\n        pass\n\n    def finalize(self):\n        """"""\n        Finalize all the operations of the 2 Main classes of the process the operator and the data loader\n        :return:\n        """"""\n        self.logger.info(""Please wait while finalizing the operation.. Thank you"")\n        self.save_checkpoint()\n        self.summary_writer.export_scalars_to_json(""{}all_scalars.json"".format(self.config.summary_dir))\n        self.summary_writer.close()\n        self.dataloader.finalize()\n'"
agents/dqn.py,18,"b'""""""\nMain agent for DQN\n""""""\nimport math\nimport random\nimport shutil\n\nimport gym\nimport torch\nfrom tensorboardX import SummaryWriter\nfrom torch.backends import cudnn\nfrom tqdm import tqdm\n\nfrom agents.base import BaseAgent\nfrom graphs.losses.huber_loss import HuberLoss\nfrom graphs.models.dqn import DQN\nfrom utils.env_utils import CartPoleEnv\nfrom utils.misc import print_cuda_statistics\nfrom utils.replay_memory import ReplayMemory, Transition\n\ncudnn.benchmark = True\n\n\nclass DQNAgent(BaseAgent):\n\n    def __init__(self, config):\n        super().__init__(config)\n        # define models (policy and target)\n        self.policy_model = DQN(self.config)\n        self.target_model = DQN(self.config)\n        # define memory\n        self.memory = ReplayMemory(self.config)\n        # define loss\n        self.loss = HuberLoss()\n        # define optimizer\n        self.optim = torch.optim.RMSprop(self.policy_model.parameters())\n\n        # define environment\n        self.env = gym.make(\'CartPole-v0\').unwrapped\n        self.cartpole = CartPoleEnv(self.config.screen_width)\n\n        # initialize counter\n        self.current_episode = 0\n        self.current_iteration = 0\n        self.episode_durations = []\n\n        # set cuda flag\n        self.is_cuda = torch.cuda.is_available()\n        if self.is_cuda and not self.config.cuda:\n            self.logger.info(""WARNING: You have a CUDA device, so you should probably enable CUDA"")\n\n        self.cuda = self.is_cuda & self.config.cuda\n\n        if self.cuda:\n            self.device = torch.device(""cuda"")\n            torch.cuda.set_device(self.config.gpu_device)\n            self.logger.info(""Program will run on *****GPU-CUDA***** "")\n            print_cuda_statistics()\n        else:\n            self.device = torch.device(""cpu"")\n            self.logger.info(""Program will run on *****CPU***** "")\n\n        self.policy_model = self.policy_model.to(self.device)\n        self.target_model = self.target_model.to(self.device)\n        self.loss = self.loss.to(self.device)\n\n        # Initialize Target model with policy model state dict\n        self.target_model.load_state_dict(self.policy_model.state_dict())\n        self.target_model.eval()\n        # Summary Writer\n        self.summary_writer = SummaryWriter(log_dir=self.config.summary_dir, comment=\'DQN\')\n\n    def load_checkpoint(self, file_name):\n        filename = self.config.checkpoint_dir + file_name\n        try:\n            self.logger.info(""Loading checkpoint \'{}\'"".format(filename))\n            checkpoint = torch.load(filename)\n\n            self.current_episode = checkpoint[\'episode\']\n            self.current_iteration = checkpoint[\'iteration\']\n            self.policy_model.load_state_dict(checkpoint[\'state_dict\'])\n            self.optim.load_state_dict(checkpoint[\'optimizer\'])\n\n            self.logger.info(""Checkpoint loaded successfully from \'{}\' at (epoch {}) at (iteration {})\\n""\n                  .format(self.config.checkpoint_dir, checkpoint[\'episode\'], checkpoint[\'iteration\']))\n        except OSError as e:\n            self.logger.info(""No checkpoint exists from \'{}\'. Skipping..."".format(self.config.checkpoint_dir))\n            self.logger.info(""**First time to train**"")\n\n    def save_checkpoint(self, file_name=""checkpoint.pth.tar"", is_best=0):\n        state = {\n            \'episode\': self.current_episode,\n            \'iteration\': self.current_iteration,\n            \'state_dict\': self.policy_model.state_dict(),\n            \'optimizer\': self.optim.state_dict(),\n        }\n        # Save the state\n        torch.save(state, self.config.checkpoint_dir + file_name)\n        # If it is the best copy it to another file \'model_best.pth.tar\'\n        if is_best:\n            shutil.copyfile(self.config.checkpoint_dir + file_name,\n                            self.config.checkpoint_dir + \'model_best.pth.tar\')\n\n    def run(self):\n        """"""\n        This function will the operator\n        :return:\n        """"""\n        try:\n            self.train()\n\n        except KeyboardInterrupt:\n            self.logger.info(""You have entered CTRL+C.. Wait to finalize"")\n\n    def select_action(self, state):\n        """"""\n        The action selection function, it either uses the model to choose an action or samples one uniformly.\n        :param state: current state of the model\n        :return:\n        """"""\n        if self.cuda:\n            state = state.cuda()\n        sample = random.random()\n        eps_threshold = self.config.eps_start + (self.config.eps_start - self.config.eps_end) * math.exp(\n            -1. * self.current_iteration / self.config.eps_decay)\n        self.current_iteration += 1\n        if sample > eps_threshold:\n            with torch.no_grad():\n                return self.policy_model(state).max(1)[1].view(1, 1)\n        else:\n            return torch.tensor([[random.randrange(2)]], device=self.device, dtype=torch.long)\n\n    def optimize_policy_model(self):\n        """"""\n        performs a single step of optimization for the policy model\n        :return:\n        """"""\n        if self.memory.length() < self.config.batch_size:\n            return\n        # sample a batch\n        transitions = self.memory.sample_batch(self.config.batch_size)\n\n        one_batch = Transition(*zip(*transitions))\n\n        # create a mask of non-final states\n        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, one_batch.next_state)), device=self.device,dtype=torch.uint8)\n        non_final_next_states = torch.cat([s for s in one_batch.next_state if s is not None])\n\n        # concatenate all batch elements into one\n        state_batch = torch.cat(one_batch.state)\n        action_batch = torch.cat(one_batch.action)\n        reward_batch = torch.cat(one_batch.reward)\n\n        state_batch = state_batch.to(self.device)\n        non_final_next_states = non_final_next_states.to(self.device)\n\n        curr_state_values = self.policy_model(state_batch)\n        curr_state_action_values = curr_state_values.gather(1, action_batch)\n\n        next_state_values = torch.zeros(self.config.batch_size, device=self.device)\n        next_state_values[non_final_mask] = self.target_model(non_final_next_states).max(1)[0].detach()\n\n        # Get the expected Q values\n        expected_state_action_values = (next_state_values * self.config.gamma) + reward_batch\n        # compute loss: temporal difference error\n        loss = self.loss(curr_state_action_values, expected_state_action_values.unsqueeze(1))\n\n        # optimizer step\n        self.optim.zero_grad()\n        loss.backward()\n        for param in self.policy_model.parameters():\n            param.grad.data.clamp_(-1, 1)\n        self.optim.step()\n\n        return loss\n\n    def train(self):\n        """"""\n        Training loop based on the number of episodes\n        :return:\n        """"""\n        for episode in tqdm(range(self.current_episode, self.config.num_episodes)):\n            self.current_episode = episode\n            # reset environment\n            self.env.reset()\n            self.train_one_epoch()\n            # The target network has its weights kept frozen most of the time\n            if self.current_episode % self.config.target_update == 0:\n                self.target_model.load_state_dict(self.policy_model.state_dict())\n\n        self.env.render()\n        self.env.close()\n\n    def train_one_epoch(self):\n        """"""\n        One episode of training; it samples an action, observe next screen and optimize the model once\n        :return:\n        """"""\n        episode_duration = 0\n        prev_frame = self.cartpole.get_screen(self.env)\n        curr_frame = self.cartpole.get_screen(self.env)\n        # get state\n        curr_state = curr_frame - prev_frame\n\n        while(1):\n            episode_duration += 1\n            # select action\n            action = self.select_action(curr_state)\n            # perform action and get reward\n            _, reward, done, _ = self.env.step(action.item())\n\n            if self.cuda:\n                reward = torch.Tensor([reward]).to(self.device)\n            else:\n                reward = torch.Tensor([reward]).to(self.device)\n\n            prev_frame = curr_frame\n            curr_frame = self.cartpole.get_screen(self.env)\n            # assign next state\n            if done:\n                next_state = None\n            else:\n                next_state = curr_frame - prev_frame\n\n            # add this transition into memory\n            self.memory.push_transition(curr_state, action, next_state, reward)\n\n            curr_state = next_state\n\n            # Policy model optimization step\n            curr_loss = self.optimize_policy_model()\n            if curr_loss is not None:\n                if self.cuda:\n                    curr_loss = curr_loss.cpu()\n                self.summary_writer.add_scalar(""Temporal_Difference_Loss"", curr_loss.detach().numpy(), self.current_iteration)\n            # check if done\n            if done:\n                break\n\n        self.summary_writer.add_scalar(""Training_Episode_Duration"", episode_duration, self.current_episode)\n\n    def validate(self):\n        pass\n\n    def finalize(self):\n        """"""\n        Finalize all the operations of the 2 Main classes of the process the operator and the data loader\n        :return:\n        """"""\n        self.logger.info(""Please wait while finalizing the operation.. Thank you"")\n        self.save_checkpoint()\n        self.summary_writer.export_scalars_to_json(""{}all_scalars.json"".format(self.config.summary_dir))\n        self.summary_writer.close()\n'"
agents/erfnet.py,17,"b'import numpy as np\n\nfrom tqdm import tqdm\nimport shutil\n\nimport torch\nfrom torch.backends import cudnn\nfrom torch.autograd import Variable\n\nfrom graphs.models.erfnet import ERF\nfrom graphs.models.erfnet_imagenet import ERFNet\nfrom datasets.voc2012 import VOCDataLoader\nfrom graphs.losses.cross_entropy import CrossEntropyLoss\n\nfrom torch.optim import lr_scheduler\n\nfrom tensorboardX import SummaryWriter\nfrom utils.metrics import AverageMeter, IOUMetric\nfrom utils.misc import print_cuda_statistics\n\nfrom agents.base import BaseAgent\n\ncudnn.benchmark = True\n\n\nclass ERFNetAgent(BaseAgent):\n    """"""\n    This class will be responsible for handling the whole process of our architecture.\n    """"""\n\n    def __init__(self, config):\n        super().__init__(config)\n        # Create an instance from the Model\n        self.logger.info(""Loading encoder pretrained in imagenet..."")\n        if self.config.pretrained_encoder:\n            pretrained_enc = torch.nn.DataParallel(ERFNet(self.config.imagenet_nclasses)).cuda()\n            pretrained_enc.load_state_dict(torch.load(self.config.pretrained_model_path)[\'state_dict\'])\n            pretrained_enc = next(pretrained_enc.children()).features.encoder\n        else:\n            pretrained_enc = None\n        # define erfNet model\n        self.model = ERF(self.config, pretrained_enc)\n        # Create an instance from the data loader\n        self.data_loader = VOCDataLoader(self.config)\n        # Create instance from the loss\n        self.loss = CrossEntropyLoss(self.config)\n        # Create instance from the optimizer\n        self.optimizer = torch.optim.Adam(self.model.parameters(),\n                                          lr=self.config.learning_rate,\n                                          betas=(self.config.betas[0], self.config.betas[1]),\n                                          eps=self.config.eps,\n                                          weight_decay=self.config.weight_decay)\n        # Define Scheduler\n        lambda1 = lambda epoch: pow((1 - ((epoch - 1) / self.config.max_epoch)), 0.9)\n        self.scheduler = lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lambda1)\n        # initialize my counters\n        self.current_epoch = 0\n        self.current_iteration = 0\n        self.best_valid_mean_iou = 0\n\n        # Check is cuda is available or not\n        self.is_cuda = torch.cuda.is_available()\n        # Construct the flag and make sure that cuda is available\n        self.cuda = self.is_cuda & self.config.cuda\n\n        if self.cuda:\n            torch.cuda.manual_seed_all(self.config.seed)\n            self.device = torch.device(""cuda"")\n            torch.cuda.set_device(self.config.gpu_device)\n            self.logger.info(""Operation will be on *****GPU-CUDA***** "")\n            print_cuda_statistics()\n\n        else:\n            self.device = torch.device(""cpu"")\n            torch.manual_seed(self.config.seed)\n            self.logger.info(""Operation will be on *****CPU***** "")\n\n        self.model = self.model.to(self.device)\n        self.loss = self.loss.to(self.device)\n        # Model Loading from the latest checkpoint if not found start from scratch.\n        self.load_checkpoint(self.config.checkpoint_file)\n\n        # Tensorboard Writer\n        self.summary_writer = SummaryWriter(log_dir=self.config.summary_dir, comment=\'FCN8s\')\n\n        # # scheduler for the optimizer\n        # self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer,\n        #                                                             \'min\', patience=self.config.learning_rate_patience,\n        #                                                             min_lr=1e-10, verbose=True)\n\n    def save_checkpoint(self, filename=\'checkpoint.pth.tar\', is_best=0):\n        """"""\n        Saving the latest checkpoint of the training\n        :param filename: filename which will contain the state\n        :param is_best: flag is it is the best model\n        :return:\n        """"""\n        state = {\n            \'epoch\': self.current_epoch + 1,\n            \'iteration\': self.current_iteration,\n            \'state_dict\': self.model.state_dict(),\n            \'optimizer\': self.optimizer.state_dict(),\n        }\n        # Save the state\n        torch.save(state, self.config.checkpoint_dir + filename)\n        # If it is the best copy it to another file \'model_best.pth.tar\'\n        if is_best:\n            shutil.copyfile(self.config.checkpoint_dir + filename,\n                            self.config.checkpoint_dir + \'model_best.pth.tar\')\n\n    def load_checkpoint(self, filename):\n        filename = self.config.checkpoint_dir + filename\n        try:\n            self.logger.info(""Loading checkpoint \'{}\'"".format(filename))\n            checkpoint = torch.load(filename)\n\n            self.current_epoch = checkpoint[\'epoch\']\n            self.current_iteration = checkpoint[\'iteration\']\n            self.model.load_state_dict(checkpoint[\'state_dict\'])\n            self.optimizer.load_state_dict(checkpoint[\'optimizer\'])\n\n            self.logger.info(""Checkpoint loaded successfully from \'{}\' at (epoch {}) at (iteration {})\\n""\n                  .format(self.config.checkpoint_dir, checkpoint[\'epoch\'], checkpoint[\'iteration\']))\n        except OSError as e:\n            self.logger.info(""No checkpoint exists from \'{}\'. Skipping..."".format(self.config.checkpoint_dir))\n            self.logger.info(""**First time to train**"")\n\n    def run(self):\n        """"""\n        This function will the operator\n        :return:\n        """"""\n        assert self.config.mode in [\'train\', \'test\', \'random\']\n        try:\n            if self.config.mode == \'test\':\n                self.test()\n            else:\n                self.train()\n\n        except KeyboardInterrupt:\n            self.logger.info(""You have entered CTRL+C.. Wait to finalize"")\n\n    def train(self):\n        """"""\n        Main training function, with per-epoch model saving\n        """"""\n\n        for epoch in range(self.current_epoch, self.config.max_epoch):\n            self.current_epoch = epoch\n            self.scheduler.step(epoch)\n            self.train_one_epoch()\n\n            valid_mean_iou, valid_loss = self.validate()\n            self.scheduler.step(valid_loss)\n\n            is_best = valid_mean_iou > self.best_valid_mean_iou\n            if is_best:\n                self.best_valid_mean_iou = valid_mean_iou\n\n            self.save_checkpoint(is_best=is_best)\n\n    def train_one_epoch(self):\n        """"""\n        One epoch training function\n        """"""\n        # Initialize tqdm\n        tqdm_batch = tqdm(self.data_loader.train_loader, total=self.data_loader.train_iterations,\n                          desc=""Epoch-{}-"".format(self.current_epoch))\n\n        # Set the model to be in training mode (for batchnorm)\n        self.model.train()\n        # Initialize your average meters\n        epoch_loss = AverageMeter()\n        metrics = IOUMetric(self.config.num_classes)\n\n        for x, y in tqdm_batch:\n            if self.cuda:\n                x, y = x.pin_memory().cuda(async=self.config.async_loading), y.cuda(async=self.config.async_loading)\n            x, y = Variable(x), Variable(y)\n            # model\n            pred = self.model(x)\n            # loss\n            cur_loss = self.loss(pred, y)\n            if np.isnan(float(cur_loss.item())):\n                raise ValueError(\'Loss is nan during training...\')\n\n            # optimizer\n            self.optimizer.zero_grad()\n            cur_loss.backward()\n            self.optimizer.step()\n\n            epoch_loss.update(cur_loss.item())\n            _, pred_max = torch.max(pred, 1)\n            metrics.add_batch(pred_max.data.cpu().numpy(), y.data.cpu().numpy())\n\n            self.current_iteration += 1\n            # exit(0)\n\n        epoch_acc, _, epoch_iou_class, epoch_mean_iou, _ = metrics.evaluate()\n        self.summary_writer.add_scalar(""epoch-training/loss"", epoch_loss.val, self.current_iteration)\n        self.summary_writer.add_scalar(""epoch_training/mean_iou"", epoch_mean_iou, self.current_iteration)\n        tqdm_batch.close()\n\n        print(""Training Results at epoch-"" + str(self.current_epoch) + "" | "" + ""loss: "" + str(\n            epoch_loss.val) + "" - acc-: "" + str(\n            epoch_acc) + ""- mean_iou: "" + str(epoch_mean_iou) + ""\\n iou per class: \\n"" + str(\n            epoch_iou_class))\n\n    def validate(self):\n        """"""\n        One epoch validation\n        :return:\n        """"""\n        tqdm_batch = tqdm(self.data_loader.valid_loader, total=self.data_loader.valid_iterations,\n                          desc=""Valiation at -{}-"".format(self.current_epoch))\n\n        # set the model in training mode\n        self.model.eval()\n\n        epoch_loss = AverageMeter()\n        metrics = IOUMetric(self.config.num_classes)\n\n        for x, y in tqdm_batch:\n            if self.cuda:\n                x, y = x.pin_memory().cuda(async=self.config.async_loading), y.cuda(async=self.config.async_loading)\n            x, y = Variable(x), Variable(y)\n            # model\n            pred = self.model(x)\n            # loss\n            cur_loss = self.loss(pred, y)\n\n            if np.isnan(float(cur_loss.item())):\n                raise ValueError(\'Loss is nan during Validation.\')\n\n            _, pred_max = torch.max(pred, 1)\n            metrics.add_batch(pred_max.data.cpu().numpy(), y.data.cpu().numpy())\n\n            epoch_loss.update(cur_loss.item())\n\n        epoch_acc, _, epoch_iou_class, epoch_mean_iou, _ = metrics.evaluate()\n        self.summary_writer.add_scalar(""epoch_validation/loss"", epoch_loss.val, self.current_iteration)\n        self.summary_writer.add_scalar(""epoch_validation/mean_iou"", epoch_mean_iou, self.current_iteration)\n\n        print(""Validation Results at epoch-"" + str(self.current_epoch) + "" | "" + ""loss: "" + str(\n            epoch_loss.val) + "" - acc-: "" + str(\n            epoch_acc) + ""- mean_iou: "" + str(epoch_mean_iou) + ""\\n iou per class: \\n"" + str(\n            epoch_iou_class))\n\n        tqdm_batch.close()\n\n        return epoch_mean_iou, epoch_loss.val\n\n    def test(self):\n        # TODO\n        pass\n\n    def finalize(self):\n        """"""\n        Finalize all the operations of the 2 Main classes of the process the operator and the data loader\n        :return:\n        """"""\n        print(""Please wait while finalizing the operation.. Thank you"")\n        self.save_checkpoint()\n        self.summary_writer.export_scalars_to_json(""{}all_scalars.json"".format(self.config.summary_dir))\n        self.summary_writer.close()\n        self.data_loader.finalize()\n'"
agents/example.py,5,"b'import numpy as np\n\nfrom tqdm import tqdm\nimport shutil\nimport random\n\nimport torch\nfrom torch import nn\nfrom torch.backends import cudnn\nfrom torch.autograd import Variable\n\nfrom agents.base import BaseAgent\n\n# import your classes here\n\nfrom tensorboardX import SummaryWriter\nfrom utils.metrics import AverageMeter, AverageMeterList\nfrom utils.misc import print_cuda_statistics\n\ncudnn.benchmark = True\n\n\nclass ExampleAgent(BaseAgent):\n\n    def __init__(self, config):\n        super().__init__(config)\n\n        # define models\n        self.model = None\n\n        # define data_loader\n        self.data_loader = None\n\n        # define loss\n        self.loss = None\n\n        # define optimizers for both generator and discriminator\n        self.optimizer = None\n\n        # initialize counter\n        self.current_epoch = 0\n        self.current_iteration = 0\n        self.best_metric = 0\n\n        # set cuda flag\n        self.is_cuda = torch.cuda.is_available()\n        if self.is_cuda and not self.config.cuda:\n            self.logger.info(""WARNING: You have a CUDA device, so you should probably enable CUDA"")\n\n        self.cuda = self.is_cuda & self.config.cuda\n\n        # set the manual seed for torch\n        self.manual_seed = self.config.seed\n        if self.cuda:\n            torch.cuda.manual_seed_all(self.manual_seed)\n            torch.cuda.set_device(self.config.gpu_device)\n            self.model = self.model.cuda()\n            self.loss = self.loss.cuda()\n            self.logger.info(""Program will run on *****GPU-CUDA***** "")\n            print_cuda_statistics()\n        else:\n            self.logger.info(""Program will run on *****CPU*****\\n"")\n\n        # Model Loading from the latest checkpoint if not found start from scratch.\n        self.load_checkpoint(self.config.checkpoint_file)\n        # Summary Writer\n        self.summary_writer = None\n\n    def load_checkpoint(self, file_name):\n        """"""\n        Latest checkpoint loader\n        :param file_name: name of the checkpoint file\n        :return:\n        """"""\n        pass\n\n    def save_checkpoint(self, file_name=""checkpoint.pth.tar"", is_best=0):\n        """"""\n        Checkpoint saver\n        :param file_name: name of the checkpoint file\n        :param is_best: boolean flag to indicate whether current checkpoint\'s accuracy is the best so far\n        :return:\n        """"""\n        pass\n\n    def run(self):\n        """"""\n        The main operator\n        :return:\n        """"""\n        try:\n            self.train()\n\n        except KeyboardInterrupt:\n            self.logger.info(""You have entered CTRL+C.. Wait to finalize"")\n\n    def train(self):\n        """"""\n        Main training loop\n        :return:\n        """"""\n        pass\n\n    def train_one_epoch(self):\n        """"""\n        One epoch of training\n        :return:\n        """"""\n        pass\n\n    def validate(self):\n        """"""\n        One cycle of model validation\n        :return:\n        """"""\n        pass\n\n    def finalize(self):\n        """"""\n        Finalizes all the operations of the 2 Main classes of the process, the operator and the data loader\n        :return:\n        """"""\n        pass\n'"
agents/mnist.py,11,"b'""""""\nMnist Main agent, as mentioned in the tutorial\n""""""\nimport numpy as np\n\nfrom tqdm import tqdm\nimport shutil\nimport random\n\nimport torch\nfrom torch import nn\nfrom torch.backends import cudnn\nfrom torch.autograd import Variable\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom agents.base import BaseAgent\n\nfrom graphs.models.mnist import Mnist\nfrom datasets.mnist import MnistDataLoader\n\nfrom tensorboardX import SummaryWriter\nfrom utils.metrics import AverageMeter, AverageMeterList\nfrom utils.misc import print_cuda_statistics\n\ncudnn.benchmark = True\n\n\nclass MnistAgent(BaseAgent):\n\n    def __init__(self, config):\n        super().__init__(config)\n\n        # define models\n        self.model = Mnist()\n\n        # define data_loader\n        self.data_loader = MnistDataLoader(config=config)\n\n        # define loss\n        self.loss = nn.NLLLoss()\n\n        # define optimizer\n        self.optimizer = optim.SGD(self.model.parameters(), lr=self.config.learning_rate, momentum=self.config.momentum)\n\n        # initialize counter\n        self.current_epoch = 0\n        self.current_iteration = 0\n        self.best_metric = 0\n\n        # set cuda flag\n        self.is_cuda = torch.cuda.is_available()\n        if self.is_cuda and not self.config.cuda:\n            self.logger.info(""WARNING: You have a CUDA device, so you should probably enable CUDA"")\n\n        self.cuda = self.is_cuda & self.config.cuda\n\n        # set the manual seed for torch\n        self.manual_seed = self.config.seed\n        if self.cuda:\n            torch.cuda.manual_seed(self.manual_seed)\n            self.device = torch.device(""cuda"")\n            torch.cuda.set_device(self.config.gpu_device)\n            self.model = self.model.to(self.device)\n            self.loss = self.loss.to(self.device)\n\n            self.logger.info(""Program will run on *****GPU-CUDA***** "")\n            print_cuda_statistics()\n        else:\n            self.device = torch.device(""cpu"")\n            torch.manual_seed(self.manual_seed)\n            self.logger.info(""Program will run on *****CPU*****\\n"")\n\n        # Model Loading from the latest checkpoint if not found start from scratch.\n        self.load_checkpoint(self.config.checkpoint_file)\n        # Summary Writer\n        self.summary_writer = None\n\n    def load_checkpoint(self, file_name):\n        """"""\n        Latest checkpoint loader\n        :param file_name: name of the checkpoint file\n        :return:\n        """"""\n        pass\n\n    def save_checkpoint(self, file_name=""checkpoint.pth.tar"", is_best=0):\n        """"""\n        Checkpoint saver\n        :param file_name: name of the checkpoint file\n        :param is_best: boolean flag to indicate whether current checkpoint\'s accuracy is the best so far\n        :return:\n        """"""\n        pass\n\n    def run(self):\n        """"""\n        The main operator\n        :return:\n        """"""\n        try:\n            self.train()\n\n        except KeyboardInterrupt:\n            self.logger.info(""You have entered CTRL+C.. Wait to finalize"")\n\n    def train(self):\n        """"""\n        Main training loop\n        :return:\n        """"""\n        for epoch in range(1, self.config.max_epoch + 1):\n            self.train_one_epoch()\n            self.validate()\n\n            self.current_epoch += 1\n    def train_one_epoch(self):\n        """"""\n        One epoch of training\n        :return:\n        """"""\n\n        self.model.train()\n        for batch_idx, (data, target) in enumerate(self.data_loader.train_loader):\n            data, target = data.to(self.device), target.to(self.device)\n            self.optimizer.zero_grad()\n            output = self.model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            self.optimizer.step()\n            if batch_idx % self.config.log_interval == 0:\n                self.logger.info(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                    self.current_epoch, batch_idx * len(data), len(self.data_loader.train_loader.dataset),\n                           100. * batch_idx / len(self.data_loader.train_loader), loss.item()))\n            self.current_iteration += 1\n\n    def validate(self):\n        """"""\n        One cycle of model validation\n        :return:\n        """"""\n        self.model.eval()\n        test_loss = 0\n        correct = 0\n        with torch.no_grad():\n            for data, target in self.data_loader.test_loader:\n                data, target = data.to(self.device), target.to(self.device)\n                output = self.model(data)\n                test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n                pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n                correct += pred.eq(target.view_as(pred)).sum().item()\n\n        test_loss /= len(self.data_loader.test_loader.dataset)\n        self.logger.info(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n            test_loss, correct, len(self.data_loader.test_loader.dataset),\n            100. * correct / len(self.data_loader.test_loader.dataset)))\n    def finalize(self):\n        """"""\n        Finalizes all the operations of the 2 Main classes of the process, the operator and the data loader\n        :return:\n        """"""\n        pass\n'"
datasets/__init__.py,0,"b""import os\nimport sys\n\npath = os.path.dirname(os.path.abspath(__file__))\n\nfor py in [f[:-3] for f in os.listdir(path) if f.endswith('.py') and f != '__init__.py']:\n    mod = __import__('.'.join([__name__, py]), fromlist=[py])\n    classes = [getattr(mod, x) for x in dir(mod) if isinstance(getattr(mod, x), type)]\n    for cls in classes:\n        setattr(sys.modules[__name__], cls.__name__, cls)\n"""
datasets/celebA.py,1,"b'""""""\nCelebA Dataloader implementation, used in DCGAN\n""""""\nimport numpy as np\n\nimport imageio\n\nimport torch\nimport torchvision.transforms as v_transforms\nimport torchvision.utils as v_utils\nimport torchvision.datasets as v_datasets\n\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\n\n\nclass CelebADataLoader:\n    def __init__(self, config):\n        self.config = config\n\n        if config.data_mode == ""imgs"":\n            transform = v_transforms.Compose(\n                [v_transforms.ToTensor(),\n                 v_transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n\n            dataset = v_datasets.ImageFolder(self.config.data_folder, transform=transform)\n\n            self.dataset_len = len(dataset)\n\n            self.num_iterations = (self.dataset_len + config.batch_size - 1) // config.batch_size\n\n            self.loader = DataLoader(dataset,\n                                     batch_size=config.batch_size,\n                                     shuffle=True,\n                                     num_workers=config.data_loader_workers,\n                                     pin_memory=config.pin_memory)\n        elif config.data_mode == ""numpy"":\n            raise NotImplementedError(""This mode is not implemented YET"")\n        else:\n            raise Exception(""Please specify in the json a specified mode in data_mode"")\n\n    def plot_samples_per_epoch(self, fake_batch, epoch):\n        """"""\n        Plotting the fake batch\n        :param fake_batch: Tensor of shape (B,C,H,W)\n        :param epoch: the number of current epoch\n        :return: img_epoch: which will contain the image of this epoch\n        """"""\n        img_epoch = \'{}samples_epoch_{:d}.png\'.format(self.config.out_dir, epoch)\n        v_utils.save_image(fake_batch,\n                           img_epoch,\n                           nrow=4,\n                           padding=2,\n                           normalize=True)\n        return imageio.imread(img_epoch)\n\n    def make_gif(self, epochs):\n        """"""\n        Make a gif from a multiple images of epochs\n        :param epochs: num_epochs till now\n        :return:\n        """"""\n        gen_image_plots = []\n        for epoch in range(epochs + 1):\n            img_epoch = \'{}samples_epoch_{:d}.png\'.format(self.config.out_dir, epoch)\n            try:\n                gen_image_plots.append(imageio.imread(img_epoch))\n            except OSError as e:\n                pass\n\n        imageio.mimsave(self.config.out_dir + \'animation_epochs_{:d}.gif\'.format(epochs), gen_image_plots, fps=2)\n\n    def finalize(self):\n        pass\n'"
datasets/cifar10.py,5,"b'""""""\nCifar10 Dataloader implementation, used in CondenseNet\n""""""\nimport logging\nimport numpy as np\n\nimport torch\nimport torchvision.transforms as v_transforms\nimport torchvision.utils as v_utils\nimport torchvision.datasets as v_datasets\n\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\n\n\nclass Cifar10DataLoader:\n    def __init__(self, config):\n        self.config = config\n        self.logger = logging.getLogger(""Cifar10DataLoader"")\n        if config.data_mode == ""numpy_train"":\n\n            self.logger.info(""Loading DATA....."")\n            normalize = v_transforms.Normalize(mean=[0.4914, 0.4824, 0.4467],\n                                             std=[0.2471, 0.2435, 0.2616])\n\n            train_set = v_datasets.CIFAR10(\'./data\', train=True, download=True,\n                                         transform=v_transforms.Compose([\n                                             v_transforms.RandomCrop(32, padding=4),\n                                             v_transforms.RandomHorizontalFlip(),\n                                             v_transforms.ToTensor(),\n                                             normalize,\n                                         ]))\n            valid_set = v_datasets.CIFAR10(\'./data\', train=False,\n                                       transform=v_transforms.Compose([\n                                           v_transforms.ToTensor(),\n                                           normalize,\n                                       ]))\n\n            self.train_loader = DataLoader(train_set, batch_size=self.config.batch_size, shuffle=True)\n            self.valid_loader = DataLoader(valid_set, batch_size=self.config.batch_size, shuffle=False)\n\n            self.train_iterations = len(self.train_loader)\n            self.valid_iterations = len(self.valid_loader)\n\n        elif config.data_mode == ""numpy_test"":\n            test_data = torch.from_numpy(np.load(config.data_folder + config.x_test)).float()\n            test_labels = torch.from_numpy(np.load(config.data_folder + config.y_test)).long()\n\n            self.len_test_data = test_data.size()[0]\n\n            self.test_iterations = (self.len_test_data + self.config.batch_size - 1) // self.config.batch_size\n\n            self.logger.info(""""""\n                Some Statistics about the testing data\n                test_data shape: {}, type: {}\n                test_labels shape: {}, type: {}\n                test_iterations: {}\n            """""".format(test_data.size(), test_data.type(), test_labels.size(), test_labels.type(),\n                       self.test_iterations))\n\n            test = TensorDataset(test_data, test_labels)\n\n            self.test_loader = DataLoader(test, batch_size=config.batch_size, shuffle=False)\n\n        elif config.data_mode == ""random"":\n            train_data = torch.randn(self.config.batch_size, self.config.input_channels, self.config.img_size, self.config.img_size)\n            train_labels = torch.ones(self.config.batch_size).long()\n            valid_data = train_data\n            valid_labels = train_labels\n            self.len_train_data = train_data.size()[0]\n            self.len_valid_data = valid_data.size()[0]\n\n            self.train_iterations = (self.len_train_data + self.config.batch_size - 1) // self.config.batch_size\n            self.valid_iterations = (self.len_valid_data + self.config.batch_size - 1) // self.config.batch_size\n\n            train = TensorDataset(train_data, train_labels)\n            valid = TensorDataset(valid_data, valid_labels)\n\n            self.train_loader = DataLoader(train, batch_size=config.batch_size, shuffle=True)\n            self.valid_loader = DataLoader(valid, batch_size=config.batch_size, shuffle=False)\n\n        else:\n            raise Exception(""Please specify in the json a specified mode in data_mode"")\n\n    def finalize(self):\n        pass\n'"
datasets/example.py,3,"b'""""""\nAn example for dataset loaders, starting with data loading including all the functions that either preprocess or postprocess data.\n""""""\nimport imageio\nimport torch\nimport torchvision.utils as v_utils\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\n\n\nclass ExampleDataLoader:\n    def __init__(self, config):\n        """"""\n        :param config:\n        """"""\n        self.config = config\n        if config.data_mode == ""imgs"":\n            raise NotImplementedError(""This mode is not implemented YET"")\n\n        elif config.data_mode == ""numpy"":\n            raise NotImplementedError(""This mode is not implemented YET"")\n\n        elif config.data_mode == ""random"":\n            train_data = torch.randn(self.config.batch_size, self.config.input_channels, self.config.img_size, self.config.img_size)\n            train_labels = torch.ones(self.config.batch_size).long()\n            valid_data = train_data\n            valid_labels = train_labels\n            self.len_train_data = train_data.size()[0]\n            self.len_valid_data = valid_data.size()[0]\n\n            self.train_iterations = (self.len_train_data + self.config.batch_size - 1) // self.config.batch_size\n            self.valid_iterations = (self.len_valid_data + self.config.batch_size - 1) // self.config.batch_size\n\n            train = TensorDataset(train_data, train_labels)\n            valid = TensorDataset(valid_data, valid_labels)\n\n            self.train_loader = DataLoader(train, batch_size=config.batch_size, shuffle=True)\n            self.valid_loader = DataLoader(valid, batch_size=config.batch_size, shuffle=False)\n\n        else:\n            raise Exception(""Please specify in the json a specified mode in data_mode"")\n\n    def plot_samples_per_epoch(self, batch, epoch):\n        """"""\n        Plotting the batch images\n        :param batch: Tensor of shape (B,C,H,W)\n        :param epoch: the number of current epoch\n        :return: img_epoch: which will contain the image of this epoch\n        """"""\n        img_epoch = \'{}samples_epoch_{:d}.png\'.format(self.config.out_dir, epoch)\n        v_utils.save_image(batch,\n                           img_epoch,\n                           nrow=4,\n                           padding=2,\n                           normalize=True)\n        return imageio.imread(img_epoch)\n\n    def make_gif(self, epochs):\n        """"""\n        Make a gif from a multiple images of epochs\n        :param epochs: num_epochs till now\n        :return:\n        """"""\n        gen_image_plots = []\n        for epoch in range(epochs + 1):\n            img_epoch = \'{}samples_epoch_{:d}.png\'.format(self.config.out_dir, epoch)\n            try:\n                gen_image_plots.append(imageio.imread(img_epoch))\n            except OSError as e:\n                pass\n\n        imageio.mimsave(self.config.out_dir + \'animation_epochs_{:d}.gif\'.format(epochs), gen_image_plots, fps=2)\n\n    def finalize(self):\n        pass\n\n'"
datasets/mnist.py,5,"b'""""""\nMnist Data loader, as given in Mnist tutorial\n""""""\nimport imageio\nimport torch\nimport torchvision.utils as v_utils\nfrom torchvision import datasets, transforms\n\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\n\n\nclass MnistDataLoader:\n    def __init__(self, config):\n        """"""\n        :param config:\n        """"""\n        self.config = config\n        if config.data_mode == ""download"":\n            self.train_loader = torch.utils.data.DataLoader(\n                datasets.MNIST(\'../data\', train=True, download=True,\n                               transform=transforms.Compose([\n                                   transforms.ToTensor(),\n                                   transforms.Normalize((0.1307,), (0.3081,))\n                               ])),\n                batch_size=self.config.batch_size, shuffle=True, num_workers=self.config.data_loader_workers, pin_memory=self.config.pin_memory)\n            self.test_loader = torch.utils.data.DataLoader(\n                datasets.MNIST(\'../data\', train=False, transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.1307,), (0.3081,))\n                ])),\n                batch_size=self.config.test_batch_size, shuffle=True, num_workers=self.config.data_loader_workers, pin_memory=self.config.pin_memory)\n        elif config.data_mode == ""imgs"":\n            raise NotImplementedError(""This mode is not implemented YET"")\n\n        elif config.data_mode == ""numpy"":\n            raise NotImplementedError(""This mode is not implemented YET"")\n\n        elif config.data_mode == ""random"":\n            train_data = torch.randn(self.config.batch_size, self.config.input_channels, self.config.img_size, self.config.img_size)\n            train_labels = torch.ones(self.config.batch_size).long()\n            valid_data = train_data\n            valid_labels = train_labels\n            self.len_train_data = train_data.size()[0]\n            self.len_valid_data = valid_data.size()[0]\n\n            self.train_iterations = (self.len_train_data + self.config.batch_size - 1) // self.config.batch_size\n            self.valid_iterations = (self.len_valid_data + self.config.batch_size - 1) // self.config.batch_size\n\n            train = TensorDataset(train_data, train_labels)\n            valid = TensorDataset(valid_data, valid_labels)\n\n            self.train_loader = DataLoader(train, batch_size=config.batch_size, shuffle=True)\n            self.test_loader = DataLoader(valid, batch_size=config.batch_size, shuffle=False)\n\n        else:\n            raise Exception(""Please specify in the json a specified mode in data_mode"")\n\n    def plot_samples_per_epoch(self, batch, epoch):\n        """"""\n        Plotting the batch images\n        :param batch: Tensor of shape (B,C,H,W)\n        :param epoch: the number of current epoch\n        :return: img_epoch: which will contain the image of this epoch\n        """"""\n        img_epoch = \'{}samples_epoch_{:d}.png\'.format(self.config.out_dir, epoch)\n        v_utils.save_image(batch,\n                           img_epoch,\n                           nrow=4,\n                           padding=2,\n                           normalize=True)\n        return imageio.imread(img_epoch)\n\n    def make_gif(self, epochs):\n        """"""\n        Make a gif from a multiple images of epochs\n        :param epochs: num_epochs till now\n        :return:\n        """"""\n        gen_image_plots = []\n        for epoch in range(epochs + 1):\n            img_epoch = \'{}samples_epoch_{:d}.png\'.format(self.config.out_dir, epoch)\n            try:\n                gen_image_plots.append(imageio.imread(img_epoch))\n            except OSError as e:\n                pass\n\n        imageio.mimsave(self.config.out_dir + \'animation_epochs_{:d}.gif\'.format(epochs), gen_image_plots, fps=2)\n\n    def finalize(self):\n        pass\n\n'"
datasets/voc2012.py,6,"b""import os\n\nimport numpy as np\nimport scipy.io as sio\nimport PIL\nfrom PIL import Image\nimport torch\n\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchvision.transforms as standard_transforms\n\nimport utils.voc_utils as extended_transforms\nfrom utils.voc_utils import make_dataset\n\n\nclass VOC(data.Dataset):\n    def __init__(self, mode, data_root, joint_transform=None, sliding_crop=None, transform=None, target_transform=None):\n        self.imgs = make_dataset(mode, data_root)\n        if len(self.imgs) == 0:\n            raise RuntimeError('Found 0 images, please check the data set')\n        self.mode = mode\n        self.joint_transform = joint_transform\n        self.sliding_crop = sliding_crop\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __getitem__(self, index):\n        if self.mode == 'test':\n            img_path, img_name = self.imgs[index]\n            img = Image.open(os.path.join(img_path, img_name + '.jpg')).convert('RGB')\n            if self.transform is not None:\n                img = self.transform(img)\n            return img_name, img\n\n        img_path, mask_path = self.imgs[index]\n        img = Image.open(img_path).convert('RGB')\n        if self.mode == 'train':\n            mask = sio.loadmat(mask_path)['GTcls']['Segmentation'][0][0]\n            mask = Image.fromarray(mask.astype(np.uint8))\n        else:\n            mask = Image.open(mask_path)\n\n        if self.joint_transform is not None:\n            img, mask = self.joint_transform(img, mask)\n\n        if self.sliding_crop is not None:\n            img_slices, mask_slices, slices_info = self.sliding_crop(img, mask)\n            if self.transform is not None:\n                img_slices = [self.transform(e) for e in img_slices]\n            if self.target_transform is not None:\n                mask_slices = [self.target_transform(e) for e in mask_slices]\n            img, mask = torch.stack(img_slices, 0), torch.stack(mask_slices, 0)\n            return img, mask, torch.LongTensor(slices_info)\n        else:\n            if self.transform is not None:\n                img = self.transform(img)\n            if self.target_transform is not None:\n                mask = self.target_transform(mask)\n            return img, mask\n\n    def __len__(self):\n        return len(self.imgs)\n\n\nclass VOCDataLoader:\n    def __init__(self, config):\n        self.config = config\n        assert self.config.mode in ['train', 'test', 'random']\n\n        mean_std = ([103.939, 116.779, 123.68], [1.0, 1.0, 1.0])\n\n        self.input_transform = standard_transforms.Compose([\n            standard_transforms.Resize((256, 256), interpolation=PIL.Image.BILINEAR),\n            extended_transforms.FlipChannels(),\n            standard_transforms.ToTensor(),\n            standard_transforms.Lambda(lambda x: x.mul_(255)),\n            standard_transforms.Normalize(*mean_std)\n        ])\n\n        self.target_transform = standard_transforms.Compose([\n            standard_transforms.Resize((256, 256), interpolation=PIL.Image.NEAREST),\n            extended_transforms.MaskToTensor()\n        ])\n\n        self.restore_transform = standard_transforms.Compose([\n            extended_transforms.DeNormalize(*mean_std),\n            standard_transforms.Lambda(lambda x: x.div_(255)),\n            standard_transforms.ToPILImage(),\n            extended_transforms.FlipChannels()\n        ])\n\n        self.visualize = standard_transforms.Compose([\n            standard_transforms.Resize(400),\n            standard_transforms.CenterCrop(400),\n            standard_transforms.ToTensor()\n        ])\n        if self.config.mode == 'random':\n            train_data = torch.randn(self.config.batch_size, self.config.input_channels, self.config.img_size,\n                                     self.config.img_size)\n            train_labels = torch.ones(self.config.batch_size, self.config.img_size, self.config.img_size).long()\n            valid_data = train_data\n            valid_labels = train_labels\n            self.len_train_data = train_data.size()[0]\n            self.len_valid_data = valid_data.size()[0]\n\n            self.train_iterations = (self.len_train_data + self.config.batch_size - 1) // self.config.batch_size\n            self.valid_iterations = (self.len_valid_data + self.config.batch_size - 1) // self.config.batch_size\n\n            train = TensorDataset(train_data, train_labels)\n            valid = TensorDataset(valid_data, valid_labels)\n\n            self.train_loader = DataLoader(train, batch_size=config.batch_size, shuffle=True)\n            self.valid_loader = DataLoader(valid, batch_size=config.batch_size, shuffle=False)\n\n        elif self.config.mode == 'train':\n            train_set = VOC('train', self.config.data_root,\n                            transform=self.input_transform, target_transform=self.target_transform)\n            valid_set = VOC('val', self.config.data_root,\n                            transform=self.input_transform, target_transform=self.target_transform)\n\n            self.train_loader = DataLoader(train_set, batch_size=self.config.batch_size, shuffle=True,\n                                           num_workers=self.config.data_loader_workers,\n                                           pin_memory=self.config.pin_memory)\n            self.valid_loader = DataLoader(valid_set, batch_size=self.config.batch_size, shuffle=False,\n                                           num_workers=self.config.data_loader_workers,\n                                           pin_memory=self.config.pin_memory)\n            self.train_iterations = (len(train_set) + self.config.batch_size) // self.config.batch_size\n            self.valid_iterations = (len(valid_set) + self.config.batch_size) // self.config.batch_size\n\n        elif self.config.mode == 'test':\n            test_set = VOC('test', self.config.data_root,\n                           transform=self.input_transform, target_transform=self.target_transform)\n\n            self.test_loader = DataLoader(test_set, batch_size=self.config.batch_size, shuffle=False,\n                                          num_workers=self.config.data_loader_workers,\n                                          pin_memory=self.config.pin_memory)\n            self.test_iterations = (len(test_set) + self.config.batch_size) // self.config.batch_size\n\n        else:\n            raise Exception('Please choose a proper mode for data loading')\n\n    def finalize(self):\n        pass\n"""
graphs/__init__.py,0,"b""import os\nimport sys\n\npath = os.path.dirname(os.path.abspath(__file__))\n\nfor py in [f[:-3] for f in os.listdir(path) if f.endswith('.py') and f != '__init__.py']:\n    mod = __import__('.'.join([__name__, py]), fromlist=[py])\n    classes = [getattr(mod, x) for x in dir(mod) if isinstance(getattr(mod, x), type)]\n    for cls in classes:\n        setattr(sys.modules[__name__], cls.__name__, cls)"""
graphs/weights_initializer.py,0,"b'""""""\r\nA file for all models\' weight initialization functions\r\n""""""\r\nimport torch\r\nfrom torch import nn\r\nimport numpy as np\r\nimport graphs\r\nimport math\r\n\r\n\r\ndef weights_init(m):\r\n    classname = m.__class__.__name__\r\n    if classname.find(\'Conv\') != -1:\r\n        m.weight.data.normal_(0.0, 0.02)\r\n    elif classname.find(\'BatchNorm\') != -1:\r\n        m.weight.data.normal_(1.0, 0.02)\r\n        m.bias.data.fill_(0)\r\n\r\n\r\ndef weights_init_normal(m):\r\n    """"""\r\n    Initialize the weights of Convolution2D and BatchNorm2D with normal.\r\n    :param m:\r\n    :return:\r\n    """"""\r\n    if isinstance(m, nn.Conv2d):\r\n        m.weight.data.normal_(0.0, 0.02)\r\n    elif isinstance(m, nn.BatchNorm2d):\r\n        m.weight.data.normal_(1.0, 0.02)\r\n        m.bias.data.fill_(0)\r\n\r\n\r\ndef init_model_weights(m):\r\n    ### initialize\r\n    for m in m.modules():\r\n        if isinstance(m, nn.Conv2d):\r\n            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\r\n            m.weight.data.normal_(0, math.sqrt(2. / n))\r\n        elif isinstance(m, nn.BatchNorm2d):\r\n            m.weight.data.fill_(1)\r\n            m.bias.data.zero_()\r\n        elif isinstance(m, nn.Linear):\r\n            m.bias.data.zero_()\r\n'"
tutorials/mnist.py,9,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\ndef train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\ndef test(args, model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\ndef main():\n    # Training settings\n    parser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\n    parser.add_argument(\'--batch-size\', type=int, default=64, metavar=\'N\',\n                        help=\'input batch size for training (default: 64)\')\n    parser.add_argument(\'--test-batch-size\', type=int, default=1000, metavar=\'N\',\n                        help=\'input batch size for testing (default: 1000)\')\n    parser.add_argument(\'--epochs\', type=int, default=10, metavar=\'N\',\n                        help=\'number of epochs to train (default: 10)\')\n    parser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                        help=\'learning rate (default: 0.01)\')\n    parser.add_argument(\'--momentum\', type=float, default=0.5, metavar=\'M\',\n                        help=\'SGD momentum (default: 0.5)\')\n    parser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                        help=\'disables CUDA training\')\n    parser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                        help=\'random seed (default: 1)\')\n    parser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                        help=\'how many batches to wait before logging training status\')\n    args = parser.parse_args()\n    use_cuda = not args.no_cuda and torch.cuda.is_available()\n\n    torch.manual_seed(args.seed)\n\n    device = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n    kwargs = {\'num_workers\': 1, \'pin_memory\': True} if use_cuda else {}\n    train_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\'../data\', train=True, download=True,\n                       transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.1307,), (0.3081,))\n                       ])),\n        batch_size=args.batch_size, shuffle=True, **kwargs)\n    test_loader = torch.utils.data.DataLoader(\n        datasets.MNIST(\'../data\', train=False, transform=transforms.Compose([\n                           transforms.ToTensor(),\n                           transforms.Normalize((0.1307,), (0.3081,))\n                       ])),\n        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n\n    model = Net().to(device)\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n    for epoch in range(1, args.epochs + 1):\n        train(args, model, device, train_loader, optimizer, epoch)\n        test(args, model, device, test_loader)\n\n\nif __name__ == \'__main__\':\n    main()'"
utils/__init__.py,0,"b""import os\nimport sys\n\npath = os.path.dirname(os.path.abspath(__file__))\n\nfor py in [f[:-3] for f in os.listdir(path) if f.endswith('.py') and f != '__init__.py']:\n    mod = __import__('.'.join([__name__, py]), fromlist=[py])\n    classes = [getattr(mod, x) for x in dir(mod) if isinstance(getattr(mod, x), type)]\n    for cls in classes:\n        setattr(sys.modules[__name__], cls.__name__, cls)"""
utils/config.py,0,"b'import os\n\nimport logging\nfrom logging import Formatter\nfrom logging.handlers import RotatingFileHandler\n\nimport json\nfrom easydict import EasyDict\nfrom pprint import pprint\n\nfrom utils.dirs import create_dirs\n\n\ndef setup_logging(log_dir):\n    log_file_format = ""[%(levelname)s] - %(asctime)s - %(name)s - : %(message)s in %(pathname)s:%(lineno)d""\n    log_console_format = ""[%(levelname)s]: %(message)s""\n\n    # Main logger\n    main_logger = logging.getLogger()\n    main_logger.setLevel(logging.INFO)\n\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n    console_handler.setFormatter(Formatter(log_console_format))\n\n    exp_file_handler = RotatingFileHandler(\'{}exp_debug.log\'.format(log_dir), maxBytes=10**6, backupCount=5)\n    exp_file_handler.setLevel(logging.DEBUG)\n    exp_file_handler.setFormatter(Formatter(log_file_format))\n\n    exp_errors_file_handler = RotatingFileHandler(\'{}exp_error.log\'.format(log_dir), maxBytes=10**6, backupCount=5)\n    exp_errors_file_handler.setLevel(logging.WARNING)\n    exp_errors_file_handler.setFormatter(Formatter(log_file_format))\n\n    main_logger.addHandler(console_handler)\n    main_logger.addHandler(exp_file_handler)\n    main_logger.addHandler(exp_errors_file_handler)\n\n\ndef get_config_from_json(json_file):\n    """"""\n    Get the config from a json file\n    :param json_file: the path of the config file\n    :return: config(namespace), config(dictionary)\n    """"""\n\n    # parse the configurations from the config json file provided\n    with open(json_file, \'r\') as config_file:\n        try:\n            config_dict = json.load(config_file)\n            # EasyDict allows to access dict values as attributes (works recursively).\n            config = EasyDict(config_dict)\n            return config, config_dict\n        except ValueError:\n            print(""INVALID JSON file format.. Please provide a good json file"")\n            exit(-1)\n\n\ndef process_config(json_file):\n    """"""\n    Get the json file\n    Processing it with EasyDict to be accessible as attributes\n    then editing the path of the experiments folder\n    creating some important directories in the experiment folder\n    Then setup the logging in the whole program\n    Then return the config\n    :param json_file: the path of the config file\n    :return: config object(namespace)\n    """"""\n    config, _ = get_config_from_json(json_file)\n    print("" THE Configuration of your experiment .."")\n    pprint(config)\n\n    # making sure that you have provided the exp_name.\n    try:\n        print("" *************************************** "")\n        print(""The experiment name is {}"".format(config.exp_name))\n        print("" *************************************** "")\n    except AttributeError:\n        print(""ERROR!!..Please provide the exp_name in json file.."")\n        exit(-1)\n\n    # create some important directories to be used for that experiment.\n    config.summary_dir = os.path.join(""experiments"", config.exp_name, ""summaries/"")\n    config.checkpoint_dir = os.path.join(""experiments"", config.exp_name, ""checkpoints/"")\n    config.out_dir = os.path.join(""experiments"", config.exp_name, ""out/"")\n    config.log_dir = os.path.join(""experiments"", config.exp_name, ""logs/"")\n    create_dirs([config.summary_dir, config.checkpoint_dir, config.out_dir, config.log_dir])\n\n    # setup logging in the project\n    setup_logging(config.log_dir)\n\n    logging.getLogger().info(""Hi, This is root."")\n    logging.getLogger().info(""After the configurations are successfully processed and dirs are created."")\n    logging.getLogger().info(""The pipeline of the project will begin now."")\n\n    return config\n'"
utils/dirs.py,0,"b'import os\nimport logging\n\n\ndef create_dirs(dirs):\n    """"""\n    dirs - a list of directories to create if these directories are not found\n    :param dirs:\n    :return:\n    """"""\n    try:\n        for dir_ in dirs:\n            if not os.path.exists(dir_):\n                os.makedirs(dir_)\n    except Exception as err:\n        logging.getLogger(""Dirs Creator"").info(""Creating directories error: {0}"".format(err))\n        exit(-1)\n'"
utils/env_utils.py,2,"b'""""""\nCart Pole environment input extraction\nCode adapted from: https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n""""""\n\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport numpy as np\n\nresize = transforms.Compose([transforms.ToPILImage(),\n                             transforms.Resize(40, interpolation=Image.CUBIC),\n                             transforms.ToTensor()])\nclass CartPoleEnv:\n    def __init__(self, screen_width):\n        super().__init__()\n        self.screen_width = screen_width\n\n    def get_cart_location(self, env):\n        world_width = env.x_threshold * 2\n        scale = self.screen_width / world_width\n        return int(env.state[0] * scale + self.screen_width / 2.0)  # MIDDLE OF CART\n\n    def get_screen(self, env):\n        screen = env.render(mode=\'rgb_array\').transpose((2, 0, 1))  # transpose into torch order (CHW)\n        # Strip off the top and bottom of the screen\n        screen = screen[:, 160:320]\n        view_width = 320\n        cart_location = self.get_cart_location(env)\n        if cart_location < view_width // 2:\n            slice_range = slice(view_width)\n        elif cart_location > (self.screen_width - view_width // 2):\n            slice_range = slice(-view_width, None)\n        else:\n            slice_range = slice(cart_location - view_width // 2,\n                                cart_location + view_width // 2)\n        # Strip off the edges, so that we have a square image centered on a cart\n        screen = screen[:, :, slice_range]\n        # Convert to float, rescale, convert to torch tensor\n        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n        screen = torch.from_numpy(screen)\n        # Resize, and add a batch dimension (BCHW)\n        return resize(screen).unsqueeze(0)'"
utils/generate_class_weights.py,6,"b'import numpy as np\n\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport os\n\nimport numpy as np\nimport scipy.io as sio\nimport PIL\nfrom PIL import Image\nimport torch\n\nfrom torch.utils import data\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torchvision.transforms as standard_transforms\n\nimport utils.voc_utils as extended_transforms\nfrom utils.voc_utils import make_dataset\n\n\nclass VOC(data.Dataset):\n    def __init__(self, mode, data_root, joint_transform=None, sliding_crop=None, transform=None, target_transform=None):\n        self.imgs = make_dataset(mode, data_root)\n        if len(self.imgs) == 0:\n            raise RuntimeError(\'Found 0 images, please check the data set\')\n        self.mode = mode\n        self.joint_transform = joint_transform\n        self.sliding_crop = sliding_crop\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __getitem__(self, index):\n        if self.mode == \'test\':\n            img_path, img_name = self.imgs[index]\n            img = Image.open(os.path.join(img_path, img_name + \'.jpg\')).convert(\'RGB\')\n            if self.transform is not None:\n                img = self.transform(img)\n            return img_name, img\n\n        img_path, mask_path = self.imgs[index]\n        img = Image.open(img_path).convert(\'RGB\')\n        if self.mode == \'train\':\n            mask = sio.loadmat(mask_path)[\'GTcls\'][\'Segmentation\'][0][0]\n            mask = Image.fromarray(mask.astype(np.uint8))\n        else:\n            mask = Image.open(mask_path)\n\n        if self.joint_transform is not None:\n            img, mask = self.joint_transform(img, mask)\n\n        if self.sliding_crop is not None:\n            img_slices, mask_slices, slices_info = self.sliding_crop(img, mask)\n            if self.transform is not None:\n                img_slices = [self.transform(e) for e in img_slices]\n            if self.target_transform is not None:\n                mask_slices = [self.target_transform(e) for e in mask_slices]\n            img, mask = torch.stack(img_slices, 0), torch.stack(mask_slices, 0)\n            return img, mask, torch.LongTensor(slices_info)\n        else:\n            if self.transform is not None:\n                img = self.transform(img)\n            if self.target_transform is not None:\n                mask = self.target_transform(mask)\n            return img, mask\n\n    def __len__(self):\n        return len(self.imgs)\n\n\nclass VOCDataLoader:\n    def __init__(self, config):\n        self.config = config\n        assert self.config.mode in [\'train\', \'test\', \'random\']\n\n        mean_std = ([103.939, 116.779, 123.68], [1.0, 1.0, 1.0])\n\n        self.input_transform = standard_transforms.Compose([\n            standard_transforms.Resize((256, 256), interpolation=PIL.Image.BILINEAR),\n            extended_transforms.FlipChannels(),\n            standard_transforms.ToTensor(),\n            standard_transforms.Lambda(lambda x: x.mul_(255)),\n            standard_transforms.Normalize(*mean_std)\n        ])\n\n        self.target_transform = standard_transforms.Compose([\n            standard_transforms.Resize((256, 256), interpolation=PIL.Image.NEAREST),\n            extended_transforms.MaskToTensor()\n        ])\n\n        self.restore_transform = standard_transforms.Compose([\n            extended_transforms.DeNormalize(*mean_std),\n            standard_transforms.Lambda(lambda x: x.div_(255)),\n            standard_transforms.ToPILImage(),\n            extended_transforms.FlipChannels()\n        ])\n\n        self.visualize = standard_transforms.Compose([\n            standard_transforms.Resize(400),\n            standard_transforms.CenterCrop(400),\n            standard_transforms.ToTensor()\n        ])\n        if self.config.mode == \'random\':\n            train_data = torch.randn(self.config.batch_size, self.config.input_channels, self.config.img_size,\n                                     self.config.img_size)\n            train_labels = torch.ones(self.config.batch_size, self.config.img_size, self.config.img_size).long()\n            valid_data = train_data\n            valid_labels = train_labels\n            self.len_train_data = train_data.size()[0]\n            self.len_valid_data = valid_data.size()[0]\n\n            self.train_iterations = (self.len_train_data + self.config.batch_size - 1) // self.config.batch_size\n            self.valid_iterations = (self.len_valid_data + self.config.batch_size - 1) // self.config.batch_size\n\n            train = TensorDataset(train_data, train_labels)\n            valid = TensorDataset(valid_data, valid_labels)\n\n            self.train_loader = DataLoader(train, batch_size=config.batch_size, shuffle=True)\n            self.valid_loader = DataLoader(valid, batch_size=config.batch_size, shuffle=False)\n\n        elif self.config.mode == \'train\':\n            train_set = VOC(\'train\', self.config.data_root,\n                            transform=self.input_transform, target_transform=self.target_transform)\n            valid_set = VOC(\'val\', self.config.data_root,\n                            transform=self.input_transform, target_transform=self.target_transform)\n\n            self.train_loader = DataLoader(train_set, batch_size=self.config.batch_size, shuffle=True,\n                                           num_workers=self.config.data_loader_workers,\n                                           pin_memory=self.config.pin_memory)\n            self.valid_loader = DataLoader(valid_set, batch_size=self.config.batch_size, shuffle=False,\n                                           num_workers=self.config.data_loader_workers,\n                                           pin_memory=self.config.pin_memory)\n            self.train_iterations = (len(train_set) + self.config.batch_size) // self.config.batch_size\n            self.valid_iterations = (len(valid_set) + self.config.batch_size) // self.config.batch_size\n\n        elif self.config.mode == \'test\':\n            test_set = VOC(\'test\', self.config.data_root,\n                           transform=self.input_transform, target_transform=self.target_transform)\n\n            self.test_loader = DataLoader(test_set, batch_size=self.config.batch_size, shuffle=False,\n                                          num_workers=self.config.data_loader_workers,\n                                          pin_memory=self.config.pin_memory)\n            self.test_iterations = (len(test_set) + self.config.batch_size) // self.config.batch_size\n\n        else:\n            raise Exception(\'Please choose a proper mode for data loading\')\n\n    def finalize(self):\n        pass\n\n\ndef calculate_weigths_labels():\n    class Config:\n        mode = ""train""\n        num_classes = 21\n        batch_size = 32\n        max_epoch = 150\n\n        validate_every = 2\n\n        checkpoint_file = ""checkpoint.pth.tar""\n\n        data_loader = ""VOCDataLoader""\n        data_root = ""../data/pascal_voc_seg/""\n        data_loader_workers = 4\n        pin_memory = True\n        async_loading = True\n\n    # Create an instance from the data loader\n    from tqdm import tqdm\n    data_loader = VOCDataLoader(Config)\n    z = np.zeros((Config.num_classes,))\n    # Initialize tqdm\n    tqdm_batch = tqdm(data_loader.train_loader, total=data_loader.train_iterations)\n\n    for _, y in tqdm_batch:\n        labels = y.numpy().astype(np.uint8).ravel().tolist()\n        z += np.bincount(labels, minlength=Config.num_classes)\n    tqdm_batch.close()\n    # ret = compute_class_weight(class_weight=\'balanced\', classes=np.arange(21), y=np.asarray(labels, dtype=np.uint8))\n    total_frequency = np.sum(z)\n    print(z)\n    print(total_frequency)\n    class_weights = []\n    for frequency in z:\n        class_weight = 1 / (np.log(1.02 + (frequency / total_frequency)))\n        class_weights.append(class_weight)\n    ret = np.array(class_weights)\n    np.save(\'../pretrained_weights/voc2012_256_class_weights\', ret)\n    print(ret)\n\n\nif __name__ == \'__main__\':\n    calculate_weigths_labels()\n'"
utils/metrics.py,0,"b'""""""\nThis file will contain the metrics of the framework\n""""""\nimport numpy as np\n\n\nclass IOUMetric:\n    """"""\n    Class to calculate mean-iou using fast_hist method\n    """"""\n\n    def __init__(self, num_classes):\n        self.num_classes = num_classes\n        self.hist = np.zeros((num_classes, num_classes))\n\n    def _fast_hist(self, label_pred, label_true):\n        mask = (label_true >= 0) & (label_true < self.num_classes)\n        hist = np.bincount(\n            self.num_classes * label_true[mask].astype(int) +\n            label_pred[mask], minlength=self.num_classes ** 2).reshape(self.num_classes, self.num_classes)\n        return hist\n\n    def add_batch(self, predictions, gts):\n        for lp, lt in zip(predictions, gts):\n            self.hist += self._fast_hist(lp.flatten(), lt.flatten())\n\n    def evaluate(self):\n        acc = np.diag(self.hist).sum() / self.hist.sum()\n        acc_cls = np.diag(self.hist) / self.hist.sum(axis=1)\n        acc_cls = np.nanmean(acc_cls)\n        iu = np.diag(self.hist) / (self.hist.sum(axis=1) + self.hist.sum(axis=0) - np.diag(self.hist))\n        mean_iu = np.nanmean(iu)\n        freq = self.hist.sum(axis=1) / self.hist.sum()\n        fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n        return acc, acc_cls, iu, mean_iu, fwavacc\n\n\nclass AverageMeter:\n    """"""\n    Class to be an average meter for any average metric like loss, accuracy, etc..\n    """"""\n\n    def __init__(self):\n        self.value = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n        self.reset()\n\n    def reset(self):\n        self.value = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.value = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    @property\n    def val(self):\n        return self.avg\n\n\nclass AverageMeterList:\n    """"""\n    Class to be an average meter for any average metric List structure like mean_iou_per_class\n    """"""\n\n    def __init__(self, num_cls):\n        self.cls = num_cls\n        self.value = [0] * self.cls\n        self.avg = [0] * self.cls\n        self.sum = [0] * self.cls\n        self.count = [0] * self.cls\n        self.reset()\n\n    def reset(self):\n        self.value = [0] * self.cls\n        self.avg = [0] * self.cls\n        self.sum = [0] * self.cls\n        self.count = [0] * self.cls\n\n    def update(self, val, n=1):\n        for i in range(self.cls):\n            self.value[i] = val[i]\n            self.sum[i] += val[i] * n\n            self.count[i] += n\n            self.avg[i] = self.sum[i] / self.count[i]\n\n    @property\n    def val(self):\n        return self.avg\n\n\ndef cls_accuracy(output, target, topk=(1,)):\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k / batch_size)\n    return res\n'"
utils/misc.py,6,"b'import time\nimport logging\n\n\ndef timeit(f):\n    """""" Decorator to time Any Function """"""\n\n    def timed(*args, **kwargs):\n        start_time = time.time()\n        result = f(*args, **kwargs)\n        end_time = time.time()\n        seconds = end_time - start_time\n        logging.getLogger(""Timer"").info(""   [-] %s : %2.5f sec, which is %2.5f min, which is %2.5f hour"" %\n                                        (f.__name__, seconds, seconds / 60, seconds / 3600))\n        return result\n\n    return timed\n\n\ndef print_cuda_statistics():\n    logger = logging.getLogger(""Cuda Statistics"")\n    import sys\n    from subprocess import call\n    import torch\n    logger.info(\'__Python VERSION:  {}\'.format(sys.version))\n    logger.info(\'__pyTorch VERSION:  {}\'.format(torch.__version__))\n    logger.info(\'__CUDA VERSION\')\n    call([""nvcc"", ""--version""])\n    logger.info(\'__CUDNN VERSION:  {}\'.format(torch.backends.cudnn.version()))\n    logger.info(\'__Number CUDA Devices:  {}\'.format(torch.cuda.device_count()))\n    logger.info(\'__Devices\')\n    call([""nvidia-smi"", ""--format=csv"",\n          ""--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free""])\n    logger.info(\'Active CUDA Device: GPU {}\'.format(torch.cuda.current_device()))\n    logger.info(\'Available devices  {}\'.format(torch.cuda.device_count()))\n    logger.info(\'Current cuda device  {}\'.format(torch.cuda.current_device()))\n'"
utils/replay_memory.py,1,"b'""""""\nReplay Memory class\nAdapted from: https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\ndate: 1st of June 2018\n""""""\nimport random\nfrom collections import namedtuple\n\nTransition = namedtuple(\'Transition\', (\'state\', \'action\', \'next_state\', \'reward\'))\n\n\nclass ReplayMemory(object):\n    def __init__(self, config):\n        self.config = config\n\n        self.capacity = self.config.memory_capacity\n        self.memory = []\n        self.position = 0\n\n    def length(self):\n        return len(self.memory)\n\n    def push_transition(self, *args):\n        if self.length() < self.capacity:\n            self.memory.append(None)\n        self.memory[self.position] = Transition(*args)\n        self.position = (self.position + 1) % self.capacity  # for the cyclic buffer\n\n    def sample_batch(self, batch_size):\n        batch = random.sample(self.memory, batch_size)\n        return batch\n'"
utils/train_utils.py,2,"b'import torch\nfrom torch import nn\nfrom torch.backends import cudnn\nfrom torch.autograd import Variable\nimport math\n\n""""""\nLearning rate adjustment used for CondenseNet model training\n""""""\ndef adjust_learning_rate(optimizer, epoch, config, batch=None, nBatch=None, method=\'cosine\'):\n    if method == \'cosine\':\n        T_total = config.max_epoch * nBatch\n        T_cur = (epoch % config.max_epoch) * nBatch + batch\n        lr = 0.5 * config.learning_rate * (1 + math.cos(math.pi * T_cur / T_total))\n    else:\n        """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n        lr = config.learning_rate * (0.1 ** (epoch // 30))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n    return lr\n'"
utils/voc_utils.py,1,"b'import os\nimport random\n\nimport numpy as np\nfrom skimage.filters import gaussian\nimport torch\nfrom PIL import Image\n\n""""""\ncolor map\n0=background, 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle # 6=bus, 7=car, 8=cat, 9=chair, 10=cow, 11=diningtable,\n12=dog, 13=horse, 14=motorbike, 15=person # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n""""""\npalette = [0, 0, 0, 128, 0, 0, 0, 128, 0, 128, 128, 0, 0, 0, 128, 128, 0, 128, 0, 128, 128,\n           128, 128, 128, 64, 0, 0, 192, 0, 0, 64, 128, 0, 192, 128, 0, 64, 0, 128, 192, 0, 128,\n           64, 128, 128, 192, 128, 128, 0, 64, 0, 128, 64, 0, 0, 192, 0, 128, 192, 0, 0, 64, 128]\n\nzero_pad = 256 * 3 - len(palette)\nfor i in range(zero_pad):\n    palette.append(0)\n\n\ndef colorize_mask(mask):\n    # mask: numpy array of the mask\n    new_mask = Image.fromarray(mask.astype(np.uint8)).convert(\'P\')\n    new_mask.putpalette(palette)\n\n    return new_mask\n\n\ndef make_dataset(mode, root):\n    assert mode in [\'train\', \'val\', \'validate\', \'test\', \'inference\']\n    items = []\n    if mode == \'train\':\n        img_path = os.path.join(root, \'benchmark_RELEASE\', \'dataset\', \'img\')\n        mask_path = os.path.join(root, \'benchmark_RELEASE\', \'dataset\', \'cls\')\n        data_list = [l.strip(\'\\n\') for l in open(os.path.join(\n            root, \'benchmark_RELEASE\', \'dataset\', \'train.txt\')).readlines()]\n        for it in data_list:\n            item = (os.path.join(img_path, it + \'.jpg\'), os.path.join(mask_path, it + \'.mat\'))\n            items.append(item)\n    elif mode == \'val\' or mode == \'validate\':\n        img_path = os.path.join(root, \'VOCdevkit\', \'VOC2012\', \'JPEGImages\')\n        mask_path = os.path.join(root, \'VOCdevkit\', \'VOC2012\', \'SegmentationClass\')\n        data_list = [l.strip(\'\\n\') for l in open(os.path.join(\n            root, \'VOCdevkit\', \'VOC2012\', \'ImageSets\', \'Segmentation\', \'seg11valid.txt\')).readlines()]\n        for it in data_list:\n            item = (os.path.join(img_path, it + \'.jpg\'), os.path.join(mask_path, it + \'.png\'))\n            items.append(item)\n    elif mode == \'test\' or mode == \'inference\':\n        img_path = os.path.join(root, \'VOCdevkit (test)\', \'VOC2012\', \'JPEGImages\')\n        data_list = [l.strip(\'\\n\') for l in open(os.path.join(\n            root, \'VOCdevkit (test)\', \'VOC2012\', \'ImageSets\', \'Segmentation\', \'test.txt\')).readlines()]\n        for it in data_list:\n            items.append((img_path, it))\n    else:\n        raise Exception(""Please choose proper mode for data"")\n    return items\n\n\nclass RandomVerticalFlip(object):\n    def __call__(self, img):\n        if random.random() < 0.5:\n            return img.transpose(Image.FLIP_TOP_BOTTOM)\n        return img\n\n\nclass DeNormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n        return tensor\n\n\nclass MaskToTensor(object):\n    def __call__(self, img):\n        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n\n\nclass FreeScale(object):\n    def __init__(self, size, interpolation=Image.BILINEAR):\n        self.size = tuple(reversed(size))  # size: (h, w)\n        self.interpolation = interpolation\n\n    def __call__(self, img):\n        return img.resize(self.size, self.interpolation)\n\n\nclass FlipChannels(object):\n    def __call__(self, img):\n        img = np.array(img)[:, :, ::-1]\n        return Image.fromarray(img.astype(np.uint8))\n\n\nclass RandomGaussianBlur(object):\n    def __call__(self, img):\n        sigma = 0.15 + random.random() * 1.15\n        blurred_img = gaussian(np.array(img), sigma=sigma, multichannel=True)\n        blurred_img *= 255\n        return Image.fromarray(blurred_img.astype(np.uint8))\n'"
graphs/losses/__init__.py,0,"b""import os\nimport sys\n\npath = os.path.dirname(os.path.abspath(__file__))\n\nfor py in [f[:-3] for f in os.listdir(path) if f.endswith('.py') and f != '__init__.py']:\n    mod = __import__('.'.join([__name__, py]), fromlist=[py])\n    classes = [getattr(mod, x) for x in dir(mod) if isinstance(getattr(mod, x), type)]\n    for cls in classes:\n        setattr(sys.modules[__name__], cls.__name__, cls)"""
graphs/losses/bce.py,1,"b'""""""\nBinary Cross Entropy for DCGAN\n""""""\n\nimport torch\nimport torch.nn as nn\n\n\nclass BinaryCrossEntropy(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.loss = nn.BCELoss()\n\n    def forward(self, logits, labels):\n        loss = self.loss(logits, labels)\n        return loss\n'"
graphs/losses/cross_entropy.py,3,"b'""""""\nCross Entropy 2D for CondenseNet\n""""""\n\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\n\nimport numpy as np\n\n\nclass CrossEntropyLoss(nn.Module):\n    def __init__(self, config=None):\n        super(CrossEntropyLoss, self).__init__()\n        if config == None:\n            self.loss = nn.CrossEntropyLoss()\n        else:\n            class_weights = np.load(config.class_weights)\n            self.loss = nn.CrossEntropyLoss(ignore_index=config.ignore_index,\n                                      weight=torch.from_numpy(class_weights.astype(np.float32)),\n                                      size_average=True, reduce=True)\n\n    def forward(self, inputs, targets):\n        return self.loss(inputs, targets)'"
graphs/losses/example.py,1,"b'""""""\nAn example for loss class definition, that will be used in the agent\n""""""\nimport torch.nn as nn\n\n\nclass CrossEntropyLoss2d(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(CrossEntropyLoss2d, self).__init__()\n        self.loss = nn.CrossEntropyLoss()\n\n    def forward(self, logits, labels):\n        loss = self.loss(logits, labels)\n        return loss\n\n\nclass BinaryCrossEntropy(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.loss = nn.BCELoss()\n\n    def forward(self, logits, labels):\n        loss = self.loss(logits, labels)\n        return loss'"
graphs/losses/huber_loss.py,1,"b'""""""\nHuber Loss for DQN model\n""""""\nimport torch\nimport torch.nn as nn\n\n\nclass HuberLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.loss = nn.SmoothL1Loss()\n\n    def forward(self, logits, labels):\n        loss = self.loss(logits, labels)\n        return loss\n'"
graphs/models/__init__.py,0,"b""import os\nimport sys\n\npath = os.path.dirname(os.path.abspath(__file__))\n\nfor py in [f[:-3] for f in os.listdir(path) if f.endswith('.py') and f != '__init__.py']:\n    mod = __import__('.'.join([__name__, py]), fromlist=[py])\n    classes = [getattr(mod, x) for x in dir(mod) if isinstance(getattr(mod, x), type)]\n    for cls in classes:\n        setattr(sys.modules[__name__], cls.__name__, cls)"""
graphs/models/condensenet.py,1,"b'""""""\nCondenseNet Model\nname: condensenet.py\ndate: May 2018\n""""""\nimport torch\nimport torch.nn as nn\nimport json\nfrom easydict import EasyDict as edict\nimport numpy as np\n\nfrom graphs.weights_initializer import init_model_weights\nfrom graphs.models.custom_layers.denseblock import DenseBlock\nfrom graphs.models.custom_layers.learnedgroupconv import LearnedGroupConv\n\nclass CondenseNet(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n\n        self.stages = self.config.stages\n        self.growth_rate = self.config.growth_rate\n        assert len(self.stages) == len(self.growth_rate)\n\n        self.init_stride = self.config.init_stride\n        self.pool_size = self.config.pool_size\n        self.num_classes = self.config.num_classes\n\n        self.progress = 0.0\n        self.num_filters = 2 * self.growth_rate[0]\n        """"""\n        Initializing layers\n        """"""\n        self.transition_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n\n        self.pool = nn.AvgPool2d(self.pool_size)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.init_conv = nn.Conv2d(in_channels=self.config.input_channels, out_channels=self.num_filters, kernel_size=3, stride=self.init_stride, padding=1, bias=False)\n\n        self.denseblock_one = DenseBlock(num_layers=self.stages[0], in_channels= self.num_filters, growth_rate=self.growth_rate[0], config=self.config)\n\n        self.num_filters += self.stages[0] * self.growth_rate[0]\n\n        self.denseblock_two = DenseBlock(num_layers=self.stages[1], in_channels= self.num_filters, growth_rate=self.growth_rate[1], config=self.config)\n\n        self.num_filters += self.stages[1] * self.growth_rate[1]\n\n        self.denseblock_three = DenseBlock(num_layers=self.stages[2], in_channels= self.num_filters, growth_rate=self.growth_rate[2], config=self.config)\n\n        self.num_filters += self.stages[2] * self.growth_rate[2]\n        self.batch_norm = nn.BatchNorm2d(self.num_filters)\n\n        self.classifier = nn.Linear(self.num_filters, self.num_classes)\n\n        self.apply(init_model_weights)\n\n    def forward(self, x, progress=None):\n        if progress:\n            LearnedGroupConv.global_progress = progress\n\n        x = self.init_conv(x)\n\n        x = self.denseblock_one(x)\n        x = self.transition_pool(x)\n\n        x = self.denseblock_two(x)\n        x = self.transition_pool(x)\n\n        x = self.denseblock_three(x)\n        x = self.batch_norm(x)\n        x = self.relu(x)\n        x = self.pool(x)\n\n        x = x.view(x.size(0), -1)\n\n        out = self.classifier(x)\n\n        return out\n\n""""""\n#########################\nModel Architecture:\n#########################\n\nInput: (N, 32, 32, 3)\n\n- Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\nDenseBlock(num_layers=14, in_channels=16, growth_rate=8)\n- AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\nDenseBlock(num_layers=14, in_channels=128, growth_rate=16)\n- AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\nDenseBlock(num_layers=14, in_channels=352, growth_rate=32)\n- BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n- ReLU(inplace)\n- AvgPool2d(kernel_size=8, stride=8, padding=0, ceil_mode=False, count_include_pad=True)\n- Linear(in_features=800, out_features=10, bias=True)\n""""""\n'"
graphs/models/dcgan_discriminator.py,2,"b'""""""\nDCGAN discriminator model\nbased on the paper: https://arxiv.org/pdf/1511.06434.pdf\ndate: 30 April 2018\n""""""\nimport torch\nimport torch.nn as nn\n\nimport json\nfrom easydict import EasyDict as edict\nfrom graphs.weights_initializer import weights_init\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n\n        self.relu = nn.LeakyReLU(self.config.relu_slope, inplace=True)\n\n        self.conv1 = nn.Conv2d(in_channels=self.config.input_channels, out_channels=self.config.num_filt_d, kernel_size=4, stride=2, padding=1, bias=False)\n\n        self.conv2 = nn.Conv2d(in_channels=self.config.num_filt_d, out_channels=self.config.num_filt_d * 2, kernel_size=4, stride=2, padding=1, bias=False)\n        self.batch_norm1 = nn.BatchNorm2d(self.config.num_filt_d*2)\n\n        self.conv3 = nn.Conv2d(in_channels=self.config.num_filt_d*2, out_channels=self.config.num_filt_d * 4, kernel_size=4, stride=2, padding=1, bias=False)\n        self.batch_norm2 = nn.BatchNorm2d(self.config.num_filt_d*4)\n\n        self.conv4 = nn.Conv2d(in_channels=self.config.num_filt_d*4, out_channels=self.config.num_filt_d*8, kernel_size=4, stride=2, padding=1, bias=False)\n        self.batch_norm3 = nn.BatchNorm2d(self.config.num_filt_d*8)\n\n        self.conv5 = nn.Conv2d(in_channels=self.config.num_filt_d*8, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False)\n\n        self.out = nn.Sigmoid()\n\n        self.apply(weights_init)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.batch_norm1(out)\n        out =  self.relu(out)\n\n        out = self.conv3(out)\n        out = self.batch_norm2(out)\n        out =  self.relu(out)\n\n        out = self.conv4(out)\n        out = self.batch_norm3(out)\n        out =  self.relu(out)\n\n        out = self.conv5(out)\n        out = self.out(out)\n\n        return out.view(-1, 1).squeeze(1)\n\n\n""""""\nnetD testing\n""""""\ndef main():\n    config = json.load(open(\'../../configs/dcgan_exp_0.json\'))\n    config = edict(config)\n    inp  = torch.autograd.Variable(torch.randn(config.batch_size, config.input_channels, config.image_size, config.image_size))\n    print (inp.shape)\n    netD = Discriminator(config)\n    out = netD(inp)\n    print (out)\n\nif __name__ == \'__main__\':\n    main()\n'"
graphs/models/dcgan_generator.py,2,"b'""""""\nDCGAN generator model\nbased on the paper: https://arxiv.org/pdf/1511.06434.pdf\ndate: 30 April 2018\n""""""\nimport torch\nimport torch.nn as nn\n\nimport json\nfrom easydict import EasyDict as edict\nfrom graphs.weights_initializer import weights_init\n\nclass Generator(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n\n        self.relu = nn.ReLU(inplace=True)\n\n        self.deconv1 = nn.ConvTranspose2d(in_channels=self.config.g_input_size, out_channels=self.config.num_filt_g * 8, kernel_size=4, stride=1, padding=0, bias=False)\n        self.batch_norm1 = nn.BatchNorm2d(self.config.num_filt_g*8)\n\n        self.deconv2 = nn.ConvTranspose2d(in_channels=self.config.num_filt_g * 8, out_channels=self.config.num_filt_g * 4, kernel_size=4, stride=2, padding=1, bias=False)\n        self.batch_norm2 = nn.BatchNorm2d(self.config.num_filt_g*4)\n\n        self.deconv3 = nn.ConvTranspose2d(in_channels=self.config.num_filt_g * 4, out_channels=self.config.num_filt_g * 2, kernel_size=4, stride=2, padding=1, bias=False)\n        self.batch_norm3 = nn.BatchNorm2d(self.config.num_filt_g*2)\n\n        self.deconv4 = nn.ConvTranspose2d(in_channels=self.config.num_filt_g * 2, out_channels=self.config.num_filt_g , kernel_size=4, stride=2, padding=1, bias=False)\n        self.batch_norm4 = nn.BatchNorm2d(self.config.num_filt_g)\n\n        self.deconv5 = nn.ConvTranspose2d(in_channels=self.config.num_filt_g, out_channels=self.config.input_channels, kernel_size=4, stride=2, padding=1, bias=False)\n\n        self.out = nn.Tanh()\n\n        self.apply(weights_init)\n\n    def forward(self, x):\n        out = self.deconv1(x)\n        out = self.batch_norm1(out)\n        out = self.relu(out)\n\n        out = self.deconv2(out)\n        out = self.batch_norm2(out)\n        out =  self.relu(out)\n\n        out = self.deconv3(out)\n        out = self.batch_norm3(out)\n        out =  self.relu(out)\n\n        out = self.deconv4(out)\n        out = self.batch_norm4(out)\n        out =  self.relu(out)\n\n        out = self.deconv5(out)\n\n        out = self.out(out)\n\n        return out\n\n\n""""""\nnetG testing\n""""""\ndef main():\n    config = json.load(open(\'../../configs/dcgan_exp_0.json\'))\n    config = edict(config)\n    inp  = torch.autograd.Variable(torch.randn(config.batch_size, config.g_input_size, 1, 1))\n    print (inp.shape)\n    netD = Generator(config)\n    out = netD(inp)\n    print (out.shape)\n\nif __name__ == \'__main__\':\n    main()\n'"
graphs/models/dqn.py,6,"b'""""""\nDeep Q Network model\nbased on the paper: https://www.nature.com/articles/nature14236\ndate: 1st of June 2018\n""""""\nimport torch\nimport torch.nn as nn\n\nfrom graphs.weights_initializer import weights_init\n\n\nclass DQN(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv1 = nn.Conv2d(in_channels=self.config.input_channels, out_channels=self.config.conv_filters[0], kernel_size=5, stride=2, padding=0, bias=True)\n        self.bn1 = nn.BatchNorm2d(self.config.conv_filters[0])\n\n        self.conv2 = nn.Conv2d(in_channels=self.config.conv_filters[0], out_channels=self.config.conv_filters[1], kernel_size=5, stride=2, padding=0, bias=True)\n        self.bn2 = nn.BatchNorm2d(self.config.conv_filters[1])\n\n        self.conv3 = nn.Conv2d(in_channels=self.config.conv_filters[1], out_channels=self.config.conv_filters[2], kernel_size=5, stride=2, padding=0, bias=True)\n        self.bn3 = nn.BatchNorm2d(self.config.conv_filters[2])\n\n        self.linear = nn.Linear(448, self.config.num_classes)\n\n        self.apply(weights_init)\n\n    def forward(self, x):\n\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n        x = self.relu(x)\n\n        out = self.linear(x.view(x.size(0), -1))\n\n        return out\n\n\n""""""\n#########################\nArchitecture:\n#########################\nInput: (N, 3, 40, 80)\n\nConv2d(3, 16, kernel_size=(5, 5), stride=(2, 2))\nConv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\nConv2d(32, 32, kernel_size=(5, 5), stride=(2, 2))\nLinear(in_features=448, out_features=2, bias=True)\n----\ntorch.Size([128, 3, 40, 80])\ntorch.Size([128, 16, 18, 38])\ntorch.Size([128, 32, 7, 17])\ntorch.Size([128, 32, 2, 7]) --> 32x2x7 = 448\ntorch.Size([128, 2])\n\n""""""\n'"
graphs/models/erfnet.py,1,"b'""""""\nERFNet Model\nJuly 2017\nAdapted from: https://github.com/Eromera/erfnet_pytorch/blob/master/train/erfnet.py\n""""""\nimport torch.nn as nn\n\nfrom graphs.models.custom_layers.erf_blocks import DownsamplerBlock, UpsamplerBlock, non_bottleneck_1d\n\n\nclass ERF(nn.Module):\n    def __init__(self, config, encoder=None):  # use encoder to pass pretrained encoder\n        super().__init__()\n\n        self.config = config\n        self.num_classes = self.config.num_classes\n\n        if encoder == None:\n            self.encoder_flag = True\n            self.encoder_layers = nn.ModuleList()\n\n            # layer 1, downsampling\n            self.initial_block = DownsamplerBlock(self.config.input_channels, 16)\n\n            # layer 2, downsampling\n            self.encoder_layers.append(DownsamplerBlock(in_channel=16, out_channel=64))\n\n            # non-bottleneck 1d - layers 3 to 7\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=64, drop_rate=0.03, dilated=1))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=64, drop_rate=0.03, dilated=1))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=64, drop_rate=0.03, dilated=1))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=64, drop_rate=0.03, dilated=1))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=64, drop_rate=0.03, dilated=1))\n\n            # layer 8, downsampling\n            self.encoder_layers.append(DownsamplerBlock(in_channel=64, out_channel=128))\n\n            # non-bottleneck 1d - layers 9 to 16\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=128, drop_rate=0.3, dilated=2))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=128, drop_rate=0.3, dilated=4))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=128, drop_rate=0.3, dilated=8))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=128, drop_rate=0.3, dilated=16))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=128, drop_rate=0.3, dilated=2))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=128, drop_rate=0.3, dilated=4))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=128, drop_rate=0.3, dilated=8))\n            self.encoder_layers.append(non_bottleneck_1d(n_channel=128, drop_rate=0.3, dilated=16))\n\n        else:\n            self.encoder_flag = False\n            self.encoder = encoder\n\n        self.decoder_layers = nn.ModuleList()\n\n        self.decoder_layers.append(UpsamplerBlock(in_channel=128, out_channel=64))\n        self.decoder_layers.append(non_bottleneck_1d(n_channel=64, drop_rate=0, dilated=1))\n        self.decoder_layers.append(non_bottleneck_1d(n_channel=64, drop_rate=0, dilated=1))\n\n        self.decoder_layers.append(UpsamplerBlock(in_channel=64, out_channel=16))\n        self.decoder_layers.append(non_bottleneck_1d(n_channel=16, drop_rate=0, dilated=1))\n        self.decoder_layers.append(non_bottleneck_1d(n_channel=16, drop_rate=0, dilated=1))\n\n        self.output_conv = nn.ConvTranspose2d(in_channels=16, out_channels=self.num_classes,kernel_size=2, stride=2, padding=0, output_padding=0, bias=True)\n\n        # self.apply(weights_init_normal)\n\n    def forward(self, x):\n        if self.encoder_flag:\n            output = self.initial_block(x)\n\n            for layer in self.encoder_layers:\n                output = layer(output)\n        else:\n            output = self.encoder(x)\n\n        for layer in self.decoder_layers:\n            output = layer(output)\n\n        output = self.output_conv(output)\n\n        return output\n'"
graphs/models/erfnet_imagenet.py,1,"b'# ERFNet encoder model definition used for pretraining in ImageNet\n# Sept 2017\n# Eduardo Romera\n# A\n#######################\n""""""\nERFNet encoder model definition used for pretraining in ImageNet\nSept 2017\nEduardo Romera\nTaken from: https://github.com/Eromera/erfnet_pytorch/blob/master/train/erfnet_imagenet.py\n""""""\n\nimport torch.nn as nn\n\nfrom graphs.models.custom_layers.erf_blocks import DownsamplerBlock, non_bottleneck_1d\n\n\nclass ERFNet(nn.Module):\n    def __init__(self, num_classes):  # use encoder to pass pretrained encoder\n        super().__init__()\n\n        self.features = Features()\n        self.classifier = Classifier(num_classes)\n\n    def forward(self, input):\n        output = self.features(input)\n        output = self.classifier(output)\n        return output\n\n\nclass Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.initial_block = DownsamplerBlock(3, 16)\n\n        self.layers = nn.ModuleList()\n\n        self.layers.append(DownsamplerBlock(16, 64))\n\n        for x in range(0, 5):  # 5 times\n            self.layers.append(non_bottleneck_1d(64, 0.1, 1))\n\n        self.layers.append(DownsamplerBlock(64, 128))\n\n        for x in range(0, 2):  # 2 times\n            self.layers.append(non_bottleneck_1d(128, 0.1, 2))\n            self.layers.append(non_bottleneck_1d(128, 0.1, 4))\n            self.layers.append(non_bottleneck_1d(128, 0.1, 8))\n            self.layers.append(non_bottleneck_1d(128, 0.1, 16))\n\n    def forward(self, input):\n        output = self.initial_block(input)\n\n        for layer in self.layers:\n            output = layer(output)\n\n        return output\n\n\nclass Features(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = Encoder()\n        self.extralayer1 = nn.MaxPool2d(2, stride=2)\n        self.extralayer2 = nn.AvgPool2d(14, 1, 0)\n\n    def forward(self, input):\n        # print(""Feat input: "", input.size())\n        output = self.encoder(input)\n        output = self.extralayer1(output)\n        output = self.extralayer2(output)\n        # print(""Feat output: "", output.size())\n        return output\n\n\nclass Classifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.linear = nn.Linear(128, num_classes)\n\n    def forward(self, input):\n        output = input.view(input.size(0), 128)  # first is batch_size\n        output = self.linear(output)\n        return output\n\n'"
graphs/models/example.py,1,"b'""""""\nAn example for the model class\n""""""\nimport torch.nn as nn\n\nfrom graphs.weights_initializer import weights_init\n\nclass Example(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n\n        # define layers\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv = nn.Conv2d(in_channels=self.config.input_channels, out_channels=self.config.num_filters, kernel_size=3, stride=1, padding=1, bias=False)\n\n        # initialize weights\n        self.apply(weights_init)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.relu(x)\n\n        out = x.view(x.size(0), -1)\n        return out\n'"
graphs/models/mnist.py,2,"b'""""""\nMnist tutorial main model\n""""""\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom ..weights_initializer import weights_init\n\n\nclass Mnist(nn.Module):\n    def __init__(self):\n        super(Mnist, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n        self.apply(weights_init)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)'"
graphs/models/custom_layers/__init__.py,0,b''
graphs/models/custom_layers/denseblock.py,2,"b'""""""\nDefinitions for custom blocks for condensenet model\n""""""\nimport torch\nimport torch.nn as nn\nfrom graphs.models.custom_layers.learnedgroupconv import LearnedGroupConv\n\nclass DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, in_channels, growth_rate, config):\n        super().__init__()\n\n        for layer_id in range(num_layers):\n            layer = DenseLayer(in_channels=in_channels + (layer_id * growth_rate), growth_rate=growth_rate, config=config)\n            self.add_module(\'dense_layer_%d\' % (layer_id + 1), layer)\n\nclass DenseLayer(nn.Module):\n    def __init__(self, in_channels, growth_rate, config):\n        super().__init__()\n        self.config = config\n        self.conv_bottleneck = self.config.conv_bottleneck\n        self.group1x1 = self.config.group1x1\n        self.group3x3 = self.config.group3x3\n        self.condense_factor = self.config.condense_factor\n        self.dropout_rate = self.config.dropout_rate\n\n        # 1x1 conv in_channels --> bottleneck*growth_rate\n        self.conv_1 = LearnedGroupConv(in_channels=in_channels, out_channels=self.conv_bottleneck * growth_rate, kernel_size=1,\n                                       groups=self.group1x1, condense_factor=self.condense_factor, dropout_rate=self.dropout_rate)\n\n        self.batch_norm = nn.BatchNorm2d(self.conv_bottleneck * growth_rate)\n        self.relu = nn.ReLU(inplace=True)\n\n        # 3x3 conv bottleneck*growth_rate --> growth_rate\n        self.conv_2 = nn.Conv2d(in_channels=self.conv_bottleneck * growth_rate, out_channels=growth_rate, kernel_size=3, padding=1, stride=1, groups=self.group3x3, bias=False)\n\n    def forward(self, x):\n        out = self.conv_1(x)\n        out = self.batch_norm(out)\n        out = self.relu(out)\n        out = self.conv_2(out)\n\n        return torch.cat([x, out], 1)\n'"
graphs/models/custom_layers/erf_blocks.py,4,"b'""""""\nCustom ERFNet building blocks\nAdapted from: https://github.com/Eromera/erfnet_pytorch/blob/master/train/erfnet.py\n""""""\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\n\nclass non_bottleneck_1d(nn.Module):\n    def __init__(self, n_channel, drop_rate, dilated):\n        super().__init__()\n\n        self.conv3x1_1 = nn.Conv2d(n_channel, n_channel, (3, 1), stride=1, padding=(1, 0), bias=True)\n\n        self.conv1x3_1 = nn.Conv2d(n_channel, n_channel, (1, 3), stride=1, padding=(0, 1), bias=True)\n\n        self.conv3x1_2 = nn.Conv2d(n_channel, n_channel, (3, 1), stride=1, padding=(1 * dilated, 0), bias=True,\n                                   dilation=(dilated, 1))\n\n        self.conv1x3_2 = nn.Conv2d(n_channel, n_channel, (1, 3), stride=1, padding=(0, 1 * dilated), bias=True,\n                                   dilation=(1, dilated))\n\n        self.bn1 = nn.BatchNorm2d(n_channel, eps=1e-03)\n        self.bn2 = nn.BatchNorm2d(n_channel, eps=1e-03)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.dropout = nn.Dropout2d(drop_rate)\n\n    def forward(self, input):\n        output = self.conv3x1_1(input)\n        output = self.relu(output)\n        output = self.conv1x3_1(output)\n        output = self.bn1(output)\n        output = self.relu(output)\n\n        output = self.conv3x1_2(output)\n        output = self.relu(output)\n        output = self.conv1x3_2(output)\n        output = self.bn2(output)\n\n        if (self.dropout.p != 0):\n            output = self.dropout(output)\n\n        return self.relu(output + input)  # +input = identity (residual connection)\n\n\nclass DownsamplerBlock(nn.Module):\n    def __init__(self, in_channel, out_channel):\n        super().__init__()\n\n        self.conv = nn.Conv2d(in_channel, out_channel - in_channel, (3, 3), stride=2, padding=1, bias=True)\n        self.pool = nn.MaxPool2d(2, stride=2)\n        self.bn = nn.BatchNorm2d(out_channel, eps=1e-3)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, input):\n        output = torch.cat([self.conv(input), self.pool(input)], 1)\n        output = self.bn(output)\n        return self.relu(output)\n\n\nclass UpsamplerBlock(nn.Module):\n    def __init__(self, in_channel, out_channel):\n        super().__init__()\n        self.conv = nn.ConvTranspose2d(in_channel, out_channel, 3, stride=2, padding=1, output_padding=1, bias=True)\n        self.bn = nn.BatchNorm2d(out_channel, eps=1e-3)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, input):\n        output = self.conv(input)\n        output = self.bn(output)\n        return self.relu(output)'"
graphs/models/custom_layers/learnedgroupconv.py,6,"b'""""""\ncoding=utf-8\nDefinitions for custom layers and blocks\nCode adapted from: https://github.com/ShichenLiu/CondenseNet/blob/master/layers.py\n""""""\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nclass LearnedGroupConv(nn.Module):\n    global_progress = 0.0\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, condense_factor=None, dropout_rate=0.):\n        super().__init__()\n\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.condense_factor = condense_factor\n        self.groups = groups\n        self.dropout_rate = dropout_rate\n\n        # Check if given configs are valid\n        assert self.in_channels % self.groups == 0, ""group value is not divisible by input channels""\n        assert self.in_channels % self.condense_factor == 0, ""condensation factor is not divisible by input channels""\n        assert self.out_channels % self.groups == 0, ""group value is not divisible by output channels""\n\n        self.batch_norm = nn.BatchNorm2d(in_channels)\n        self.relu = nn.ReLU(inplace=True)\n        if self.dropout_rate > 0:\n            self.dropout = nn.Dropout(self.dropout_rate, inplace=False)\n        self.conv = nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels, kernel_size=kernel_size,\n                              stride=stride, padding=padding, dilation=dilation, groups=1, bias=False)\n        # register conv buffers\n        self.register_buffer(\'_count\', torch.zeros(1))\n        self.register_buffer(\'_stage\', torch.zeros(1))\n        self.register_buffer(\'_mask\', torch.ones(self.conv.weight.size()))\n\n    def forward(self, x):\n        out = self.batch_norm(x)\n        out = self.relu(out)\n        if self.dropout_rate > 0:\n            out = self.dropout(out)\n        ## Dropping here ##\n        self.check_if_drop()\n        # To mask the output\n        weight = self.conv.weight * self.mask\n        out_conv = F.conv2d(input=out, weight=weight, bias=None, stride=self.conv.stride, padding=self.conv.padding, dilation=self.conv.dilation, groups=1)\n        return out_conv\n\n    """"""\n    Paper: Sec 3.1: Condensation procedure: number of epochs for each condensing stage: M/2(C-1)\n    Paper: Sec 3.1: Condensation factor: allow each group to select R/C of inputs.\n    - During training a fraction of (C\xe2\x88\x921)/C connections are removed after each of the C-1 condensing stages\n    - we remove columns in Fg (by zeroing them out) if their L1-norm is small compared to the L1-norm of other columns.\n    """"""\n    def check_if_drop(self):\n        current_progress = LearnedGroupConv.global_progress\n        delta = 0\n        # Get current stage\n        for i in range(self.condense_factor - 1):   # 3 condensation stages\n            if current_progress * 2 < (i + 1) / (self.condense_factor - 1):\n                stage = i\n                break\n        else:\n            stage = self.condense_factor - 1\n        # Check for actual dropping\n        if not self.reach_stage(stage):\n            self.stage = stage\n            delta = self.in_channels // self.condense_factor\n            print(delta)\n        if delta > 0:\n            self.drop(delta)\n        return\n\n    def drop(self, delta):\n        weight = self.conv.weight * self.mask\n        # Sum up all kernels\n        print(weight.size())\n        assert weight.size()[-1] == 1\n        weight = weight.abs().squeeze()\n        assert weight.size()[0] == self.out_channels\n        assert weight.size()[1] == self.in_channels\n        d_out = self.out_channels // self.groups\n        print(d_out.size())\n        # Shuffle weights\n        weight = weight.view(d_out, self.groups, self.in_channels)\n        print(weight.size())\n\n        weight = weight.transpose(0, 1).contiguous()\n        print(weight.size())\n\n        weight = weight.view(self.out_channels, self.in_channels)\n        print(weight.size())\n        # Sort and drop\n        for i in range(self.groups):\n            wi = weight[i * d_out:(i + 1) * d_out, :]\n            # Take corresponding delta index\n            di = wi.sum(0).sort()[1][self.count:self.count + delta]\n            for d in di.data:\n                self._mask[i::self.groups, d, :, :].fill_(0)\n        self.count = self.count + delta\n\n    def reach_stage(self, stage):\n        return (self._stage >= stage).all()\n\n    @property\n    def count(self):\n        return int(self._count[0])\n\n    @count.setter\n    def count(self, val):\n        self._count.fill_(val)\n\n    @property\n    def stage(self):\n        return int(self._stage[0])\n\n    @stage.setter\n    def stage(self, val):\n        self._stage.fill_(val)\n\n    @property\n    def mask(self):\n        return Variable(self._mask)\n'"
