file_path,api_count,code
adjust_prediction.py,1,"b'import numpy as np\nimport os\nimport pandas as pd\nimport torch\nfrom src.p_dataload import KaggleAmazonDataset\n\n\n## Load MultiLabelBinarizer config\nX_train = KaggleAmazonDataset(\'./data/train.csv\',\'./data/train-jpg/\',\'.jpg\')\nmlb = X_train.getLabelEncoder()\n\n## Load sample submission:\ndf_test = pd.read_csv(\'./data/sample_submission_v2.csv\')\n\n## Load raw prediction (proba):\nsubm_proba = np.loadtxt(\'./out/2017-05-12_1223-resnet50-L2reg-new-data-raw-pred-0.922374050536.csv\',\n                       delimiter=\';\')\n\n## Load threshold:\nmodel_path = \'./snapshots/2017-05-12_1223-resnet50-L2reg-new-data-model_best.pth\'\ncheckpoint = torch.load(model_path)\nthreshold = checkpoint[\'threshold\']\n\n## Force single weather: TODO check if cloudy is alone\nweather = subm_proba[:, 0:4]\nindices = np.argmax(weather, axis=1)\nnew_weather = np.eye(4)[indices]\nsubm_proba[:,0:4] = new_weather\n\npredictions = subm_proba > threshold\n\nresult = pd.DataFrame({\n    \'image_name\': df_test[\'image_name\'],\n    \'tags\': mlb.inverse_transform(predictions)\n    })\nresult[\'tags\'] = result[\'tags\'].apply(lambda tags: "" "".join(tags))\n    \nresult_path = \'./out/2017-05-12_1223-resnet50-L2reg-new-data-adjusted-pred-0.922374050536.csv\'\nresult.to_csv(result_path, index=False)'"
compute-mean-std.py,0,"b'import cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nRESOLUTION = 96 # Ideally we shouldn\'t be resizing but I\'m lacking memory\n\nif __name__ == ""__main__"":\n    data = []\n    df_train = pd.read_csv(\'./data/train.csv\')\n\n    for file in tqdm(df_train[\'image_name\'], miniters=256):\n        img = cv2.imread(\'./data/train-jpg/{}.jpg\'.format(file))\n        data.append(cv2.resize(img,(RESOLUTION,RESOLUTION)))\n\n    data = np.array(data, np.float32) / 255 # Must use float32 at least otherwise we get over float16 limits\n    print(""Shape: "", data.shape)\n\n    means = []\n    stdevs = []\n    for i in range(3):\n        pixels = data[:,:,:,i].ravel()\n        means.append(np.mean(pixels))\n        stdevs.append(np.std(pixels))\n\n    print(""means: {}"".format(means))\n    print(""stdevs: {}"".format(stdevs))\n    print(\'transforms.Normalize(mean = {}, std = {})\'.format(means, stdevs))'"
main_keras.py,0,"b'import numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\n\nfrom timeit import default_timer as timer\nfrom src.k_dataloader import AmazonGenerator\nfrom src.k_model_selection import train_valid_split\n\nfrom sklearn.metrics import fbeta_score\n\nRESOLUTION = 256\n\nif __name__ == ""__main__"":\n    # Initiate timer\n    global_timer = timer()\n\n    # Setting random seeds for reproducibility. (Caveat, some CuDNN algorithms are non-deterministic)\n    np.random.seed(1337)    \n    \n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                     activation=\'relu\',\n                     input_shape=(RESOLUTION,RESOLUTION, 3)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, (3, 3), activation=\'relu\'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    model.add(Dense(96, activation=\'relu\'))\n    model.add(BatchNormalization())\n    model.add(Dense(17, activation=\'sigmoid\'))\n\n    model.compile(loss=\'binary_crossentropy\',\n                  optimizer=\'adam\',\n                  metrics=[\'accuracy\'])\n    \n    train_gen = AmazonGenerator(featurewise_center=True,\n                            featurewise_std_normalization=True,\n                            width_shift_range=0.15,\n                            horizontal_flip=True,\n                            rotation_range=15,\n                            rescale=1./255\n                           )\n    \n    valid_gen = AmazonGenerator(featurewise_center=True,\n                                featurewise_std_normalization=True,\n                                rescale=1./255)\n    \n    # train_gen.fit_from_csv(\'./data/train.csv\',\n    #                               \'./data/train-jpg/\',\n    #                               \'.jpg\',\n    #                              rescale=1./255,\n    #                              target_size=(RESOLUTION,RESOLUTION))\n    \n    # train_gen.dump_dataset_mean_std(\'train_256_mean.npy\', \'train_256_std.npy\')\n    train_gen.load_mean_std(\'train_256_mean.npy\', \'train_256_std.npy\')\n    valid_gen.load_mean_std(\'train_256_mean.npy\', \'train_256_std.npy\')\n    \n    df_train = pd.read_csv(\'./data/train.csv\')\n    \n    trn_idx, val_idx = train_valid_split(df_train, 0.2)\n    \n    batch_size = 32\n    \n    x_trn = train_gen.flow_from_df(df_train.iloc[trn_idx].reset_index(),\n                                   \'./data/train-jpg/\',\n                                   \'.jpg\',\n                                   mode=\'fit\',\n                                   batch_size=batch_size)\n    x_val = valid_gen.flow_from_df(df_train.iloc[val_idx].reset_index(),\n                                   \'./data/train-jpg/\',\n                                   \'.jpg\',\n                                   mode=\'predict\',\n                                   batch_size=batch_size)\n    model.fit_generator(x_trn,\n                        steps_per_epoch = len(trn_idx) / batch_size,\n                        epochs=1,\n                        workers=6, pickle_safe=True\n                       )\n    \n    ypreds = model.predict_generator(x_val,\n                                     steps = len(val_idx)/batch_size,\n                                     workers=6, pickle_safe=True\n                                    )\n    \n    mlb = train_gen.getLabelEncoder()\n    predictions = ypreds > 0.2\n    true_labels = mlb.transform(df_train[\'tags\'].iloc[val_idx].values)\n    \n    score=fbeta_score(true_labels, predictions, beta=2, average=\'samples\')\n    \n    end_global_timer = timer()\n    print(""################## Success #########################"")\n    print(""Total elapsed time: %s"" % (end_global_timer - global_timer))'"
main_pytorch-baseline.py,8,"b'## Custom Imports\nfrom src.p_dataload import KaggleAmazonDataset\nfrom src.p_neuro import Net, ResNet50, ResNet101, DenseNet121\nfrom src.p_training import train, snapshot\nfrom src.p_validation import validate\nfrom src.p_model_selection import train_valid_split\nfrom src.p_logger import setup_logs\nfrom src.p_prediction import predict, output\nfrom src.p_data_augmentation import ColorJitter\n# from src.p_metrics import SmoothF2Loss\nfrom src.p_sampler import SubsetSampler, balance_weights\n\n## Utilities\nimport random\nimport logging\nimport time\nfrom timeit import default_timer as timer\nimport os\n\n## Libraries\nimport numpy as np\nimport math\n\n## Torch\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport torch\nfrom torchsample.transforms import Affine\nfrom torch.utils.data.sampler import WeightedRandomSampler, SubsetRandomSampler\n\n############################################################################\n#######  CONTROL CENTER ############# STAR COMMAND #########################\n## Variables setup\nmodel = ResNet50(17).cuda()\n# model = Net().cuda()\n# model = WideResNet(16, 17, 4, 0.3)\n# model = ResNet101(17).cuda()\n# model = DenseNet121(17).cuda() # Note: Until May 5 19:12 CEST DenseNet121 was actually ResNet50 :/\n\nepochs = 30\nbatch_size = 16\n\n# Run name\nrun_name = time.strftime(""%Y-%m-%d_%H%M-"") + ""BASELINE""\n\n## Normalization on dataset mean/std\n# normalize = transforms.Normalize(mean=[0.30249774, 0.34421161, 0.31507745],\n#                                  std=[0.13718569, 0.14363895, 0.16695958])\n\n## Normalization on ImageNet mean/std for finetuning\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n# Note, p_training has lr_decay automated\n# optimizer = optim.Adam(model.parameters(), lr=0.1) # From scratch # Don\'t use Weight Decay with PReLU\n# optimizer = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=1e-4)  # From scratch\noptimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9) # Finetuning whole model\n\ncriterion = torch.nn.MultiLabelSoftMarginLoss()\n# criterion = SmoothF2Loss() # Using F2 directly as a cost function does 0.88 as a final cross validation. This is probably explained because cross-enropy is very efficient for sigmoid outputs (turning it into a convex problem). So keep Sigmoid + Cross entropy or something else + SmoothF2\n\nsave_dir = \'./snapshots\'\n\n#######  CONTROL CENTER ############# STAR COMMAND #########################\n############################################################################\n\nif __name__ == ""__main__"":\n    # Initiate timer\n    global_timer = timer()\n\n    # Setup logs\n    logger = setup_logs(save_dir, run_name)\n\n    # Setting random seeds for reproducibility. (Caveat, some CuDNN algorithms are non-deterministic)\n    torch.manual_seed(1337)\n    torch.cuda.manual_seed(1337)\n    np.random.seed(1337)\n    random.seed(1337)\n\n    ##############################################################\n    ## Loading the dataset\n\n    ## Augmentation + Normalization for full training\n    ds_transform_augmented = transforms.Compose([\n                     transforms.RandomSizedCrop(224),\n                     transforms.RandomHorizontalFlip(),\n                     transforms.ToTensor(),\n                     ColorJitter(),\n                     normalize\n                     # Affine(\n                     #     rotation_range = 15,\n                     #     translation_range = (0.2,0.2),\n                     #     shear_range = math.pi/6,\n                     #     zoom_range=(0.7,1.4)\n                     # )\n    ])\n\n    ## Normalization only for validation and test\n    ds_transform_raw = transforms.Compose([\n                     transforms.Scale(224),\n                     transforms.ToTensor(),\n                     normalize\n                     ])\n\n    ####     #########     ########     ###########     #####\n\n    X_train = KaggleAmazonDataset(\'./data/train.csv\',\'./data/train-jpg/\',\'.jpg\',\n                                 ds_transform_augmented\n                                 )\n    X_val = KaggleAmazonDataset(\'./data/train.csv\',\'./data/train-jpg/\',\'.jpg\',\n                                 ds_transform_raw\n                                 )\n\n    # Resample the dataset\n    # weights = balance_weights(X_train.getDF(), \'tags\', X_train.getLabelEncoder())\n    # weights = np.clip(weights,0.02,0.2) # We need to let the net view the most common classes or learning is too slow\n\n    # Creating a validation split\n    train_idx, valid_idx = train_valid_split(X_train, 0.2)\n\n    # weights[valid_idx] = 0\n\n    # train_sampler = WeightedRandomSampler(weights, len(train_idx))\n    train_sampler = SubsetRandomSampler(train_idx)\n    valid_sampler = SubsetSampler(valid_idx)\n\n    ######    ##########    ##########    ########    #########\n\n    # Both dataloader loads from the same dataset but with different indices\n    train_loader = DataLoader(X_train,\n                          batch_size=batch_size,\n                          sampler=train_sampler,\n                          num_workers=4,\n                          pin_memory=True)\n\n    valid_loader = DataLoader(X_val,\n                          batch_size=batch_size,\n                          sampler=valid_sampler,\n                          num_workers=4,\n                          pin_memory=True)\n\n    ###########################################################\n    ## Start training\n    best_score = 0.\n    for epoch in range(epochs):\n        epoch_timer = timer()\n\n        # Train and validate\n        train(epoch, train_loader, model, criterion, optimizer)\n        score, loss, threshold = validate(epoch, valid_loader, model, criterion, X_train.getLabelEncoder())\n        # Save\n        is_best = score > best_score\n        best_score = max(score, best_score)\n        snapshot(save_dir, run_name, is_best,{\n            \'epoch\': epoch + 1,\n            \'state_dict\': model.state_dict(),\n            \'best_score\': best_score,\n            \'optimizer\': optimizer.state_dict(),\n            \'threshold\': threshold,\n            \'val_loss\': loss\n        })\n\n        end_epoch_timer = timer()\n        logger.info(""#### End epoch {}, elapsed time: {}"".format(epoch, end_epoch_timer - epoch_timer))\n\n    ###########################################################\n    ## Prediction\n    X_test = KaggleAmazonDataset(\'./data/sample_submission.csv\',\'./data/test-jpg/\',\'.jpg\',\n                                  ds_transform_raw\n                                 )\n    test_loader = DataLoader(X_test,\n                              batch_size=batch_size,\n                              num_workers=4,\n                              pin_memory=True)\n\n    # Load model from best iteration\n    logger.info(\'===> loading best model for prediction\')\n    checkpoint = torch.load(os.path.join(save_dir,\n                                        run_name + \'-model_best.pth\'\n                                        )\n                           )\n    model.load_state_dict(checkpoint[\'state_dict\'])\n\n    # Predict\n    predictions = predict(test_loader, model) # TODO load model from the best on disk\n\n    output(predictions,\n           checkpoint[\'threshold\'],\n           X_test,\n           X_train.getLabelEncoder(),\n           \'./out\',\n           run_name,\n           checkpoint[\'best_score\']) # TODO early_stopping and use best_score\n\n    ##########################################################\n\n    end_global_timer = timer()\n    logger.info(""################## Success #########################"")\n    logger.info(""Total elapsed time: %s"" % (end_global_timer - global_timer))\n'"
main_pytorch.py,9,"b'## Custom Imports\nfrom src.p2_dataload import KaggleAmazonDataset\nfrom src.p_neuro import Net, ResNet50, ResNet101, ResNet152, DenseNet121\nfrom src.p3_neuroRNN import GRU_ResNet50, LSTM_ResNet50, Skip_LSTM_RN50\nfrom src.p_training import train, snapshot\n#from src.p2_validation import validate\nfrom src.p_validation import validate\nfrom src.p_model_selection import train_valid_split\nfrom src.p_logger import setup_logs\n#from src.p2_prediction import predict, output\nfrom src.p_prediction import predict, output\nfrom src.p_data_augmentation import ColorJitter, PowerPIL\n# from src.p_metrics import SmoothF2Loss\nfrom src.p2_loss import ConvolutedLoss\nfrom src.p_sampler import SubsetSampler, balance_weights\n\n## Utilities\nimport random\nimport logging\nimport time\nfrom timeit import default_timer as timer\nimport os\n\n## Libraries\nimport numpy as np\nimport math\n\n## Torch\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport torch\nfrom torchsample.transforms import Affine\nfrom torch.utils.data.sampler import WeightedRandomSampler, SubsetRandomSampler\n\n############################################################################\n#######  CONTROL CENTER ############# STAR COMMAND #########################\n## Variables setup\nmodel = ResNet50(17).cuda()\n# model = ResNet152(17).cuda()\n\n# model = GRU_ResNet50(17, 128, 2).cuda()\n# model = LSTM_ResNet50(17, 128, 2).cuda()\n# model = Skip_LSTM_RN50(17, 128, 2).cuda()\n\nepochs = 16\nbatch_size = 64\n\n# Run name\nrun_name = time.strftime(""%Y-%m-%d_%H%M-"") + ""resnet50-L2reg-new-data""\n## Normalization on ImageNet mean/std for finetuning\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n# Note, p_training has lr_decay automated\noptimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0005) # Finetuning whole model\n\n# criterion = ConvolutedLoss()\ncriterion = torch.nn.MultiLabelSoftMarginLoss(\n    weight = torch.Tensor([1,  4,  2,  1,\n                             1,  3,  3,  3,\n                             4,  4,  1,  2,\n                             1,  1,  3,  4,  1])\n    ).cuda()\n\n#classes = [\n#    \'clear\', \'cloudy\', \'haze\',\'partly_cloudy\',\n#    \'agriculture\',\'artisinal_mine\',\'bare_ground\',\'blooming\',\n#    \'blow_down\',\'conventional_mine\',\'cultivation\',\'habitation\',\n#    \'primary\',\'road\',\'selective_logging\',\'slash_burn\',\'water\'\n#    ]\n## Frequency\n#    [28203,  2330,  2695,  7251,\n#     12338,   339,   859,   332,\n#        98,   100,  4477,  3662,\n#     37840,  8076,   340,   209,  7262]\n\nsave_dir = \'./snapshots\'\n\n#######  CONTROL CENTER ############# STAR COMMAND #########################\n############################################################################\n\nif __name__ == ""__main__"":\n    # Initiate timer\n    global_timer = timer()\n    \n    # Setup logs\n    logger = setup_logs(save_dir, run_name)\n\n    # Setting random seeds for reproducibility. (Caveat, some CuDNN algorithms are non-deterministic)\n    torch.manual_seed(1337)\n    torch.cuda.manual_seed(1337)\n    np.random.seed(1337)\n    random.seed(1337)\n    \n    ##############################################################\n    ## Loading the dataset\n    \n    ## Augmentation + Normalization for full training\n    ds_transform_augmented = transforms.Compose([\n                     transforms.RandomSizedCrop(224),\n                     PowerPIL(),\n                     transforms.ToTensor(),\n                     # ColorJitter(), # Use PowerPIL instead, with PillowSIMD it\'s much more efficient\n                     normalize,\n                     # Affine(\n                     #    rotation_range = 15,\n                     #    translation_range = (0.2,0.2),\n                     #    shear_range = math.pi/6,\n                     #    zoom_range=(0.7,1.4)\n                     #)\n    ])\n    \n    ## Normalization only for validation and test\n    ds_transform_raw = transforms.Compose([\n                     transforms.Scale(224),\n                     transforms.ToTensor(),\n                     normalize\n                     ])\n    \n    ####     #########     ########     ###########     #####\n    \n    X_train = KaggleAmazonDataset(\'./data/train_v2.csv\',\'./data/train-jpg/\',\'.jpg\',\n                                 ds_transform_augmented\n                                 )\n    X_val = KaggleAmazonDataset(\'./data/train_v2.csv\',\'./data/train-jpg/\',\'.jpg\',\n                                 ds_transform_raw\n                                 )\n    \n    # Resample the dataset\n    # weights = balance_weights(X_train.getDF(), \'tags\', X_train.getLabelEncoder())\n    # weights = np.clip(weights,0.02,0.2) # We need to let the net view the most common classes or learning is too slow\n\n    # Creating a validation split\n    train_idx, valid_idx = train_valid_split(X_train, 0.2)\n    \n    # weights[valid_idx] = 0\n    \n    # train_sampler = WeightedRandomSampler(weights, len(train_idx))\n    train_sampler = SubsetRandomSampler(train_idx)\n    valid_sampler = SubsetSampler(valid_idx)\n    \n    ######    ##########    ##########    ########    #########\n    \n    # Both dataloader loads from the same dataset but with different indices\n    train_loader = DataLoader(X_train,\n                          batch_size=batch_size,\n                          sampler=train_sampler,\n                          num_workers=4,\n                          pin_memory=True)\n    \n    valid_loader = DataLoader(X_val,\n                          batch_size=batch_size,\n                          sampler=valid_sampler,\n                          num_workers=4,\n                          pin_memory=True)\n    \n    ###########################################################\n    ## Start training\n    best_score = 0.\n    for epoch in range(epochs):\n        epoch_timer = timer()\n        \n        # Train and validate\n        train(epoch, train_loader, model, criterion, optimizer)\n        score, loss, threshold = validate(epoch, valid_loader, model, criterion, X_train.getLabelEncoder())\n        # Save\n        is_best = score > best_score\n        best_score = max(score, best_score)\n        snapshot(save_dir, run_name, is_best,{\n            \'epoch\': epoch + 1,\n            \'state_dict\': model.state_dict(),\n            \'best_score\': best_score,\n            \'optimizer\': optimizer.state_dict(),\n            \'threshold\': threshold,\n            \'val_loss\': loss\n        })\n        \n        end_epoch_timer = timer()\n        logger.info(""#### End epoch {}, elapsed time: {}"".format(epoch, end_epoch_timer - epoch_timer))\n        \n    ###########################################################\n    ## Prediction\n    X_test = KaggleAmazonDataset(\'./data/sample_submission_v2.csv\',\'./data/test-jpg/\',\'.jpg\',\n                                  ds_transform_raw\n                                 )\n    test_loader = DataLoader(X_test,\n                              batch_size=batch_size,\n                              num_workers=4,\n                              pin_memory=True)\n    \n    # Load model from best iteration\n    logger.info(\'===> loading best model for prediction\')\n    checkpoint = torch.load(os.path.join(save_dir,\n                                        run_name + \'-model_best.pth\'\n                                        )\n                           )\n    model.load_state_dict(checkpoint[\'state_dict\'])\n    \n    # Predict\n    predictions = predict(test_loader, model) # TODO load model from the best on disk\n    \n    output(predictions,\n           checkpoint[\'threshold\'],\n           X_test,\n           X_train.getLabelEncoder(),\n           \'./out\',\n           run_name,\n           checkpoint[\'best_score\']) # TODO early_stopping and use best_score\n    \n    ##########################################################\n    \n    end_global_timer = timer()\n    logger.info(""################## Success #########################"")\n    logger.info(""Total elapsed time: %s"" % (end_global_timer - global_timer))'"
pytorch_predict_only.py,7,"b'## Custom Imports\nfrom src.p_dataload import KaggleAmazonDataset\nfrom src.p_neuro import Net, ResNet50, DenseNet121\nfrom src.p_training import train, snapshot\nfrom src.p_validation import validate\nfrom src.p_model_selection import train_valid_split\nfrom src.p_logger import setup_logs\nfrom src.p_prediction import predict, output\nfrom src.p_data_augmentation import ColorJitter\n\n## Utilities\nimport random\nimport logging\nimport time\nfrom timeit import default_timer as timer\nimport os\n\n## Libraries\nimport numpy as np\n\n## Torch\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch\n\n\n############################################################################\n#######  CONTROL CENTER ############# STAR COMMAND #########################\n\n# Run name\nrun_name = ""2017-05-04_1730-thresh_densenet121-predict-only""\n\nmodel = DenseNet121(17).cuda()\nbatch_size = 32\n\n## Normalization on dataset mean/std\n# normalize = transforms.Normalize(mean=[0.30249774, 0.34421161, 0.31507745],\n#                                  std=[0.13718569, 0.14363895, 0.16695958])\n    \n## Normalization on ImageNet mean/std for finetuning\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\nsave_dir = \'./snapshots\'\n\n#######  CONTROL CENTER ############# STAR COMMAND #########################\n############################################################################\n\nif __name__ == ""__main__"":\n    # Initiate timer\n    global_timer = timer()\n    \n    # Setup logs\n    logger = setup_logs(save_dir, run_name)\n\n    # Setting random seeds for reproducibility. (Caveat, some CuDNN algorithms are non-deterministic)\n    torch.manual_seed(1337)\n    torch.cuda.manual_seed(1337)\n    np.random.seed(1337)\n    random.seed(1337)\n    \n    ## Normalization only for validation and test\n    ds_transform_raw = transforms.Compose([\n                     transforms.CenterCrop(224),\n                     transforms.ToTensor(),\n                     normalize\n                     ])\n    \n\n    \n    X_test = KaggleAmazonDataset(\'./data/sample_submission_v2.csv\',\'./data/test-jpg/\',\'.jpg\',\n                                  ds_transform_raw\n                                 )\n    test_loader = DataLoader(X_test,\n                              batch_size=batch_size,\n                              num_workers=4,\n                              pin_memory=True)\n    \n    # Load model from best iteration\n    model_path = \'./snapshots/2017-05-04_1730-thresh_densenet121-model_best.pth\'\n    logger.info(\'===> loading {} for prediction\'.format(model_path))\n    checkpoint = torch.load(model_path)\n    model.load_state_dict(checkpoint[\'state_dict\'])\n    \n    # Predict\n    predictions = predict(test_loader, model) # TODO load model from the best on disk\n    \n    # Output\n    X_train = KaggleAmazonDataset(\'./data/train.csv\',\'./data/train-jpg/\',\'.jpg\')\n                                 \n    \n    output(predictions,\n           checkpoint[\'threshold\'],\n           X_test,\n           X_train.getLabelEncoder(),\n           \'./out\',\n           \'2017-05-04_1730-thresh_densenet121\',\n           checkpoint[\'best_score\'])\n    \n    ##########################################################\n    \n    end_global_timer = timer()\n    logger.info(""################## Success #########################"")\n    logger.info(""Total elapsed time: %s"" % (end_global_timer - global_timer))'"
baseline/001-keras-baseline-0.80752.py,0,"b'import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\n\nimport keras as k\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nimport cv2\nfrom tqdm import tqdm\n\nRESOLUTION = 128\nCACHE_FILE = \'001-baseline-cache.h5\'\nTHRESHOLD = 0.2\n\ndf_train = pd.read_csv(\'../data/train.csv\')\n\nmlb = MultiLabelBinarizer()\nX_train = []\nX_test = []\ndf_train = pd.read_csv(\'../data/train.csv\')\ny_train = mlb.fit_transform(df_train[\'tags\'].str.split())\n\nfor file in tqdm(df_train[\'image_name\'], miniters=256):\n    img = cv2.imread(\'../data/train-jpg/{}.jpg\'.format(file))\n    X_train.append(cv2.resize(img,(RESOLUTION,RESOLUTION)))\n\nX_train = np.array(X_train, np.float16) / 255. ## TODO load per batch to avoid memory error here\n\nprint(X_train.shape)\nprint(y_train.shape)\n\nsplit = 15000\nx_train, x_valid, y_train, y_valid = X_train[:split], X_train[split:], y_train[:split], y_train[split:]\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation=\'relu\',\n                 input_shape=(RESOLUTION,RESOLUTION, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), activation=\'relu\'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\'relu\'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(17, activation=\'sigmoid\'))\n\nmodel.compile(loss=\'binary_crossentropy\', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n              optimizer=\'adam\',\n              metrics=[\'accuracy\'])\n\n\n\nif os.path.isfile(CACHE_FILE):\n    print(\'####### Loading model from cache ######\')\n    model = load_model(CACHE_FILE)\n\nelse:\n    print(\'####### Cache not found, building from scratch ######\')\n    model.fit(x_train, y_train,\n              batch_size=64,\n              epochs=6, # Should implement early stopping\n              verbose=1,\n              validation_data=(x_valid, y_valid))\n    model.save(CACHE_FILE)\n\nfrom sklearn.metrics import fbeta_score\n\np_valid = model.predict(x_valid, batch_size=128)\nprint(y_valid)\nprint(p_valid)\nprint(fbeta_score(y_valid, np.array(p_valid) > THRESHOLD, beta=2, average=\'samples\'))\n\n\n######## Prediction ########\n\ndf_test = pd.read_csv(\'../data/sample_submission.csv\')\n\nfor file in tqdm(df_test[\'image_name\'], miniters=256):\n    img = cv2.imread(\'../data/test-jpg/{}.jpg\'.format(file))\n    X_test.append(cv2.resize(img,(RESOLUTION,RESOLUTION)))\n\n\nX_test = np.array(X_test, np.float16) / 255.\n\ny_pred = model.predict(X_test, batch_size=128)\n# np.savetxt(""pred-baseline.csv"", y_pred, delimiter="";"")\n\ndf_submission = pd.DataFrame()\ndf_submission[\'image_name\'] = df_test[\'image_name\']\ndf_submission[\'tags\'] = [\' \'.join(x) for x in mlb.inverse_transform(y_pred > THRESHOLD)]\n\ndf_submission.to_csv(\'001-baseline.csv\', index=False)\n'"
src/_deprecated.py,2,"b'### From Validation.py\n\n## DEPRECATED: Unfortunately COBYLA from Scipy can does not respect ""lexical bounds"".\n## Beware: the following will probably overfit the threshold to the validation set\n##################################################################################\n## Metrics\n## Given the labels imbalance we can\'t use the same threshold for each label.\n## We could implement our own maximizer on all 17 classes but scipy.optimize already have\n## 4 optimizations algorithms in C/Fortran that can work with constraints: L-BFGS-B, TNC, COBYLA and SLSQP.\n## Of those only cobyla doesn\'t rely on 2nd order hessians which are error-prone with our function\n## based on inequalities\n\n# Cobyla constraints are build by comparing return value with 0.\n# They must be >= 0 or be rejected\n\ndef constr_sup0(x):\n    return np.min(x)\ndef constr_inf1(x):\n    return 1 - np.max(x)\n\ndef f2_score(true_target, predictions):\n\n    def f_neg(threshold):\n        ## Scipy tries to minimize the function so we must get its inverse\n        return - fbeta_score(true_target, predictions > threshold, beta=2, average=\'samples\')\n\n    # Initialization of best threshold search\n    thr_0 = np.array([0.2 for i in range(17)])\n    \n    # Search\n    thr_opt = fmin_cobyla(f_neg, thr_0, [constr_sup0,constr_inf1], disp=0)\n\n    logger.info(""===> Optimal threshold for each label:\\n{}"".format(thr_opt))\n    \n    score = fbeta_score(true_target, predictions > thr_opt, beta=2, average=\'samples\')\n    return score, thr_opt\n\n## The jit is slower than scikit by a few ms. Unless the optimizing loop can be JIT too it\'s not worth it\n\n##################################################################################\n## Metrics\n## Given the labels imbalance we can\'t use the same threshold for each label.\n## We loop on each column label independently and maximize F2 score\n## Limit: might overfit\n## We don\'t model interdependance of coefs\n\nfrom numba import jit\n\n\n# True Positive\n@jit(nopython=True)\ndef true_pos(pred_labels, true_labels):\n    return np.sum(np.logical_and(pred_labels == 1, true_labels == 1))\n \n# True Negative\n@jit(nopython=True)\ndef true_neg(pred_labels, true_labels):\n    return np.sum(np.logical_and(pred_labels == 0, true_labels == 0))\n \n# False Positive - Type I Error\n@jit(nopython=True)\ndef false_pos(pred_labels, true_labels):\n    return np.sum(np.logical_and(pred_labels == 1, true_labels == 0))\n \n# False Negative - Type II Error\n@jit(nopython=True)\ndef false_neg(pred_labels, true_labels):\n    return np.sum(np.logical_and(pred_labels == 0, true_labels == 1))\n\n@jit(nopython=True)\ndef precision(pred_labels, true_labels):\n    TP = true_pos(pred_labels, true_labels)\n    FP = false_pos(pred_labels, true_labels)\n    \n    # Edge cases True Positives = 0, False negative = 0\n    # No predicted labels at all\n    # Shouldn\'t happen all photos must have at least one label\n    #\xc2\xa0We return 0 so that the threshold becomes better\n    #\xc2\xa0Should we penalize more ?\n    if TP==0 and FP==0: return 0\n    \n    return TP / (TP + FP)\n\n@jit(nopython=True)\ndef recall(pred_labels, true_labels):\n    TP = true_pos(pred_labels, true_labels)\n    FN = false_neg(pred_labels, true_labels)\n    \n    # Edge cases True Positives = 0, False negative = 0\n    # i.e no label in the true_labels input.\n    # Shouldn\'t happen  all photos have at least one label\n\n    return TP / (TP + FN)\n\n@jit(nopython=True)\ndef f2_score_macro(pred_labels, true_labels):\n    p = precision(pred_labels, true_labels)\n    r = recall(pred_labels, true_labels)\n    if p == 0 and r == 0: return 0\n    return 5 * p * r / (4 * p + r)\n\n@jit\ndef f2_score_mean(pred_labels, true_labels):\n    # F2_score_mean accelerated by numba\n    # Cannot force nopython mode because for loop on arrays does not work\n    i = 0\n    acc = 0\n    for (x,y) in zip(pred_labels,true_labels):\n        acc += f2_score_macro(x,y)\n        i+=1\n    return acc / i\n\n\n### Kaggle kernel search\ndef search_best_threshold(p_valid, y_valid, try_all=False, verbose=False):\n    p_valid, y_valid = np.array(p_valid), np.array(y_valid)\n\n    best_threshold = 0\n    best_score = -1\n    totry = np.arange(0,1,0.005) if try_all is False else np.unique(p_valid)\n    for t in totry:\n        score = fbeta_score(y_valid, p_valid > t, beta=2, average=\'samples\')\n        if score > best_score:\n            best_score = score\n            best_threshold = t\n    logger.info(""===> Optimal threshold for each label:\\n{}"".format(best_threshold))\n    return best_score, best_threshold\n\n# Search with L-BFGS-B\n    thr_0 = np.array([0.20 for i in range(17)])\n    constraints = [(0.,1.) for i in range(17)]\nthr_opt, score_neg, dico = fmin_l_bfgs_b(f_neg, thr_0, bounds=constraints, approx_grad=True, epsilon=0.05)\n\n## From dataload.py\n##################################################\n## DEPRECATED: https://discuss.pytorch.org/t/feedback-on-pytorch-for-kaggle-competitions/2252/8?u=mratsim\n## Augmentation on PyTorch are done randomly at each epoch\n\nclass AugmentedAmazonDataset(Dataset):\n    """"""Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n    This dataset is augmented\n\n    Arguments:\n        A CSV file path\n        Path to image folder\n        Extension of images\n    """"""\n\n    def __init__(self, csv_path, img_path, img_ext, transform=None):\n    \n        tmp_df = pd.read_csv(csv_path)\n        assert tmp_df[\'image_name\'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n""Some images referenced in the CSV file were not found""\n        \n        self.mlb = MultiLabelBinarizer()\n        self.img_path = img_path\n        self.img_ext = img_ext\n        self.transform = transform\n\n        self.X = tmp_df[\'image_name\']\n        self.y = self.mlb.fit_transform(tmp_df[\'tags\'].str.split()).astype(np.float32)\n        self.augmentNumber = 14 # TODO, do something about this harcoded value\n\n    def __getitem__(self, index):\n        real_length = self.real_length()\n        real_index = index % real_length\n        \n        img = Image.open(self.img_path + self.X[real_index] + self.img_ext)\n        img = img.convert(\'RGB\')\n        \n        ## Augmentation code\n        if 0 <= index < real_length:\n            pass\n        \n        ### Mirroring and Rotating\n        elif real_length <= index < 2 * real_length:\n            img = img.transpose(FLIP_LEFT_RIGHT)\n        elif 2 * real_length <= index < 3 * real_length:\n            img = img.transpose(FLIP_TOP_BOTTOM)\n        elif 3 * real_length <= index < 4 * real_length:\n            img = img.transpose(ROTATE_90)\n        elif 4 * real_length <= index < 5 * real_length:\n            img = img.transpose(ROTATE_180)\n        elif 5 * real_length <= index < 6 * real_length:\n            img = img.transpose(ROTATE_270)\n\n        ### Color balance\n        elif 6 * real_length <= index < 7 * real_length:\n            img = Color(img).enhance(0.95)\n        elif 7 * real_length <= index < 8 * real_length:\n            img = Color(img).enhance(1.05)\n        ## Contrast\n        elif 8 * real_length <= index < 9 * real_length:\n            img = Contrast(img).enhance(0.95)\n        elif 9 * real_length <= index < 10 * real_length:\n            img = Contrast(img).enhance(1.05)\n        ## Brightness\n        elif 10 * real_length <= index < 11 * real_length:\n            img = Brightness(img).enhance(0.95)\n        elif 11 * real_length <= index < 12 * real_length:\n            img = Brightness(img).enhance(1.05)\n        ## Sharpness\n        elif 12 * real_length <= index < 13 * real_length:\n            img = Sharpness(img).enhance(0.95)\n        elif 13 * real_length <= index < 14 * real_length:\n            img = Sharpness(img).enhance(1.05)\n        else:\n            raise IndexError(""Index out of bounds"")\n            \n        \n        if self.transform is not None:\n            img = self.transform(img)\n        \n        label = from_numpy(self.y[real_index])\n        return img, label\n    \n    def __len__(self):\n        return len(self.X.index) * self.augmentNumber\n    \n    def real_length(self):\n        return len(self.X.index)\n    \n    def getLabelEncoder(self):\n        return self.mlb\n    \n#### Usage\n\n    ############################################################\n    # Augmented part\n    # X_train = AugmentedAmazonDataset(\'./data/train.csv\',\'./data/train-jpg/\',\'.jpg\',\n    #                            ds_transform\n    #                            )\n    \n    # Creating a validation split\n    # train_idx, valid_idx = augmented_train_valid_split(X_train, 0.2)\n    \n    # nb_augment = X_train.augmentNumber\n    # augmented_train_idx = [i * nb_augment + idx for idx in train_idx for i in range(0,nb_augment)]\n                           \n    # train_sampler = SubsetRandomSampler(augmented_train_idx)\n    # valid_sampler = SubsetRandomSampler(valid_idx)\n    ###########################################################\n    \n    \n##################################################\n## DEPRECATED: AugmentedAmazonDataset is deprecated\n## https://discuss.pytorch.org/t/feedback-on-pytorch-for-kaggle-competitions/2252/8?u=mratsim\n## Augmentation on PyTorch are done randomly at each epoch\n\n\ndef augmented_train_valid_split(dataset, test_size = 0.25, shuffle = False, random_seed = 0):\n    """""" Return a list of splitted indices from a DataSet.\n    Indices can be used with DataLoader to build a train and validation set.\n    \n    Arguments:\n        A Dataset\n        A test_size, as a float between 0 and 1 (percentage split) or as an int (fixed number split)\n        Shuffling True or False\n        Random seed\n    """"""\n    length = dataset.real_length()\n    indices = list(range(1,length))\n    \n    if shuffle == True:\n        random.seed(random_seed)\n        random.shuffle(indices)\n    \n    if type(test_size) is float:\n        split = floor(test_size * length)\n    elif type(test_size) is int:\n        split = test_size\n    else:\n        raise ValueError(\'%s should be an int or a float\' % str)\n    return indices[split:], indices[:split]\n'"
src/k_dataloader.py,0,"b'from __future__ import absolute_import\nfrom __future__ import print_function\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom keras.preprocessing.image import ImageDataGenerator, Iterator, load_img, img_to_array\nimport pandas as pd\nimport os\nimport threading\nimport numpy as np\nimport keras.backend as K\n\n## For computing mean and std\nfrom tqdm import tqdm\nimport cv2\n\nclass AmazonGenerator(ImageDataGenerator):\n    def __init__(self, *args, **kwargs):\n        super(AmazonGenerator, self).__init__(*args, **kwargs)\n        self.iterator = None\n    \n    def flow_from_csv(self, csv_path, img_path, img_ext,\n                     mode=\'fit\',\n                     target_size=(256, 256),\n                     color_mode=\'rgb\',\n                     batch_size=32, shuffle=True, seed=None):\n \n        self.iterator = AmazonCSVIterator(self, csv_path,\n                              img_path, img_ext,\n                              mode=mode,\n                              target_size = target_size,\n                              color_mode = color_mode,\n                              batch_size = batch_size,\n                              shuffle = shuffle,\n                              seed = seed,\n                              data_format=None)\n        self.mlb = self.iterator.getLabelEncoder()\n        return(self.iterator)\n    \n    def flow_from_df(self, dataframe, img_path, img_ext,\n                     mode=\'fit\',\n                     target_size=(256, 256),\n                     color_mode=\'rgb\',\n                     batch_size=32, shuffle=True, seed=None):\n \n        self.iterator = AmazonDFIterator(self, dataframe,img_path, img_ext,\n                              mode=mode,\n                              target_size = target_size,\n                              color_mode = color_mode,\n                              batch_size = batch_size,\n                              shuffle = shuffle,\n                              seed = seed,\n                              data_format=None)\n        self.mlb = self.iterator.getLabelEncoder()\n        return(self.iterator) \n    \n    def getLabelEncoder(self):\n        return self.iterator.getLabelEncoder()\n    \n    def fit_from_csv(self, csv_path, img_path, img_ext, rescale, target_size):\n        \'\'\'Required for featurewise_center, featurewise_std_normalization \n        when using images loaded from csv.\n\n        # Arguments\n            csv_path: Path to the csv with image list\n            img_path: Directory with all images\n            img_ext: Extension of images\n            rescaling factor: usually we rescale images from 0-255 to 0-1\n            resolution: A tuple of int. Images will be rescaled to that resolution before computing mean as we need to hold them all in memory. Set as big as your memory allows\n        \'\'\'\n        \n        # Computing mean and variance using Welford\'s algorithm for one pass only and numerical stability.        \n        df = pd.read_csv(csv_path)\n        \n        # Pre-allocation\n        shape = cv2.imread(os.path.join(\n                             img_path,\n                             df[\'image_name\'].iloc[0] + img_ext)).shape\n        \n        mean= np.zeros(shape, dtype=np.float32)\n        M2= np.zeros(shape, dtype=np.float32)\n\n        print(\'Computing mean and standard deviation on the dataset\')\n        for n, file in enumerate(tqdm(df[\'image_name\'], miniters=256), 1):\n            img = cv2.imread(os.path.join(img_path, file + img_ext)).astype(np.float32)\n            img *= rescale\n            delta = img - mean\n            mean += delta/n\n            delta2 = img - mean\n            M2 += delta*delta2\n                \n        self.mean = mean\n        self.std = M2 / (n-1)\n        \n        print(""Mean has shape: "" + str(self.mean.shape))\n        print(""Std has shape: "" + str(self.std.shape))\n        \n    def dump_dataset_mean_std(self, path_mean, path_std):\n        if self.mean is None or self.std is None:\n            raise ValueError(\'Mean and Std must be computed before, fit the generator first\')\n        np.save(path_mean, self.mean)\n        np.save(path_std, self.std)\n        \n\n    def load_mean_std(self, path_mean, path_std):\n        self.mean = np.load(path_mean)\n        self.std = np.load(path_std)\n        print(""Mean has shape: "" + str(self.mean.shape))\n        print(""Std has shape: "" + str(self.std.shape))\n\nclass AmazonCSVIterator(Iterator):\n    def __init__(self, image_data_generator, csv_path,\n                 img_path, img_ext,\n                 mode=\'fit\',\n                 target_size=(256, 256),\n                 color_mode=\'rgb\',\n                 batch_size=32, shuffle=True, seed=None,\n                 data_format=None):\n        \n        ## Common initialization routines\n        self.target_size = tuple(target_size)\n        if color_mode not in {\'rgb\', \'grayscale\'}:\n            raise ValueError(\'Invalid color mode:\', color_mode,\n                             \'; expected ""rgb"" or ""grayscale"".\')\n        self.color_mode = color_mode\n        \n        if data_format is None:\n            self.data_format = K.image_data_format()\n\n        if self.color_mode == \'rgb\':\n            if self.data_format == \'channels_last\':\n                self.image_shape = self.target_size + (3,)\n            else:\n                self.image_shape = (3,) + self.target_size\n        else:\n            if self.data_format == \'channels_last\':\n                self.image_shape = self.target_size + (1,)\n            else:\n                self.image_shape = (1,) + self.target_size\n                \n        self.image_data_generator = image_data_generator\n        \n        ## Specific to Amazon\n        tmp_df = pd.read_csv(csv_path)\n        assert tmp_df[\'image_name\'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n""Some images referenced in the CSV file were not found""\n        \n        self.mlb = MultiLabelBinarizer()\n        self.img_path = img_path\n        self.img_ext = img_ext\n        self.X = tmp_df[\'image_name\']\n        self.mode = mode\n        if mode == \'fit\':\n            self.y = self.mlb.fit_transform(tmp_df[\'tags\'].str.split())\n        \n        ## Init parent class\n        super(AmazonCSVIterator, self).__init__(self.X.shape[0],\n                                             batch_size, shuffle, seed)\n\n    def next(self):\n        """"""For python 2.x.\n        # Returns The next batch.\n        """"""\n        \n        with self.lock:\n            index_array, current_index, current_batch_size = next(self.index_generator)\n        \n        # The transformation of images is not under thread lock\n        # so it can be done in parallel\n        batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n        grayscale = self.color_mode == \'grayscale\'\n        \n        # Build batch of images\n        for i, j in enumerate(index_array):\n            fpath = os.path.join(self.img_path,self.X[j] + self.img_ext)\n            img = load_img(fpath,\n                           grayscale=grayscale,\n                           target_size=self.target_size)\n            x = img_to_array(img, data_format=self.data_format)\n            x = self.image_data_generator.random_transform(x)\n            x = self.image_data_generator.standardize(x)\n            batch_x[i] = x\n        \n        # Build batch of labels.\n        if mode==\'fit\':\n            batch_y = self.y[index_array]\n            return batch_x, batch_y\n        elif mode==\'predict\':\n            return batch_x\n        else: raise ValueError(\'The mode should be either \\\'fit\\\' or \\\'predict\\\'\')\n            \n    def getLabelEncoder(self):\n        return self.mlb\n\nclass AmazonDFIterator(Iterator):\n    def __init__(self, image_data_generator, df, img_path, img_ext,\n                 mode=\'fit\',\n                 target_size=(256, 256),\n                 color_mode=\'rgb\',\n                 batch_size=32, shuffle=True, seed=None,\n                 data_format=None):\n        \n        ## Common initialization routines\n        self.target_size = tuple(target_size)\n        if color_mode not in {\'rgb\', \'grayscale\'}:\n            raise ValueError(\'Invalid color mode:\', color_mode,\n                             \'; expected ""rgb"" or ""grayscale"".\')\n        self.color_mode = color_mode\n        \n        if data_format is None:\n            self.data_format = K.image_data_format()\n\n        if self.color_mode == \'rgb\':\n            if self.data_format == \'channels_last\':\n                self.image_shape = self.target_size + (3,)\n            else:\n                self.image_shape = (3,) + self.target_size\n        else:\n            if self.data_format == \'channels_last\':\n                self.image_shape = self.target_size + (1,)\n            else:\n                self.image_shape = (1,) + self.target_size\n                \n        self.image_data_generator = image_data_generator\n        \n        ## Specific to Amazon\n        assert df[\'image_name\'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n""Some images referenced in the CSV file were not found""\n        \n        self.mlb = MultiLabelBinarizer()\n        self.img_path = img_path\n        self.img_ext = img_ext\n        self.X = df[\'image_name\']\n        self.mode = mode\n        if mode == \'fit\':\n            self.y = self.mlb.fit_transform(df[\'tags\'].str.split())\n        \n        ## Init parent class\n        super(AmazonDFIterator, self).__init__(self.X.shape[0],\n                                             batch_size, shuffle, seed)\n\n    def next(self):\n        """"""For python 2.x.\n        # Returns The next batch.\n        """"""\n        \n        with self.lock:\n            index_array, current_index, current_batch_size = next(self.index_generator)\n        \n        # The transformation of images is not under thread lock\n        # so it can be done in parallel\n        batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n        grayscale = self.color_mode == \'grayscale\'\n        \n        # Build batch of images\n        for i, j in enumerate(index_array):\n            fpath = os.path.join(self.img_path,self.X[j] + self.img_ext)\n            img = load_img(fpath,\n                           grayscale=grayscale,\n                           target_size=self.target_size)\n            x = img_to_array(img, data_format=self.data_format)\n            x = self.image_data_generator.random_transform(x)\n            x = self.image_data_generator.standardize(x)\n            batch_x[i] = x\n        \n        # Build batch of labels.\n        if self.mode==\'fit\':\n            batch_y = self.y[index_array]\n            return batch_x, batch_y\n        elif self.mode==\'predict\':\n            return batch_x\n        else: raise ValueError(\'The mode should be either \\\'fit\\\' or \\\'predict\\\'\')\n            \n    def getLabelEncoder(self):\n        return self.mlb'"
src/k_model_selection.py,0,"b'import random\nfrom math import floor\n\ndef train_valid_split(dataframe, test_size = 0.25, shuffle = False, random_seed = 0):\n    """""" Return a list of splitted indices from a DataSet.\n    Indices can be used with DataLoader to build a train and validation set.\n    \n    Arguments:\n        A Dataframe\n        A test_size, as a float between 0 and 1 (percentage split) or as an int (fixed number split)\n        Shuffling True or False\n        Random seed\n    """"""\n    length = len(dataframe.index)\n    indices = list(range(1,length))\n    \n    if shuffle == True:\n        random.seed(random_seed)\n        random.shuffle(indices)\n    \n    if type(test_size) is float:\n        split = floor(test_size * length)\n    elif type(test_size) is int:\n        split = test_size\n    else:\n        raise ValueError(\'%s should be an int or a float\' % str)\n    return indices[split:], indices[:split]'"
src/p2_dataload.py,1,"b'from torch.utils.data.dataset import Dataset\nfrom torchvision import transforms\nimport pandas as pd\nimport os\nfrom PIL import Image # Replace by accimage when ready\nfrom PIL.Image import FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM, ROTATE_90, ROTATE_180, ROTATE_270\nfrom PIL.ImageEnhance import Color, Contrast, Brightness, Sharpness\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom torch import np, from_numpy # Numpy like wrapper\n\nclass KaggleAmazonDataset(Dataset):\n    """"""Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n\n    Arguments:\n        A CSV file path\n        Path to image folder\n        Extension of images\n    """"""\n\n    def __init__(self, csv_path, img_path, img_ext, transform=None):\n    \n        self.df = pd.read_csv(csv_path)\n        assert self.df[\'image_name\'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n""Some images referenced in the CSV file were not found""\n        \n        # Ordering weather first\n        self.mlb = MultiLabelBinarizer(\n                    classes = [\n                       \'clear\', \'cloudy\', \'haze\',\'partly_cloudy\',\n                       \'agriculture\',\'artisinal_mine\',\'bare_ground\',\'blooming\',\n                       \'blow_down\',\'conventional_mine\',\'cultivation\',\'habitation\',\n                       \'primary\',\'road\',\'selective_logging\',\'slash_burn\',\'water\'\n                      ]\n        )\n        self.img_path = img_path\n        self.img_ext = img_ext\n        self.transform = transform\n\n        self.X = self.df[\'image_name\']\n        self.y = self.mlb.fit_transform(self.df[\'tags\'].str.split()).astype(np.float32)\n\n    def X(self):\n        return self.X\n        \n    def __getitem__(self, index):\n        img = Image.open(self.img_path + self.X[index] + self.img_ext)\n        img = img.convert(\'RGB\')\n        if self.transform is not None:\n            img = self.transform(img)\n        \n        label = from_numpy(self.y[index])\n        return img, label\n\n    def __len__(self):\n        return len(self.df.index)\n    \n    def getLabelEncoder(self):\n        return self.mlb\n    \n    def getDF(self):\n        return self.df'"
src/p2_loss.py,4,"b'import torch.nn.functional as F\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch\nfrom torch.autograd import Variable\n\n# If needed to code the categorical cross entropy from scratch: https://github.com/twitter/torch-autograd/blob/master/src/loss/init.lua\n\nclass ConvolutedLoss(_WeightedLoss):\n    """""" Treat the weather as MultiClassification (only one label possible)\n        Treat the rest as Multilabel\n        ==> Multi-Task learning\n    """"""\n    def __init__(self, weight=None, size_average=True):\n        super(ConvolutedLoss, self).__init__(size_average)\n        if weight is None:\n            self.register_buffer(\'weight_weather\', None)\n            self.register_buffer(\'weight_other\', None)\n        else:\n            self.register_buffer(\'weight_weather\', weight[:4]) # Weather conditions are the first 4\n            self.register_buffer(\'weight_other\', weight[4:])\n    \n    def forward(self, input, target):\n        # Cross-Entropy wants categorical not one-hot\n        # Reverse one hot\n        weather_targets = Variable(torch.arange(0,4).expand(target.size(0),4).masked_select(target[:,:4].data.byte().cpu()).long().cuda(), requires_grad = False)\n        \n        loss_weather = F.cross_entropy(input[:,:4],\n                                       weather_targets,\n                                       self.weight_weather,\n                                       self.size_average)\n        loss_other = F.binary_cross_entropy(F.sigmoid(input[:,4:]),\n                                            target[:,4:],\n                                            self.weight_other,\n                                            self.size_average)\n        \n        return (loss_weather * 4/17) + (loss_other * 13/17)\n        '"
src/p2_metrics.py,5,"b'import numpy as np\nimport logging\nfrom sklearn.metrics import fbeta_score\nfrom scipy.optimize import fmin_l_bfgs_b, basinhopping\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom timeit import default_timer as timer\n\n\n## Get the same logger from main""\nlogger = logging.getLogger(""Planet-Amazon"")\n\ndef best_f2_score(true_labels, predictions):\n\n    def f_neg(threshold):\n        ## Scipy tries to minimize the function so we must get its inverse\n        return - fbeta_score(true_labels, predictions > threshold, beta=2, average=\'samples\')\n\n    # Initialization of best threshold search\n    thr_0 = [0.20] * 17\n    constraints = [(0.,1.)] * 17\n    def bounds(**kwargs):\n        x = kwargs[""x_new""]\n        tmax = bool(np.all(x <= 1))\n        tmin = bool(np.all(x >= 0)) \n        return tmax and tmin\n    \n    # Search using L-BFGS-B, the epsilon step must be big otherwise there is no gradient\n    minimizer_kwargs = {""method"": ""L-BFGS-B"",\n                        ""bounds"":constraints,\n                        ""options"":{\n                            ""eps"": 0.05\n                            }\n                       }\n    \n    # We combine L-BFGS-B with Basinhopping for stochastic search with random steps\n    logger.info(""===> Searching optimal threshold for each label"")\n    start_time = timer()\n    \n    opt_output = basinhopping(f_neg, thr_0,\n                                stepsize = 0.1,\n                                minimizer_kwargs=minimizer_kwargs,\n                                niter=10,\n                                accept_test=bounds)\n    \n    end_time = timer()\n    logger.info(""===> Optimal threshold for each label:\\n{}"".format(opt_output.x))\n    logger.info(""Threshold found in: %s seconds"" % (end_time - start_time))\n    \n    score = - opt_output.fun\n    return score, opt_output.x\n\n\n# We use real valued F2 score for training. Input can be anything between 0 and 1.\n# Threshold is not differentiable so we don\'t use it during training\n# We get a smooth F2 score valid for real values and not only 0/1\ndef torch_f2_score(y_true, y_pred):\n    return torch_fbeta_score(y_true, y_pred, 2)\n\ndef torch_fbeta_score(y_true, y_pred, beta, eps=1e-9):\n    beta2 = beta**2\n\n    y_true = y_true.float()\n\n    true_positive = (y_pred * y_true).sum(dim=1)\n    precision = true_positive.div(y_pred.sum(dim=1).add(eps))\n    recall = true_positive.div(y_true.sum(dim=1).add(eps))\n\n    return torch.mean(\n        (precision*recall).\n        div(precision.mul(beta2) + recall + eps).\n        mul(1 + beta2))\n\n\nclass SmoothF2Loss(nn.Module):\n    def __init__(self):\n        super(MeanF2Loss, self).__init__()\n    \n    def forward(self, input, target):\n        return 1 - torch_f2_score(target, torch.sigmoid(input))'"
src/p2_prediction.py,3,"b'from torch.autograd import Variable\nimport numpy as np\nimport logging\nimport os\nimport pandas as pd\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport torch\n\n## Get the same logger from main""\nlogger = logging.getLogger(""Planet-Amazon"")\n\n##################################################\n#### Prediction function\ndef predict(test_loader, model):    \n    model.eval()\n    predictions = []\n    \n    logger.info(""Starting Prediction"")\n    for batch_idx, (data, _) in enumerate(tqdm(test_loader)):\n        data = data.cuda(async=True)\n        data = Variable(data, volatile=True)\n    \n        raw_pred = model(data)\n        # Even though we use softmax for training, it doesn\'t give good result here\n        # However activated neuro for weather will giv emuch larger response for much easier thresholding\n        # pred = torch.cat(\n        #                    (\n        #                        F.softmax(raw_pred[:4]),\n        #                        F.sigmoid(raw_pred[4:])\n        #                    ), 0\n        #       )\n        pred = F.sigmoid(raw_pred)\n        predictions.append(pred.data.cpu().numpy())\n    \n    predictions = np.vstack(predictions)\n    \n    logger.info(""===> Raw predictions done. Here is a snippet"")\n    print(predictions)\n    return predictions\n\ndef output(predictions, threshold, X_test, mlb, dir_path, run_name, accuracy):\n    \n    raw_pred_path = os.path.join(dir_path, run_name + \'-raw-pred-\'+str(accuracy)+\'.csv\')\n    np.savetxt(raw_pred_path,predictions,delimiter="";"")\n    logger.info(""Raw predictions saved to {}"".format(raw_pred_path))\n    \n    predictions = predictions > threshold\n    \n    result = pd.DataFrame({\n        \'image_name\': X_test.X,\n        \'tags\': mlb.inverse_transform(predictions)\n    })\n    result[\'tags\'] = result[\'tags\'].apply(lambda tags: "" "".join(tags))\n    \n    logger.info(""===> Final predictions done. Here is a snippet"")\n    print(result)\n    \n    result_path = os.path.join(dir_path, run_name + \'-final-pred-\'+str(accuracy)+\'.csv\')\n    result.to_csv(result_path, index=False)\n    logger.info(""Final predictions saved to {}"".format(result_path))'"
src/p2_validation.py,3,"b'from torch.autograd import Variable\nimport numpy as np\nimport logging\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport torch\n\nfrom src.p_metrics import best_f2_score\n\n## Get the same logger from main""\nlogger = logging.getLogger(""Planet-Amazon"")\n\n##################################################\n#### Validate function\ndef validate(epoch,valid_loader,model,loss_func,mlb):\n    ## Volatile variables do not save intermediate results and build graphs for backprop, achieving massive memory savings.\n    \n    model.eval()\n    total_loss = 0\n    predictions = []\n    true_labels = []\n    \n    logger.info(""Starting Validation"")\n    for batch_idx, (data, target) in enumerate(tqdm(valid_loader)):\n        true_labels.append(target.cpu().numpy())\n        \n        data, target = data.cuda(async=True), target.cuda(async=True)\n        data, target = Variable(data, volatile=True), Variable(target, volatile=True)\n    \n        raw_pred = model(data)\n        # Even though we use softmax for training, it doesn\'t give good result here\n        # However activated neuro for weather will giv emuch larger response for much easier thresholding\n        # pred = torch.cat(\n        #                    (\n        #                        F.softmax(raw_pred[:4]),\n        #                        F.sigmoid(raw_pred[4:])\n        #                    ), 0\n        #       )\n        pred = F.sigmoid(raw_pred)\n        predictions.append(pred.data.cpu().numpy())\n        \n        total_loss += loss_func(raw_pred,target).data[0]\n    \n    avg_loss = total_loss / len(valid_loader)\n    \n    predictions = np.vstack(predictions)\n    true_labels = np.vstack(true_labels)\n   \n    score, threshold = best_f2_score(true_labels, predictions)\n    logger.info(""Corresponding tags\\n{}"".format(mlb.classes_))\n    \n    logger.info(""===> Validation - Avg. loss: {:.4f}\\tF2 Score: {:.4f}"".format(avg_loss,score))\n    return score, avg_loss, threshold'"
src/p3_neuroRNN.py,7,"b""from torch import nn, ones\nfrom torch.autograd import Variable\nfrom torchvision import models\nfrom torch.nn.init import kaiming_normal\nfrom torch import np\nimport torch\nimport torch.nn.functional as F\n\n\nclass GRU_ResNet50(nn.Module):\n    ## We use ResNet weights from PyCaffe.\n    def __init__(self, num_classes, hidden_size, num_layers):\n        super(GRU_ResNet50, self).__init__()\n        \n        # Loading ResNet arch from PyTorch and weights from Pycaffe\n        original_model = models.resnet50(pretrained=False)\n        original_model.load_state_dict(torch.load('./zoo/resnet50.pth'))\n        \n        # Everything except the last linear layer\n        self.features = nn.Sequential(*list(original_model.children())[:-1])\n        \n        # Get number of features of last layer\n        num_feats = original_model.fc.in_features\n        \n        self.bn = nn.BatchNorm1d(num_feats, momentum=0.01)\n        \n        self.hidden_size = hidden_size\n        self.rnn = nn.GRU(input_size=num_feats,\n                            hidden_size=hidden_size,\n                            num_layers=num_layers,\n                            batch_first = True)\n        \n        # Plug our classifier\n        self.classifier = nn.Sequential(\n        nn.Linear(hidden_size, num_classes)\n        )\n        \n        # Init of last layer\n        for m in self.classifier:\n            kaiming_normal(m.weight)\n        self.bn.weight.data.fill_(1)\n        self.bn.bias.data.zero_()\n        # How to init RNN?\n\n        # Freeze those weights\n        # for p in self.features.parameters():\n        #     p.requires_grad = False\n\n    def forward(self, x, hidden=None):\n        f = self.features(x)\n        f = self.bn(f.view(f.size(0), -1))\n        f = f.unsqueeze(1)\n        x, hidden = self.rnn(f, hidden)\n        x = x.view(-1, self.hidden_size)\n        y = self.classifier(x)\n        return y\n    \nclass LSTM_ResNet50(nn.Module):\n    ## We use ResNet weights from PyCaffe.\n    def __init__(self, num_classes, hidden_size, num_layers):\n        super(LSTM_ResNet50, self).__init__()\n        \n        # Loading ResNet arch from PyTorch and weights from Pycaffe\n        original_model = models.resnet50(pretrained=False)\n        original_model.load_state_dict(torch.load('./zoo/resnet50.pth'))\n        \n        # Everything except the last linear layer\n        self.features = nn.Sequential(*list(original_model.children())[:-1])\n        \n        # Get number of features of last layer\n        num_feats = original_model.fc.in_features\n        \n        self.bn = nn.BatchNorm1d(num_feats, momentum=0.01)\n        \n        self.hidden_size = hidden_size\n        self.rnn = nn.LSTM(input_size=num_feats,\n                            hidden_size=hidden_size,\n                            num_layers=num_layers,\n                            batch_first = True)\n        \n        # Plug our classifier\n        self.classifier = nn.Sequential(\n        nn.Linear(hidden_size, num_classes)\n        )\n        \n        # Init of last layer\n        for m in self.classifier:\n            kaiming_normal(m.weight)\n        self.bn.weight.data.fill_(1)\n        self.bn.bias.data.zero_()\n                \n        # How to init RNN?\n\n        # Freeze those weights\n        # for p in self.features.parameters():\n        #     p.requires_grad = False\n\n    def forward(self, x, hidden=None):\n        f = self.features(x)\n        f = self.bn(f.view(f.size(0), -1))\n        f = f.unsqueeze(1)\n        x, hidden = self.rnn(f, hidden)\n        x = x.view(-1, self.hidden_size)\n        y = self.classifier(x)\n        return y\n\n    \nclass Skip_LSTM_RN50(nn.Module):\n    ## We use ResNet weights from PyCaffe.\n    def __init__(self, num_classes, hidden_size, num_layers):\n        super(Skip_LSTM_RN50, self).__init__()\n        \n        # Loading ResNet arch from PyTorch and weights from Pycaffe\n        original_model = models.resnet50(pretrained=False)\n        original_model.load_state_dict(torch.load('./zoo/resnet50.pth'))\n        \n        # Everything except the last linear layer\n        self.features = nn.Sequential(*list(original_model.children())[:-1])\n        \n        # Get number of features of last layer\n        num_feats = original_model.fc.in_features\n        \n        self.bn = nn.BatchNorm1d(num_feats, momentum=0.01)\n        \n        self.hidden_size = hidden_size\n        self.rnn = nn.LSTM(input_size=num_feats,\n                            hidden_size=hidden_size,\n                            num_layers=num_layers,\n                            batch_first = True)\n        \n        # Plug our classifier\n        self.classifier = nn.Sequential(\n        nn.Linear(hidden_size + num_feats, num_classes)\n        )\n        \n        # Init of last layer\n        for m in self.classifier:\n            kaiming_normal(m.weight)\n        self.bn.weight.data.fill_(1)\n        self.bn.bias.data.zero_()\n                \n        # How to init RNN?\n\n        # Freeze those weights\n        # for p in self.features.parameters():\n        #     p.requires_grad = False\n\n    def forward(self, x, hidden=None):\n        f = self.features(x)\n        f = self.bn(f.view(f.size(0), -1))\n        x, hidden = self.rnn(f.unsqueeze(1), hidden)\n        x = x.view(-1, self.hidden_size)\n        c = torch.cat((x,f),1) # Skip connection to avoid the LSTM eating the whole gradients\n        y = self.classifier(c)\n        return y"""
src/p_data_augmentation.py,1,"b'## Additional transforms for PyTorch data augmentation\n## It is very recommended to use Pillow-SIMD for speed gain in the 5x range.\n## https://python-pillow.org/pillow-perf/\n## OpenCV built with IPP and TBB is also fast but inaccurate\n\nimport torch\nimport random\nimport PIL.ImageEnhance as ie\nimport PIL.Image as im\n\n\nclass Lighting(object):\n    """"""Lighting noise(AlexNet - style PCA - based noise)""""""\n\n    def __init__(self, alphastd, eigval, eigvec):\n        self.alphastd = alphastd\n        self.eigval = eigval\n        self.eigvec = eigvec\n\n    def __call__(self, img):\n        if self.alphastd == 0:\n            return img\n\n        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n        rgb = self.eigvec.type_as(img).clone()\\\n            .mul(alpha.view(1, 3).expand(3, 3))\\\n            .mul(self.eigval.view(1, 3).expand(3, 3))\\\n            .sum(1).squeeze()\n\n        return img.add(rgb.view(3, 1, 1).expand_as(img))\n\n\nclass Grayscale(object):\n\n    def __call__(self, img):\n        gs = img.clone()\n        gs[0].mul_(0.299).add_(0.587, gs[1]).add_(0.114, gs[2])\n        gs[1].copy_(gs[0])\n        gs[2].copy_(gs[0])\n        return gs\n\n\nclass Saturation(object):\n\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = Grayscale()(img)\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass Brightness(object):\n\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = img.new().resize_as_(img).zero_()\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass Contrast(object):\n\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = Grayscale()(img)\n        gs.fill_(gs.mean())\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass RandomOrder(object):\n    """""" Composes several transforms together in random order.\n    """"""\n\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img):\n        if self.transforms is None:\n            return img\n        order = torch.randperm(len(self.transforms))\n        for i in order:\n            img = self.transforms[i](img)\n        return img\n\n\nclass ColorJitter(RandomOrder):\n\n    def __init__(self, brightness=0.4, contrast=0.4, saturation=0.4):\n        self.transforms = []\n        if brightness != 0:\n            self.transforms.append(Brightness(brightness))\n        if contrast != 0:\n            self.transforms.append(Contrast(contrast))\n        if saturation != 0:\n            self.transforms.append(Saturation(saturation))\n\nclass RandomFlip(object):\n    """"""Randomly flips the given PIL.Image with a probability of 0.25 horizontal,\n                                                                0.25 vertical,\n                                                                0.5 as is\n    """"""\n    \n    def __call__(self, img):\n        dispatcher = {\n            0: img,\n            1: img,\n            2: img.transpose(im.FLIP_LEFT_RIGHT),\n            3: img.transpose(im.FLIP_TOP_BOTTOM)\n        }\n    \n        return dispatcher[random.randint(0,3)] #randint is inclusive\n\nclass RandomRotate(object):\n    """"""Randomly rotate the given PIL.Image with a probability of 1/6 90\xc2\xb0,\n                                                                 1/6 180\xc2\xb0,\n                                                                 1/6 270\xc2\xb0,\n                                                                 1/2 as is\n    """"""\n    \n    def __call__(self, img):\n        dispatcher = {\n            0: img,\n            1: img,\n            2: img,            \n            3: img.transpose(im.ROTATE_90),\n            4: img.transpose(im.ROTATE_180),\n            5: img.transpose(im.ROTATE_270)\n        }\n    \n        return dispatcher[random.randint(0,5)] #randint is inclusive\n    \nclass PILColorBalance(object):\n\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Color(img).enhance(alpha)\n\nclass PILContrast(object):\n\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Contrast(img).enhance(alpha)\n\n\nclass PILBrightness(object):\n\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Brightness(img).enhance(alpha)\n\nclass PILSharpness(object):\n\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Sharpness(img).enhance(alpha)\n    \n\n# Check ImageEnhancer effect: https://www.youtube.com/watch?v=_7iDTpTop04\n# Not documented but all enhancements can go beyond 1.0 to 2\n# Image must be RGB\n# Use Pillow-SIMD because Pillow is too slow\nclass PowerPIL(RandomOrder):\n    def __init__(self, rotate=True,\n                       flip=True,\n                       colorbalance=0.4,\n                       contrast=0.4,\n                       brightness=0.4,\n                       sharpness=0.4):\n        self.transforms = []\n        if rotate:\n            self.transforms.append(RandomRotate())\n        if flip:\n            self.transforms.append(RandomFlip())\n        if brightness != 0:\n            self.transforms.append(PILBrightness(brightness))\n        if contrast != 0:\n            self.transforms.append(PILContrast(contrast))\n        if colorbalance != 0:\n            self.transforms.append(PILColorBalance(colorbalance))\n        if sharpness != 0:\n            self.transforms.append(PILSharpness(sharpness))'"
src/p_dataload.py,1,"b'from torch.utils.data.dataset import Dataset\nfrom torchvision import transforms\nimport pandas as pd\nimport os\nfrom PIL import Image # Replace by accimage when ready\nfrom PIL.Image import FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM, ROTATE_90, ROTATE_180, ROTATE_270\nfrom PIL.ImageEnhance import Color, Contrast, Brightness, Sharpness\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom torch import np, from_numpy # Numpy like wrapper\n\nclass KaggleAmazonDataset(Dataset):\n    """"""Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n\n    Arguments:\n        A CSV file path\n        Path to image folder\n        Extension of images\n    """"""\n\n    def __init__(self, csv_path, img_path, img_ext, transform=None):\n    \n        self.df = pd.read_csv(csv_path)\n        assert self.df[\'image_name\'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n""Some images referenced in the CSV file were not found""\n        \n        self.mlb = MultiLabelBinarizer()\n        self.img_path = img_path\n        self.img_ext = img_ext\n        self.transform = transform\n\n        self.X = self.df[\'image_name\']\n        self.y = self.mlb.fit_transform(self.df[\'tags\'].str.split()).astype(np.float32)\n\n    def X(self):\n        return self.X\n        \n    def __getitem__(self, index):\n        img = Image.open(self.img_path + self.X[index] + self.img_ext)\n        img = img.convert(\'RGB\')\n        if self.transform is not None:\n            img = self.transform(img)\n        \n        label = from_numpy(self.y[index])\n        return img, label\n\n    def __len__(self):\n        return len(self.df.index)\n    \n    def getLabelEncoder(self):\n        return self.mlb\n    \n    def getDF(self):\n        return self.df'"
src/p_logger.py,0,"b'import logging\nimport os\n\ndef setup_logs(save_dir, run_name):\n    # initialize logger\n    logger = logging.getLogger(""Planet-Amazon"")\n    logger.setLevel(logging.INFO)\n \n    # create the logging file handler\n    log_file = os.path.join(save_dir, run_name + "".log"")\n    fh = logging.FileHandler(log_file)\n    \n    # create the logging console handler\n    ch = logging.StreamHandler()\n    \n    # format\n    formatter = logging.Formatter(""%(asctime)s - %(message)s"")\n    fh.setFormatter(formatter)\n    \n    # add handlers to logger object\n    logger.addHandler(fh)\n    logger.addHandler(ch)\n    \n    return logger'"
src/p_metrics.py,5,"b'import numpy as np\nimport logging\nfrom sklearn.metrics import fbeta_score\nfrom scipy.optimize import fmin_l_bfgs_b, basinhopping\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom timeit import default_timer as timer\n\n\n## Get the same logger from main""\nlogger = logging.getLogger(""Planet-Amazon"")\n\ndef best_f2_score(true_labels, predictions):\n\n    def f_neg(threshold):\n        ## Scipy tries to minimize the function so we must get its inverse\n        return - fbeta_score(true_labels, predictions > threshold, beta=2, average=\'samples\')\n\n    # Initialization of best threshold search\n    thr_0 = [0.20] * 17\n    constraints = [(0.,1.)] * 17\n    def bounds(**kwargs):\n        x = kwargs[""x_new""]\n        tmax = bool(np.all(x <= 1))\n        tmin = bool(np.all(x >= 0)) \n        return tmax and tmin\n    \n    # Search using L-BFGS-B, the epsilon step must be big otherwise there is no gradient\n    minimizer_kwargs = {""method"": ""L-BFGS-B"",\n                        ""bounds"":constraints,\n                        ""options"":{\n                            ""eps"": 0.05\n                            }\n                       }\n    \n    # We combine L-BFGS-B with Basinhopping for stochastic search with random steps\n    logger.info(""===> Searching optimal threshold for each label"")\n    start_time = timer()\n    \n    opt_output = basinhopping(f_neg, thr_0,\n                                stepsize = 0.1,\n                                minimizer_kwargs=minimizer_kwargs,\n                                niter=10,\n                                accept_test=bounds)\n    \n    end_time = timer()\n    logger.info(""===> Optimal threshold for each label:\\n{}"".format(opt_output.x))\n    logger.info(""Threshold found in: %s seconds"" % (end_time - start_time))\n    \n    score = - opt_output.fun\n    return score, opt_output.x\n\n\n# We use real valued F2 score for training. Input can be anything between 0 and 1.\n# Threshold is not differentiable so we don\'t use it during training\n# We get a smooth F2 score valid for real values and not only 0/1\ndef torch_f2_score(y_true, y_pred):\n    return torch_fbeta_score(y_true, y_pred, 2)\n\ndef torch_fbeta_score(y_true, y_pred, beta, eps=1e-9):\n    beta2 = beta**2\n\n    y_true = y_true.float()\n\n    true_positive = (y_pred * y_true).sum(dim=1)\n    precision = true_positive.div(y_pred.sum(dim=1).add(eps))\n    recall = true_positive.div(y_true.sum(dim=1).add(eps))\n\n    return torch.mean(\n        (precision*recall).\n        div(precision.mul(beta2) + recall + eps).\n        mul(1 + beta2))\n\n\nclass SmoothF2Loss(nn.Module):\n    def __init__(self):\n        super(MeanF2Loss, self).__init__()\n    \n    def forward(self, input, target):\n        return 1 - torch_f2_score(target, torch.sigmoid(input))'"
src/p_model_selection.py,0,"b'import random\nfrom math import floor\n\ndef train_valid_split(dataset, test_size = 0.25, shuffle = False, random_seed = 0):\n    """""" Return a list of splitted indices from a DataSet.\n    Indices can be used with DataLoader to build a train and validation set.\n    \n    Arguments:\n        A Dataset\n        A test_size, as a float between 0 and 1 (percentage split) or as an int (fixed number split)\n        Shuffling True or False\n        Random seed\n    """"""\n    length = dataset.__len__()\n    indices = list(range(1,length))\n    \n    if shuffle == True:\n        random.seed(random_seed)\n        random.shuffle(indices)\n    \n    if type(test_size) is float:\n        split = floor(test_size * length)\n    elif type(test_size) is int:\n        split = test_size\n    else:\n        raise ValueError(\'%s should be an int or a float\' % str)\n    return indices[split:], indices[:split]'"
src/p_neuro.py,5,"b""from torch import nn, ones\nfrom torchvision import models\nfrom torch.nn.init import kaiming_normal\nfrom torch import np\nimport torch\nimport torch.nn.functional as F\n\n\n## Custom baseline\nclass Net(nn.Module):    \n    def __init__(self, input_size=(3,224,224), nb_classes=17):\n        \n        super(Net, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3,32,3),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32,64,3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d((3,3))\n        )\n        \n        ## Compute linear layer size\n        self.flat_feats = self._get_flat_feats(input_size, self.features)\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(self.flat_feats, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(p=0.15),\n            nn.Linear(256, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Dropout(p=0.10),\n            nn.Linear(64, nb_classes)\n        )\n     \n        ## Weights initialization\n        def _weights_init(m):\n            if isinstance(m, nn.Conv2d or nn.Linear):\n                kaiming_normal(m.weight)\n            elif isinstance(m, nn.BatchNorm2d or BatchNorm1d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        \n        self.apply(_weights_init)       \n    \n    def _get_flat_feats(self, in_size, feats):\n        f = feats(Variable(ones(1,*in_size)))\n        return int(np.prod(f.size()[1:]))\n    \n\n            \n    def forward(self, x):\n        feats = self.features(x)\n        flat_feats = feats.view(-1, self.flat_feats)\n        out = self.classifier(flat_feats)\n        return out\n\n    \n## ResNet fine-tuning\nclass ResNet50(nn.Module):\n    ## We use ResNet weights from PyCaffe.\n    def __init__(self, num_classes):\n        super(ResNet50, self).__init__()\n        \n        # Loading ResNet arch from PyTorch and weights from Pycaffe\n        original_model = models.resnet50(pretrained=False)\n        original_model.load_state_dict(torch.load('./zoo/resnet50.pth'))\n        \n        # Everything except the last linear layer\n        self.features = nn.Sequential(*list(original_model.children())[:-1])\n        \n        # Get number of features of last layer\n        num_feats = original_model.fc.in_features\n        \n        # Plug our classifier\n        self.classifier = nn.Sequential(\n        nn.Linear(num_feats, num_classes)\n        )\n        \n        # Init of last layer\n        for m in self.classifier:\n            kaiming_normal(m.weight)\n\n        # Freeze those weights\n        # for p in self.features.parameters():\n        #     p.requires_grad = False\n\n    def forward(self, x):\n        f = self.features(x)\n        f = f.view(f.size(0), -1)\n        y = self.classifier(f)\n        return y\n\nclass ResNet101(nn.Module):\n    ## We use ResNet weights from PyCaffe.\n    def __init__(self, num_classes):\n        super(ResNet101, self).__init__()\n        \n        # Loading ResNet arch from PyTorch and weights from Pycaffe\n        original_model = models.resnet101(pretrained=False)\n        original_model.load_state_dict(torch.load('./zoo/resnet101.pth'))\n        \n        # Everything except the last linear layer\n        self.features = nn.Sequential(*list(original_model.children())[:-1])\n        \n        # Get number of features of last layer\n        num_feats = original_model.fc.in_features\n        \n        # Plug our classifier\n        self.classifier = nn.Sequential(\n        nn.Linear(num_feats, num_classes)\n        )\n        \n        # Init of last layer\n        for m in self.classifier:\n            kaiming_normal(m.weight)\n\n        # Freeze those weights\n        # for p in self.features.parameters():\n        #     p.requires_grad = False\n\n    def forward(self, x):\n        f = self.features(x)\n        f = f.view(f.size(0), -1)\n        y = self.classifier(f)\n        return y\n\nclass ResNet152(nn.Module):\n    ## We use ResNet weights from PyCaffe.\n    def __init__(self, num_classes):\n        super(ResNet152, self).__init__()\n        \n        # Loading ResNet arch from PyTorch and weights from Pycaffe\n        original_model = models.resnet152(pretrained=False)\n        original_model.load_state_dict(torch.load('./zoo/resnet152.pth'))\n        \n        # Everything except the last linear layer\n        self.features = nn.Sequential(*list(original_model.children())[:-1])\n        \n        # Get number of features of last layer\n        num_feats = original_model.fc.in_features\n        \n        # Plug our classifier\n        self.classifier = nn.Sequential(\n        nn.Linear(num_feats, num_classes)\n        )\n        \n        # Init of last layer\n        for m in self.classifier:\n            kaiming_normal(m.weight)\n\n        # Freeze those weights\n        # for p in self.features.parameters():\n        #     p.requires_grad = False\n\n    def forward(self, x):\n        f = self.features(x)\n        f = f.view(f.size(0), -1)\n        y = self.classifier(f)\n        return y\n    \n## VGG fine-tuning\nclass VGG16(nn.Module):\n        def __init__(self, nb_classes=17):\n            super(VGG16, self).__init__()\n            original_model = models.vgg16(pretrained=False)\n            self.features = original_model.features\n            self.classifier = nn.Sequential(\n                    nn.Dropout(),\n                    nn.Linear(25088, 4096),\n                    nn.ReLU(inplace=True),\n                    nn.Dropout(),\n                    nn.Linear(4096, 4096),\n                    nn.ReLU(inplace=True),\n                    nn.Linear(4096, num_classes),\n                )\n\n            # Freeze Convolutional weights\n            for p in self.features.parameters():\n                p.requires_grad = False\n\n        def forward(self, x):\n            f = self.features(x)\n            f = f.view(f.size(0), -1)\n            y = self.classifier(f)\n            return y\n\nclass DenseNet121(nn.Module):\n    def __init__(self, num_classes):\n        super(DenseNet121, self).__init__()\n        \n        original_model = models.densenet121(pretrained=True)\n        \n        # Everything except the last linear layer\n        self.features = nn.Sequential(*list(original_model.children())[:-1])\n        \n        # Get number of features of last layer\n        num_feats = original_model.classifier.in_features\n        \n        # Plug our classifier\n        self.classifier = nn.Sequential(\n        nn.Linear(num_feats, num_classes)\n        )\n\n        # Init of last layer\n        for m in self.classifier:\n            kaiming_normal(m.weight)\n            \n        # Freeze weights\n        # for p in self.features.parameters():\n        #     p.requires_grad = False\n\n    def forward(self, x):\n        f = self.features(x)\n        out = F.relu(f, inplace=True)\n        out = F.avg_pool2d(out, kernel_size=7).view(f.size(0), -1)\n        out = self.classifier(out)\n        return out"""
src/p_prediction.py,2,"b'from torch.autograd import Variable\nimport numpy as np\nimport logging\nimport os\nimport pandas as pd\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\n## Get the same logger from main""\nlogger = logging.getLogger(""Planet-Amazon"")\n\n##################################################\n#### Prediction function\ndef predict(test_loader, model):    \n    model.eval()\n    predictions = []\n    \n    logger.info(""Starting Prediction"")\n    for batch_idx, (data, _) in enumerate(tqdm(test_loader)):\n        data = data.cuda(async=True)\n        data = Variable(data, volatile=True)\n    \n        pred = F.sigmoid(model(data))\n        predictions.append(pred.data.cpu().numpy())\n    \n    predictions = np.vstack(predictions)\n    \n    logger.info(""===> Raw predictions done. Here is a snippet"")\n    logger.info(predictions)\n    return predictions\n\ndef output(predictions, threshold, X_test, mlb, dir_path, run_name, accuracy):\n    \n    raw_pred_path = os.path.join(dir_path, run_name + \'-raw-pred-\'+str(accuracy)+\'.csv\')\n    np.savetxt(raw_pred_path,predictions,delimiter="";"")\n    logger.info(""Raw predictions saved to {}"".format(raw_pred_path))\n    \n    predictions = predictions > threshold\n    \n    result = pd.DataFrame({\n        \'image_name\': X_test.X,\n        \'tags\': mlb.inverse_transform(predictions)\n    })\n    result[\'tags\'] = result[\'tags\'].apply(lambda tags: "" "".join(tags))\n    \n    logger.info(""===> Final predictions done. Here is a snippet"")\n    logger.info(result)\n    \n    result_path = os.path.join(dir_path, run_name + \'-final-pred-\'+str(accuracy)+\'.csv\')\n    result.to_csv(result_path, index=False)\n    logger.info(""Final predictions saved to {}"".format(result_path))'"
src/p_sampler.py,1,"b'from torch.utils.data.sampler import Sampler\nimport numpy as np\nimport pandas as pd\n\nclass SubsetSampler(Sampler):\n     """"""Samples elements from a given list of indices.\n \n     Arguments:\n         indices (list): a list of indices\n     """"""\n \n     def __init__(self, indices):\n        self.num_samples = len(indices)\n        self.indices = indices\n \n     def __iter__(self):\n        return iter(self.indices)\n \n     def __len__(self):\n        return self.num_samples\n    \ndef balance_weights(df_source, col_target, mlb):\n    """""" Compute balanced weights from a Multilabel dataframe\n    \n    Arguments:\n        Dataframe\n        The name of the column with the target labels\n        A MultiLabelBinarizer to one-hot-encode/decode the label column\n        \n    Returns:\n        A Pandas Series with balanced weights\n    """"""\n    \n    # Create a working copy of the dataframe\n    df = df_source.copy(deep=True)\n    \n    df_labels = mlb.transform(df[col_target].str.split("" ""))\n    \n    ##\xc2\xa0Next 4 lines won\'t be needed when axis argument is added to np.unique in NumPy 1.13\n    ncols = df_labels.shape[1]\n    dtype = df_labels.dtype.descr * ncols\n    struct = df_labels.view(dtype)\n    uniq_labels, uniq_counts = np.unique(struct, return_counts=True)\n    \n    uniq_labels = uniq_labels.view(df_labels.dtype).reshape(-1, ncols)\n    \n    ## We convert the One-Hot-Encoded labels as string to store them in a dataframe and join on them\n    df_stats = pd.DataFrame({\n        \'target\':np.apply_along_axis(np.array_str, 1, uniq_labels),\n        \'freq\':uniq_counts\n    })\n    \n    df[\'target\'] = np.apply_along_axis(np.array_str, 1, df_labels)\n    \n    ## Join the dataframe to add frequency\n    df = df.merge(df_stats,how=\'left\',on=\'target\')\n    \n    ## Compute balanced weights\n    weights = 1 / df[\'freq\'].astype(np.float)\n    \n    return weights'"
src/p_training.py,2,"b'from torch.autograd import Variable\nimport torch\nimport os\nimport logging\n\n## Get the same logger from main""\nlogger = logging.getLogger(""Planet-Amazon"")\n\n\ndef lr_scheduler(optimizer, epoch, init_lr=0.01, lr_decay_epoch=7):\n    """"""Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.""""""\n    lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n\n    if epoch % lr_decay_epoch == 0:\n        logger.info(\'LR is set to {}\'.format(lr))\n\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n    return optimizer\n\ndef train(epoch,train_loader,model,loss_func, optimizer):\n    model.train()\n    optimizer = lr_scheduler(optimizer, epoch)\n    \n    \n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.cuda(async=True), target.cuda(async=True)\n        data, target = Variable(data), Variable(target, requires_grad=False)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = loss_func(output,target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            logger.info(\'Train Epoch: {:03d} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader) * len(data),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef snapshot(dir_path, run_name, is_best, state):\n    snapshot_file = os.path.join(dir_path,\n                    run_name + \'-model_best.pth\')\n    if is_best:\n        torch.save(state, snapshot_file)\n        logger.info(""Snapshot saved to {}"".format(snapshot_file))'"
src/p_validation.py,2,"b'from torch.autograd import Variable\nimport numpy as np\nimport logging\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\nfrom src.p_metrics import best_f2_score\n\n## Get the same logger from main""\nlogger = logging.getLogger(""Planet-Amazon"")\n\n##################################################\n#### Validate function\ndef validate(epoch,valid_loader,model,loss_func,mlb):\n    ## Volatile variables do not save intermediate results and build graphs for backprop, achieving massive memory savings.\n    \n    model.eval()\n    total_loss = 0\n    predictions = []\n    true_labels = []\n    \n    logger.info(""Starting Validation"")\n    for batch_idx, (data, target) in enumerate(tqdm(valid_loader)):\n        true_labels.append(target.cpu().numpy())\n        \n        data, target = data.cuda(async=True), target.cuda(async=True)\n        data, target = Variable(data, volatile=True), Variable(target, volatile=True)\n    \n        pred = model(data)\n        predictions.append(F.sigmoid(pred).data.cpu().numpy())\n        \n        total_loss += loss_func(pred,target).data[0]\n    \n    avg_loss = total_loss / len(valid_loader)\n    \n    predictions = np.vstack(predictions)\n    true_labels = np.vstack(true_labels)\n   \n    score, threshold = best_f2_score(true_labels, predictions)\n    logger.info(""Corresponding tags\\n{}"".format(mlb.classes_))\n    \n    logger.info(""===> Validation - Avg. loss: {:.4f}\\tF2 Score: {:.4f}"".format(avg_loss,score))\n    return score, avg_loss, threshold'"
baseline/unfinished_attempts/000-Mxnet-ResNet-baseline-TODO.py,0,"b'import xgboost as xgb\nimport cv2\nimport mxnet as mx\nimport os\nimport numpy as np\nfrom timeit import default_timer as timer\nfrom sklearn.model_selection import train_test_split\n\nSRC_IMAGES = \'../data/train-jpg/\'\nSRCDIR = os.listdir(SRC_IMAGES)\nTMPDIR = \'./tmp/\'\n\ndef get_extractor():\n    model = mx.model.FeedForward.load(\'../pretrained-models/resnet-50\', 0, ctx=mx.gpu(), numpy_batch_size=1)\n    fea_symbol = model.symbol.get_internals()[""flatten0_output""]\n    feature_extractor = mx.model.FeedForward(ctx=mx.gpu(), symbol=fea_symbol, numpy_batch_size=64,\n                                             arg_params=model.arg_params, aux_params=model.aux_params,\n                                             allow_extra_params=True)\n\n    return feature_extractor\n\n\ndef prepare_image_batch(image):\n    img = SRC_IMAGES + image\n    img = cv2.imread(img)\n    img = 255.0 / np.amax(img) * img\n    # img = cv2.equalizeHist(img.astype(np.uint8))\n    img = cv2.resize(img.astype(np.int16), (224, 224))\n    img = img.reshape(1,3,224,224)\n\n    return img\n\ndef calc_features():\n    net = get_extractor()\n    n=1\n    for image in SRCDIR:\n        print(""Doing image %s/%s: %s"" % (n, len(SRCDIR), image))\n        img = prepare_image_batch(image)\n        print(img.shape)\n        feats = net.predict(img)\n        print(""Prediction features have shape:"")\n        print(feats.shape)\n        np.save(TMPDIR+image, feats)\n        \n        n+=1\n\n\nif __name__ == \'__main__\':\n    start_time = timer()\n    calc_features()\n    # make_submit()\n    end_time = timer()\n    print(""Elapsed time: %s"" % (end_time - start_time))'"
baseline/unfinished_attempts/002-Keras-Inception-Transfer.py,0,"b""from keras.applications.inception_v3 import InceptionV3\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Dense, Flatten, Input, BatchNormalization\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom sklearn.metrics import fbeta_score\nfrom tqdm import tqdm\nimport cv2\nimport numpy as np\nimport os\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nRESOLUTION = 96\nCACHE_FILE = '002-inception-baseline-cache.h5'\nTHRESHOLD = 0.2\n\ndef build_model():\n    #Create own input format\n    model_input = Input(shape=(RESOLUTION,RESOLUTION,3),name = 'image_input')\n    \n    #Load Inception v3\n    base_model = InceptionV3(weights='imagenet', include_top=False)\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    x = base_model(model_input)\n    feat = Flatten(name='flatten')(x)\n    feat = Dense(128, activation='relu')(feat)\n    feat = BatchNormalization()(feat)\n    out = Dense(17, activation='sigmoid')(feat)\n    model = Model(inputs=model_input, outputs=out)\n    \n    model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n    \n    \n    print('######## Summary ########')\n    model.summary()\n    print('\\n\\n\\n######## Config ########')\n    model.get_config()\n    print('\\n\\n\\n######## ###### ########')\n    \n    return model\n\nmlb = MultiLabelBinarizer()\nX_train = []\nX_test = []\ndf_train = pd.read_csv('../data/train.csv')\ny_train = mlb.fit_transform(df_train['tags'].str.split())\n\n\nfor file in tqdm(df_train['image_name'], miniters=256):\n    img = cv2.imread('../data/train-jpg/{}.jpg'.format(file))\n    X_train.append(cv2.resize(img,(RESOLUTION,RESOLUTION)))\n\nX_train = np.array(X_train, np.float16) / 255. ## TODO load per batch to avoid memory error here\n\nprint(X_train.shape)\nprint(y_train.shape)\n\n######## Validation ########\nx_trn, x_val, y_trn, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\nif os.path.isfile(CACHE_FILE):\n    print('####### Loading model from cache ######')\n    model = load_model(CACHE_FILE)\n\nelse:\n    print('####### Cache not found, building from scratch ######')\n    model = build_model()\n    model.fit(x_trn, y_trn,\n              batch_size=64,\n              epochs=15,\n              verbose=1,\n              validation_data=(x_val, y_val))\n    model.save(CACHE_FILE)\n    \n\np_valid = model.predict(x_val, batch_size=128)\nprint(y_val)\nprint(p_valid)\nprint(fbeta_score(y_val, np.array(p_valid) > THRESHOLD, beta=2, average='samples'))\n\n######## Prediction ########\n\ndf_test = pd.read_csv('../data/sample_submission.csv')\n\nfor file in tqdm(df_test['image_name'], miniters=256):\n    img = cv2.imread('../data/test-jpg/{}.jpg'.format(file))\n    X_test.append(cv2.resize(img,(RESOLUTION,RESOLUTION)))\n\n\nX_test = np.array(X_test, np.float16) / 255.\n\ny_pred = model.predict(X_test, batch_size=128)\n\ndf_submission = pd.DataFrame()\ndf_submission['image_name'] = df_test['image_name']\ndf_submission['tags'] = [' '.join(x) for x in mlb.inverse_transform(y_pred > THRESHOLD)]\n\ndf_submission.to_csv('002-inception-baseline.csv', index=False)"""
