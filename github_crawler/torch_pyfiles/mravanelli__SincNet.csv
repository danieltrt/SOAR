file_path,api_count,code
TIMIT_preparation.py,0,"b'#!/usr/bin/env python3\n\n# TIMIT_preparation \n# Mirco Ravanelli \n# Mila - University of Montreal \n\n# July 2018\n\n# Description: \n# This code prepares TIMIT for the following speaker identification experiments. \n# It removes start and end silences according to the information reported in the *.wrd files and normalizes the amplitude of each sentence.\n \n# How to run it:\n# python TIMIT_preparation.py $TIMIT_FOLDER $OUTPUT_FOLDER data_lists/TIMIT_all.scp \n\n# NOTE: This script expects filenames in lowercase (e.g, train/dr1/fcjf0/si1027.wav"" rather than ""TRAIN/DR1/FCJF0/SI1027.WAV)\n\n\nimport shutil\nimport os\nimport soundfile as sf\nimport numpy as np\nimport sys\n\ndef ReadList(list_file):\n f=open(list_file,""r"")\n lines=f.readlines()\n list_sig=[]\n for x in lines:\n    list_sig.append(x.rstrip())\n f.close()\n return list_sig\n\ndef copy_folder(in_folder,out_folder):\n if not(os.path.isdir(out_folder)):\n  shutil.copytree(in_folder, out_folder, ignore=ig_f)\n\ndef ig_f(dir, files):\n return [f for f in files if os.path.isfile(os.path.join(dir, f))]\n\n\n\nin_folder=sys.argv[1]\nout_folder=sys.argv[2]\nlist_file=sys.argv[3]\n\n# Read List file\nlist_sig=ReadList(list_file)\n\n# Replicate input folder structure to output folder\ncopy_folder(in_folder,out_folder)\n\n\n# Speech Data Reverberation Loop\nfor i in range(len(list_sig)): \n \n # Open the wav file\n wav_file=in_folder+\'/\'+list_sig[i]\n [signal, fs] = sf.read(wav_file)\n signal=signal.astype(np.float64)\n\n # Signal normalization\n signal=signal/np.max(np.abs(signal))\n\n # Read wrd file\n wrd_file=wav_file.replace("".wav"","".wrd"")\n wrd_sig=ReadList(wrd_file)\n beg_sig=int(wrd_sig[0].split(\' \')[0])\n end_sig=int(wrd_sig[-1].split(\' \')[1])\n \n # Remove silences\n signal=signal[beg_sig:end_sig]\n\n \n # Save normalized speech\n file_out=out_folder+\'/\'+list_sig[i]\n\n sf.write(file_out, signal, fs)\n \n print(""Done %s"" % (file_out))\n'"
compute_d_vector.py,15,"b'# compute_d_vector.py\n# Mirco Ravanelli \n# Mila - University of Montreal \n\n# Feb 2019\n\n# Description: \n# This code computes d-vectors using a pre-trained model\n \n\nimport os\nimport soundfile as sf\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport numpy as np\nfrom dnn_models import MLP\nfrom dnn_models import SincNet as CNN \nfrom data_io import ReadList,read_conf_inp,str_to_bool\nimport sys\n\n# Model to use for computing the d-vectors\nmodel_file=\'/home/mirco/sincnet_models/SincNet_TIMIT/model_raw.pkl\' # This is the model to use for computing the d-vectors (it should be pre-trained using the speaker-id DNN)\ncfg_file=\'/home/mirco/SincNet/cfg/SincNet_TIMIT.cfg\' # Config file of the speaker-id experiment used to generate the model\nte_lst=\'data_lists/TIMIT_test.scp\' # List of the wav files to process\nout_dict_file=\'d_vect_timit.npy\' # output dictionary containing the a sentence id as key as the d-vector as value\ndata_folder=\'/home/mirco/Dataset/TIMIT_norm_nosil\'\n\navoid_small_en_fr=True\nenergy_th = 0.1  # Avoid frames with an energy that is 1/10 over the average energy\n\ndevice = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n#device = None\n\n# Reading cfg file\noptions=read_conf_inp(cfg_file)\n\n\n#[data]\npt_file=options.pt_file\noutput_folder=options.output_folder\n\n#[windowing]\nfs=int(options.fs)\ncw_len=int(options.cw_len)\ncw_shift=int(options.cw_shift)\n\n#[cnn]\ncnn_N_filt=list(map(int, options.cnn_N_filt.split(\',\')))\ncnn_len_filt=list(map(int, options.cnn_len_filt.split(\',\')))\ncnn_max_pool_len=list(map(int, options.cnn_max_pool_len.split(\',\')))\ncnn_use_laynorm_inp=str_to_bool(options.cnn_use_laynorm_inp)\ncnn_use_batchnorm_inp=str_to_bool(options.cnn_use_batchnorm_inp)\ncnn_use_laynorm=list(map(str_to_bool, options.cnn_use_laynorm.split(\',\')))\ncnn_use_batchnorm=list(map(str_to_bool, options.cnn_use_batchnorm.split(\',\')))\ncnn_act=list(map(str, options.cnn_act.split(\',\')))\ncnn_drop=list(map(float, options.cnn_drop.split(\',\')))\n\n\n#[dnn]\nfc_lay=list(map(int, options.fc_lay.split(\',\')))\nfc_drop=list(map(float, options.fc_drop.split(\',\')))\nfc_use_laynorm_inp=str_to_bool(options.fc_use_laynorm_inp)\nfc_use_batchnorm_inp=str_to_bool(options.fc_use_batchnorm_inp)\nfc_use_batchnorm=list(map(str_to_bool, options.fc_use_batchnorm.split(\',\')))\nfc_use_laynorm=list(map(str_to_bool, options.fc_use_laynorm.split(\',\')))\nfc_act=list(map(str, options.fc_act.split(\',\')))\n\n#[class]\nclass_lay=list(map(int, options.class_lay.split(\',\')))\nclass_drop=list(map(float, options.class_drop.split(\',\')))\nclass_use_laynorm_inp=str_to_bool(options.class_use_laynorm_inp)\nclass_use_batchnorm_inp=str_to_bool(options.class_use_batchnorm_inp)\nclass_use_batchnorm=list(map(str_to_bool, options.class_use_batchnorm.split(\',\')))\nclass_use_laynorm=list(map(str_to_bool, options.class_use_laynorm.split(\',\')))\nclass_act=list(map(str, options.class_act.split(\',\')))\n\n\nwav_lst_te=ReadList(te_lst)\nsnt_te=len(wav_lst_te)\n\n\n# Folder creation\ntry:\n    os.stat(output_folder)\nexcept:\n    os.mkdir(output_folder) \n    \n    \n# loss function\ncost = nn.NLLLoss()\n\n  \n# Converting context and shift in samples\nwlen=int(fs*cw_len/1000.00)\nwshift=int(fs*cw_shift/1000.00)\n\n# Batch_dev\nBatch_dev=128\n\n\n# Feature extractor CNN\nCNN_arch = {\'input_dim\': wlen,\n          \'fs\': fs,\n          \'cnn_N_filt\': cnn_N_filt,\n          \'cnn_len_filt\': cnn_len_filt,\n          \'cnn_max_pool_len\':cnn_max_pool_len,\n          \'cnn_use_laynorm_inp\': cnn_use_laynorm_inp,\n          \'cnn_use_batchnorm_inp\': cnn_use_batchnorm_inp,\n          \'cnn_use_laynorm\':cnn_use_laynorm,\n          \'cnn_use_batchnorm\':cnn_use_batchnorm,\n          \'cnn_act\': cnn_act,\n          \'cnn_drop\':cnn_drop,          \n          }\n\nCNN_net=CNN(CNN_arch)\nCNN_net.to(device)\n\n\n\nDNN1_arch = {\'input_dim\': CNN_net.out_dim,\n          \'fc_lay\': fc_lay,\n          \'fc_drop\': fc_drop, \n          \'fc_use_batchnorm\': fc_use_batchnorm,\n          \'fc_use_laynorm\': fc_use_laynorm,\n          \'fc_use_laynorm_inp\': fc_use_laynorm_inp,\n          \'fc_use_batchnorm_inp\':fc_use_batchnorm_inp,\n          \'fc_act\': fc_act,\n          }\n\nDNN1_net=MLP(DNN1_arch)\nDNN1_net.to(device)\n\n\nDNN2_arch = {\'input_dim\':fc_lay[-1] ,\n          \'fc_lay\': class_lay,\n          \'fc_drop\': class_drop, \n          \'fc_use_batchnorm\': class_use_batchnorm,\n          \'fc_use_laynorm\': class_use_laynorm,\n          \'fc_use_laynorm_inp\': class_use_laynorm_inp,\n          \'fc_use_batchnorm_inp\':class_use_batchnorm_inp,\n          \'fc_act\': class_act,\n          }\n\n\nDNN2_net=MLP(DNN2_arch)\nDNN2_net.to(device)\n\n\ncheckpoint_load = torch.load(model_file)\nCNN_net.load_state_dict(checkpoint_load[\'CNN_model_par\'])\nDNN1_net.load_state_dict(checkpoint_load[\'DNN1_model_par\'])\nDNN2_net.load_state_dict(checkpoint_load[\'DNN2_model_par\'])\n\n\n\nCNN_net.eval()\nDNN1_net.eval()\nDNN2_net.eval()\ntest_flag=1 \n\n\nd_vector_dim=fc_lay[-1]\nd_vect_dict={}\n\n   \nwith torch.no_grad(): \n    \n    for i in range(snt_te):\n           \n         [signal, fs] = sf.read(data_folder+\'/\'+wav_lst_te[i])\n         \n         # Amplitude normalization\n         signal=signal/np.max(np.abs(signal))\n        \n         signal=torch.from_numpy(signal).float().to(device).contiguous()\n        \n         if avoid_small_en_fr: \n             # computing energy on each frame:\n             beg_samp=0\n             end_samp=wlen\n    \n             N_fr=int((signal.shape[0]-wlen)/(wshift))\n             Batch_dev=N_fr\n             en_arr=torch.zeros(N_fr).float().contiguous().to(device)\n             count_fr=0\n             count_fr_tot=0\n             while end_samp<signal.shape[0]:\n                en_arr[count_fr]=torch.sum(signal[beg_samp:end_samp].pow(2))\n                beg_samp=beg_samp+wshift\n                end_samp=beg_samp+wlen\n                count_fr=count_fr+1\n                count_fr_tot=count_fr_tot+1\n                if count_fr==N_fr:\n                    break\n    \n             en_arr_bin=en_arr>torch.mean(en_arr)*0.1\n             en_arr_bin.to(device)\n             n_vect_elem=torch.sum(en_arr_bin)\n    \n             if n_vect_elem<10:\n                 print(\'only few elements used to compute d-vectors\')\n                 sys.exit(0)\n\n\n\n         # split signals into chunks\n         beg_samp=0\n         end_samp=wlen\n         \n         N_fr=int((signal.shape[0]-wlen)/(wshift))\n         \n        \n         sig_arr=torch.zeros([Batch_dev,wlen]).float().to(device).contiguous()\n         dvects=Variable(torch.zeros(N_fr,d_vector_dim).float().to(device).contiguous())\n         count_fr=0\n         count_fr_tot=0\n         while end_samp<signal.shape[0]:\n             sig_arr[count_fr,:]=signal[beg_samp:end_samp]\n             beg_samp=beg_samp+wshift\n             end_samp=beg_samp+wlen\n             count_fr=count_fr+1\n             count_fr_tot=count_fr_tot+1\n             if count_fr==Batch_dev:\n                 inp=Variable(sig_arr)\n                 dvects[count_fr_tot-Batch_dev:count_fr_tot,:]=DNN1_net(CNN_net(inp))\n                 count_fr=0\n                 sig_arr=torch.zeros([Batch_dev,wlen]).float().to(device).contiguous()\n           \n         if count_fr>0:\n          inp=Variable(sig_arr[0:count_fr])\n          dvects[count_fr_tot-count_fr:count_fr_tot,:]=DNN1_net(CNN_net(inp))\n        \n         if avoid_small_en_fr:\n             dvects=dvects.index_select(0, (en_arr_bin==1).nonzero().view(-1))\n         \n         # averaging and normalizing all the d-vectors\n         d_vect_out=torch.mean(dvects/dvects.norm(p=2, dim=1).view(-1,1),dim=0)\n         \n         # checks for nan\n         nan_sum=torch.sum(torch.isnan(d_vect_out))\n\n         if nan_sum>0:\n             print(wav_lst_te[i])\n             sys.exit(0)\n\n         \n         # saving the d-vector in a numpy dictionary\n         dict_key=wav_lst_te[i].split(\'/\')[-2]+\'/\'+wav_lst_te[i].split(\'/\')[-1]\n         d_vect_dict[dict_key]=d_vect_out.cpu().numpy()\n         print(dict_key)\n\n# Save the dictionary\nnp.save(out_dict_file, d_vect_dict)\n         \n    \n    \n\n\n\n'"
data_io.py,2,"b'import configparser as ConfigParser\nfrom optparse import OptionParser\nimport numpy as np\n#import scipy.io.wavfile\nimport torch\n\ndef ReadList(list_file):\n f=open(list_file,""r"")\n lines=f.readlines()\n list_sig=[]\n for x in lines:\n    list_sig.append(x.rstrip())\n f.close()\n return list_sig\n\n\ndef read_conf():\n \n parser=OptionParser()\n parser.add_option(""--cfg"") # Mandatory\n (options,args)=parser.parse_args()\n cfg_file=options.cfg\n Config = ConfigParser.ConfigParser()\n Config.read(cfg_file)\n\n #[data]\n options.tr_lst=Config.get(\'data\', \'tr_lst\')\n options.te_lst=Config.get(\'data\', \'te_lst\')\n options.lab_dict=Config.get(\'data\', \'lab_dict\')\n options.data_folder=Config.get(\'data\', \'data_folder\')\n options.output_folder=Config.get(\'data\', \'output_folder\')\n options.pt_file=Config.get(\'data\', \'pt_file\')\n\n #[windowing]\n options.fs=Config.get(\'windowing\', \'fs\')\n options.cw_len=Config.get(\'windowing\', \'cw_len\')\n options.cw_shift=Config.get(\'windowing\', \'cw_shift\')\n\n #[cnn]\n options.cnn_N_filt=Config.get(\'cnn\', \'cnn_N_filt\')\n options.cnn_len_filt=Config.get(\'cnn\', \'cnn_len_filt\')\n options.cnn_max_pool_len=Config.get(\'cnn\', \'cnn_max_pool_len\')\n options.cnn_use_laynorm_inp=Config.get(\'cnn\', \'cnn_use_laynorm_inp\')\n options.cnn_use_batchnorm_inp=Config.get(\'cnn\', \'cnn_use_batchnorm_inp\')\n options.cnn_use_laynorm=Config.get(\'cnn\', \'cnn_use_laynorm\')\n options.cnn_use_batchnorm=Config.get(\'cnn\', \'cnn_use_batchnorm\')\n options.cnn_act=Config.get(\'cnn\', \'cnn_act\')\n options.cnn_drop=Config.get(\'cnn\', \'cnn_drop\')\n\n\n #[dnn]\n options.fc_lay=Config.get(\'dnn\', \'fc_lay\')\n options.fc_drop=Config.get(\'dnn\', \'fc_drop\')\n options.fc_use_laynorm_inp=Config.get(\'dnn\', \'fc_use_laynorm_inp\')\n options.fc_use_batchnorm_inp=Config.get(\'dnn\', \'fc_use_batchnorm_inp\')\n options.fc_use_batchnorm=Config.get(\'dnn\', \'fc_use_batchnorm\')\n options.fc_use_laynorm=Config.get(\'dnn\', \'fc_use_laynorm\')\n options.fc_act=Config.get(\'dnn\', \'fc_act\')\n\n #[class]\n options.class_lay=Config.get(\'class\', \'class_lay\')\n options.class_drop=Config.get(\'class\', \'class_drop\')\n options.class_use_laynorm_inp=Config.get(\'class\', \'class_use_laynorm_inp\')\n options.class_use_batchnorm_inp=Config.get(\'class\', \'class_use_batchnorm_inp\')\n options.class_use_batchnorm=Config.get(\'class\', \'class_use_batchnorm\')\n options.class_use_laynorm=Config.get(\'class\', \'class_use_laynorm\')\n options.class_act=Config.get(\'class\', \'class_act\')\n\n\n #[optimization]\n options.lr=Config.get(\'optimization\', \'lr\')\n options.batch_size=Config.get(\'optimization\', \'batch_size\')\n options.N_epochs=Config.get(\'optimization\', \'N_epochs\')\n options.N_batches=Config.get(\'optimization\', \'N_batches\')\n options.N_eval_epoch=Config.get(\'optimization\', \'N_eval_epoch\')\n options.seed=Config.get(\'optimization\', \'seed\')\n \n return options\n\n\ndef str_to_bool(s):\n    if s == \'True\':\n         return True\n    elif s == \'False\':\n         return False\n    else:\n         raise ValueError \n         \n         \ndef create_batches_rnd(batch_size,data_folder,wav_lst,N_snt,wlen,lab_dict,fact_amp):\n    \n # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n sig_batch=np.zeros([batch_size,wlen])\n lab_batch=np.zeros(batch_size)\n  \n snt_id_arr=np.random.randint(N_snt, size=batch_size)\n \n rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n\n for i in range(batch_size):\n     \n  # select a random sentence from the list  (joint distribution)\n  [fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst[snt_id_arr[i]])\n  signal=signal.astype(float)/32768\n\n  # accesing to a random chunk\n  snt_len=signal.shape[0]\n  snt_beg=np.random.randint(snt_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n  snt_end=snt_beg+wlen\n  \n  sig_batch[i,:]=signal[snt_beg:snt_end]*rand_amp_arr[i]\n  lab_batch[i]=lab_dict[wav_lst[snt_id_arr[i]]]\n  \n inp=torch.from_numpy(sig_batch).float().cuda().contiguous()  # Current Frame\n lab=torch.from_numpy(lab_batch).float().cuda().contiguous()\n  \n return inp,lab  \n\n\n\ndef read_conf_inp(cfg_file):\n \n parser=OptionParser()\n (options,args)=parser.parse_args()\n \n Config = ConfigParser.ConfigParser()\n Config.read(cfg_file)\n\n #[data]\n options.tr_lst=Config.get(\'data\', \'tr_lst\')\n options.te_lst=Config.get(\'data\', \'te_lst\')\n options.lab_dict=Config.get(\'data\', \'lab_dict\')\n options.data_folder=Config.get(\'data\', \'data_folder\')\n options.output_folder=Config.get(\'data\', \'output_folder\')\n options.pt_file=Config.get(\'data\', \'pt_file\')\n\n #[windowing]\n options.fs=Config.get(\'windowing\', \'fs\')\n options.cw_len=Config.get(\'windowing\', \'cw_len\')\n options.cw_shift=Config.get(\'windowing\', \'cw_shift\')\n\n #[cnn]\n options.cnn_N_filt=Config.get(\'cnn\', \'cnn_N_filt\')\n options.cnn_len_filt=Config.get(\'cnn\', \'cnn_len_filt\')\n options.cnn_max_pool_len=Config.get(\'cnn\', \'cnn_max_pool_len\')\n options.cnn_use_laynorm_inp=Config.get(\'cnn\', \'cnn_use_laynorm_inp\')\n options.cnn_use_batchnorm_inp=Config.get(\'cnn\', \'cnn_use_batchnorm_inp\')\n options.cnn_use_laynorm=Config.get(\'cnn\', \'cnn_use_laynorm\')\n options.cnn_use_batchnorm=Config.get(\'cnn\', \'cnn_use_batchnorm\')\n options.cnn_act=Config.get(\'cnn\', \'cnn_act\')\n options.cnn_drop=Config.get(\'cnn\', \'cnn_drop\')\n\n\n #[dnn]\n options.fc_lay=Config.get(\'dnn\', \'fc_lay\')\n options.fc_drop=Config.get(\'dnn\', \'fc_drop\')\n options.fc_use_laynorm_inp=Config.get(\'dnn\', \'fc_use_laynorm_inp\')\n options.fc_use_batchnorm_inp=Config.get(\'dnn\', \'fc_use_batchnorm_inp\')\n options.fc_use_batchnorm=Config.get(\'dnn\', \'fc_use_batchnorm\')\n options.fc_use_laynorm=Config.get(\'dnn\', \'fc_use_laynorm\')\n options.fc_act=Config.get(\'dnn\', \'fc_act\')\n\n #[class]\n options.class_lay=Config.get(\'class\', \'class_lay\')\n options.class_drop=Config.get(\'class\', \'class_drop\')\n options.class_use_laynorm_inp=Config.get(\'class\', \'class_use_laynorm_inp\')\n options.class_use_batchnorm_inp=Config.get(\'class\', \'class_use_batchnorm_inp\')\n options.class_use_batchnorm=Config.get(\'class\', \'class_use_batchnorm\')\n options.class_use_laynorm=Config.get(\'class\', \'class_use_laynorm\')\n options.class_act=Config.get(\'class\', \'class_act\')\n\n\n #[optimization]\n options.lr=Config.get(\'optimization\', \'lr\')\n options.batch_size=Config.get(\'optimization\', \'batch_size\')\n options.N_epochs=Config.get(\'optimization\', \'N_epochs\')\n options.N_batches=Config.get(\'optimization\', \'N_batches\')\n options.N_eval_epoch=Config.get(\'optimization\', \'N_eval_epoch\')\n options.seed=Config.get(\'optimization\', \'seed\')\n \n return options'"
dnn_models.py,36,"b'import numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport sys\nfrom torch.autograd import Variable\nimport math\n\ndef flip(x, dim):\n    xsize = x.size()\n    dim = x.dim() + dim if dim < 0 else dim\n    x = x.contiguous()\n    x = x.view(-1, *xsize[dim:])\n    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1, \n                      -1, -1), (\'cpu\',\'cuda\')[x.is_cuda])().long(), :]\n    return x.view(xsize)\n\n\ndef sinc(band,t_right):\n    y_right= torch.sin(2*math.pi*band*t_right)/(2*math.pi*band*t_right)\n    y_left= flip(y_right,0)\n\n    y=torch.cat([y_left,Variable(torch.ones(1)).cuda(),y_right])\n\n    return y\n    \n\nclass SincConv_fast(nn.Module):\n    """"""Sinc-based convolution\n    Parameters\n    ----------\n    in_channels : `int`\n        Number of input channels. Must be 1.\n    out_channels : `int`\n        Number of filters.\n    kernel_size : `int`\n        Filter length.\n    sample_rate : `int`, optional\n        Sample rate. Defaults to 16000.\n    Usage\n    -----\n    See `torch.nn.Conv1d`\n    Reference\n    ---------\n    Mirco Ravanelli, Yoshua Bengio,\n    ""Speaker Recognition from raw waveform with SincNet"".\n    https://arxiv.org/abs/1808.00158\n    """"""\n\n    @staticmethod\n    def to_mel(hz):\n        return 2595 * np.log10(1 + hz / 700)\n\n    @staticmethod\n    def to_hz(mel):\n        return 700 * (10 ** (mel / 2595) - 1)\n\n    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50):\n\n        super(SincConv_fast,self).__init__()\n\n        if in_channels != 1:\n            #msg = (f\'SincConv only support one input channel \'\n            #       f\'(here, in_channels = {in_channels:d}).\')\n            msg = ""SincConv only support one input channel (here, in_channels = {%i})"" % (in_channels)\n            raise ValueError(msg)\n\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        \n        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n        if kernel_size%2==0:\n            self.kernel_size=self.kernel_size+1\n            \n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n\n        if bias:\n            raise ValueError(\'SincConv does not support bias.\')\n        if groups > 1:\n            raise ValueError(\'SincConv does not support groups.\')\n\n        self.sample_rate = sample_rate\n        self.min_low_hz = min_low_hz\n        self.min_band_hz = min_band_hz\n\n        # initialize filterbanks such that they are equally spaced in Mel scale\n        low_hz = 30\n        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n\n        mel = np.linspace(self.to_mel(low_hz),\n                          self.to_mel(high_hz),\n                          self.out_channels + 1)\n        hz = self.to_hz(mel)\n        \n\n        # filter lower frequency (out_channels, 1)\n        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n\n        # filter frequency band (out_channels, 1)\n        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n\n        # Hamming window\n        #self.window_ = torch.hamming_window(self.kernel_size)\n        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\n\n\n        # (1, kernel_size/2)\n        n = (self.kernel_size - 1) / 2.0\n        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n\n \n\n\n    def forward(self, waveforms):\n        """"""\n        Parameters\n        ----------\n        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\n            Batch of waveforms.\n        Returns\n        -------\n        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\n            Batch of sinc filters activations.\n        """"""\n\n        self.n_ = self.n_.to(waveforms.device)\n\n        self.window_ = self.window_.to(waveforms.device)\n\n        low = self.min_low_hz  + torch.abs(self.low_hz_)\n        \n        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\n        band=(high-low)[:,0]\n        \n        f_times_t_low = torch.matmul(low, self.n_)\n        f_times_t_high = torch.matmul(high, self.n_)\n\n        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \n        band_pass_center = 2*band.view(-1,1)\n        band_pass_right= torch.flip(band_pass_left,dims=[1])\n        \n        \n        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\n\n        \n        band_pass = band_pass / (2*band[:,None])\n        \n\n        self.filters = (band_pass).view(\n            self.out_channels, 1, self.kernel_size)\n\n        return F.conv1d(waveforms, self.filters, stride=self.stride,\n                        padding=self.padding, dilation=self.dilation,\n                         bias=None, groups=1) \n\n\n        \n        \nclass sinc_conv(nn.Module):\n\n    def __init__(self, N_filt,Filt_dim,fs):\n        super(sinc_conv,self).__init__()\n\n        # Mel Initialization of the filterbanks\n        low_freq_mel = 80\n        high_freq_mel = (2595 * np.log10(1 + (fs / 2) / 700))  # Convert Hz to Mel\n        mel_points = np.linspace(low_freq_mel, high_freq_mel, N_filt)  # Equally spaced in Mel scale\n        f_cos = (700 * (10**(mel_points / 2595) - 1)) # Convert Mel to Hz\n        b1=np.roll(f_cos,1)\n        b2=np.roll(f_cos,-1)\n        b1[0]=30\n        b2[-1]=(fs/2)-100\n                \n        self.freq_scale=fs*1.0\n        self.filt_b1 = nn.Parameter(torch.from_numpy(b1/self.freq_scale))\n        self.filt_band = nn.Parameter(torch.from_numpy((b2-b1)/self.freq_scale))\n\n        \n        self.N_filt=N_filt\n        self.Filt_dim=Filt_dim\n        self.fs=fs\n        \n\n    def forward(self, x):\n        \n        filters=Variable(torch.zeros((self.N_filt,self.Filt_dim))).cuda()\n        N=self.Filt_dim\n        t_right=Variable(torch.linspace(1, (N-1)/2, steps=int((N-1)/2))/self.fs).cuda()\n        \n        \n        min_freq=50.0;\n        min_band=50.0;\n        \n        filt_beg_freq=torch.abs(self.filt_b1)+min_freq/self.freq_scale\n        filt_end_freq=filt_beg_freq+(torch.abs(self.filt_band)+min_band/self.freq_scale)\n       \n        n=torch.linspace(0, N, steps=N)\n\n        # Filter window (hamming)\n        window=0.54-0.46*torch.cos(2*math.pi*n/N);\n        window=Variable(window.float().cuda())\n\n        \n        for i in range(self.N_filt):\n                        \n            low_pass1 = 2*filt_beg_freq[i].float()*sinc(filt_beg_freq[i].float()*self.freq_scale,t_right)\n            low_pass2 = 2*filt_end_freq[i].float()*sinc(filt_end_freq[i].float()*self.freq_scale,t_right)\n            band_pass=(low_pass2-low_pass1)\n\n            band_pass=band_pass/torch.max(band_pass)\n\n            filters[i,:]=band_pass.cuda()*window\n\n        out=F.conv1d(x, filters.view(self.N_filt,1,self.Filt_dim))\n    \n        return out\n    \n\ndef act_fun(act_type):\n\n if act_type==""relu"":\n    return nn.ReLU()\n            \n if act_type==""tanh"":\n    return nn.Tanh()\n            \n if act_type==""sigmoid"":\n    return nn.Sigmoid()\n           \n if act_type==""leaky_relu"":\n    return nn.LeakyReLU(0.2)\n            \n if act_type==""elu"":\n    return nn.ELU()\n                     \n if act_type==""softmax"":\n    return nn.LogSoftmax(dim=1)\n        \n if act_type==""linear"":\n    return nn.LeakyReLU(1) # initializzed like this, but not used in forward!\n            \n            \nclass LayerNorm(nn.Module):\n\n    def __init__(self, features, eps=1e-6):\n        super(LayerNorm,self).__init__()\n        self.gamma = nn.Parameter(torch.ones(features))\n        self.beta = nn.Parameter(torch.zeros(features))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n\n\nclass MLP(nn.Module):\n    def __init__(self, options):\n        super(MLP, self).__init__()\n        \n        self.input_dim=int(options[\'input_dim\'])\n        self.fc_lay=options[\'fc_lay\']\n        self.fc_drop=options[\'fc_drop\']\n        self.fc_use_batchnorm=options[\'fc_use_batchnorm\']\n        self.fc_use_laynorm=options[\'fc_use_laynorm\']\n        self.fc_use_laynorm_inp=options[\'fc_use_laynorm_inp\']\n        self.fc_use_batchnorm_inp=options[\'fc_use_batchnorm_inp\']\n        self.fc_act=options[\'fc_act\']\n        \n       \n        self.wx  = nn.ModuleList([])\n        self.bn  = nn.ModuleList([])\n        self.ln  = nn.ModuleList([])\n        self.act = nn.ModuleList([])\n        self.drop = nn.ModuleList([])\n       \n\n       \n        # input layer normalization\n        if self.fc_use_laynorm_inp:\n           self.ln0=LayerNorm(self.input_dim)\n          \n        # input batch normalization    \n        if self.fc_use_batchnorm_inp:\n           self.bn0=nn.BatchNorm1d([self.input_dim],momentum=0.05)\n           \n           \n        self.N_fc_lay=len(self.fc_lay)\n             \n        current_input=self.input_dim\n        \n        # Initialization of hidden layers\n        \n        for i in range(self.N_fc_lay):\n            \n         # dropout\n         self.drop.append(nn.Dropout(p=self.fc_drop[i]))\n         \n         # activation\n         self.act.append(act_fun(self.fc_act[i]))\n         \n         \n         add_bias=True\n         \n         # layer norm initialization\n         self.ln.append(LayerNorm(self.fc_lay[i]))\n         self.bn.append(nn.BatchNorm1d(self.fc_lay[i],momentum=0.05))\n         \n         if self.fc_use_laynorm[i] or self.fc_use_batchnorm[i]:\n             add_bias=False\n         \n              \n         # Linear operations\n         self.wx.append(nn.Linear(current_input, self.fc_lay[i],bias=add_bias))\n         \n         # weight initialization\n         self.wx[i].weight = torch.nn.Parameter(torch.Tensor(self.fc_lay[i],current_input).uniform_(-np.sqrt(0.01/(current_input+self.fc_lay[i])),np.sqrt(0.01/(current_input+self.fc_lay[i]))))\n         self.wx[i].bias = torch.nn.Parameter(torch.zeros(self.fc_lay[i]))\n         \n         current_input=self.fc_lay[i]\n         \n         \n    def forward(self, x):\n        \n      # Applying Layer/Batch Norm\n      if bool(self.fc_use_laynorm_inp):\n        x=self.ln0((x))\n        \n      if bool(self.fc_use_batchnorm_inp):\n        x=self.bn0((x))\n        \n      for i in range(self.N_fc_lay):\n\n        if self.fc_act[i]!=\'linear\':\n            \n          if self.fc_use_laynorm[i]:\n           x = self.drop[i](self.act[i](self.ln[i](self.wx[i](x))))\n          \n          if self.fc_use_batchnorm[i]:\n           x = self.drop[i](self.act[i](self.bn[i](self.wx[i](x))))\n          \n          if self.fc_use_batchnorm[i]==False and self.fc_use_laynorm[i]==False:\n           x = self.drop[i](self.act[i](self.wx[i](x)))\n           \n        else:\n          if self.fc_use_laynorm[i]:\n           x = self.drop[i](self.ln[i](self.wx[i](x)))\n          \n          if self.fc_use_batchnorm[i]:\n           x = self.drop[i](self.bn[i](self.wx[i](x)))\n          \n          if self.fc_use_batchnorm[i]==False and self.fc_use_laynorm[i]==False:\n           x = self.drop[i](self.wx[i](x)) \n          \n      return x\n\n\n\nclass SincNet(nn.Module):\n    \n    def __init__(self,options):\n       super(SincNet,self).__init__()\n    \n       self.cnn_N_filt=options[\'cnn_N_filt\']\n       self.cnn_len_filt=options[\'cnn_len_filt\']\n       self.cnn_max_pool_len=options[\'cnn_max_pool_len\']\n       \n       \n       self.cnn_act=options[\'cnn_act\']\n       self.cnn_drop=options[\'cnn_drop\']\n       \n       self.cnn_use_laynorm=options[\'cnn_use_laynorm\']\n       self.cnn_use_batchnorm=options[\'cnn_use_batchnorm\']\n       self.cnn_use_laynorm_inp=options[\'cnn_use_laynorm_inp\']\n       self.cnn_use_batchnorm_inp=options[\'cnn_use_batchnorm_inp\']\n       \n       self.input_dim=int(options[\'input_dim\'])\n       \n       self.fs=options[\'fs\']\n       \n       self.N_cnn_lay=len(options[\'cnn_N_filt\'])\n       self.conv  = nn.ModuleList([])\n       self.bn  = nn.ModuleList([])\n       self.ln  = nn.ModuleList([])\n       self.act = nn.ModuleList([])\n       self.drop = nn.ModuleList([])\n       \n             \n       if self.cnn_use_laynorm_inp:\n           self.ln0=LayerNorm(self.input_dim)\n           \n       if self.cnn_use_batchnorm_inp:\n           self.bn0=nn.BatchNorm1d([self.input_dim],momentum=0.05)\n           \n       current_input=self.input_dim \n       \n       for i in range(self.N_cnn_lay):\n         \n         N_filt=int(self.cnn_N_filt[i])\n         len_filt=int(self.cnn_len_filt[i])\n         \n         # dropout\n         self.drop.append(nn.Dropout(p=self.cnn_drop[i]))\n         \n         # activation\n         self.act.append(act_fun(self.cnn_act[i]))\n                    \n         # layer norm initialization         \n         self.ln.append(LayerNorm([N_filt,int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i])]))\n\n         self.bn.append(nn.BatchNorm1d(N_filt,int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i]),momentum=0.05))\n            \n\n         if i==0:\n          self.conv.append(SincConv_fast(self.cnn_N_filt[0],self.cnn_len_filt[0],self.fs))\n              \n         else:\n          self.conv.append(nn.Conv1d(self.cnn_N_filt[i-1], self.cnn_N_filt[i], self.cnn_len_filt[i]))\n          \n         current_input=int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i])\n\n         \n       self.out_dim=current_input*N_filt\n\n\n\n    def forward(self, x):\n       batch=x.shape[0]\n       seq_len=x.shape[1]\n       \n       if bool(self.cnn_use_laynorm_inp):\n        x=self.ln0((x))\n        \n       if bool(self.cnn_use_batchnorm_inp):\n        x=self.bn0((x))\n        \n       x=x.view(batch,1,seq_len)\n\n       \n       for i in range(self.N_cnn_lay):\n           \n         if self.cnn_use_laynorm[i]:\n          if i==0:\n           x = self.drop[i](self.act[i](self.ln[i](F.max_pool1d(torch.abs(self.conv[i](x)), self.cnn_max_pool_len[i]))))  \n          else:\n           x = self.drop[i](self.act[i](self.ln[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i]))))   \n          \n         if self.cnn_use_batchnorm[i]:\n          x = self.drop[i](self.act[i](self.bn[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i]))))\n\n         if self.cnn_use_batchnorm[i]==False and self.cnn_use_laynorm[i]==False:\n          x = self.drop[i](self.act[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i])))\n\n       \n       x = x.view(batch,-1)\n\n       return x\n   \n\n    \n   \n'"
speaker_id.py,20,"b'# speaker_id.py\n# Mirco Ravanelli \n# Mila - University of Montreal \n\n# July 2018\n\n# Description: \n# This code performs a speaker_id experiments with SincNet.\n \n# How to run it:\n# python speaker_id.py --cfg=cfg/SincNet_TIMIT.cfg\n\nimport os\n#import scipy.io.wavfile\nimport soundfile as sf\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nimport sys\nimport numpy as np\nfrom dnn_models import MLP,flip\nfrom dnn_models import SincNet as CNN \nfrom data_io import ReadList,read_conf,str_to_bool\n\n\ndef create_batches_rnd(batch_size,data_folder,wav_lst,N_snt,wlen,lab_dict,fact_amp):\n    \n # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n sig_batch=np.zeros([batch_size,wlen])\n lab_batch=np.zeros(batch_size)\n  \n snt_id_arr=np.random.randint(N_snt, size=batch_size)\n \n rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n\n for i in range(batch_size):\n     \n  # select a random sentence from the list \n  #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst[snt_id_arr[i]])\n  #signal=signal.astype(float)/32768\n\n  [signal, fs] = sf.read(data_folder+wav_lst[snt_id_arr[i]])\n\n  # accesing to a random chunk\n  snt_len=signal.shape[0]\n  snt_beg=np.random.randint(snt_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n  snt_end=snt_beg+wlen\n\n  channels = len(signal.shape)\n  if channels == 2:\n    print(\'WARNING: stereo to mono: \'+data_folder+wav_lst[snt_id_arr[i]])\n    signal = signal[:,0]\n  \n  sig_batch[i,:]=signal[snt_beg:snt_end]*rand_amp_arr[i]\n  lab_batch[i]=lab_dict[wav_lst[snt_id_arr[i]]]\n  \n inp=Variable(torch.from_numpy(sig_batch).float().cuda().contiguous())\n lab=Variable(torch.from_numpy(lab_batch).float().cuda().contiguous())\n  \n return inp,lab  \n\n\n\n# Reading cfg file\noptions=read_conf()\n\n#[data]\ntr_lst=options.tr_lst\nte_lst=options.te_lst\npt_file=options.pt_file\nclass_dict_file=options.lab_dict\ndata_folder=options.data_folder+\'/\'\noutput_folder=options.output_folder\n\n#[windowing]\nfs=int(options.fs)\ncw_len=int(options.cw_len)\ncw_shift=int(options.cw_shift)\n\n#[cnn]\ncnn_N_filt=list(map(int, options.cnn_N_filt.split(\',\')))\ncnn_len_filt=list(map(int, options.cnn_len_filt.split(\',\')))\ncnn_max_pool_len=list(map(int, options.cnn_max_pool_len.split(\',\')))\ncnn_use_laynorm_inp=str_to_bool(options.cnn_use_laynorm_inp)\ncnn_use_batchnorm_inp=str_to_bool(options.cnn_use_batchnorm_inp)\ncnn_use_laynorm=list(map(str_to_bool, options.cnn_use_laynorm.split(\',\')))\ncnn_use_batchnorm=list(map(str_to_bool, options.cnn_use_batchnorm.split(\',\')))\ncnn_act=list(map(str, options.cnn_act.split(\',\')))\ncnn_drop=list(map(float, options.cnn_drop.split(\',\')))\n\n\n#[dnn]\nfc_lay=list(map(int, options.fc_lay.split(\',\')))\nfc_drop=list(map(float, options.fc_drop.split(\',\')))\nfc_use_laynorm_inp=str_to_bool(options.fc_use_laynorm_inp)\nfc_use_batchnorm_inp=str_to_bool(options.fc_use_batchnorm_inp)\nfc_use_batchnorm=list(map(str_to_bool, options.fc_use_batchnorm.split(\',\')))\nfc_use_laynorm=list(map(str_to_bool, options.fc_use_laynorm.split(\',\')))\nfc_act=list(map(str, options.fc_act.split(\',\')))\n\n#[class]\nclass_lay=list(map(int, options.class_lay.split(\',\')))\nclass_drop=list(map(float, options.class_drop.split(\',\')))\nclass_use_laynorm_inp=str_to_bool(options.class_use_laynorm_inp)\nclass_use_batchnorm_inp=str_to_bool(options.class_use_batchnorm_inp)\nclass_use_batchnorm=list(map(str_to_bool, options.class_use_batchnorm.split(\',\')))\nclass_use_laynorm=list(map(str_to_bool, options.class_use_laynorm.split(\',\')))\nclass_act=list(map(str, options.class_act.split(\',\')))\n\n\n#[optimization]\nlr=float(options.lr)\nbatch_size=int(options.batch_size)\nN_epochs=int(options.N_epochs)\nN_batches=int(options.N_batches)\nN_eval_epoch=int(options.N_eval_epoch)\nseed=int(options.seed)\n\n\n# training list\nwav_lst_tr=ReadList(tr_lst)\nsnt_tr=len(wav_lst_tr)\n\n# test list\nwav_lst_te=ReadList(te_lst)\nsnt_te=len(wav_lst_te)\n\n\n# Folder creation\ntry:\n    os.stat(output_folder)\nexcept:\n    os.mkdir(output_folder) \n    \n    \n# setting seed\ntorch.manual_seed(seed)\nnp.random.seed(seed)\n\n# loss function\ncost = nn.NLLLoss()\n\n  \n# Converting context and shift in samples\nwlen=int(fs*cw_len/1000.00)\nwshift=int(fs*cw_shift/1000.00)\n\n# Batch_dev\nBatch_dev=128\n\n\n# Feature extractor CNN\nCNN_arch = {\'input_dim\': wlen,\n          \'fs\': fs,\n          \'cnn_N_filt\': cnn_N_filt,\n          \'cnn_len_filt\': cnn_len_filt,\n          \'cnn_max_pool_len\':cnn_max_pool_len,\n          \'cnn_use_laynorm_inp\': cnn_use_laynorm_inp,\n          \'cnn_use_batchnorm_inp\': cnn_use_batchnorm_inp,\n          \'cnn_use_laynorm\':cnn_use_laynorm,\n          \'cnn_use_batchnorm\':cnn_use_batchnorm,\n          \'cnn_act\': cnn_act,\n          \'cnn_drop\':cnn_drop,          \n          }\n\nCNN_net=CNN(CNN_arch)\nCNN_net.cuda()\n\n# Loading label dictionary\nlab_dict=np.load(class_dict_file).item()\n\n\n\nDNN1_arch = {\'input_dim\': CNN_net.out_dim,\n          \'fc_lay\': fc_lay,\n          \'fc_drop\': fc_drop, \n          \'fc_use_batchnorm\': fc_use_batchnorm,\n          \'fc_use_laynorm\': fc_use_laynorm,\n          \'fc_use_laynorm_inp\': fc_use_laynorm_inp,\n          \'fc_use_batchnorm_inp\':fc_use_batchnorm_inp,\n          \'fc_act\': fc_act,\n          }\n\nDNN1_net=MLP(DNN1_arch)\nDNN1_net.cuda()\n\n\nDNN2_arch = {\'input_dim\':fc_lay[-1] ,\n          \'fc_lay\': class_lay,\n          \'fc_drop\': class_drop, \n          \'fc_use_batchnorm\': class_use_batchnorm,\n          \'fc_use_laynorm\': class_use_laynorm,\n          \'fc_use_laynorm_inp\': class_use_laynorm_inp,\n          \'fc_use_batchnorm_inp\':class_use_batchnorm_inp,\n          \'fc_act\': class_act,\n          }\n\n\nDNN2_net=MLP(DNN2_arch)\nDNN2_net.cuda()\n\n\nif pt_file!=\'none\':\n   checkpoint_load = torch.load(pt_file)\n   CNN_net.load_state_dict(checkpoint_load[\'CNN_model_par\'])\n   DNN1_net.load_state_dict(checkpoint_load[\'DNN1_model_par\'])\n   DNN2_net.load_state_dict(checkpoint_load[\'DNN2_model_par\'])\n\n\n\noptimizer_CNN = optim.RMSprop(CNN_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \noptimizer_DNN1 = optim.RMSprop(DNN1_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \noptimizer_DNN2 = optim.RMSprop(DNN2_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \n\n\n\nfor epoch in range(N_epochs):\n  \n  test_flag=0\n  CNN_net.train()\n  DNN1_net.train()\n  DNN2_net.train()\n \n  loss_sum=0\n  err_sum=0\n\n  for i in range(N_batches):\n\n    [inp,lab]=create_batches_rnd(batch_size,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict,0.2)\n    pout=DNN2_net(DNN1_net(CNN_net(inp)))\n    \n    pred=torch.max(pout,dim=1)[1]\n    loss = cost(pout, lab.long())\n    err = torch.mean((pred!=lab.long()).float())\n    \n   \n    \n    optimizer_CNN.zero_grad()\n    optimizer_DNN1.zero_grad() \n    optimizer_DNN2.zero_grad() \n    \n    loss.backward()\n    optimizer_CNN.step()\n    optimizer_DNN1.step()\n    optimizer_DNN2.step()\n    \n    loss_sum=loss_sum+loss.detach()\n    err_sum=err_sum+err.detach()\n \n\n  loss_tot=loss_sum/N_batches\n  err_tot=err_sum/N_batches\n  \n \n   \n   \n# Full Validation  new  \n  if epoch%N_eval_epoch==0:\n      \n   CNN_net.eval()\n   DNN1_net.eval()\n   DNN2_net.eval()\n   test_flag=1 \n   loss_sum=0\n   err_sum=0\n   err_sum_snt=0\n   \n   with torch.no_grad():  \n    for i in range(snt_te):\n       \n     #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst_te[i])\n     #signal=signal.astype(float)/32768\n\n     [signal, fs] = sf.read(data_folder+wav_lst_te[i])\n\n     signal=torch.from_numpy(signal).float().cuda().contiguous()\n     lab_batch=lab_dict[wav_lst_te[i]]\n    \n     # split signals into chunks\n     beg_samp=0\n     end_samp=wlen\n     \n     N_fr=int((signal.shape[0]-wlen)/(wshift))\n     \n\n     sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n     lab= Variable((torch.zeros(N_fr+1)+lab_batch).cuda().contiguous().long())\n     pout=Variable(torch.zeros(N_fr+1,class_lay[-1]).float().cuda().contiguous())\n     count_fr=0\n     count_fr_tot=0\n     while end_samp<signal.shape[0]:\n         sig_arr[count_fr,:]=signal[beg_samp:end_samp]\n         beg_samp=beg_samp+wshift\n         end_samp=beg_samp+wlen\n         count_fr=count_fr+1\n         count_fr_tot=count_fr_tot+1\n         if count_fr==Batch_dev:\n             inp=Variable(sig_arr)\n             pout[count_fr_tot-Batch_dev:count_fr_tot,:]=DNN2_net(DNN1_net(CNN_net(inp)))\n             count_fr=0\n             sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n   \n     if count_fr>0:\n      inp=Variable(sig_arr[0:count_fr])\n      pout[count_fr_tot-count_fr:count_fr_tot,:]=DNN2_net(DNN1_net(CNN_net(inp)))\n\n    \n     pred=torch.max(pout,dim=1)[1]\n     loss = cost(pout, lab.long())\n     err = torch.mean((pred!=lab.long()).float())\n    \n     [val,best_class]=torch.max(torch.sum(pout,dim=0),0)\n     err_sum_snt=err_sum_snt+(best_class!=lab[0]).float()\n    \n    \n     loss_sum=loss_sum+loss.detach()\n     err_sum=err_sum+err.detach()\n    \n    err_tot_dev_snt=err_sum_snt/snt_te\n    loss_tot_dev=loss_sum/snt_te\n    err_tot_dev=err_sum/snt_te\n\n  \n   print(""epoch %i, loss_tr=%f err_tr=%f loss_te=%f err_te=%f err_te_snt=%f"" % (epoch, loss_tot,err_tot,loss_tot_dev,err_tot_dev,err_tot_dev_snt))\n  \n   with open(output_folder+""/res.res"", ""a"") as res_file:\n    res_file.write(""epoch %i, loss_tr=%f err_tr=%f loss_te=%f err_te=%f err_te_snt=%f\\n"" % (epoch, loss_tot,err_tot,loss_tot_dev,err_tot_dev,err_tot_dev_snt))   \n\n   checkpoint={\'CNN_model_par\': CNN_net.state_dict(),\n               \'DNN1_model_par\': DNN1_net.state_dict(),\n               \'DNN2_model_par\': DNN2_net.state_dict(),\n               }\n   torch.save(checkpoint,output_folder+\'/model_raw.pkl\')\n  \n  else:\n   print(""epoch %i, loss_tr=%f err_tr=%f"" % (epoch, loss_tot,err_tot))\n\n\n'"
