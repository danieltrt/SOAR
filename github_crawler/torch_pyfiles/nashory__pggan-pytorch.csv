file_path,api_count,code
config.py,0,"b'"""""" config.py\n""""""\nimport argparse\nimport time\n\nparser = argparse.ArgumentParser(\'PGGAN\')\n\n## general settings.\nparser.add_argument(\'--train_data_root\', type=str, default=\'/homes/user/Desktop/YOUR_DIRECTORY\')\nparser.add_argument(\'--random_seed\', type=int, default=int(time.time()))\nparser.add_argument(\'--n_gpu\', type=int, default=1)             # for Multi-GPU training.\n\n## training parameters.\nparser.add_argument(\'--lr\', type=float, default=0.001)          # learning rate.\nparser.add_argument(\'--lr_decay\', type=float, default=0.87)     # learning rate decay at every resolution transition.\nparser.add_argument(\'--eps_drift\', type=float, default=0.001)   # coeff for the drift loss.\nparser.add_argument(\'--smoothing\', type=float, default=0.997)   # smoothing factor for smoothed generator.\nparser.add_argument(\'--nc\', type=int, default=3)                # number of input channel.\nparser.add_argument(\'--nz\', type=int, default=512)              # input dimension of noise.\nparser.add_argument(\'--ngf\', type=int, default=512)             # feature dimension of final layer of generator.\nparser.add_argument(\'--ndf\', type=int, default=512)             # feature dimension of first layer of discriminator.\nparser.add_argument(\'--TICK\', type=int, default=1000)           # 1 tick = 1000 images = (1000/batch_size) iter.\nparser.add_argument(\'--max_resl\', type=int, default=8)          # 10-->1024, 9-->512, 8-->256\nparser.add_argument(\'--trns_tick\', type=int, default=200)       # transition tick\nparser.add_argument(\'--stab_tick\', type=int, default=100)       # stabilization tick\n\n\n## network structure.\nparser.add_argument(\'--flag_wn\', type=bool, default=True)           # use of equalized-learning rate.\nparser.add_argument(\'--flag_bn\', type=bool, default=False)          # use of batch-normalization. (not recommended)\nparser.add_argument(\'--flag_pixelwise\', type=bool, default=True)    # use of pixelwise normalization for generator.\nparser.add_argument(\'--flag_gdrop\', type=bool, default=True)        # use of generalized dropout layer for discriminator.\nparser.add_argument(\'--flag_leaky\', type=bool, default=True)        # use of leaky relu instead of relu.\nparser.add_argument(\'--flag_tanh\', type=bool, default=False)        # use of tanh at the end of the generator.\nparser.add_argument(\'--flag_sigmoid\', type=bool, default=False)     # use of sigmoid at the end of the discriminator.\nparser.add_argument(\'--flag_add_noise\', type=bool, default=True)    # add noise to the real image(x)\nparser.add_argument(\'--flag_norm_latent\', type=bool, default=False) # pixelwise normalization of latent vector (z)\nparser.add_argument(\'--flag_add_drift\', type=bool, default=True)   # add drift loss\n\n\n\n\n## optimizer setting.\nparser.add_argument(\'--optimizer\', type=str, default=\'adam\')        # optimizer type.\nparser.add_argument(\'--beta1\', type=float, default=0.0)             # beta1 for adam.\nparser.add_argument(\'--beta2\', type=float, default=0.99)            # beta2 for adam.\n\n\n## display and save setting.\nparser.add_argument(\'--use_tb\', type=bool, default=True)            # enable tensorboard visualization\nparser.add_argument(\'--save_img_every\', type=int, default=20)       # save images every specified iteration.\nparser.add_argument(\'--display_tb_every\', type=int, default=5)      # display progress every specified iteration.\n\n\n## parse and save config.\nconfig, _ = parser.parse_known_args()\n'"
custom_layers.py,22,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.autograd import Variable\nimport torch \nimport torch.nn as nn\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport copy\nfrom torch.nn.init import kaiming_normal, calculate_gain\n\n# same function as ConcatTable container in Torch7.\nclass ConcatTable(nn.Module):\n    def __init__(self, layer1, layer2):\n        super(ConcatTable, self).__init__()\n        self.layer1 = layer1\n        self.layer2 = layer2\n        \n    def forward(self,x):\n        y = [self.layer1(x), self.layer2(x)]\n        return y\n\nclass Flatten(nn.Module):\n    def __init__(self):\n        super(Flatten, self).__init__()\n\n    def forward(self, x):\n        return x.view(x.size(0), -1)\n\n\n\nclass fadein_layer(nn.Module):\n    def __init__(self, config):\n        super(fadein_layer, self).__init__()\n        self.alpha = 0.0\n\n    def update_alpha(self, delta):\n        self.alpha = self.alpha + delta\n        self.alpha = max(0, min(self.alpha, 1.0))\n\n    # input : [x_low, x_high] from ConcatTable()\n    def forward(self, x):\n        return torch.add(x[0].mul(1.0-self.alpha), x[1].mul(self.alpha))\n\n\n\n# https://github.com/github-pengge/PyTorch-progressive_growing_of_gans/blob/master/models/base_model.py\nclass minibatch_std_concat_layer(nn.Module):\n    def __init__(self, averaging='all'):\n        super(minibatch_std_concat_layer, self).__init__()\n        self.averaging = averaging.lower()\n        if 'group' in self.averaging:\n            self.n = int(self.averaging[5:])\n        else:\n            assert self.averaging in ['all', 'flat', 'spatial', 'none', 'gpool'], 'Invalid averaging mode'%self.averaging\n        self.adjusted_std = lambda x, **kwargs: torch.sqrt(torch.mean((x - torch.mean(x, **kwargs)) ** 2, **kwargs) + 1e-8)\n\n    def forward(self, x):\n        shape = list(x.size())\n        target_shape = copy.deepcopy(shape)\n        vals = self.adjusted_std(x, dim=0, keepdim=True)\n        if self.averaging == 'all':\n            target_shape[1] = 1\n            vals = torch.mean(vals, dim=1, keepdim=True)\n        elif self.averaging == 'spatial':\n            if len(shape) == 4:\n                vals = mean(vals, axis=[2,3], keepdim=True)             # torch.mean(torch.mean(vals, 2, keepdim=True), 3, keepdim=True)\n        elif self.averaging == 'none':\n            target_shape = [target_shape[0]] + [s for s in target_shape[1:]]\n        elif self.averaging == 'gpool':\n            if len(shape) == 4:\n                vals = mean(x, [0,2,3], keepdim=True)                   # torch.mean(torch.mean(torch.mean(x, 2, keepdim=True), 3, keepdim=True), 0, keepdim=True)\n        elif self.averaging == 'flat':\n            target_shape[1] = 1\n            vals = torch.FloatTensor([self.adjusted_std(x)])\n        else:                                                           # self.averaging == 'group'\n            target_shape[1] = self.n\n            vals = vals.view(self.n, self.shape[1]/self.n, self.shape[2], self.shape[3])\n            vals = mean(vals, axis=0, keepdim=True).view(1, self.n, 1, 1)\n        vals = vals.expand(*target_shape)\n        return torch.cat([x, vals], 1)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(averaging = %s)' % (self.averaging)\n\n\nclass pixelwise_norm_layer(nn.Module):\n    def __init__(self):\n        super(pixelwise_norm_layer, self).__init__()\n        self.eps = 1e-8\n\n    def forward(self, x):\n        return x / (torch.mean(x**2, dim=1, keepdim=True) + self.eps) ** 0.5\n\n\n# for equaliaeed-learning rate.\nclass equalized_conv2d(nn.Module):\n    def __init__(self, c_in, c_out, k_size, stride, pad, initializer='kaiming', bias=False):\n        super(equalized_conv2d, self).__init__()\n        self.conv = nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False)\n        if initializer == 'kaiming':    kaiming_normal(self.conv.weight, a=calculate_gain('conv2d'))\n        elif initializer == 'xavier':   xavier_normal(self.conv.weight)\n        \n        conv_w = self.conv.weight.data.clone()\n        self.bias = torch.nn.Parameter(torch.FloatTensor(c_out).fill_(0))\n        self.scale = (torch.mean(self.conv.weight.data ** 2)) ** 0.5\n        self.conv.weight.data.copy_(self.conv.weight.data/self.scale)\n\n    def forward(self, x):\n        x = self.conv(x.mul(self.scale))\n        return x + self.bias.view(1,-1,1,1).expand_as(x)\n        \n \nclass equalized_deconv2d(nn.Module):\n    def __init__(self, c_in, c_out, k_size, stride, pad, initializer='kaiming'):\n        super(equalized_deconv2d, self).__init__()\n        self.deconv = nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False)\n        if initializer == 'kaiming':    kaiming_normal(self.deconv.weight, a=calculate_gain('conv2d'))\n        elif initializer == 'xavier':   xavier_normal(self.deconv.weight)\n        \n        deconv_w = self.deconv.weight.data.clone()\n        self.bias = torch.nn.Parameter(torch.FloatTensor(c_out).fill_(0))\n        self.scale = (torch.mean(self.deconv.weight.data ** 2)) ** 0.5\n        self.deconv.weight.data.copy_(self.deconv.weight.data/self.scale)\n    def forward(self, x):\n        x = self.deconv(x.mul(self.scale))\n        return x + self.bias.view(1,-1,1,1).expand_as(x)\n\n\nclass equalized_linear(nn.Module):\n    def __init__(self, c_in, c_out, initializer='kaiming'):\n        super(equalized_linear, self).__init__()\n        self.linear = nn.Linear(c_in, c_out, bias=False)\n        if initializer == 'kaiming':    kaiming_normal(self.linear.weight, a=calculate_gain('linear'))\n        elif initializer == 'xavier':   torch.nn.init.xavier_normal(self.linear.weight)\n        \n        linear_w = self.linear.weight.data.clone()\n        self.bias = torch.nn.Parameter(torch.FloatTensor(c_out).fill_(0))\n        self.scale = (torch.mean(self.linear.weight.data ** 2)) ** 0.5\n        self.linear.weight.data.copy_(self.linear.weight.data/self.scale)\n        \n    def forward(self, x):\n        x = self.linear(x.mul(self.scale))\n        return x + self.bias.view(1,-1).expand_as(x)\n\n\n# ref: https://github.com/github-pengge/PyTorch-progressive_growing_of_gans/blob/master/models/base_model.py\nclass generalized_drop_out(nn.Module):\n    def __init__(self, mode='mul', strength=0.4, axes=(0,1), normalize=False):\n        super(generalized_drop_out, self).__init__()\n        self.mode = mode.lower()\n        assert self.mode in ['mul', 'drop', 'prop'], 'Invalid GDropLayer mode'%mode\n        self.strength = strength\n        self.axes = [axes] if isinstance(axes, int) else list(axes)\n        self.normalize = normalize\n        self.gain = None\n\n    def forward(self, x, deterministic=False):\n        if deterministic or not self.strength:\n            return x\n\n        rnd_shape = [s if axis in self.axes else 1 for axis, s in enumerate(x.size())]  # [x.size(axis) for axis in self.axes]\n        if self.mode == 'drop':\n            p = 1 - self.strength\n            rnd = np.random.binomial(1, p=p, size=rnd_shape) / p\n        elif self.mode == 'mul':\n            rnd = (1 + self.strength) ** np.random.normal(size=rnd_shape)\n        else:\n            coef = self.strength * x.size(1) ** 0.5\n            rnd = np.random.normal(size=rnd_shape) * coef + 1\n\n        if self.normalize:\n            rnd = rnd / np.linalg.norm(rnd, keepdims=True)\n        rnd = Variable(torch.from_numpy(rnd).type(x.data.type()))\n        if x.is_cuda:\n            rnd = rnd.cuda()\n        return x * rnd\n\n    def __repr__(self):\n        param_str = '(mode = %s, strength = %s, axes = %s, normalize = %s)' % (self.mode, self.strength, self.axes, self.normalize)\n        return self.__class__.__name__ + param_str\n\n\n\n"""
dataloader.py,2,"b""import os\nimport torch as torch\nimport numpy as np\nfrom io import BytesIO\nimport scipy.misc\n#import tensorflow as tf\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torch.autograd import Variable\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n\n\nclass dataloader:\n    def __init__(self, config):\n        self.root = config.train_data_root\n        self.batch_table = {4:32, 8:32, 16:32, 32:16, 64:16, 128:16, 256:12, 512:3, 1024:1} # change this according to available gpu memory.\n        self.batchsize = int(self.batch_table[pow(2,2)])        # we start from 2^2=4\n        self.imsize = int(pow(2,2))\n        self.num_workers = 4\n        \n    def renew(self, resl):\n        print('[*] Renew dataloader configuration, load data from {}.'.format(self.root))\n        \n        self.batchsize = int(self.batch_table[pow(2,resl)])\n        self.imsize = int(pow(2,resl))\n        self.dataset = ImageFolder(\n                    root=self.root,\n                    transform=transforms.Compose(   [\n                                                    transforms.Resize(size=(self.imsize,self.imsize), interpolation=Image.NEAREST),\n                                                    transforms.ToTensor(),\n                                                    ]))\n\n        self.dataloader = DataLoader(\n            dataset=self.dataset,\n            batch_size=self.batchsize,\n            shuffle=True,\n            num_workers=self.num_workers\n        )\n\n    def __iter__(self):\n        return iter(self.dataloader)\n    \n    def __next__(self):\n        return next(self.dataloader)\n\n    def __len__(self):\n        return len(self.dataloader.dataset)\n\n       \n    def get_batch(self):\n        dataIter = iter(self.dataloader)\n        return next(dataIter)[0].mul(2).add(-1)         # pixel range [-1, 1]\n\n\n        \n\n\n\n\n\n\n\n\n"""
generate_interpolated.py,8,"b""# generate interpolated images.\n\n\nimport os,sys\nimport torch\nfrom config import config\nfrom torch.autograd import Variable\nimport utils as utils\n\n\nuse_cuda = True\ncheckpoint_path = 'repo/model/gen_R8_T55.pth.tar'\nn_intp = 20\n\n# load trained model.\nimport network as net\ntest_model = net.Generator(config)\nif use_cuda:\n    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n    test_model = torch.nn.DataParallel(test_model).cuda(device=0)\nelse:\n    torch.set_default_tensor_type('torch.FloatTensor')\n\nfor resl in range(3, config.max_resl+1):\n    test_model.module.grow_network(resl)\n    test_model.module.flush_network()\nprint(test_model)\n\nprint('load checkpoint form ... {}'.format(checkpoint_path))\ncheckpoint = torch.load(checkpoint_path)\ntest_model.module.load_state_dict(checkpoint['state_dict'])\n\n# create folder.\nfor i in range(1000):\n    name = 'repo/interpolation/try_{}'.format(i)\n    if not os.path.exists(name):\n        os.system('mkdir -p {}'.format(name))\n        break;\n\n# interpolate between twe noise(z1, z2).\nz_intp = torch.FloatTensor(1, config.nz)\nz1 = torch.FloatTensor(1, config.nz).normal_(0.0, 1.0)\nz2 = torch.FloatTensor(1, config.nz).normal_(0.0, 1.0)\nif use_cuda:\n    z_intp = z_intp.cuda()\n    z1 = z1.cuda()\n    z2 = z2.cuda()\n    test_model = test_model.cuda()\n\nz_intp = Variable(z_intp)\n\nfor i in range(1, n_intp+1):\n    alpha = 1.0/float(n_intp+1)\n    z_intp.data = z1.mul_(alpha) + z2.mul_(1.0-alpha)\n    fake_im = test_model.module(z_intp)\n    fname = os.path.join(name, '_intp{}.jpg'.format(i))\n    utils.save_image_single(fake_im.data, fname, imsize=pow(2,config.max_resl))\n    print('saved {}-th interpolated image ...'.format(i))\n\n\n"""
network.py,3,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.autograd import Variable\nfrom custom_layers import *\nimport copy\n\n\n# defined for code simplicity.\ndef deconv(layers, c_in, c_out, k_size, stride=1, pad=0, leaky=True, bn=False, wn=False, pixel=False, only=False):\n    if wn:  layers.append(equalized_conv2d(c_in, c_out, k_size, stride, pad))\n    else:   layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad))\n    if not only:\n        if leaky:   layers.append(nn.LeakyReLU(0.2))\n        else:       layers.append(nn.ReLU())\n        if bn:      layers.append(nn.BatchNorm2d(c_out))\n        if pixel:   layers.append(pixelwise_norm_layer())\n    return layers\n\ndef conv(layers, c_in, c_out, k_size, stride=1, pad=0, leaky=True, bn=False, wn=False, pixel=False, gdrop=True, only=False):\n    if gdrop:       layers.append(generalized_drop_out(mode='prop', strength=0.0))\n    if wn:          layers.append(equalized_conv2d(c_in, c_out, k_size, stride, pad, initializer='kaiming'))\n    else:           layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad))\n    if not only:\n        if leaky:   layers.append(nn.LeakyReLU(0.2))\n        else:       layers.append(nn.ReLU())\n        if bn:      layers.append(nn.BatchNorm2d(c_out))\n        if pixel:   layers.append(pixelwise_norm_layer())\n    return layers\n\ndef linear(layers, c_in, c_out, sig=True, wn=False):\n    layers.append(Flatten())\n    if wn:      layers.append(equalized_linear(c_in, c_out))\n    else:       layers.append(Linear(c_in, c_out))\n    if sig:     layers.append(nn.Sigmoid())\n    return layers\n\n    \ndef deepcopy_module(module, target):\n    new_module = nn.Sequential()\n    for name, m in module.named_children():\n        if name == target:\n            new_module.add_module(name, m)                          # make new structure and,\n            new_module[-1].load_state_dict(m.state_dict())         # copy weights\n    return new_module\n\ndef soft_copy_param(target_link, source_link, tau):\n    ''' soft-copy parameters of a link to another link. '''\n    target_params = dict(target_link.named_parameters())\n    for param_name, param in source_link.named_parameters():\n        target_params[param_name].data = target_params[param_name].data.mul(1.0-tau)\n        target_params[param_name].data = target_params[param_name].data.add(param.data.mul(tau))\n\ndef get_module_names(model):\n    names = []\n    for key, val in model.state_dict().iteritems():\n        name = key.split('.')[0]\n        if not name in names:\n            names.append(name)\n    return names\n\n\nclass Generator(nn.Module):\n    def __init__(self, config):\n        super(Generator, self).__init__()\n        self.config = config\n        self.flag_bn = config.flag_bn\n        self.flag_pixelwise = config.flag_pixelwise\n        self.flag_wn = config.flag_wn\n        self.flag_leaky = config.flag_leaky\n        self.flag_tanh = config.flag_tanh\n        self.flag_norm_latent = config.flag_norm_latent\n        self.nc = config.nc\n        self.nz = config.nz\n        self.ngf = config.ngf\n        self.layer_name = None\n        self.module_names = []\n        self.model = self.get_init_gen()\n\n    def first_block(self):\n        layers = []\n        ndim = self.ngf\n        if self.flag_norm_latent:\n            layers.append(pixelwise_norm_layer())\n        layers = deconv(layers, self.nz, ndim, 4, 1, 3, self.flag_leaky, self.flag_bn, self.flag_wn, self.flag_pixelwise)\n        layers = deconv(layers, ndim, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, self.flag_pixelwise)\n        return  nn.Sequential(*layers), ndim\n\n    def intermediate_block(self, resl):\n        halving = False\n        layer_name = 'intermediate_{}x{}_{}x{}'.format(int(pow(2,resl-1)), int(pow(2,resl-1)), int(pow(2, resl)), int(pow(2, resl)))\n        ndim = self.ngf\n        if resl==3 or resl==4 or resl==5:\n            halving = False\n            ndim = self.ngf\n        elif resl==6 or resl==7 or resl==8 or resl==9 or resl==10:\n            halving = True\n            for i in range(int(resl)-5):\n                ndim = ndim/2\n        ndim = int(ndim)\n        layers = []\n        layers.append(nn.Upsample(scale_factor=2, mode='nearest'))       # scale up by factor of 2.0\n        if halving:\n            layers = deconv(layers, ndim*2, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, self.flag_pixelwise)\n            layers = deconv(layers, ndim, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, self.flag_pixelwise)\n        else:\n            layers = deconv(layers, ndim, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, self.flag_pixelwise)\n            layers = deconv(layers, ndim, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, self.flag_pixelwise)\n        return  nn.Sequential(*layers), ndim, layer_name\n    \n    def to_rgb_block(self, c_in):\n        layers = []\n        layers = deconv(layers, c_in, self.nc, 1, 1, 0, self.flag_leaky, self.flag_bn, self.flag_wn, self.flag_pixelwise, only=True)\n        if self.flag_tanh:  layers.append(nn.Tanh())\n        return nn.Sequential(*layers)\n\n    def get_init_gen(self):\n        model = nn.Sequential()\n        first_block, ndim = self.first_block()\n        model.add_module('first_block', first_block)\n        model.add_module('to_rgb_block', self.to_rgb_block(ndim))\n        self.module_names = get_module_names(model)\n        return model\n    \n    def grow_network(self, resl):\n        # we make new network since pytorch does not support remove_module()\n        new_model = nn.Sequential()\n        names = get_module_names(self.model)\n        for name, module in self.model.named_children():\n            if not name=='to_rgb_block':\n                new_model.add_module(name, module)                      # make new structure and,\n                new_model[-1].load_state_dict(module.state_dict())      # copy pretrained weights\n            \n        if resl >= 3 and resl <= 9:\n            print('growing network[{}x{} to {}x{}]. It may take few seconds...'.format(int(pow(2,resl-1)), int(pow(2,resl-1)), int(pow(2,resl)), int(pow(2,resl))))\n            low_resl_to_rgb = deepcopy_module(self.model, 'to_rgb_block')\n            prev_block = nn.Sequential()\n            prev_block.add_module('low_resl_upsample', nn.Upsample(scale_factor=2, mode='nearest'))\n            prev_block.add_module('low_resl_to_rgb', low_resl_to_rgb)\n\n            inter_block, ndim, self.layer_name = self.intermediate_block(resl)\n            next_block = nn.Sequential()\n            next_block.add_module('high_resl_block', inter_block)\n            next_block.add_module('high_resl_to_rgb', self.to_rgb_block(ndim))\n\n            new_model.add_module('concat_block', ConcatTable(prev_block, next_block))\n            new_model.add_module('fadein_block', fadein_layer(self.config))\n            self.model = None\n            self.model = new_model\n            self.module_names = get_module_names(self.model)\n           \n    def flush_network(self):\n        try:\n            print('flushing network... It may take few seconds...')\n            # make deep copy and paste.\n            high_resl_block = deepcopy_module(self.model.concat_block.layer2, 'high_resl_block')\n            high_resl_to_rgb = deepcopy_module(self.model.concat_block.layer2, 'high_resl_to_rgb')\n           \n            new_model = nn.Sequential()\n            for name, module in self.model.named_children():\n                if name!='concat_block' and name!='fadein_block':\n                    new_model.add_module(name, module)                      # make new structure and,\n                    new_model[-1].load_state_dict(module.state_dict())      # copy pretrained weights\n\n            # now, add the high resolution block.\n            new_model.add_module(self.layer_name, high_resl_block)\n            new_model.add_module('to_rgb_block', high_resl_to_rgb)\n            self.model = new_model\n            self.module_names = get_module_names(self.model)\n        except:\n            self.model = self.model\n\n    def freeze_layers(self):\n        # let's freeze pretrained blocks. (Found freezing layers not helpful, so did not use this func.)\n        print('freeze pretrained weights ... ')\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        x = self.model(x.view(x.size(0), -1, 1, 1))\n        return x\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, config):\n        super(Discriminator, self).__init__()\n        self.config = config\n        self.flag_bn = config.flag_bn\n        self.flag_pixelwise = config.flag_pixelwise\n        self.flag_wn = config.flag_wn\n        self.flag_leaky = config.flag_leaky\n        self.flag_sigmoid = config.flag_sigmoid\n        self.nz = config.nz\n        self.nc = config.nc\n        self.ndf = config.ndf\n        self.layer_name = None\n        self.module_names = []\n        self.model = self.get_init_dis()\n\n    def last_block(self):\n        # add minibatch_std_concat_layer later.\n        ndim = self.ndf\n        layers = []\n        layers.append(minibatch_std_concat_layer())\n        layers = conv(layers, ndim+1, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, pixel=False)\n        layers = conv(layers, ndim, ndim, 4, 1, 0, self.flag_leaky, self.flag_bn, self.flag_wn, pixel=False)\n        layers = linear(layers, ndim, 1, sig=self.flag_sigmoid, wn=self.flag_wn)\n        return  nn.Sequential(*layers), ndim\n    \n    def intermediate_block(self, resl):\n        halving = False\n        layer_name = 'intermediate_{}x{}_{}x{}'.format(int(pow(2,resl)), int(pow(2,resl)), int(pow(2, resl-1)), int(pow(2, resl-1)))\n        ndim = self.ndf\n        if resl==3 or resl==4 or resl==5:\n            halving = False\n            ndim = self.ndf\n        elif resl==6 or resl==7 or resl==8 or resl==9 or resl==10:\n            halving = True\n            for i in range(int(resl)-5):\n                ndim = ndim/2\n        ndim = int(ndim)\n        layers = []\n        if halving:\n            layers = conv(layers, ndim, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, pixel=False)\n            layers = conv(layers, ndim, ndim*2, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, pixel=False)\n        else:\n            layers = conv(layers, ndim, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, pixel=False)\n            layers = conv(layers, ndim, ndim, 3, 1, 1, self.flag_leaky, self.flag_bn, self.flag_wn, pixel=False)\n        \n        layers.append(nn.AvgPool2d(kernel_size=2))       # scale up by factor of 2.0\n        return  nn.Sequential(*layers), ndim, layer_name\n    \n    def from_rgb_block(self, ndim):\n        layers = []\n        layers = conv(layers, self.nc, ndim, 1, 1, 0, self.flag_leaky, self.flag_bn, self.flag_wn, pixel=False)\n        return  nn.Sequential(*layers)\n    \n    def get_init_dis(self):\n        model = nn.Sequential()\n        last_block, ndim = self.last_block()\n        model.add_module('from_rgb_block', self.from_rgb_block(ndim))\n        model.add_module('last_block', last_block)\n        self.module_names = get_module_names(model)\n        return model\n    \n\n    def grow_network(self, resl):\n            \n        if resl >= 3 and resl <= 9:\n            print('growing network[{}x{} to {}x{}]. It may take few seconds...'.format(int(pow(2,resl-1)), int(pow(2,resl-1)), int(pow(2,resl)), int(pow(2,resl))))\n            low_resl_from_rgb = deepcopy_module(self.model, 'from_rgb_block')\n            prev_block = nn.Sequential()\n            prev_block.add_module('low_resl_downsample', nn.AvgPool2d(kernel_size=2))\n            prev_block.add_module('low_resl_from_rgb', low_resl_from_rgb)\n\n            inter_block, ndim, self.layer_name = self.intermediate_block(resl)\n            next_block = nn.Sequential()\n            next_block.add_module('high_resl_from_rgb', self.from_rgb_block(ndim))\n            next_block.add_module('high_resl_block', inter_block)\n\n            new_model = nn.Sequential()\n            new_model.add_module('concat_block', ConcatTable(prev_block, next_block))\n            new_model.add_module('fadein_block', fadein_layer(self.config))\n\n            # we make new network since pytorch does not support remove_module()\n            names = get_module_names(self.model)\n            for name, module in self.model.named_children():\n                if not name=='from_rgb_block':\n                    new_model.add_module(name, module)                      # make new structure and,\n                    new_model[-1].load_state_dict(module.state_dict())      # copy pretrained weights\n            self.model = None\n            self.model = new_model\n            self.module_names = get_module_names(self.model)\n\n    def flush_network(self):\n        try:\n            print('flushing network... It may take few seconds...')\n            # make deep copy and paste.\n            high_resl_block = deepcopy_module(self.model.concat_block.layer2, 'high_resl_block')\n            high_resl_from_rgb = deepcopy_module(self.model.concat_block.layer2, 'high_resl_from_rgb')\n           \n            # add the high resolution block.\n            new_model = nn.Sequential()\n            new_model.add_module('from_rgb_block', high_resl_from_rgb)\n            new_model.add_module(self.layer_name, high_resl_block)\n            \n            # add rest.\n            for name, module in self.model.named_children():\n                if name!='concat_block' and name!='fadein_block':\n                    new_model.add_module(name, module)                      # make new structure and,\n                    new_model[-1].load_state_dict(module.state_dict())      # copy pretrained weights\n\n            self.model = new_model\n            self.module_names = get_module_names(self.model)\n        except:\n            self.model = self.model\n    \n    def freeze_layers(self):\n        # let's freeze pretrained blocks. (Found freezing layers not helpful, so did not use this func.)\n        print('freeze pretrained weights ... ')\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n \n\n\n\n\n\n\n\n\n"""
tf_recorder.py,7,"b'import torch\nimport torchvision.utils as vutils\nimport numpy as np\nimport torchvision.models as models\nimport utils as utils\nfrom torchvision import datasets\nfrom tensorboardX import SummaryWriter\nimport os, sys\nimport utils as utils\n\n\nclass tf_recorder:\n    def __init__(self):\n        utils.mkdir(\'repo/tensorboard\')\n        \n        for i in range(1000):\n            self.targ = \'repo/tensorboard/try_{}\'.format(i)\n            if not os.path.exists(self.targ):\n                self.writer = SummaryWriter(self.targ)\n                break\n                \n    def add_scalar(self, index, val, niter):\n        self.writer.add_scalar(index, val, niter)\n\n    def add_scalars(self, index, group_dict, niter):\n        self.writer.add_scalar(index, group_dict, niter)\n\n    def add_image_grid(self, index, ngrid, x, niter):\n        grid = utils.make_image_grid(x, ngrid)\n        self.writer.add_image(index, grid, niter)\n\n    def add_image_single(self, index, x, niter):\n        self.writer.add_image(index, x, niter)\n\n    def add_graph(self, index, x_input, model):\n        torch.onnx.export(model, x_input, os.path.join(self.targ, ""{}.proto"".format(index)), verbose=True)\n        self.writer.add_graph_onnx(os.path.join(self.targ, ""{}.proto"".format(index)))\n\n    def export_json(self, out_file):\n        self.writer.export_scalars_to_json(out_file)\n\n\n\n\n\n\n\n\n\'\'\'\nresnet18 = models.resnet18(False)\nwriter = SummaryWriter()\nfor n_iter in range(100):\n    s1 = torch.rand(1) # value to keep\n    s2 = torch.rand(1)\n    writer.add_scalar(\'data/scalar1\', s1[0], n_iter) #data grouping by `slash`\n    writer.add_scalar(\'data/scalar2\', s2[0], n_iter)\n    writer.add_scalars(\'data/scalar_group\', {""xsinx"":n_iter*np.sin(n_iter),\n                                             ""xcosx"":n_iter*np.cos(n_iter),\n                                             ""arctanx"": np.arctan(n_iter)}, n_iter)\ndataset = datasets.MNIST(\'mnist\', train=False, download=True)\nimages = dataset.test_data[:100].float()\nlabel = dataset.test_labels[:100]\nfeatures = images.view(100, 784)\nwriter.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))\n\n# export scalar data to JSON for external processing\nwriter.export_scalars_to_json(""./all_scalars.json"")\nwriter.close()\n\'\'\'\n\n\n\n\'\'\'\nresnet18 = models.resnet18(False)\nwriter = SummaryWriter()\nsample_rate = 44100\nfreqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]\n\nfor n_iter in range(100):\n    s1 = torch.rand(1) # value to keep\n    s2 = torch.rand(1)\n    writer.add_scalar(\'data/scalar1\', s1[0], n_iter) #data grouping by `slash`\n    writer.add_scalar(\'data/scalar2\', s2[0], n_iter)\n    writer.add_scalars(\'data/scalar_group\', {""xsinx"":n_iter*np.sin(n_iter),\n                                             ""xcosx"":n_iter*np.cos(n_iter),\n                                             ""arctanx"": np.arctan(n_iter)}, n_iter)\n    x = torch.rand(32, 3, 64, 64) # output from network\n    if n_iter%10==0:\n        x = vutils.make_grid(x, normalize=True, scale_each=True)\n        writer.add_image(\'Image\', x, n_iter)\n        x = torch.zeros(sample_rate*2)\n        for i in range(x.size(0)):\n            x[i] = np.cos(freqs[n_iter//10]*np.pi*float(i)/float(sample_rate)) # sound amplitude should in [-1, 1]\n        writer.add_text(\'Text\', \'text logged at step:\'+str(n_iter), n_iter)\n        for name, param in resnet18.named_parameters():\n            writer.add_histogram(name, param.clone().cpu().data.numpy(), n_iter)\n        writer.add_pr_curve(\'xoxo\', np.random.randint(2, size=100), np.random.rand(100), n_iter) #needs tensorboard 0.4RC or later\ndataset = datasets.MNIST(\'mnist\', train=False, download=True)\nimages = dataset.test_data[:100].float()\nlabel = dataset.test_labels[:100]\nfeatures = images.view(100, 784)\nwriter.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))\n\n# export scalar data to JSON for external processing\nwriter.export_scalars_to_json(""./all_scalars.json"")\n\nwriter.close()\n\'\'\'\n\n'"
trainer.py,26,"b""import dataloader as DL\nfrom config import config\nimport network as net\nfrom math import floor, ceil\nimport os, sys\nimport torch\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport tf_recorder as tensorboard\nimport utils as utils\nimport numpy as np\n# import tensorflow as tf\n\nclass trainer:\n    def __init__(self, config):\n        self.config = config\n        if torch.cuda.is_available():\n            self.use_cuda = True\n            torch.set_default_tensor_type('torch.cuda.FloatTensor')\n        else:\n            self.use_cuda = False\n            torch.set_default_tensor_type('torch.FloatTensor')\n        \n        self.nz = config.nz\n        self.optimizer = config.optimizer\n\n        self.resl = 2           # we start from 2^2 = 4\n        self.lr = config.lr\n        self.eps_drift = config.eps_drift\n        self.smoothing = config.smoothing\n        self.max_resl = config.max_resl\n        self.trns_tick = config.trns_tick\n        self.stab_tick = config.stab_tick\n        self.TICK = config.TICK\n        self.globalIter = 0\n        self.globalTick = 0\n        self.kimgs = 0\n        self.stack = 0\n        self.epoch = 0\n        self.fadein = {'gen':None, 'dis':None}\n        self.complete = {'gen':0, 'dis':0}\n        self.phase = 'init'\n        self.flag_flush_gen = False\n        self.flag_flush_dis = False\n        self.flag_add_noise = self.config.flag_add_noise\n        self.flag_add_drift = self.config.flag_add_drift\n        \n        # network and cirterion\n        self.G = net.Generator(config)\n        self.D = net.Discriminator(config)\n        print ('Generator structure: ')\n        print(self.G.model)\n        print ('Discriminator structure: ')\n        print(self.D.model)\n        self.mse = torch.nn.MSELoss()\n        if self.use_cuda:\n            self.mse = self.mse.cuda()\n            torch.cuda.manual_seed(config.random_seed)\n            if config.n_gpu==1:\n                self.G = torch.nn.DataParallel(self.G).cuda(device=0)\n                self.D = torch.nn.DataParallel(self.D).cuda(device=0)\n            else:\n                gpus = []\n                for i  in range(config.n_gpu):\n                    gpus.append(i)\n                self.G = torch.nn.DataParallel(self.G, device_ids=gpus).cuda()\n                self.D = torch.nn.DataParallel(self.D, device_ids=gpus).cuda()  \n\n        \n        # define tensors, ship model to cuda, and get dataloader.\n        self.renew_everything()\n        \n        # tensorboard\n        self.use_tb = config.use_tb\n        if self.use_tb:\n            self.tb = tensorboard.tf_recorder()\n        \n\n    def resl_scheduler(self):\n        '''\n        this function will schedule image resolution(self.resl) progressively.\n        it should be called every iteration to ensure resl value is updated properly.\n        step 1. (trns_tick) --> transition in generator.\n        step 2. (stab_tick) --> stabilize.\n        step 3. (trns_tick) --> transition in discriminator.\n        step 4. (stab_tick) --> stabilize.\n        '''\n        if floor(self.resl) != 2 :\n            self.trns_tick = self.config.trns_tick\n            self.stab_tick = self.config.stab_tick\n        \n        self.batchsize = self.loader.batchsize\n        delta = 1.0/(2*self.trns_tick+2*self.stab_tick)\n        d_alpha = 1.0*self.batchsize/self.trns_tick/self.TICK\n\n        # update alpha if fade-in layer exist.\n        if self.fadein['gen'] is not None:\n            if self.resl%1.0 < (self.trns_tick)*delta:\n                self.fadein['gen'].update_alpha(d_alpha)\n                self.complete['gen'] = self.fadein['gen'].alpha*100\n                self.phase = 'gtrns'\n            elif self.resl%1.0 >= (self.trns_tick)*delta and self.resl%1.0 < (self.trns_tick+self.stab_tick)*delta:\n                self.phase = 'gstab'\n        if self.fadein['dis'] is not None:\n            if self.resl%1.0 >= (self.trns_tick+self.stab_tick)*delta and self.resl%1.0 < (self.stab_tick + self.trns_tick*2)*delta:\n                self.fadein['dis'].update_alpha(d_alpha)\n                self.complete['dis'] = self.fadein['dis'].alpha*100\n                self.phase = 'dtrns'\n            elif self.resl%1.0 >= (self.stab_tick + self.trns_tick*2)*delta and self.phase!='final':\n                self.phase = 'dstab'\n            \n        prev_kimgs = self.kimgs\n        self.kimgs = self.kimgs + self.batchsize\n        if (self.kimgs%self.TICK) < (prev_kimgs%self.TICK):\n            self.globalTick = self.globalTick + 1\n            # increase linearly every tick, and grow network structure.\n            prev_resl = floor(self.resl)\n            self.resl = self.resl + delta\n            self.resl = max(2, min(10.5, self.resl))        # clamping, range: 4 ~ 1024\n\n            # flush network.\n            if self.flag_flush_gen and self.resl%1.0 >= (self.trns_tick+self.stab_tick)*delta and prev_resl!=2:\n                if self.fadein['gen'] is not None:\n                    self.fadein['gen'].update_alpha(d_alpha)\n                    self.complete['gen'] = self.fadein['gen'].alpha*100\n                self.flag_flush_gen = False\n                self.G.module.flush_network()   # flush G\n                print(self.G.module.model)\n                #self.Gs.module.flush_network()         # flush Gs\n                self.fadein['gen'] = None\n                self.complete['gen'] = 0.0\n                self.phase = 'dtrns'\n            elif self.flag_flush_dis and floor(self.resl) != prev_resl and prev_resl!=2:\n                if self.fadein['dis'] is not None:\n                    self.fadein['dis'].update_alpha(d_alpha)\n                    self.complete['dis'] = self.fadein['dis'].alpha*100\n                self.flag_flush_dis = False\n                self.D.module.flush_network()   # flush and,\n                print(self.D.module.model)\n                self.fadein['dis'] = None\n                self.complete['dis'] = 0.0\n                if floor(self.resl) < self.max_resl and self.phase != 'final':\n                    self.phase = 'gtrns'\n\n            # grow network.\n            if floor(self.resl) != prev_resl and floor(self.resl)<self.max_resl+1:\n                self.lr = self.lr * float(self.config.lr_decay)\n                self.G.grow_network(floor(self.resl))\n                #self.Gs.grow_network(floor(self.resl))\n                self.D.grow_network(floor(self.resl))\n                self.renew_everything()\n                self.fadein['gen'] = dict(self.G.model.named_children())['fadein_block']\n                self.fadein['dis'] = dict(self.D.model.named_children())['fadein_block']\n                self.flag_flush_gen = True\n                self.flag_flush_dis = True\n\n            if floor(self.resl) >= self.max_resl and self.resl%1.0 >= (self.stab_tick + self.trns_tick*2)*delta:\n                self.phase = 'final'\n                self.resl = self.max_resl + (self.stab_tick + self.trns_tick*2)*delta\n\n\n            \n    def renew_everything(self):\n        # renew dataloader.\n        self.loader = DL.dataloader(config)\n        self.loader.renew(min(floor(self.resl), self.max_resl))\n        \n        # define tensors\n        self.z = torch.FloatTensor(self.loader.batchsize, self.nz)\n        self.x = torch.FloatTensor(self.loader.batchsize, 3, self.loader.imsize, self.loader.imsize)\n        self.x_tilde = torch.FloatTensor(self.loader.batchsize, 3, self.loader.imsize, self.loader.imsize)\n        self.real_label = torch.FloatTensor(self.loader.batchsize).fill_(1)\n        self.fake_label = torch.FloatTensor(self.loader.batchsize).fill_(0)\n\t\t\n        # enable cuda\n        if self.use_cuda:\n            self.z = self.z.cuda()\n            self.x = self.x.cuda()\n            self.x_tilde = self.x.cuda()\n            self.real_label = self.real_label.cuda()\n            self.fake_label = self.fake_label.cuda()\n            torch.cuda.manual_seed(config.random_seed)\n\n        # wrapping autograd Variable.\n        self.x = Variable(self.x)\n        self.x_tilde = Variable(self.x_tilde)\n        self.z = Variable(self.z)\n        self.real_label = Variable(self.real_label)\n        self.fake_label = Variable(self.fake_label)\n        \n        # ship new model to cuda.\n        if self.use_cuda:\n            self.G = self.G.cuda()\n            self.D = self.D.cuda()\n        \n        # optimizer\n        betas = (self.config.beta1, self.config.beta2)\n        if self.optimizer == 'adam':\n            self.opt_g = Adam(filter(lambda p: p.requires_grad, self.G.parameters()), lr=self.lr, betas=betas, weight_decay=0.0)\n            self.opt_d = Adam(filter(lambda p: p.requires_grad, self.D.parameters()), lr=self.lr, betas=betas, weight_decay=0.0)\n        \n\n    def feed_interpolated_input(self, x):\n        if self.phase == 'gtrns' and floor(self.resl)>2 and floor(self.resl)<=self.max_resl:\n            alpha = self.complete['gen']/100.0\n            transform = transforms.Compose( [   transforms.ToPILImage(),\n                                                transforms.Scale(size=int(pow(2,floor(self.resl)-1)), interpolation=0),      # 0: nearest\n                                                transforms.Scale(size=int(pow(2,floor(self.resl))), interpolation=0),      # 0: nearest\n                                                transforms.ToTensor(),\n                                            ] )\n            x_low = x.clone().add(1).mul(0.5)\n            for i in range(x_low.size(0)):\n                x_low[i] = transform(x_low[i]).mul(2).add(-1)\n            x = torch.add(x.mul(alpha), x_low.mul(1-alpha)) # interpolated_x\n\n        if self.use_cuda:\n            return x.cuda()\n        else:\n            return x\n\n    def add_noise(self, x):\n        # TODO: support more method of adding noise.\n        if self.flag_add_noise==False:\n            return x\n\n        if hasattr(self, '_d_'):\n            self._d_ = self._d_ * 0.9 + torch.mean(self.fx_tilde).item() * 0.1\n        else:\n            self._d_ = 0.0\n        strength = 0.2 * max(0, self._d_ - 0.5)**2\n        z = np.random.randn(*x.size()).astype(np.float32) * strength\n        z = Variable(torch.from_numpy(z)).cuda() if self.use_cuda else Variable(torch.from_numpy(z))\n        return x + z\n\n    def train(self):\n        # noise for test.\n        self.z_test = torch.FloatTensor(self.loader.batchsize, self.nz)\n        if self.use_cuda:\n            self.z_test = self.z_test.cuda()\n        self.z_test = Variable(self.z_test, volatile=True)\n        self.z_test.data.resize_(self.loader.batchsize, self.nz).normal_(0.0, 1.0)\n        \n        for step in range(2, self.max_resl+1+5):\n            for iter in tqdm(range(0,(self.trns_tick*2+self.stab_tick*2)*self.TICK, self.loader.batchsize)):\n                self.globalIter = self.globalIter+1\n                self.stack = self.stack + self.loader.batchsize\n                if self.stack > ceil(len(self.loader.dataset)):\n                    self.epoch = self.epoch + 1\n                    self.stack = int(self.stack%(ceil(len(self.loader.dataset))))\n\n                # reslolution scheduler.\n                self.resl_scheduler()\n                \n                # zero gradients.\n                self.G.zero_grad()\n                self.D.zero_grad()\n\n                # update discriminator.\n                self.x.data = self.feed_interpolated_input(self.loader.get_batch())\n                if self.flag_add_noise:\n                    self.x = self.add_noise(self.x)\n                self.z.data.resize_(self.loader.batchsize, self.nz).normal_(0.0, 1.0)\n                self.x_tilde = self.G(self.z)\n               \n                self.fx = self.D(self.x)\n                self.fx_tilde = self.D(self.x_tilde.detach())\n                \n\t\t        loss_d = self.mse(self.fx.squeeze(), self.real_label) + \\\n                                  self.mse(self.fx_tilde, self.fake_label)\n                loss_d.backward()\n                self.opt_d.step()\n\n                # update generator.\n                fx_tilde = self.D(self.x_tilde)\n                loss_g = self.mse(fx_tilde.squeeze(), self.real_label.detach())\n                loss_g.backward()\n                self.opt_g.step()\n                \n                # logging.\n                log_msg = ' [E:{0}][T:{1}][{2:6}/{3:6}]  errD: {4:.4f} | errG: {5:.4f} | [lr:{11:.5f}][cur:{6:.3f}][resl:{7:4}][{8}][{9:.1f}%][{10:.1f}%]'.format(self.epoch, self.globalTick, self.stack, len(self.loader.dataset), loss_d.item(), loss_g.item(), self.resl, int(pow(2,floor(self.resl))), self.phase, self.complete['gen'], self.complete['dis'], self.lr)\n                tqdm.write(log_msg)\n\n                # save model.\n                self.snapshot('repo/model')\n\n                # save image grid.\n                if self.globalIter%self.config.save_img_every == 0:\n                    with torch.no_grad():\n                        x_test = self.G(self.z_test)\n                    utils.mkdir('repo/save/grid')\n                    utils.save_image_grid(x_test.data, 'repo/save/grid/{}_{}_G{}_D{}.jpg'.format(int(self.globalIter/self.config.save_img_every), self.phase, self.complete['gen'], self.complete['dis']))\n                    utils.mkdir('repo/save/resl_{}'.format(int(floor(self.resl))))\n                    utils.save_image_single(x_test.data, 'repo/save/resl_{}/{}_{}_G{}_D{}.jpg'.format(int(floor(self.resl)),int(self.globalIter/self.config.save_img_every), self.phase, self.complete['gen'], self.complete['dis']))\n\n                # tensorboard visualization.\n                if self.use_tb:\n                    with torch.no_grad():\n                        x_test = self.G(self.z_test)\n                    self.tb.add_scalar('data/loss_g', loss_g[0].item(), self.globalIter)\n                    self.tb.add_scalar('data/loss_d', loss_d[0].item(), self.globalIter)\n                    self.tb.add_scalar('tick/lr', self.lr, self.globalIter)\n                    self.tb.add_scalar('tick/cur_resl', int(pow(2,floor(self.resl))), self.globalIter)\n                    '''IMAGE GRID\n                    self.tb.add_image_grid('grid/x_test', 4, utils.adjust_dyn_range(x_test.data.float(), [-1,1], [0,1]), self.globalIter)\n                    self.tb.add_image_grid('grid/x_tilde', 4, utils.adjust_dyn_range(self.x_tilde.data.float(), [-1,1], [0,1]), self.globalIter)\n                    self.tb.add_image_grid('grid/x_intp', 4, utils.adjust_dyn_range(self.x.data.float(), [-1,1], [0,1]), self.globalIter)\n                    '''\n\n    def get_state(self, target):\n        if target == 'gen':\n            state = {\n                'resl' : self.resl,\n                'state_dict' : self.G.module.state_dict(),\n                'optimizer' : self.opt_g.state_dict(),\n            }\n            return state\n        elif target == 'dis':\n            state = {\n                'resl' : self.resl,\n                'state_dict' : self.D.module.state_dict(),\n                'optimizer' : self.opt_d.state_dict(),\n            }\n            return state\n\n\n    def get_state(self, target):\n        if target == 'gen':\n            state = {\n                'resl' : self.resl,\n                'state_dict' : self.G.module.state_dict(),\n                'optimizer' : self.opt_g.state_dict(),\n            }\n            return state\n        elif target == 'dis':\n            state = {\n                'resl' : self.resl,\n                'state_dict' : self.D.module.state_dict(),\n                'optimizer' : self.opt_d.state_dict(),\n            }\n            return state\n\n\n    def snapshot(self, path):\n        if not os.path.exists(path):\n            if os.name == 'nt':\n                os.system('mkdir {}'.format(path.replace('/', '\\\\')))\n            else:\n                os.system('mkdir -p {}'.format(path))\n        # save every 100 tick if the network is in stab phase.\n        ndis = 'dis_R{}_T{}.pth.tar'.format(int(floor(self.resl)), self.globalTick)\n        ngen = 'gen_R{}_T{}.pth.tar'.format(int(floor(self.resl)), self.globalTick)\n        if self.globalTick%50==0:\n            if self.phase == 'gstab' or self.phase =='dstab' or self.phase == 'final':\n                save_path = os.path.join(path, ndis)\n                if not os.path.exists(save_path):\n                    torch.save(self.get_state('dis'), save_path)\n                    save_path = os.path.join(path, ngen)\n                    torch.save(self.get_state('gen'), save_path)\n                    print('[snapshot] model saved @ {}'.format(path))\n\nif __name__ == '__main__':\n    ## perform training.\n    print('----------------- configuration -----------------')\n    for k, v in vars(config).items():\n        print('  {}: {}'.format(k, v))\n    print('-------------------------------------------------')\n    torch.backends.cudnn.benchmark = True           # boost speed.\n    trainer = trainer(config)\n    trainer.train()\n\n\n"""
utils.py,8,"b'"""""" utils.py\n""""""\n\nimport os\nimport torch\nimport numpy as np\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport time\n\n\ndef adjust_dyn_range(x, drange_in, drange_out):\n    if not drange_in == drange_out:\n        scale = float(drange_out[1]-drange_out[0])/float(drange_in[1]-drange_in[0])\n        bias = drange_out[0]-drange_in[0]*scale\n        x = x.mul(scale).add(bias)\n    return x\n\n\ndef resize(x, size):\n    transform = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Scale(size),\n        transforms.ToTensor(),\n        ])\n    return transform(x)\n\n\ndef make_image_grid(x, ngrid):\n    x = x.clone().cpu()\n    if pow(ngrid,2) < x.size(0):\n        grid = make_grid(x[:ngrid*ngrid], nrow=ngrid, padding=0, normalize=True, scale_each=False)\n    else:\n        grid = torch.FloatTensor(ngrid*ngrid, x.size(1), x.size(2), x.size(3)).fill_(1)\n        grid[:x.size(0)].copy_(x)\n        grid = make_grid(grid, nrow=ngrid, padding=0, normalize=True, scale_each=False)\n    return grid\n\n\ndef save_image_single(x, path, imsize=512):\n    from PIL import Image\n    grid = make_image_grid(x, 1)\n    ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).numpy()\n    im = Image.fromarray(ndarr)\n    im = im.resize((imsize,imsize), Image.NEAREST)\n    im.save(path)\n\n\ndef save_image_grid(x, path, imsize=512, ngrid=4):\n    from PIL import Image\n    grid = make_image_grid(x, ngrid)\n    ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).numpy()\n    im = Image.fromarray(ndarr)\n    im = im.resize((imsize,imsize), Image.NEAREST)\n    im.save(path)\n\n\n\ndef load_model(net, path):\n    net.load_state_dict(torch.load(path))\n\ndef save_model(net, path):\n    torch.save(net.state_dict(), path)\n\n\ndef make_summary(writer, key, value, step):\n    if hasattr(value, \'__len__\'):\n        for idx, img in enumerate(value):\n            summary = tf.Summary()\n            sio = BytesIO()\n            scipy.misc.toimage(img).save(sio, format=\'png\')\n            image_summary = tf.Summary.Image(encoded_image_string=sio.getvalue())\n            summary.value.add(tag=""{}/{}"".format(key, idx), image=image_summary)\n            writer.add_summary(summary, global_step=step)\n    else:\n        summary = tf.Summary(value=[tf.Summary.Value(tag=key, simple_value=value)])\n        writer.add_summary(summary, global_step=step)\n\n\ndef mkdir(path):\n    if os.name == \'nt\':\n        os.system(\'mkdir {}\'.format(path.replace(\'/\', \'\\\\\')))\n    else:\n        os.system(\'mkdir -r {}\'.format(path))\n\n\nimport torch\nimport math\nirange = range\ndef make_grid(tensor, nrow=8, padding=2,\n              normalize=False, range=None, scale_each=False, pad_value=0):\n    """"""Make a grid of images.\n    Args:\n        tensor (Tensor or list): 4D mini-batch Tensor of shape (B x C x H x W)\n            or a list of images all of the same size.\n        nrow (int, optional): Number of images displayed in each row of the grid.\n            The Final grid size is (B / nrow, nrow). Default is 8.\n        padding (int, optional): amount of padding. Default is 2.\n        normalize (bool, optional): If True, shift the image to the range (0, 1),\n            by subtracting the minimum and dividing by the maximum pixel value.\n        range (tuple, optional): tuple (min, max) where min and max are numbers,\n            then these numbers are used to normalize the image. By default, min and max\n            are computed from the tensor.\n        scale_each (bool, optional): If True, scale each image in the batch of\n            images separately rather than the (min, max) over all images.\n        pad_value (float, optional): Value for the padded pixels.\n    Example:\n        See this notebook `here <https://gist.github.com/anonymous/bf16430f7750c023141c562f3e9f2a91>`_\n    """"""\n    if not (torch.is_tensor(tensor) or\n            (isinstance(tensor, list) and all(torch.is_tensor(t) for t in tensor))):\n        raise TypeError(\'tensor or list of tensors expected, got {}\'.format(type(tensor)))\n\n    # if list of tensors, convert to a 4D mini-batch Tensor\n    if isinstance(tensor, list):\n        tensor = torch.stack(tensor, dim=0)\n\n    if tensor.dim() == 2:  # single image H x W\n        tensor = tensor.view(1, tensor.size(0), tensor.size(1))\n    if tensor.dim() == 3:  # single image\n        if tensor.size(0) == 1:  # if single-channel, convert to 3-channel\n            tensor = torch.cat((tensor, tensor, tensor), 0)\n        return tensor\n    if tensor.dim() == 4 and tensor.size(1) == 1:  # single-channel images\n        tensor = torch.cat((tensor, tensor, tensor), 1)\n\n    if normalize is True:\n        tensor = tensor.clone()  # avoid modifying tensor in-place\n        if range is not None:\n            assert isinstance(range, tuple), \\\n                ""range has to be a tuple (min, max) if specified. min and max are numbers""\n\n        def norm_ip(img, min, max):\n            img.clamp_(min=min, max=max)\n            img.add_(-min).div_(max - min)\n\n        def norm_range(t, range):\n            if range is not None:\n                norm_ip(t, range[0], range[1])\n            else:\n                norm_ip(t, t.min(), t.max())\n\n        if scale_each is True:\n            for t in tensor:  # loop over mini-batch dimension\n                norm_range(t, range)\n        else:\n            norm_range(tensor, range)\n\n    # make the mini-batch of images into a grid\n    nmaps = tensor.size(0)\n    xmaps = min(nrow, nmaps)\n    ymaps = int(math.ceil(float(nmaps) / xmaps))\n    height, width = int(tensor.size(2) + padding), int(tensor.size(3) + padding)\n    grid = tensor.new(3, height * ymaps + padding, width * xmaps + padding).fill_(pad_value)\n    k = 0\n    for y in irange(ymaps):\n        for x in irange(xmaps):\n            if k >= nmaps:\n                break\n            grid.narrow(1, y * height + padding, height - padding)\\\n                .narrow(2, x * width + padding, width - padding)\\\n                .copy_(tensor[k])\n            k = k + 1\n    return grid\n\n\ndef save_image(tensor, filename, nrow=8, padding=2,\n               normalize=False, range=None, scale_each=False, pad_value=0):\n    """"""Save a given Tensor into an image file.\n    Args:\n        tensor (Tensor or list): Image to be saved. If given a mini-batch tensor,\n            saves the tensor as a grid of images by calling ``make_grid``.\n        **kwargs: Other arguments are documented in ``make_grid``.\n    """"""\n    from PIL import Image\n    tensor = tensor.cpu()\n    grid = make_grid(tensor, nrow=nrow, padding=padding, pad_value=pad_value,\n                     normalize=normalize, range=range, scale_each=scale_each)\n    ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).numpy()\n    im = Image.fromarray(ndarr)\n    im.save(filename)\n'"
