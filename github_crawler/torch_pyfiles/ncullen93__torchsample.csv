file_path,api_count,code
setup.py,0,"b""#!/usr/bin/env python\n\nfrom setuptools import setup, find_packages\n\nsetup(name='torchsample',\n      version='0.1.3',\n      description='High-Level Training, Augmentation, and Sampling for Pytorch',\n      author='NC Cullen',\n      author_email='nickmarch31@yahoo.com',\n      packages=find_packages()\n     )"""
examples/mnist_example.py,2,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchsample.modules import ModuleTrainer\nfrom torchsample.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom torchsample.regularizers import L1Regularizer, L2Regularizer\nfrom torchsample.constraints import UnitNorm\nfrom torchsample.initializers import XavierUniform\nfrom torchsample.metrics import CategoricalAccuracy\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:10000]\ny_train = y_train[:10000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]\n\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\n\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\n\ncallbacks = [EarlyStopping(patience=10),\n             ReduceLROnPlateau(factor=0.5, patience=5)]\nregularizers = [L1Regularizer(scale=1e-3, module_filter='conv*'),\n                L2Regularizer(scale=1e-5, module_filter='fc*')]\nconstraints = [UnitNorm(frequency=3, unit='batch', module_filter='fc*')]\ninitializers = [XavierUniform(bias=False, module_filter='fc*')]\nmetrics = [CategoricalAccuracy(top_k=3)]\n\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta',\n                regularizers=regularizers,\n                constraints=constraints,\n                initializers=initializers,\n                metrics=metrics)\n\n#summary = trainer.summary([1,28,28])\n#print(summary)\n\ntrainer.fit(x_train, y_train, \n          val_data=(x_test, y_test),\n          num_epoch=20, \n          batch_size=128,\n          verbose=1)\n\n\n"""
examples/mnist_loader_example.py,3,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\n\nfrom torchsample.modules import ModuleTrainer\nfrom torchsample.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom torchsample.regularizers import L1Regularizer, L2Regularizer\nfrom torchsample.constraints import UnitNorm\nfrom torchsample.initializers import XavierUniform\nfrom torchsample.metrics import CategoricalAccuracy\nfrom torchsample import TensorDataset\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:10000]\ny_train = y_train[:10000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]\n\ntrain_dataset = TensorDataset(x_train, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=32)\nval_dataset = TensorDataset(x_test, y_test)\nval_loader = DataLoader(val_dataset, batch_size=32)\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\n\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ncallbacks = [EarlyStopping(patience=10),\n             ReduceLROnPlateau(factor=0.5, patience=5)]\nregularizers = [L1Regularizer(scale=1e-3, module_filter='conv*'),\n                L2Regularizer(scale=1e-5, module_filter='fc*')]\nconstraints = [UnitNorm(frequency=3, unit='batch', module_filter='fc*')]\ninitializers = [XavierUniform(bias=False, module_filter='fc*')]\nmetrics = [CategoricalAccuracy(top_k=3)]\n\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta',\n                regularizers=regularizers,\n                constraints=constraints,\n                initializers=initializers,\n                metrics=metrics, \n                callbacks=callbacks)\n\ntrainer.fit_loader(train_loader, val_loader, num_epoch=20, verbose=1)\n\n\n\n"""
tests/test_metrics.py,5,"b""import unittest\nimport torch\nfrom torch.autograd import Variable\n\nfrom torchsample.metrics import CategoricalAccuracy\n\nclass TestMetrics(unittest.TestCase):\n\n    def test_categorical_accuracy(self):\n        metric = CategoricalAccuracy()\n        predicted = Variable(torch.eye(10))\n        expected = Variable(torch.LongTensor(list(range(10))))\n        self.assertEqual(metric(predicted, expected), 100.0)\n        \n        # Set 1st column to ones\n        predicted = Variable(torch.zeros(10, 10))\n        predicted.data[:, 0] = torch.ones(10)\n        self.assertEqual(metric(predicted, expected), 55.0)\n\nif __name__ == '__main__':\n    unittest.main()"""
tests/utils.py,0,"b'\nimport numpy as np\nimport torch as th\n\ndef get_test_data(num_train=1000, num_test=500, \n                  input_shape=(10,), output_shape=(2,),\n                  classification=True, num_classes=2):\n    """"""Generates test data to train a model on.\n\n    classification=True overrides output_shape\n    (i.e. output_shape is set to (1,)) and the output\n    consists in integers in [0, num_class-1].\n\n    Otherwise: float output with shape output_shape.\n    """"""\n    samples = num_train + num_test\n    if classification:\n        y = np.random.randint(0, num_classes, size=(samples,))\n        X = np.zeros((samples,) + input_shape)\n        for i in range(samples):\n            X[i] = np.random.normal(loc=y[i], scale=0.7, size=input_shape)\n    else:\n        y_loc = np.random.random((samples,))\n        X = np.zeros((samples,) + input_shape)\n        y = np.zeros((samples,) + output_shape)\n        for i in range(samples):\n            X[i] = np.random.normal(loc=y_loc[i], scale=0.7, size=input_shape)\n            y[i] = np.random.normal(loc=y_loc[i], scale=0.7, size=output_shape)\n\n    return (th.from_numpy(X[:num_train]), th.from_numpy(y[:num_train])), \\\n           (th.from_numpy(X[num_train:]), th.from_numpy(y[num_train:]))'"
torchsample/__init__.py,0,b'\nfrom __future__ import absolute_import\n\nfrom .version import __version__\n\nfrom .datasets import *\nfrom .samplers import *\n\n#from .callbacks import *\n#from .constraints import *\n#from .regularizers import *\n\n#from . import functions\n#from . import transforms\nfrom . import modules\n'
torchsample/callbacks.py,0,"b'""""""\nSuperModule Callbacks\n""""""\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nfrom collections import OrderedDict\nfrom collections import Iterable\nimport warnings\n\nimport os\nimport csv\nimport time\nfrom tempfile import NamedTemporaryFile\nimport shutil\nimport datetime\nimport numpy as np\n\nfrom tqdm import tqdm\n\nimport torch as th\n\n\ndef _get_current_time():\n    return datetime.datetime.now().strftime(""%B %d, %Y - %I:%M%p"")\n\nclass CallbackContainer(object):\n    """"""\n    Container holding a list of callbacks.\n    """"""\n    def __init__(self, callbacks=None, queue_length=10):\n        callbacks = callbacks or []\n        self.callbacks = [c for c in callbacks]\n        self.queue_length = queue_length\n\n    def append(self, callback):\n        self.callbacks.append(callback)\n\n    def set_params(self, params):\n        for callback in self.callbacks:\n            callback.set_params(params)\n\n    def set_trainer(self, trainer):\n        self.trainer = trainer\n        for callback in self.callbacks:\n            callback.set_trainer(trainer)\n\n    def on_epoch_begin(self, epoch, logs=None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_begin(epoch, logs)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_epoch_end(epoch, logs)\n\n    def on_batch_begin(self, batch, logs=None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_batch_begin(batch, logs)\n\n    def on_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        for callback in self.callbacks:\n            callback.on_batch_end(batch, logs)\n\n    def on_train_begin(self, logs=None):\n        logs = logs or {}\n        logs[\'start_time\'] = _get_current_time()\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)\n\n    def on_train_end(self, logs=None):\n        logs = logs or {}\n        logs[\'final_loss\'] = self.trainer.history.epoch_losses[-1],\n        logs[\'best_loss\'] = min(self.trainer.history.epoch_losses),\n        logs[\'stop_time\'] = _get_current_time()\n        for callback in self.callbacks:\n            callback.on_train_end(logs)\n\n\nclass Callback(object):\n    """"""\n    Abstract base class used to build new callbacks.\n    """"""\n\n    def __init__(self):\n        pass\n\n    def set_params(self, params):\n        self.params = params\n\n    def set_trainer(self, model):\n        self.trainer = model\n\n    def on_epoch_begin(self, epoch, logs=None):\n        pass\n\n    def on_epoch_end(self, epoch, logs=None):\n        pass\n\n    def on_batch_begin(self, batch, logs=None):\n        pass\n\n    def on_batch_end(self, batch, logs=None):\n        pass\n\n    def on_train_begin(self, logs=None):\n        pass\n\n    def on_train_end(self, logs=None):\n        pass\n\n\nclass TQDM(Callback):\n\n    def __init__(self):\n        """"""\n        TQDM Progress Bar callback\n\n        This callback is automatically applied to \n        every SuperModule if verbose > 0\n        """"""\n        self.progbar = None\n        super(TQDM, self).__init__()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        # make sure the dbconnection gets closed\n        if self.progbar is not None:\n            self.progbar.close()\n\n    def on_train_begin(self, logs):\n        self.train_logs = logs\n\n    def on_epoch_begin(self, epoch, logs=None):\n        try:\n            self.progbar = tqdm(total=self.train_logs[\'num_batches\'],\n                                unit=\' batches\')\n            self.progbar.set_description(\'Epoch %i/%i\' % \n                            (epoch+1, self.train_logs[\'num_epoch\']))\n        except:\n            pass\n\n    def on_epoch_end(self, epoch, logs=None):\n        log_data = {key: \'%.04f\' % value for key, value in self.trainer.history.batch_metrics.items()}\n        for k, v in logs.items():\n            if k.endswith(\'metric\'):\n                log_data[k.split(\'_metric\')[0]] = \'%.02f\' % v\n            else:\n                 log_data[k] = v\n        self.progbar.set_postfix(log_data)\n        self.progbar.update()\n        self.progbar.close()\n\n    def on_batch_begin(self, batch, logs=None):\n        self.progbar.update(1)\n\n    def on_batch_end(self, batch, logs=None):\n        log_data = {key: \'%.04f\' % value for key, value in self.trainer.history.batch_metrics.items()}\n        for k, v in logs.items():\n            if k.endswith(\'metric\'):\n                log_data[k.split(\'_metric\')[0]] = \'%.02f\' % v\n        self.progbar.set_postfix(log_data)\n\n\nclass History(Callback):\n    """"""\n    Callback that records events into a `History` object.\n\n    This callback is automatically applied to\n    every SuperModule.\n    """"""\n    def __init__(self, model):\n        super(History, self).__init__()\n        self.samples_seen = 0.\n        self.trainer = model\n\n    def on_train_begin(self, logs=None):\n        self.epoch_metrics = {\n            \'loss\': []\n        }\n        self.batch_size = logs[\'batch_size\']\n        self.has_val_data = logs[\'has_val_data\']\n        self.has_regularizers = logs[\'has_regularizers\']\n        if self.has_val_data:\n            self.epoch_metrics[\'val_loss\'] = []\n        if self.has_regularizers:\n            self.epoch_metrics[\'reg_loss\'] = []\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.batch_metrics = {\n            \'loss\': 0.\n        }\n        if self.has_regularizers:\n            self.batch_metrics[\'reg_loss\'] = 0.\n        self.samples_seen = 0.\n\n    def on_epoch_end(self, epoch, logs=None):\n        #for k in self.batch_metrics:\n        #    k_log = k.split(\'_metric\')[0]\n        # self.epoch_metrics.update(self.batch_metrics)\n        # TODO\n        pass\n\n    def on_batch_end(self, batch, logs=None):\n        for k in self.batch_metrics:\n            self.batch_metrics[k] = (self.samples_seen*self.batch_metrics[k] + logs[k]*self.batch_size) / (self.samples_seen+self.batch_size)\n        self.samples_seen += self.batch_size\n\n    def __getitem__(self, name):\n        return self.epoch_metrics[name]\n\n    def __repr__(self):\n        return str(self.epoch_metrics)\n\n    def __str__(self):\n        return str(self.epoch_metrics)\n\n\nclass ModelCheckpoint(Callback):\n    """"""\n    Model Checkpoint to save model weights during training\n\n    save_checkpoint({\n                \'epoch\': epoch + 1,\n                \'arch\': args.arch,\n                \'state_dict\': model.state_dict(),\n                \'best_prec1\': best_prec1,\n                \'optimizer\' : optimizer.state_dict(),\n            }\n    def save_checkpoint(state, is_best, filename=\'checkpoint.pth.tar\'):\n        th.save(state, filename)\n        if is_best:\n            shutil.copyfile(filename, \'model_best.pth.tar\')\n\n    """"""\n\n    def __init__(self,\n                 directory, \n                 filename=\'ckpt.pth.tar\', \n                 monitor=\'val_loss\', \n                 save_best_only=False, \n                 save_weights_only=True,\n                 max_save=-1,\n                 verbose=0):\n        """"""\n        Model Checkpoint to save model weights during training\n\n        Arguments\n        ---------\n        file : string\n            file to which model will be saved.\n            It can be written \'filename_{epoch}_{loss}\' and those\n            values will be filled in before saving.\n        monitor : string in {\'val_loss\', \'loss\'}\n            whether to monitor train or val loss\n        save_best_only : boolean\n            whether to only save if monitored value has improved\n        save_weight_only : boolean \n            whether to save entire model or just weights\n            NOTE: only `True` is supported at the moment\n        max_save : integer > 0 or -1\n            the max number of models to save. Older model checkpoints\n            will be overwritten if necessary. Set equal to -1 to have\n            no limit\n        verbose : integer in {0, 1}\n            verbosity\n        """"""\n        if directory.startswith(\'~\'):\n            directory = os.path.expanduser(directory)\n        self.directory = directory\n        self.filename = filename\n        self.file = os.path.join(self.directory, self.filename)\n        self.monitor = monitor\n        self.save_best_only = save_best_only\n        self.save_weights_only = save_weights_only\n        self.max_save = max_save\n        self.verbose = verbose\n\n        if self.max_save > 0:\n            self.old_files = []\n\n        # mode = \'min\' only supported\n        self.best_loss = float(\'inf\')\n        super(ModelCheckpoint, self).__init__()\n\n    def save_checkpoint(self, epoch, file, is_best=False):\n        th.save({ \n            \'epoch\': epoch + 1,\n             #\'arch\': args.arch,\n            \'state_dict\': self.trainer.model.state_dict(),\n            #\'best_prec1\': best_prec1,\n            \'optimizer\' : self.trainer._optimizer.state_dict(),\n            #\'loss\':{},\n                #            #\'regularizers\':{},\n                #            #\'constraints\':{},\n                #            #\'initializers\':{},\n                #            #\'metrics\':{},\n                #            #\'val_loss\':{}\n            }, file)\n        if is_best:\n            shutil.copyfile(file, \'model_best.pth.tar\')\n\n    def on_epoch_end(self, epoch, logs=None):\n\n        file = self.file.format(epoch=\'%03i\'%(epoch+1), \n                                loss=\'%0.4f\'%logs[self.monitor])\n        if self.save_best_only:\n            current_loss = logs.get(self.monitor)\n            if current_loss is None:\n                pass\n            else:\n                if current_loss < self.best_loss:\n                    if self.verbose > 0:\n                        print(\'\\nEpoch %i: improved from %0.4f to %0.4f saving model to %s\' % \n                              (epoch+1, self.best_loss, current_loss, file))\n                    self.best_loss = current_loss\n                    #if self.save_weights_only:\n                    #else:\n                    self.save_checkpoint(epoch, file)\n                    if self.max_save > 0:\n                        if len(self.old_files) == self.max_save:\n                            try:\n                                os.remove(self.old_files[0])\n                            except:\n                                pass\n                            self.old_files = self.old_files[1:]\n                        self.old_files.append(file)\n        else:\n            if self.verbose > 0:\n                print(\'\\nEpoch %i: saving model to %s\' % (epoch+1, file))\n            self.save_checkpoint(epoch, file)\n            if self.max_save > 0:\n                if len(self.old_files) == self.max_save:\n                    try:\n                        os.remove(self.old_files[0])\n                    except:\n                        pass\n                    self.old_files = self.old_files[1:]\n                self.old_files.append(file)\n\n\nclass EarlyStopping(Callback):\n    """"""\n    Early Stopping to terminate training early under certain conditions\n    """"""\n\n    def __init__(self, \n                 monitor=\'val_loss\',\n                 min_delta=0,\n                 patience=5):\n        """"""\n        EarlyStopping callback to exit the training loop if training or\n        validation loss does not improve by a certain amount for a certain\n        number of epochs\n\n        Arguments\n        ---------\n        monitor : string in {\'val_loss\', \'loss\'}\n            whether to monitor train or val loss\n        min_delta : float\n            minimum change in monitored value to qualify as improvement.\n            This number should be positive.\n        patience : integer\n            number of epochs to wait for improvment before terminating.\n            the counter be reset after each improvment\n        """"""\n        self.monitor = monitor\n        self.min_delta = min_delta\n        self.patience = patience\n        self.wait = 0\n        self.best_loss = 1e-15\n        self.stopped_epoch = 0\n        super(EarlyStopping, self).__init__()\n\n    def on_train_begin(self, logs=None):\n        self.wait = 0\n        self.best_loss = 1e15\n\n    def on_epoch_end(self, epoch, logs=None):\n        current_loss = logs.get(self.monitor)\n        if current_loss is None:\n            pass\n        else:\n            if (current_loss - self.best_loss) < -self.min_delta:\n                self.best_loss = current_loss\n                self.wait = 1\n            else:\n                if self.wait >= self.patience:\n                    self.stopped_epoch = epoch + 1\n                    self.trainer._stop_training = True\n                self.wait += 1\n\n    def on_train_end(self, logs):\n        if self.stopped_epoch > 0:\n            print(\'\\nTerminated Training for Early Stopping at Epoch %04i\' % \n                (self.stopped_epoch))\n\n\nclass LRScheduler(Callback):\n    """"""\n    Schedule the learning rate according to some function of the \n    current epoch index, current learning rate, and current train/val loss.\n    """"""\n\n    def __init__(self, schedule):\n        """"""\n        LearningRateScheduler callback to adapt the learning rate\n        according to some function\n\n        Arguments\n        ---------\n        schedule : callable\n            should return a number of learning rates equal to the number\n            of optimizer.param_groups. It should take the epoch index and\n            **kwargs (or logs) as argument. **kwargs (or logs) will return\n            the epoch logs such as mean training and validation loss from\n            the epoch\n        """"""\n        if isinstance(schedule, dict):\n            schedule = self.schedule_from_dict\n            self.schedule_dict = schedule\n            if any([k < 1.0 for k in schedule.keys()]):\n                self.fractional_bounds = False\n            else:\n                self.fractional_bounds = True\n        self.schedule = schedule\n        super(LRScheduler, self).__init__()\n\n    def schedule_from_dict(self, epoch, logs=None):\n        for epoch_bound, learn_rate in self.schedule_dict.items():\n            # epoch_bound is in units of ""epochs""\n            if not self.fractional_bounds:\n                if epoch_bound < epoch:\n                    return learn_rate\n            # epoch_bound is in units of ""cumulative percent of epochs""\n            else:\n                if epoch <= epoch_bound*logs[\'num_epoch\']:\n                    return learn_rate\n        warnings.warn(\'Check the keys in the schedule dict.. Returning last value\')\n        return learn_rate\n\n    def on_epoch_begin(self, epoch, logs=None):\n        current_lrs = [p[\'lr\'] for p in self.trainer._optimizer.param_groups]\n        lr_list = self.schedule(epoch, current_lrs, **logs)\n        if not isinstance(lr_list, list):\n            lr_list = [lr_list]\n\n        for param_group, lr_change in zip(self.trainer._optimizer.param_groups, lr_list):\n            param_group[\'lr\'] = lr_change\n\n\nclass ReduceLROnPlateau(Callback):\n    """"""\n    Reduce the learning rate if the train or validation loss plateaus\n    """"""\n\n    def __init__(self,\n                 monitor=\'val_loss\', \n                 factor=0.1, \n                 patience=10,\n                 epsilon=0, \n                 cooldown=0, \n                 min_lr=0,\n                 verbose=0):\n        """"""\n        Reduce the learning rate if the train or validation loss plateaus\n\n        Arguments\n        ---------\n        monitor : string in {\'loss\', \'val_loss\'}\n            which metric to monitor\n        factor : floar\n            factor to decrease learning rate by\n        patience : integer\n            number of epochs to wait for loss improvement before reducing lr\n        epsilon : float\n            how much improvement must be made to reset patience\n        cooldown : integer \n            number of epochs to cooldown after a lr reduction\n        min_lr : float\n            minimum value to ever let the learning rate decrease to\n        verbose : integer\n            whether to print reduction to console\n        """"""\n        self.monitor = monitor\n        if factor >= 1.0:\n            raise ValueError(\'ReduceLROnPlateau does not support a factor >= 1.0.\')\n        self.factor = factor\n        self.min_lr = min_lr\n        self.epsilon = epsilon\n        self.patience = patience\n        self.verbose = verbose\n        self.cooldown = cooldown\n        self.cooldown_counter = 0\n        self.wait = 0\n        self.best_loss = 1e15\n        self._reset()\n        super(ReduceLROnPlateau, self).__init__()\n\n    def _reset(self):\n        """"""\n        Reset the wait and cooldown counters\n        """"""\n        self.monitor_op = lambda a, b: (a - b) < -self.epsilon\n        self.best_loss = 1e15\n        self.cooldown_counter = 0\n        self.wait = 0\n\n    def on_train_begin(self, logs=None):\n        self._reset()\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs[\'lr\'] = [p[\'lr\'] for p in self.trainer._optimizer.param_groups]\n        current_loss = logs.get(self.monitor)\n        if current_loss is None:\n            pass\n        else:\n            # if in cooldown phase\n            if self.cooldown_counter > 0: \n                self.cooldown_counter -= 1\n                self.wait = 0\n            # if loss improved, grab new loss and reset wait counter\n            if self.monitor_op(current_loss, self.best_loss):\n                self.best_loss = current_loss\n                self.wait = 0\n            # loss didnt improve, and not in cooldown phase\n            elif not (self.cooldown_counter > 0):\n                if self.wait >= self.patience:\n                    for p in self.trainer._optimizer.param_groups:\n                        old_lr = p[\'lr\']\n                        if old_lr > self.min_lr + 1e-4:\n                            new_lr = old_lr * self.factor\n                            new_lr = max(new_lr, self.min_lr)\n                            if self.verbose > 0:\n                                print(\'\\nEpoch %05d: reducing lr from %0.3f to %0.3f\' % \n                                    (epoch, old_lr, new_lr))\n                            p[\'lr\'] = new_lr\n                            self.cooldown_counter = self.cooldown\n                            self.wait = 0\n                self.wait += 1\n\n\nclass CSVLogger(Callback):\n    """"""\n    Logs epoch-level metrics to a CSV file\n    """"""\n\n    def __init__(self, \n                 file, \n                 separator=\',\', \n                 append=False):\n        """"""\n        Logs epoch-level metrics to a CSV file\n\n        Arguments\n        ---------\n        file : string\n            path to csv file\n        separator : string\n            delimiter for file\n        apped : boolean\n            whether to append result to existing file or make new file\n        """"""\n        self.file = file\n        self.sep = separator\n        self.append = append\n        self.writer = None\n        self.keys = None\n        self.append_header = True\n        super(CSVLogger, self).__init__()\n\n    def on_train_begin(self, logs=None):\n        if self.append:\n            if os.path.exists(self.file):\n                with open(self.file) as f:\n                    self.append_header = not bool(len(f.readline()))\n            self.csv_file = open(self.file, \'a\')\n        else:\n            self.csv_file = open(self.file, \'w\')\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        RK = {\'num_batches\', \'num_epoch\'}\n\n        def handle_value(k):\n            is_zero_dim_tensor = isinstance(k, th.Tensor) and k.dim() == 0\n            if isinstance(k, Iterable) and not is_zero_dim_tensor:\n                return \'""[%s]""\' % (\', \'.join(map(str, k)))\n            else:\n                return k\n\n        if not self.writer:\n            self.keys = sorted(logs.keys())\n\n            class CustomDialect(csv.excel):\n                delimiter = self.sep\n\n            self.writer = csv.DictWriter(self.csv_file,\n                    fieldnames=[\'epoch\'] + [k for k in self.keys if k not in RK], \n                    dialect=CustomDialect)\n            if self.append_header:\n                self.writer.writeheader()\n\n        row_dict = OrderedDict({\'epoch\': epoch})\n        row_dict.update((key, handle_value(logs[key])) for key in self.keys if key not in RK)\n        self.writer.writerow(row_dict)\n        self.csv_file.flush()\n\n    def on_train_end(self, logs=None):\n        self.csv_file.close()\n        self.writer = None\n\n\nclass ExperimentLogger(Callback):\n\n    def __init__(self,\n                 directory,\n                 filename=\'Experiment_Logger.csv\',\n                 save_prefix=\'Model_\', \n                 separator=\',\', \n                 append=True):\n\n        self.directory = directory\n        self.filename = filename\n        self.file = os.path.join(self.directory, self.filename)\n        self.save_prefix = save_prefix\n        self.sep = separator\n        self.append = append\n        self.writer = None\n        self.keys = None\n        self.append_header = True\n        super(ExperimentLogger, self).__init__()\n\n    def on_train_begin(self, logs=None):\n        if self.append:\n            open_type = \'a\'\n        else:\n            open_type = \'w\'\n\n        # if append is True, find whether the file already has header\n        num_lines = 0\n        if self.append:\n            if os.path.exists(self.file):\n                with open(self.file) as f:\n                    for num_lines, l in enumerate(f):\n                        pass\n                    # if header exists, DONT append header again\n                with open(self.file) as f:\n                    self.append_header = not bool(len(f.readline()))\n                \n        model_idx = num_lines\n        REJECT_KEYS={\'has_validation_data\'}\n        MODEL_NAME = self.save_prefix + str(model_idx) # figure out how to get model name\n        self.row_dict = OrderedDict({\'model\': MODEL_NAME})\n        self.keys = sorted(logs.keys())\n        for k in self.keys:\n            if k not in REJECT_KEYS:\n                self.row_dict[k] = logs[k]\n\n        class CustomDialect(csv.excel):\n            delimiter = self.sep\n\n        with open(self.file, open_type) as csv_file:\n            writer = csv.DictWriter(csv_file,\n                fieldnames=[\'model\'] + [k for k in self.keys if k not in REJECT_KEYS], \n                dialect=CustomDialect)\n            if self.append_header:\n                writer.writeheader()\n\n            writer.writerow(self.row_dict)\n            csv_file.flush()\n\n    def on_train_end(self, logs=None):\n        REJECT_KEYS={\'has_validation_data\'}\n        row_dict = self.row_dict\n\n        class CustomDialect(csv.excel):\n            delimiter = self.sep\n        self.keys = self.keys\n        temp_file = NamedTemporaryFile(delete=False, mode=\'w\')\n        with open(self.file, \'r\') as csv_file, temp_file:\n            reader = csv.DictReader(csv_file,\n                fieldnames=[\'model\'] + [k for k in self.keys if k not in REJECT_KEYS], \n                dialect=CustomDialect)\n            writer = csv.DictWriter(temp_file,\n                fieldnames=[\'model\'] + [k for k in self.keys if k not in REJECT_KEYS], \n                dialect=CustomDialect)\n            for row_idx, row in enumerate(reader):\n                if row_idx == 0:\n                    # re-write header with on_train_end\'s metrics\n                    pass\n                if row[\'model\'] == self.row_dict[\'model\']:\n                    writer.writerow(row_dict)\n                else:\n                    writer.writerow(row)\n        shutil.move(temp_file.name, self.file)   \n\n\nclass LambdaCallback(Callback):\n    """"""\n    Callback for creating simple, custom callbacks on-the-fly.\n    """"""\n    def __init__(self,\n                 on_epoch_begin=None,\n                 on_epoch_end=None,\n                 on_batch_begin=None,\n                 on_batch_end=None,\n                 on_train_begin=None,\n                 on_train_end=None,\n                 **kwargs):\n        super(LambdaCallback, self).__init__()\n        self.__dict__.update(kwargs)\n        if on_epoch_begin is not None:\n            self.on_epoch_begin = on_epoch_begin\n        else:\n            self.on_epoch_begin = lambda epoch, logs: None\n        if on_epoch_end is not None:\n            self.on_epoch_end = on_epoch_end\n        else:\n            self.on_epoch_end = lambda epoch, logs: None\n        if on_batch_begin is not None:\n            self.on_batch_begin = on_batch_begin\n        else:\n            self.on_batch_begin = lambda batch, logs: None\n        if on_batch_end is not None:\n            self.on_batch_end = on_batch_end\n        else:\n            self.on_batch_end = lambda batch, logs: None\n        if on_train_begin is not None:\n            self.on_train_begin = on_train_begin\n        else:\n            self.on_train_begin = lambda logs: None\n        if on_train_end is not None:\n            self.on_train_end = on_train_end\n        else:\n            self.on_train_end = lambda logs: None\n\n'"
torchsample/constraints.py,0,"b'\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nfrom fnmatch import fnmatch\n\nimport torch as th\nfrom .callbacks import Callback\n\n\nclass ConstraintContainer(object):\n\n    def __init__(self, constraints):\n        self.constraints = constraints\n        self.batch_constraints = [c for c in self.constraints if c.unit.upper() == \'BATCH\']\n        self.epoch_constraints = [c for c in self.constraints if c.unit.upper() == \'EPOCH\']\n\n    def register_constraints(self, model):\n        """"""\n        Grab pointers to the weights which will be modified by constraints so\n        that we dont have to search through the entire network using `apply`\n        each time\n        """"""\n        # get batch constraint pointers\n        self._batch_c_ptrs = {}\n        for c_idx, constraint in enumerate(self.batch_constraints):\n            self._batch_c_ptrs[c_idx] = []\n            for name, module in model.named_modules():\n                if fnmatch(name, constraint.module_filter) and hasattr(module, \'weight\'):\n                    self._batch_c_ptrs[c_idx].append(module)\n\n        # get epoch constraint pointers\n        self._epoch_c_ptrs = {}\n        for c_idx, constraint in enumerate(self.epoch_constraints):\n            self._epoch_c_ptrs[c_idx] = []\n            for name, module in model.named_modules():\n                if fnmatch(name, constraint.module_filter) and hasattr(module, \'weight\'):\n                    self._epoch_c_ptrs[c_idx].append(module)\n\n    def apply_batch_constraints(self, batch_idx):\n        for c_idx, modules in self._batch_c_ptrs.items():\n            if (batch_idx+1) % self.constraints[c_idx].frequency == 0:\n                for module in modules:\n                    self.constraints[c_idx](module)\n\n    def apply_epoch_constraints(self, epoch_idx):\n        for c_idx, modules in self._epoch_c_ptrs.items():\n            if (epoch_idx+1) % self.constraints[c_idx].frequency == 0:\n                for module in modules:\n                    self.constraints[c_idx](module)\n\n\nclass ConstraintCallback(Callback):\n\n    def __init__(self, container):\n        self.container = container\n\n    def on_batch_end(self, batch_idx, logs):\n        self.container.apply_batch_constraints(batch_idx)\n\n    def on_epoch_end(self, epoch_idx, logs):\n        self.container.apply_epoch_constraints(epoch_idx)\n\n\nclass Constraint(object):\n\n    def __call__(self):\n        raise NotImplementedError(\'Subclass much implement this method\')\n\n\nclass UnitNorm(Constraint):\n    """"""\n    UnitNorm constraint.\n\n    Constraints the weights to have column-wise unit norm\n    """"""\n    def __init__(self, \n                 frequency=1, \n                 unit=\'batch\',\n                 module_filter=\'*\'):\n\n        self.frequency = frequency\n        self.unit = unit\n        self.module_filter = module_filter\n\n    def __call__(self, module):\n        w = module.weight.data\n        module.weight.data = w.div(th.norm(w,2,0))\n\n\nclass MaxNorm(Constraint):\n    """"""\n    MaxNorm weight constraint.\n\n    Constrains the weights incident to each hidden unit\n    to have a norm less than or equal to a desired value.\n\n    Any hidden unit vector with a norm less than the max norm\n    constaint will not be altered.\n    """"""\n\n    def __init__(self, \n                 value, \n                 axis=0, \n                 frequency=1, \n                 unit=\'batch\',\n                 module_filter=\'*\'):\n        self.value = float(value)\n        self.axis = axis\n\n        self.frequency = frequency\n        self.unit = unit\n        self.module_filter = module_filter\n\n    def __call__(self, module):\n        w = module.weight.data\n        module.weight.data = th.renorm(w, 2, self.axis, self.value)\n\n\nclass NonNeg(Constraint):\n    """"""\n    Constrains the weights to be non-negative.\n    """"""\n    def __init__(self, \n                 frequency=1, \n                 unit=\'batch\',\n                 module_filter=\'*\'):\n        self.frequency = frequency\n        self.unit = unit\n        self.module_filter = module_filter\n\n    def __call__(self, module):\n        w = module.weight.data\n        module.weight.data = w.gt(0).float().mul(w)\n\n\n\n\n\n\n'"
torchsample/datasets.py,0,"b'\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport os\nimport fnmatch\n\nimport numpy as np\nimport pandas as pd\nimport PIL.Image as Image\nimport nibabel\n\nimport torch as th\n\nfrom . import transforms\n\n\nclass BaseDataset(object):\n    """"""An abstract class representing a Dataset.\n\n    All other datasets should subclass it. All subclasses should override\n    ``__len__``, that provides the size of the dataset, and ``__getitem__``,\n    supporting integer indexing in range from 0 to len(self) exclusive.\n    """"""\n\n    def __len__(self):\n        return len(self.inputs) if not isinstance(self.inputs, (tuple,list)) else len(self.inputs[0])\n\n    def add_input_transform(self, transform, add_to_front=True, idx=None):\n        if idx is None:\n            idx = np.arange(len(self.num_inputs))\n        elif not is_tuple_or_list(idx):\n            idx = [idx]\n\n        if add_to_front:\n            for i in idx:\n                self.input_transform[i] = transforms.Compose([transform, self.input_transform[i]])\n        else:\n            for i in idx:\n                self.input_transform[i] = transforms.Compose([self.input_transform[i], transform])\n\n    def add_target_transform(self, transform, add_to_front=True, idx=None):\n        if idx is None:\n            idx = np.arange(len(self.num_targets))\n        elif not is_tuple_or_list(idx):\n            idx = [idx]\n\n        if add_to_front:\n            for i in idx:\n                self.target_transform[i] = transforms.Compose([transform, self.target_transform[i]])\n        else:\n            for i in idx:\n                self.target_transform[i] = transforms.Compose([self.target_transform[i], transform])\n\n    def add_co_transform(self, transform, add_to_front=True, idx=None):\n        if idx is None:\n            idx = np.arange(len(self.min_inputs_or_targets))\n        elif not is_tuple_or_list(idx):\n            idx = [idx]\n\n        if add_to_front:\n            for i in idx:\n                self.co_transform[i] = transforms.Compose([transform, self.co_transform[i]])\n        else:\n            for i in idx:\n                self.co_transform[i] = transforms.Compose([self.co_transform[i], transform])\n\n    def load(self, num_samples=None, load_range=None):\n        """"""\n        Load all data or a subset of the data into actual memory.\n        For instance, if the inputs are paths to image files, then this\n        function will actually load those images.\n    \n        Arguments\n        ---------\n        num_samples : integer (optional)\n            number of samples to load. if None, will load all\n        load_range : numpy array of integers (optional)\n            the index range of images to load\n            e.g. np.arange(4) loads the first 4 inputs+targets\n        """"""\n        def _parse_shape(x):\n            if isinstance(x, (list,tuple)):\n                return (len(x),)\n            elif isinstance(x, th.Tensor):\n                return x.size()\n            else:\n                return (1,)\n\n        if num_samples is None and load_range is None:\n            num_samples = len(self)\n            load_range = np.arange(num_samples)\n        elif num_samples is None and load_range is not None:\n            num_samples = len(load_range)\n        elif num_samples is not None and load_range is None:\n            load_range = np.arange(num_samples)\n\n\n        if self.has_target:\n            for enum_idx, sample_idx in enumerate(load_range):\n                input_sample, target_sample = self.__getitem__(sample_idx)\n\n                if enum_idx == 0:\n                    if self.num_inputs == 1:\n                        _shape = [len(load_range)] + list(_parse_shape(input_sample))\n                        inputs = np.empty(_shape)\n                    else:\n                        inputs = []\n                        for i in range(self.num_inputs):\n                            _shape = [len(load_range)] + list(_parse_shape(input_sample[i]))\n                            inputs.append(np.empty(_shape))\n                        #inputs = [np.empty((len(load_range), *_parse_shape(input_sample[i]))) for i in range(self.num_inputs)]\n\n                    if self.num_targets == 1:\n                        _shape = [len(load_range)] + list(_parse_shape(target_sample))\n                        targets = np.empty(_shape)\n                        #targets = np.empty((len(load_range), *_parse_shape(target_sample)))\n                    else:\n                        targets = []\n                        for i in range(self.num_targets):\n                            _shape = [len(load_range)] + list(_parse_shape(target_sample[i]))\n                            targets.append(np.empty(_shape))\n                        #targets = [np.empty((len(load_range), *_parse_shape(target_sample[i]))) for i in range(self.num_targets)]\n\n                if self.num_inputs == 1:\n                    inputs[enum_idx] = input_sample\n                else:\n                    for i in range(self.num_inputs):\n                        inputs[i][enum_idx] = input_sample[i]\n\n                if self.num_targets == 1:\n                    targets[enum_idx] = target_sample\n                else:\n                    for i in range(self.num_targets):\n                        targets[i][enum_idx] = target_sample[i]\n\n            return inputs, targets\n        else:\n            for enum_idx, sample_idx in enumerate(load_range):\n                input_sample = self.__getitem__(sample_idx)\n\n                if enum_idx == 0:\n                    if self.num_inputs == 1:\n                        _shape = [len(load_range)] + list(_parse_shape(input_sample))\n                        inputs = np.empty(_shape)\n                        #inputs = np.empty((len(load_range), *_parse_shape(input_sample)))\n                    else:\n                        inputs = []\n                        for i in range(self.num_inputs):\n                            _shape = [len(load_range)] + list(_parse_shape(input_sample[i]))\n                            inputs.append(np.empty(_shape))\n                        #inputs = [np.empty((len(load_range), *_parse_shape(input_sample[i]))) for i in range(self.num_inputs)]\n\n                if self.num_inputs == 1:\n                    inputs[enum_idx] = input_sample\n                else:\n                    for i in range(self.num_inputs):\n                        inputs[i][enum_idx] = input_sample[i]\n\n            return inputs\n\n    def fit_transforms(self):\n        """"""\n        Make a single pass through the entire dataset in order to fit \n        any parameters of the transforms which require the entire dataset.\n        e.g. StandardScaler() requires mean and std for the entire dataset.\n\n        If you dont call this fit function, then transforms which require properties\n        of the entire dataset will just work at the batch level.\n        e.g. StandardScaler() will normalize each batch by the specific batch mean/std\n        """"""\n        it_fit = hasattr(self.input_transform, \'update_fit\')\n        tt_fit = hasattr(self.target_transform, \'update_fit\')\n        ct_fit = hasattr(self.co_transform, \'update_fit\')\n        if it_fit or tt_fit or ct_fit:\n            for sample_idx in range(len(self)):\n                if hasattr(self, \'input_loader\'):\n                    x = self.input_loader(self.inputs[sample_idx])\n                else:\n                    x = self.inputs[sample_idx]\n                if it_fit:\n                    self.input_transform.update_fit(x)\n                if self.has_target:\n                    if hasattr(self, \'target_loader\'):\n                        y = self.target_loader(self.targets[sample_idx])\n                    else:\n                        y = self.targets[sample_idx]\n                if tt_fit:\n                    self.target_transform.update_fit(y)\n                if ct_fit:\n                    self.co_transform.update_fit(x,y)\n\n\ndef _process_array_argument(x):\n    if not is_tuple_or_list(x):\n        x = [x]\n    return x\n\n\nclass TensorDataset(BaseDataset):\n\n    def __init__(self,\n                 inputs,\n                 targets=None,\n                 input_transform=None, \n                 target_transform=None,\n                 co_transform=None):\n        """"""\n        Dataset class for loading in-memory data.\n\n        Arguments\n        ---------\n        inputs: numpy array\n\n        targets : numpy array\n\n        input_transform : class with __call__ function implemented\n            transform to apply to input sample individually\n\n        target_transform : class with __call__ function implemented\n            transform to apply to target sample individually\n\n        co_transform : class with __call__ function implemented\n            transform to apply to both input and target sample simultaneously\n\n        """"""\n        self.inputs = _process_array_argument(inputs)\n        self.num_inputs = len(self.inputs)\n        self.input_return_processor = _return_first_element_of_list if self.num_inputs==1 else _pass_through\n\n        if targets is None:\n            self.has_target = False\n        else:\n            self.targets = _process_array_argument(targets)\n            self.num_targets = len(self.targets)\n            self.target_return_processor = _return_first_element_of_list if self.num_targets==1 else _pass_through\n            self.min_inputs_or_targets = min(self.num_inputs, self.num_targets)\n            self.has_target = True            \n        \n        self.input_transform = _process_transform_argument(input_transform, self.num_inputs)\n        if self.has_target:\n            self.target_transform = _process_transform_argument(target_transform, self.num_targets)\n            self.co_transform = _process_co_transform_argument(co_transform, self.num_inputs, self.num_targets)\n\n    def __getitem__(self, index):\n        """"""\n        Index the dataset and return the input + target\n        """"""\n        input_sample = [self.input_transform[i](self.inputs[i][index]) for i in range(self.num_inputs)]\n\n        if self.has_target:\n            target_sample = [self.target_transform[i](self.targets[i][index]) for i in range(self.num_targets)]\n            #for i in range(self.min_inputs_or_targets):\n            #    input_sample[i], target_sample[i] = self.co_transform[i](input_sample[i], target_sample[i])\n\n            return self.input_return_processor(input_sample), self.target_return_processor(target_sample)\n        else:\n            return self.input_return_processor(input_sample)\n\n\ndef default_file_reader(x):\n    def pil_loader(path):\n        return Image.open(path).convert(\'RGB\')\n    def npy_loader(path):\n        return np.load(path)\n    def nifti_loader(path):\n        return nibabel.load(path).get_data()\n    if isinstance(x, str):\n        if x.endswith(\'.npy\'):\n            x = npy_loader(x)\n        elif x.endsiwth(\'.nii.gz\'):\n            x = nifti_loader(x)\n        else:\n            try:\n                x = pil_loader(x)\n            except:\n                raise ValueError(\'File Format is not supported\')\n    #else:\n        #raise ValueError(\'x should be string, but got %s\' % type(x))\n    return x\n\ndef is_tuple_or_list(x):\n    return isinstance(x, (tuple,list))\n\ndef _process_transform_argument(tform, num_inputs):\n    tform = tform if tform is not None else _pass_through\n    if is_tuple_or_list(tform):\n        if len(tform) != num_inputs:\n            raise Exception(\'If transform is list, must provide one transform for each input\')\n        tform = [t if t is not None else _pass_through for t in tform]\n    else:\n        tform = [tform] * num_inputs\n    return tform\n\ndef _process_co_transform_argument(tform, num_inputs, num_targets):\n    tform = tform if tform is not None else _multi_arg_pass_through\n    if is_tuple_or_list(tform):\n        if len(tform) != num_inputs:\n            raise Exception(\'If transform is list, must provide one transform for each input\')\n        tform = [t if t is not None else _multi_arg_pass_through for t in tform]\n    else:\n        tform = [tform] * min(num_inputs, num_targets)\n    return tform\n\ndef _process_csv_argument(csv):\n    if isinstance(csv, str):\n        df = pd.read_csv(csv)\n    elif isinstance(csv, pd.DataFrame):\n        df = csv\n    else:\n        raise ValueError(\'csv argument must be string or dataframe\')\n    return df\n\ndef _select_dataframe_columns(df, cols):\n    if isinstance(cols[0], str):\n        inputs = df.loc[:,cols].values\n    elif isinstance(cols[0], int):\n        inputs = df.iloc[:,cols].values\n    else:\n        raise ValueError(\'Provided columns should be string column names or integer column indices\')\n    return inputs\n\ndef _process_cols_argument(cols):\n    if isinstance(cols, tuple):\n        cols = list(cols)\n    return cols\n\ndef _return_first_element_of_list(x):\n    return x[0]\n\ndef _pass_through(x):\n    return x\n\ndef _multi_arg_pass_through(*x):\n    return x\n\n\nclass CSVDataset(BaseDataset):\n\n    def __init__(self,\n                 csv,\n                 input_cols=[0],\n                 target_cols=[1],\n                 input_transform=None,\n                 target_transform=None,\n                 co_transform=None):\n        """"""\n        Initialize a Dataset from a CSV file/dataframe. This does NOT\n        actually load the data into memory if the CSV contains filepaths.\n\n        Arguments\n        ---------\n        csv : string or pandas.DataFrame\n            if string, should be a path to a .csv file which\n            can be loaded as a pandas dataframe\n        \n        input_cols : int/list of ints, or string/list of strings\n            which columns to use as input arrays.\n            If int(s), should be column indicies\n            If str(s), should be column names \n        \n        target_cols : int/list of ints, or string/list of strings\n            which columns to use as input arrays.\n            If int(s), should be column indicies\n            If str(s), should be column names \n\n        input_transform : class which implements a __call__ method\n            tranform(s) to apply to inputs during runtime loading\n\n        target_tranform : class which implements a __call__ method\n            transform(s) to apply to targets during runtime loading\n\n        co_transform : class which implements a __call__ method\n            transform(s) to apply to both inputs and targets simultaneously\n            during runtime loading\n        """"""\n        self.input_cols = _process_cols_argument(input_cols)\n        self.target_cols = _process_cols_argument(target_cols)\n        \n        self.df = _process_csv_argument(csv)\n\n        self.inputs = _select_dataframe_columns(self.df, input_cols)\n        self.num_inputs = self.inputs.shape[1]\n        self.input_return_processor = _return_first_element_of_list if self.num_inputs==1 else _pass_through\n\n        if target_cols is None:\n            self.num_targets = 0\n            self.has_target = False\n        else:\n            self.targets = _select_dataframe_columns(self.df, target_cols)\n            self.num_targets = self.targets.shape[1]\n            self.target_return_processor = _return_first_element_of_list if self.num_targets==1 else _pass_through\n            self.has_target = True\n            self.min_inputs_or_targets = min(self.num_inputs, self.num_targets)\n\n        self.input_loader = default_file_reader\n        self.target_loader = default_file_reader\n        \n        self.input_transform = _process_transform_argument(input_transform, self.num_inputs)\n        if self.has_target:\n            self.target_transform = _process_transform_argument(target_transform, self.num_targets)\n            self.co_transform = _process_co_transform_argument(co_transform, self.num_inputs, self.num_targets)\n\n    def __getitem__(self, index):\n        """"""\n        Index the dataset and return the input + target\n        """"""\n        input_sample = [self.input_transform[i](self.input_loader(self.inputs[index, i])) for i in range(self.num_inputs)]\n\n        if self.has_target:\n            target_sample = [self.target_transform[i](self.target_loader(self.targets[index, i])) for i in range(self.num_targets)]\n            for i in range(self.min_inputs_or_targets):\n                input_sample[i], input_sample[i] = self.co_transform[i](input_sample[i], target_sample[i])\n\n            return self.input_return_processor(input_sample), self.target_return_processor(target_sample)\n        else:\n            return self.input_return_processor(input_sample)\n\n    def split_by_column(self, col):\n        """"""\n        Split this dataset object into multiple dataset objects based on \n        the unique factors of the given column. The number of returned\n        datasets will be equal to the number of unique values in the given\n        column. The transforms and original dataframe will all be transferred\n        to the new datasets \n\n        Useful for splitting a dataset into train/val/test datasets.\n\n        Arguments\n        ---------\n        col : integer or string\n            which column to split the data on. \n            if int, should be column index\n            if str, should be column name\n\n        Returns\n        -------\n        - list of new datasets with transforms copied\n        """"""\n        if isinstance(col, int):\n            split_vals = self.df.iloc[:,col].values.flatten()\n\n            new_df_list = []\n            for unique_split_val in np.unique(split_vals):\n                new_df = self.df[:][self.df.iloc[:,col]==unique_split_val]\n                new_df_list.append(new_df)\n        elif isinstance(col, str):\n            split_vals = self.df.loc[:,col].values.flatten()\n\n            new_df_list = []\n            for unique_split_val in np.unique(split_vals):\n                new_df = self.df[:][self.df.loc[:,col]==unique_split_val]\n                new_df_list.append(new_df)\n        else:\n            raise ValueError(\'col argument not valid - must be column name or index\')\n\n        new_datasets = []\n        for new_df in new_df_list:\n            new_dataset = self.copy(new_df)\n            new_datasets.append(new_dataset)\n\n        return new_datasets\n\n    def train_test_split(self, train_size):\n        if train_size < 1:\n            train_size = int(train_size * len(self))\n\n        train_indices = np.random.choice(len(self), train_size, replace=False)\n        test_indices = np.array([i for i in range(len(self)) if i not in train_indices])\n        \n        train_df = self.df.iloc[train_indices,:]\n        test_df = self.df.iloc[test_indices,:]\n\n        train_dataset = self.copy(train_df)\n        test_dataset = self.copy(test_df)\n\n        return train_dataset, test_dataset\n\n    def copy(self, df=None):\n        if df is None:\n            df = self.df\n\n        return CSVDataset(df,\n                          input_cols=self.input_cols, \n                          target_cols=self.target_cols,\n                          input_transform=self.input_transform,\n                          target_transform=self.target_transform,\n                          co_transform=self.co_transform)\n\n\nclass FolderDataset(BaseDataset):\n\n    def __init__(self, \n                 root,\n                 class_mode=\'label\',\n                 input_regex=\'*\',\n                 target_regex=None,\n                 input_transform=None, \n                 target_transform=None,\n                 co_transform=None, \n                 input_loader=\'npy\'):\n        """"""\n        Dataset class for loading out-of-memory data.\n\n        Arguments\n        ---------\n        root : string\n            path to main directory\n\n        class_mode : string in `{\'label\', \'image\'}`\n            type of target sample to look for and return\n            `label` = return class folder as target\n            `image` = return another image as target as found by \'target_regex\'\n                NOTE: if class_mode == \'image\', you must give an\n                input and target regex and the input/target images should\n                be in a folder together with no other images in that folder\n\n        input_regex : string (default is any valid image file)\n            regular expression to find input images\n            e.g. if all your inputs have the word \'input\', \n            you\'d enter something like input_regex=\'*input*\'\n        \n        target_regex : string (default is Nothing)\n            regular expression to find target images if class_mode == \'image\'\n            e.g. if all your targets have the word \'segment\', \n            you\'d enter somthing like target_regex=\'*segment*\'\n\n        transform : transform class\n            transform to apply to input sample individually\n\n        target_transform : transform class\n            transform to apply to target sample individually\n\n        input_loader : string in `{\'npy\', \'pil\', \'nifti\'} or callable\n            defines how to load samples from file\n            if a function is provided, it should take in a file path\n            as input and return the loaded sample.\n\n        """"""\n        self.input_loader = default_file_reader\n        self.target_loader = default_file_reader if class_mode == \'image\' else lambda x: x\n\n        root = os.path.expanduser(root)\n\n        classes, class_to_idx = _find_classes(root)\n        inputs, targets = _finds_inputs_and_targets(root, class_mode,\n            class_to_idx, input_regex, target_regex)\n\n        if len(inputs) == 0:\n            raise(RuntimeError(\'Found 0 images in subfolders of: %s\' % root))\n        else:\n            print(\'Found %i images\' % len(inputs))\n\n        self.root = os.path.expanduser(root)\n        self.inputs = inputs\n        self.targets = targets\n        self.classes = classes\n        self.class_to_idx = class_to_idx\n\n        self.input_transform = input_transform if input_transform is not None else lambda x: x\n        if isinstance(input_transform, (tuple,list)):\n            self.input_transform = transforms.Compose(self.input_transform)\n        self.target_transform = target_transform if target_transform is not None else lambda x: x\n        if isinstance(target_transform, (tuple,list)):\n            self.target_transform = transforms.Compose(self.target_transform)\n        self.co_transform = co_transform if co_transform is not None else lambda x,y: (x,y)\n        if isinstance(co_transform, (tuple,list)):\n            self.co_transform = transforms.Compose(self.co_transform)\n        \n        self.class_mode = class_mode\n\n    def get_full_paths(self):\n        return [os.path.join(self.root, i) for i in self.inputs]\n\n    def __getitem__(self, index):\n        input_sample = self.inputs[index]\n        input_sample = self.input_loader(input_sample)\n        input_sample = self.input_transform(input_sample)\n\n        target_sample = self.targets[index]\n        target_sample = self.target_loader(target_sample)\n        target_sample = self.target_transform(target_sample)\n        \n        input_sample, target_sample = self.co_transform(input_sample, target_sample)\n\n        return input_sample, target_sample\n    \n    def __len__(self):\n        return len(self.inputs)\n\n\n\ndef _find_classes(dir):\n    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    return classes, class_to_idx\n\ndef _is_image_file(filename):\n    IMG_EXTENSIONS = [\n        \'.jpg\', \'.JPG\', \'.jpeg\', \'.JPEG\',\n        \'.png\', \'.PNG\', \'.ppm\', \'.PPM\', \'.bmp\', \'.BMP\',\n        \'.nii.gz\', \'.npy\'\n    ]\n    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n\ndef _finds_inputs_and_targets(directory, class_mode, class_to_idx=None, \n            input_regex=None, target_regex=None, ):\n    """"""\n    Map a dataset from a root folder\n    """"""\n    if class_mode == \'image\':\n        if not input_regex and not target_regex:\n            raise ValueError(\'must give input_regex and target_regex if\'+\n                \' class_mode==image\')\n    inputs = []\n    targets = []\n    for subdir in sorted(os.listdir(directory)):\n        d = os.path.join(directory, subdir)\n        if not os.path.isdir(d):\n            continue\n\n        for root, _, fnames in sorted(os.walk(d)):\n            for fname in fnames:\n                if _is_image_file(fname):\n                    if fnmatch.fnmatch(fname, input_regex):\n                        path = os.path.join(root, fname)\n                        inputs.append(path)\n                        if class_mode == \'label\':\n                            targets.append(class_to_idx[subdir])\n                    if class_mode == \'image\' and \\\n                            fnmatch.fnmatch(fname, target_regex):\n                        path = os.path.join(root, fname)\n                        targets.append(path)\n    if class_mode is None:\n        return inputs\n    else:\n        return inputs, targets\n'"
torchsample/initializers.py,30,"b'""""""\nClasses to initialize module weights\n""""""\n\nfrom fnmatch import fnmatch\n\nimport torch.nn.init\n\n\ndef _validate_initializer_string(init):\n    dir_f = dir(torch.nn.init)\n    loss_fns = [d.lower() for d in dir_f]\n    if isinstance(init, str):\n        try:\n            str_idx = loss_fns.index(init.lower())\n        except:\n            raise ValueError(\'Invalid loss string input - must match pytorch function.\')\n        return getattr(torch.nn.init, dir(torch.nn.init)[str_idx])\n    elif callable(init):\n        return init\n    else:\n        raise ValueError(\'Invalid loss input\')\n\n\nclass InitializerContainer(object):\n\n    def __init__(self, initializers):\n        self._initializers = initializers\n\n    def apply(self, model):\n        for initializer in self._initializers:\n            model.apply(initializer)\n\n\nclass Initializer(object):\n\n    def __call__(self, module):\n        raise NotImplementedError(\'Initializer must implement this method\')\n\n\nclass GeneralInitializer(Initializer):\n\n    def __init__(self, initializer, bias=False, bias_only=False, **kwargs):\n        self._initializer = _validate_initializer_string(initializer)\n        self.kwargs = kwargs\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                self._initializer(module.bias.data, **self.kwargs)\n            else:\n                self._initializer(module.weight.data, **self.kwargs)\n                if self.bias:\n                    self._initializer(module.bias.data, **self.kwargs)\n\n\nclass Normal(Initializer):\n\n    def __init__(self, mean=0.0, std=0.02, bias=False, \n                 bias_only=False, module_filter=\'*\'):\n        self.mean = mean\n        self.std = std\n\n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(Normal, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.normal(module.bias.data, mean=self.mean, std=self.std)\n            else:\n                torch.nn.init.normal(module.weight.data, mean=self.mean, std=self.std)\n                if self.bias:\n                    torch.nn.init.normal(module.bias.data, mean=self.mean, std=self.std)\n\n\nclass Uniform(Initializer):\n\n    def __init__(self, a=0, b=1, bias=False, bias_only=False, module_filter=\'*\'):\n        self.a = a\n        self.b = b\n\n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(Uniform, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.uniform(module.bias.data, a=self.a, b=self.b)\n            else:\n                torch.nn.init.uniform(module.weight.data, a=self.a, b=self.b)\n                if self.bias:\n                    torch.nn.init.uniform(module.bias.data, a=self.a, b=self.b)\n\n\nclass ConstantInitializer(Initializer):\n\n    def __init__(self, value, bias=False, bias_only=False, module_filter=\'*\'):\n        self.value = value\n\n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(ConstantInitializer, self).__init__()\n\n    def __call__(self, module, bias=False, bias_only=False, module_filter=\'*\'):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.constant(module.bias.data, val=self.value)\n            else:\n                torch.nn.init.constant(module.weight.data, val=self.value)\n                if self.bias:\n                    torch.nn.init.constant(module.bias.data, val=self.value)\n\n\nclass XavierUniform(Initializer):\n\n    def __init__(self, gain=1, bias=False, bias_only=False, module_filter=\'*\'):\n        self.gain = gain\n\n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(XavierUniform, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.xavier_uniform(module.bias.data, gain=self.gain)\n            else:\n                torch.nn.init.xavier_uniform(module.weight.data, gain=self.gain)\n                if self.bias:\n                    torch.nn.init.xavier_uniform(module.bias.data, gain=self.gain)\n\n\nclass XavierNormal(Initializer):\n\n    def __init__(self, gain=1, bias=False, bias_only=False, module_filter=\'*\'):\n        self.gain = gain\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(XavierNormal, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.xavier_normal(module.bias.data, gain=self.gain)\n            else:\n                torch.nn.init.xavier_normal(module.weight.data, gain=self.gain)\n                if self.bias:\n                    torch.nn.init.xavier_normal(module.bias.data, gain=self.gain)\n\n\nclass KaimingUniform(Initializer):\n\n    def __init__(self, a=0, mode=\'fan_in\', bias=False, bias_only=False, module_filter=\'*\'):\n        self.a = a\n        self.mode = mode\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(KaimingUniform, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.kaiming_uniform(module.bias.data, a=self.a, mode=self.mode)\n            else:\n                torch.nn.init.kaiming_uniform(module.weight.data, a=self.a, mode=self.mode)\n                if self.bias:\n                    torch.nn.init.kaiming_uniform(module.bias.data, a=self.a, mode=self.mode)\n\n\nclass KaimingNormal(Initializer):\n\n    def __init__(self, a=0, mode=\'fan_in\', bias=False, bias_only=False, module_filter=\'*\'):\n        self.a = a\n        self.mode = mode\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(KaimingNormal, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.kaiming_normal(module.bias.data, a=self.a, mode=self.mode)\n            else:\n                torch.nn.init.kaiming_normal(module.weight.data, a=self.a, mode=self.mode)\n                if self.bias:\n                    torch.nn.init.kaiming_normal(module.bias.data, a=self.a, mode=self.mode)\n\n\nclass Orthogonal(Initializer):\n\n    def __init__(self, gain=1, bias=False, bias_only=False, module_filter=\'*\'):\n        self.gain = gain\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(Orthogonal, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.orthogonal(module.bias.data, gain=self.gain)\n            else:\n                torch.nn.init.orthogonal(module.weight.data, gain=self.gain)\n                if self.bias:\n                    torch.nn.init.orthogonal(module.bias.data, gain=self.gain)\n\n\nclass Sparse(Initializer):\n\n    def __init__(self, sparsity, std=0.01, bias=False, bias_only=False, module_filter=\'*\'):\n        self.sparsity = sparsity\n        self.std = std\n        \n        self.bias = bias\n        self.bias_only = bias_only\n        self.module_filter = module_filter\n\n        super(Sparse, self).__init__()\n\n    def __call__(self, module):\n        classname = module.__class__.__name__\n        if fnmatch(classname, self.module_filter) and hasattr(module, \'weight\'):\n            if self.bias_only:\n                torch.nn.init.sparse(module.bias.data, sparsity=self.sparsity, std=self.std)\n            else:\n                torch.nn.init.sparse(module.weight.data, sparsity=self.sparsity, std=self.std)\n                if self.bias:\n                    torch.nn.init.sparse(module.bias.data, sparsity=self.sparsity, std=self.std)\n\n\n\n'"
torchsample/metrics.py,0,"b'\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport torch as th\n\nfrom .utils import th_matrixcorr\n\nfrom .callbacks import Callback\n\nclass MetricContainer(object):\n\n\n    def __init__(self, metrics, prefix=\'\'):\n        self.metrics = metrics\n        self.helper = None\n        self.prefix = prefix\n\n    def set_helper(self, helper):\n        self.helper = helper\n\n    def reset(self):\n        for metric in self.metrics:\n            metric.reset()\n\n    def __call__(self, output_batch, target_batch):\n        logs = {}\n        for metric in self.metrics:\n            logs[self.prefix+metric._name] = self.helper.calculate_loss(output_batch,\n                                                                        target_batch,\n                                                                        metric) \n        return logs\n\nclass Metric(object):\n\n    def __call__(self, y_pred, y_true):\n        raise NotImplementedError(\'Custom Metrics must implement this function\')\n\n    def reset(self):\n        raise NotImplementedError(\'Custom Metrics must implement this function\')\n\n\nclass MetricCallback(Callback):\n\n    def __init__(self, container):\n        self.container = container\n    def on_epoch_begin(self, epoch_idx, logs):\n        self.container.reset()\n\nclass CategoricalAccuracy(Metric):\n\n    def __init__(self, top_k=1):\n        self.top_k = top_k\n        self.correct_count = 0\n        self.total_count = 0\n\n        self._name = \'acc_metric\'\n\n    def reset(self):\n        self.correct_count = 0\n        self.total_count = 0\n\n    def __call__(self, y_pred, y_true):\n        top_k = y_pred.topk(self.top_k,1)[1]\n        true_k = y_true.view(len(y_true),1).expand_as(top_k)\n        self.correct_count += top_k.eq(true_k).float().sum().data[0]\n        self.total_count += len(y_pred)\n        accuracy = 100. * float(self.correct_count) / float(self.total_count)\n        return accuracy\n\n\nclass BinaryAccuracy(Metric):\n\n    def __init__(self):\n        self.correct_count = 0\n        self.total_count = 0\n\n        self._name = \'acc_metric\'\n\n    def reset(self):\n        self.correct_count = 0\n        self.total_count = 0\n\n    def __call__(self, y_pred, y_true):\n        y_pred_round = y_pred.round().long()\n        self.correct_count += y_pred_round.eq(y_true).float().sum().data[0]\n        self.total_count += len(y_pred)\n        accuracy = 100. * float(self.correct_count) / float(self.total_count)\n        return accuracy\n\n\nclass ProjectionCorrelation(Metric):\n\n    def __init__(self):\n        self.corr_sum = 0.\n        self.total_count = 0.\n\n        self._name = \'corr_metric\'\n\n    def reset(self):\n        self.corr_sum = 0.\n        self.total_count = 0.\n\n    def __call__(self, y_pred, y_true=None):\n        """"""\n        y_pred should be two projections\n        """"""\n        covar_mat = th.abs(th_matrixcorr(y_pred[0].data, y_pred[1].data))\n        self.corr_sum += th.trace(covar_mat)\n        self.total_count += covar_mat.size(0)\n        return self.corr_sum / self.total_count\n\n\nclass ProjectionAntiCorrelation(Metric):\n\n    def __init__(self):\n        self.anticorr_sum = 0.\n        self.total_count = 0.\n\n        self._name = \'anticorr_metric\'\n\n    def reset(self):\n        self.anticorr_sum = 0.\n        self.total_count = 0.\n\n    def __call__(self, y_pred, y_true=None):\n        """"""\n        y_pred should be two projections\n        """"""\n        covar_mat = th.abs(th_matrixcorr(y_pred[0].data, y_pred[1].data))\n        upper_sum = th.sum(th.triu(covar_mat,1))\n        lower_sum = th.sum(th.tril(covar_mat,-1))\n        self.anticorr_sum += upper_sum\n        self.anticorr_sum += lower_sum\n        self.total_count += covar_mat.size(0)*(covar_mat.size(1) - 1)\n        return self.anticorr_sum / self.total_count\n\n\n\n'"
torchsample/regularizers.py,0,"b'\nimport torch as th\nfrom fnmatch import fnmatch\n\nfrom .callbacks import Callback\n\nclass RegularizerContainer(object):\n\n    def __init__(self, regularizers):\n        self.regularizers = regularizers\n        self._forward_hooks = []\n\n    def register_forward_hooks(self, model):\n        for regularizer in self.regularizers:\n            for module_name, module in model.named_modules():\n                if fnmatch(module_name, regularizer.module_filter) and hasattr(module, \'weight\'):\n                    hook = module.register_forward_hook(regularizer)\n                    self._forward_hooks.append(hook)\n        \n        if len(self._forward_hooks) == 0:\n            raise Exception(\'Tried to register regularizers but no modules \'\n                \'were found that matched any module_filter argument.\')\n\n    def unregister_forward_hooks(self):\n        for hook in self._forward_hooks:\n            hook.remove()\n\n    def reset(self):\n        for r in self.regularizers:\n            r.reset()\n\n    def get_value(self):\n        value = sum([r.value for r in self.regularizers])\n        self.current_value = value.data[0]\n        return value\n\n    def __len__(self):\n        return len(self.regularizers)\n\n\nclass RegularizerCallback(Callback):\n\n    def __init__(self, container):\n        self.container = container\n\n    def on_batch_end(self, batch, logs=None):\n        self.container.reset()\n\n\nclass Regularizer(object):\n\n    def reset(self):\n        raise NotImplementedError(\'subclass must implement this method\')\n\n    def __call__(self, module, input=None, output=None):\n        raise NotImplementedError(\'subclass must implement this method\')\n\n\nclass L1Regularizer(Regularizer):\n\n    def __init__(self, scale=1e-3, module_filter=\'*\'):\n        self.scale = float(scale)\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        value = th.sum(th.abs(module.weight)) * self.scale\n        self.value += value\n\n\nclass L2Regularizer(Regularizer):\n\n    def __init__(self, scale=1e-3, module_filter=\'*\'):\n        self.scale = float(scale)\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        value = th.sum(th.pow(module.weight,2)) * self.scale\n        self.value += value\n\n\nclass L1L2Regularizer(Regularizer):\n\n    def __init__(self, l1_scale=1e-3, l2_scale=1e-3, module_filter=\'*\'):\n        self.l1 = L1Regularizer(l1_scale)\n        self.l2 = L2Regularizer(l2_scale)\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        self.l1(module, input, output)\n        self.l2(module, input, output)\n        self.value += (self.l1.value + self.l2.value)\n\n\n# ------------------------------------------------------------------\n# ------------------------------------------------------------------\n# ------------------------------------------------------------------\n\nclass UnitNormRegularizer(Regularizer):\n    """"""\n    UnitNorm constraint on Weights\n\n    Constraints the weights to have column-wise unit norm\n    """"""\n    def __init__(self,\n                 scale=1e-3,\n                 module_filter=\'*\'):\n\n        self.scale = scale\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        w = module.weight\n        norm_diff = th.norm(w, 2, 1).sub(1.)\n        value = self.scale * th.sum(norm_diff.gt(0).float().mul(norm_diff))\n        self.value += value\n\n\nclass MaxNormRegularizer(Regularizer):\n    """"""\n    MaxNorm regularizer on Weights\n\n    Constraints the weights to have column-wise unit norm\n    """"""\n    def __init__(self,\n                 scale=1e-3,\n                 module_filter=\'*\'):\n\n        self.scale = scale\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        w = module.weight\n        norm_diff = th.norm(w,2,self.axis).sub(self.value)\n        value = self.scale * th.sum(norm_diff.gt(0).float().mul(norm_diff))\n        self.value += value\n\n\nclass NonNegRegularizer(Regularizer):\n    """"""\n    Non-Negativity regularizer on Weights\n\n    Constraints the weights to have column-wise unit norm\n    """"""\n    def __init__(self,\n                 scale=1e-3,\n                 module_filter=\'*\'):\n\n        self.scale = scale\n        self.module_filter = module_filter\n        self.value = 0.\n\n    def reset(self):\n        self.value = 0.\n\n    def __call__(self, module, input=None, output=None):\n        w = module.weight\n        value = -1 * self.scale * th.sum(w.gt(0).float().mul(w))\n        self.value += value\n\n'"
torchsample/samplers.py,0,"b'\nimport torch as th\nimport math\n\nclass Sampler(object):\n    """"""Base class for all Samplers.\n\n    Every Sampler subclass has to provide an __iter__ method, providing a way\n    to iterate over indices of dataset elements, and a __len__ method that\n    returns the length of the returned iterators.\n    """"""\n\n    def __init__(self, data_source):\n        pass\n\n    def __iter__(self):\n        raise NotImplementedError\n\n    def __len__(self):\n        raise NotImplementedError\n\nclass StratifiedSampler(Sampler):\n    """"""Stratified Sampling\n\n    Provides equal representation of target classes in each batch\n    """"""\n    def __init__(self, class_vector, batch_size):\n        """"""\n        Arguments\n        ---------\n        class_vector : torch tensor\n            a vector of class labels\n        batch_size : integer\n            batch_size\n        """"""\n        self.n_splits = int(class_vector.size(0) / batch_size)\n        self.class_vector = class_vector\n\n    def gen_sample_array(self):\n        try:\n            from sklearn.model_selection import StratifiedShuffleSplit\n        except:\n            print(\'Need scikit-learn for this functionality\')\n        import numpy as np\n        \n        s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.5)\n        X = th.randn(self.class_vector.size(0),2).numpy()\n        y = self.class_vector.numpy()\n        s.get_n_splits(X, y)\n\n        train_index, test_index = next(s.split(X, y))\n        return np.hstack([train_index, test_index])\n\n    def __iter__(self):\n        return iter(self.gen_sample_array())\n\n    def __len__(self):\n        return len(self.class_vector)\n\nclass MultiSampler(Sampler):\n    """"""Samples elements more than once in a single pass through the data.\n\n    This allows the number of samples per epoch to be larger than the number\n    of samples itself, which can be useful when training on 2D slices taken\n    from 3D images, for instance.\n    """"""\n    def __init__(self, nb_samples, desired_samples, shuffle=False):\n        """"""Initialize MultiSampler\n\n        Arguments\n        ---------\n        data_source : the dataset to sample from\n        \n        desired_samples : number of samples per batch you want\n            whatever the difference is between an even division will\n            be randomly selected from the samples.\n            e.g. if len(data_source) = 3 and desired_samples = 4, then\n            all 3 samples will be included and the last sample will be\n            randomly chosen from the 3 original samples.\n\n        shuffle : boolean\n            whether to shuffle the indices or not\n        \n        Example:\n            >>> m = MultiSampler(2, 6)\n            >>> x = m.gen_sample_array()\n            >>> print(x) # [0,1,0,1,0,1]\n        """"""\n        self.data_samples = nb_samples\n        self.desired_samples = desired_samples\n        self.shuffle = shuffle\n\n    def gen_sample_array(self):\n        from torchsample.utils import th_random_choice\n        n_repeats = self.desired_samples / self.data_samples\n        cat_list = []\n        for i in range(math.floor(n_repeats)):\n            cat_list.append(th.arange(0,self.data_samples))\n        # add the left over samples\n        left_over = self.desired_samples % self.data_samples\n        if left_over > 0:\n            cat_list.append(th_random_choice(self.data_samples, left_over))\n        self.sample_idx_array = th.cat(cat_list).long()\n        return self.sample_idx_array\n\n    def __iter__(self):\n        return iter(self.gen_sample_array())\n\n    def __len__(self):\n        return self.desired_samples\n\n\nclass SequentialSampler(Sampler):\n    """"""Samples elements sequentially, always in the same order.\n\n    Arguments:\n        data_source (Dataset): dataset to sample from\n    """"""\n\n    def __init__(self, nb_samples):\n        self.num_samples = nb_samples\n\n    def __iter__(self):\n        return iter(range(self.num_samples))\n\n    def __len__(self):\n        return self.num_samples\n\n\nclass RandomSampler(Sampler):\n    """"""Samples elements randomly, without replacement.\n\n    Arguments:\n        data_source (Dataset): dataset to sample from\n    """"""\n\n    def __init__(self, nb_samples):\n        self.num_samples = nb_samples\n\n    def __iter__(self):\n        return iter(th.randperm(self.num_samples).long())\n\n    def __len__(self):\n        return self.num_samples\n\n\n'"
torchsample/utils.py,0,"b'""""""\nUtility functions for th.Tensors\n""""""\n\nimport pickle\nimport random\nimport numpy as np\n\nimport torch as th\n\n\ndef th_allclose(x, y):\n    """"""\n    Determine whether two torch tensors have same values\n    Mimics np.allclose\n    """"""\n    return th.sum(th.abs(x-y)) < 1e-5\n\n\ndef th_flatten(x):\n    """"""Flatten tensor""""""\n    return x.contiguous().view(-1)\n\ndef th_c_flatten(x):\n    """"""\n    Flatten tensor, leaving channel intact.\n    Assumes CHW format.\n    """"""\n    return x.contiguous().view(x.size(0), -1)\n\ndef th_bc_flatten(x):\n    """"""\n    Flatten tensor, leaving batch and channel dims intact.\n    Assumes BCHW format\n    """"""\n    return x.contiguous().view(x.size(0), x.size(1), -1)\n\n\ndef th_zeros_like(x):\n    return x.new().resize_as_(x).zero_()\n\ndef th_ones_like(x):\n    return x.new().resize_as_(x).fill_(1)\n\ndef th_constant_like(x, val):\n    return x.new().resize_as_(x).fill_(val)\n\n\ndef th_iterproduct(*args):\n    return th.from_numpy(np.indices(args).reshape((len(args),-1)).T)\n\ndef th_iterproduct_like(x):\n    return th_iterproduct(*x.size())\n\n\ndef th_uniform(lower, upper):\n    return random.uniform(lower, upper)\n\n\ndef th_gather_nd(x, coords):\n    x = x.contiguous()\n    inds = coords.mv(th.LongTensor(x.stride()))\n    x_gather = th.index_select(th_flatten(x), 0, inds)\n    return x_gather\n\n\ndef th_affine2d(x, matrix, mode=\'bilinear\', center=True):\n    """"""\n    2D Affine image transform on th.Tensor\n    \n    Arguments\n    ---------\n    x : th.Tensor of size (C, H, W)\n        image tensor to be transformed\n\n    matrix : th.Tensor of size (3, 3) or (2, 3)\n        transformation matrix\n\n    mode : string in {\'nearest\', \'bilinear\'}\n        interpolation scheme to use\n\n    center : boolean\n        whether to alter the bias of the transform \n        so the transform is applied about the center\n        of the image rather than the origin\n\n    Example\n    ------- \n    >>> import torch\n    >>> from torchsample.utils import *\n    >>> x = th.zeros(2,1000,1000)\n    >>> x[:,100:1500,100:500] = 10\n    >>> matrix = th.FloatTensor([[1.,0,-50],\n    ...                             [0,1.,-50]])\n    >>> xn = th_affine2d(x, matrix, mode=\'nearest\')\n    >>> xb = th_affine2d(x, matrix, mode=\'bilinear\')\n    """"""\n\n    if matrix.dim() == 2:\n        matrix = matrix[:2,:]\n        matrix = matrix.unsqueeze(0)\n    elif matrix.dim() == 3:\n        if matrix.size()[1:] == (3,3):\n            matrix = matrix[:,:2,:]\n\n    A_batch = matrix[:,:,:2]\n    if A_batch.size(0) != x.size(0):\n        A_batch = A_batch.repeat(x.size(0),1,1)\n    b_batch = matrix[:,:,2].unsqueeze(1)\n\n    # make a meshgrid of normal coordinates\n    _coords = th_iterproduct(x.size(1),x.size(2))\n    coords = _coords.unsqueeze(0).repeat(x.size(0),1,1).float()\n\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,:,0] = coords[:,:,0] - (x.size(1) / 2. - 0.5)\n        coords[:,:,1] = coords[:,:,1] - (x.size(2) / 2. - 0.5)\n    # apply the coordinate transformation\n    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(1) / 2. - 0.5)\n        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(2) / 2. - 0.5)\n\n    # map new coordinates using bilinear interpolation\n    if mode == \'nearest\':\n        x_transformed = th_nearest_interp2d(x.contiguous(), new_coords)\n    elif mode == \'bilinear\':\n        x_transformed = th_bilinear_interp2d(x.contiguous(), new_coords)\n\n    return x_transformed\n\n\ndef th_nearest_interp2d(input, coords):\n    """"""\n    2d nearest neighbor interpolation th.Tensor\n    """"""\n    # take clamp of coords so they\'re in the image bounds\n    x = th.clamp(coords[:,:,0], 0, input.size(1)-1).round()\n    y = th.clamp(coords[:,:,1], 0, input.size(2)-1).round()\n\n    stride = th.LongTensor(input.stride())\n    x_ix = x.mul(stride[1]).long()\n    y_ix = y.mul(stride[2]).long()\n\n    input_flat = input.view(input.size(0),-1)\n\n    mapped_vals = input_flat.gather(1, x_ix.add(y_ix))\n\n    return mapped_vals.view_as(input)\n\n\ndef th_bilinear_interp2d(input, coords):\n    """"""\n    bilinear interpolation in 2d\n    """"""\n    x = th.clamp(coords[:,:,0], 0, input.size(1)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    y = th.clamp(coords[:,:,1], 0, input.size(2)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n\n    stride = th.LongTensor(input.stride())\n    x0_ix = x0.mul(stride[1]).long()\n    x1_ix = x1.mul(stride[1]).long()\n    y0_ix = y0.mul(stride[2]).long()\n    y1_ix = y1.mul(stride[2]).long()\n\n    input_flat = input.view(input.size(0),-1)\n\n    vals_00 = input_flat.gather(1, x0_ix.add(y0_ix))\n    vals_10 = input_flat.gather(1, x1_ix.add(y0_ix))\n    vals_01 = input_flat.gather(1, x0_ix.add(y1_ix))\n    vals_11 = input_flat.gather(1, x1_ix.add(y1_ix))\n    \n    xd = x - x0\n    yd = y - y0\n    xm = 1 - xd\n    ym = 1 - yd\n\n    x_mapped = (vals_00.mul(xm).mul(ym) +\n                vals_10.mul(xd).mul(ym) +\n                vals_01.mul(xm).mul(yd) +\n                vals_11.mul(xd).mul(yd))\n\n    return x_mapped.view_as(input)\n\n\ndef th_affine3d(x, matrix, mode=\'trilinear\', center=True):\n    """"""\n    3D Affine image transform on th.Tensor\n    """"""\n    A = matrix[:3,:3]\n    b = matrix[:3,3]\n\n    # make a meshgrid of normal coordinates\n    coords = th_iterproduct(x.size(1),x.size(2),x.size(3)).float()\n\n\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,0] = coords[:,0] - (x.size(1) / 2. - 0.5)\n        coords[:,1] = coords[:,1] - (x.size(2) / 2. - 0.5)\n        coords[:,2] = coords[:,2] - (x.size(3) / 2. - 0.5)\n\n    \n    # apply the coordinate transformation\n    new_coords = coords.mm(A.t().contiguous()) + b.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,0] = new_coords[:,0] + (x.size(1) / 2. - 0.5)\n        new_coords[:,1] = new_coords[:,1] + (x.size(2) / 2. - 0.5)\n        new_coords[:,2] = new_coords[:,2] + (x.size(3) / 2. - 0.5)\n\n    # map new coordinates using bilinear interpolation\n    if mode == \'nearest\':\n        x_transformed = th_nearest_interp3d(x, new_coords)\n    elif mode == \'trilinear\':\n        x_transformed = th_trilinear_interp3d(x, new_coords)\n    else:\n        x_transformed = th_trilinear_interp3d(x, new_coords)\n\n    return x_transformed\n\n\ndef th_nearest_interp3d(input, coords):\n    """"""\n    2d nearest neighbor interpolation th.Tensor\n    """"""\n    # take clamp of coords so they\'re in the image bounds\n    coords[:,0] = th.clamp(coords[:,0], 0, input.size(1)-1).round()\n    coords[:,1] = th.clamp(coords[:,1], 0, input.size(2)-1).round()\n    coords[:,2] = th.clamp(coords[:,2], 0, input.size(3)-1).round()\n\n    stride = th.LongTensor(input.stride())[1:].float()\n    idx = coords.mv(stride).long()\n\n    input_flat = th_flatten(input)\n\n    mapped_vals = input_flat[idx]\n\n    return mapped_vals.view_as(input)\n\n\ndef th_trilinear_interp3d(input, coords):\n    """"""\n    trilinear interpolation of 3D th.Tensor image\n    """"""\n    # take clamp then floor/ceil of x coords\n    x = th.clamp(coords[:,0], 0, input.size(1)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    # take clamp then floor/ceil of y coords\n    y = th.clamp(coords[:,1], 0, input.size(2)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n    # take clamp then floor/ceil of z coords\n    z = th.clamp(coords[:,2], 0, input.size(3)-2)\n    z0 = z.floor()\n    z1 = z0 + 1\n\n    stride = th.LongTensor(input.stride())[1:]\n    x0_ix = x0.mul(stride[0]).long()\n    x1_ix = x1.mul(stride[0]).long()\n    y0_ix = y0.mul(stride[1]).long()\n    y1_ix = y1.mul(stride[1]).long()\n    z0_ix = z0.mul(stride[2]).long()\n    z1_ix = z1.mul(stride[2]).long()\n\n    input_flat = th_flatten(input)\n\n    vals_000 = input_flat[x0_ix+y0_ix+z0_ix]\n    vals_100 = input_flat[x1_ix+y0_ix+z0_ix]\n    vals_010 = input_flat[x0_ix+y1_ix+z0_ix]\n    vals_001 = input_flat[x0_ix+y0_ix+z1_ix]\n    vals_101 = input_flat[x1_ix+y0_ix+z1_ix]\n    vals_011 = input_flat[x0_ix+y1_ix+z1_ix]\n    vals_110 = input_flat[x1_ix+y1_ix+z0_ix]\n    vals_111 = input_flat[x1_ix+y1_ix+z1_ix]\n\n    xd = x - x0\n    yd = y - y0\n    zd = z - z0\n    xm1 = 1 - xd\n    ym1 = 1 - yd\n    zm1 = 1 - zd\n\n    x_mapped = (vals_000.mul(xm1).mul(ym1).mul(zm1) +\n                vals_100.mul(xd).mul(ym1).mul(zm1) +\n                vals_010.mul(xm1).mul(yd).mul(zm1) +\n                vals_001.mul(xm1).mul(ym1).mul(zd) +\n                vals_101.mul(xd).mul(ym1).mul(zd) +\n                vals_011.mul(xm1).mul(yd).mul(zd) +\n                vals_110.mul(xd).mul(yd).mul(zm1) +\n                vals_111.mul(xd).mul(yd).mul(zd))\n\n    return x_mapped.view_as(input)\n\n\ndef th_pearsonr(x, y):\n    """"""\n    mimics scipy.stats.pearsonr\n    """"""\n    mean_x = th.mean(x)\n    mean_y = th.mean(y)\n    xm = x.sub(mean_x)\n    ym = y.sub(mean_y)\n    r_num = xm.dot(ym)\n    r_den = th.norm(xm, 2) * th.norm(ym, 2)\n    r_val = r_num / r_den\n    return r_val\n\n\ndef th_corrcoef(x):\n    """"""\n    mimics np.corrcoef\n    """"""\n    # calculate covariance matrix of rows\n    mean_x = th.mean(x, 1)\n    xm = x.sub(mean_x.expand_as(x))\n    c = xm.mm(xm.t())\n    c = c / (x.size(1) - 1)\n\n    # normalize covariance matrix\n    d = th.diag(c)\n    stddev = th.pow(d, 0.5)\n    c = c.div(stddev.expand_as(c))\n    c = c.div(stddev.expand_as(c).t())\n\n    # clamp between -1 and 1\n    c = th.clamp(c, -1.0, 1.0)\n\n    return c\n\n\ndef th_matrixcorr(x, y):\n    """"""\n    return a correlation matrix between\n    columns of x and columns of y.\n\n    So, if X.size() == (1000,4) and Y.size() == (1000,5),\n    then the result will be of size (4,5) with the\n    (i,j) value equal to the pearsonr correlation coeff\n    between column i in X and column j in Y\n    """"""\n    mean_x = th.mean(x, 0)\n    mean_y = th.mean(y, 0)\n    xm = x.sub(mean_x.expand_as(x))\n    ym = y.sub(mean_y.expand_as(y))\n    r_num = xm.t().mm(ym)\n    r_den1 = th.norm(xm,2,0)\n    r_den2 = th.norm(ym,2,0)\n    r_den = r_den1.t().mm(r_den2)\n    r_mat = r_num.div(r_den)\n    return r_mat\n\n\ndef th_random_choice(a, n_samples=1, replace=True, p=None):\n    """"""\n    Parameters\n    -----------\n    a : 1-D array-like\n        If a th.Tensor, a random sample is generated from its elements.\n        If an int, the random sample is generated as if a was th.range(n)\n    n_samples : int, optional\n        Number of samples to draw. Default is None, in which case a\n        single value is returned.\n    replace : boolean, optional\n        Whether the sample is with or without replacement\n    p : 1-D array-like, optional\n        The probabilities associated with each entry in a.\n        If not given the sample assumes a uniform distribution over all\n        entries in a.\n\n    Returns\n    --------\n    samples : 1-D ndarray, shape (size,)\n        The generated random samples\n    """"""\n    if isinstance(a, int):\n        a = th.arange(0, a)\n\n    if p is None:\n        if replace:\n            idx = th.floor(th.rand(n_samples)*a.size(0)).long()\n        else:\n            idx = th.randperm(len(a))[:n_samples]\n    else:\n        if abs(1.0-sum(p)) > 1e-3:\n            raise ValueError(\'p must sum to 1.0\')\n        if not replace:\n            raise ValueError(\'replace must equal true if probabilities given\')\n        idx_vec = th.cat([th.zeros(round(p[i]*1000))+i for i in range(len(p))])\n        idx = (th.floor(th.rand(n_samples)*999)).long()\n        idx = idx_vec[idx].long()\n    selection = a[idx]\n    if n_samples == 1:\n        selection = selection[0]\n    return selection\n\n\ndef save_transform(file, transform):\n    """"""\n    Save a transform object\n    """"""\n    with open(file, \'wb\') as output_file:\n        pickler = pickle.Pickler(output_file, -1)\n        pickler.dump(transform)\n\n\ndef load_transform(file):\n    """"""\n    Load a transform object\n    """"""\n    with open(file, \'rb\') as input_file:\n        transform = pickle.load(input_file)\n    return transform\n    \n\n\n    \n'"
torchsample/version.py,0,"b""__version__ = '0.1.3'\n"""
tests/transforms/test_affine_transforms.py,0,"b'""""""\nTest affine transforms\n\nTransforms:\n    - Affine + RandomAffine\n    - AffineCompose\n    - Rotate + RandomRotate\n    - Translate + RandomTranslate\n    - Shear + RandomShear\n    - Zoom + RandomZoom\n""""""\n\n#import pytest\n\nimport torch as th\n\nfrom torchsample.transforms import (RandomAffine, Affine,\n                        RandomRotate, RandomChoiceRotate, Rotate,\n                        RandomTranslate, RandomChoiceTranslate, Translate,\n                        RandomShear, RandomChoiceShear, Shear,\n                        RandomZoom, RandomChoiceZoom, Zoom)\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n## DATA SET ##\ndef gray2d_setup():\n    images = {}\n\n    x = th.zeros(1,30,30)\n    x[:,10:21,10:21] = 1\n    images[\'gray_01\'] = x\n\n    x = th.zeros(1,30,40)\n    x[:,10:21,10:21] = 1\n    images[\'gray_02\'] = x\n\n    return images\n\ndef multi_gray2d_setup():\n    old_imgs = gray2d_setup()\n    images = {}\n    for k,v in old_imgs.items():\n        images[k+\'_2imgs\'] = [v,v]\n        images[k+\'_3imgs\'] = [v,v,v]\n        images[k+\'_4imgs\'] = [v,v,v,v]\n    return images\n\ndef color2d_setup():\n    images = {}\n\n    x = th.zeros(3,30,30)\n    x[:,10:21,10:21] = 1\n    images[\'color_01\'] = x\n\n    x = th.zeros(3,30,40)\n    x[:,10:21,10:21] = 1\n    images[\'color_02\'] = x\n\n    return images\n\ndef multi_color2d_setup():\n    old_imgs = color2d_setup()\n    images = {}\n    for k,v in old_imgs.items():\n        images[k+\'_2imgs\'] = [v,v]\n        images[k+\'_3imgs\'] = [v,v,v]\n        images[k+\'_4imgs\'] = [v,v,v,v]\n    return images\n\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n\ndef Affine_setup():\n    tforms = {}\n    tforms[\'random_affine\'] = RandomAffine(rotation_range=30, \n                                           translation_range=0.1)\n    tforms[\'affine\'] = Affine(th.FloatTensor([[0.9,0,0],[0,0.9,0]]))\n    return tforms\n\ndef Rotate_setup():\n    tforms = {}\n    tforms[\'random_rotate\'] = RandomRotate(30)\n    tforms[\'random_choice_rotate\'] = RandomChoiceRotate([30,40,50])\n    tforms[\'rotate\'] = Rotate(30)\n    return tforms\n\ndef Translate_setup():\n    tforms = {}\n    tforms[\'random_translate\'] = RandomTranslate(0.1)\n    tforms[\'random_choice_translate\'] = RandomChoiceTranslate([0.1,0.2])\n    tforms[\'translate\'] = Translate(0.3)\n    return tforms\n\ndef Shear_setup():\n    tforms = {}\n    tforms[\'random_shear\'] = RandomShear(30)\n    tforms[\'random_choice_shear\'] = RandomChoiceShear([20,30,40])\n    tforms[\'shear\'] = Shear(25)\n    return tforms\n\ndef Zoom_setup():\n    tforms = {}\n    tforms[\'random_zoom\'] = RandomZoom((0.8,1.2))\n    tforms[\'random_choice_zoom\'] = RandomChoiceZoom([0.8,0.9,1.1,1.2])\n    tforms[\'zoom\'] = Zoom(0.9)\n    return tforms\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\ndef test_affine_transforms_runtime(verbose=1):\n    """"""\n    Test that there are no runtime errors\n    """"""\n    ### MAKE TRANSFORMS ###\n    tforms = {}\n    tforms.update(Affine_setup())\n    tforms.update(Rotate_setup())\n    tforms.update(Translate_setup())\n    tforms.update(Shear_setup())\n    tforms.update(Zoom_setup())\n\n    ### MAKE DATA\n    images = {}\n    images.update(gray2d_setup())\n    images.update(multi_gray2d_setup())\n    images.update(color2d_setup())\n    images.update(multi_color2d_setup())\n\n    successes = []\n    failures = []\n    for im_key, im_val in images.items():\n        for tf_key, tf_val in tforms.items():\n            try:\n                if isinstance(im_val, (tuple,list)):\n                    tf_val(*im_val)\n                else:\n                    tf_val(im_val)\n                successes.append((im_key, tf_key))\n            except:\n                failures.append((im_key, tf_key))\n\n    if verbose > 0:\n        for k, v in failures:\n            print(\'%s - %s\' % (k, v))\n\n    print(\'# SUCCESSES: \', len(successes))\n    print(\'# FAILURES: \' , len(failures))\n\n\nif __name__==\'__main__\':\n    test_affine_transforms_runtime()\n\n\n\n\n\n\n\n\n'"
tests/transforms/test_image_transforms.py,0,"b'""""""\nTests for torchsample/transforms/image_transforms.py\n""""""\n\n\nimport torch as th\n\nfrom torchsample.transforms import (Grayscale, RandomGrayscale,\n                    Gamma, RandomGamma, RandomChoiceGamma,\n                    Brightness, RandomBrightness, RandomChoiceBrightness,\n                    Saturation, RandomSaturation, RandomChoiceSaturation,\n                    Contrast, RandomContrast, RandomChoiceContrast)\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n## DATA SET ##\ndef gray2d_setup():\n    images = {}\n\n    x = th.zeros(1,30,30)\n    x[:,10:21,10:21] = 1\n    images[\'gray_01\'] = x\n\n    x = th.zeros(1,30,40)\n    x[:,10:21,10:21] = 1\n    images[\'gray_02\'] = x\n\n    return images\n\ndef multi_gray2d_setup():\n    old_imgs = gray2d_setup()\n    images = {}\n    for k,v in old_imgs.items():\n        images[k+\'_2imgs\'] = [v,v]\n        images[k+\'_3imgs\'] = [v,v,v]\n        images[k+\'_4imgs\'] = [v,v,v,v]\n    return images\n\ndef color2d_setup():\n    images = {}\n\n    x = th.zeros(3,30,30)\n    x[:,10:21,10:21] = 1\n    images[\'color_01\'] = x\n\n    x = th.zeros(3,30,40)\n    x[:,10:21,10:21] = 1\n    images[\'color_02\'] = x\n\n    return images\n\ndef multi_color2d_setup():\n    old_imgs = color2d_setup()\n    images = {}\n    for k,v in old_imgs.items():\n        images[k+\'_2imgs\'] = [v,v]\n        images[k+\'_3imgs\'] = [v,v,v]\n        images[k+\'_4imgs\'] = [v,v,v,v]\n    return images\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n## TFORMS SETUP ###\ndef Grayscale_setup():\n    tforms = {}\n    tforms[\'grayscale_keepchannels\'] = Grayscale(keep_channels=True)\n    tforms[\'grayscale_dontkeepchannels\'] = Grayscale(keep_channels=False)\n\n    tforms[\'random_grayscale_nop\'] = RandomGrayscale()\n    tforms[\'random_grayscale_p_01\'] = RandomGrayscale(0)\n    tforms[\'random_grayscale_p_02\'] = RandomGrayscale(0.5)\n    tforms[\'random_grayscale_p_03\'] = RandomGrayscale(1)\n\n    return tforms\n\ndef Gamma_setup():\n    tforms = {}\n    tforms[\'gamma_<1\'] = Gamma(value=0.5)\n    tforms[\'gamma_=1\'] = Gamma(value=1.0)\n    tforms[\'gamma_>1\'] = Gamma(value=1.5)\n    tforms[\'random_gamma_01\'] = RandomGamma(0.5,1.5)\n    tforms[\'random_gamma_02\'] = RandomGamma(0.5,1.0)\n    tforms[\'random_gamma_03\'] = RandomGamma(1.0,1.5)\n    tforms[\'random_choice_gamma_01\'] = RandomChoiceGamma([0.5,1.0])\n    tforms[\'random_choice_gamma_02\'] = RandomChoiceGamma([0.5,1.0],p=[0.5,0.5])\n    tforms[\'random_choice_gamma_03\'] = RandomChoiceGamma([0.5,1.0],p=[0.2,0.8])\n\n    return tforms\n\ndef Brightness_setup():\n    tforms = {}\n    tforms[\'brightness_=-1\'] = Brightness(value=-1)\n    tforms[\'brightness_<0\'] = Brightness(value=-0.5)\n    tforms[\'brightness_=0\'] = Brightness(value=0)\n    tforms[\'brightness_>0\'] = Brightness(value=0.5)\n    tforms[\'brightness_=1\'] = Brightness(value=1)\n\n    tforms[\'random_brightness_01\'] = RandomBrightness(-1,-0.5)\n    tforms[\'random_brightness_02\'] = RandomBrightness(-0.5,0)\n    tforms[\'random_brightness_03\'] = RandomBrightness(0,0.5)\n    tforms[\'random_brightness_04\'] = RandomBrightness(0.5,1)\n\n    tforms[\'random_choice_brightness_01\'] = RandomChoiceBrightness([-1,0,1])\n    tforms[\'random_choice_brightness_02\'] = RandomChoiceBrightness([-1,0,1],p=[0.2,0.5,0.3])\n    tforms[\'random_choice_brightness_03\'] = RandomChoiceBrightness([0,0,0,0],p=[0.25,0.5,0.25,0.25])\n\n    return tforms\n\ndef Saturation_setup():\n    tforms = {}\n    tforms[\'saturation_=-1\'] = Saturation(-1)\n    tforms[\'saturation_<0\'] = Saturation(-0.5)\n    tforms[\'saturation_=0\'] = Saturation(0)\n    tforms[\'saturation_>0\'] = Saturation(0.5)\n    tforms[\'saturation_=1\'] = Saturation(1)\n\n    tforms[\'random_saturation_01\'] = RandomSaturation(-1,-0.5)\n    tforms[\'random_saturation_02\'] = RandomSaturation(-0.5,0)\n    tforms[\'random_saturation_03\'] = RandomSaturation(0,0.5)\n    tforms[\'random_saturation_04\'] = RandomSaturation(0.5,1)\n\n    tforms[\'random_choice_saturation_01\'] = RandomChoiceSaturation([-1,0,1])\n    tforms[\'random_choice_saturation_02\'] = RandomChoiceSaturation([-1,0,1],p=[0.2,0.5,0.3])\n    tforms[\'random_choice_saturation_03\'] = RandomChoiceSaturation([0,0,0,0],p=[0.25,0.5,0.25,0.25])\n    \n    return tforms\n\ndef Contrast_setup():\n    tforms = {}\n    tforms[\'contrast_<<0\'] = Contrast(-10)\n    tforms[\'contrast_<0\'] = Contrast(-1)\n    tforms[\'contrast_=0\'] = Contrast(0)\n    tforms[\'contrast_>0\'] = Contrast(1)\n    tforms[\'contrast_>>0\'] = Contrast(10)\n\n    tforms[\'random_contrast_01\'] = RandomContrast(-10,-1)\n    tforms[\'random_contrast_02\'] = RandomContrast(-1,0)\n    tforms[\'random_contrast_03\'] = RandomContrast(0,1)\n    tforms[\'random_contrast_04\'] = RandomContrast(1,10)\n\n    tforms[\'random_choice_saturation_01\'] = RandomChoiceContrast([-1,0,1])\n    tforms[\'random_choice_saturation_02\'] = RandomChoiceContrast([-10,0,10],p=[0.2,0.5,0.3])\n    tforms[\'random_choice_saturation_03\'] = RandomChoiceContrast([1,1],p=[0.5,0.5])\n    \n    return tforms\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\ndef test_image_transforms_runtime(verbose=1):\n    """"""\n    Test that there are no runtime errors\n    """"""\n    ### MAKE TRANSFORMS ###\n    tforms = {}\n    tforms.update(Gamma_setup())\n    tforms.update(Brightness_setup())\n    tforms.update(Saturation_setup())\n    tforms.update(Contrast_setup())\n\n    ### MAKE DATA ###\n    images = {}\n    images.update(gray2d_setup())\n    images.update(multi_gray2d_setup())\n    images.update(color2d_setup())\n    images.update(multi_color2d_setup())\n\n    successes = []\n    failures = []\n    for im_key, im_val in images.items():\n        for tf_key, tf_val in tforms.items():\n            try:\n                if isinstance(im_val, (tuple,list)):\n                    tf_val(*im_val)\n                else:\n                    tf_val(im_val)\n                successes.append((im_key, tf_key))\n            except:\n                failures.append((im_key, tf_key))\n\n    if verbose > 0:\n        for k, v in failures:\n            print(\'%s - %s\' % (k, v))\n\n    print(\'# SUCCESSES: \', len(successes))\n    print(\'# FAILURES: \' , len(failures))\n\n\nif __name__==\'__main__\':\n    test_image_transforms_runtime()\n'"
tests/transforms/test_tensor_transforms.py,0,"b'""""""\nTests for torchsample/transforms/image_transforms.py\n""""""\n\n\nimport torch as th\n\nfrom torchsample.transforms import (ToTensor,\n                                    ToVariable,\n                                    ToCuda,\n                                    ToFile,\n                                    ChannelsLast, HWC,\n                                    ChannelsFirst, CHW,\n                                    TypeCast,\n                                    AddChannel,\n                                    Transpose,\n                                    RangeNormalize,\n                                    StdNormalize,\n                                    RandomCrop,\n                                    SpecialCrop,\n                                    Pad,\n                                    RandomFlip,\n                                    RandomOrder)\n\n# ----------------------------------------------------\n\n## DATA SET ##\ndef gray2d_setup():\n    images = {}\n\n    x = th.zeros(1,30,30)\n    x[:,10:21,10:21] = 1\n    images[\'gray_01\'] = x\n\n    x = th.zeros(1,30,40)\n    x[:,10:21,10:21] = 1\n    images[\'gray_02\'] = x\n    return images\n\ndef multi_gray2d_setup():\n    old_imgs = gray2d_setup()\n    images = {}\n    for k,v in old_imgs.items():\n        images[k+\'_2imgs\'] = [v,v]\n        images[k+\'_3imgs\'] = [v,v,v]\n        images[k+\'_4imgs\'] = [v,v,v,v]\n    return images\n\ndef color2d_setup():\n    images = {}\n\n    x = th.zeros(3,30,30)\n    x[:,10:21,10:21] = 1\n    images[\'color_01\'] = x\n\n    x = th.zeros(3,30,40)\n    x[:,10:21,10:21] = 1\n    images[\'color_02\'] = x\n\n    return images\n\ndef multi_color2d_setup():\n    old_imgs = color2d_setup()\n    images = {}\n    for k,v in old_imgs.items():\n        images[k+\'_2imgs\'] = [v,v]\n        images[k+\'_3imgs\'] = [v,v,v]\n        images[k+\'_4imgs\'] = [v,v,v,v]\n    return images\n# ----------------------------------------------------\n# ----------------------------------------------------\n\n## TFORMS SETUP ###\ndef ToTensor_setup():\n    tforms = {}\n\n    tforms[\'totensor\'] = ToTensor()\n\n    return tforms\n\ndef ToVariable_setup():\n    tforms = {}\n\n    tforms[\'tovariable\'] = ToVariable()\n\n    return tforms\n\ndef ToCuda_setup():\n    tforms = {}\n\n    tforms[\'tocuda\'] = ToCuda()\n\n    return tforms\n\ndef ToFile_setup():\n    tforms = {}\n\n    ROOT = \'~/desktop/data/\'\n    tforms[\'tofile_npy\'] = ToFile(root=ROOT, fmt=\'npy\')\n    tforms[\'tofile_pth\'] = ToFile(root=ROOT, fmt=\'pth\')\n    tforms[\'tofile_jpg\'] = ToFile(root=ROOT, fmt=\'jpg\')\n    tforms[\'tofile_png\'] = ToFile(root=ROOT, fmt=\'png\')\n\n    return tforms\n\ndef ChannelsLast_setup():\n    tforms = {}\n\n    tforms[\'channels_last\'] = ChannelsLast()\n    tforms[\'hwc\'] = HWC()\n\n    return tforms\n\ndef ChannelsFirst_setup():\n    tforms = {}\n\n    tforms[\'channels_first\'] = ChannelsFirst()\n    tforms[\'chw\'] = CHW()\n\n    return tforms\n\ndef TypeCast_setup():\n    tforms = {}\n\n    tforms[\'byte\'] = TypeCast(\'byte\')\n    tforms[\'double\'] = TypeCast(\'double\')\n    tforms[\'float\'] = TypeCast(\'float\')\n    tforms[\'int\'] = TypeCast(\'int\')\n    tforms[\'long\'] = TypeCast(\'long\')\n    tforms[\'short\'] = TypeCast(\'short\')\n\n    return tforms\n\ndef AddChannel_setup():\n    tforms = {}\n\n    tforms[\'addchannel_axis0\'] = AddChannel(axis=0)\n    tforms[\'addchannel_axis1\'] = AddChannel(axis=1)\n    tforms[\'addchannel_axis2\'] = AddChannel(axis=2)\n\n    return tforms\n\ndef Transpose_setup():\n    tforms = {}\n\n    tforms[\'transpose_01\'] = Transpose(0, 1)\n    tforms[\'transpose_02\'] = Transpose(0, 2)\n    tforms[\'transpose_10\'] = Transpose(1, 0)\n    tforms[\'transpose_12\'] = Transpose(1, 2)\n    tforms[\'transpose_20\'] = Transpose(2, 0)\n    tforms[\'transpose_21\'] = Transpose(2, 1)\n\n    return tforms\n\ndef RangeNormalize_setup():\n    tforms = {}\n\n    tforms[\'rangenorm_01\'] = RangeNormalize(0, 1)\n    tforms[\'rangenorm_-11\'] = RangeNormalize(-1, 1)\n    tforms[\'rangenorm_-33\'] = RangeNormalize(-3, 3)\n    tforms[\'rangenorm_02\'] = RangeNormalize(0, 2)\n\n    return tforms\n\ndef StdNormalize_setup():\n    tforms = {}\n\n    tforms[\'stdnorm\'] = StdNormalize()\n\n    return tforms\n\ndef RandomCrop_setup():\n    tforms = {}\n\n    tforms[\'randomcrop_1010\'] = RandomCrop((10,10))\n    tforms[\'randomcrop_510\'] = RandomCrop((5,10))\n    tforms[\'randomcrop_105\'] = RandomCrop((10,5))\n    tforms[\'randomcrop_99\'] = RandomCrop((9,9))\n    tforms[\'randomcrop_79\'] = RandomCrop((7,9))\n    tforms[\'randomcrop_97\'] = RandomCrop((9,7))\n\n    return tforms\n\ndef SpecialCrop_setup():\n    tforms = {}\n\n    tforms[\'specialcrop_0_1010\'] = SpecialCrop((10,10),0)\n    tforms[\'specialcrop_0_510\'] = SpecialCrop((5,10),0)\n    tforms[\'specialcrop_0_105\'] = SpecialCrop((10,5),0)\n    tforms[\'specialcrop_0_99\'] = SpecialCrop((9,9),0)\n    tforms[\'specialcrop_0_79\'] = SpecialCrop((7,9),0)\n    tforms[\'specialcrop_0_97\'] = SpecialCrop((9,7),0)\n\n    tforms[\'specialcrop_1_1010\'] = SpecialCrop((10,10),1)\n    tforms[\'specialcrop_1_510\'] = SpecialCrop((5,10),1)\n    tforms[\'specialcrop_1_105\'] = SpecialCrop((10,5),1)\n    tforms[\'specialcrop_1_99\'] = SpecialCrop((9,9),1)\n    tforms[\'specialcrop_1_79\'] = SpecialCrop((7,9),1)\n    tforms[\'specialcrop_1_97\'] = SpecialCrop((9,7),1)\n\n    tforms[\'specialcrop_2_1010\'] = SpecialCrop((10,10),2)\n    tforms[\'specialcrop_2_510\'] = SpecialCrop((5,10),2)\n    tforms[\'specialcrop_2_105\'] = SpecialCrop((10,5),2)\n    tforms[\'specialcrop_2_99\'] = SpecialCrop((9,9),2)\n    tforms[\'specialcrop_2_79\'] = SpecialCrop((7,9),2)\n    tforms[\'specialcrop_2_97\'] = SpecialCrop((9,7),2)\n\n    tforms[\'specialcrop_3_1010\'] = SpecialCrop((10,10),3)\n    tforms[\'specialcrop_3_510\'] = SpecialCrop((5,10),3)\n    tforms[\'specialcrop_3_105\'] = SpecialCrop((10,5),3)\n    tforms[\'specialcrop_3_99\'] = SpecialCrop((9,9),3)\n    tforms[\'specialcrop_3_79\'] = SpecialCrop((7,9),3)\n    tforms[\'specialcrop_3_97\'] = SpecialCrop((9,7),3)\n\n    tforms[\'specialcrop_4_1010\'] = SpecialCrop((10,10),4)\n    tforms[\'specialcrop_4_510\'] = SpecialCrop((5,10),4)\n    tforms[\'specialcrop_4_105\'] = SpecialCrop((10,5),4)\n    tforms[\'specialcrop_4_99\'] = SpecialCrop((9,9),4)\n    tforms[\'specialcrop_4_79\'] = SpecialCrop((7,9),4)\n    tforms[\'specialcrop_4_97\'] = SpecialCrop((9,7),4)\n    return tforms\n\ndef Pad_setup():\n    tforms = {}\n\n    tforms[\'pad_4040\'] = Pad((40,40))\n    tforms[\'pad_3040\'] = Pad((30,40))\n    tforms[\'pad_4030\'] = Pad((40,30))\n    tforms[\'pad_3939\'] = Pad((39,39))\n    tforms[\'pad_3941\'] = Pad((39,41))\n    tforms[\'pad_4139\'] = Pad((41,39))\n    tforms[\'pad_4138\'] = Pad((41,38))\n    tforms[\'pad_3841\'] = Pad((38,41))\n\n    return tforms\n\ndef RandomFlip_setup():\n    tforms = {}\n\n    tforms[\'randomflip_h_01\'] = RandomFlip(h=True, v=False)\n    tforms[\'randomflip_h_02\'] = RandomFlip(h=True, v=False, p=0)\n    tforms[\'randomflip_h_03\'] = RandomFlip(h=True, v=False, p=1)\n    tforms[\'randomflip_h_04\'] = RandomFlip(h=True, v=False, p=0.3)\n    tforms[\'randomflip_v_01\'] = RandomFlip(h=False, v=True)\n    tforms[\'randomflip_v_02\'] = RandomFlip(h=False, v=True, p=0)\n    tforms[\'randomflip_v_03\'] = RandomFlip(h=False, v=True, p=1)\n    tforms[\'randomflip_v_04\'] = RandomFlip(h=False, v=True, p=0.3)\n    tforms[\'randomflip_hv_01\'] = RandomFlip(h=True, v=True)\n    tforms[\'randomflip_hv_02\'] = RandomFlip(h=True, v=True, p=0)\n    tforms[\'randomflip_hv_03\'] = RandomFlip(h=True, v=True, p=1)\n    tforms[\'randomflip_hv_04\'] = RandomFlip(h=True, v=True, p=0.3)\n    return tforms\n\ndef RandomOrder_setup():\n    tforms = {}\n\n    tforms[\'randomorder\'] = RandomOrder()\n\n    return tforms\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\ndef test_image_transforms_runtime(verbose=1):\n    ### MAKE TRANSFORMS ###\n    tforms = {}\n    tforms.update(ToTensor_setup())\n    tforms.update(ToVariable_setup())\n    tforms.update(ToCuda_setup())\n    #tforms.update(ToFile_setup())\n    tforms.update(ChannelsLast_setup())\n    tforms.update(ChannelsFirst_setup())\n    tforms.update(TypeCast_setup())\n    tforms.update(AddChannel_setup())\n    tforms.update(Transpose_setup())\n    tforms.update(RangeNormalize_setup())\n    tforms.update(StdNormalize_setup())\n    tforms.update(RandomCrop_setup())\n    tforms.update(SpecialCrop_setup())\n    tforms.update(Pad_setup())\n    tforms.update(RandomFlip_setup())\n    tforms.update(RandomOrder_setup())\n\n\n    ### MAKE DATA\n    images = {}\n    images.update(gray2d_setup())\n    images.update(multi_gray2d_setup())\n    images.update(color2d_setup())\n    images.update(multi_color2d_setup())\n\n    successes =[]\n    failures = []\n    for im_key, im_val in images.items():\n        for tf_key, tf_val in tforms.items():\n            try:\n                if isinstance(im_val, (tuple,list)):\n                    tf_val(*im_val)\n                else:\n                    tf_val(im_val)\n                successes.append((im_key, tf_key))\n            except:\n                failures.append((im_key, tf_key))\n\n    if verbose > 0:\n        for k, v in failures:\n            print(\'%s - %s\' % (k, v))\n\n    print(\'# SUCCESSES: \', len(successes))\n    print(\'# FAILURES: \' , len(failures))\n\n\nif __name__==\'__main__\':\n    test_image_transforms_runtime()\n'"
torchsample/functions/__init__.py,0,b'\nfrom .affine import *'
torchsample/functions/affine.py,36,"b'\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nfrom ..utils import th_iterproduct, th_flatten\n\n\ndef F_affine2d(x, matrix, center=True):\n    """"""\n    2D Affine image transform on torch.autograd.Variable\n    """"""\n    if matrix.dim() == 2:\n        matrix = matrix.view(-1,2,3)\n\n    A_batch = matrix[:,:,:2]\n    if A_batch.size(0) != x.size(0):\n        A_batch = A_batch.repeat(x.size(0),1,1)\n    b_batch = matrix[:,:,2].unsqueeze(1)\n\n    # make a meshgrid of normal coordinates\n    _coords = th_iterproduct(x.size(1),x.size(2))\n    coords = Variable(_coords.unsqueeze(0).repeat(x.size(0),1,1).float(),\n                    requires_grad=False)\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,:,0] = coords[:,:,0] - (x.size(1) / 2. + 0.5)\n        coords[:,:,1] = coords[:,:,1] - (x.size(2) / 2. + 0.5)\n\n    # apply the coordinate transformation\n    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(1) / 2. + 0.5)\n        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(2) / 2. + 0.5)\n\n    # map new coordinates using bilinear interpolation\n    x_transformed = F_bilinear_interp2d(x, new_coords)\n\n    return x_transformed\n\n\ndef F_bilinear_interp2d(input, coords):\n    """"""\n    bilinear interpolation of 2d torch.autograd.Variable\n    """"""\n    x = torch.clamp(coords[:,:,0], 0, input.size(1)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    y = torch.clamp(coords[:,:,1], 0, input.size(2)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n\n    stride = torch.LongTensor(input.stride())\n    x0_ix = x0.mul(stride[1]).long()\n    x1_ix = x1.mul(stride[1]).long()\n    y0_ix = y0.mul(stride[2]).long()\n    y1_ix = y1.mul(stride[2]).long()\n\n    input_flat = input.view(input.size(0),-1).contiguous()\n\n    vals_00 = input_flat.gather(1, x0_ix.add(y0_ix).detach())\n    vals_10 = input_flat.gather(1, x1_ix.add(y0_ix).detach())\n    vals_01 = input_flat.gather(1, x0_ix.add(y1_ix).detach())\n    vals_11 = input_flat.gather(1, x1_ix.add(y1_ix).detach())\n    \n    xd = x - x0\n    yd = y - y0\n    xm = 1 - xd\n    ym = 1 - yd\n\n    x_mapped = (vals_00.mul(xm).mul(ym) +\n                vals_10.mul(xd).mul(ym) +\n                vals_01.mul(xm).mul(yd) +\n                vals_11.mul(xd).mul(yd))\n\n    return x_mapped.view_as(input)\n\n\ndef F_batch_affine2d(x, matrix, center=True):\n    """"""\n\n    x : torch.Tensor\n        shape = (Samples, C, H, W)\n        NOTE: Assume C is always equal to 1!\n    matrix : torch.Tensor\n        shape = (Samples, 6) or (Samples, 2, 3)\n\n    Example\n    -------\n    >>> x = Variable(torch.zeros(3,1,10,10))\n    >>> x[:,:,3:7,3:7] = 1\n    >>> m1 = torch.FloatTensor([[1.2,0,0],[0,1.2,0]])\n    >>> m2 = torch.FloatTensor([[0.8,0,0],[0,0.8,0]])\n    >>> m3 = torch.FloatTensor([[1.0,0,3],[0,1.0,3]])\n    >>> matrix = Variable(torch.stack([m1,m2,m3]))\n    >>> xx = F_batch_affine2d(x,matrix)\n    """"""\n    if matrix.dim() == 2:\n        matrix = matrix.view(-1,2,3)\n\n    A_batch = matrix[:,:,:2]\n    b_batch = matrix[:,:,2].unsqueeze(1)\n\n    # make a meshgrid of normal coordinates\n    _coords = th_iterproduct(x.size(2),x.size(3))\n    coords = Variable(_coords.unsqueeze(0).repeat(x.size(0),1,1).float(),\n                requires_grad=False)\n\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,:,0] = coords[:,:,0] - (x.size(2) / 2. + 0.5)\n        coords[:,:,1] = coords[:,:,1] - (x.size(3) / 2. + 0.5)\n    \n    # apply the coordinate transformation\n    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(2) / 2. + 0.5)\n        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(3) / 2. + 0.5)\n\n    # map new coordinates using bilinear interpolation\n    x_transformed = F_batch_bilinear_interp2d(x, new_coords)\n\n    return x_transformed\n\n\ndef F_batch_bilinear_interp2d(input, coords):\n    """"""\n    input : torch.Tensor\n        size = (N,H,W,C)\n    coords : torch.Tensor\n        size = (N,H*W*C,2)\n    """"""\n    x = torch.clamp(coords[:,:,0], 0, input.size(2)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    y = torch.clamp(coords[:,:,1], 0, input.size(3)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n\n    stride = torch.LongTensor(input.stride())\n    x0_ix = x0.mul(stride[2]).long()\n    x1_ix = x1.mul(stride[2]).long()\n    y0_ix = y0.mul(stride[3]).long()\n    y1_ix = y1.mul(stride[3]).long()\n\n    input_flat = input.view(input.size(0),-1).contiguous()\n\n    vals_00 = input_flat.gather(1, x0_ix.add(y0_ix).detach())\n    vals_10 = input_flat.gather(1, x1_ix.add(y0_ix).detach())\n    vals_01 = input_flat.gather(1, x0_ix.add(y1_ix).detach())\n    vals_11 = input_flat.gather(1, x1_ix.add(y1_ix).detach())\n    \n    xd = x - x0\n    yd = y - y0\n    xm = 1 - xd\n    ym = 1 - yd\n\n    x_mapped = (vals_00.mul(xm).mul(ym) +\n                vals_10.mul(xd).mul(ym) +\n                vals_01.mul(xm).mul(yd) +\n                vals_11.mul(xd).mul(yd))\n\n    return x_mapped.view_as(input)\n\n\ndef F_affine3d(x, matrix, center=True):\n    A = matrix[:3,:3]\n    b = matrix[:3,3]\n\n    # make a meshgrid of normal coordinates\n    coords = Variable(th_iterproduct(x.size(1),x.size(2),x.size(3)).float(),\n                requires_grad=False)\n\n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,0] = coords[:,0] - (x.size(1) / 2. + 0.5)\n        coords[:,1] = coords[:,1] - (x.size(2) / 2. + 0.5)\n        coords[:,2] = coords[:,2] - (x.size(3) / 2. + 0.5)\n\n    \n    # apply the coordinate transformation\n    new_coords = F.linear(coords, A, b)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,0] = new_coords[:,0] + (x.size(1) / 2. + 0.5)\n        new_coords[:,1] = new_coords[:,1] + (x.size(2) / 2. + 0.5)\n        new_coords[:,2] = new_coords[:,2] + (x.size(3) / 2. + 0.5)\n\n    # map new coordinates using bilinear interpolation\n    x_transformed = F_trilinear_interp3d(x, new_coords)\n\n    return x_transformed\n\n\ndef F_trilinear_interp3d(input, coords):\n    """"""\n    trilinear interpolation of 3D image\n    """"""\n    # take clamp then floor/ceil of x coords\n    x = torch.clamp(coords[:,0], 0, input.size(1)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    # take clamp then floor/ceil of y coords\n    y = torch.clamp(coords[:,1], 0, input.size(2)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n    # take clamp then floor/ceil of z coords\n    z = torch.clamp(coords[:,2], 0, input.size(3)-2)\n    z0 = z.floor()\n    z1 = z0 + 1\n\n    stride = torch.LongTensor(input.stride())[1:]\n    x0_ix = x0.mul(stride[0]).long()\n    x1_ix = x1.mul(stride[0]).long()\n    y0_ix = y0.mul(stride[1]).long()\n    y1_ix = y1.mul(stride[1]).long()\n    z0_ix = z0.mul(stride[2]).long()\n    z1_ix = z1.mul(stride[2]).long()\n\n    input_flat = th_flatten(input)\n\n    vals_000 = input_flat[x0_ix.add(y0_ix).add(z0_ix).detach()]\n    vals_100 = input_flat[x1_ix.add(y0_ix).add(z0_ix).detach()]\n    vals_010 = input_flat[x0_ix.add(y1_ix).add(z0_ix).detach()]\n    vals_001 = input_flat[x0_ix.add(y0_ix).add(z1_ix).detach()]\n    vals_101 = input_flat[x1_ix.add(y0_ix).add(z1_ix).detach()]\n    vals_011 = input_flat[x0_ix.add(y1_ix).add(z1_ix).detach()]\n    vals_110 = input_flat[x1_ix.add(y1_ix).add(z0_ix).detach()]\n    vals_111 = input_flat[x1_ix.add(y1_ix).add(z1_ix).detach()]\n\n    xd = x - x0\n    yd = y - y0\n    zd = z - z0\n    xm = 1 - xd\n    ym = 1 - yd\n    zm = 1 - zd\n\n    x_mapped = (vals_000.mul(xm).mul(ym).mul(zm) +\n                vals_100.mul(xd).mul(ym).mul(zm) +\n                vals_010.mul(xm).mul(yd).mul(zm) +\n                vals_001.mul(xm).mul(ym).mul(zd) +\n                vals_101.mul(xd).mul(ym).mul(zd) +\n                vals_011.mul(xm).mul(yd).mul(zd) +\n                vals_110.mul(xd).mul(yd).mul(zm) +\n                vals_111.mul(xd).mul(yd).mul(zd))\n\n    return x_mapped.view_as(input)\n\n\ndef F_batch_affine3d(x, matrix, center=True):\n    """"""\n\n    x : torch.Tensor\n        shape = (Samples, C, H, W)\n        NOTE: Assume C is always equal to 1!\n    matrix : torch.Tensor\n        shape = (Samples, 6) or (Samples, 2, 3)\n\n    Example\n    -------\n    >>> x = Variable(torch.zeros(3,1,10,10,10))\n    >>> x[:,:,3:7,3:7,3:7] = 1\n    >>> m1 = torch.FloatTensor([[1.2,0,0,0],[0,1.2,0,0],[0,0,1.2,0]])\n    >>> m2 = torch.FloatTensor([[0.8,0,0,0],[0,0.8,0,0],[0,0,0.8,0]])\n    >>> m3 = torch.FloatTensor([[1.0,0,0,3],[0,1.0,0,3],[0,0,1.0,3]])\n    >>> matrix = Variable(torch.stack([m1,m2,m3]))\n    >>> xx = F_batch_affine3d(x,matrix)\n    """"""\n    if matrix.dim() == 2:\n        matrix = matrix.view(-1,3,4)\n\n    A_batch = matrix[:,:3,:3]\n    b_batch = matrix[:,:3,3].unsqueeze(1)\n\n    # make a meshgrid of normal coordinates\n    _coords = th_iterproduct(x.size(2),x.size(3),x.size(4))\n    coords = Variable(_coords.unsqueeze(0).repeat(x.size(0),1,1).float(),\n                requires_grad=False)\n    \n    if center:\n        # shift the coordinates so center is the origin\n        coords[:,:,0] = coords[:,:,0] - (x.size(2) / 2. + 0.5)\n        coords[:,:,1] = coords[:,:,1] - (x.size(3) / 2. + 0.5)\n        coords[:,:,2] = coords[:,:,2] - (x.size(4) / 2. + 0.5)\n    \n    # apply the coordinate transformation\n    new_coords = coords.bmm(A_batch.transpose(1,2)) + b_batch.expand_as(coords)\n\n    if center:\n        # shift the coordinates back so origin is origin\n        new_coords[:,:,0] = new_coords[:,:,0] + (x.size(2) / 2. + 0.5)\n        new_coords[:,:,1] = new_coords[:,:,1] + (x.size(3) / 2. + 0.5)\n        new_coords[:,:,2] = new_coords[:,:,2] + (x.size(4) / 2. + 0.5)\n\n    # map new coordinates using bilinear interpolation\n    x_transformed = F_batch_trilinear_interp3d(x, new_coords)\n\n    return x_transformed\n\n\ndef F_batch_trilinear_interp3d(input, coords):\n    """"""\n    input : torch.Tensor\n        size = (N,H,W,C)\n    coords : torch.Tensor\n        size = (N,H*W*C,2)\n    """"""\n    x = torch.clamp(coords[:,:,0], 0, input.size(2)-2)\n    x0 = x.floor()\n    x1 = x0 + 1\n    y = torch.clamp(coords[:,:,1], 0, input.size(3)-2)\n    y0 = y.floor()\n    y1 = y0 + 1\n    z = torch.clamp(coords[:,:,2], 0, input.size(4)-2)\n    z0 = z.floor()\n    z1 = z0 + 1\n\n    stride = torch.LongTensor(input.stride())\n    x0_ix = x0.mul(stride[2]).long()\n    x1_ix = x1.mul(stride[2]).long()\n    y0_ix = y0.mul(stride[3]).long()\n    y1_ix = y1.mul(stride[3]).long()\n    z0_ix = z0.mul(stride[4]).long()\n    z1_ix = z1.mul(stride[4]).long()\n\n    input_flat = input.contiguous().view(input.size(0),-1)\n\n    vals_000 = input_flat.gather(1,x0_ix.add(y0_ix).add(z0_ix).detach())\n    vals_100 = input_flat.gather(1,x1_ix.add(y0_ix).add(z0_ix).detach())\n    vals_010 = input_flat.gather(1,x0_ix.add(y1_ix).add(z0_ix).detach())\n    vals_001 = input_flat.gather(1,x0_ix.add(y0_ix).add(z1_ix).detach())\n    vals_101 = input_flat.gather(1,x1_ix.add(y0_ix).add(z1_ix).detach())\n    vals_011 = input_flat.gather(1,x0_ix.add(y1_ix).add(z1_ix).detach())\n    vals_110 = input_flat.gather(1,x1_ix.add(y1_ix).add(z0_ix).detach())\n    vals_111 = input_flat.gather(1,x1_ix.add(y1_ix).add(z1_ix).detach())\n\n    xd = x - x0\n    yd = y - y0\n    zd = z - z0\n    xm = 1 - xd\n    ym = 1 - yd\n    zm = 1 - zd\n\n    x_mapped = (vals_000.mul(xm).mul(ym).mul(zm) +\n                vals_100.mul(xd).mul(ym).mul(zm) +\n                vals_010.mul(xm).mul(yd).mul(zm) +\n                vals_001.mul(xm).mul(ym).mul(zd) +\n                vals_101.mul(xd).mul(ym).mul(zd) +\n                vals_011.mul(xm).mul(yd).mul(zd) +\n                vals_110.mul(xd).mul(yd).mul(zm) +\n                vals_111.mul(xd).mul(yd).mul(zd))\n\n    return x_mapped.view_as(input)\n\n\n'"
torchsample/modules/__init__.py,0,b'from __future__ import absolute_import\n\nfrom .module_trainer import ModuleTrainer\n'
torchsample/modules/_utils.py,2,"b'\nimport datetime\nimport warnings\n\ntry:\n    from inspect import signature\nexcept:\n    warnings.warn(\'inspect.signature not available... \'\n        \'you should upgrade to Python 3.x\')\n\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom ..metrics import Metric, CategoricalAccuracy, BinaryAccuracy\nfrom ..initializers import GeneralInitializer\n\ndef _add_regularizer_to_loss_fn(loss_fn, \n                                regularizer_container):\n    def new_loss_fn(output_batch, target_batch):\n        return loss_fn(output_batch, target_batch) + regularizer_container.get_value()\n    return new_loss_fn\n\ndef _is_iterable(x):\n    return isinstance(x, (tuple, list))\ndef _is_tuple_or_list(x):\n    return isinstance(x, (tuple, list))\n\ndef _parse_num_inputs_and_targets_from_loader(loader):\n    """""" NOT IMPLEMENTED """"""\n    #batch = next(iter(loader))\n    num_inputs = loader.dataset.num_inputs\n    num_targets = loader.dataset.num_targets\n    return num_inputs, num_targets\n\ndef _parse_num_inputs_and_targets(inputs, targets=None):\n    if isinstance(inputs, (list, tuple)):\n        num_inputs = len(inputs)\n    else:\n        num_inputs = 1\n    if targets is not None:\n        if isinstance(targets, (list, tuple)):\n            num_targets = len(targets)\n        else:\n            num_targets = 1\n    else:\n        num_targets = 0\n    return num_inputs, num_targets\n\ndef _standardize_user_data(inputs, targets=None):\n    if not isinstance(inputs, (list,tuple)):\n        inputs = [inputs]\n    if targets is not None:\n        if not isinstance(targets, (list,tuple)):\n            targets = [targets]\n        return inputs, targets\n    else:\n        return inputs\n\ndef _validate_metric_input(metric):\n    if isinstance(metric, str):\n        if metric.upper() == \'CATEGORICAL_ACCURACY\' or metric.upper() == \'ACCURACY\':\n            return CategoricalAccuracy()\n        elif metric.upper() == \'BINARY_ACCURACY\':\n            return BinaryAccuracy()\n        else:\n            raise ValueError(\'Invalid metric string input - must match pytorch function.\')\n    elif isinstance(metric, Metric):\n        return metric\n    else:\n        raise ValueError(\'Invalid metric input\')\n\ndef _validate_loss_input(loss):\n    dir_f = dir(F)\n    loss_fns = [d.lower() for d in dir_f]\n    if isinstance(loss, str):\n        if loss.lower() == \'unconstrained\':\n            return lambda x: x\n        elif loss.lower() == \'unconstrained_sum\':\n            return lambda x: x.sum()\n        elif loss.lower() == \'unconstrained_mean\':\n            return lambda x: x.mean()\n        else:\n            try:\n                str_idx = loss_fns.index(loss.lower())\n            except:\n                raise ValueError(\'Invalid loss string input - must match pytorch function.\')\n            return getattr(F, dir(F)[str_idx])\n    elif callable(loss):\n        return loss\n    else:\n        raise ValueError(\'Invalid loss input\')\n\ndef _validate_optimizer_input(optimizer):\n    dir_optim = dir(optim)\n    opts = [o.lower() for o in dir_optim]\n    if isinstance(optimizer, str):\n        try:\n            str_idx = opts.index(optimizer.lower())    \n        except:\n            raise ValueError(\'Invalid optimizer string input - must match pytorch function.\')\n        return getattr(optim, dir_optim[str_idx])\n    elif hasattr(optimizer, \'step\') and hasattr(optimizer, \'zero_grad\'):\n        return optimizer\n    else:\n        raise ValueError(\'Invalid optimizer input\')\n\ndef _validate_initializer_input(initializer):\n    if isinstance(initializer, str):\n        try:\n            initializer = GeneralInitializer(initializer)\n        except:\n            raise ValueError(\'Invalid initializer string input - must match pytorch function.\')\n        return initializer\n    elif callable(initializer):\n        return initializer\n    else:\n        raise ValueError(\'Invalid optimizer input\')\n\ndef _get_current_time():\n    return datetime.datetime.now().strftime(""%B %d, %Y - %I:%M%p"")\n\ndef _nb_function_args(fn):\n    return len(signature(fn).parameters)'"
torchsample/modules/module_trainer.py,3,"b'""""""\nModuleTrainer for high level training on Pytorch models\n""""""\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport warnings\nimport functools\nimport math\nfrom collections import OrderedDict\n\nimport torch as th\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n# local imports\nfrom ._utils import (_validate_loss_input, _validate_metric_input,\n                     _validate_optimizer_input, _validate_initializer_input,\n                     _standardize_user_data, _parse_num_inputs_and_targets,\n                     _is_tuple_or_list, _parse_num_inputs_and_targets_from_loader,\n                     _add_regularizer_to_loss_fn)\n\nfrom ..callbacks import CallbackContainer, History, TQDM\nfrom ..regularizers import RegularizerContainer, RegularizerCallback\nfrom ..initializers import InitializerContainer\nfrom ..constraints import ConstraintContainer, ConstraintCallback\nfrom ..metrics import MetricContainer, MetricCallback\n\nfrom tqdm import tqdm\n\n\nclass ModuleTrainer(object):\n\n    def __init__(self, model):\n        """"""\n        ModelTrainer for high-level training of Pytorch models\n\n        Major Parts\n        -----------\n        - optimizer(s)\n        - loss(es)\n        - regularizers\n        - initializers\n        - constraints\n        - metrics\n        - callbacks\n        """"""\n        if not isinstance(model, nn.Module):\n            raise ValueError(\'model argument must inherit from torch.nn.Module\')\n        self.model = model\n\n        # callbacks\n        self._callbacks = []\n\n        # regularizers\n        self._regularizers = []\n        self._has_regularizers = False\n\n        # initializers\n        self._initializers = []\n\n        # constraints\n        self._constraints = []\n        self._has_constraints = False\n\n        # metrics\n        self._metrics = []\n        self._has_metrics = False\n\n        # transforms\n        self._transforms = []\n        self._has_transforms = False\n\n        # losses\n        self._loss = None\n        self._loss_fn = None\n\n        # other properties\n        self._stop_training = False\n\n    def set_loss(self, loss):\n        self._loss = loss\n        if _is_tuple_or_list(loss):\n            self._loss_fn = [_validate_loss_input(l) for l in loss]\n        else:\n            self._loss_fn = _validate_loss_input(loss)\n\n    def set_optimizer(self, optimizer, **kwargs):\n        if type(optimizer) is type or isinstance(optimizer, str):\n            if \'parameters\' in kwargs:\n                parameters = kwargs[\'parameters\']\n            else:\n                parameters = self.model.parameters()\n\n            optimizer = _validate_optimizer_input(optimizer)\n            self._optimizer = optimizer(parameters, **kwargs)\n        else:\n            self._optimizer = optimizer\n\n    def set_callbacks(self, callbacks):\n        if not _is_tuple_or_list(callbacks):\n            callbacks = [callbacks]\n        self._callbacks = [self.history] + callbacks\n\n    def set_regularizers(self, regularizers):\n        regularizers = [regularizers] if not _is_tuple_or_list(regularizers) else regularizers\n        self._regularizers = regularizers\n        self._has_regularizers = True\n\n    def set_initializers(self, initializers):\n        initializers = [initializers] if not _is_tuple_or_list(initializers) else initializers\n        initializers = [_validate_initializer_input(it) for it in initializers]\n        self._initializers = initializers\n\n    def set_constraints(self, constraints):\n        constraints = [constraints] if not _is_tuple_or_list(constraints) else constraints\n        self._has_constraints = True\n        self._constraints = constraints\n\n    def set_metrics(self, metrics):\n        metrics = [metrics] if not _is_tuple_or_list(metrics) else metrics\n        metrics = [_validate_metric_input(m) for m in metrics]\n        self._has_metrics = True\n        self._metrics = metrics\n\n    def set_transforms(self, transforms):\n        if not _is_tuple_or_list(transforms):\n            transforms = (transforms, lambda x: x, lambda x,y: (x,y))\n        if len(transforms) == 1:\n            transforms = (transforms, lambda x: x, lambda x,y: (x,y))\n        elif len(transforms) == 2:\n            transforms = (transforms, transforms, lambda x,y: (x,y))\n\n        self._has_input_transform = transforms[0] is not None\n        self._has_target_transform = transforms[1] is not None\n        self._has_co_transform = transforms[2] is not None\n\n        self._has_transforms = True\n        self._transforms = transforms\n\n    def compile(self,\n                optimizer,\n                loss,\n                callbacks=None,\n                regularizers=None,\n                initializers=None,\n                constraints=None,\n                metrics=None,\n                transforms=None):\n        self.set_optimizer(optimizer)\n        self.set_loss(loss)\n\n        if regularizers is not None:\n            self.set_regularizers(regularizers)\n            self.regularizer_container = RegularizerContainer(self._regularizers)\n            self.regularizer_container.register_forward_hooks(self.model)\n        else:\n            self._has_regularizers = False\n\n        self.history = History(self)\n        self._callbacks = [self.history]\n        if callbacks is not None:\n            self.set_callbacks(callbacks)\n\n\n        if initializers is not None:\n            self.set_initializers(initializers)\n            self.initializer_container = InitializerContainer(self._initializers)\n            # actually initialize the model\n            self.initializer_container.apply(self.model)\n\n        if constraints is not None:\n            self.set_constraints(constraints)\n            self.constraint_container = ConstraintContainer(self._constraints)\n            self.constraint_container.register_constraints(self.model)\n        else:\n            self._has_constraints = False\n\n        if metrics is not None:\n            self.set_metrics(metrics)\n            self.metric_container = MetricContainer(self._metrics)\n        else:\n            self._has_metrics = False\n        \n        if transforms is not None:\n            self.set_transforms(transforms)\n        else:\n            self._has_transforms = False\n\n    def fit(self,\n            inputs,\n            targets=None,\n            val_data=None,\n            initial_epoch=0,\n            num_epoch=100,\n            batch_size=32,\n            shuffle=False,\n            cuda_device=-1,\n            verbose=1):\n        """"""\n        Fit a model on in-memory tensors using ModuleTrainer\n        """"""\n        self.model.train(True)\n        # ----------------------------------------------------------------------\n        num_inputs, num_targets = _parse_num_inputs_and_targets(inputs, targets)\n        len_inputs = len(inputs) if not _is_tuple_or_list(inputs) else len(inputs[0])\n        \n        if val_data is not None:\n            if num_targets == 0:\n                val_data = (val_data, None)\n            if len(val_data) != 2:\n                raise Exception(\'val_data must be a 2-tuple\')\n            num_val_inputs, num_val_targets = _parse_num_inputs_and_targets(val_data[0], val_data[1])\n            if (num_inputs != num_val_inputs) or (num_targets != num_val_targets):\n                raise Exception(\'The number of input/target tensors must be the same for training and validation data\\n\'\n                                 \'Num Input tensors: (%i train, %i val), Num Target tensors: (%i train, %i val)\' % (num_inputs, num_val_inputs, num_targets, num_val_targets) )\n            val_inputs, val_targets = val_data\n        has_val_data = val_data is not None\n        num_batches = int(math.ceil(len_inputs / batch_size))\n        # ----------------------------------------------------------------------\n\n        fit_helper = _get_helper(self, num_inputs, num_targets)\n        fit_loss_fn = fit_helper.get_partial_loss_fn(self._loss_fn)\n        fit_forward_fn = fit_helper.get_partial_forward_fn(self.model)\n\n        with TQDM() as pbar:\n            tmp_callbacks = []\n            if verbose > 0:\n                tmp_callbacks.append(pbar)\n            if self._has_regularizers:\n                tmp_callbacks.append(RegularizerCallback(self.regularizer_container))\n                fit_loss_fn = _add_regularizer_to_loss_fn(fit_loss_fn,\n                                                          self.regularizer_container)\n            if self._has_constraints:\n                tmp_callbacks.append(ConstraintCallback(self.constraint_container))\n            if self._has_metrics:\n                self.metric_container.set_helper(fit_helper)\n                tmp_callbacks.append(MetricCallback(self.metric_container))\n\n            callback_container = CallbackContainer(self._callbacks+tmp_callbacks)\n            callback_container.set_trainer(self)\n            callback_container.on_train_begin({\'batch_size\': batch_size,\n                                               \'num_batches\': num_batches,\n                                               \'num_epoch\': num_epoch,\n                                               \'has_val_data\': has_val_data,\n                                               \'has_regularizers\': self._has_regularizers,\n                                               \'has_metrics\': self._has_metrics})\n\n            for epoch_idx in range(initial_epoch,num_epoch):\n                epoch_logs = {}\n                callback_container.on_epoch_begin(epoch_idx, epoch_logs)\n\n                if shuffle:\n                    inputs, targets = fit_helper.shuffle_arrays(inputs, targets)\n\n                batch_logs = {}\n                for batch_idx in range(num_batches):\n                    callback_container.on_batch_begin(batch_idx, batch_logs)\n\n                    input_batch, target_batch = fit_helper.grab_batch(batch_idx, batch_size, inputs, targets)\n                    if cuda_device >= 0:\n                        input_batch, target_batch = fit_helper.move_to_cuda(cuda_device, input_batch, target_batch)\n                    if self._has_transforms:\n                        input_batch, target_batch = fit_helper.apply_transforms(self._transforms, input_batch, target_batch)\n\n                    # ---------------------------------------------\n                    self._optimizer.zero_grad()\n                    output_batch = fit_forward_fn(input_batch)\n                    loss = fit_loss_fn(output_batch, target_batch)\n                    loss.backward()\n                    self._optimizer.step()\n                    # ---------------------------------------------\n\n                    if self._has_regularizers:\n                        batch_logs[\'reg_loss\'] = self.regularizer_container.current_value\n                    if self._has_metrics:\n                        metrics_logs = self.metric_container(output_batch, target_batch)\n                        batch_logs.update(metrics_logs)\n\n                    batch_logs[\'loss\'] = loss.data[0]\n                    callback_container.on_batch_end(batch_idx, batch_logs)\n\n                if has_val_data:\n                    val_epoch_logs = self.evaluate(val_inputs,\n                                                   val_targets,\n                                                   batch_size=batch_size,\n                                                   cuda_device=cuda_device,\n                                                   verbose=verbose)\n                    epoch_logs.update(val_epoch_logs)\n                    epoch_logs.update(batch_logs)\n                    # TODO how to fix this?\n                    # self.history.batch_metrics.update(val_epoch_logs)\n\n                callback_container.on_epoch_end(epoch_idx, self.history.epoch_metrics)\n\n                if self._stop_training:\n                    break\n        self.model.train(mode=False)\n\n    def fit_loader(self,\n                   loader,\n                   val_loader=None,\n                   initial_epoch=0,\n                   num_epoch=100,\n                   cuda_device=-1,\n                   verbose=1):\n        """"""\n        Fit a model on in-memory tensors using ModuleTrainer\n        """"""\n        self.model.train(mode=True)\n        # ----------------------------------------------------------------------\n        num_inputs = loader.dataset.num_inputs\n        num_targets = loader.dataset.num_targets\n        len_inputs = len(loader.sampler) if loader.sampler else len(loader.dataset)\n        batch_size = loader.batch_size\n\n        if val_loader is not None:\n            num_val_inputs = val_loader.dataset.num_inputs\n            num_val_targets = val_loader.dataset.num_targets\n            if (num_inputs != num_val_inputs) or (num_targets != num_val_targets):\n                raise ValueError(\'num_inputs != num_val_inputs or num_targets != num_val_targets\')\n        has_val_data = val_loader is not None\n        num_batches = int(math.ceil(len_inputs / batch_size))\n        # ----------------------------------------------------------------------\n\n        fit_helper = _get_helper(self, num_inputs, num_targets)\n        fit_loss_fn = fit_helper.get_partial_loss_fn(self._loss_fn)\n        fit_forward_fn = fit_helper.get_partial_forward_fn(self.model)\n\n        with TQDM() as pbar:\n            tmp_callbacks = []\n            if verbose > 0:\n                tmp_callbacks.append(pbar)\n            if self._has_regularizers:\n                tmp_callbacks.append(RegularizerCallback(self.regularizer_container))\n                fit_loss_fn = _add_regularizer_to_loss_fn(fit_loss_fn,\n                                                            self.regularizer_container)\n            if self._has_constraints:\n                tmp_callbacks.append(ConstraintCallback(self.constraint_container))\n            if self._has_metrics:\n                self.metric_container.set_helper(fit_helper)\n                tmp_callbacks.append(MetricCallback(self.metric_container))\n\n            callback_container = CallbackContainer(self._callbacks+tmp_callbacks)\n            callback_container.set_trainer(self)\n            callback_container.on_train_begin({\'batch_size\': loader.batch_size,\n                                               \'num_batches\': num_batches,\n                                               \'num_epoch\': num_epoch,\n                                               \'has_val_data\': has_val_data,\n                                               \'has_regularizers\': self._has_regularizers,\n                                               \'has_metrics\': self._has_metrics})\n\n            for epoch_idx in range(initial_epoch,num_epoch):\n                epoch_logs = {}\n                callback_container.on_epoch_begin(epoch_idx, epoch_logs)\n\n                batch_logs = {}\n                loader_iter = iter(loader)\n                for batch_idx in range(num_batches):\n\n                    callback_container.on_batch_begin(batch_idx, batch_logs)\n\n                    input_batch, target_batch = fit_helper.grab_batch_from_loader(loader_iter)\n                    if cuda_device >= 0:\n                        input_batch, target_batch = fit_helper.move_to_cuda(cuda_device, input_batch, target_batch)\n                    \n                    # ---------------------------------------------\n                    self._optimizer.zero_grad()\n                    output_batch = fit_forward_fn(input_batch)\n                    loss = fit_loss_fn(output_batch, target_batch)\n                    loss.backward()\n                    self._optimizer.step()\n                    # ---------------------------------------------\n\n                    if self._has_regularizers:\n                        batch_logs[\'reg_loss\'] = self.regularizer_container.current_value\n                    if self._has_metrics:\n                        metrics_logs = self.metric_container(output_batch, target_batch)\n                        batch_logs.update(metrics_logs)\n\n                    batch_logs[\'loss\'] = loss.data[0]\n                    callback_container.on_batch_end(batch_idx, batch_logs)\n\n                epoch_logs.update(self.history.batch_metrics)\n                if has_val_data:\n                    val_epoch_logs = self.evaluate_loader(val_loader,\n                                                          cuda_device=cuda_device,\n                                                          verbose=verbose)\n                    self._in_train_loop = False\n                    #self.history.batch_metrics.update(val_epoch_logs)\n                    #epoch_logs.update(val_epoch_logs)\n                    epoch_logs.update(val_epoch_logs)\n                    epoch_logs.update(batch_logs)\n                    # TODO how to fix this?\n                    # self.history.batch_metrics.update(val_epoch_logs)\n\n                callback_container.on_epoch_end(epoch_idx, epoch_logs)\n\n                if self._stop_training:\n                    break\n        self.model.train(mode=False)\n\n    def predict(self,\n                inputs,\n                batch_size=32,\n                cuda_device=-1,\n                verbose=1):\n        self.model.train(mode=False)\n        # --------------------------------------------------------\n        num_inputs, _ = _parse_num_inputs_and_targets(inputs, None)\n        len_inputs = len(inputs) if not _is_tuple_or_list(inputs) else len(inputs[0])\n        num_batches = int(math.ceil(len_inputs / batch_size))\n        # --------------------------------------------------------\n\n        predict_helper = _get_helper(self, num_inputs, num_targets=0)\n        pred_forward_fn = predict_helper.get_partial_forward_fn(self.model)\n        \n        for batch_idx in range(num_batches):\n            input_batch, _ = predict_helper.grab_batch(batch_idx, batch_size, inputs, None, volatile=True)\n            if cuda_device >= 0:\n                inputs = predict_helper.move_to_cuda(cuda_device, inputs)\n            output_batch = pred_forward_fn(input_batch)\n\n            if batch_idx == 0:\n                len_outputs = 1 if not _is_tuple_or_list(output_batch) else len(output_batch)\n                prediction_lists = [[] for _ in range(len_outputs)]\n\n            if len_outputs == 1:\n                prediction_lists[0].append(output_batch)\n            else:\n                for out_idx in range(len_outputs):\n                    prediction_lists[out_idx].append(output_batch[out_idx])\n            \n        final_pred_list = [th.cat(pred_list,0) for pred_list in prediction_lists]\n        self.model.train(mode=True)\n        return final_pred_list if len_outputs > 1 else final_pred_list[0]\n\n    def predict_loader(self,\n                       loader,\n                       cuda_device=-1,\n                       verbose=1):\n        self.model.train(mode=False)\n        # --------------------------------------------------------\n        num_inputs, num_targets = _parse_num_inputs_and_targets_from_loader(loader)\n        batch_size = loader.batch_size\n        len_inputs = len(loader.sampler) if loader.sampler else len(loader.dataset)\n        num_batches = int(math.ceil(len_inputs / batch_size))\n        # --------------------------------------------------------\n\n        predict_helper = _get_helper(self, num_inputs, num_targets=0)\n        pred_forward_fn = predict_helper.get_partial_forward_fn(self.model)\n\n        loader_iter = iter(loader)\n\n        _range = tqdm(range(num_batches)) if verbose > 0 else range(num_batches)\n\n        for batch_idx in _range:\n            input_batch, _ = predict_helper.grab_batch_from_loader(loader_iter, volatile=True)\n            if cuda_device >= 0:\n                input_batch, _ = predict_helper.move_to_cuda(cuda_device, input_batch)\n\n            output_batch = pred_forward_fn(input_batch)\n\n            if batch_idx == 0:\n                len_outputs = 1 if not _is_tuple_or_list(output_batch) else len(output_batch)\n                prediction_lists = [[] for _ in range(len_outputs)]\n\n            if len_outputs == 1:\n                prediction_lists[0].append(output_batch)\n            else:\n                for out_idx in range(len_outputs):\n                    prediction_lists[out_idx].append(output_batch[out_idx])\n            \n        final_pred_list = [th.cat(pred_list,0) for pred_list in prediction_lists]\n        self.model.train(mode=True)\n        return final_pred_list if len_outputs > 1 else final_pred_list[0]\n\n    def evaluate(self,\n                 inputs,\n                 targets=None,\n                 batch_size=32,\n                 cuda_device=-1,\n                 verbose=1):\n        self.model.train(mode=False)\n        num_inputs, num_targets = _parse_num_inputs_and_targets(inputs, targets)\n        len_inputs = len(inputs) if not _is_tuple_or_list(inputs) else len(inputs[0])\n        num_batches = int(math.ceil(len_inputs / batch_size))\n\n        evaluate_helper = _get_helper(self, num_inputs, num_targets)\n        eval_loss_fn = evaluate_helper.get_partial_loss_fn(self._loss_fn)\n        eval_forward_fn = evaluate_helper.get_partial_forward_fn(self.model)\n        eval_logs= {\'val_loss\': 0.}\n        \n        if self._has_metrics:\n            metric_container = MetricContainer(self._metrics, prefix=\'val_\')\n            metric_container.set_helper(evaluate_helper)\n            metric_container.reset()\n\n        samples_seen = 0\n        for batch_idx in range(num_batches):\n            input_batch, target_batch = evaluate_helper.grab_batch(batch_idx, batch_size, inputs, targets, volatile=True)\n            if cuda_device >= 0:\n                input_batch, target_batch = evaluate_helper.move_to_cuda(cuda_device, input_batch, target_batch)\n\n            self._optimizer.zero_grad()\n            output_batch = eval_forward_fn(input_batch)\n            loss = eval_loss_fn(output_batch, target_batch)\n            \n            samples_seen += batch_size\n            eval_logs[\'val_loss\'] = (samples_seen*eval_logs[\'val_loss\'] + loss.data[0]*batch_size) / (samples_seen+batch_size)\n            \n            if self._has_metrics:\n                metrics_logs = metric_container(output_batch, target_batch)\n                eval_logs.update(metrics_logs)\n\n        self.model.train(mode=True)\n        return eval_logs\n\n    def evaluate_loader(self,\n                        loader,\n                        cuda_device=-1,\n                        verbose=1):\n        self.model.train(mode=False)\n        num_inputs, num_targets = _parse_num_inputs_and_targets_from_loader(loader)\n        batch_size = loader.batch_size\n        len_inputs = len(loader.sampler) if loader.sampler else len(loader.dataset) \n        num_batches = int(math.ceil(len_inputs / batch_size))\n\n        evaluate_helper = _get_helper(self, num_inputs, num_targets)\n        eval_loss_fn = evaluate_helper.get_partial_loss_fn(self._loss_fn)\n        eval_forward_fn = evaluate_helper.get_partial_forward_fn(self.model)\n        eval_logs= {\'val_loss\': 0.}\n        loader_iter = iter(loader)\n        \n        if self._has_metrics:\n            metric_container = MetricContainer(self._metrics, prefix=\'val_\')\n            metric_container.set_helper(evaluate_helper)\n            metric_container.reset()\n\n        samples_seen = 0\n        for batch_idx in range(num_batches):\n            input_batch, target_batch = evaluate_helper.grab_batch_from_loader(loader_iter, volatile=True)\n            if cuda_device >= 0:\n                input_batch, target_batch = evaluate_helper.move_to_cuda(cuda_device, input_batch, target_batch)\n\n            self._optimizer.zero_grad()\n            output_batch = eval_forward_fn(input_batch)\n            loss = eval_loss_fn(output_batch, target_batch)\n            \n            samples_seen += batch_size\n            eval_logs[\'val_loss\'] = (samples_seen*eval_logs[\'val_loss\'] + loss.data[0]*batch_size) / (samples_seen+batch_size)\n            \n            if self._has_metrics:\n                metrics_logs = metric_container(output_batch, target_batch)\n                eval_logs.update(metrics_logs)\n\n        self.model.train(mode=True)\n        return eval_logs\n\n    def summary(self, input_size):\n        def register_hook(module):\n            def hook(module, input, output):\n                class_name = str(module.__class__).split(\'.\')[-1].split(""\'"")[0]\n                module_idx = len(summary)\n\n                m_key = \'%s-%i\' % (class_name, module_idx+1)\n                summary[m_key] = OrderedDict()\n                summary[m_key][\'input_shape\'] = list(input[0].size())\n                summary[m_key][\'input_shape\'][0] = -1\n                summary[m_key][\'output_shape\'] = list(output.size())\n                summary[m_key][\'output_shape\'][0] = -1\n\n                params = 0\n                if hasattr(module, \'weight\'):\n                    params += th.prod(th.LongTensor(list(module.weight.size())))\n                    if module.weight.requires_grad:\n                        summary[m_key][\'trainable\'] = True\n                    else:\n                        summary[m_key][\'trainable\'] = False\n                if hasattr(module, \'bias\'):\n                    params +=  th.prod(th.LongTensor(list(module.bias.size())))\n                summary[m_key][\'nb_params\'] = params\n\n            if not isinstance(module, nn.Sequential) and \\\n               not isinstance(module, nn.ModuleList) and \\\n               not (module == self.model):\n                hooks.append(module.register_forward_hook(hook))\n\n        # create properties\n        summary = OrderedDict()\n        hooks = []\n        # register forward hooks\n        self.model.apply(register_hook)\n\n        if isinstance(input_size[0], (list, tuple)):\n            x = [Variable(th.rand(1,*in_size)) for in_size in input_size]\n            self.model(*x)\n        else:\n            x = Variable(th.rand(1,*input_size))\n            self.model(x)\n\n        # remove these hooks\n        for h in hooks:\n            h.remove()\n\n        return summary\n\ndef _get_helper(trainer, num_inputs, num_targets):\n    if (num_inputs == 1) and (num_targets == 1):\n        helper = SingleInput_SingleTarget_Helper()\n\n    elif (num_inputs == 1) and (num_targets > 1):\n        # use same loss function for all targets if multiple loss fns not explicitly given\n        if not _is_tuple_or_list(trainer._loss_fn):\n            trainer._loss_fn = [trainer._loss_fn] * num_targets\n        else:\n            if len(trainer._loss_fn) != num_targets:\n                raise ValueError(\'must give one loss function for every input if you give multiple\')\n        helper = SingleInput_MultiTarget_Helper()\n\n    elif (num_inputs == 1) and (num_targets == 0):\n        helper = SingleInput_NoTarget_Helper()\n\n    elif (num_inputs > 1) and (num_targets == 1):\n        helper = MultiInput_SingleTarget_Helper()\n\n    elif (num_inputs > 1) and (num_targets > 1):\n        # use same loss function for all targets if multiple loss fns not explicitly given\n        if not _is_tuple_or_list(trainer._loss_fn):\n            trainer._loss_fn = [trainer._loss_fn] * num_targets\n        else:\n            if len(trainer._loss_fn) != num_targets:\n                raise ValueError(\'must give one loss function for every input if you give multiple\')\n        helper = MultiInput_MultiTarget_Helper()\n\n    elif (num_inputs > 1) and (num_targets == 0):\n        helper = MultiInput_NoTarget_Helper()\n\n    return helper\n\n\nclass SingleInput_SingleTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets):\n        inputs = inputs.cuda(cuda_device)\n        targets = targets.cuda(cuda_device)\n        return inputs, targets\n    def shuffle_arrays(self, inputs, targets):\n        rand_indices = th.randperm(len(inputs))\n        inputs = inputs[rand_indices]\n        targets = targets[rand_indices]\n        return inputs, targets\n    def grab_batch(self, batch_idx, batch_size, inputs, targets, volatile=False):\n        input_batch = Variable(inputs[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n        target_batch = Variable(targets[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile, requires_grad=False)\n        return input_batch, target_batch\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch, target_batch = next(loader_iter)\n        return Variable(input_batch, volatile=volatile), Variable(target_batch, volatile=volatile, requires_grad=False)\n    def apply_transforms(self, tforms, input_batch, target_batch):\n        input_batch = tforms[0](input_batch)\n        target_batch = tforms[1](target_batch)\n        input_batch, target_batch = tforms[2](input_batch, target_batch)\n        return input_batch, target_batch\n    def forward_pass(self, input_batch, model):\n        return model(input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return loss_fn(output_batch, target_batch)\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n        #def new_loss_fn(output_batch, target_batch):\n        #    return self.calculate_loss(output_batch, target_batch, loss_fn)\n        #return new_loss_fn\n\n\nclass SingleInput_MultiTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets):\n        inputs = inputs.cuda(cuda_device)\n        targets = [target_.cuda(cuda_device) for target_ in targets]\n        return inputs, targets\n    def shuffle_arrays(self, inputs, targets):\n        rand_indices = th.randperm(len(inputs))\n        inputs = inputs[rand_indices]\n        targets = [target_[rand_indices] for target_ in targets]\n        return inputs, targets\n    def grab_batch(self, batch_idx, batch_size, inputs, targets, volatile=False):\n        input_batch = Variable(inputs[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n        target_batch = [Variable(target_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile, requires_grad=False)\n                        for target_ in targets]\n        return input_batch, target_batch\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch, target_batch = next(loader_iter)\n        return Variable(input_batch, volatile=volatile), [Variable(target_, volatile=volatile, requires_grad=False) for target_ in target_batch]\n    def apply_transforms(self, tforms, input_batch, target_batch):\n        input_batch = tforms[0](input_batch)\n        target_batch = [tforms[1](target_) for target_ in target_batch]\n        return input_batch, target_batch\n    def forward_pass(self, input_batch, model):\n        return model(input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return sum([loss_fn[idx](output_batch[idx], target_batch[idx]) \n                    for idx in range(len(output_batch))])\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n\nclass MultiInput_SingleTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets):\n        inputs = [input_.cuda(cuda_device) for input_ in inputs] \n        targets = targets.cuda(cuda_device)\n        return inputs, targets\n    def shuffle_arrays(self, inputs, targets):\n        rand_indices = th.randperm(len(inputs))\n        inputs = [input_[rand_indices] for input_ in inputs]\n        targets = targets[rand_indices]\n        return inputs, targets\n    def grab_batch(self, batch_idx, batch_size, inputs, targets, volatile=False):\n        input_batch = [Variable(input_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n                       for input_ in inputs]\n        target_batch = Variable(targets[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile, requires_grad=False)\n        return input_batch, target_batch\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch, target_batch = next(loader_iter)\n        return [Variable(input_, volatile=volatile) for input_ in input_batch], Variable(target_batch, volatile=volatile, requires_grad=False)\n    def apply_transforms(self, tforms, input_batch, target_batch):\n        input_batch = [tforms[0](input_) for input_ in input_batch]\n        target_batch = tforms[1](target_batch)\n        return input_batch, target_batch\n    def forward_pass(self, input_batch, model):\n        return model(*input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return loss_fn(output_batch, target_batch)\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n\nclass MultiInput_MultiTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets):\n        inputs = [input_.cuda(cuda_device) for input_ in inputs] \n        targets = [target_.cuda(cuda_device) for target_ in targets]\n        return inputs, targets\n    def shuffle_arrays(self, inputs, targets):\n        rand_indices = th.randperm(len(inputs))\n        inputs = [input_[rand_indices] for input_ in inputs]\n        targets = [input_[rand_indices] for input_ in inputs]\n        return inputs, targets\n    def grab_batch(self, batch_idx, batch_size, inputs, targets, volatile=False):\n        input_batch = [Variable(input_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n                       for input_ in inputs]\n        target_batch = [Variable(target_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile, requires_grad=False)\n                       for target_ in targets]\n        return input_batch, target_batch\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch, target_batch = next(loader_iter)\n        return [Variable(input_, volatile=volatile) for input_ in input_batch], [Variable(target_, volatile=volatile, requires_grad=False) for target_ in target_batch]\n    def apply_transforms(self, tforms, input_batch, target_batch):\n        input_batch = [tforms[0](input_) for input_ in input_batch]\n        target_batch = [tforms[1](target_) for target_ in target_batch]\n        return input_batch, target_batch\n    def forward_pass(self, input_batch, model):\n        return model(*input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return sum([loss_fn[idx](output_batch[idx], target_batch[idx]) \n                    for idx in range(len(output_batch))])\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n\nclass SingleInput_NoTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets=None):\n        inputs = inputs.cuda(cuda_device)\n        return inputs, None\n    def shuffle_arrays(self, inputs, targets=None):\n        rand_indices = th.randperm(len(inputs))\n        inputs = inputs[rand_indices]\n        return inputs, None\n    def grab_batch(self, batch_idx, batch_size, inputs, targets=None, volatile=False):\n        input_batch = Variable(inputs[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n        return input_batch, None\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch = next(loader_iter)\n        return Variable(input_batch, volatile=volatile), None\n    def apply_transforms(self, tforms, input_batch, target_batch=None):\n        input_batch = tforms[0](input_batch)\n        return input_batch, None\n    def forward_pass(self, input_batch, model):\n        return model(input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return loss_fn(output_batch)\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n\nclass MultiInput_NoTarget_Helper(object):\n    def move_to_cuda(self, cuda_device, inputs, targets=None):\n        inputs = [input_.cuda(cuda_device) for input_ in inputs]\n        return inputs, None\n    def shuffle_arrays(self, inputs, targets=None):\n        rand_indices = th.randperm(len(inputs))\n        inputs = [input_[rand_indices] for input_ in inputs]\n        return inputs, None\n    def grab_batch(self, batch_idx, batch_size, inputs, targets=None, volatile=False):\n        input_batch = [Variable(input_[batch_idx*batch_size:(batch_idx+1)*batch_size], volatile=volatile)\n                       for input_ in inputs]\n        return input_batch, None\n    def grab_batch_from_loader(self, loader_iter, volatile=False):\n        input_batch = next(loader_iter)\n        return [Variable(input_, volatile=volatile) for input_ in input_batch], None\n    def apply_transforms(self, tforms, input_batch, target_batch=None):\n        input_batch = [tforms[0](input_) for input_ in input_batch]\n        return input_batch, None\n    def forward_pass(self, input_batch, model):\n        return model(*input_batch)\n    def get_partial_forward_fn(self, model):\n        return functools.partial(self.forward_pass, model=model)\n    def calculate_loss(self, output_batch, target_batch, loss_fn):\n        return loss_fn(output_batch)\n    def get_partial_loss_fn(self, loss_fn):\n        return functools.partial(self.calculate_loss, loss_fn=loss_fn)\n'"
torchsample/transforms/__init__.py,0,b'\nfrom __future__ import absolute_import\n\nfrom .affine_transforms import *\nfrom .image_transforms import *\nfrom .tensor_transforms import *'
torchsample/transforms/affine_transforms.py,0,"b'""""""\nAffine transforms implemented on torch tensors, and\nrequiring only one interpolation\n""""""\n\nimport math\nimport random\nimport torch as th\n\nfrom ..utils import th_affine2d, th_random_choice\n\n\nclass RandomAffine(object):\n\n    def __init__(self, \n                 rotation_range=None, \n                 translation_range=None,\n                 shear_range=None, \n                 zoom_range=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Perform an affine transforms with various sub-transforms, using\n        only one interpolation and without having to instantiate each\n        sub-transform individually.\n\n        Arguments\n        ---------\n        rotation_range : one integer or float\n            image will be rotated randomly between (-degrees, degrees) \n\n        translation_range : a float or a tuple/list with 2 floats between [0, 1)\n            first value:\n                image will be horizontally shifted between \n                (-height_range * height_dimension, height_range * height_dimension)\n            second value:\n                Image will be vertically shifted between \n                (-width_range * width_dimension, width_range * width_dimension)\n\n        shear_range : float\n            image will be sheared randomly between (-degrees, degrees)\n\n        zoom_range : list/tuple with two floats between [0, infinity).\n            first float should be less than the second\n            lower and upper bounds on percent zoom. \n            Anything less than 1.0 will zoom in on the image, \n            anything greater than 1.0 will zoom out on the image.\n            e.g. (0.7, 1.0) will only zoom in, \n                 (1.0, 1.4) will only zoom out,\n                 (0.7, 1.4) will randomly zoom in or out\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        """"""\n        self.transforms = []\n        if rotation_range is not None:\n            rotation_tform = RandomRotate(rotation_range, lazy=True)\n            self.transforms.append(rotation_tform)\n\n        if translation_range is not None:\n            translation_tform = RandomTranslate(translation_range, lazy=True)\n            self.transforms.append(translation_tform)\n\n        if shear_range is not None:\n            shear_tform = RandomShear(shear_range, lazy=True)\n            self.transforms.append(shear_tform) \n\n        if zoom_range is not None:\n            zoom_tform = RandomZoom(zoom_range, lazy=True)\n            self.transforms.append(zoom_tform)\n\n        self.interp = interp\n        self.lazy = lazy\n\n        if len(self.transforms) == 0:\n            raise Exception(\'Must give at least one transform parameter\')\n\n    def __call__(self, *inputs):\n        # collect all of the lazily returned tform matrices\n        tform_matrix = self.transforms[0](inputs[0])\n        for tform in self.transforms[1:]:\n            tform_matrix = tform_matrix.mm(tform(inputs[0])) \n        self.tform_matrix = tform_matrix\n\n        if self.lazy:\n            return tform_matrix\n        else:\n            outputs = Affine(tform_matrix,\n                             interp=self.interp)(*inputs)\n            return outputs\n\n\nclass Affine(object):\n\n    def __init__(self, \n                 tform_matrix,\n                 interp=\'bilinear\'):\n        """"""\n        Perform an affine transforms with various sub-transforms, using\n        only one interpolation and without having to instantiate each\n        sub-transform individually.\n\n        Arguments\n        ---------\n        tform_matrix : a 2x3 or 3x3 matrix\n            affine transformation matrix to apply\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        """"""\n        self.tform_matrix = tform_matrix\n        self.interp = interp\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            input_tf = th_affine2d(_input,\n                                   self.tform_matrix,\n                                   mode=interp[idx])\n            outputs.append(input_tf)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass AffineCompose(object):\n\n    def __init__(self, \n                 transforms,\n                 interp=\'bilinear\'):\n        """"""\n        Apply a collection of explicit affine transforms to an input image,\n        and to a target image if necessary\n\n        Arguments\n        ---------\n        transforms : list or tuple\n            each element in the list/tuple should be an affine transform.\n            currently supported transforms:\n                - Rotate()\n                - Translate()\n                - Shear()\n                - Zoom()\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        """"""\n        self.transforms = transforms\n        self.interp = interp\n        # set transforms to lazy so they only return the tform matrix\n        for t in self.transforms:\n            t.lazy = True\n\n    def __call__(self, *inputs):\n        # collect all of the lazily returned tform matrices\n        tform_matrix = self.transforms[0](inputs[0])\n        for tform in self.transforms[1:]:\n            tform_matrix = tform_matrix.mm(tform(inputs[0])) \n\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            input_tf = th_affine2d(_input,\n                                   tform_matrix,\n                                   mode=interp[idx])\n            outputs.append(input_tf)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass RandomRotate(object):\n\n    def __init__(self, \n                 rotation_range,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly rotate an image between (-degrees, degrees). If the image\n        has multiple channels, the same rotation will be applied to each channel.\n\n        Arguments\n        ---------\n        rotation_range : integer or float\n            image will be rotated between (-degrees, degrees) degrees\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        self.rotation_range = rotation_range\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        degree = random.uniform(-self.rotation_range, self.rotation_range)\n\n        if self.lazy:\n            return Rotate(degree, lazy=True)(inputs[0])\n        else:\n            outputs = Rotate(degree,\n                             interp=self.interp)(*inputs)\n            return outputs\n\n\nclass RandomChoiceRotate(object):\n\n    def __init__(self, \n                 values,\n                 p=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly rotate an image from a list of values. If the image\n        has multiple channels, the same rotation will be applied to each channel.\n\n        Arguments\n        ---------\n        values : a list or tuple\n            the values from which the rotation value will be sampled\n\n        p : a list or tuple the same length as `values`\n            the probabilities of sampling any given value. Must sum to 1.\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        if isinstance(values, (list, tuple)):\n            values = th.FloatTensor(values)\n        self.values = values\n        if p is None:\n            p = th.ones(len(values)) / len(values)\n        else:\n            if abs(1.0-sum(p)) > 1e-3:\n                raise ValueError(\'Probs must sum to 1\')\n        self.p = p\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        degree = th_random_choice(self.values, p=self.p)\n\n        if self.lazy:\n            return Rotate(degree, lazy=True)(inputs[0])\n        else:\n            outputs = Rotate(degree,\n                             interp=self.interp)(*inputs)\n            return outputs\n\n\nclass Rotate(object):\n\n    def __init__(self, \n                 value,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly rotate an image between (-degrees, degrees). If the image\n        has multiple channels, the same rotation will be applied to each channel.\n\n        Arguments\n        ---------\n        rotation_range : integer or float\n            image will be rotated between (-degrees, degrees) degrees\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        self.value = value\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        theta = math.pi / 180 * self.value\n        rotation_matrix = th.FloatTensor([[math.cos(theta), -math.sin(theta), 0],\n                                          [math.sin(theta), math.cos(theta), 0],\n                                          [0, 0, 1]])\n        if self.lazy:\n            return rotation_matrix\n        else:\n            outputs = []\n            for idx, _input in enumerate(inputs):\n                input_tf = th_affine2d(_input,\n                                       rotation_matrix,\n                                       mode=interp[idx],\n                                       center=True)\n                outputs.append(input_tf)\n            return outputs if idx > 1 else outputs[0]\n\n\nclass RandomTranslate(object):\n\n    def __init__(self, \n                 translation_range,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly translate an image some fraction of total height and/or\n        some fraction of total width. If the image has multiple channels,\n        the same translation will be applied to each channel.\n\n        Arguments\n        ---------\n        translation_range : two floats between [0, 1) \n            first value:\n                fractional bounds of total height to shift image\n                image will be horizontally shifted between \n                (-height_range * height_dimension, height_range * height_dimension)\n            second value:\n                fractional bounds of total width to shift image \n                Image will be vertically shifted between \n                (-width_range * width_dimension, width_range * width_dimension)\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        if isinstance(translation_range, float):\n            translation_range = (translation_range, translation_range)\n        self.height_range = translation_range[0]\n        self.width_range = translation_range[1]\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        # height shift\n        random_height = random.uniform(-self.height_range, self.height_range)\n        # width shift\n        random_width = random.uniform(-self.width_range, self.width_range)\n\n        if self.lazy:\n            return Translate([random_height, random_width], \n                             lazy=True)(inputs[0])\n        else:\n            outputs = Translate([random_height, random_width],\n                                 interp=self.interp)(*inputs)\n            return outputs\n\n\nclass RandomChoiceTranslate(object):\n\n    def __init__(self,\n                 values,\n                 p=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly translate an image some fraction of total height and/or\n        some fraction of total width from a list of potential values. \n        If the image has multiple channels,\n        the same translation will be applied to each channel.\n\n        Arguments\n        ---------\n        values : a list or tuple\n            the values from which the translation value will be sampled\n\n        p : a list or tuple the same length as `values`\n            the probabilities of sampling any given value. Must sum to 1.\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if true, only create the affine transform matrix and return that\n            if false, perform the transform on the tensor and return the tensor\n        """"""\n        if isinstance(values, (list, tuple)):\n            values = th.FloatTensor(values)\n        self.values = values\n        if p is None:\n            p = th.ones(len(values)) / len(values)\n        else:\n            if abs(1.0-sum(p)) > 1e-3:\n                raise ValueError(\'Probs must sum to 1\')\n        self.p = p\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        random_height = th_random_choice(self.values, p=self.p)\n        random_width = th_random_choice(self.values, p=self.p)\n\n        if self.lazy:\n            return Translate([random_height, random_width],\n                             lazy=True)(inputs[0])\n        else:\n            outputs = Translate([random_height, random_width],\n                                interp=self.interp)(*inputs)\n            return outputs\n\n\nclass Translate(object):\n\n    def __init__(self, \n                 value, \n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Arguments\n        ---------\n        value : float or 2-tuple of float\n            if single value, both horizontal and vertical translation\n            will be this value * total height/width. Thus, value should\n            be a fraction of total height/width with range (-1, 1)\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        """"""\n        if not isinstance(value, (tuple,list)):\n            value = (value, value)\n\n        if value[0] > 1 or value[0] < -1:\n            raise ValueError(\'Translation must be between -1 and 1\')\n        if value[1] > 1 or value[1] < -1:\n            raise ValueError(\'Translation must be between -1 and 1\')\n\n        self.height_range = value[0]\n        self.width_range = value[1]\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        tx = self.height_range * inputs[0].size(1)\n        ty = self.width_range * inputs[0].size(2)\n\n        translation_matrix = th.FloatTensor([[1, 0, tx],\n                                             [0, 1, ty],\n                                             [0, 0, 1]])\n        if self.lazy:\n            return translation_matrix\n        else:\n            outputs = []\n            for idx, _input in enumerate(inputs):\n                input_tf = th_affine2d(_input,\n                                       translation_matrix,\n                                       mode=interp[idx],\n                                       center=True)\n                outputs.append(input_tf)\n            return outputs if idx > 1 else outputs[0]\n\n\nclass RandomShear(object):\n\n    def __init__(self, \n                 shear_range,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly shear an image with radians (-shear_range, shear_range)\n\n        Arguments\n        ---------\n        shear_range : float\n            radian bounds on the shear transform\n        \n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if false, perform the transform on the tensor and return the tensor\n            if true, only create the affine transform matrix and return that\n        """"""\n        self.shear_range = shear_range\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        shear = random.uniform(-self.shear_range, self.shear_range)\n        if self.lazy:\n            return Shear(shear, \n                         lazy=True)(inputs[0])\n        else:\n            outputs = Shear(shear,\n                            interp=self.interp)(*inputs)\n            return outputs\n\n\nclass RandomChoiceShear(object):\n\n    def __init__(self,\n                 values,\n                 p=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly shear an image with a value sampled from a list of values.\n\n        Arguments\n        ---------\n        values : a list or tuple\n            the values from which the rotation value will be sampled\n\n        p : a list or tuple the same length as `values`\n            the probabilities of sampling any given value. Must sum to 1.\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if false, perform the transform on the tensor and return the tensor\n            if true, only create the affine transform matrix and return that\n        """"""\n        if isinstance(values, (list, tuple)):\n            values = th.FloatTensor(values)\n        self.values = values\n        if p is None:\n            p = th.ones(len(values)) / len(values)\n        else:\n            if abs(1.0-sum(p)) > 1e-3:\n                raise ValueError(\'Probs must sum to 1\')\n        self.p = p\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        shear = th_random_choice(self.values, p=self.p)\n\n        if self.lazy:\n            return Shear(shear, \n                         lazy=True)(inputs[0])\n        else:\n            outputs = Shear(shear,\n                            interp=self.interp)(*inputs)\n            return outputs \n\n\nclass Shear(object):\n\n    def __init__(self,\n                 value,\n                 interp=\'bilinear\',\n                 lazy=False):\n        self.value = value\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        theta = (math.pi * self.value) / 180\n        shear_matrix = th.FloatTensor([[1, -math.sin(theta), 0],\n                                        [0, math.cos(theta), 0],\n                                        [0, 0, 1]])\n        if self.lazy:\n            return shear_matrix\n        else:\n            outputs = []\n            for idx, _input in enumerate(inputs):\n                input_tf = th_affine2d(_input,\n                                       shear_matrix,\n                                       mode=interp[idx],\n                                       center=True)\n                outputs.append(input_tf)\n            return outputs if idx > 1 else outputs[0]\n\n\nclass RandomZoom(object):\n\n    def __init__(self, \n                 zoom_range,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly zoom in and/or out on an image \n\n        Arguments\n        ---------\n        zoom_range : tuple or list with 2 values, both between (0, infinity)\n            lower and upper bounds on percent zoom. \n            Anything less than 1.0 will zoom in on the image, \n            anything greater than 1.0 will zoom out on the image.\n            e.g. (0.7, 1.0) will only zoom in, \n                 (1.0, 1.4) will only zoom out,\n                 (0.7, 1.4) will randomly zoom in or out\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if false, perform the transform on the tensor and return the tensor\n            if true, only create the affine transform matrix and return that\n        """"""\n        if not isinstance(zoom_range, list) and not isinstance(zoom_range, tuple):\n            raise ValueError(\'zoom_range must be tuple or list with 2 values\')\n        self.zoom_range = zoom_range\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        zx = random.uniform(self.zoom_range[0], self.zoom_range[1])\n        zy = random.uniform(self.zoom_range[0], self.zoom_range[1])\n\n        if self.lazy:\n            return Zoom([zx, zy], lazy=True)(inputs[0])\n        else:\n            outputs = Zoom([zx, zy], \n                           interp=self.interp)(*inputs)\n            return outputs\n\n\nclass RandomChoiceZoom(object):\n\n    def __init__(self, \n                 values,\n                 p=None,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Randomly zoom in and/or out on an image with a value sampled from\n        a list of values\n\n        Arguments\n        ---------\n        values : a list or tuple\n            the values from which the applied zoom value will be sampled\n\n        p : a list or tuple the same length as `values`\n            the probabilities of sampling any given value. Must sum to 1.\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy    : boolean\n            if false, perform the transform on the tensor and return the tensor\n            if true, only create the affine transform matrix and return that\n        """"""\n        if isinstance(values, (list, tuple)):\n            values = th.FloatTensor(values)\n        self.values = values\n        if p is None:\n            p = th.ones(len(values)) / len(values)\n        else:\n            if abs(1.0-sum(p)) > 1e-3:\n                raise ValueError(\'Probs must sum to 1\')\n        self.p = p\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        zx = th_random_choice(self.values, p=self.p)\n        zy = th_random_choice(self.values, p=self.p)\n\n        if self.lazy:\n            return Zoom([zx, zy], lazy=True)(inputs[0])\n        else:\n            outputs = Zoom([zx, zy], \n                           interp=self.interp)(*inputs)\n            return outputs\n\n\nclass Zoom(object):\n\n    def __init__(self,\n                 value,\n                 interp=\'bilinear\',\n                 lazy=False):\n        """"""\n        Arguments\n        ---------\n        value : float\n            Fractional zoom.\n            =1 : no zoom\n            >1 : zoom-in (value-1)%\n            <1 : zoom-out (1-value)%\n\n        interp : string in {\'bilinear\', \'nearest\'} or list of strings\n            type of interpolation to use. You can provide a different\n            type of interpolation for each input, e.g. if you have two\n            inputs then you can say `interp=[\'bilinear\',\'nearest\']\n\n        lazy: boolean\n            If true, just return transformed\n        """"""\n\n        if not isinstance(value, (tuple,list)):\n            value = (value, value)\n        self.value = value\n        self.interp = interp\n        self.lazy = lazy\n\n    def __call__(self, *inputs):\n        if not isinstance(self.interp, (tuple,list)):\n            interp = [self.interp]*len(inputs)\n        else:\n            interp = self.interp\n\n        zx, zy = self.value\n        zoom_matrix = th.FloatTensor([[zx, 0, 0],\n                                      [0, zy, 0],\n                                      [0, 0,  1]])        \n\n        if self.lazy:\n            return zoom_matrix\n        else:\n            outputs = []\n            for idx, _input in enumerate(inputs):\n                input_tf = th_affine2d(_input,\n                                       zoom_matrix,\n                                       mode=interp[idx],\n                                       center=True)\n                outputs.append(input_tf)\n            return outputs if idx > 1 else outputs[0]\n\n\n'"
torchsample/transforms/distortion_transforms.py,0,"b'""""""\nTransforms to distort local or global information of an image\n""""""\n\n\nimport torch as th\nimport numpy as np\nimport random\n\n\nclass Scramble(object):\n    """"""\n    Create blocks of an image and scramble them\n    """"""\n    def __init__(self, blocksize):\n        self.blocksize = blocksize\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            size = _input.size()\n            img_height = size[1]\n            img_width = size[2]\n\n            x_blocks = int(img_height/self.blocksize) # number of x blocks\n            y_blocks = int(img_width/self.blocksize)\n            ind = th.randperm(x_blocks*y_blocks)\n\n            new = th.zeros(_input.size())\n            count = 0\n            for i in range(x_blocks):\n                for j in range (y_blocks):\n                    row = int(ind[count] / x_blocks)\n                    column = ind[count] % x_blocks\n                    new[:, i*self.blocksize:(i+1)*self.blocksize, j*self.blocksize:(j+1)*self.blocksize] = \\\n                    _input[:, row*self.blocksize:(row+1)*self.blocksize, column*self.blocksize:(column+1)*self.blocksize]\n                    count += 1\n            outputs.append(new)\n        return outputs if idx > 1 else outputs[0]\n \n\nclass RandomChoiceScramble(object):\n\n    def __init__(self, blocksizes):\n        self.blocksizes = blocksizes\n\n    def __call__(self, *inputs):\n        blocksize = random.choice(self.blocksizes)\n        outputs = Scramble(blocksize=blocksize)(*inputs)\n        return outputs\n\n\ndef _blur_image(image, H):\n    # break image up into its color components\n    size = image.shape\n    imr = image[0,:,:]\n    img = image[1,:,:]\n    imb = image[2,:,:]\n\n    # compute Fourier transform and frequqnecy spectrum\n    Fim1r = np.fft.fftshift(np.fft.fft2(imr))\n    Fim1g  = np.fft.fftshift(np.fft.fft2(img))\n    Fim1b  = np.fft.fftshift(np.fft.fft2(imb))\n    \n    # Apply the lowpass filter to the Fourier spectrum of the image\n    filtered_imager = np.multiply(H, Fim1r)\n    filtered_imageg = np.multiply(H, Fim1g)\n    filtered_imageb = np.multiply(H, Fim1b)\n    \n    newim = np.zeros(size)\n\n    # convert the result to the spatial domain.\n    newim[0,:,:] = np.absolute(np.real(np.fft.ifft2(filtered_imager)))\n    newim[1,:,:] = np.absolute(np.real(np.fft.ifft2(filtered_imageg)))\n    newim[2,:,:] = np.absolute(np.real(np.fft.ifft2(filtered_imageb)))\n\n    return newim.astype(\'uint8\')\n\ndef _butterworth_filter(rows, cols, thresh, order):\n    # X and Y matrices with ranges normalised to +/- 0.5\n    array1 = np.ones(rows)\n    array2 = np.ones(cols)\n    array3 = np.arange(1,rows+1)\n    array4 = np.arange(1,cols+1)\n\n    x = np.outer(array1, array4)\n    y = np.outer(array3, array2)\n\n    x = x - float(cols/2) - 1\n    y = y - float(rows/2) - 1\n\n    x = x / cols\n    y = y / rows\n\n    radius = np.sqrt(np.square(x) + np.square(y))\n\n    matrix1 = radius/thresh\n    matrix2 = np.power(matrix1, 2*order)\n    f = np.reciprocal(1 + matrix2)\n\n    return f\n\n\nclass Blur(object):\n    """"""\n    Blur an image with a Butterworth filter with a frequency\n    cutoff matching local block size\n    """"""\n    def __init__(self, threshold, order=5):\n        """"""\n        scramble blocksize of 128 => filter threshold of 64\n        scramble blocksize of 64 => filter threshold of 32\n        scramble blocksize of 32 => filter threshold of 16\n        scramble blocksize of 16 => filter threshold of 8\n        scramble blocksize of 8 => filter threshold of 4\n        """"""\n        self.threshold = threshold\n        self.order = order\n\n    def __call__(self, *inputs):\n        """"""\n        inputs should have values between 0 and 255\n        """"""\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            rows = _input.size(1)\n            cols = _input.size(2)\n            fc = self.threshold # threshold\n            fs = 128.0 # max frequency\n            n  = self.order # filter order\n            fc_rad = (fc/fs)*0.5\n            H = _butterworth_filter(rows, cols, fc_rad, n)\n            _input_blurred = _blur_image(_input.numpy().astype(\'uint8\'), H)\n            _input_blurred = th.from_numpy(_input_blurred).float()\n            outputs.append(_input_blurred)\n\n        return outputs if idx > 1 else outputs[0]\n\n\nclass RandomChoiceBlur(object):\n\n    def __init__(self, thresholds, order=5):\n        """"""\n        thresholds = [64.0, 32.0, 16.0, 8.0, 4.0]\n        """"""\n        self.thresholds = thresholds\n        self.order = order\n\n    def __call__(self, *inputs):\n        threshold = random.choice(self.thresholds)\n        outputs = Blur(threshold=threshold, order=self.order)(*inputs)\n        return outputs\n\n\n\n\n\n\n'"
torchsample/transforms/image_transforms.py,0,"b'""""""\nTransforms very specific to images such as \ncolor, lighting, contrast, brightness, etc transforms\n\nNOTE: Most of these transforms assume your image intensity\nis between 0 and 1, and are torch tensors (NOT numpy or PIL)\n""""""\n\nimport random\n\nimport torch as th\n\nfrom ..utils import th_random_choice\n\n\ndef _blend(img1, img2, alpha):\n    """"""\n    Weighted sum of two images\n\n    Arguments\n    ---------\n    img1 : torch tensor\n    img2 : torch tensor\n    alpha : float between 0 and 1\n        how much weight to put on img1 and 1-alpha weight\n        to put on img2\n    """"""\n    return img1.mul(alpha).add(1 - alpha, img2)\n\n\nclass Grayscale(object):\n\n    def __init__(self, keep_channels=False):\n        """"""\n        Convert RGB image to grayscale\n\n        Arguments\n        ---------\n        keep_channels : boolean\n            If true, will keep all 3 channels and they will be the same\n            If false, will just return 1 grayscale channel\n        """"""\n        self.keep_channels = keep_channels\n        if keep_channels:\n            self.channels = 3\n        else:\n            self.channels = 1\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input_dst = _input[0]*0.299 + _input[1]*0.587 + _input[2]*0.114\n            _input_gs = _input_dst.repeat(self.channels,1,1)\n            outputs.append(_input_gs)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomGrayscale(object):\n\n    def __init__(self, p=0.5):\n        """"""\n        Randomly convert RGB image(s) to Grayscale w/ some probability,\n        NOTE: Always retains the 3 channels if image is grayscaled\n\n        p : a float\n            probability that image will be grayscaled\n        """"""\n        self.p = p\n\n    def __call__(self, *inputs):\n        pval = random.random()\n        if pval < self.p:\n            outputs = Grayscale(keep_channels=True)(*inputs)\n        else:\n            outputs = inputs\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\nclass Gamma(object):\n\n    def __init__(self, value):\n        """"""\n        Performs Gamma Correction on the input image. Also known as \n        Power Law Transform. This function transforms the input image \n        pixelwise according \n        to the equation Out = In**gamma after scaling each \n        pixel to the range 0 to 1.\n\n        Arguments\n        ---------\n        value : float\n            <1 : image will tend to be lighter\n            =1 : image will stay the same\n            >1 : image will tend to be darker\n        """"""\n        self.value = value\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = th.pow(_input, self.value)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomGamma(object):\n\n    def __init__(self, min_val, max_val):\n        """"""\n        Performs Gamma Correction on the input image with some\n        randomly selected gamma value between min_val and max_val. \n        Also known as Power Law Transform. This function transforms \n        the input image pixelwise according to the equation \n        Out = In**gamma after scaling each pixel to the range 0 to 1.\n\n        Arguments\n        ---------\n        min_val : float\n            min range\n        max_val : float\n            max range\n\n        NOTE:\n        for values:\n            <1 : image will tend to be lighter\n            =1 : image will stay the same\n            >1 : image will tend to be darker\n        """"""\n        self.values = (min_val, max_val)\n\n    def __call__(self, *inputs):\n        value = random.uniform(self.values[0], self.values[1])\n        outputs = Gamma(value)(*inputs)\n        return outputs\n\nclass RandomChoiceGamma(object):\n\n    def __init__(self, values, p=None):\n        """"""\n        Performs Gamma Correction on the input image with some\n        gamma value selected in the list of given values.\n        Also known as Power Law Transform. This function transforms \n        the input image pixelwise according to the equation \n        Out = In**gamma after scaling each pixel to the range 0 to 1.\n\n        Arguments\n        ---------\n        values : list of floats\n            gamma values to sampled from\n        p : list of floats - same length as `values`\n            if None, values will be sampled uniformly.\n            Must sum to 1.\n\n        NOTE:\n        for values:\n            <1 : image will tend to be lighter\n            =1 : image will stay the same\n            >1 : image will tend to be darker\n        """"""\n        self.values = values\n        self.p = p\n\n    def __call__(self, *inputs):\n        value = th_random_choice(self.values, p=self.p)\n        outputs = Gamma(value)(*inputs)\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\nclass Brightness(object):\n    def __init__(self, value):\n        """"""\n        Alter the Brightness of an image\n\n        Arguments\n        ---------\n        value : brightness factor\n            =-1 = completely black\n            <0 = darker\n            0 = no change\n            >0 = brighter\n            =1 = completely white\n        """"""\n        self.value = max(min(value,1.0),-1.0)\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = th.clamp(_input.float().add(self.value).type(_input.type()), 0, 1)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomBrightness(object):\n\n    def __init__(self, min_val, max_val):\n        """"""\n        Alter the Brightness of an image with a value randomly selected\n        between `min_val` and `max_val`\n\n        Arguments\n        ---------\n        min_val : float\n            min range\n        max_val : float\n            max range\n        """"""\n        self.values = (min_val, max_val)\n\n    def __call__(self, *inputs):\n        value = random.uniform(self.values[0], self.values[1])\n        outputs = Brightness(value)(*inputs)\n        return outputs\n\nclass RandomChoiceBrightness(object):\n\n    def __init__(self, values, p=None):\n        """"""\n        Alter the Brightness of an image with a value randomly selected\n        from the list of given values with given probabilities\n\n        Arguments\n        ---------\n        values : list of floats\n            brightness values to sampled from\n        p : list of floats - same length as `values`\n            if None, values will be sampled uniformly.\n            Must sum to 1.\n        """"""\n        self.values = values\n        self.p = p\n\n    def __call__(self, *inputs):\n        value = th_random_choice(self.values, p=self.p)\n        outputs = Brightness(value)(*inputs)\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\nclass Saturation(object):\n\n    def __init__(self, value):\n        """"""\n        Alter the Saturation of image\n\n        Arguments\n        ---------\n        value : float\n            =-1 : gray\n            <0 : colors are more muted\n            =0 : image stays the same\n            >0 : colors are more pure\n            =1 : most saturated\n        """"""\n        self.value = max(min(value,1.0),-1.0)\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _in_gs = Grayscale(keep_channels=True)(_input)\n            alpha = 1.0 + self.value\n            _in = th.clamp(_blend(_input, _in_gs, alpha), 0, 1)\n            outputs.append(_in)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomSaturation(object):\n\n    def __init__(self, min_val, max_val):\n        """"""\n        Alter the Saturation of an image with a value randomly selected\n        between `min_val` and `max_val`\n\n        Arguments\n        ---------\n        min_val : float\n            min range\n        max_val : float\n            max range\n        """"""\n        self.values = (min_val, max_val)\n\n    def __call__(self, *inputs):\n        value = random.uniform(self.values[0], self.values[1])\n        outputs = Saturation(value)(*inputs)\n        return outputs\n\nclass RandomChoiceSaturation(object):\n\n    def __init__(self, values, p=None):\n        """"""\n        Alter the Saturation of an image with a value randomly selected\n        from the list of given values with given probabilities\n\n        Arguments\n        ---------\n        values : list of floats\n            saturation values to sampled from\n        p : list of floats - same length as `values`\n            if None, values will be sampled uniformly.\n            Must sum to 1.\n\n        """"""\n        self.values = values\n        self.p = p\n\n    def __call__(self, *inputs):\n        value = th_random_choice(self.values, p=self.p)\n        outputs = Saturation(value)(*inputs)\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\nclass Contrast(object):\n    """"""\n\n    """"""\n    def __init__(self, value):\n        """"""\n        Adjust Contrast of image.\n\n        Contrast is adjusted independently for each channel of each image.\n\n        For each channel, this Op computes the mean of the image pixels \n        in the channel and then adjusts each component x of each pixel to \n        (x - mean) * contrast_factor + mean.\n\n        Arguments\n        ---------\n        value : float\n            smaller value: less contrast\n            ZERO: channel means\n            larger positive value: greater contrast\n            larger negative value: greater inverse contrast\n        """"""\n        self.value = value\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            channel_means = _input.mean(1).mean(2)\n            channel_means = channel_means.expand_as(_input)\n            _input = th.clamp((_input - channel_means) * self.value + channel_means,0,1)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nclass RandomContrast(object):\n\n    def __init__(self, min_val, max_val):\n        """"""\n        Alter the Contrast of an image with a value randomly selected\n        between `min_val` and `max_val`\n\n        Arguments\n        ---------\n        min_val : float\n            min range\n        max_val : float\n            max range\n        """"""\n        self.values = (min_val, max_val)\n\n    def __call__(self, *inputs):\n        value = random.uniform(self.values[0], self.values[1])\n        outputs = Contrast(value)(*inputs)\n        return outputs\n\nclass RandomChoiceContrast(object):\n\n    def __init__(self, values, p=None):\n        """"""\n        Alter the Contrast of an image with a value randomly selected\n        from the list of given values with given probabilities\n\n        Arguments\n        ---------\n        values : list of floats\n            contrast values to sampled from\n        p : list of floats - same length as `values`\n            if None, values will be sampled uniformly.\n            Must sum to 1.\n\n        """"""\n        self.values = values\n        self.p = p\n\n    def __call__(self, *inputs):\n        value = th_random_choice(self.values, p=None)\n        outputs = Contrast(value)(*inputs)\n        return outputs\n\n# ----------------------------------------------------\n# ----------------------------------------------------\n\ndef rgb_to_hsv(x):\n    """"""\n    Convert from RGB to HSV\n    """"""\n    hsv = th.zeros(*x.size())\n    c_min = x.min(0)\n    c_max = x.max(0)\n\n    delta = c_max[0] - c_min[0]\n\n    # set H\n    r_idx = c_max[1].eq(0)\n    hsv[0][r_idx] = ((x[1][r_idx] - x[2][r_idx]) / delta[r_idx]) % 6\n    g_idx = c_max[1].eq(1)\n    hsv[0][g_idx] = 2 + ((x[2][g_idx] - x[0][g_idx]) / delta[g_idx])\n    b_idx = c_max[1].eq(2)\n    hsv[0][b_idx] = 4 + ((x[0][b_idx] - x[1][b_idx]) / delta[b_idx])\n    hsv[0] = hsv[0].mul(60)\n\n    # set S\n    hsv[1] = delta / c_max[0]\n\n    # set V - good\n    hsv[2] = c_max[0]\n\n    return hsv\n'"
torchsample/transforms/tensor_transforms.py,6,"b'\nimport os\nimport random\nimport math\nimport numpy as np\n\nimport torch as th\nfrom torch.autograd import Variable\n\nfrom ..utils import th_random_choice\n\nclass Compose(object):\n    """"""\n    Composes several transforms together.\n    """"""\n    def __init__(self, transforms):\n        """"""\n        Composes (chains) several transforms together into\n        a single transform\n\n        Arguments\n        ---------\n        transforms : a list of transforms\n            transforms will be applied sequentially\n        """"""\n        self.transforms = transforms\n\n    def __call__(self, *inputs):\n        for transform in self.transforms:\n            if not isinstance(inputs, (list,tuple)):\n                inputs = [inputs]\n            inputs = transform(*inputs)\n        return inputs\n\n\nclass RandomChoiceCompose(object):\n    """"""\n    Randomly choose to apply one transform from a collection of transforms\n\n    e.g. to randomly apply EITHER 0-1 or -1-1 normalization to an input:\n        >>> transform = RandomChoiceCompose([RangeNormalize(0,1),\n                                             RangeNormalize(-1,1)])\n        >>> x_norm = transform(x) # only one of the two normalizations is applied\n    """"""\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, *inputs):\n        tform = random.choice(self.transforms)\n        outputs = tform(*inputs)\n        return outputs\n\n\nclass ToTensor(object):\n    """"""\n    Converts a numpy array to torch.Tensor\n    """"""\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = th.from_numpy(_input)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass ToVariable(object):\n    """"""\n    Converts a torch.Tensor to autograd.Variable\n    """"""\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = Variable(_input)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass ToCuda(object):\n    """"""\n    Moves an autograd.Variable to the GPU\n    """"""\n    def __init__(self, device=0):\n        """"""\n        Moves an autograd.Variable to the GPU\n\n        Arguments\n        ---------\n        device : integer\n            which GPU device to put the input(s) on\n        """"""\n        self.device = device\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.cuda(self.device)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass ToFile(object):\n    """"""\n    Saves an image to file. Useful as a pass-through ransform\n    when wanting to observe how augmentation affects the data\n\n    NOTE: Only supports saving to Numpy currently\n    """"""\n    def __init__(self, root):\n        """"""\n        Saves an image to file. Useful as a pass-through ransform\n        when wanting to observe how augmentation affects the data\n\n        NOTE: Only supports saving to Numpy currently\n\n        Arguments\n        ---------\n        root : string\n            path to main directory in which images will be saved\n        """"""\n        if root.startswith(\'~\'):\n            root = os.path.expanduser(root)\n        self.root = root\n        self.counter = 0\n\n    def __call__(self, *inputs):\n        for idx, _input in inputs:\n            fpath = os.path.join(self.root, \'img_%i_%i.npy\'%(self.counter, idx))\n            np.save(fpath, _input.numpy())\n        self.counter += 1\n        return inputs\n\n\nclass ChannelsLast(object):\n    """"""\n    Transposes a tensor so that the channel dim is last\n    `HWC` and `DHWC` are aliases for this transform.    \n    """"""\n    def __init__(self, safe_check=False):\n        """"""\n        Transposes a tensor so that the channel dim is last\n        `HWC` and `DHWC` are aliases for this transform.\n\n        Arguments\n        ---------\n        safe_check : boolean\n            if true, will check if channels are already last and, if so,\n            will just return the inputs\n        """"""\n        self.safe_check = safe_check\n\n    def __call__(self, *inputs):\n        ndim = inputs[0].dim()\n        if self.safe_check:\n            # check if channels are already last\n            if inputs[0].size(-1) < inputs[0].size(0):\n                return inputs\n        plist = list(range(1,ndim))+[0]\n\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.permute(*plist)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nHWC = ChannelsLast\nDHWC = ChannelsLast\n\nclass ChannelsFirst(object):\n    """"""\n    Transposes a tensor so that the channel dim is first.\n    `CHW` and `CDHW` are aliases for this transform.\n    """"""\n    def __init__(self, safe_check=False):\n        """"""\n        Transposes a tensor so that the channel dim is first.\n        `CHW` and `CDHW` are aliases for this transform.\n\n        Arguments\n        ---------\n        safe_check : boolean\n            if true, will check if channels are already last and, if so,\n            will just return the inputs\n        """"""\n        self.safe_check = safe_check\n\n    def __call__(self, *inputs):\n        ndim = inputs[0].dim()\n        if self.safe_check:\n            # check if channels are already first\n            if inputs[0].size(0) < inputs[0].size(-1):\n                return inputs\n        plist = [ndim-1] + list(range(0,ndim-1))\n\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.permute(*plist)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nCHW = ChannelsFirst\nCDHW = ChannelsFirst\n\nclass TypeCast(object):\n    """"""\n    Cast a torch.Tensor to a different type\n    """"""\n    def __init__(self, dtype=\'float\'):\n        """"""\n        Cast a torch.Tensor to a different type\n\n        Arguments\n        ---------\n        dtype : string or torch.*Tensor literal or list of such\n            data type to which input(s) will be cast.\n            If list, it should be the same length as inputs.\n        """"""\n        if isinstance(dtype, (list,tuple)):\n            dtypes = []\n            for dt in dtype:\n                if isinstance(dt, str):\n                    if dt == \'byte\':\n                        dt = th.ByteTensor\n                    elif dt == \'double\':\n                        dt = th.DoubleTensor\n                    elif dt == \'float\':\n                        dt = th.FloatTensor\n                    elif dt == \'int\':\n                        dt = th.IntTensor\n                    elif dt == \'long\':\n                        dt = th.LongTensor\n                    elif dt == \'short\':\n                        dt = th.ShortTensor\n                dtypes.append(dt)\n            self.dtype = dtypes\n        else:\n            if isinstance(dtype, str):\n                if dtype == \'byte\':\n                    dtype = th.ByteTensor\n                elif dtype == \'double\':\n                    dtype = th.DoubleTensor\n                elif dtype == \'float\':\n                    dtype = th.FloatTensor\n                elif dtype == \'int\':\n                    dtype = th.IntTensor\n                elif dtype == \'long\':\n                    dtype = th.LongTensor\n                elif dtype == \'short\':\n                    dtype = th.ShortTensor\n            self.dtype = dtype\n\n    def __call__(self, *inputs):\n        if not isinstance(self.dtype, (tuple,list)):\n            dtypes = [self.dtype]*len(inputs)\n        else:\n            dtypes = self.dtype\n        \n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.type(dtypes[idx])\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass AddChannel(object):\n    """"""\n    Adds a dummy channel to an image. \n    This will make an image of size (28, 28) to now be\n    of size (1, 28, 28), for example.\n    """"""\n    def __init__(self, axis=0):\n        """"""\n        Adds a dummy channel to an image, also known as\n        expanding an axis or unsqueezing a dim\n\n        Arguments\n        ---------\n        axis : integer\n            dimension to be expanded to singleton\n        """"""\n        self.axis = axis\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.unsqueeze(self.axis)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\nExpandAxis = AddChannel\nUnsqueeze = AddChannel\n\nclass Transpose(object):\n\n    def __init__(self, dim1, dim2):\n        """"""\n        Swaps two dimensions of a tensor\n\n        Arguments\n        ---------\n        dim1 : integer\n            first dim to switch\n        dim2 : integer\n            second dim to switch\n        """"""\n        self.dim1 = dim1\n        self.dim2 = dim2\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = th.transpose(_input, self.dim1, self.dim2)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass RangeNormalize(object):\n    """"""\n    Given min_val: (R, G, B) and max_val: (R,G,B),\n    will normalize each channel of the th.*Tensor to\n    the provided min and max values.\n\n    Works by calculating :\n        a = (max\'-min\')/(max-min)\n        b = max\' - a * max\n        new_value = a * value + b\n    where min\' & max\' are given values, \n    and min & max are observed min/max for each channel\n    \n    Arguments\n    ---------\n    min_range : float or integer\n        Min value to which tensors will be normalized\n    max_range : float or integer\n        Max value to which tensors will be normalized\n    fixed_min : float or integer\n        Give this value if every sample has the same min (max) and \n        you know for sure what it is. For instance, if you\n        have an image then you know the min value will be 0 and the\n        max value will be 255. Otherwise, the min/max value will be\n        calculated for each individual sample and this will decrease\n        speed. Dont use this if each sample has a different min/max.\n    fixed_max :float or integer\n        See above\n\n    Example:\n        >>> x = th.rand(3,5,5)\n        >>> rn = RangeNormalize((0,0,10),(1,1,11))\n        >>> x_norm = rn(x)\n\n    Also works with just one value for min/max:\n        >>> x = th.rand(3,5,5)\n        >>> rn = RangeNormalize(0,1)\n        >>> x_norm = rn(x)\n    """"""\n    def __init__(self, \n                 min_val, \n                 max_val):\n        """"""\n        Normalize a tensor between a min and max value\n\n        Arguments\n        ---------\n        min_val : float\n            lower bound of normalized tensor\n        max_val : float\n            upper bound of normalized tensor\n        """"""\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _min_val = _input.min()\n            _max_val = _input.max()\n            a = (self.max_val - self.min_val) / (_max_val - _min_val)\n            b = self.max_val- a * _max_val\n            _input = _input.mul(a).add(b)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass StdNormalize(object):\n    """"""\n    Normalize torch tensor to have zero mean and unit std deviation\n    """"""\n    def __call__(self, *inputs):\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.sub(_input.mean()).div(_input.std())\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass Slice2D(object):\n\n    def __init__(self, axis=0, reject_zeros=False):\n        """"""\n        Take a random 2D slice from a 3D image along \n        a given axis. This image should not have a 4th channel dim.\n\n        Arguments\n        ---------\n        axis : integer in {0, 1, 2}\n            the axis on which to take slices\n\n        reject_zeros : boolean\n            whether to reject slices that are all zeros\n        """"""\n        self.axis = axis\n        self.reject_zeros = reject_zeros\n\n    def __call__(self, x, y=None):\n        while True:\n            keep_slice  = random.randint(0,x.size(self.axis)-1)\n            if self.axis == 0:\n                slice_x = x[keep_slice,:,:]\n                if y is not None:\n                    slice_y = y[keep_slice,:,:]\n            elif self.axis == 1:\n                slice_x = x[:,keep_slice,:]\n                if y is not None:\n                    slice_y = y[:,keep_slice,:]\n            elif self.axis == 2:\n                slice_x = x[:,:,keep_slice]\n                if y is not None:\n                    slice_y = y[:,:,keep_slice]\n\n            if not self.reject_zeros:\n                break\n            else:\n                if y is not None and th.sum(slice_y) > 0:\n                        break\n                elif th.sum(slice_x) > 0:\n                        break\n        if y is not None:\n            return slice_x, slice_y\n        else:\n            return slice_x\n\n\nclass RandomCrop(object):\n\n    def __init__(self, size):\n        """"""\n        Randomly crop a torch tensor\n\n        Arguments\n        --------\n        size : tuple or list\n            dimensions of the crop\n        """"""\n        self.size = size\n\n    def __call__(self, *inputs):\n        h_idx = random.randint(0,inputs[0].size(1)-self.size[0])\n        w_idx = random.randint(0,inputs[1].size(2)-self.size[1])\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input[:, h_idx:(h_idx+self.size[0]),w_idx:(w_idx+self.size[1])]\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n\nclass SpecialCrop(object):\n\n    def __init__(self, size, crop_type=0):\n        """"""\n        Perform a special crop - one of the four corners or center crop\n\n        Arguments\n        ---------\n        size : tuple or list\n            dimensions of the crop\n\n        crop_type : integer in {0,1,2,3,4}\n            0 = center crop\n            1 = top left crop\n            2 = top right crop\n            3 = bottom right crop\n            4 = bottom left crop\n        """"""\n        if crop_type not in {0, 1, 2, 3, 4}:\n            raise ValueError(\'crop_type must be in {0, 1, 2, 3, 4}\')\n        self.size = size\n        self.crop_type = crop_type\n    \n    def __call__(self, x, y=None):\n        if self.crop_type == 0:\n            # center crop\n            x_diff  = (x.size(1)-self.size[0])/2.\n            y_diff  = (x.size(2)-self.size[1])/2.\n            ct_x    = [int(math.ceil(x_diff)),x.size(1)-int(math.floor(x_diff))]\n            ct_y    = [int(math.ceil(y_diff)),x.size(2)-int(math.floor(y_diff))]\n            indices = [ct_x,ct_y]        \n        elif self.crop_type == 1:\n            # top left crop\n            tl_x = [0, self.size[0]]\n            tl_y = [0, self.size[1]]\n            indices = [tl_x,tl_y]\n        elif self.crop_type == 2:\n            # top right crop\n            tr_x = [0, self.size[0]]\n            tr_y = [x.size(2)-self.size[1], x.size(2)]\n            indices = [tr_x,tr_y]\n        elif self.crop_type == 3:\n            # bottom right crop\n            br_x = [x.size(1)-self.size[0],x.size(1)]\n            br_y = [x.size(2)-self.size[1],x.size(2)]\n            indices = [br_x,br_y]\n        elif self.crop_type == 4:\n            # bottom left crop\n            bl_x = [x.size(1)-self.size[0], x.size(1)]\n            bl_y = [0, self.size[1]]\n            indices = [bl_x,bl_y]\n        \n        x = x[:,indices[0][0]:indices[0][1],indices[1][0]:indices[1][1]]\n\n        if y is not None:\n            y = y[:,indices[0][0]:indices[0][1],indices[1][0]:indices[1][1]]\n            return x, y\n        else:\n            return x\n\n\nclass Pad(object):\n\n    def __init__(self, size):\n        """"""\n        Pads an image to the given size\n\n        Arguments\n        ---------\n        size : tuple or list\n            size of crop\n        """"""\n        self.size = size\n\n    def __call__(self, x, y=None):\n        x = x.numpy()\n        shape_diffs = [int(np.ceil((i_s - d_s))) for d_s,i_s in zip(x.shape,self.size)]\n        shape_diffs = np.maximum(shape_diffs,0)\n        pad_sizes = [(int(np.ceil(s/2.)),int(np.floor(s/2.))) for s in shape_diffs]\n        x = np.pad(x, pad_sizes, mode=\'constant\')\n        if y is not None:\n            y = y.numpy()\n            y = np.pad(y, pad_sizes, mode=\'constant\')\n            return th.from_numpy(x), th.from_numpy(y)\n        else:\n            return th.from_numpy(x)\n\n\nclass RandomFlip(object):\n\n    def __init__(self, h=True, v=False, p=0.5):\n        """"""\n        Randomly flip an image horizontally and/or vertically with\n        some probability.\n\n        Arguments\n        ---------\n        h : boolean\n            whether to horizontally flip w/ probability p\n\n        v : boolean\n            whether to vertically flip w/ probability p\n\n        p : float between [0,1]\n            probability with which to apply allowed flipping operations\n        """"""\n        self.horizontal = h\n        self.vertical = v\n        self.p = p\n\n    def __call__(self, x, y=None):\n        x = x.numpy()\n        if y is not None:\n            y = y.numpy()\n        # horizontal flip with p = self.p\n        if self.horizontal:\n            if random.random() < self.p:\n                x = x.swapaxes(2, 0)\n                x = x[::-1, ...]\n                x = x.swapaxes(0, 2)\n                if y is not None:\n                    y = y.swapaxes(2, 0)\n                    y = y[::-1, ...]\n                    y = y.swapaxes(0, 2)\n        # vertical flip with p = self.p\n        if self.vertical:\n            if random.random() < self.p:\n                x = x.swapaxes(1, 0)\n                x = x[::-1, ...]\n                x = x.swapaxes(0, 1)\n                if y is not None:\n                    y = y.swapaxes(1, 0)\n                    y = y[::-1, ...]\n                    y = y.swapaxes(0, 1)\n        if y is None:\n            # must copy because torch doesnt current support neg strides\n            return th.from_numpy(x.copy())\n        else:\n            return th.from_numpy(x.copy()),th.from_numpy(y.copy())\n\n\nclass RandomOrder(object):\n    """"""\n    Randomly permute the channels of an image\n    """"""\n    def __call__(self, *inputs):\n        order = th.randperm(inputs[0].dim())\n        outputs = []\n        for idx, _input in enumerate(inputs):\n            _input = _input.index_select(0, order)\n            outputs.append(_input)\n        return outputs if idx > 1 else outputs[0]\n\n'"
tests/integration/fit_complex/multi_input_multi_target.py,2,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchsample.modules import ModuleTrainer\nfrom torchsample import regularizers as regs\nfrom torchsample import constraints as cons\nfrom torchsample import initializers as inits\nfrom torchsample import callbacks as cbks\nfrom torchsample import metrics\nfrom torchsample import transforms as tforms\n\nimport os\nfrom torchvision import datasets\n\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:100]\ny_test = y_test[:100]\n\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x, y, z):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x), F.log_softmax(x), F.log_softmax(x)\n\n# with one loss function given\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\nregularizers = [regs.L1Regularizer(1e-4, 'fc*'), regs.L2Regularizer(1e-5, 'conv*')]\nconstraints = [cons.UnitNorm(5, 'batch', 'fc*'),\n               cons.MaxNorm(5, 0, 'batch', 'conv*')]\ncallbacks = [cbks.ReduceLROnPlateau(monitor='loss', verbose=1)]\n\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta',\n                regularizers=regularizers,\n                constraints=constraints,\n                callbacks=callbacks)\n\ntrainer.fit([x_train, x_train, x_train], \n            [y_train, y_train, y_train],\n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\nyp1, yp2, yp3 = trainer.predict([x_train, x_train, x_train])\nprint(yp1.size(), yp2.size(), yp3.size())\n\neval_loss = trainer.evaluate([x_train, x_train, x_train],\n                             [y_train, y_train, y_train])\nprint(eval_loss)\n\n# With multiple loss functions given\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ntrainer.compile(loss=['nll_loss', 'nll_loss', 'nll_loss'],\n                optimizer='adadelta',\n                regularizers=regularizers,\n                constraints=constraints,\n                callbacks=callbacks)\n\ntrainer.fit([x_train, x_train, x_train], \n            [y_train, y_train, y_train],\n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\n# should raise exception for giving multiple loss functions \n# but not giving a loss function for every input\ntry:\n    model = Network()\n    trainer = ModuleTrainer(model)\n\n    trainer.compile(loss=['nll_loss', 'nll_loss'],\n                    optimizer='adadelta',\n                    regularizers=regularizers,\n                    constraints=constraints,\n                    callbacks=callbacks)\n\n    trainer.fit([x_train, x_train, x_train], \n                [y_train, y_train, y_train],\n                num_epoch=3, \n                batch_size=128,\n                verbose=1)\nexcept:\n    print('Exception correctly caught')\n\n"""
tests/integration/fit_loader_simple/single_input_multi_target.py,3,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nfrom torchsample.modules import ModuleTrainer\nfrom torchsample import TensorDataset\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]\n\ntrain_data = TensorDataset(x_train, [y_train, y_train])\ntrain_loader = DataLoader(train_data, batch_size=128)\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x), F.log_softmax(x)\n\n\n# one loss function for multiple targets\nmodel = Network()\ntrainer = ModuleTrainer(model)\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta')\n\ntrainer.fit_loader(train_loader,\n                    num_epoch=3, \n                    verbose=1)\nypred1, ypred2 = trainer.predict(x_train)\nprint(ypred1.size(), ypred2.size())\n\neval_loss = trainer.evaluate(x_train, [y_train, y_train])\nprint(eval_loss)\n# multiple loss functions\nmodel = Network()\ntrainer = ModuleTrainer(model)\ntrainer.compile(loss=['nll_loss', 'nll_loss'],\n                optimizer='adadelta')\ntrainer.fit_loader(train_loader,\n                   num_epoch=3, \n                   verbose=1)\n\n\n\n"""
tests/integration/fit_loader_simple/single_input_single_target.py,3,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nfrom torchsample.modules import ModuleTrainer\nfrom torchsample import TensorDataset\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]\n\ntrain_data = TensorDataset(x_train, y_train)\ntrain_loader = DataLoader(train_data, batch_size=128)\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        #x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\n\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta')\n\ntrainer.fit_loader(train_loader,\n                   num_epoch=3,\n                   verbose=1)\n\nypred = trainer.predict(x_train)\nprint(ypred.size())\n\neval_loss = trainer.evaluate(x_train, y_train)\nprint(eval_loss)\n\nprint(trainer.history)\n#print(trainer.history['loss'])\n\n"""
tests/integration/fit_simple/simple_multi_input_multi_target.py,2,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchsample.modules import ModuleTrainer\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:100]\ny_test = y_test[:100]\n\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x, y, z):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x), F.log_softmax(x), F.log_softmax(x)\n\n# with one loss function given\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta')\n\ntrainer.fit([x_train, x_train, x_train], \n            [y_train, y_train, y_train],\n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\nyp1, yp2, yp3 = trainer.predict([x_train, x_train, x_train])\nprint(yp1.size(), yp2.size(), yp3.size())\n\neval_loss = trainer.evaluate([x_train, x_train, x_train],\n                             [y_train, y_train, y_train])\nprint(eval_loss)\n\n# With multiple loss functions given\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ntrainer.compile(loss=['nll_loss', 'nll_loss', 'nll_loss'],\n                optimizer='adadelta')\n\ntrainer.fit([x_train, x_train, x_train], \n            [y_train, y_train, y_train],\n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\n# should raise exception for giving multiple loss functions \n# but not giving a loss function for every input\ntry:\n    model = Network()\n    trainer = ModuleTrainer(model)\n\n    trainer.compile(loss=['nll_loss', 'nll_loss'],\n                    optimizer='adadelta')\n\n    trainer.fit([x_train, x_train, x_train], \n                [y_train, y_train, y_train],\n                num_epoch=3, \n                batch_size=128,\n                verbose=1)\nexcept:\n    print('Exception correctly caught')\n\n"""
tests/integration/fit_simple/simple_multi_input_no_target.py,2,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchsample.modules import ModuleTrainer\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]\n\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 1)\n\n    def forward(self, x, y, z):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return th.abs(10 - x)\n\n\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ntrainer.compile(loss='unconstrained_sum',\n                optimizer='adadelta')\n\ntrainer.fit([x_train, x_train, x_train],\n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\nypred = trainer.predict([x_train, x_train, x_train])\nprint(ypred.size())\n\neval_loss = trainer.evaluate([x_train, x_train, x_train])\nprint(eval_loss)\n\n"""
tests/integration/fit_simple/simple_multi_input_single_target.py,2,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchsample.modules import ModuleTrainer\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:100]\ny_test = y_test[:100]\n\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x, y, z):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\n\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta')\n\ntrainer.fit([x_train, x_train, x_train], y_train,\n            val_data=([x_test, x_test, x_test], y_test),\n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\nypred = trainer.predict([x_train, x_train, x_train])\nprint(ypred.size())\n\neval_loss = trainer.evaluate([x_train, x_train, x_train], y_train)\nprint(eval_loss)"""
tests/integration/fit_simple/single_input_multi_target.py,2,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchsample.modules import ModuleTrainer\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]\n\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x), F.log_softmax(x)\n\n\n# one loss function for multiple targets\nmodel = Network()\ntrainer = ModuleTrainer(model)\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta')\n\ntrainer.fit(x_train, \n            [y_train, y_train], \n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\nypred1, ypred2 = trainer.predict(x_train)\nprint(ypred1.size(), ypred2.size())\n\neval_loss = trainer.evaluate(x_train, [y_train, y_train])\nprint(eval_loss)\n# multiple loss functions\nmodel = Network()\ntrainer = ModuleTrainer(model)\ntrainer.compile(loss=['nll_loss', 'nll_loss'],\n                optimizer='adadelta')\ntrainer.fit(x_train, \n            [y_train, y_train], \n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\n\n\n"""
tests/integration/fit_simple/single_input_no_target.py,2,"b""\nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchsample.modules import ModuleTrainer\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]\n\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 1)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return th.abs(10 - x)\n\n\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ntrainer.compile(loss='unconstrained_sum',\n                optimizer='adadelta')\n\ntrainer.fit(x_train,\n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\nypred = trainer.predict(x_train)\nprint(ypred.size())\n\neval_loss = trainer.evaluate(x_train, None)\nprint(eval_loss)"""
tests/integration/fit_simple/single_input_single_target.py,2,"b"" \nimport torch as th\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torchsample.modules import ModuleTrainer\nfrom torchsample import regularizers as reg\nfrom torchsample import constraints as con\n\nimport os\nfrom torchvision import datasets\nROOT = '/users/ncullen/desktop/data/mnist'\ndataset = datasets.MNIST(ROOT, train=True, download=True)\nx_train, y_train = th.load(os.path.join(dataset.root, 'processed/training.pt'))\nx_test, y_test = th.load(os.path.join(dataset.root, 'processed/test.pt'))\n\nx_train = x_train.float()\ny_train = y_train.long()\nx_test = x_test.float()\ny_test = y_test.long()\n\nx_train = x_train / 255.\nx_test = x_test / 255.\nx_train = x_train.unsqueeze(1)\nx_test = x_test.unsqueeze(1)\n\n# only train on a subset\nx_train = x_train[:1000]\ny_train = y_train[:1000]\nx_test = x_test[:1000]\ny_test = y_test[:1000]\n\n\n# Define your model EXACTLY as if you were using nn.Module\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(1600, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1, 1600)\n        x = F.relu(self.fc1(x))\n        #x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)\n\n\nmodel = Network()\ntrainer = ModuleTrainer(model)\n\ntrainer.compile(loss='nll_loss',\n                optimizer='adadelta',\n                regularizers=[reg.L1Regularizer(1e-4)])\n\ntrainer.fit(x_train, y_train, \n            val_data=(x_test, y_test),\n            num_epoch=3, \n            batch_size=128,\n            verbose=1)\n\nypred = trainer.predict(x_train)\nprint(ypred.size())\n\neval_loss = trainer.evaluate(x_train, y_train)\nprint(eval_loss)\n\nprint(trainer.history)\n#print(trainer.history['loss'])\n\n"""
