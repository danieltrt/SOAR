file_path,api_count,code
BERT/const.py,0,"b'PAD = 0\nUNK = 1\nSEP = 2\nCLS = 3\nMASK = 4\n\n\nWORD = {\n    UNK: \'<unk>\',\n    PAD: \'<pad>\',\n    SEP: \'<sep>\',\n    CLS: \'<cls>\',\n    MASK: \'<mask>\',\n}\n\n\nRANDOM_MARK = 0.8\nRANDOM_WORD = 0.5\nRANDOM_WORD_SAMPLE = 0.15\nRANDOM_SENT = 0.5\n\nNEXT = 1\nNOT_NEXT = 0\n\nSEGMENTA = 1\nSEGMENTB = 2\n\nINIT_RANGE = 0.02\n\nNOT_USE_WEIGHT_DECAY = [\'bias\', \'gamma\', \'beta\']\nSPLIT_CODE = ""@@@###@@@""\n'"
BERT/corpus.py,1,"b'import torch\n\nfrom const import *\n\n\ndef word2idx(sents, word2idx):\n    results = []\n    for t1, t2 in sents:\n        t1 = [word2idx[w] if w in word2idx else UNK for w in t1]\n        t2 = [word2idx[w] if w in word2idx else UNK for w in t2]\n        results.append([t1, t2])\n\n    return results\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK,\n            WORD[SEP]: SEP,\n            WORD[CLS]: CLS,\n            WORD[MASK]: MASK\n        }\n        self.idx = len(self.word2idx)\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, sents, min_count=5):\n        words = [word for sent in sents for word in sent[0] + sent[1]]\n        word_count = {w: 0 for w in set(words)}\n        for w in words:\n            word_count[w] += 1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n\nclass Corpus(object):\n    def __init__(self, save_data=""data/corpus.pt"", max_len=128):\n\n        self.train = ""data/fuel.cnn""\n        self.save_data = save_data\n        self.word = Dictionary()\n        self.max_len = max_len\n\n    def parse_data(self, _file):\n        sents = []\n        for sentence in open(_file):\n            t1, t2 = sentence.strip().split(SPLIT_CODE)\n\n            words1 = t1.strip().split()\n            words2 = t2.strip().split()\n\n            sents.append([words1, words2])\n\n        print(f""ignored word count: {self.word(sents)}"")\n        self.sents = sents\n\n    def save(self):\n        self.parse_data(self.train)\n\n        data = {\n            \'max_len\': self.max_len,\n            \'dict\': self.word.word2idx,\n            \'word\': word2idx(self.sents, self.word.word2idx),\n        }\n\n        torch.save(data, self.save_data)\n        print(f\'Finish dumping the data to file - {self.save_data}\')\n        print(f\'words length - {len(self.word)}\')\n\n\nif __name__ == ""__main__"":\n    corpus = Corpus()\n    corpus.save()\n'"
BERT/data_loader.py,8,"b'import random\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\n\nfrom const import *\n\n\ndef truncate_seq_pair(tokens_a, tokens_b, max_length):\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_length:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop()\n        else:\n            tokens_b.pop()\n\n\nclass BERTDataSet(Dataset):\n    def __init__(self, sents, max_len, word_dict, steps):\n        self.sents_size = len(sents)\n        self.max_len = max_len\n        self.word_size = len(word_dict)\n        self.sents = np.asarray(sents)\n        self.steps = steps\n\n    def __len__(self):\n        return self.steps\n\n    def __getitem__(self, item):\n        inp, sent_label, word_label, segment_label = self.gen_one()\n\n        pos = torch.LongTensor(\n            [pos + 1 if w != PAD else 0 for pos, w in enumerate(inp)])\n        inp = torch.LongTensor(inp)\n        sent_label = torch.LongTensor([sent_label])\n        word_label = torch.LongTensor(word_label)\n        segment_label = torch.LongTensor(segment_label)\n\n        return inp, pos, sent_label, word_label, segment_label\n\n    def random_sample(self):\n        idx = np.random.choice(self.sents_size, 1)\n        return self.sents[idx][0]\n\n    def gather_sent(self):\n        sent = self.random_sample()\n        if random.random() > RANDOM_SENT:\n            return sent[0], sent[1], NEXT\n        else:\n            return sent[0], self.random_sample()[1], NOT_NEXT\n\n    def gather_word(self, sent):\n        label = []\n        for idx, word in enumerate(sent):\n            if random.random() < RANDOM_WORD_SAMPLE:\n                if random.random() < RANDOM_MARK:\n                    sent[idx] = MASK\n                else:\n                    if random.random() < RANDOM_WORD:\n                        sent[idx] = np.random.choice(self.word_size, 1)[0]\n                label.append(word)\n            else:\n                label.append(PAD)\n\n        return sent, label\n\n    def pad_sent(self, sent):\n        return sent + (self.max_len - len(sent)) * [PAD]\n\n    def gen_one(self):\n        t1, t2, label = self.gather_sent()\n        truncate_seq_pair(t1, t2, self.max_len - 3)\n\n        t1, t1_label = self.gather_word(t1)\n        t2, t2_label = self.gather_word(t2)\n\n        t1 = [CLS] + t1 + [SEP]\n        t2 = t2 + [SEP]\n\n        t1_label = [PAD] + t1_label + [PAD]\n        t2_label = t2_label + [PAD]\n\n        one = self.pad_sent(t1 + t2)\n        word_label = self.pad_sent(t1_label + t2_label)\n        segment_label = self.pad_sent([SEGMENTA for _ in range(\n            len(t1))] + [SEGMENTB for _ in range(len(t2))])\n\n        return one, label, word_label, segment_label\n\n\nif __name__ == ""__main__"":\n    from torch.utils.data import DataLoader\n\n    data = torch.load(""data/corpus.pt"")\n    ds = BERTDataSet(data[""word""], data[""max_len""], data[""dict""], 10000)\n    train_data_loader = DataLoader(ds, batch_size=1, num_workers=1)\n    for inp, pos, sent_label, word_label, segment_label in train_data_loader:\n        print(""="" * 90)\n        print(inp.shape)\n        print(pos.shape)\n        print(sent_label.shape)\n        print(word_label.shape)\n        print(segment_label.shape)\n        print(""="" * 90)\n        print(word_label.shape)\n        print((word_label > 0).float().sum())\n\n    itow = {v: k for k, v in data[""dict""].items()}\n\n    for _ in range(10):\n        one, label, word_label, segment_label = ds.gen_one()\n        print(label)\n        print("" "".join([itow[w] for w in one]))\n        print("" "".join([itow[w] for w in word_label]))\n        print(segment_label)\n        print(""="" * 30)\n'"
BERT/fine_tuning.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom const import *\n\nfrom model import BERT\n\n\nclass Classifier(nn.Module):\n    def __init__(self, lsz, args):\n        super().__init__()\n\n        self.bert = BERT(args)\n\n        self.sent_predict = nn.Linear(args.d_model, lsz)\n        self.sent_predict.weight.data.normal_(INIT_RANGE)\n        self.sent_predict.bias.data.zero_()\n\n    def get_trainable_parameters(self):\n        return self.bert.get_trainable_parameters()\n\n    def forward(self, inp, pos, segment_label):\n        _, sent_encode = self.bert(inp, pos, segment_label)\n        return F.log_softmax(self.sent_predict(sent_encode), dim=-1)\n\n    def load_model(self, path=""model.pt""):\n        data = torch.load(path)\n        self.bert.load_model(data[""weights""])\n'"
BERT/fuel.py,0,"b'import re\nimport zipfile\n\nfrom const import SPLIT_CODE\n\n\ndef normalizeString(s):\n    s = s.lower().strip()\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"""", s)\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    return s\n\n\ndef parse_sent(wfile, sent, min_len=5):\n    temp, sents = [], []\n    for word in sent:\n        word = normalizeString(word.decode(""utf-8""))\n        temp += [word]\n        if re.search(r""[.!?]"", word) is not None:\n            sents.append("" "".join(temp))\n            temp = []\n\n    if len(sents) > 1:\n        for index in range(len(sents) - 1):\n            wfile.write(SPLIT_CODE.join(\n                [sents[index], sents[index + 1]]) + ""\\r\\n"")\n\n\ndef fuel(inf, stop_tag=b""\\r\\n"", min_len=20):\n    zf = zipfile.ZipFile(inf)\n    namelist = [fname for fname in zf.namelist() if fname.find("".txt"") > 0]\n\n    contexts = []\n    with open(""data/fuel"", ""w"") as wf:\n        for name in namelist[:100]:\n            for line in zf.open(name):\n                if line == stop_tag and len(contexts) > 0:\n                    if len(contexts) > min_len:\n                        parse_sent(wf, contexts)\n                    contexts = []\n\n                words = line.strip().split()\n                contexts += words\n\n\nif __name__ == ""__main__"":\n    fuel(""data/Gutenberg.zip"")\n'"
BERT/fuel_cnn.py,0,"b'import re\nimport zipfile\n\nfrom const import SPLIT_CODE\n\n\ndef normalizeString(s):\n    s = s.lower().strip()\n    s = re.sub(r""[^a-zA-Z]+"", r"""", s)\n    return s\n\n\ndef parse_sent(wfile, sents):\n    context = []\n    for sent in sents:\n        temp = []\n        for word in sent:\n            word = normalizeString(word.decode(""utf-8""))\n            if len(word) != 0:\n                temp += [word]\n        context.append("" "".join(temp))\n\n    if len(context) > 1:\n        for index in range(len(context) - 1):\n            wfile.write(\n                SPLIT_CODE.join([context[index], context[index + 1]]) + ""\\r\\n"")\n\n\ndef fuel(inf, stop_tag=b""@highlight""):\n    zf = zipfile.ZipFile(inf)\n    namelist = [fname for fname in zf.namelist() if fname.find(\n        "".story"") > 0 and fname.find(""__MACOSX"") == -1]\n    print(len(namelist))\n    with open(""data/fuel.cnn"", ""w"") as wf:\n        for name in namelist[:10000]:\n            contexts = []\n            for line in zf.open(name):\n                content = line.strip()\n                if content == stop_tag:\n                    break\n\n                if len(content) == 0:\n                    continue\n\n                sent = line.split()\n                contexts.append(sent)\n\n            parse_sent(wf, contexts)\n\n\nif __name__ == ""__main__"":\n    fuel(""data/stories.zip"")\n'"
BERT/model.py,19,"b'import math\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.nn.functional as F\nimport numpy as np\n\nfrom const import *\n\n\ndef position(n_position, d_model):\n    position_enc = np.array([[pos / np.power(10000, 2 * i / d_model)\n                              for i in range(d_model)] for pos in range(n_position)])\n\n    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2])\n    position_enc[1:, 1::2] = np.sin(position_enc[1:, 1::2])\n\n    return torch.from_numpy(position_enc).float()\n\n\ndef get_attn_padding_mask(seq_q):\n    assert seq_q.dim() == 2\n    bsz, len_q = seq_q.size()\n    pad_attn_mask = seq_q.data.eq(PAD).unsqueeze(1)\n    pad_attn_mask = pad_attn_mask.expand(bsz, len_q, len_q)\n    return pad_attn_mask\n\n\nclass WordCrossEntropy(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, props, tgt):\n        tgt_props = props.gather(2, tgt.unsqueeze(2)).squeeze()\n        mask = (tgt > 0).float()\n        tgt_sum = mask.sum()\n        loss = -(tgt_props * mask).sum() / tgt_sum\n\n        _, index = torch.max(props, -1)\n        corrects = ((index.data == tgt).float() * mask).sum()\n\n        return loss, corrects, tgt_sum\n\n\nclass LayerNorm(nn.Module):\n    def __init__(self, hidden_size, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n        self.gamma = nn.Parameter(torch.ones(hidden_size))\n        self.beta = nn.Parameter(torch.zeros(hidden_size))\n\n    def forward(self, input):\n        mu = torch.mean(input, dim=-1, keepdim=True)\n        sigma = torch.std(input, dim=-1, keepdim=True).clamp(min=self.eps)\n        output = (input - mu) / sigma\n        return output * self.gamma.expand_as(output) + self.beta.expand_as(output)\n\n\nclass GELU(nn.Module):\n    """"""\n    different from 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n    """"""\n\n    def forward(self, x):\n        return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n\n\nclass PositionWise(nn.Module):\n    def __init__(self, d_model, d_ff, dropout):\n        super().__init__()\n\n        self.seq = nn.Sequential(\n            nn.Conv1d(d_model, d_ff, 1),\n            GELU(),\n            nn.Conv1d(d_ff, d_model, 1),\n            nn.Dropout(dropout)\n        )\n        self.lm = LayerNorm(d_model)\n\n    def forward(self, input):\n        residual = input\n        out = self.seq(input.transpose(1, 2)).transpose(1, 2)\n        return self.lm(residual + out)\n\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self, d_k, dropout):\n        super().__init__()\n        self.temper = np.power(d_k, 0.5)\n        self.dropout = nn.Dropout(dropout)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, q, k, v, attn_mask):\n        attn = torch.bmm(q, k.transpose(1, 2)) / self.temper\n        attn.data.masked_fill_(attn_mask, -float(\'inf\'))\n\n        attn = self.softmax(attn.view(-1, attn.size(2))).view(*attn.size())\n        attn = self.dropout(attn)\n        return torch.bmm(attn, v)\n\n\nclass MultiHeadAtt(nn.Module):\n    def __init__(self, n_head, d_model, dropout):\n        super().__init__()\n        self.n_head = n_head\n        self.d_v = self.d_k = d_k = d_model // n_head\n\n        for name in [""w_qs"", ""w_ks"", ""w_vs""]:\n            self.__setattr__(name,\n                             nn.Parameter(torch.FloatTensor(n_head, d_model, d_k)))\n\n        self.attention = ScaledDotProductAttention(d_k, dropout)\n        self.lm = LayerNorm(d_model)\n        self.w_o = nn.Linear(d_model, d_model, bias=False)\n        self.dropout = dropout\n\n        self.reset_parameters()\n\n    def forward(self, q, k, v, attn_mask):\n        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n        residual = q\n\n        bsz, len_q, d_model = q.size()\n        len_k, len_v = k.size(1), v.size(1)\n\n        def reshape(x):\n            """"""[bsz, len, d_*] -> [n_head x (bsz*len) x d_*]""""""\n            return x.repeat(n_head, 1, 1).view(n_head, -1, d_model)\n\n        q_s, k_s, v_s = map(reshape, [q, k, v])\n\n        q_s = torch.bmm(q_s, self.w_qs).view(-1, len_q, d_k)\n        k_s = torch.bmm(k_s, self.w_ks).view(-1, len_k, d_k)\n        v_s = torch.bmm(v_s, self.w_vs).view(-1, len_v, d_v)\n\n        outputs = self.attention(q_s, k_s, v_s, attn_mask.repeat(n_head, 1, 1))\n        outputs = torch.cat(torch.split(outputs, bsz, dim=0),\n                            dim=-1).view(-1, n_head * d_v)\n        outputs = F.dropout(self.w_o(outputs),\n                            p=self.dropout).view(bsz, len_q, -1)\n        return self.lm(outputs + residual)\n\n    def reset_parameters(self):\n        self.w_qs.data.normal_(std=INIT_RANGE)\n        self.w_ks.data.normal_(std=INIT_RANGE)\n        self.w_vs.data.normal_(std=INIT_RANGE)\n        self.w_o.weight.data.normal_(std=INIT_RANGE)\n\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, d_ff, n_head, dropout):\n        super().__init__()\n        self.mh = MultiHeadAtt(n_head, d_model, dropout)\n        self.pw = PositionWise(d_model, d_ff, dropout)\n\n    def forward(self, enc_input, slf_attn_mask):\n        enc_output = self.mh(\n            enc_input, enc_input, enc_input, slf_attn_mask)\n        enc_output = self.pw(enc_output)\n        return enc_output\n\n\nclass Pooler(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n\n        self.linear = nn.Linear(d_model, d_model)\n        self.linear.weight.data.normal_(std=INIT_RANGE)\n        self.linear.bias.data.zero_()\n\n    def forward(self, x):\n        x = self.linear(x[:, 0])\n        return F.tanh(x)\n\n\nclass BERT(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        n_position = args.max_len + 1\n\n        self.enc_ebd = nn.Embedding(args.vsz, args.d_model)\n        self.seg_ebd = nn.Embedding(3, args.d_model)\n        self.pos_ebd = nn.Embedding(n_position, args.d_model)\n        self.pos_ebd.weight.data = position(n_position, args.d_model)\n        self.pos_ebd.weight.requires_grad = False\n\n        self.dropout = nn.Dropout(p=args.dropout)\n        self.ebd_normal = LayerNorm(args.d_model)\n        self.out_normal = LayerNorm(args.d_model)\n\n        self.encodes = nn.ModuleList([EncoderLayer(\n            args.d_model, args.d_ff, args.n_head, args.dropout) for _ in range(args.n_stack_layers)])\n\n        self.pooler = Pooler(args.d_model)\n        self.transform = nn.Linear(\n            args.d_model, args.d_model)  # word hidden layer\n        self.gelu = GELU()\n\n    def reset_parameters(self):\n        self.enc_ebd.weight.data.normal_(std=INIT_RANGE)\n        self.seg_ebd.weight.data.normal_(std=INIT_RANGE)\n\n        self.transform.weight.data.normal_(std=INIT_RANGE)\n        self.transform.bias.data.zero_()\n\n    def forward(self, inp, pos, segment_label):\n        encode = self.enc_ebd(\n            inp) + self.seg_ebd(segment_label) + self.pos_ebd(pos)\n\n        encode = self.dropout(self.ebd_normal(encode))\n\n        slf_attn_mask = get_attn_padding_mask(inp)\n\n        for layer in self.encodes:\n            encode = layer(encode, slf_attn_mask)\n\n        sent_encode = self.pooler(encode)\n        word_encode = self.out_normal(self.gelu(self.transform(encode)))\n\n        return word_encode, sent_encode\n\n    def get_trainable_parameters(self):\n        return filter(lambda p: p.requires_grad, self.parameters())\n\n    def parameters_count(self):\n        return sum(x.numel() for x in self.parameters())\n\n    def save_model(self, args, data, path=""model.pt""):\n        torch.save({\n            ""args"": args,\n            ""weights"": self.state_dict(),\n            ""dict"": data[""dict""],\n            ""max_len"": data[""max_len""]\n        }, path)\n\n    def load_model(self, weights):\n        self.load_state_dict(weights)\n        self.cuda()\n'"
BERT/optimization.py,4,"b'import math\nimport torch\nfrom torch.optim import Optimizer\n\n\ndef get_lr(group, step):\n    lr, warmup, train_steps = group[\'lr\'], group[\'warmup\'], group[\'train_steps\']\n\n    if step < warmup:\n        return lr * (train_steps - step) / train_steps\n\n    return lr * step / warmup\n\n\nclass AdamWeightDecayOptimizer(Optimizer):\n    def __init__(self, params, lr=5e-5, warmup=10000, train_steps=100000, weight_decay=0.01, clip=1.0, betas=(0.9, 0.999), eps=1e-6):\n\n        if not 0.0 <= lr:\n            raise ValueError(f""Invalid learning rate: {lr}"")\n        if not 0.0 <= eps:\n            raise ValueError(f""Invalid epsilon value: {eps}"")\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(\n                f""Invalid beta parameter at index 0: {betas[0]}"")\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(\n                f""Invalid beta parameter at index 1: {betas[1]}"")\n        defaults = dict(lr=lr, betas=betas, eps=eps, warmup=warmup,\n                        train_steps=train_steps, weight_decay=weight_decay, clip=clip)\n        super(AdamWeightDecayOptimizer, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(AdamWeightDecayOptimizer, self).__setstate__(state)\n\n    def step(self, closure=None):\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group[\'params\']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                if grad.is_sparse:\n                    raise RuntimeError(\n                        \'Adam does not support sparse gradients, please consider SparseAdam instead\')\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state[\'step\'] = 0\n                    state[\'exp_avg\'] = torch.zeros_like(p.data)\n                    state[\'exp_avg_sq\'] = torch.zeros_like(p.data)\n\n                if group[\'clip\'] != 0.:\n                    torch.nn.utils.clip_grad_norm_(p, group[\'clip\'])\n\n                exp_avg, exp_avg_sq = state[\'exp_avg\'], state[\'exp_avg_sq\']\n                beta1, beta2 = group[\'betas\']\n\n                state[\'step\'] += 1\n\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                update = exp_avg / (exp_avg_sq.sqrt() + group[\'eps\'])\n\n                if group[\'weight_decay\'] != 0.:\n                    update += group[\'weight_decay\'] * p.data\n\n                update_with_lr = get_lr(group, state[\'step\']) * update\n                p.data.add_(-update_with_lr)\n\n        return loss\n\n\nif __name__ == ""__main__"":\n\n    from pretrain import Pretraining\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--batch_size\', type=int, default=2)\n    parser.add_argument(\'--lr\', type=float, default=5e-5)\n    parser.add_argument(\'--dropout\', type=float, default=0.1)\n    parser.add_argument(\'--d_model\', type=int, default=768)\n    parser.add_argument(\'--d_ff\', type=int, default=3072)\n    parser.add_argument(\'--n_head\', type=int, default=12)\n    parser.add_argument(\'--n_stack_layers\', type=int, default=12)\n    parser.add_argument(\'--n_warmup_steps\', type=int, default=10000)\n    parser.add_argument(\'--initializer_range\', type=float, default=0.02)\n    parser.add_argument(\'--weight_decay\', type=float, default=.01)\n    args = parser.parse_args()\n\n    args.vsz = 10\n    args.max_len = 16\n\n    model = Pretraining(2, args)\n\n    adam = AdamWeightDecayOptimizer(\n        model.get_optimizer_parameters(args.weight_decay), args.lr\n    )\n\n    group = {\n        ""lr"": 0.0005,\n        ""warmup"": 10000,\n        ""train_steps"": 100000,\n    }\n\n    print(get_lr(group, 10003))\n'"
BERT/pretrain.py,7,"b'import torch.nn as nn\nimport torch.nn.functional as F\n\nfrom const import *\n\nfrom model import BERT\n\n\nclass Pretraining(nn.Module):\n    def __init__(self, lsz, args):\n        super().__init__()\n\n        self.bert = BERT(args)\n\n        self.sent_predict = nn.Linear(args.d_model, lsz)\n        self.word_predict = nn.Linear(args.d_model, args.vsz)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        self.bert.reset_parameters()\n\n        self.sent_predict.weight.data.normal_(INIT_RANGE)\n        self.sent_predict.bias.data.zero_()\n\n        self.word_predict.weight = self.bert.enc_ebd.weight  # share weights\n        self.word_predict.bias.data.zero_()\n\n    def get_optimizer_parameters(self, decay):\n        return [{\'params\': [p for n, p in self.named_parameters(\n        ) if n.split(""."")[-1] not in NOT_USE_WEIGHT_DECAY and p.requires_grad], \'weight_decay\': decay},\n            {\'params\': [p for n, p in self.named_parameters(\n            ) if n.split(""."")[-1] in NOT_USE_WEIGHT_DECAY and p.requires_grad], \'weight_decay\': 0.0}]\n\n    def forward(self, inp, pos, segment_label):\n        word_encode, sent_encode = self.bert(inp, pos, segment_label)\n\n        sent = F.log_softmax(self.sent_predict(sent_encode), dim=-1)\n        word = F.log_softmax(self.word_predict(word_encode), dim=-1)\n\n        return word, sent\n\n\nif __name__ == ""__main__"":\n    import torch\n    import data_loader\n    from torch.utils.data import DataLoader\n    import time\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--steps\', type=int, default=1000000)\n    parser.add_argument(\'--batch_size\', type=int, default=2)\n    parser.add_argument(\'--seed\', type=int, default=1234)\n    parser.add_argument(\'--num_cpus\', type=int, default=5)\n    parser.add_argument(\'--cuda_devices\', type=str, default=\'0,3,5,6,7\')\n    parser.add_argument(\'--save\', type=str, default=\'bert.pt\')\n    parser.add_argument(\'--data\', type=str, default=\'data/corpus.pt\')\n    parser.add_argument(\'--lr\', type=float, default=1e-4)\n    parser.add_argument(\'--dropout\', type=float, default=0.1)\n    parser.add_argument(\'--d_model\', type=int, default=768)\n    parser.add_argument(\'--d_ff\', type=int, default=3072)\n    parser.add_argument(\'--n_head\', type=int, default=12)\n    parser.add_argument(\'--n_stack_layers\', type=int, default=12)\n    parser.add_argument(\'--n_warmup_steps\', type=int, default=10000)\n    parser.add_argument(\'--initializer_range\', type=float, default=0.02)\n    args = parser.parse_args()\n\n    data = torch.load(""data/corpus.pt"")\n    ds = data_loader.BERTDataSet(\n        data[""word""], data[""max_len""], data[""dict""], 10000)\n    train_data_loader = DataLoader(ds, batch_size=3, num_workers=5)\n    s_criterion = torch.nn.CrossEntropyLoss()\n    device_ids = [0, 2]\n    args.max_len = data[""max_len""]\n    args.vsz = ds.word_size\n    b = Pretraining(2, args)\n    b = b.cuda(device_ids[0])\n    paral_b = torch.nn.DataParallel(b, device_ids=device_ids)\n    print(\n        f""BERT have {b.bert.parameters_count()} paramerters in total"")\n    for datas in train_data_loader:\n        inp, pos, sent_label, word_label, segment_label = list(\n            map(lambda x: x.cuda(device_ids[0]), datas))\n\n        word, sent = paral_b(inp, pos, segment_label)\n        print(word.shape)\n        print(sent.shape)\n        print(torch.max(sent, 1)[1])\n        print(sent_label.shape)\n\n        s_criterion(sent, sent_label.view(-1))\n        b.bert.save_model(args, data)\n\n        time.sleep(2)\n'"
BERT/train.py,9,"b'import random\n\nimport torch\nfrom torch.utils.data import DataLoader\nimport numpy as np\n\nfrom model import WordCrossEntropy\nfrom optimization import AdamWeightDecayOptimizer\nfrom pretrain import Pretraining\nfrom data_loader import BERTDataSet\n\n\ntry:\n    import tensorflow as tf\nexcept ImportError:\n    tf = None\n\ntf_summary_writer = tf and tf.summary.FileWriter(""logdir"")\n\n\ndef add_summary_value(key, value, tf_step):\n    summary = tf.Summary(value=[tf.Summary.Value(tag=key, simple_value=value)])\n    tf_summary_writer.add_summary(summary, tf_step)\n\n\ndef main(args):\n    assert torch.cuda.is_available(), ""need to use GPUs""\n\n    use_cuda = torch.cuda.is_available()\n    cuda_devices = list(map(int, args.cuda_devices.split("","")))\n    is_multigpu = len(cuda_devices) > 1\n    device = ""cuda""\n\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.cuda.manual_seed(args.seed)\n    if is_multigpu > 1:\n        torch.cuda.manual_seed_all(args.seed)\n\n    data = torch.load(args.data)\n    dataset = BERTDataSet(data[\'word\'],\n                          data[\'max_len\'],\n                          data[""dict""],\n                          args.batch_size * args.steps)\n    training_data = DataLoader(dataset,\n                               batch_size=args.batch_size,\n                               num_workers=args.num_cpus)\n\n    args.max_len = data[""max_len""]\n    args.vsz = dataset.word_size\n    model = Pretraining(2, args)\n\n    print(\n        f""BERT have {model.bert.parameters_count()} paramerters in total"")\n\n    optimizer = AdamWeightDecayOptimizer(\n        model.get_optimizer_parameters(args.weight_decay),\n        lr=args.lr,\n        warmup=args.n_warmup_steps,\n        train_steps=args.steps,\n        weight_decay=args.weight_decay,\n        clip=args.clip\n    )\n\n    w_criterion = WordCrossEntropy()\n    w_criterion = w_criterion.to(device)\n\n    s_criterion = torch.nn.CrossEntropyLoss()\n\n    model = model.to(device)\n    model.train()\n    paral_model = torch.nn.DataParallel(model, device_ids=cuda_devices)\n\n    for step, datas in enumerate(training_data):\n        inp, pos, sent_label, word_label, segment_label = list(\n            map(lambda x: x.to(device), datas))\n        sent_label = sent_label.view(-1)\n        optimizer.zero_grad()\n        word, sent = paral_model(inp, pos, segment_label)\n        w_loss, w_corrects, tgt_sum = w_criterion(word, word_label)\n        s_loss = s_criterion(sent, sent_label)\n        loss = w_loss + s_loss\n        loss.backward()\n        optimizer.step()\n        s_corrects = (torch.max(sent, 1)[1].data == sent_label.data).sum()\n\n        print(f""[Step {step+1}/{args.steps}] [word_loss: {w_loss:.5f}, sent_loss: {s_loss:.5f}, loss: {loss:.5f}, w_pre: {w_corrects/tgt_sum*100:.2f}% {w_corrects}/{tgt_sum}, s_pre: {float(s_corrects)/args.batch_size*100:.2f}% {s_corrects}/{args.batch_size}]"")\n\n        if tf is not None:\n            add_summary_value(""Word loss"", w_loss, step)\n            add_summary_value(""Sent loss"", s_loss, step)\n            add_summary_value(""Loss"", loss, step)\n            add_summary_value(""Word predict"", w_corrects / tgt_sum, step)\n            add_summary_value(""Sent predict"", float(\n                s_corrects) / args.batch_size, step)\n            tf_summary_writer.flush()\n\n\nif __name__ == ""__main__"":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\'--steps\', type=int, default=100000)\n    parser.add_argument(\'--batch_size\', type=int, default=32)\n    parser.add_argument(\'--seed\', type=int, default=1234)\n    parser.add_argument(\'--num_cpus\', type=int, default=5)\n    parser.add_argument(\'--cuda_devices\', type=str, default=\'0,6,7\')\n    parser.add_argument(\'--save\', type=str, default=\'bert.pt\')\n    parser.add_argument(\'--data\', type=str, default=\'data/corpus.pt\')\n    parser.add_argument(\'--lr\', type=float, default=5e-5)\n    parser.add_argument(\'--dropout\', type=float, default=0.1)\n    parser.add_argument(\'--d_model\', type=int, default=768)\n    parser.add_argument(\'--d_ff\', type=int, default=3072)\n    parser.add_argument(\'--n_head\', type=int, default=12)\n    parser.add_argument(\'--n_stack_layers\', type=int, default=12)\n    parser.add_argument(\'--n_warmup_steps\', type=int, default=10000)\n    parser.add_argument(\'--clip\', type=float, default=1.0)\n    parser.add_argument(\'--weight_decay\', type=float, default=.01)\n\n    args = parser.parse_args()\n\n    main(args)\n'"
Customize/Embedding.py,2,"b'import torch\nimport torch.nn as nn\n\nimport numpy as np\n\n# using pre-trained word2vec init embedding\nclass PreEmbedding(nn.Module):\n    def __init__(self, pre_w2v, vocab_size, ebd_dim):\n        self.lookup_table = nn.Embedding(vocab_size, ebd_dim)\n\n        # load pre-trained word2vec\n        # 1st: check data type\n        assert isinstance(pre_w2v, np.ndarray)\n\n        # 2st: load\n        self.lookup_table.weight.data.copy_(torch.from_numpy(pre_w2v))\n\n        # 3st: frozen embedding weight\n        self.lookup_table.weight.requires_grad = False\n\n    def forward(self, x):\n        return self.lookup_table(x)\n'"
Customize/Highway.py,7,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\n\nimport math\n\nclass highway_layer(nn.Module):\n    def __init__(self, hsz, active):\n        super().__init__()\n\n        self.hsz = hsz\n        self.active = active\n\n        self.gate = nn.Linear(hsz, hsz)\n        self.h = nn.Linear(hsz, hsz)\n\n    def _init_weight(self):\n        stdv = 1. / math.sqrt(self.hsz)\n\n        self.gate.weight.data.uniform_(-stdv, stdv)\n        self.gate.bias.data.fill_(-1)\n\n        if active.__name__ == ""relu"":\n            init.xavier_normal(self.h.weight)\n        else:\n            self.h.weight.data.uniform_(-stdv, stdv)\n\n    def forward(self, x):\n        gate = F.sigmoid(self.gate(x))\n\n        return torch.mul(self.active(self.h(x)), gate) + torch.mul(x, (1 - gate))\n\nclass Highway(nn.Module):\n    def __init__(self, num_layers, hsz, active):\n        super().__init__()\n\n        self.layers = nn.ModuleList([\n            highway_layer(hsz, active) for _ in range(num_layers)])\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n\n        return x\n\nif __name__ == ""__main__"":\n    from torch.autograd import Variable\n\n    x = Variable(torch.randn((2, 4, 3)))\n    hw = Highway(2, 3, F.relu)\n\n    print(hw(x))\n\n    x = Variable(torch.randn((2, 3)))\n    hw = Highway(1, 3, F.tanh)\n\n    print(hw(x))\n'"
Customize/LSTM.py,6,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass C_LSTMCell(nn.Module):\n    def __init__(self, input_size, hidden_size, bias=True):\n        super().__init__()\n        # [4*out_feature, in_feature]\n        self.w_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n        # [4*out_feature, out_feature]\n        self.w_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n        if bias:\n            self.b_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n            self.b_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n        else:\n            self.b_ih = None\n            self.b_hh = None\n\n        for weight in self.parameters():\n            weight.data.uniform_(-0.1, 0.1)\n\n    def forward(self, input, hidden):\n        hx, cx = hidden\n        gates = F.linear(input, self.w_ih, self.b_ih) + \\\n            F.linear(hx, self.w_hh, self.b_hh)  # [bsz, 4*hidden_size]\n        in_gate, forget_gate, cell_gate, out_gate = gates.chunk(4, 1)\n        in_gate, forget_gate, out_gate = map(\n            F.sigmoid, [in_gate, forget_gate, out_gate])\n        cell_gate = F.tanh(cell_gate)\n\n        cy = forget_gate * cx + in_gate * cell_gate\n        hy = out_gate * F.tanh(cy)\n\n        return hy, cy\n'"
Customize/multi-GPU.py,9,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom torch.nn.parallel.data_parallel import DataParallel\n\n\nclass model(nn.Module):\n    def __init__(self, vocab_size, label_size, max_len, embed_dim=128, dropout=0.5):\n        super().__init__()\n\n        self.lookup_table = nn.Embedding(vocab_size, embed_dim)\n        self.logistic = nn.Linear(embed_dim * max_len, label_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        x = self.lookup_table(x)\n        x = self.logistic(x.view(x.size(0), -1))\n        x = self.dropout(x)\n        return F.log_softmax(x, dim=-1)\n\n\nclass DS(Dataset):\n    def __init__(self, src_sents, label, max_len):\n        self.sents_size = len(src_sents)\n        self._max_len = max_len\n        self._src_sents = np.asarray(src_sents)\n        self._label = label\n\n    def __len__(self):\n        return self.sents_size\n\n    def __getitem__(self, item):\n        def pad_to_longest(inst, max_len):\n            inst_data = np.array(inst + [0] * (max_len - len(inst)))\n            inst_data_tensor = torch.from_numpy(inst_data)\n            return inst_data_tensor\n\n        data = pad_to_longest(self._src_sents[item], self._max_len)\n        label = torch.tensor(self._label[item])\n\n        return data, label\n\n\ndevice = ""cuda""\n\ndata = torch.load(""corpus.pt"")\nds = DS(data[\'train\'][\'src\'],\n        data[\'train\'][\'label\'],\n        1000)\ntrain_data_loader = DataLoader(ds, batch_size=1000)\n\ndevice_ids = [0, 7]\n\nm = model(data[\'dict\'][\'vocab_size\'],\n          data[\'dict\'][\'label_size\'],\n          1000)\nm = m.to(device)\n\noptimizer = torch.optim.Adam(m.parameters())\ncriterion = torch.nn.CrossEntropyLoss()\nm = DataParallel(m, device_ids=device_ids)\n\n\nif __name__ == ""__main__"":\n    m.train()\n    for _ in range(100):\n        for data, label in train_data_loader:\n            data = data.to(device)\n            label = label.to(device)\n            optimizer.zero_grad()\n            target = m(data)\n\n            loss = criterion(target, label)\n            loss.backward()\n            optimizer.step()\n'"
Customize/pre_data.py,3,"b'import numpy as np\nimport pickle\nimport torch\n\n\nclass MiddleDataHandler(object):\n    """"""\n    save and load data for train\n    """"""\n\n    def __init__(self):\n        self.pk = pickle\n\n    def save(self, obj, _file):\n        """"""\n        args:\n            obj: dict\n            _file: the file to save obj\n        """"""\n        self.pk.dump(obj, open(_file, ""wb""), True)\n\n    def load(self, _file):\n        """"""\n        args:\n            _file: load dict from the file\n\n        return:\n            obj\n        """"""\n        return self.pk.load(open(_file, ""rb""))\n\n\ndef load_pre_w2c(_file, _dict):\n    """"""\n    load pre-train word2vec form file\n    args:\n        _file: word2vec file\n        _dict: dictionary: map word to index, middle data which is for train\n\n    return:\n        word map from obj to vec\n        type: matrix, numpy array\n    """"""\n\n    # contain w2v pre-train data\n    # key: word\n    # value: vec\n    w2c_dict = {}\n\n    # load and check length of vec\n    for line in open(_file):\n        temp = line.strip().split("" "")\n\n        # discard first line\n        if len(temp) < 10:\n            continue\n        w2c_dict[temp[0]] = list(map(float, temp[1:]))\n\n        # length of vec, just one time\n        if ""len_"" not in locals():\n            len_ = len(temp[1:])\n\n    # random init embedding: (0, 1]\n    emb_mx = np.random.rand(len(_dict), len_)\n    for word, idx in sorted(_dict.items(), key=lambda x: x[1]):\n        if word in w2c_dict:\n            emb_mx[idx] = np.asarray(w2c_dict[word])\n\n    return emb_mx\n\n\ndef to_one_hot(y, n_dims=None):\n    y_tensor = torch.tensor(y, dtype=torch.int64).view(-1, 1)\n    n_dims = n_dims if n_dims is not None else int(torch.max(y_tensor)) + 1\n    y_one_hot = torch.zeros(\n        y_tensor.size()[0], n_dims).scatter_(1, y_tensor, 1)\n    return y_one_hot\n\n\ndef is_chinese_char(c):\n    if ((c >= 0x4E00 and c <= 0x9FFF) or\n            (c >= 0x3400 and c <= 0x4DBF) or\n            (c >= 0x20000 and c <= 0x2A6DF) or\n            (c >= 0x2A700 and c <= 0x2B73F) or\n            (c >= 0x2B740 and c <= 0x2B81F) or\n            (c >= 0x2B820 and c <= 0x2CEAF) or\n            (c >= 0xF900 and c <= 0xFAFF) or\n            (c >= 0x2F800 and c <= 0x2FA1F)):\n        return True\n\n    return False\n'"
Customize/segmenter.py,0,"b'import os\nimport copy\nimport sys\nimport gzip\nimport codecs\n\nimport jieba\nimport jieba.posseg as pseg\n\n\ndef uutf8(s, from_enc=\'utf8\'):\n    if isinstance(s, bytes):\n        return s\n    return s.encode(from_enc)\n\n\ndef rstr(s, from_enc=\'utf8\', to_enc=\'utf8\'):\n    if isinstance(s, bytes):\n        return s.decode(to_enc)\n    if from_enc == to_enc:\n        return s\n    return uutf8(s, from_enc).decode(to_enc)\n\n\ndef sopen(filename, mode=\'rb\', enc=\'utf8\', errors=\'strict\'):\n    readMode = \'r\' in mode\n    if readMode and \'w\' in mode:\n        print(""Must be either read mode or write, but not both"")\n        raise\n\n    elif filename.endswith(\'.gz\'):\n        stream = gzip.GzipFile(filename, mode)\n    elif filename == \'-\':\n        if readMode:\n            stream = sys.stdin\n        else:\n            stream = sys.stdout\n    else:\n        stream = open(filename, mode)\n\n    if enc not in (None, \'byte\'):\n        if readMode:\n            return codecs.getreader(enc)(stream, errors)\n        else:\n            return codecs.getwriter(enc)(stream, errors)\n    return stream\n\n\nclass Jieba(object):\n    def __init__(self, useSynonym=False, HMM=False):\n\n        self.jieba = jieba\n        self.pseg = pseg\n        self.HMM = HMM\n        _path = os.path.normpath(\n            ""%s/"" % os.path.dirname(os.path.abspath(__file__)))\n        self.jieba.load_userdict(os.path.join(\n            _path, ""segmenter_dicts/default.dict""))\n\n        # synonym\n        if useSynonym:\n            self.synonym = {}\n            self.synonym_max_len = 0\n            for line in sopen(os.path.join(_path, ""segmenter_dicts/synonym"")):\n                fields = line.strip().split()\n                if len(fields) != 2:\n                    continue\n                self.synonym[fields[0]] = fields[1]\n                self.synonym_max_len = max(\n                    self.synonym_max_len, len(fields[0]))\n\n        # number\n        self.number = {\n            ""\xe9\x9b\xb6"": \'0\',\n            ""\xe4\xb8\x80"": \'1\',\n            ""\xe4\xba\x8c"": \'2\',\n            ""\xe4\xb8\x89"": \'3\',\n            ""\xe5\x9b\x9b"": \'4\',\n            ""\xe4\xba\x94"": \'5\',\n            ""\xe5\x85\xad"": \'6\',\n            ""\xe4\xb8\x83"": \'7\',\n            ""\xe5\x85\xab"": \'8\',\n            ""\xe4\xb9\x9d"": \'9\'}\n\n        # punct\n        self.punct = {\n            ""\xe3\x80\x80"": \' \',\n            ""\xef\xbd\x9e"": \'~\'\n        }\n\n    def join(self, words, syn=False, num=False, punct=True, period=True):\n        words = [w[0] for w in words]\n        if syn:\n            n = len(words)\n            for i in range(n):\n                if not words:\n                    continue\n\n                m = 0\n                j = i\n                while j < n:\n                    m += len(words[j])\n                    if m > self.synonym_max_len:\n                        break\n                    j += 1\n\n                while j > i:\n                    compound = u\'\'.join(words[i:j])\n                    if compound in self.synonym:\n                        compound = self.synonym[compound]\n                        words[i] = compound\n                        for k in range(i + 1, j):\n                            words[k] = u\'\'\n                        break\n                    j -= 1\n        res = u\'\'.join(words)\n\n        if num:\n            chs = []\n            for ch in res:\n                chs.append(self.number.get(ch, ch))\n            res = u\'\'.join(chs)\n\n        puncts = copy.deepcopy(self.punct)\n        if period:\n            puncts[u\'\xe3\x80\x82\'] = u\'.\'\n\n        if punct:\n            chs = []\n            for ch in res:\n                chs.append(puncts.get(ch, ch))\n            res = u\'\'.join(chs)\n        return res\n\n    def segment(self, text):\n        if not text:\n            return []\n        words = self.pseg.cut(uutf8(text, from_enc=\'utf8\'), HMM=self.HMM)\n        return [(rstr(w), f) for w, f in words]\n\n    def segment_search(self, text):\n        if not text:\n            return []\n        words = self.jieba.cut_for_search(uutf8(text, from_enc=\'utf8\'))\n        return [w for w in words]\n\n\nif __name__ == \'__main__\':\n    jb = Jieba(useSynonym=True, HMM=False)\n    print([e[0] for e in jb.segment(""\xe4\xbd\xa0\xe5\xae\x85\xe7\x94\xb7\xe5\xae\x85\xe5\xa5\xb3"")])\n    print([e[1] for e in jb.segment(""\xe5\x88\x98\xe4\xb9\x90\xe5\xa6\x8d\xe8\xb7\x9f\xe7\x8e\x8b\xe5\xae\x9d\xe5\xbc\xba\xe5\xbe\x88\xe9\x85\x8d\xe4\xba\xba\xe5\x90\x8c\xe6\xa0\xb7\xe8\xa7\x89\xe5\xbe\x97\xe4\xb9\x88"")])\n    print([e[0] for e in jb.segment(""\xe5\x88\x98\xe4\xb9\x90\xe5\xa6\x8d\xe8\xb7\x9f\xe7\x8e\x8b\xe5\xae\x9d\xe5\xbc\xba\xe5\xbe\x88\xe9\x85\x8d\xe4\xba\xba\xe5\x90\x8c\xe6\xa0\xb7\xe8\xa7\x89\xe5\xbe\x97\xe4\xb9\x88"")])\n    print([e[0] for e in jb.segment(""\xe5\x81\x9a\xe4\xba\xba\xe4\xb8\x8d\xe8\x83\xbd\xe5\xa4\xaaCNN"")])\n    print([e[0] for e in jb.segment(""\xe6\x88\x91\xe6\x98\xaf\xe5\x8c\x97\xe4\xba\xac\xe6\xb4\xbe\xe6\x9d\xa5\xe7\x9a\x84"")])\n    print([e[0] for e in jb.segment(""\xe5\x85\xb3\xe6\x88\x91\xe5\x90\x8a\xe4\xba\x8b"")])\n    print([e[0] for e in jb.segment(""hEllo\xef\xbc\x8c\xe9\xae\xae\xe8\x8a\xb1\xe5\xbf\xab\xe9\x80\x92\xe5\x82\xac\xe5\x8d\x95\xef\xbc\x9f"")])\n    print([e[0] for e in jb.segment(""\xe6\x88\x91\xe4\xbb\xac\xe4\xb8\xad\xe5\x87\xba\xe4\xba\x86\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\x9b\xe5\xbe\x92"")])\n    print(jb.segment_search(""\xe5\xb0\x8f\xe6\x98\x8e\xe7\xa1\x95\xe5\xa3\xab\xe6\xaf\x95\xe4\xb8\x9a\xe4\xba\x8e\xe4\xb8\xad\xe5\x9b\xbd\xe7\xa7\x91\xe5\xad\xa6\xe9\x99\xa2\xe8\xae\xa1\xe7\xae\x97\xe6\x89\x80\xef\xbc\x8c\xe5\x90\x8e\xe5\x9c\xa8\xe6\x97\xa5\xe6\x9c\xac\xe4\xba\xac\xe9\x83\xbd\xe5\xa4\xa7\xe5\xad\xa6\xe6\xb7\xb1\xe9\x80\xa0""))\n    print(\' \'.join([\'/\'.join(e) for e in jb.segment(""hEllo\xef\xbc\x8c\xe9\xae\xae\xe8\x8a\xb1\xe5\xbf\xab\xe9\x80\x92\xe5\x82\xac\xe5\x8d\x95\xef\xbc\x9f"")]))\n    print(\' \'.join([\'/\'.join(e) for e in jb.segment(""\xe5\x8c\x85\xe9\x82\xae\xe8\xb4\xb9"")]))\n    print(\' \'.join([\'/\'.join(e) for e in jb.segment(""\xe5\x85\x8d\xe9\x82\xae\xe8\xb4\xb9"")]))\n    print(\' \'.join([\'/\'.join(e) for e in jb.segment(""\xe5\xa4\x9a\xe4\xb9\x85\xe5\x87\xa0\xe5\xa4\xa9"")]))\n    print(jb.join(jb.segment(\'\xe4\xbd\xa0\xe7\x9a\x84\xe3\x80\x80\xe5\xbf\xab\xe9\x80\x92\xe5\x8d\x95\xe5\x8f\xb7\xe6\x98\xaf\xe5\xa4\x9a\xe5\xb0\x91\xef\xbc\x8cJason\xef\xbc\x8c\xe4\xb8\x80\xe7\x99\xbe\xe4\xba\x94\xe5\x8d\x81\xe4\xb8\x83\xef\xbd\x9e\xe3\x80\x82\'),\n                  syn=False, num=False, punct=True))\n    print(jb.join(jb.segment(""\xe5\x9c\xa8\xe5\x93\x88\xe6\x88\x91\xe5\x8b\x92\xe4\xb8\xaa\xe5\x8e\xbb\xe5\x9c\xa8\xe4\xb9\x88\xe6\x9c\x89\xe5\xb0\x91\xe4\xbc\x98\xe6\x83\xa0\xe6\x9c\x89\xe5\x95\xa5\xe6\x9c\x89\xe4\xbb\x80\xe4\xb9\x88\xe6\x99\x95\xe8\xa7\xa3\xe5\x86\xb3\xe4\xbf\xae\xe5\xa4\x8d\xe6\x9d\x90\xe8\xb4\xa8\xe8\xb4\xa8\xe5\x9c\xb0""),\n                  syn=True, num=True, punct=True, period=False))\n    print(\' \'.join([\'\'.join(e[0])\n                    for e in jb.segment(""redis\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe5\xb7\xb2\xe8\xa7\xa3\xe5\x86\xb3\xe8\xa1\xa5\xe5\x85\x85\xe4\xb8\x8b\xe5\x93\x88\xef\xbc\x8c\xe4\xb9\x9d\xe5\xbd\xa9\xe8\x8a\xb1\xe7\x94\xb0\xe6\x98\xaf\xe5\xae\xa2\xe6\x88\xb7\xe7\xab\xaf\xe5\x87\xba\xe7\x8e\xb0\xe6\x8e\x88\xe6\x9d\x83\xe8\xaf\xb4\xe6\x98\x8e\xe6\x9d\x90\xe8\xb4\xa8\xe8\xb4\xa8\xe5\x9c\xb0"")]))\n    print(\' \'.join([\'\'.join(e[0]) for e in jb.segment(""\xe8\xaf\xb7\xe5\xb8\xae\xe6\x88\x91\xe8\xa7\xa3\xe6\xa2\xa6"")]))\n    print([\'\'.join(e[0])\n           for e in jb.segment(""redis\xe9\x97\xae\xe9\xa2\x98\xef\xbc\x8c\xe5\xb7\xb2\xe8\xa7\xa3\xe5\x86\xb3\xe8\xa1\xa5\xe5\x85\x85\xe4\xb8\x8b\xe5\x93\x88\xef\xbc\x8c\xe4\xb9\x9d\xe5\xbd\xa9\xe8\x8a\xb1\xe7\x94\xb0\xe6\x98\xaf\xe5\xae\xa2\xe6\x88\xb7\xe7\xab\xaf\xe5\x87\xba\xe7\x8e\xb0\xe6\x8e\x88\xe6\x9d\x83\xe8\xaf\xb4\xe6\x98\x8e\xe6\x9d\x90\xe8\xb4\xa8\xe8\xb4\xa8\xe5\x9c\xb0"")])\n'"
DenseNet/model.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom collections import OrderedDict\n\nclass _Transition(nn.Module):\n    def __init__(self, in_channels, out_channels, dropout):\n        super().__init__()\n\n        self.layer = nn.Sequential(\n            nn.BatchNorm2d(in_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n            nn.AvgPool2d(2, stride=2)\n        )\n        self.dropout = dropout\n\n    def forward(self, input):\n        out = self.layer(input)\n        if self.dropout > 0.:\n            out = F.dropout(out, p=self.dropout)\n        return out\n\nclass _DenseBLayer(nn.Module):\n    def __init__(self, in_channels, growth_rate, dropout):\n        super().__init__()\n\n        self.layer = nn.Sequential(\n            nn.BatchNorm2d(in_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels, 4*growth_rate, kernel_size=1, bias=False),\n            nn.BatchNorm2d(4*growth_rate),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n        )\n        self.dropout = dropout\n\n    def forward(self, input):\n        out = self.layer(input)\n        out = torch.cat([out, input], 1)\n        if self.dropout > 0.:\n            out = F.dropout(out, p=self.dropout)\n        return out\n\nclass _DenseBlock(nn.Module):\n    def __init__(self, num_layers, growth_rate, in_channels, dropout):\n        super().__init__()\n\n        self.bottleneck = nn.Sequential(OrderedDict([(""dbl_{}"".format(l),\n            _DenseBLayer(in_channels + growth_rate*l, growth_rate, dropout)) for l in range(num_layers)]))\n\n    def forward(self, input):\n        return self.bottleneck(input)\n\nclass DenseNet(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        self.init_cnn_layer = nn.Sequential(OrderedDict([\n            (\'conv0\', nn.Conv2d(3, args.channels, kernel_size=3, padding=1, bias=False)),\n            (\'norm0\', nn.BatchNorm2d(args.channels)),\n            (\'relu0\', nn.ReLU(inplace=True))\n        ]))\n\n        denseblocks = []\n        for l, nums in enumerate(args.layer_nums):\n            denseblocks += [(""db_{}"".format(l), _DenseBlock(nums, args.growth_rate, args.channels, args.dropout))]\n            _in_channels = args.channels + args.growth_rate*nums\n            args.channels = _in_channels // 2\n            if l != len(args.layer_nums)-1:\n                denseblocks += [(""t_{}"".format(l), _Transition(_in_channels, args.channels, args.dropout))]\n\n        denseblocks += [(""nb_5"", nn.BatchNorm2d(_in_channels))]\n        denseblocks += [(""relu_5"", nn.ReLU(inplace=True))]\n\n        if args.dropout != 0.:\n            denseblocks += [(""dropout_5"", nn.Dropout(args.dropout))]\n\n        self.denseblocks = nn.Sequential(OrderedDict(denseblocks))\n\n        self.lr = nn.Linear(_in_channels, args.num_class)\n        self.lr.bias.data.fill_(0)\n\n    def forward(self, input):\n        out = self.init_cnn_layer(input)\n        out = self.denseblocks(out)\n        out = F.avg_pool2d(out, 8).squeeze()\n        return self.lr(out)\n'"
DenseNet/optim.py,0,"b'import numpy as np\n\nclass ScheduledOptim(object):\n    def __init__(self, optimizer, epochs, lr):\n        self.optimizer = optimizer\n        self.n_current_epochs = 0\n        self.lr = lr\n        self.epochs = epochs\n\n    def step(self):\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def update_learning_rate(self):\n        self.n_current_epochs += 1\n\n        # Is divided by 10 at 50% and 75% of the total number of training epochs\n        if self.n_current_epochs == (self.epochs//3) or self.n_current_epochs == (self.epochs//3)*2:\n            self.lr = self.lr / 10\n            print(""| learning rate updated - {}"".format(self.lr))\n            print(\'-\' * 90)\n            for param_group in self.optimizer.param_groups:\n                param_group[\'lr\'] = self.lr\n'"
DenseNet/train.py,11,"b'import argparse\n\nimport torch\n\nparser = argparse.ArgumentParser(description=\'DenseNet\')\nparser.add_argument(\'--save\', type=str, default=\'./DenseNet.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--unuse-cuda\', action=\'store_true\',\n                    help=\'unuse cuda\')\n\nparser.add_argument(\'--lr\', type=float, default=0.1)\nparser.add_argument(\'--epochs\', type=int, default=90,\n                    help=\'number of epochs for train\')\nparser.add_argument(\'--batch-size\', type=int, default=64,\n                    help=\'batch size for training\')\nparser.add_argument(\'--weight-decay\', type=float, default=1e-4)\nparser.add_argument(\'--momentum\', type=float, default=.9)\nparser.add_argument(\'--augmentation\', action=\'store_true\')\nparser.add_argument(\'--dropout\', type=float, default=0.)\n\nparser.add_argument(\'--num-class\', type=int, default=100)\nparser.add_argument(\'--growth-rate\', type=int, default=12)\nparser.add_argument(\'--channels\', type=int, default=24)\nparser.add_argument(\'--depth\', type=int, default=100)\n\nargs = parser.parse_args()\n\nimport torch\n\ntorch.manual_seed(args.seed)\nuse_cuda = torch.cuda.is_available() and not args.unuse_cuda\nargs.layer_nums = [(100-4)//6 for _ in range(3)]\nargs.dropout = args.dropout if args.augmentation else 0.\n\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# ##############################################################################\n# Load data\n###############################################################################\nimport torchvision.datasets as td\nimport torchvision.transforms as transforms\nimport numpy as np\n\ndef dataLoader(is_train=True, cuda=True, batch_size=64, shuffle=True):\n        if is_train:\n            trans = [transforms.RandomHorizontalFlip(),\n                     transforms.RandomCrop(32, padding=4),\n                     transforms.ToTensor(),\n                     transforms.Normalize(mean=[n/255.\n                        for n in [129.3, 124.1, 112.4]], std=[n/255. for n in [68.2,  65.4,  70.4]])]\n            trans = transforms.Compose(trans)\n            train_set = td.CIFAR100(\'data\', train=True, transform=trans)\n            size = len(train_set.train_labels)\n            train_loader = torch.utils.data.DataLoader(\n                            train_set, batch_size=batch_size, shuffle=shuffle)\n        else:\n            trans = [transforms.ToTensor(),\n                     transforms.Normalize(mean=[n/255.\n                        for n in [129.3, 124.1, 112.4]], std=[n/255. for n in [68.2,  65.4,  70.4]])]\n            trans = transforms.Compose(trans)\n            test_set = td.CIFAR100(\'data\', train=False, transform=trans)\n            size = len(test_set.test_labels)\n            train_loader = torch.utils.data.DataLoader(\n                            test_set, batch_size=batch_size, shuffle=shuffle)\n\n        return train_loader, size\n\ntraining_data, training_size = dataLoader(cuda=use_cuda, batch_size=args.batch_size)\nvalidation_data, validation_size = dataLoader(cuda=use_cuda, batch_size=args.batch_size, is_train=False, shuffle=False)\n# ##############################################################################\n# Build model\n# ##############################################################################\nimport model\nfrom optim import ScheduledOptim\n\nfrom modelp import densenet161\n\ndensenet = model.DenseNet(args)\n\nif use_cuda:\n    densenet = densenet.cuda()\n\noptimizer = ScheduledOptim(torch.optim.SGD(densenet.parameters(), lr=args.lr,\n    momentum=args.momentum, weight_decay=args.weight_decay), args.epochs, args.lr)\n\ncriterion = torch.nn.CrossEntropyLoss()\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\n\nfrom torch.autograd import Variable\n\ntrain_loss = []\nvalid_loss = []\ntrain_acc = []\naccuracy = []\n\ndef evaluate():\n    densenet.eval()\n    corrects = eval_loss = 0\n    for data, label in tqdm(validation_data, mininterval=0.2,\n                desc=\'Evaluate Processing\', leave=False):\n        data, label = Variable(data, volatile=True), Variable(label, volatile=True)\n        if use_cuda:\n            data, label = data.cuda(), label.cuda()\n\n        pred = densenet(data)\n        loss = criterion(pred, label)\n\n        eval_loss += loss.data[0]\n        corrects += (torch.max(pred, 1)[1].view(label.size()).data == label.data).sum()\n\n    return eval_loss/validation_size, corrects, corrects/validation_size * 100.0\n\ndef train():\n    densenet.train()\n    corrects = total_loss = 0\n    for data, label in tqdm(training_data, mininterval=1,\n                desc=\'Train Processing\', leave=False):\n        data, label = Variable(data), Variable(label)\n        if use_cuda:\n            data, label = data.cuda(), label.cuda()\n\n        optimizer.zero_grad()\n\n        target = densenet(data)\n        loss = criterion(target, label)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.data\n        corrects += (torch.max(target, 1)[1].view(label.size()).data == label.data).sum()\n\n    return total_loss[0]/training_size, corrects, corrects/training_size * 100.0\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs+1):\n        epoch_start_time = time.time()\n        loss, corrects, acc = train()\n        train_acc.append(acc / 100.)\n        train_loss.append(loss*1000.)\n        optimizer.update_learning_rate()\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f} | accuracy {:.4f}%({}/{})\'.format(epoch, time.time() - epoch_start_time, loss, acc, corrects, training_size))\n\n        loss, corrects, acc = evaluate()\n        valid_loss.append(loss*1000.)\n        accuracy.append(acc / 100.)\n\n        print(\'-\' * 90)\n        print(\'| end of epoch {:3d} | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(epoch, loss, acc, corrects, validation_size))\n        print(\'-\' * 90)\n        if not best_acc or best_acc < corrects:\n            best_acc = corrects\n            model_state_dict = densenet.state_dict()\n            model_source = {\n                ""settings"": args,\n                ""model"": model_state_dict\n            }\n            torch.save(model_source, args.save)\nexcept KeyboardInterrupt:\n    print(""-""*90)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format((time.time() - total_start_time)/60.0))\n\n'"
Image-Cap/caption.py,1,"b'import json\nimport re\nimport os\n\nimport torch\n\nfrom const import *\n\ndef normalizeString(s):\n    s = s.lower().strip()\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    return s\n\ndef words2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[BOS]: BOS,\n            WORD[EOS]: EOS,\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        self.idx = 4\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, sents, min_count):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words: word_count[w]+=1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\nclass Captions(object):\n    """"""\n    Data: COCO2017\n    captions_train2017|captions_val2017 data strcut:\n        {""info"": info,\n        ""licenses"": [license],\n        ""images"": [image],\n        ""annotations"": [annotation]}\n    """"""\n    def __init__(self, cap_path,\n            save_data=""data/img_caption.pt"", max_len=16, min_word_count=2):\n        self.dict = Dictionary()\n        self.max_len = max_len\n        self.min_word_count = min_word_count\n        self.save_data = save_data\n\n        self.train_imgs, self.train_labels, cut_counts = self._build(\n                ""{}/captions_train2017.json"".format(cap_path))\n\n        self.val_imgs, self.val_labels, _ = self._build(\n                ""{}/captions_val2017.json"".format(cap_path))\n\n        ignore = self.dict(self.train_labels, self.min_word_count)\n\n        print(""Caption`s length out of range numbers - [{}]"".format(cut_counts))\n        if ignore != 0:\n            print(""Ignored word counts - [{}]"".format(ignore))\n\n        self._save()\n\n    def _build(self, cap_file):\n        def _cut(s, cut_counts, max_len):\n            words = [w for w in normalizeString(s).strip().split()]\n            if len(words) > max_len:\n                cut_counts[0] += 1\n                words = words[:max_len]\n            words = words + [WORD[EOS]]\n\n            return words\n\n        caps = json.loads(next(open(cap_file)))\n        images, annotations = caps[""images""], caps[""annotations""]\n        img_dict = {img[""id""]: img[""file_name""] for img in images}\n\n        cut_counts, imgs, labels = [0], [], []\n        for anno in annotations:\n            imgs.append(img_dict[anno[""image_id""]])\n            labels.append(_cut(anno[""caption""], cut_counts, self.max_len))\n\n        return imgs, labels, cut_counts[0]\n\n    def _save(self):\n        data = {\n            \'max_word_len\': self.max_len+1,\n            \'vocab_size\': len(self.dict),\n            \'dict\': self.dict.word2idx,\n            \'train\': {\n                \'imgs\': self.train_imgs,\n                \'captions\': words2idx(self.train_labels, self.dict.word2idx),\n            },\n            \'valid\': {\n                \'imgs\': self.val_imgs,\n                \'captions\': words2idx(self.val_labels, self.dict.word2idx),\n            }\n        }\n\n        torch.save(data, self.save_data)\n        print(\'words length - [{}]\'.format(len(self.dict)))\n\nif __name__ == ""__main__"":\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\'Image Caption\')\n    parser.add_argument(\'--cap_path\', type=str, default=\'data\')\n    args = parser.parse_args()\n\n    Captions(args.cap_path)'"
Image-Cap/const.py,0,"b""PAD = 0\nUNK = 1\nBOS = 2\nEOS = 3\n\nWORD = {\n    UNK: '<unk>',\n    PAD: '<pad>',\n    BOS: '<sos>',\n    EOS: '<eos>',\n}\n\n"""
Image-Cap/data_loader.py,4,"b'import torch\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import transforms\n\nfrom PIL import Image\n\nimport numpy as np\n\nfrom const import PAD\n\n\nclass Data_loader(object):\n    def __init__(self, path, imgs, labels, max_len, batch_size, is_cuda, img_size=299, evaluation=False):\n        self._path = path\n        self._imgs = imgs\n        self._labels = np.asarray(labels)\n        self._max_len = max_len\n        self._is_cuda = is_cuda\n        self.evaluation = evaluation\n        self._step = 0\n        self._batch_size = batch_size\n        self.sents_size = len(imgs)\n        self._stop_step = self.sents_size // batch_size\n\n        self._encode = transforms.Compose([\n            transforms.Resize(img_size),\n            transforms.CenterCrop(img_size),\n            transforms.ToTensor()\n        ])\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def img2variable(img_files):\n            tensors = [self._encode(Image.open(\n                self._path + img_name).convert(\'RGB\')).unsqueeze(0) for img_name in img_files]\n            v = Variable(torch.cat(tensors, 0), volatile=self.evaluation)\n            if self._is_cuda:\n                v = v.cuda()\n            return v\n\n        def label2variable(labels):\n            """"""maybe sth change between Pytorch versions, add func long() for compatibility\n            """"""\n\n            _labels = np.array(\n                [l + [PAD] * (self._max_len - len(l)) for l in labels])\n            _labels = Variable(torch.from_numpy(_labels),\n                               volatile=self.evaluation).long()\n            if self._is_cuda:\n                _labels = _labels.cuda()\n            return _labels\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step * self._batch_size\n        self._step += 1\n\n        _imgs = img2variable(self._imgs[_start:_start + self._batch_size])\n        _labels = label2variable(\n            self._labels[_start:_start + self._batch_size])\n        return _imgs, _labels\n\n\nif __name__ == ""__main__"":\n    data = torch.load(""data/img_caption.pt"")\n    training_data = Data_loader(\n        ""data/train2017/"",\n        data[\'train\'][\'imgs\'],\n        data[\'train\'][\'captions\'],\n        16, batch_size=2, is_cuda=True)\n    print(training_data.sents_size)\n    img, labels = next(training_data)\n    print(labels)\n    id2word = {v: k for k, v in data[""dict""].items()}\n    # print(img)\n    print([id2word[_id] for _id in labels[1].data.tolist()])\n'"
Image-Cap/model.py,14,"b'import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.nn.parameter import Parameter\nfrom torchvision.models import inception_v3\n\nimport numpy as np\n\nfrom const import BOS, PAD\n\n\nclass Attention(nn.Module):\n    def __init__(self, hsz):\n        super().__init__()\n\n        self.hsz = hsz\n\n        self.sigma = nn.Linear(hsz, hsz)\n        self.beta = nn.Linear(hsz, hsz, bias=False)\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        stdv = 1. / math.sqrt(self.hsz)\n\n        self.sigma.weight.data.uniform_(-stdv, stdv)\n        self.beta.weight.data.uniform_(-stdv, stdv)\n\n    def forward(self, hiddens, hidden):\n        hiddens.append(hidden)\n        sigma = torch.tanh(self.sigma(hidden))\n        _hiddens = torch.stack(hiddens, dim=1)\n        _betas = torch.sum(torch.exp(self.beta(_hiddens)), dim=1)\n        beta = torch.exp(self.beta(sigma)) / _betas\n\n        return (beta * hidden).unsqueeze(1)\n\n\nclass Actor(nn.Module):\n    def __init__(self, vocab_size, dec_hsz, rnn_layers, bsz, max_len, dropout, use_cuda):\n        super().__init__()\n\n        self.torch = torch.cuda if use_cuda else torch\n        self.dec_hsz = dec_hsz\n        self.rnn_layers = rnn_layers\n        self.bsz = bsz\n        self.max_len = max_len\n        self.vocab_size = vocab_size\n        self.dropout = dropout\n\n        self.enc = inception_v3(True)\n        self.enc_out = nn.Linear(1000, dec_hsz)\n        self.lookup_table = nn.Embedding(vocab_size, dec_hsz, padding_idx=PAD)\n        self.rnn = nn.LSTM(dec_hsz + dec_hsz, dec_hsz, rnn_layers,\n                           batch_first=True,\n                           dropout=dropout)\n        self.attn = Attention(dec_hsz)\n        self.out = nn.Linear(self.dec_hsz, vocab_size)\n\n        self._reset_parameters()\n\n    def forward(self, hidden, labels=None):\n        word = Variable(self.torch.LongTensor([[BOS]] * self.bsz))\n        emb_enc = self.lookup_table(word)\n        hiddens = [hidden[0].squeeze()]\n        attn = torch.transpose(hidden[0], 0, 1)\n        outputs, words = [], []\n\n        for i in range(self.max_len):\n            _, hidden = self.rnn(torch.cat([emb_enc, attn], -1), hidden)\n            h_state = F.dropout(hidden[0], p=self.dropout)\n\n            props = F.log_softmax(self.out(h_state[-1]), dim=-1)\n            attn = self.attn(hiddens, h_state[-1])\n\n            if labels is not None:\n                emb_enc = self.lookup_table(labels[:, i]).unsqueeze(1)\n\n            else:\n                _props = props.data.clone().exp()\n                word = Variable(_props.multinomial(1), requires_grad=False)\n                words.append(word)\n\n                emb_enc = self.lookup_table(word)\n\n            outputs.append(props.unsqueeze(1))\n\n        if labels is not None:\n            return torch.cat(outputs, 1)\n\n        else:\n            return torch.cat(outputs, 1), torch.cat(words, 1)\n\n    def encode(self, imgs):\n        if self.training:\n            enc = self.enc(imgs)[0]\n        else:\n            enc = self.enc(imgs)\n        enc = self.enc_out(enc)\n        return enc\n\n    def feed_enc(self, enc):\n        weight = next(self.parameters()).data\n        c = Variable(weight.new(\n            self.rnn_layers, self.bsz, self.dec_hsz).zero_())\n\n        h = Variable(enc.data.\n                     unsqueeze(0).expand(self.rnn_layers, *enc.size()))\n\n        return (h.contiguous(), c.contiguous())\n\n    def _reset_parameters(self):\n        stdv = 1. / math.sqrt(self.vocab_size)\n\n        self.enc_out.weight.data.uniform_(-stdv, stdv)\n        self.lookup_table.weight.data.uniform_(-stdv, stdv)\n        self.out.weight.data.uniform_(-stdv, stdv)\n\n        for p in self.enc.parameters():\n            p.requires_grad = False\n\n    def get_trainable_parameters(self):\n        return filter(lambda m: m.requires_grad, self.parameters())\n\n\nclass Critic(nn.Module):\n    def __init__(self, vocab_size, dec_hsz, rnn_layers, bsz, max_len, dropout, use_cuda):\n        super().__init__()\n\n        self.use_cuda = use_cuda\n        self.dec_hsz = dec_hsz\n        self.rnn_layers = rnn_layers\n        self.bsz = bsz\n        self.max_len = max_len\n        self.vocab_size = vocab_size\n        self.dropout = dropout\n\n        self.lookup_table = nn.Embedding(vocab_size, dec_hsz, padding_idx=PAD)\n        self.rnn = nn.LSTM(self.dec_hsz,\n                           self.dec_hsz,\n                           self.rnn_layers,\n                           batch_first=True,\n                           dropout=dropout)\n        self.value = nn.Linear(self.dec_hsz, 1)\n\n        self._reset_parameters()\n\n    def feed_enc(self, enc):\n        weight = next(self.parameters()).data\n        c = Variable(weight.new(\n            self.rnn_layers, self.bsz, self.dec_hsz).zero_())\n\n        h = Variable(enc.data.\n                     unsqueeze(0).expand(self.rnn_layers, *enc.size()))\n        return (h.contiguous(), c.contiguous())\n\n    def forward(self, inputs, hidden):\n        emb_enc = self.lookup_table(inputs.clone()[:, :-1])\n        _, out = self.rnn(emb_enc, hidden)\n        out = F.dropout(out[0][-1], p=self.dropout)\n\n        return self.value(out).squeeze()\n\n    def _reset_parameters(self):\n        stdv = 1. / math.sqrt(self.vocab_size)\n\n        self.lookup_table.weight.data.uniform_(-stdv, stdv)\n        self.value.weight.data.uniform_(-stdv, stdv)\n'"
Image-Cap/optim.py,2,"b""from torch.optim import Adam\nimport torch\n\n\nclass Optim(object):\n    def __init__(self, params, lr, is_pre,\n                 grad_clip, new_lr=0.0, weight_decay=0.):\n        self.optimizer = Adam(params, lr=lr, betas=(\n            0.9, 0.98), eps=1e-09, weight_decay=weight_decay)\n        self.grad_clip = grad_clip\n        self.params = params\n        if is_pre:\n            self.step = self.pre_step\n        else:\n            assert new_lr != 0.0\n\n            self.n_current_steps = 0\n            self.new_lr = new_lr\n            self.step = self.train_step\n\n    def train_step(self):\n        self.optimizer.step()\n\n        self.n_current_steps += 1\n        if self.n_current_steps == 1e6:\n            self.update_learning_rate()\n\n    def pre_step(self):\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def clip_grad_norm(self):\n        torch.nn.utils.clip_grad_norm(self.params, self.grad_clip)\n\n    def update_learning_rate(self):\n        for param_group in self.optimizer.param_groups:\n            param_group['lr'] = self.new_lr\n\n\nclass Policy_optim(Optim):\n    def __init__(self, params, lr, grad_clip, new_lr):\n        super().__init__(params, lr, False, grad_clip, new_lr)\n\n    def train_step(self, reward):\n        for group in self.optimizer.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n\n                p.grad = p.grad.mul(reward)\n\n        self.optimizer.step()\n\n        self.n_current_steps += 1\n        if self.n_current_steps == 1e6:\n            self.update_learning_rate()\n"""
Image-Cap/rouge.py,10,"b""import numpy as np\nimport torch\nfrom torch.autograd import Variable\n\nfrom const import PAD\n\n\ndef _lcs(x, y):\n    n = len(x)\n    m = len(y)\n    table = dict()\n\n    for i in range(n + 1):\n        for j in range(m + 1):\n            if i == 0 or j == 0:\n                table[i, j] = 0\n            elif x[i - 1] == y[j - 1]:\n                table[i, j] = table[i - 1, j - 1] + 1\n            else:\n                table[i, j] = max(table[i - 1, j], table[i, j - 1])\n\n    def recon(i, j):\n        if i == 0 or j == 0:\n            return []\n        elif x[i - 1] == y[j - 1]:\n            return recon(i - 1, j - 1) + [x[i - 1]]\n        elif table[i - 1, j] > table[i, j - 1]:\n            return recon(i - 1, j)\n        else:\n            return recon(i, j - 1)\n\n    return len(recon(n, m)), n, m\n\n\ndef rouge_l(evals, refs):\n    assert evals.size() == refs.size()\n    use_cuda = evals.is_cuda\n\n    evals, refs = map(lambda x: x.data.cpu().numpy(), [evals, refs])\n\n    scores = []\n    for eva, ref in zip(evals, refs):\n        same_len, eva_len, ref_len = map(float,\n                                         _lcs(eva, ref[np.where(ref > PAD)]))\n\n        r_lcs, p_lcs = same_len / ref_len, same_len / eva_len\n\n        beta = p_lcs / (r_lcs + 1e-12)\n        f_lcs = ((1 + (beta**2)) * r_lcs * p_lcs) / \\\n            (r_lcs + ((beta**2) * p_lcs) + 1e-12)\n        scores.append(f_lcs)\n\n    scores = np.asarray(scores, dtype=np.float32)\n    scores = Variable(torch.from_numpy(scores), requires_grad=False)\n\n    if use_cuda:\n        scores = scores.cuda()\n\n    return scores\n\n\ndef mask_score(props, words, scores):\n    assert words.size() == scores.size()\n    mask = (words > 0).float()\n\n    return props * scores * mask\n\n\nif __name__ == '__main__':\n    import torch\n    from torch.autograd import Variable\n    import torch.nn.functional as F\n\n    data = Variable(torch.LongTensor([[3, 1, 2, 3, 1, 0], [2, 3, 4, 4, 0, 0]]))\n    label = Variable(torch.LongTensor(\n        [[3, 1, 2, 3, 1, 0], [2, 3, 2, 3, 1, 0]]))\n    bl = Variable(torch.LongTensor([[3, 1, 2, 3, 2, 0], [1, 3, 4, 4, 0, 0]]))\n    data = data.cuda()\n    label = label.cuda()\n    bl = bl.cuda()\n\n    reward = rouge_l(bl, label) - rouge_l(data, label)\n    print(reward)\n\n    props = torch.randn(16, 17, 256)\n    words = torch.LongTensor([[i for i in range(16, -1, -1)]\n                              for _ in range(16)])\n    scores = torch.randn(16, 17)\n\n    print(mask_score(props, words, scores))\n"""
Image-Cap/train.py,11,"b'import argparse\r\n\r\nparser = argparse.ArgumentParser(description=\'Image Cation\')\r\nparser.add_argument(\'--logdir\', type=str, default=\'tb_logdir\')\r\nparser.add_argument(\'--seed\', type=int, default=1111)\r\nparser.add_argument(\'--unuse_cuda\', action=\'store_true\')\r\nparser.add_argument(\'--path\', type=str, default=\'data/\')\r\nparser.add_argument(\'--data\', type=str, default=\'data/img_caption.pt\')\r\nparser.add_argument(\'--save\', type=str, default=\'imgcapt_v2_{}.pt\')\r\nparser.add_argument(\'--lr\', type=float, default=5e-5)\r\nparser.add_argument(\'--new_lr\', type=float, default=5e-6)\r\nparser.add_argument(\'--actor_epochs\', type=int, default=1)\r\nparser.add_argument(\'--epochs\', type=int, default=40)\r\nparser.add_argument(\'--iterations\', type=int, default=2000)\r\nparser.add_argument(\'--batch_size\', type=int, default=16)\r\nparser.add_argument(\'--dec_hsz\', type=int, default=512)\r\nparser.add_argument(\'--rnn_layers\', type=int, default=1)\r\nparser.add_argument(\'--dropout\', type=float, default=.5)\r\nparser.add_argument(\'--grad_clip\', type=float, default=1.)\r\n\r\nargs = parser.parse_args()\r\n\r\nimport torch\r\n\r\ntorch.manual_seed(args.seed)\r\nuse_cuda = torch.cuda.is_available() and not args.unuse_cuda\r\n\r\nif use_cuda:\r\n    torch.cuda.manual_seed(args.seed)\r\n\r\n# ##############################################################################\r\n# Tensorboard\r\n################################################################################\r\ntry:\r\n    import tensorflow as tf\r\n    tf_step = 0\r\nexcept ImportError:\r\n    tf = None\r\n\r\ntf_summary_writer = tf and tf.summary.FileWriter(args.logdir)\r\n\r\n\r\ndef add_summary_value(key, value):\r\n    global tf_step\r\n\r\n    summary = tf.Summary(value=[tf.Summary.Value(tag=key, simple_value=value)])\r\n    tf_summary_writer.add_summary(summary, tf_step)\r\n\r\n\r\n# ##############################################################################\r\n# Load data\r\n################################################################################\r\nfrom data_loader import Data_loader\r\n\r\ndata = torch.load(args.data)\r\nargs.max_len = data[""max_word_len""]\r\nargs.dict = data[""dict""]\r\nargs.vocab_size = data[""vocab_size""]\r\n\r\ntraining_data = Data_loader(\r\n    ""data/train2017/"",\r\n    data[\'train\'][\'imgs\'],\r\n    data[\'train\'][\'captions\'],\r\n    args.max_len,\r\n    batch_size=args.batch_size,\r\n    is_cuda=use_cuda)\r\n\r\nvalidation_data = Data_loader(\r\n    ""data/val2017/"",\r\n    data[\'valid\'][\'imgs\'],\r\n    data[\'valid\'][\'captions\'],\r\n    args.max_len,\r\n    batch_size=args.batch_size,\r\n    is_cuda=use_cuda,\r\n    evaluation=True)\r\n\r\n# ##############################################################################\r\n# Build model\r\n# ##############################################################################\r\nimport model\r\nfrom const import PAD\r\nfrom optim import Optim, Policy_optim\r\n\r\nactor = model.Actor(args.vocab_size,\r\n                    args.dec_hsz,\r\n                    args.rnn_layers,\r\n                    args.batch_size,\r\n                    args.max_len,\r\n                    args.dropout,\r\n                    use_cuda)\r\n\r\ncritic = model.Critic(args.vocab_size,\r\n                      args.dec_hsz,\r\n                      args.rnn_layers,\r\n                      args.batch_size,\r\n                      args.max_len,\r\n                      args.dropout,\r\n                      use_cuda)\r\n\r\noptim_pre_A = Optim(actor.get_trainable_parameters(),\r\n                    args.lr, True, args.grad_clip)\r\noptim_pre_C = Optim(critic.parameters(), args.lr, True,\r\n                    args.grad_clip, weight_decay=0.5)\r\n\r\noptim_A = Policy_optim(actor.get_trainable_parameters(), args.lr,\r\n                       args.new_lr, args.grad_clip)\r\noptim_C = Optim(critic.parameters(), args.lr,\r\n                False, args.new_lr, args.grad_clip)\r\n\r\ncriterion_A = torch.nn.CrossEntropyLoss(ignore_index=PAD)\r\ncriterion_C = torch.nn.MSELoss()\r\n\r\nif use_cuda:\r\n    actor = actor.cuda()\r\n    critic = critic.cuda()\r\n\r\n# ##############################################################################\r\n# Training\r\n# ##############################################################################\r\nfrom tqdm import tqdm\r\n\r\nfrom torch.autograd import Variable\r\nimport torch.nn.functional as F\r\n\r\nfrom rouge import rouge_l, mask_score\r\n\r\n\r\ndef pre_train_actor():\r\n    if tf:\r\n        global tf_step\r\n    for imgs, labels in tqdm(training_data,\r\n                             mininterval=1,\r\n                             desc=""Pre-train Actor"",\r\n                             leave=False):\r\n        optim_pre_A.zero_grad()\r\n\r\n        enc = actor.encode(imgs)\r\n        hidden = actor.feed_enc(enc)\r\n        target = actor(hidden, labels)\r\n\r\n        loss = criterion_A(target.view(-1, target.size(2)), labels.view(-1))\r\n\r\n        loss.backward()\r\n        optim_pre_A.clip_grad_norm()\r\n        optim_pre_A.step()\r\n        if tf is not None:\r\n            add_summary_value(""pre-train actor loss"", loss.data[0])\r\n            tf_step += 1\r\n\r\n            if tf_step % 100 == 0:\r\n                tf_summary_writer.flush()\r\n\r\n\r\ndef pre_train_critic():\r\n    iterations = 0\r\n    actor.eval()\r\n    critic.train()\r\n    if tf:\r\n        global tf_step\r\n    for imgs, labels in tqdm(training_data,\r\n                             mininterval=1,\r\n                             desc=""Pre-train Critic"",\r\n                             leave=False):\r\n        optim_pre_C.zero_grad()\r\n\r\n        enc = actor.encode(imgs)\r\n        hidden_A = actor.feed_enc(enc)\r\n        # we pre-train the critic network by feeding it with sampled actions from the fixed pre-trained actor.\r\n        _, words = actor(hidden_A)\r\n        policy_values = rouge_l(words, labels)\r\n\r\n        hidden_C = critic.feed_enc(enc)\r\n        estimated_values = critic(words, hidden_C)\r\n        loss = criterion_C(estimated_values, policy_values)\r\n\r\n        loss.backward()\r\n        optim_pre_C.clip_grad_norm()\r\n        optim_pre_C.step()\r\n\r\n        iterations += 1\r\n        if tf is not None:\r\n            add_summary_value(""pre-train critic loss"", loss.data[0])\r\n            tf_step += 1\r\n\r\n            if tf_step % 100 == 0:\r\n                tf_summary_writer.flush()\r\n\r\n        if iterations == args.iterations:\r\n            break\r\n\r\n\r\ndef train_actor_critic():\r\n    actor.train()\r\n    critic.train()\r\n    if tf:\r\n        global tf_step\r\n\r\n    for imgs, labels in tqdm(training_data,\r\n                             mininterval=1,\r\n                             desc=""Actor-Critic Training"",\r\n                             leave=False):\r\n        optim_A.zero_grad()\r\n        optim_C.zero_grad()\r\n\r\n        enc = actor.encode(imgs)\r\n        hidden_A = actor.feed_enc(enc)\r\n        target, words = actor(hidden_A)\r\n        policy_values = rouge_l(words, labels)\r\n\r\n        hidden_C = critic.feed_enc(enc)\r\n        estimated_values = critic(words, hidden_C)\r\n\r\n        loss_c = criterion_C(estimated_values, policy_values)\r\n        loss_c.backward()\r\n        optim_C.clip_grad_norm()\r\n        optim_C.step()\r\n\r\n        reward = torch.mean(policy_values - estimated_values)\r\n\r\n        loss_a = criterion_A(target.view(-1, target.size(2)), labels.view(-1))\r\n        loss_a.backward()\r\n        optim_A.clip_grad_norm()\r\n        optim_A.step(reward)\r\n\r\n        if tf is not None:\r\n            add_summary_value(""train critic loss"", loss_c[0])\r\n            add_summary_value(""train actor loss"", loss_a.data[0])\r\n            add_summary_value(""train actor reward"", reward.data)\r\n            add_summary_value(""train critic score"",\r\n                              estimated_values.data.mean())\r\n            add_summary_value(""train actor score"", policy_values.data.mean())\r\n            tf_step += 1\r\n\r\n            if tf_step % 100 == 0:\r\n                tf_summary_writer.flush()\r\n\r\n\r\ndef eval():\r\n    actor.eval()\r\n    eval_score = .0\r\n    for imgs, labels in tqdm(validation_data,\r\n                             mininterval=1,\r\n                             desc=""Actor-Critic Eval"",\r\n                             leave=False):\r\n        enc = actor.encode(imgs)\r\n\r\n        hidden = actor.feed_enc(enc)\r\n        words, _ = actor.speak(hidden)\r\n\r\n        scores = rouge_l(words, labels)\r\n        scores = scores.sum()\r\n\r\n        eval_score += scores.data\r\n\r\n    eval_score = eval_score[0] / validation_data.sents_size\r\n\r\n    return eval_score\r\n\r\n\r\ntry:\r\n    print(""="" * 40 + ""Pre-train Actor"" + ""="" * 40)\r\n    actor.train()\r\n    if tf:\r\n        tf_step = 0\r\n    for step in range(args.actor_epochs):\r\n        pre_train_actor()\r\n        model_state_dict = actor.state_dict()\r\n        model_source = {\r\n            ""settings"": args,\r\n            ""model"": model_state_dict,\r\n            ""dict"": data[\'dict\']\r\n        }\r\n        torch.save(model_source, args.save.format(""pret-actor_"" + str(step)))\r\n\r\n    if tf:\r\n        tf_step = 0\r\n    print(""="" * 40 + ""Pre-train Critic"" + ""="" * 40)\r\n    pre_train_critic()\r\n\r\n    if tf:\r\n        tf_step = 0\r\n    print(""="" * 40 + ""Actor-Critic Training"" + ""="" * 40)\r\n    for step in range(args.epochs):\r\n        train_actor_critic()\r\n        eval_score = eval()\r\n        print(""-"" * 20 + ""epoch-{}-eval | eval score: {:.4f}"".format(step,\r\n                                                                     eval_score) + ""-"" * 20)\r\n\r\n        model_state_dict = actor.state_dict()\r\n        model_source = {\r\n            ""settings"": args,\r\n            ""model"": model_state_dict,\r\n            ""dict"": data[\'dict\']\r\n        }\r\n        torch.save(model_source, args.save.format(step))\r\n\r\nexcept KeyboardInterrupt:\r\n    print(""-"" * 90)\r\n    print(""Exiting from training early"")\r\n'"
LSTM-CNNs-CRF/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    UNK: '<unk>',\n    PAD: '<pad>'\n}\n\nSTART = 1\nSTOP = 2\n\nTAG = {\n    PAD: '<pad>',\n    START: '<start>',\n    STOP: '<stop>'\n}\n"""
LSTM-CNNs-CRF/corpus.py,1,"b'import torch\n\nimport logging\nimport argparse\nimport os\nimport copy\nimport re\n\nfrom const import *\n\n\ndef normalizeString(s):\n    s = s.lower().strip()\n    try:\n        float(s)\n        return ""@""\n    except:\n        return s\n\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\n\ndef char2idx(sents, char2idx):\n    return [[[char2idx[c] if c in char2idx else UNK for c in word] for word in sent] for sent in sents]\n\n\nclass Dictionary(object):\n    def __init__(self, word2idx={}, idx_num=0):\n        self.word2idx = word2idx\n        self.idx = idx_num\n\n    def _add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def _convert(self):\n        self.idx2word = {v: k for k, v in self.word2idx.items()}\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Words(Dictionary):\n    def __init__(self):\n        word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        super().__init__(word2idx=word2idx, idx_num=len(word2idx))\n\n    def __call__(self, sents):\n        words = set([word for sent in sents for word in sent])\n        for word in words:\n            self._add(word)\n\n\nclass Chars(Dictionary):\n    def __init__(self):\n        word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        super().__init__(word2idx=word2idx, idx_num=len(word2idx))\n\n    def __call__(self, sents):\n        chars = set([char for sent in sents for word in sent for char in word])\n        for char in chars:\n            self._add(char)\n\n\nclass Labels(Dictionary):\n    def __init__(self):\n        word2idx = {\n            TAG[PAD]: PAD,\n            TAG[START]: START,\n            TAG[STOP]: STOP\n        }\n        super().__init__(word2idx=word2idx, idx_num=len(word2idx))\n\n    def __call__(self, labels):\n        _labels = set([l for label in labels for l in label])\n        for label in _labels:\n            self._add(label)\n\n\nclass Corpus(object):\n    def __init__(self, path, save_data,\n                 word_max_len=32, char_max_len=8, label_tag=3):\n\n        self.train = os.path.join(path, ""train"")\n        self.valid = os.path.join(path, ""testa"")\n        self._save_data = save_data\n        self._label_tag = label_tag\n        self.coutinue_tag = \'-DOCSTART-\'\n\n        self.w = Words()\n        self.c = Chars()\n        self.l = Labels()\n        self.word_max_len = word_max_len\n        self.char_max_len = char_max_len\n\n    def parse_data(self, _file, is_train=True):\n        sents, labels = [], []\n        _words, _labels = [], []\n        for sentence in open(_file):\n            if sentence == \'\\n\':\n                if len(_words) == 0:\n                    continue\n                sents.append(_words.copy())\n                labels.append(_labels.copy())\n                _words, _labels = [], []\n                continue\n            temp = sentence.strip().split(\' \')\n\n            label, word = temp[self._label_tag].strip(), temp[0].strip()\n            if word == self.coutinue_tag:\n                continue\n\n            _words += [normalizeString(word)]\n            _labels += [label]\n\n        out_of_range_sents = out_of_range_words = 0\n        dc_sents = copy.deepcopy(sents)\n\n        for index, words in enumerate(sents):\n            if len(words) > self.word_max_len:\n                out_of_range_sents += 1\n                sents[index] = words[:self.word_max_len]\n                labels[index] = labels[index][:self.word_max_len]\n                dc_sents[index] = words[:self.word_max_len]\n\n            for w_index, word in enumerate(dc_sents[index]):\n                if len(word) > self.char_max_len:\n                    out_of_range_words += 1\n                    dc_sents[index][w_index] = word[:self.char_max_len]\n\n            dc_sents[index] = [[char for char in word]\n                               for word in dc_sents[index]]\n\n        if is_train:\n            self.w(sents)\n            self.c(dc_sents)\n            self.l(labels)\n            self.train_sents = sents\n            self.train_chars = dc_sents\n            self.train_labels = labels\n        else:\n            self.valid_sents = sents\n            self.valid_chars = dc_sents\n            self.valid_labels = labels\n\n        print(""parse down, out of range sents - {}, out of range words - {}"".format(\n            out_of_range_sents, out_of_range_words))\n\n    def save(self):\n        self.parse_data(self.train)\n        self.parse_data(self.valid, False)\n        data = {\n            \'word_max_len\': self.word_max_len,\n            \'char_max_len\': self.char_max_len,\n            \'dict\': {\n                \'word\': self.w.word2idx,\n                \'word_size\': len(self.w),\n                \'char\': self.c.word2idx,\n                \'char_size\': len(self.c),\n                \'label\': self.l.word2idx,\n                \'label_size\': len(self.l),\n            },\n            \'train\': {\n                \'word\': word2idx(self.train_sents, self.w.word2idx),\n                \'char\': char2idx(self.train_chars, self.c.word2idx),\n                \'label\': word2idx(self.train_labels, self.l.word2idx)\n            },\n            \'valid\': {\n                \'word\': word2idx(self.valid_sents, self.w.word2idx),\n                \'char\': char2idx(self.valid_chars, self.c.word2idx),\n                \'label\': word2idx(self.valid_labels, self.l.word2idx)\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'Finish dumping the data to file - [{}]\'.format(self._save_data))\n        print(\'words length - [{}]\'.format(len(self.w)))\n        print(\'chars length - [{}]\'.format(len(self.c)))\n        print(\'labels - [{}]\'.format(self.l.word2idx))\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--file-path\', type=str, default=""./data"",\n                        help=\'file path\')\n    parser.add_argument(\'--save-data\', type=str, default=""corpus.pt"",\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--word-max-lenth\', type=int, default=40,\n                        help=\'max length left of sentence\')\n    parser.add_argument(\'--char-max-lenth\', type=int, default=10,\n                        help=\'max length left of word\')\n    args = parser.parse_args()\n    corpus = Corpus(args.file_path, args.save_data,\n                    args.word_max_lenth, args.char_max_lenth)\n    corpus.save()\n'"
LSTM-CNNs-CRF/data_loader.py,4,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\n\nclass DataLoader(object):\n    def __init__(self, sents, chars, label, word_max_len, char_max_len, cuda=True,\n                 batch_size=64, shuffle=True, evaluation=False):\n        self.cuda = cuda\n        self.sents_size = len(sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size\n        self.evaluation = evaluation\n\n        self._batch_size = batch_size\n        self._word_max_len = word_max_len\n        self._char_max_len = char_max_len\n        self._sents = np.asarray(sents)\n        self._chars = np.asarray(chars)\n        self._label = np.asarray(label)\n\n        if shuffle:\n            self._shuffle()\n\n    def _shuffle(self):\n        indices = np.arange(self._sents.shape[0])\n        np.random.shuffle(indices)\n        self._sents = self._sents[indices]\n        self._chars = self._chars[indices]\n        self._label = self._label[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def pad_to_longest(insts, is_char=False, word_max_len=None, char_max_len=None):\n            if is_char:\n                assert char_max_len is not None and word_max_len is not None\n\n                temp_char = [const.PAD] * char_max_len\n                temp_insts = np.array(\n                    [inst + [temp_char] * (word_max_len - len(inst)) for inst in insts])\n                inst_data = np.array(\n                    [[word + [const.PAD] * (char_max_len - len(word)) for word in inst] for inst in temp_insts])\n            else:\n                max_len = max(len(inst) for inst in insts)\n                inst_data = np.array(\n                    [inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n\n            if self.evaluation:\n                with torch.no_grad():\n                    inst_data_tensor = Variable(torch.from_numpy(inst_data))\n            else:\n                inst_data_tensor = Variable(torch.from_numpy(inst_data))\n\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n\n            return inst_data_tensor\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step * self._batch_size\n        _bsz = self._batch_size\n        self._step += 1\n\n        word = pad_to_longest(self._sents[_start:_start + _bsz])\n        char = pad_to_longest(self._chars[_start:_start + _bsz],\n                              True, word.size(1), self._char_max_len)\n        label = pad_to_longest(self._label[_start:_start + _bsz])\n\n        return word, char, label\n'"
LSTM-CNNs-CRF/model.py,21,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.nn import init\n\nfrom const import *\n\n\ndef log_sum_exp(input, keepdim=False):\n    assert input.dim() == 2\n    max_scores, _ = input.max(dim=-1, keepdim=True)\n    output = input - max_scores\n    return max_scores + torch.log(torch.sum(torch.exp(output), dim=-1, keepdim=keepdim))\n\n\ndef gather_index(input, index):\n    assert input.dim() == 2 and index.dim() == 1\n    index = index.unsqueeze(1).expand_as(input)\n    output = torch.gather(input, 1, index)\n    return output[:, 0]\n\n\nclass CRF(nn.Module):\n    def __init__(self, label_size, is_cuda):\n        super().__init__()\n        self.label_size = label_size\n        self.transitions = nn.Parameter(\n            torch.randn(label_size, label_size))\n        self._init_weight()\n        self.torch = torch.cuda if is_cuda else torch\n\n    def _init_weight(self):\n        init.xavier_uniform_(self.transitions)\n        self.transitions.data[START, :].fill_(-10000.)\n        self.transitions.data[:, STOP].fill_(-10000.)\n\n    def _score_sentence(self, input, tags):\n        bsz, sent_len, l_size = input.size()\n        score = Variable(self.torch.FloatTensor(bsz).fill_(0.))\n        s_score = Variable(self.torch.LongTensor([[START]] * bsz))\n\n        tags = torch.cat([s_score, tags], dim=-1)\n        input_t = input.transpose(0, 1)\n\n        for i, words in enumerate(input_t):\n            temp = self.transitions.index_select(1, tags[:, i])\n            bsz_t = gather_index(temp.transpose(0, 1), tags[:, i + 1])\n            w_step_score = gather_index(words, tags[:, i + 1])\n            score = score + bsz_t + w_step_score\n\n        temp = self.transitions.index_select(1, tags[:, -1])\n        bsz_t = gather_index(temp.transpose(0, 1),\n                             Variable(self.torch.LongTensor([STOP] * bsz)))\n        return score + bsz_t\n\n    def forward(self, input):\n        bsz, sent_len, l_size = input.size()\n        init_alphas = self.torch.FloatTensor(\n            bsz, self.label_size).fill_(-10000.)\n        init_alphas[:, START].fill_(0.)\n        forward_var = Variable(init_alphas)\n\n        input_t = input.transpose(0, 1)\n        for words in input_t:\n            alphas_t = []\n            for next_tag in range(self.label_size):\n                emit_score = words[:, next_tag].view(-1, 1)\n                trans_score = self.transitions[next_tag].view(1, -1)\n                next_tag_var = forward_var + trans_score + emit_score\n                alphas_t.append(log_sum_exp(next_tag_var, True))\n            forward_var = torch.cat(alphas_t, dim=-1)\n        forward_var = forward_var + self.transitions[STOP].view(\n            1, -1)\n        return log_sum_exp(forward_var)\n\n    def viterbi_decode(self, input):\n        backpointers = []\n        bsz, sent_len, l_size = input.size()\n\n        init_vvars = self.torch.FloatTensor(\n            bsz, self.label_size).fill_(-10000.)\n        init_vvars[:, START].fill_(0.)\n        forward_var = Variable(init_vvars)\n\n        input_t = input.transpose(0, 1)\n        for words in input_t:\n            bptrs_t = []\n            viterbivars_t = []\n\n            for next_tag in range(self.label_size):\n                _trans = self.transitions[next_tag].view(\n                    1, -1).expand_as(words)\n                next_tag_var = forward_var + _trans\n                best_tag_scores, best_tag_ids = torch.max(\n                    next_tag_var, 1, keepdim=True)  # bsz\n                bptrs_t.append(best_tag_ids)\n                viterbivars_t.append(best_tag_scores)\n\n            forward_var = torch.cat(viterbivars_t, -1) + words\n            backpointers.append(torch.cat(bptrs_t, dim=-1))\n\n        terminal_var = forward_var + self.transitions[STOP].view(1, -1)\n        _, best_tag_ids = torch.max(terminal_var, 1)\n\n        best_path = [best_tag_ids.view(-1, 1)]\n        for bptrs_t in reversed(backpointers):\n            best_tag_ids = gather_index(bptrs_t, best_tag_ids)\n            best_path.append(best_tag_ids.contiguous().view(-1, 1))\n\n        best_path.pop()\n        best_path.reverse()\n\n        return torch.cat(best_path, dim=-1)\n\n\nclass BiLSTM(nn.Module):\n    def __init__(self, word_size, word_ebd_dim, kernel_num, lstm_hsz, lstm_layers, dropout, batch_size):\n        super().__init__()\n        self.lstm_layers = lstm_layers\n        self.lstm_hsz = lstm_hsz\n        self.batch_size = batch_size\n\n        self.word_ebd = nn.Embedding(word_size, word_ebd_dim)\n        self.lstm = nn.LSTM(word_ebd_dim + kernel_num,\n                            hidden_size=lstm_hsz // 2,\n                            num_layers=lstm_layers,\n                            batch_first=True,\n                            dropout=dropout,\n                            bidirectional=True)\n        self._init_weights()\n\n    def _init_weights(self, scope=1.):\n        self.word_ebd.weight.data.uniform_(-scope, scope)\n\n    def forward(self, words, char_feats, hidden=None):\n        encode = self.word_ebd(words)\n        encode = torch.cat((char_feats, encode), dim=-1)\n        output, hidden = self.lstm(encode, hidden)\n        return output, hidden\n\n    def init_hidden(self):\n        weight = next(self.parameters()).data\n        return (Variable(weight.new(self.lstm_layers * 2, self.batch_size, self.lstm_hsz // 2).zero_()),\n                Variable(weight.new(self.lstm_layers * 2, self.batch_size, self.lstm_hsz // 2).zero_()))\n\n\nclass CNN(nn.Module):\n    def __init__(self, char_size, char_ebd_dim,\n                 kernel_num, filter_size, dropout):\n        super().__init__()\n\n        self.char_size = char_size\n        self.char_ebd_dim = char_ebd_dim\n        self.kernel_num = kernel_num\n        self.filter_size = filter_size\n        self.dropout = dropout\n\n        self.char_ebd = nn.Embedding(self.char_size, self.char_ebd_dim)\n        self.char_cnn = nn.Conv2d(in_channels=1,\n                                  out_channels=self.kernel_num,\n                                  kernel_size=(self.filter_size, self.char_ebd_dim))\n        self._init_weight()\n\n    def _init_weight(self, scope=1.):\n        init.xavier_uniform_(self.char_ebd.weight)\n\n    def forward(self, input):\n        bsz, word_len, char_len = input.size()\n        encode = input.view(-1, char_len)\n        encode = self.char_ebd(encode).unsqueeze(1)\n        encode = F.relu(self.char_cnn(encode))\n        encode = F.max_pool2d(encode,\n                              kernel_size=(encode.size(2), 1))\n        encode = F.dropout(encode.squeeze(), p=self.dropout)\n        return encode.view(bsz, word_len, -1)\n\n\nclass Model(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.cnn = CNN(self.char_size, self.char_ebd_dim,\n                       self.kernel_num, self.filter_size, self.dropout)\n        self.bilstm = BiLSTM(self.word_size, self.word_ebd_dim, self.kernel_num,\n                             self.lstm_hsz, self.lstm_layers, self.dropout, self.batch_size)\n\n        self.logistic = nn.Linear(self.lstm_hsz, self.label_size)\n        self.crf = CRF(self.label_size, self.use_cuda)\n        self._init_weights()\n\n    def forward(self, words, chars, labels, hidden=None):\n        char_feats = self.cnn(chars)\n        output, _ = self.bilstm(words, char_feats, hidden)\n        output = self.logistic(output)\n        pre_score = self.crf(output)\n        label_score = self.crf._score_sentence(output, labels)\n        return (pre_score - label_score).mean(), None\n\n    def predict(self, word, char):\n        char_out = self.cnn(char)\n        lstm_out, _ = self.bilstm(word, char_out)\n        out = self.logistic(lstm_out)\n        return self.crf.viterbi_decode(out)\n\n    def _init_weights(self, scope=1.):\n        self.logistic.weight.data.uniform_(-scope, scope)\n        self.logistic.bias.data.fill_(0)\n'"
LSTM-CNNs-CRF/optim.py,0,"b""import numpy as np\n\nclass ScheduledOptim(object):\n    def __init__(self, optimizer, lr):\n        self.optimizer = optimizer\n        self.n_current_steps = 1\n        self.lr = lr\n\n    def step(self):\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def update_learning_rate(self):\n        self.n_current_steps += 1\n        new_lr = self.lr / self.n_current_steps\n\n        for param_group in self.optimizer.param_groups:\n            param_group['lr'] = new_lr\n"""
LSTM-CNNs-CRF/train.py,6,"b'import argparse\n\nparser = argparse.ArgumentParser(description=\'LSTM CNN CRF\')\nparser.add_argument(\'--epochs\', type=int, default=32,\n                    help=\'number of epochs for train\')\nparser.add_argument(\'--batch-size\', type=int, default=128,\n                    help=\'batch size for training\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda-able\', action=\'store_true\',\n                    help=\'enables cuda\')\nparser.add_argument(\'--lr\', type=float, default=0.001,\n                    help=\'learning rate\')\nparser.add_argument(\'--use-crf\', action=\'store_true\',\n                    help=\'use crf\')\n\nparser.add_argument(\'--save\', type=str, default=\'lstm_cnns_crf.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--save-epoch\', action=\'store_true\',\n                    help=\'save every epoch\')\nparser.add_argument(\'--data\', type=str, default=\'corpus.pt\',\n                    help=\'location of the data corpus\')\n\nparser.add_argument(\'--char-ebd-dim\', type=int, default=32,\n                    help=\'number of char embedding dimension\')\nparser.add_argument(\'--kernel-num\', type=int, default=32,\n                    help=\'number of kernel\')\nparser.add_argument(\'--filter-size\', type=int, default=2,\n                    help=\'filter size\')\nparser.add_argument(\'--word-ebd-dim\', type=int, default=128,\n                    help=\'number of word embedding dimension\')\nparser.add_argument(\'--dropout\', type=float, default=0.5,\n                    help=\'the probability for dropout\')\nparser.add_argument(\'--lstm-hsz\', type=int, default=256,\n                    help=\'BiLSTM hidden size\')\nparser.add_argument(\'--lstm-layers\', type=int, default=3,\n                    help=\'biLSTM layer numbers\')\nparser.add_argument(\'--l2\', type=float, default=0.05,\n                    help=\'l2 regularization\')\nparser.add_argument(\'--clip\', type=float, default=.5,\n                    help=\'gradient clipping\')\n\nargs = parser.parse_args()\n\nimport torch\nfrom torch.autograd import Variable\n\ntorch.manual_seed(args.seed)\nargs.use_cuda = use_cuda = torch.cuda.is_available() and args.cuda_able\n\n# ##############################################################################\n# Load data\n###############################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.word_max_len = data[""word_max_len""]\nargs.char_max_len = data[""char_max_len""]\nargs.word_size = data[\'dict\'][\'word_size\']\nargs.char_size = data[\'dict\'][\'char_size\']\nargs.label_size = data[\'dict\'][\'label_size\']\n\ntraining_data = DataLoader(\n    data[\'train\'][\'word\'],\n    data[\'train\'][\'char\'],\n    data[\'train\'][\'label\'],\n    args.word_max_len,\n    args.char_max_len,\n    cuda=use_cuda,\n    batch_size=args.batch_size)\n\nvalidation_data = DataLoader(\n    data[\'valid\'][\'word\'],\n    data[\'valid\'][\'char\'],\n    data[\'valid\'][\'label\'],\n    args.word_max_len,\n    args.char_max_len,\n    batch_size=args.batch_size,\n    shuffle=False,\n    cuda=use_cuda,\n    evaluation=True)\n\n# ##############################################################################\n# Build model\n# ##############################################################################\nfrom model import Model\nfrom optim import ScheduledOptim\n\nmodel = Model(args)\nif use_cuda:\n    model = model.cuda()\n\noptimizer = ScheduledOptim(\n    torch.optim.Adam(model.parameters(), lr=args.lr,\n                     betas=(0.9, 0.98), eps=1e-09, weight_decay=args.l2),\n    args.lr)\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\nimport const\n\ntrain_loss = []\nvalid_loss = []\naccuracy = []\n\n\ndef evaluate():\n    model.eval()\n    corrects = eval_loss = 0\n\n    for word, char, label in tqdm(validation_data, mininterval=0.2,\n                                  desc=\'Evaluate Processing\', leave=False):\n        loss, _ = model(word, char, label)\n        pred = model.predict(word, char)\n\n        eval_loss += loss.data.item()\n\n        corrects += (pred.data == label.data).sum()\n\n    _size = validation_data.sents_size * args.word_max_len\n    return eval_loss / validation_data._stop_step, corrects, float(corrects) / _size * 100, _size\n\n\ndef train():\n    model.train()\n    total_loss = 0\n    for word, char, label in tqdm(training_data, mininterval=1,\n                                  desc=\'Train Processing\', leave=False):\n\n        optimizer.zero_grad()\n        loss, _ = model(word, char, label)\n        loss.backward()\n\n        optimizer.step()\n        optimizer.update_learning_rate()\n        total_loss += loss.data\n    return total_loss / training_data._stop_step\n\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs + 1):\n        epoch_start_time = time.time()\n        loss = train()\n        train_loss.append(loss * 1000.)\n\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(\n            epoch, time.time() - epoch_start_time, loss))\n\n        loss, corrects, acc, size = evaluate()\n\n        valid_loss.append(loss * 1000.)\n        accuracy.append(acc / 100.)\n\n        epoch_start_time = time.time()\n        print(\'-\' * 90)\n        print(\'| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(\n            epoch, time.time() - epoch_start_time, loss, acc, corrects, size))\n        print(\'-\' * 90)\n        if not best_acc or best_acc < corrects:\n            best_acc = corrects\n            model_state_dict = model.state_dict()\n            model_source = {\n                ""settings"": args,\n                ""model"": model_state_dict,\n                ""word_dict"": data[\'dict\'][\'word\'],\n                ""label_dict"": data[\'dict\'][\'label\']\n            }\n            torch.save(model_source, args.save)\nexcept KeyboardInterrupt:\n    print(""-"" * 90)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format(\n        (time.time() - total_start_time) / 60.0))\n'"
alpha-zero/const.py,1,b'import torch\n\n# GOMOKU\nSPACE = 0.\nBLACK = 1.\nWHITE = 2.\nSIZE = 8\n\n# MCTS\nCPUCT = 5\nMCTSSIMNUM = 400\nHISTORY = 3\nTEMPTRIG = 8\n\n# Dirichlet\nDLEPS = .25\nDLALPHA = .03\n\n# Net params\nIND = HISTORY * 2 + 2\nOUTD = SIZE**2\nBLOCKS = 10\nRES_BLOCK_FILLTERS = 128\n\n# Train params\nUSECUDA = torch.cuda.is_available()\nEPOCHS = 5\nGAMETIMES = 3000\nCHECKOUT = 50\nEVALNUMS = 20\nMINIBATCH = 512\nWINRATE = .55\nTRAINLEN = 10000\n\n# Optim\nLR = 0.03\nL2 = 0.0001\n'
alpha-zero/data_loader.py,1,"b'import numpy as np\nimport torch\nimport random\n\nfrom const import *\n\n\ndef to_tensor(x, use_cuda=USECUDA, unsqueeze=False):\n    x = torch.from_numpy(x).type(torch.Tensor)\n    if use_cuda:\n        x = x.cuda()\n\n    if unsqueeze:\n        x = x.unsqueeze(0)\n\n    return x\n\n\ndef to_numpy(x, use_cuda=True):\n    if use_cuda:\n        return x.data.cpu().numpy().flatten()\n    else:\n        return x.data.numpy().flatten()\n\n\nclass DataLoader(object):\n    def __init__(self, cuda, batch_size):\n        self.cuda = cuda\n        self.bsz = batch_size\n\n    def __call__(self, datas):\n        mini_batch = random.sample(datas, self.bsz)\n        states, pi, rewards = [], [], []\n        for s, p, r in mini_batch:\n            states.append(s)\n            pi.append(p)\n            rewards.append(r)\n\n        states = to_tensor(np.stack(states, axis=0), use_cuda=self.cuda)\n        pi = to_tensor(np.stack(pi, axis=0), use_cuda=self.cuda)\n        rewards = to_tensor(np.stack(rewards, axis=0), use_cuda=self.cuda)\n\n        return states, pi, rewards.view(-1, 1)\n'"
alpha-zero/game.py,0,"b'from copy import deepcopy\nimport random\n\nimport numpy as np\n\nfrom mcts import MonteCarloTreeSearch, TreeNode\nfrom const import *\n\n\nclass Board(object):\n    def __init__(self,\n                 size=SIZE,\n                 hist_num=HISTORY,\n                 c_action=-1,\n                 player=BLACK):\n\n        self.size = size\n        self.c_action = c_action\n        self.hist_num = hist_num\n        self.valid_moves = list(range(size**2))\n        self.invalid_moves = []\n        self.board = np.zeros([size, size])\n        self.c_player = player\n        self.players = {""black"": BLACK, ""white"": WHITE}\n\n        # BLACK -> 0 | WHITE -> 1\n        self.history = [np.zeros((hist_num, size, size)),\n                        np.zeros((hist_num, size, size))]\n\n    # private method\n    def _mask_pieces_by_player(self, player):\n        \'\'\'binary feature planes\'\'\'\n\n        new_board = np.zeros([self.size, self.size])\n        new_board[np.where(self.board == player)] = 1.\n        return new_board\n\n    def _get_piece(self, x, y):\n        if 0 <= x < self.size and 0 <= y < self.size:\n            return self.board[x, y]\n        return SPACE\n\n    def _is_space(self, x, y):\n        assert 0 <= x < self.size and 0 <= y < self.size\n        return self.board[x, y] == SPACE\n\n    @property\n    def last_player(self):\n        if self.c_player == self.players[""white""]:\n            return self.players[""black""]\n        return self.players[""white""]\n\n    def clone(self):\n        c_board = Board(size=self.size,\n                        hist_num=self.hist_num,\n                        player=self.c_player,\n                        c_action=self.c_action)\n\n        c_board.valid_moves = self.valid_moves.copy()\n        c_board.invalid_moves = self.invalid_moves.copy()\n        c_board.board = self.board.copy()\n        c_board.history = [h.copy() for h in self.history]\n\n        return c_board\n\n    def move(self, action):\n        x, y = action // self.size, action % self.size\n        assert self._is_space(x, y)\n\n        self.valid_moves.remove(action)\n        self.invalid_moves.append(action)\n        self.c_action = action\n        self.board[x, y] = self.c_player\n\n        p_index = int(self.c_player - BLACK)\n        self.history[p_index] = np.roll(self.history[p_index], 1, axis=0)\n        self.history[p_index][0] = self._mask_pieces_by_player(self.c_player)\n\n    def is_game_over(self, player=None):\n        x, y = self.c_action // self.size, self.c_action % self.size\n        if player is None:\n            player = self.c_player\n\n        for i in range(x - 4, x + 5):\n            if self._get_piece(i, y) == self._get_piece(i + 1, y) == self._get_piece(i + 2, y) == self._get_piece(i + 3, y) == self._get_piece(i + 4, y) == player:\n                return True\n\n        for j in range(y - 4, y + 5):\n            if self._get_piece(x, j) == self._get_piece(x, j + 1) == self._get_piece(x, j + 2) == self._get_piece(x, j + 3) == self._get_piece(x, j + 4) == player:\n                return True\n\n        j = y - 4\n        for i in range(x - 4, x + 5):\n            if self._get_piece(i, j) == self._get_piece(i + 1, j + 1) == self._get_piece(i + 2, j + 2) == self._get_piece(i + 3, j + 3) == self._get_piece(i + 4, j + 4) == player:\n                return True\n            j += 1\n\n        i = x + 4\n        for j in range(y - 4, y + 5):\n            if self._get_piece(i, j) == self._get_piece(i - 1, j + 1) == self._get_piece(i - 2, j + 2) == self._get_piece(i - 3, j + 3) == self._get_piece(i - 4, j + 4) == player:\n                return True\n            i -= 1\n\n        return False\n\n    def is_draw(self):\n        index = np.where(self.board == SPACE)\n        return len(index[0]) == 0\n\n    def gen_state(self):\n        to_action = np.zeros((1, self.size, self.size))\n        to_action[0][self.c_action // self.size,\n                     self.c_action % self.size] = 1.\n        to_play = np.full((1, self.size, self.size), self.c_player - BLACK)\n        state = np.concatenate(self.history + [to_play, to_action], axis=0)\n\n        return state\n\n    def trigger(self):\n        self.c_player = self.players[""black""] if self.c_player == self.players[""white""] else self.players[""white""]\n\n    def show(self):\n        for x in range(self.size):\n            print(""{0:8}"".format(x), end=\'\')\n        print(\'\\r\\n\')\n\n        for row in range(self.size):\n            print(""{:4d}"".format(row), end=\'\')\n            for col in range(self.size):\n                if self.board[row, col] == SPACE:\n                    print(""-"".center(8), end=\'\')\n                elif self.board[row, col] == BLACK:\n                    print(""O"".center(8), end=\'\')\n                else:\n                    print(""X"".center(8), end=\'\')\n            print(\'\\r\\n\\r\\n\')\n\n\nclass Game(object):\n    def __init__(self, net, evl_net):\n        self.net = net\n        self.evl_net = evl_net\n        self.board = Board()\n\n    def play(self):\n        datas, node = [], TreeNode()\n        mc = MonteCarloTreeSearch(self.net)\n        move_count = 0\n\n        while True:\n            if move_count < TEMPTRIG:\n                pi, next_node = mc.search(self.board, node, temperature=1)\n            else:\n                pi, next_node = mc.search(self.board, node)\n\n            datas.append([self.board.gen_state(), pi, self.board.c_player])\n\n            self.board.move(next_node.action)\n            next_node.parent = None\n            node = next_node\n\n            if self.board.is_draw():\n                reward = 0.\n                break\n\n            if self.board.is_game_over():\n                reward = 1.\n                break\n\n            self.board.trigger()\n            move_count += 1\n\n        datas = np.asarray(datas)\n        datas[:, 2][datas[:, 2] == self.board.c_player] = reward\n        datas[:, 2][datas[:, 2] != self.board.c_player] = -reward\n\n        return datas\n\n    def evaluate(self, result):\n        self.net.eval()\n        self.evl_net.eval()\n\n        if random.randint(0, 1) == 1:\n            players = {\n                BLACK: (MonteCarloTreeSearch(self.net), ""net""),\n                WHITE: (MonteCarloTreeSearch(self.evl_net), ""eval""),\n            }\n        else:\n            players = {\n                WHITE: (MonteCarloTreeSearch(self.net), ""net""),\n                BLACK: (MonteCarloTreeSearch(self.evl_net), ""eval""),\n            }\n        node = TreeNode()\n\n        while True:\n            _, next_node = players[self.board.c_player][0].search(\n                self.board, node)\n\n            self.board.move(next_node.action)\n\n            if self.board.is_draw():\n                result[0] += 1\n                return\n\n            if self.board.is_game_over():\n                if players[self.board.c_player][1] == ""net"":\n                    result[1] += 1\n                else:\n                    result[2] += 1\n                return\n\n            self.board.trigger()\n\n            next_node.parent = None\n            node = next_node\n\n    def reset(self):\n        self.board = Board()\n'"
alpha-zero/mcts.py,0,"b'from copy import deepcopy\n\nimport numpy as np\n\nfrom const import *\nfrom data_loader import to_tensor, to_numpy\n\n\nclass TreeNode(object):\n    def __init__(self,\n                 action=None,\n                 props=None,\n                 parent=None):\n\n        self.parent = parent\n        self.action = action\n        self.children = []\n\n        self.N = 0  # visit count\n        self.Q = .0  # mean action value\n        self.W = .0  # total action value\n        self.P = props  # prior probability\n\n    def is_leaf(self):\n        return len(self.children) == 0\n\n    def select_child(self):\n        index = np.argmax(np.asarray([c.uct() for c in self.children]))\n        return self.children[index]\n\n    def uct(self):\n        return self.Q + self.P * CPUCT * (np.sqrt(self.parent.N) / (1 + self.N))\n\n    def expand_node(self, props):\n        self.children = [TreeNode(action=action, props=p, parent=self)\n                         for action, p in enumerate(props) if p > 0.]\n\n    def backup(self, v):\n        self.N += 1\n        self.W += v\n        self.Q = self.W / self.N\n\n\nclass MonteCarloTreeSearch(object):\n    def __init__(self, net,\n                 ms_num=MCTSSIMNUM):\n\n        self.net = net\n        self.ms_num = ms_num\n\n    def search(self, borad, node, temperature=.001):\n        self.borad = borad\n        self.root = node\n\n        for _ in range(self.ms_num):\n            node = self.root\n            borad = self.borad.clone()\n\n            while not node.is_leaf():\n                node = node.select_child()\n                borad.move(node.action)\n                borad.trigger()\n\n            # be carefull - opponent state\n            value, props = self.net(\n                to_tensor(borad.gen_state(), unsqueeze=True))\n            value = to_numpy(value, USECUDA)[0]\n            props = np.exp(to_numpy(props, USECUDA))\n\n            # add dirichlet noise for root node\n            if node.parent is None:\n                props = self.dirichlet_noise(props)\n\n            # normalize\n            props[borad.invalid_moves] = 0.\n            total_p = np.sum(props)\n            if total_p > 0:\n                props /= total_p\n\n            # winner, draw or continue\n            if borad.is_draw():\n                value = 0.\n            else:\n                done = borad.is_game_over(player=borad.last_player)\n                if done:\n                    value = -1.\n                else:\n                    node.expand_node(props)\n\n            while node is not None:\n                value = -value\n                node.backup(value)\n                node = node.parent\n\n        action_times = np.zeros(borad.size**2)\n        for child in self.root.children:\n            action_times[child.action] = child.N\n\n        action, pi = self.decision(action_times, temperature)\n        for child in self.root.children:\n            if child.action == action:\n                return pi, child\n\n    @staticmethod\n    def dirichlet_noise(props, eps=DLEPS, alpha=DLALPHA):\n        return (1 - eps) * props + eps * np.random.dirichlet(np.full(len(props), alpha))\n\n    @staticmethod\n    def decision(pi, temperature):\n        pi = (1.0 / temperature) * np.log(pi + 1e-10)\n        pi = np.exp(pi - np.max(pi))\n        pi /= np.sum(pi)\n        action = np.random.choice(len(pi), p=pi)\n        return action, pi\n'"
alpha-zero/net.py,6,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom const import *\n\n\nclass ResBlockNet(nn.Module):\n  def __init__(self,\n               ind=RES_BLOCK_FILLTERS,\n               block_filters=RES_BLOCK_FILLTERS,\n               kr_size=3,\n               stride=1,\n               padding=1,\n               bias=False):\n\n    super().__init__()\n\n    self.layers = nn.Sequential(\n        nn.Conv2d(ind, block_filters, kr_size,\n                  stride=stride,\n                  padding=padding,\n                  bias=bias),\n        nn.BatchNorm2d(block_filters),\n        nn.ReLU(),\n        nn.Conv2d(block_filters, block_filters, kr_size,\n                  stride=stride,\n                  padding=padding,\n                  bias=bias),\n        nn.BatchNorm2d(block_filters),\n    )\n\n  def forward(self, x):\n    res = x\n    out = self.layers(x) + x\n\n    return F.relu(out)\n\n\nclass Feature(nn.Module):\n  def __init__(self,\n               ind=IND,\n               outd=RES_BLOCK_FILLTERS):\n\n    super().__init__()\n\n    self.layer = nn.Sequential(\n        nn.Conv2d(ind, outd,\n                  stride=1,\n                  kernel_size=3,\n                  padding=1,\n                  bias=False),\n        nn.BatchNorm2d(outd),\n        nn.ReLU(),\n    )\n    self.encodes = nn.ModuleList([ResBlockNet() for _ in range(BLOCKS)])\n\n  def forward(self, x):\n    x = self.layer(x)\n    for enc in self.encodes:\n      x = enc(x)\n    return x\n\n\nclass Policy(nn.Module):\n  def __init__(self,\n               ind=RES_BLOCK_FILLTERS,\n               outd=OUTD,\n               kernels=2):\n\n    super().__init__()\n\n    self.out = outd * kernels\n\n    self.conv = nn.Sequential(\n        nn.Conv2d(ind, kernels, kernel_size=1),\n        nn.BatchNorm2d(kernels),\n        nn.ReLU(),\n    )\n\n    self.linear = nn.Linear(kernels * outd, outd)\n    self.linear.weight.data.uniform_(-.1, .1)\n\n  def forward(self, x):\n    x = self.conv(x)\n    x = x.view(-1, self.out)\n    x = self.linear(x)\n\n    return F.log_softmax(x, dim=-1)\n\n\nclass Value(nn.Module):\n  def __init__(self,\n               ind=RES_BLOCK_FILLTERS,\n               outd=OUTD,\n               hsz=256,\n               kernels=1):\n    super().__init__()\n\n    self.outd = outd\n\n    self.conv = nn.Sequential(\n        nn.Conv2d(ind, kernels, kernel_size=1),\n        nn.BatchNorm2d(kernels),\n        nn.ReLU(),\n    )\n\n    self.linear = nn.Sequential(\n        nn.Linear(outd, hsz),\n        nn.ReLU(),\n        nn.Linear(hsz, 1),\n        nn.Tanh(),\n    )\n\n    self._reset_parameters()\n\n  def forward(self, x):\n    x = self.conv(x)\n    x = x.view(-1, self.outd)\n\n    return self.linear(x)\n\n  def _reset_parameters(self):\n    for layer in self.modules():\n      if type(layer) == nn.Linear:\n        layer.weight.data.uniform_(-.1, .1)\n\n\nclass Net(nn.Module):\n  def __init__(self):\n    super().__init__()\n\n    self.feat = Feature()\n    self.value = Value()\n    self.policy = Policy()\n\n  def forward(self, x):\n    feats = self.feat(x)\n    winners = self.value(feats)\n    props = self.policy(feats)\n\n    return winners, props\n\n  def save_model(self, path=""model.pt""):\n    torch.save(self.state_dict(), path)\n\n  def load_model(self, path=""model.pt"", cuda=True):\n    if cuda:\n      self.load_state_dict(torch.load(path))\n      self.cuda()\n    else:\n      self.load_state_dict(torch.load(\n          path, map_location=lambda storage, loc: storage))\n      self.cpu()\n\n\nclass AlphaEntropy(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.v_loss = nn.MSELoss()\n\n  def forward(self, props, v, pi, reward):\n    v_loss = self.v_loss(v, reward)\n    p_loss = -torch.mean(torch.sum(props * pi, 1))\n\n    return p_loss + v_loss\n\n\nclass ScheduledOptim(object):\n  def __init__(self, optimizer, lr):\n\n    self.lr = lr\n    self.optimizer = optimizer\n\n  def step(self):\n    self.optimizer.step()\n\n  def zero_grad(self):\n    self.optimizer.zero_grad()\n\n  def update_learning_rate(self, lr_multiplier):\n    new_lr = self.lr * lr_multiplier\n    for param_group in self.optimizer.param_groups:\n      param_group[\'lr\'] = new_lr\n\n\nif __name__ == ""__main__"":\n  net = Net()\n  net.load_model()\n'"
alpha-zero/play.py,0,"b'from mcts import MonteCarloTreeSearch, TreeNode\nfrom net import Net\nfrom const import *\nfrom game import Board\n\n\nclass Play(object):\n    def __init__(self):\n        net = Net()\n        if USECUDA:\n            net = net.cuda()\n        net.load_model(""model.pt"", cuda=USECUDA)\n        self.net = net\n        self.net.eval()\n\n    def go(self):\n        print(""One rule:\\r\\n Move piece form \'x,y\' \\r\\n eg 1,3\\r\\n"")\n        print(""-"" * 60)\n        print(""Ready Go"")\n\n        mc = MonteCarloTreeSearch(self.net, 1000)\n        node = TreeNode()\n        board = Board()\n\n        while True:\n            if board.c_player == BLACK:\n                action = input(f""Your piece is \'O\' and move: "")\n                action = [int(n, 10) for n in action.split("","")]\n                action = action[0] * board.size + action[1]\n                next_node = TreeNode(action=action)\n            else:\n                _, next_node = mc.search(board, node)\n\n            board.move(next_node.action)\n            board.show()\n\n            next_node.parent = None\n            node = next_node\n\n            if board.is_draw():\n                print(""-"" * 28 + ""Draw"" + ""-"" * 28)\n                return\n\n            if board.is_game_over():\n                if board.c_player == BLACK:\n                    print(""-"" * 28 + ""Win"" + ""-"" * 28)\n                else:\n                    print(""-"" * 28 + ""Loss"" + ""-"" * 28)\n                return\n\n            board.trigger()\n\n\nif __name__ == ""__main__"":\n    p = Play()\n    p.go()\n'"
alpha-zero/train.py,5,"b'import time\nfrom collections import deque\nimport random\n\nimport numpy as np\nimport torch\n\nfrom net import *\nfrom game import Game\nfrom data_loader import DataLoader\n\n\nclass Train(object):\n    def __init__(self, use_cuda=USECUDA, lr=LR):\n\n        if use_cuda:\n            torch.cuda.manual_seed(1234)\n        else:\n            torch.manual_seed(1234)\n\n        self.kl_targ = 0.02\n        self.lr_multiplier = 1.\n        self.use_cuda = use_cuda\n\n        self.net = Net()\n        self.eval_net = Net()\n        if use_cuda:\n            self.net = self.net.cuda()\n            self.eval_net = self.eval_net.cuda()\n\n        self.dl = DataLoader(use_cuda, MINIBATCH)\n        self.sample_data = deque(maxlen=TRAINLEN)\n        self.gen_optim(lr)\n        self.entropy = AlphaEntropy()\n\n    def sample(self, datas):\n        for state, pi, reward in datas:\n            c_state = state.copy()\n            c_pi = pi.copy()\n            for i in range(4):\n                c_state = np.array([np.rot90(s, i) for s in c_state])\n                c_pi = np.rot90(c_pi.reshape(SIZE, SIZE), i)\n                self.sample_data.append([c_state, c_pi.flatten(), reward])\n\n                c_state = np.array([np.fliplr(s) for s in c_state])\n                c_pi = np.fliplr(c_pi)\n                self.sample_data.append([c_state, c_pi.flatten(), reward])\n\n        return len(datas)\n\n    def gen_optim(self, lr):\n        optim = torch.optim.Adam(self.net.parameters(), lr=lr, weight_decay=L2)\n        self.optim = ScheduledOptim(optim, lr)\n\n    def run(self):\n        model_path = f""model_{time.strftime(\'%Y%m%d%H%M\', time.localtime())}.pt""\n        self.net.save_model(path=model_path)\n        self.eval_net.load_model(path=model_path, cuda=self.use_cuda)\n\n        for step in range(1, 1 + GAMETIMES):\n            game = Game(self.net, self.eval_net)\n            print(f""Game - {step} | data length - {self.sample(game.play())}"")\n            if len(self.sample_data) < MINIBATCH:\n                continue\n\n            states, pi, rewards = self.dl(self.sample_data)\n            _, old_props = self.net(states)\n\n            for _ in range(EPOCHS):\n                self.optim.zero_grad()\n\n                v, props = self.net(states)\n                loss = self.entropy(props, v, pi, rewards)\n                loss.backward()\n\n                self.optim.step()\n\n                _, new_props = self.net(states)\n                kl = torch.mean(torch.sum(\n                    torch.exp(old_props) * (old_props - new_props), 1)).item()\n                if kl > self.kl_targ * 4:\n                    break\n\n            if kl > self.kl_targ * 2 and self.lr_multiplier > 0.1:\n                self.lr_multiplier /= 1.5\n            elif kl < self.kl_targ / 2 and self.lr_multiplier < 10:\n                self.lr_multiplier *= 1.5\n\n            self.optim.update_learning_rate(self.lr_multiplier)\n\n            print(\n                f""kl - {kl} | lr_multiplier - {self.lr_multiplier} | loss - {loss}"")\n            print(""-"" * 100 + ""\\r\\n"")\n\n            if step % CHECKOUT == 0:\n                result = [0, 0, 0]  # draw win loss\n                for _ in range(EVALNUMS):\n                    game.reset()\n                    game.evaluate(result)\n\n                if result[1] + result[2] == 0:\n                    rate = 0\n                else:\n                    rate = result[1] / (result[1] + result[2])\n\n                print(f""step - {step} evaluation"")\n                print(\n                    f""win - {result[1]} | loss - {result[2]} | draw - {result[0]}"")\n\n                # save or reload model\n                if rate >= WINRATE:\n                    print(f""new best model. rate - {rate}"")\n                    self.net.save_model(path=model_path)\n                    self.eval_net.load_model(\n                        path=model_path, cuda=self.use_cuda)\n                else:\n                    print(f""load last model. rate - {rate}"")\n                    self.net.load_model(path=model_path, cuda=self.use_cuda)\n\n                print(""-"" * 100 + ""\\r\\n"")\n\n\nif __name__ == ""__main__"":\n    t = Train()\n    t.run()\n'"
biLSTM-CRF-cut/const.py,0,"b""X = 0\nB = 1\nM = 2\nE = 3\nS = 4\n\nWORD = {\n    S: 's',\n    B: 'b',\n    M: 'm',\n    E: 'e',\n    X: 'x'\n}\n\nUNK = 1\nUNK_WORD = 'u'\n"""
biLSTM-CRF-cut/corpus.py,1,"b'import torch\n\nimport argparse\n\nimport const\n\n\ndef corpora2idx(sents, ind2idx):\n    return [[ind2idx[w] if w in ind2idx else const.UNK for w in s] for s in sents]\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            const.WORD[const.X]: const.X,\n            const.UNK_WORD: const.X\n        }\n        self.idx2word = {\n            const.X: const.WORD[const.X],\n            const.UNK: const.UNK_WORD\n        }\n        self.idx = 2\n\n    def add(self, ind):\n        if self.word2idx.get(ind) is None:\n            self.word2idx[ind] = self.idx\n            self.idx2word[self.idx] = ind\n            self.idx += 1\n\n    def build_idx(self, sents):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words: word_count[w]+=1\n\n        for word, count in word_count.items():\n            self.add(word)\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\nclass Corpus(object):\n    def __init__(self, train_src, valid_src, save_data, max_len=32):\n        self._train_src = train_src\n        self._valid_src = valid_src\n        self._save_data = save_data\n        self.max_len = max_len\n\n        self.sent_dict = Dictionary()\n        self.tgt_dict = {\n            const.WORD[const.X]: const.X,\n            const.WORD[const.B]: const.B,\n            const.WORD[const.M]: const.M,\n            const.WORD[const.E]: const.E,\n            const.WORD[const.S]: const.S\n        }\n\n    def parse_train(self):\n        src_sents, labels = [], []\n\n        for sentence in open(self._train_src):\n            words, tgts = [], []\n\n            objs = sentence.strip().split(""\\t"")\n            if len(objs) > self.max_len:\n                objs = objs[:self.max_len]\n\n            for obj in objs:\n                word, tgt = obj.strip().split(""/"")\n                words += [word]\n                tgts += [tgt]\n\n            src_sents.append(words)\n            labels.append(tgts)\n\n        self.sent_dict.build_idx(src_sents)\n\n        self.src_sents = src_sents\n        self.labels = labels\n\n    def parse_valid(self):\n        src_sents, labels = [], []\n\n        for sentence in open(self._valid_src):\n            words, tgts = [], []\n\n            objs = sentence.strip().split(""\\t"")\n            if len(objs) > self.max_len:\n                objs = objs[:self.max_len]\n\n            for obj in objs:\n                word, tgt = obj.strip().split(""/"")\n                words += [word]\n                tgts += [tgt]\n\n            src_sents.append(words)\n            labels.append(tgts)\n\n\n        self.valid_src_sents = src_sents\n        self.valid_labels = labels\n\n    def save(self):\n        data = {\n            \'trains_score\': self.trains_score(),\n            \'max_len\': self.max_len,\n            \'tag_size\': len(self.tgt_dict),\n            \'dict\': {\n                \'src\': self.sent_dict.word2idx,\n                \'vocab_size\': len(self.sent_dict),\n                \'tgt\': self.tgt_dict\n            },\n            \'train\': {\n                \'src\': corpora2idx(self.src_sents, self.sent_dict.word2idx),\n                \'label\': corpora2idx(self.labels, self.tgt_dict),\n            },\n            \'valid\': {\n                \'src\': corpora2idx(self.valid_src_sents, self.sent_dict.word2idx),\n                \'label\': corpora2idx(self.valid_labels, self.tgt_dict),\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'Finish dumping the corora data to file - [{}]\'.format(self._save_data))\n        print(\'words length - [{}]\'.format(len(self.sent_dict)))\n\n    def trains_score(self):\n        A = {\n          \'sb\':0,\n          \'ss\':0,\n          \'be\':0,\n          \'bm\':0,\n          \'me\':0,\n          \'mm\':0,\n          \'eb\':0,\n          \'es\':0\n        }\n        for label in self.labels:\n            for t in range(len(label) - 1):\n                key = label[t] + label[t+1]\n                A[key] += 1.0\n\n        ts = dict()\n        ts[\'sb\'] = A[\'sb\'] / (A[\'sb\'] + A[\'ss\'])\n        ts[\'ss\'] = 1.0 - ts[\'sb\']\n        ts[\'be\'] = A[\'be\'] / (A[\'be\'] + A[\'bm\'])\n        ts[\'bm\'] = 1.0 - ts[\'be\']\n        ts[\'me\'] = A[\'me\'] / (A[\'me\'] + A[\'mm\'])\n        ts[\'mm\'] = 1.0 - ts[\'me\']\n        ts[\'eb\'] = A[\'eb\'] / (A[\'eb\'] + A[\'es\'])\n        ts[\'es\'] = 1.0 - ts[\'eb\']\n\n        return ts\n\n    def process(self):\n        self.parse_train()\n        self.parse_valid()\n        self.save()\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'bilstm crf word-cut\')\n    parser.add_argument(\'--train-src\', type=str, required=True,\n                        help=\'train file\')\n    parser.add_argument(\'--save-data\', type=str, required=True,\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--valid-src\', type=str, default=None,\n                        help=\'valid file\')\n    parser.add_argument(\'--max-lenth\', type=int, default=32,\n                        help=\'max length left of sentence [default: 32]\')\n    args = parser.parse_args()\n    corpus = Corpus(args.train_src, args.valid_src, args.save_data, args.max_lenth)\n    corpus.process()\n'"
biLSTM-CRF-cut/data_loader.py,2,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\nclass DataLoader(object):\n    def __init__(self, src_sents, label, max_len, cuda=True, batch_size=64, shuffle=True):\n        self.cuda = cuda\n        self.sents_size = len(src_sents)\n\n        self._batch_size = batch_size\n        self._max_len = max_len\n        self._src_sents = np.asarray(src_sents)\n        self._label = np.asarray(label)\n        if shuffle:\n            self.shuffle()\n\n    def shuffle(self):\n        indices = np.arange(self._src_sents.shape[0])\n        np.random.shuffle(indices)\n        self._src_sents = self._src_sents[indices]\n        self._label = self._label[indices]\n\n    def get_batch(self, i, evaluation=False):\n        def pad_to_longest(insts, max_len):\n            inst_data = np.array([inst + [const.X] * (max_len - len(inst)) for inst in insts])\n\n            inst_data_tensor = Variable(torch.from_numpy(inst_data), volatile=evaluation)\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        bsz = min(self._batch_size, self.sents_size-1-i)\n\n        src = pad_to_longest(self._src_sents[i:i+bsz], self._max_len)\n        label = pad_to_longest(self._label[i:i+bsz], self._max_len)\n        return src, label.view(-1)\n'"
biLSTM-CRF-cut/model.py,4,"b'import time\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.nn import init\n\nclass BiLSTM_Cut(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.lookup_table = nn.Embedding(self.vocab_size, self.embed_dim)\n        self.bi_lstm = nn.LSTM(self.embed_dim,\n                               self.lstm_hsz,\n                               num_layers=self.lstm_layers,\n                               batch_first=True,\n                               dropout=self.dropout,\n                               bidirectional=True)\n\n        self.logistic = nn.Linear(2*self.lstm_hsz, self.tag_size)\n        self._init_weights(scope=self.w_init)\n\n    def forward(self, sentences):\n        sents_ebd = self.lookup_table(sentences)\n        output, _ = self.bi_lstm(sents_ebd)\n        output = self.logistic(output).view(-1, self.tag_size)\n        return F.log_softmax(output)\n\n    def _init_weights(self, scope=0.25):\n        self.lookup_table.weight.data.uniform_(-scope, scope)\n        init.xavier_uniform(self.logistic.weight)\n\n'"
biLSTM-CRF-cut/optim.py,0,"b'import numpy as np\n\nclass ScheduledOptim(object):\n    def __init__(self, optimizer, hsz, n_warmup_steps):\n        self.optimizer = optimizer\n        self.hsz = hsz\n        self.n_warmup_steps = n_warmup_steps\n        self.n_current_steps = 0\n\n    def step(self):\n        ""Step by the inner optimizer""\n        self.optimizer.step()\n\n    def zero_grad(self):\n        ""Zero out the gradients by the inner optimizer""\n        self.optimizer.zero_grad()\n\n    def update_learning_rate(self):\n        self.n_current_steps += 1\n        new_lr = np.power(self.hsz, -0.5) * np.min([np.power(self.n_current_steps, -0.5), np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n\n        for param_group in self.optimizer.param_groups:\n            param_group[\'lr\'] = new_lr\n'"
biLSTM-CRF-cut/segment.py,6,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport numpy as np\nimport re\n\nfrom const import *\nfrom model import BiLSTM_Cut\n\nimport time\n\nclass Segment(object):\n    def __init__(self, model_source=""model"", cuda=False):\n        self.torch = torch.cuda if cuda else torch\n        self.cuda = cuda\n        if self.cuda:\n            model_source = torch.load(model_source)\n        else:\n            model_source = torch.load(model_source, map_location=lambda storage, loc: storage)\n\n        self.src_dict = model_source[""src_dict""]\n        self.trains_score = model_source[""trains_score""]\n        self.args = args = model_source[""settings""]\n\n        model = BiLSTM_Cut(args)\n        model.load_state_dict(model_source[\'model\'])\n\n        if self.cuda:\n            model = model.cuda()\n            model.prob_projection = nn.Softmax().cuda()\n        else:\n            model = model.cpu()\n            model.prob_projection = nn.Softmax().cpu()\n\n        self.model = model.eval()\n\n    def text2tensor(self, text):\n        ids = [self.src_dict[w] if w in self.src_dict else UNK for w in text]\n        ids = Variable(torch.LongTensor(ids).unsqueeze(0), volatile=True)\n        if self.cuda:\n            ids = ids.cuda()\n        return ids\n\n    def viterbi(self, nodes):\n        paths = {WORD[B]: nodes[0][WORD[B]], WORD[S]: nodes[0][WORD[S]]}\n\n        for w_step in range(1, len(nodes)):\n            _path = paths.copy()\n            paths = {}\n\n            sub_paths = {}\n            for code, score in nodes[w_step].items():\n                for last_code, last_score in _path.items():\n                    if last_code[-1] + code in self.trains_score:\n                        sub_paths[last_code+code] = last_score*score*self.trains_score[last_code[-1] + code]\n\n            sorted_sub_path = sorted(sub_paths.items(),\n                                key=lambda path: path[1],\n                                reverse=True)\n\n            best_path, best_score = sorted_sub_path[0]\n            paths[best_path] = best_score\n\n        sorted_path = sorted(paths.items(),\n                            key=lambda path: path[1],\n                            reverse=True)\n        best_path, _ = sorted_path[0]\n        return best_path\n\n    def text_cut(self, text):\n        if text:\n            text_len = len(text)\n            tensor = self.text2tensor(text)\n            pre = self.model.prob_projection(self.model(tensor))\n            nodes = [dict(zip([WORD[B], WORD[M], WORD[E], WORD[S]], each[1:])) for each in pre.data]\n\n            tags = self.viterbi(nodes)\n            words = []\n            for i in range(len(text)):\n                if tags[i] in [WORD[B], WORD[S]]:\n                    words.append(text[i])\n                else:\n                    words[-1] += text[i]\n\n            return words\n        else:\n            return []\n\n    def sentence_cut(self, sentence):\n        not_cuts = re.compile(u\'([0-9\\da-zA-Z ]+)|[\xe3\x80\x82\xef\xbc\x8c\xe3\x80\x81\xef\xbc\x9f\xef\xbc\x81.\\.\\?,!]\')\n        result = []\n        start = 0\n        for seg_sign in not_cuts.finditer(sentence):\n            result.extend(self.text_cut(sentence[start:seg_sign.start()]))\n            result.append(sentence[seg_sign.start():seg_sign.end()])\n            start = seg_sign.end()\n        result.extend(self.text_cut(sentence[start:]))\n        return result\n\nif __name__ == ""__main__"":\n    import time\n    sg = Segment()\n    print(sg.sentence_cut(""ngram\xe6\x98\xaf\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe4\xb8\xad\xe4\xb8\x80\xe4\xb8\xaa\xe9\x9d\x9e\xe5\xb8\xb8\xe9\x87\x8d\xe8\xa6\x81\xe7\x9a\x84\xe6\xa6\x82\xe5\xbf\xb5\xef\xbc\x8c\xe9\x80\x9a\xe5\xb8\xb8\xe5\x9c\xa8NLP\xe4\xb8\xad\xef\xbc\x8c\xe4\xba\xba\xe4\xbb\xac\xe5\x9f\xba\xe4\xba\x8e\xe4\xb8\x80\xe5\xae\x9a\xe7\x9a\x84\xe8\xaf\xad\xe6\x96\x99\xe5\xba\x93\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe5\x88\xa9\xe7\x94\xa8ngram\xe6\x9d\xa5\xe9\xa2\x84\xe8\xae\xa1\xe6\x88\x96\xe8\x80\x85\xe8\xaf\x84\xe4\xbc\xb0\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8f\xa5\xe5\xad\x90\xe6\x98\xaf\xe5\x90\xa6\xe5\x90\x88\xe7\x90\x86\xe3\x80\x82\xe5\x8f\xa6\xe5\xa4\x96\xe4\xb8\x80\xe6\x96\xb9\xe9\x9d\xa2\xef\xbc\x8cngram\xe7\x9a\x84\xe5\x8f\xa6\xe5\xa4\x96\xe4\xb8\x80\xe4\xb8\xaa\xe4\xbd\x9c\xe7\x94\xa8\xe6\x98\xaf\xe7\x94\xa8\xe6\x9d\xa5\xe8\xaf\x84\xe4\xbc\xb0\xe4\xb8\xa4\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe4\xb9\x8b\xe9\x97\xb4\xe7\x9a\x84\xe5\xb7\xae\xe5\xbc\x82\xe7\xa8\x8b\xe5\xba\xa6\xe3\x80\x82\xe8\xbf\x99\xe6\x98\xaf\xe6\xa8\xa1\xe7\xb3\x8a\xe5\x8c\xb9\xe9\x85\x8d\xe4\xb8\xad\xe5\xb8\xb8\xe7\x94\xa8\xe7\x9a\x84\xe4\xb8\x80\xe7\xa7\x8d\xe6\x89\x8b\xe6\xae\xb5\xe3\x80\x82\xe6\x9c\xac\xe6\x96\x87\xe5\xb0\x86\xe4\xbb\x8e\xe6\xad\xa4\xe5\xbc\x80\xe5\xa7\x8b\xef\xbc\x8c\xe8\xbf\x9b\xe8\x80\x8c\xe5\x90\x91\xe8\xaf\xbb\xe8\x80\x85\xe5\xb1\x95\xe7\xa4\xbangram\xe5\x9c\xa8\xe8\x87\xaa\xe7\x84\xb6\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86\xe4\xb8\xad\xe7\x9a\x84\xe5\x90\x84\xe7\xa7\x8dpowerful\xe7\x9a\x84\xe5\xba\x94\xe7\x94\xa8""))\n'"
biLSTM-CRF-cut/train.py,11,"b'import argparse\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn.functional as F\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--epochs\', type=int, default=32,\n                    help=\'number of epochs for train [default: 32]\')\nparser.add_argument(\'--batch-size\', type=int, default=64,\n                    help=\'batch size for training [default: 64]\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda-able\', action=\'store_true\',\n                    help=\'enables cuda\')\n\nparser.add_argument(\'--save\', type=str, default=\'model/lstm_cut.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--save-epoch\', action=\'store_true\',\n                    help=\'save every epoch\')\nparser.add_argument(\'--data\', type=str, default=\'./data/lstm_cut.pt\',\n                    help=\'location of the data corpus\')\n\nparser.add_argument(\'--embed-dim\', type=int, default=256,\n                    help=\'number of embedding dimension [default: 256]\')\nparser.add_argument(\'--dropout\', type=float, default=0.3,\n                    help=\'the probability for dropout (0 = no dropout) [default: 0.3]\')\nparser.add_argument(\'--lstm-hsz\', type=int, default=256,\n                    help=\'BiLSTM hidden size\')\nparser.add_argument(\'--lstm-layers\', type=int, default=3,\n                    help=\'biLSTM layer numbers\')\nparser.add_argument(\'--w-init\', type=float, default=0.25,\n                    help=\'weight init scope\')\nparser.add_argument(\'--n-warmup-steps\', type=int, default=0)\n\nargs = parser.parse_args()\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available() and args.cuda_able\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# ##############################################################################\n# Load data\n# ##############################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_len = data[""max_len""]\nargs.tag_size = data[""tag_size""]\nargs.vocab_size = data[\'dict\'][\'vocab_size\']\nargs.trains_score = data[\'trains_score\']\ntraining_data = DataLoader(\n    data[\'train\'][\'src\'],\n    data[\'train\'][\'label\'],\n    args.max_len,\n    batch_size=args.batch_size,\n    cuda=use_cuda)\n\nvalidation_data = DataLoader(\n    data[\'valid\'][\'src\'],\n    data[\'valid\'][\'label\'],\n    args.max_len,\n    batch_size=args.batch_size,\n    shuffle=False,\n    cuda=use_cuda)\n\nargs.n_warmup_steps = args.n_warmup_steps if args.n_warmup_steps != 0 else training_data.sents_size // args.batch_size\n\n# ##############################################################################\n# Build model\n# ##############################################################################\nfrom model import BiLSTM_Cut\nfrom optim import ScheduledOptim\n\nmodel = BiLSTM_Cut(args)\nif use_cuda:\n    model = model.cuda()\n\noptimizer = ScheduledOptim(\n    torch.optim.Adam(model.parameters(),\n                     betas=(0.9, 0.98), eps=1e-09),\n    args.lstm_hsz, args.n_warmup_steps)\n\ncriterion = torch.nn.CrossEntropyLoss()\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\n\n\ndef evaluate():\n    model.eval()\n    corrects = eval_loss = 0\n    _size = validation_data.sents_size\n    for batch in tqdm(range(0, _size, args.batch_size),\n                      mininterval=0.2, desc=\'Evaluate Processing\', leave=False):\n        src, label = validation_data.get_batch(batch, evaluation=True)\n        pred = model(src)\n        loss = criterion(pred, label)\n        eval_loss += loss.data[0]\n        corrects += (torch.max(pred, 1)\n                     [1].view(label.size()).data == label.data).sum()\n\n    _size *= args.max_len\n    return eval_loss / _size, corrects, corrects / _size * 100.0, _size\n\n\ndef train():\n    model.train()\n    total_loss = 0\n    _size = training_data.sents_size\n    for batch in tqdm(range(0, _size, args.batch_size),\n                      mininterval=2, desc=\'Training Processing\', leave=False):\n        src, label = training_data.get_batch(batch)\n\n        optimizer.zero_grad()\n        pred = model(src)\n\n        loss = criterion(pred, label)\n        loss.backward()\n\n        optimizer.step()\n        optimizer.update_learning_rate()\n        total_loss += loss.data\n    return total_loss[0] / (_size * args.max_len)\n\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs + 1):\n        epoch_start_time = time.time()\n        loss = train()\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(\n            epoch, time.time() - epoch_start_time, loss))\n\n        loss, corrects, acc, size = evaluate()\n        epoch_start_time = time.time()\n        print(\'-\' * 90)\n        print(\'| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(\n            epoch, time.time() - epoch_start_time, loss, acc, corrects, size))\n        print(\'-\' * 90)\n\n        model_state_dict = model.state_dict()\n        model_source = {\n            ""settings"": args,\n            ""model"": model_state_dict,\n            ""src_dict"": data[\'dict\'][\'src\'],\n            ""trains_score"": data[\'trains_score\']\n        }\n        if not best_acc or best_acc < corrects:\n            best_acc = corrects\n            torch.save(model_source, args.save)\n        if args.save_epoch:\n            torch.save(model_source, ""{}_{}"".format(args.save, epoch))\n\nexcept KeyboardInterrupt:\n    print(""-"" * 80)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format(\n        (time.time() - total_start_time) / 60.0))\n'"
biLSTM-CRF/const.py,0,"b'X = 0\nO = 1\nBH = 2\nIH = 3\nBW = 4\nIW = 5\n\nWORD = {\n    X: \'x\',\n    O: \'o\',\n    BH: \'H\',\n    IH: \'h\',\n    BW: \'W\',\n    IW: \'w\'\n}\n\nUNK = 1\nUNK_WORD = \'u\'\n\nSPLIT_TAG = ""###""\n'"
biLSTM-CRF/corpus.py,1,"b'import torch\n\nimport argparse\n\nfrom const import *\n\n\ndef corpora2idx(sents, ind2idx):\n    return [[ind2idx[w] if w in ind2idx else UNK for w in s] for s in sents]\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[X]: X,\n            UNK_WORD: X\n        }\n        self.idx2word = {\n            X: WORD[X],\n            UNK: UNK_WORD\n        }\n        self.idx = 2\n\n    def add(self, ind):\n        if self.word2idx.get(ind) is None:\n            self.word2idx[ind] = self.idx\n            self.idx2word[self.idx] = ind\n            self.idx += 1\n\n    def build_idx(self, sents):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words: word_count[w]+=1\n\n        for word, count in word_count.items():\n            self.add(word)\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\nclass Corpus(object):\n    def __init__(self, train_src, valid_src, save_data, max_len=32):\n        self._train_src = train_src\n        self._valid_src = valid_src\n        self._save_data = save_data\n        self.max_len = max_len\n\n        self.sent_dict = Dictionary()\n        self.tgt_dict = {\n            WORD[X]: X,\n            WORD[O]: O,\n            WORD[BH]: BH,\n            WORD[IH]: IH,\n            WORD[BW]: BW,\n            WORD[IW]: IW\n        }\n\n    def parse_train(self):\n        src_sents, labels = [], []\n        ignore_text = 0\n        for sentence in open(self._train_src):\n            words, tgts = [], []\n\n            objs = sentence.strip().split(""\\t"")\n            if len(objs) > self.max_len:\n                ignore_text += 1\n                objs = objs[:self.max_len]\n\n            for obj in objs:\n                word, tgt = obj.strip().split(SPLIT_TAG)\n                words += [word]\n                tgts += [tgt]\n\n            src_sents.append(words)\n            labels.append(tgts)\n\n        self.sent_dict.build_idx(src_sents)\n\n        self.src_sents = src_sents\n        self.labels = labels\n        print(""length of text more then {} numbers: {}"".format(self.max_len, ignore_text))\n\n    def parse_valid(self):\n        src_sents, labels = [], []\n\n        for sentence in open(self._valid_src):\n            words, tgts = [], []\n\n            objs = sentence.strip().split(""\\t"")\n            if len(objs) > self.max_len:\n                objs = objs[:self.max_len]\n\n            for obj in objs:\n                word, tgt = obj.strip().split(SPLIT_TAG)\n                words += [word]\n                tgts += [tgt]\n\n            src_sents.append(words)\n            labels.append(tgts)\n\n\n        self.valid_src_sents = src_sents\n        self.valid_labels = labels\n\n    def save(self):\n        data = {\n            \'trains_score\': self.trains_score(),\n            \'max_len\': self.max_len,\n            \'tag_size\': len(self.tgt_dict),\n            \'dict\': {\n                \'src\': self.sent_dict.word2idx,\n                \'vocab_size\': len(self.sent_dict),\n                \'tgt\': self.tgt_dict\n            },\n            \'train\': {\n                \'src\': corpora2idx(self.src_sents, self.sent_dict.word2idx),\n                \'label\': corpora2idx(self.labels, self.tgt_dict),\n            },\n            \'valid\': {\n                \'src\': corpora2idx(self.valid_src_sents, self.sent_dict.word2idx),\n                \'label\': corpora2idx(self.valid_labels, self.tgt_dict),\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'Finish dumping the corora data to file - [{}]\'.format(self._save_data))\n        print(\'words length - [{}]\'.format(len(self.sent_dict)))\n\n    def trains_score(self):\n        A = {\n          \'oH\':0,\n          \'oW\':0,\n          \'oo\':0,\n          \'Hh\':1.0,\n          \'hh\':0,\n          \'ho\':0,\n          \'hW\':0,\n          \'Ww\':1.0,\n          \'ww\':0,\n          \'wo\':0,\n          \'wH\':0,\n        }\n        for label in self.labels:\n            for t in range(len(label) - 1):\n                key = label[t] + label[t+1]\n                assert key in A\n                A[key] += 1.0\n\n        ts = dict()\n        ts[\'oH\'] = A[\'oH\'] / (A[\'oH\'] + A[\'oW\'] + A[\'oo\'])\n        ts[\'oW\'] = A[\'oW\'] / (A[\'oH\'] + A[\'oW\'] + A[\'oo\'])\n        ts[\'oo\'] = A[\'oo\'] / (A[\'oH\'] + A[\'oW\'] + A[\'oo\'])\n\n        ts[\'hh\'] = A[\'hh\'] / (A[\'hh\'] + A[\'ho\'] + A[\'hW\'])\n        ts[\'ho\'] = A[\'ho\'] / (A[\'hh\'] + A[\'ho\'] + A[\'hW\'])\n        ts[\'hW\'] = A[\'hW\'] / (A[\'hh\'] + A[\'ho\'] + A[\'hW\'])\n\n        ts[\'ww\'] = A[\'ww\'] / (A[\'ww\'] + A[\'wo\'] + A[\'wH\'])\n        ts[\'wo\'] = A[\'wo\'] / (A[\'ww\'] + A[\'wo\'] + A[\'wH\'])\n        ts[\'wH\'] = A[\'wH\'] / (A[\'ww\'] + A[\'wo\'] + A[\'wH\'])\n\n        ts[""Hh""] = 1.\n        ts[""Ww""] = 1.\n\n        return ts\n\n    def process(self):\n        self.parse_train()\n        self.parse_valid()\n        self.save()\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'bilstm crf nre\')\n    parser.add_argument(\'--train-src\', type=str, required=True,\n                        help=\'train file\')\n    parser.add_argument(\'--save-data\', type=str, required=True,\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--valid-src\', type=str, default=None,\n                        help=\'valid file\')\n    parser.add_argument(\'--max-lenth\', type=int, default=32,\n                        help=\'max length left of sentence [default: 32]\')\n    args = parser.parse_args()\n    corpus = Corpus(args.train_src, args.valid_src, args.save_data, args.max_lenth)\n    corpus.process()\n'"
biLSTM-CRF/data_loader.py,2,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\nclass DataLoader(object):\n    def __init__(self, src_sents, label, max_len, cuda=True, batch_size=64, shuffle=True):\n        self.cuda = cuda\n        self.sents_size = len(src_sents)\n\n        self._batch_size = batch_size\n        self._max_len = max_len\n        self._src_sents = np.asarray(src_sents)\n        self._label = np.asarray(label)\n        if shuffle:\n            self.shuffle()\n\n    def shuffle(self):\n        indices = np.arange(self._src_sents.shape[0])\n        np.random.shuffle(indices)\n        self._src_sents = self._src_sents[indices]\n        self._label = self._label[indices]\n\n    def get_batch(self, i, evaluation=False):\n        def pad_to_longest(insts, max_len):\n            inst_data = np.array([inst + [const.X] * (max_len - len(inst)) for inst in insts])\n\n            inst_data_tensor = Variable(torch.from_numpy(inst_data), volatile=evaluation)\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        bsz = min(self._batch_size, self.sents_size-1-i)\n\n        src = pad_to_longest(self._src_sents[i:i+bsz], self._max_len)\n        label = pad_to_longest(self._label[i:i+bsz], self._max_len)\n        return src, label.view(-1)\n'"
biLSTM-CRF/model.py,4,"b'import time\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.nn import init\n\n\nclass BiLSTM_CRF_Size(nn.Module):\n    def __init__(self, args):\n        super(BiLSTM_CRF_Size, self).__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.lookup_table = nn.Embedding(self.vocab_size, self.embed_dim)\n        self.bi_lstm = nn.LSTM(self.embed_dim,\n                               self.lstm_hsz,\n                               num_layers=self.lstm_layers,\n                               batch_first=True,\n                               dropout=self.dropout,\n                               bidirectional=True)\n\n        self.logistic = nn.Linear(2 * self.lstm_hsz, self.tag_size)\n        self._init_weights(scope=self.w_init)\n\n    def forward(self, sentences):\n        sents_ebd = self.lookup_table(sentences)\n        output, _ = self.bi_lstm(sents_ebd)\n        output = self.logistic(output).view(-1, self.tag_size)\n        return F.log_softmax(output)\n\n    def _init_weights(self, scope=0.25):\n        self.lookup_table.weight.data.uniform_(-scope, scope)\n        init.xavier_uniform(self.logistic.weight)\n'"
biLSTM-CRF/optim.py,0,"b'import numpy as np\n\nclass ScheduledOptim(object):\n    def __init__(self, optimizer, hsz, n_warmup_steps):\n        self.optimizer = optimizer\n        self.hsz = hsz\n        self.n_warmup_steps = n_warmup_steps\n        self.n_current_steps = 0\n\n    def step(self):\n        ""Step by the inner optimizer""\n        self.optimizer.step()\n\n    def zero_grad(self):\n        ""Zero out the gradients by the inner optimizer""\n        self.optimizer.zero_grad()\n\n    def update_learning_rate(self):\n        self.n_current_steps += 1\n        new_lr = np.power(self.hsz, -0.5) * np.min([np.power(self.n_current_steps, -0.5), np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n\n        for param_group in self.optimizer.param_groups:\n            param_group[\'lr\'] = new_lr\n'"
biLSTM-CRF/predict.py,6,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport numpy as np\nimport re\n\nfrom const import *\nfrom model import BiLSTM_CRF_Size\n\n\nclass Predict(object):\n    def __init__(self, model_source, cuda=False):\n        self.torch = torch.cuda if cuda else torch\n        self.cuda = cuda\n        if self.cuda:\n            model_source = torch.load(model_source)\n        else:\n            model_source = torch.load(\n                model_source, map_location=lambda storage, loc: storage)\n\n        self.src_dict = model_source[""src_dict""]\n        self.trains_score = model_source[""trains_score""]\n        self.args = args = model_source[""settings""]\n\n        model = BiLSTM_CRF_Size(args)\n        model.load_state_dict(model_source[\'model\'])\n\n        if self.cuda:\n            model = model.cuda()\n            model.prob_projection = nn.Softmax().cuda()\n        else:\n            model = model.cpu()\n            model.prob_projection = nn.Softmax().cpu()\n\n        self.model = model.eval()\n\n    def text2tensor(self, text):\n        ids = [self.src_dict[w] if w in self.src_dict else UNK for w in text]\n        ids = Variable(torch.LongTensor(ids).unsqueeze(0), volatile=True)\n        if self.cuda:\n            ids = ids.cuda()\n        return ids\n\n    def viterbi(self, nodes):\n        paths = {\n            WORD[O]: nodes[0][WORD[O]],\n            WORD[BH]: nodes[0][WORD[BH]],\n            WORD[BW]: nodes[0][WORD[BW]]\n        }\n\n        for w_step in range(1, len(nodes)):\n            _path = paths.copy()\n            paths = {}\n\n            self.sub_paths = {}\n            for code, score in nodes[w_step].items():\n                for last_code, last_score in _path.items():\n                    if last_code[-1] + code in self.trains_score:\n                        self.sub_paths[last_code+code] = last_score * \\\n                            score*self.trains_score[last_code[-1] + code]\n\n            sorted_sub_path = sorted(self.sub_paths.items(),\n                                     key=lambda path: path[1],\n                                     reverse=True)\n\n            best_path, best_score = sorted_sub_path[0]\n            paths[best_path] = best_score\n\n        sorted_path = sorted(paths.items(),\n                             key=lambda path: path[1],\n                             reverse=True)\n        best_path, _ = sorted_path[0]\n        return best_path\n\n    def get_size(self, text):\n        res = {}\n        if text == """":\n            return res\n\n        tensor = self.text2tensor(text)\n        pre = self.model.prob_projection(self.model(tensor))\n        nodes = [dict(zip([WORD[O], WORD[BH], WORD[IH], WORD[BW],\n                           WORD[IW]], each[1:])) for each in pre.data]\n\n        tags = self.viterbi(nodes)\n\n        height, weight = [], []\n        for index, word in enumerate(text):\n            if tags[index] in [WORD[BH], WORD[IH]]:\n                height.append(word)\n\n            if tags[index] in [WORD[BW], WORD[IW]]:\n                weight.append(word)\n\n        if len(height) != 0:\n            res[""height""] = """".join(height)\n        if len(weight) != 0:\n            res[""weight""] = """".join(weight)\n\n        return res\n'"
biLSTM-CRF/train.py,11,"b'import argparse\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn.functional as F\n\nparser = argparse.ArgumentParser(description=\'CNN Ranking\')\nparser.add_argument(\'--epochs\', type=int, default=32,\n                    help=\'number of epochs for train [default: 32]\')\nparser.add_argument(\'--batch-size\', type=int, default=64,\n                    help=\'batch size for training [default: 64]\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda-able\', action=\'store_true\',\n                    help=\'enables cuda\')\n\nparser.add_argument(\'--save\', type=str, default=\'model/lstm_crf_size.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--save-epoch\', action=\'store_true\',\n                    help=\'save every epoch\')\nparser.add_argument(\'--data\', type=str, default=\'./data/lstm_crf_size.pt\',\n                    help=\'location of the data corpus\')\n\nparser.add_argument(\'--embed-dim\', type=int, default=256,\n                    help=\'number of embedding dimension [default: 256]\')\nparser.add_argument(\'--dropout\', type=float, default=0.3,\n                    help=\'the probability for dropout (0 = no dropout) [default: 0.3]\')\nparser.add_argument(\'--lstm-hsz\', type=int, default=256,\n                    help=\'BiLSTM hidden size\')\nparser.add_argument(\'--lstm-layers\', type=int, default=3,\n                    help=\'biLSTM layer numbers\')\nparser.add_argument(\'--w-init\', type=float, default=0.25,\n                    help=\'weight init scope\')\nparser.add_argument(\'--n-warmup-steps\', type=int, default=0)\n\nargs = parser.parse_args()\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available() and args.cuda_able\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# ##############################################################################\n# Load data\n# ##############################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_len = data[""max_len""]\nargs.tag_size = data[""tag_size""]\nargs.vocab_size = data[\'dict\'][\'vocab_size\']\nargs.trains_score = data[\'trains_score\']\ntraining_data = DataLoader(\n             data[\'train\'][\'src\'],\n             data[\'train\'][\'label\'],\n             args.max_len,\n             batch_size=args.batch_size,\n             cuda=use_cuda)\n\nvalidation_data = DataLoader(\n              data[\'valid\'][\'src\'],\n              data[\'valid\'][\'label\'],\n              args.max_len,\n              batch_size=args.batch_size,\n              shuffle=False,\n              cuda=use_cuda)\n\nargs.n_warmup_steps = args.n_warmup_steps if args.n_warmup_steps != 0 else training_data.sents_size // args.batch_size\n\n# ##############################################################################\n# Build model\n# ##############################################################################\nfrom model import BiLSTM_CRF_Size\nfrom optim import ScheduledOptim\n\nmodel = BiLSTM_CRF_Size(args)\nif use_cuda:\n   model = model.cuda()\n\noptimizer = ScheduledOptim(\n            torch.optim.Adam(model.parameters(),\n                            betas=(0.9, 0.98), eps=1e-09),\n            args.lstm_hsz, args.n_warmup_steps)\n\ncriterion = torch.nn.CrossEntropyLoss()\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\n\ndef evaluate():\n    model.eval()\n    corrects = eval_loss = 0\n    _size = validation_data.sents_size\n    for batch in tqdm(range(0, _size, args.batch_size),\n                      mininterval=0.2, desc=\'Evaluate Processing\', leave=False):\n        src, label = validation_data.get_batch(batch, evaluation=True)\n        pred = model(src)\n        loss = criterion(pred, label)\n        eval_loss += loss.data[0]\n        corrects += (torch.max(pred, 1)[1].view(label.size()).data == label.data).sum()\n\n    _size *= args.max_len\n    return eval_loss/_size, corrects, corrects/_size * 100.0, _size\n\ndef train():\n    model.train()\n    total_loss = 0\n    _size = training_data.sents_size\n    for batch in tqdm(range(0, _size, args.batch_size),\n                      mininterval=2, desc=\'Training Processing\', leave=False):\n        src, label = training_data.get_batch(batch)\n\n        optimizer.zero_grad()\n        pred = model(src)\n\n        loss = criterion(pred, label)\n        loss.backward()\n\n        optimizer.step()\n        optimizer.update_learning_rate()\n        total_loss += loss.data\n    return total_loss[0]/(_size*args.max_len)\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs+1):\n        epoch_start_time = time.time()\n        loss = train()\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(epoch, time.time() - epoch_start_time, loss))\n\n        loss, corrects, acc, size = evaluate()\n        epoch_start_time = time.time()\n        print(\'-\' * 90)\n        print(\'| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(epoch, time.time() - epoch_start_time, loss, acc, corrects, size))\n        print(\'-\' * 90)\n\n        model_state_dict = model.state_dict()\n        model_source = {\n            ""settings"": args,\n            ""model"": model_state_dict,\n            ""src_dict"": data[\'dict\'][\'src\'],\n            ""trains_score"": data[\'trains_score\']\n        }\n        if not best_acc or best_acc < corrects:\n            best_acc = corrects\n            torch.save(model_source, args.save)\n        if args.save_epoch:\n            torch.save(model_source, ""{}_{}"".format(args.save, epoch))\n\nexcept KeyboardInterrupt:\n    print(""-""*80)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format((time.time() - total_start_time)/60.0))\n'"
biMPM/base_layer.py,8,"b'import torch.nn as nn\nfrom torch.autograd import Variable\nimport torch\nimport time\nfrom torch.nn.functional import cosine_similarity\n\nfrom module_utils import *\n\nclass FullMatchLay(nn.Module):\n    def __init__(self, mp_dim, cont_dim):\n        super().__init__()\n        self.cont_dim = cont_dim\n        self.mp_dim = mp_dim\n\n        self.register_parameter(""weight"", nn.Parameter(torch.Tensor(mp_dim, cont_dim)))\n        self.weight.data.uniform_(-1., 1.)\n\n    def forward(self, cont_repres, other_cont_first):\n        """"""\n        Args:\n            cont_repres - [batch_size, this_len, context_lstm_dim]\n            other_cont_first - [batch_size, context_lstm_dim]\n        Return:\n            size - [batch_size, this_len, mp_dim]\n        """"""\n        def expand(context, weight):\n            """"""\n            Args:\n                [batch_size, this_len, context_lstm_dim]\n                [mp_dim, context_lstm_dim]\n            Return:\n                [batch_size, this_len, mp_dim, context_lstm_dim]\n            """"""\n            # [1, 1, mp_dim, context_lstm_dim]\n            weight = weight.unsqueeze(0)\n            weight = weight.unsqueeze(0)\n            # [batch_size, this_len, 1, context_lstm_dim]\n            context = context.unsqueeze(2)\n            return torch.mul(context, weight)\n\n        cont_repres = expand(cont_repres, self.weight)\n\n        other_cont_first = multi_perspective_expand_for_2D(other_cont_first, self.weight)\n        # [batch_size, 1, mp_dim, context_lstm_dim]\n        other_cont_first = other_cont_first.unsqueeze(1)\n        return cosine_similarity(cont_repres, other_cont_first, cont_repres.dim()-1)\n\nclass MaxpoolMatchLay(nn.Module):\n    def __init__(self, mp_dim, cont_dim):\n        super().__init__()\n        self.cont_dim = cont_dim\n        self.mp_dim = mp_dim\n\n        self.register_parameter(""weight"", nn.Parameter(torch.Tensor(mp_dim, cont_dim)))\n        self.weight.data.uniform_(-1., 1.)\n\n    def forward(self, cont_repres, other_cont_repres):\n        """"""\n        Args:\n            cont_repres - [batch_size, this_len, context_lstm_dim]\n            other_cont_repres - [batch_size, other_len, context_lstm_dim]\n        Return:\n            size - [bsz, this_len, mp_dim*2]\n        """"""\n        bsz = cont_repres.size(0)\n        this_len = cont_repres.size(1)\n        other_len = other_cont_repres.size(1)\n\n        cont_repres = cont_repres.view(-1, self.cont_dim)\n        other_cont_repres = other_cont_repres.view(-1, self.cont_dim)\n\n        cont_repres = multi_perspective_expand_for_2D(cont_repres, self.weight)\n        other_cont_repres = multi_perspective_expand_for_2D(other_cont_repres, self.weight)\n\n        cont_repres = cont_repres.view(bsz, this_len, self.mp_dim, self.cont_dim)\n        other_cont_repres = other_cont_repres.view(bsz, other_len, self.mp_dim, self.cont_dim)\n\n        # [bsz, this_len, 1, self.mp_dim, self.cont_dim]\n        cont_repres = cont_repres.unsqueeze(2)\n        # [bsz, 1, other_len, self.mp_dim, self.cont_dim]\n        other_cont_repres = other_cont_repres.unsqueeze(1)\n\n        # [bsz, this_len, other_len, self.mp_dim]fanruan\n        simi = cosine_similarity(cont_repres, other_cont_repres, cont_repres.dim()-1)\n\n        t_max, _ = simi.max(2)\n        t_mean = simi.mean(2)\n        return torch.cat((t_max, t_mean), 2)\n\nclass AtteMatchLay(nn.Module):\n    def __init__(self, mp_dim, cont_dim):\n        super(AtteMatchLay, self).__init__()\n        self.cont_dim = cont_dim\n        self.mp_dim = mp_dim\n\n        self.register_parameter(""weight"", nn.Parameter(torch.Tensor(mp_dim, cont_dim)))\n        self.weight.data.uniform_(-1., 1.)\n\n    def forward(self, repres, max_att):\n        """"""\n        Args:\n            repres - [bsz, a_len|q_len, cont_dim]\n            max_att - [bsz, q_len|a_len, cont_dim]\n        Return:\n            size - [bsz, sentence_len, mp_dim]\n        """"""\n        bsz = repres.size(0)\n        sent_len = repres.size(1)\n\n        repres = repres.view(-1, self.cont_dim)\n        max_att = max_att.view(-1, self.cont_dim)\n        repres = multi_perspective_expand_for_2D(repres, self.weight)\n        max_att = multi_perspective_expand_for_2D(max_att, self.weight)\n        temp = cosine_similarity(repres, max_att, repres.dim()-1)\n\n        return temp.view(bsz, sent_len, self.mp_dim)\n'"
biMPM/model.py,22,"b'import numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nfrom base_layer import *\nfrom module_utils import *\n\n# place filled defined\nPF_POS = 1\neps = 1e-12\n\nclass biMPModule(nn.Module):\n    """"""\n    Word Representation Layer\n        - Corpus Embedding(Word Embedding)\n        - Word Embedding(Character Embedding)\n    from biMPM TensorFlow, there is a layer called Highway which is a f**king lstmcell implement, do not know y?\n    Context Representation Layer\n    Matching Layer\n    Aggregation Layer\n    Prediction Layer\n    """"""\n    def __init__(self, args):\n        super().__init__()\n\n        # init argments\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        # context repres -> matching | W\n        self.context_dim = self.corpus_emb_dim + self.word_lstm_dim\n\n        # Word Representation Layer - Corpus Embedding(Word Embedding)\n        self.corpus_emb = nn.Embedding(self.corpora_len, self.corpus_emb_dim)\n        self._init_corpus_embedding()\n\n        # Word Representation Layer - Word Embedding(Character Embedding)\n        self.word_emb = nn.Embedding(self.words_len, self.word_emb_dim)\n        # self.word_lstm_cell = nn.LSTMCell(self.word_emb_dim, self.word_lstm_dim)\n        self.word_lstm = nn.LSTM(self.word_emb_dim,\n                                 self.word_lstm_dim,\n                                 num_layers=self.word_layer_num,\n                                 dropout=self.dropout,\n                                 batch_first=True)\n\n        # Context Representation Layer\n        self.context_lstm = nn.LSTM(self.context_dim,\n                                    self.context_lstm_dim,\n                                    num_layers=self.context_layer_num,\n                                    dropout=self.dropout,\n                                    batch_first=True,\n                                    bidirectional=True)\n\n        # Pre Attentive Matching\n        self.pre_q_attmath_layer = AtteMatchLay(self.mp_dim, self.context_dim)\n        self.pre_a_attmath_layer = AtteMatchLay(self.mp_dim, self.context_dim)\n\n        # Full Matching\n        self.f_full_layer = FullMatchLay(self.mp_dim, self.context_lstm_dim)\n        self.b_full_layer = FullMatchLay(self.mp_dim, self.context_lstm_dim)\n\n        # Maxpoll Matching\n        self.f_max_layer = MaxpoolMatchLay(self.mp_dim, self.context_lstm_dim)\n        self.b_max_layer = MaxpoolMatchLay(self.mp_dim, self.context_lstm_dim)\n\n        # Attentive Matching\n        self.f_att_layer = AtteMatchLay(self.mp_dim, self.context_lstm_dim)\n        self.b_att_layer = AtteMatchLay(self.mp_dim, self.context_lstm_dim)\n\n        # Max Attentive Matching\n        self.f_max_att_layer = AtteMatchLay(self.mp_dim, self.context_lstm_dim)\n        self.b_max_att_layer = AtteMatchLay(self.mp_dim, self.context_lstm_dim)\n\n        # Aggregation Layer\n        self.aggre_lstm = nn.LSTM(11*self.mp_dim+6,\n                                  self.aggregation_lstm_dim,\n                                  num_layers=self.aggregation_layer_num,\n                                  dropout=self.dropout,\n                                  batch_first=True,\n                                  bidirectional=True)\n        # Prediction Layer\n        self.l1 = nn.Linear(self.aggregation_lstm_dim*4,\n                            self.aggregation_lstm_dim*2)\n\n        self.l2 = nn.Linear(self.aggregation_lstm_dim*2,\n                            self.num_class)\n\n        self._init_weights_and_bias()\n\n    def forward(self, q_corpora, q_words, a_corpora, a_words):\n        """"""\n        Module main forward\n        """"""\n        # Step 1 - Get Mask from q_corpora and a_corpora\n        self.q_mask = q_corpora.ge(PF_POS)\n        self.a_mask = a_corpora.ge(PF_POS)\n\n        # Step 2 - Word Representation Layer\n        self.q_repres = self._word_repre_layer((q_corpora, q_words))\n        self.a_repres = self._word_repre_layer((a_corpora, a_words))\n\n        # Step 3 - Cosine Similarity and mask\n        iqr_temp = self.q_repres.unsqueeze(1) # [bsz, 1, q_len, context_dim]\n        ipr_temp = self.a_repres.unsqueeze(2) # [bsz, a_len, 1, context_dim]\n\n        # [bsz, a_len, q_len]\n        simi = F.cosine_similarity(iqr_temp, ipr_temp, dim=3)\n        simi_mask = self._cosine_similarity_mask(simi)\n\n        # Step 4 - Matching Layer\n        q_aware_reps, a_aware_reps = self._bilateral_match(simi_mask)\n        q_aware_reps = F.dropout(q_aware_reps, p=self.dropout)\n        a_aware_reps = F.dropout(a_aware_reps, p=self.dropout)\n\n        # Step 5 - Aggregation Layer\n        aggre = self._aggre(q_aware_reps, a_aware_reps)\n\n        # Step 6 - Prediction Layer\n        predict = F.tanh(self.l1(aggre))\n        predict = F.dropout(predict, p=self.dropout)\n        return F.softmax(self.l2(predict))\n\n    def _word_repre_layer(self, input):\n        """"""\n        args:\n            - input: (q_sentence, q_words)|(a_sentence, a_words)\n              q_sentence - [batch_size, sent_length]\n              q_words - [batch_size, sent_length, words_len]\n        return:\n            - output: [batch_size, sent_length, context_dim]\n        """"""\n        sentence, words = input\n        # [batch_size, sent_length, corpus_emb_dim]\n        s_encode = self.corpus_emb(sentence)\n\n        # [batch_size, sent_length, word_lstm_dim]\n        w_encode = self._word_repre_forward(words)\n        w_encode = F.dropout(w_encode, p=self.dropout, training=True, inplace=False)\n\n        out = torch.cat((s_encode, w_encode), 2)\n        return out\n\n    def _word_repre_forward(self, input):\n        """"""\n        args:\n            - input: q_words|a_words size: [batch_size, sent_length, words_len]\n                ps: q_words|a_words is matrix: corpus * words\n        return:\n            - output: [batch_size, sent_length, word_lstm_dim]\n        """"""\n        bsz = input.size(0)\n        sent_length = input.size(1)\n        words_len = input.size(2)\n        input = input.view(-1, words_len)\n\n        # [batch_size*sent_length, words_len, word_lstm_dim]\n        encode = self.word_emb(input)\n        _, hidden = self.word_lstm(encode)\n\n        # [batch_size, sent_length, word_lstm_dim]\n        output = hidden[0].view(bsz, sent_length, self.word_lstm_dim)\n        return output\n\n    def _cosine_similarity_mask(self, simi):\n        # [bsz, a_len, q_len]\n        simi = torch.mul(simi, self.q_mask.unsqueeze(1).float()).clamp(min=eps)\n        simi = torch.mul(simi, self.a_mask.unsqueeze(2).float()).clamp(min=eps)\n        return simi\n\n    def _bilateral_match(self, cos_simi):\n        """"""\n        Args:\n            cos_simi: [bsz, a_len, q_len]\n        Return:\n            q_aware_reps: [bsz, q_len, mp_dim*11+6]\n            a_aware_reps: [bsz, a_len, mp_dim*11+6]\n        """"""\n        # size: [bsz, q_len, a_len]\n        cos_simi_q = cos_simi.permute(0, 2, 1)\n\n        # [bsz, a_len, 1]\n        q_aware_reps = [torch.max(cos_simi, 2, keepdim=True)[0],\n                        torch.mean(cos_simi, 2, keepdim=True)]\n        # [bsz, q_len, 1]\n        a_aware_reps = [torch.max(cos_simi_q, 2, keepdim=True)[0],\n                        torch.mean(cos_simi_q, 2, keepdim=True)]\n\n        # Max Attentive Matching\n        q_max_att = max_repres((self.q_repres, cos_simi))\n        q_max_att_rep = self.pre_q_attmath_layer(self.a_repres, q_max_att)\n        q_aware_reps.append(q_max_att_rep)\n\n        a_max_att = max_repres((self.a_repres, cos_simi_q))\n        a_max_att_rep = self.pre_a_attmath_layer(self.q_repres, a_max_att)\n        a_aware_reps.append(a_max_att_rep)\n\n        # Context MP Matching\n        # range 1 - bilstm\n        q_repr_context_f, q_repr_context_b = self._context_repre_forward(self.q_repres)\n        a_repr_context_f, a_repr_context_b = self._context_repre_forward(self.a_repres)\n\n        # range 2 - all match layers\n        left_match = self._all_match_layer(a_repr_context_f,\n                                           a_repr_context_b,\n                                           self.a_mask,\n                                           q_repr_context_f,\n                                           q_repr_context_b,\n                                           self.q_mask)\n        right_match = self._all_match_layer(q_repr_context_f,\n                                            q_repr_context_b,\n                                            self.q_mask,\n                                            a_repr_context_f,\n                                            a_repr_context_b,\n                                            self.a_mask)\n\n        q_aware_reps.extend(left_match)\n        a_aware_reps.extend(right_match)\n        q_aware_reps = torch.cat(q_aware_reps, dim=2)\n        a_aware_reps = torch.cat(a_aware_reps, dim=2)\n\n        return q_aware_reps, a_aware_reps\n\n    def _context_repre_forward(self, input):\n        """"""\n        Args:\n            - input: [bsz, sent_length, context_dim]]\n        Return:\n            - output: size - ([bsz, sent_length, context_lstm_dim], [bsz, sent_length, context_lstm_dim])\n        """"""\n        output, _ = self.context_lstm(input)\n        return output.split(self.context_lstm_dim, 2)\n\n    def _aggre(self, q_aware_reps, a_aware_reps):\n        """"""\n        Aggregation Layer handle\n        Args:\n            q_aware_reps - [batch_size, question_len, 11*mp_dim+6]\n            a_aware_reps - [batch_size, answer_len, 11*mp_dim+6]\n        Return:\n            size - [batch_size, aggregation_lstm_dim*4]\n        """"""\n        _aggres = []\n        _, (q_hidden, _) = self.aggre_lstm(q_aware_reps)\n        _, (a_hidden, _) = self.aggre_lstm(a_aware_reps)\n\n        # [batch_size, aggregation_lstm_dim]\n        _aggres.append(q_hidden[-2])\n        _aggres.append(q_hidden[-1])\n        _aggres.append(a_hidden[-2])\n        _aggres.append(a_hidden[-1])\n        return torch.cat(_aggres, dim=1)\n\n    def _all_match_layer(self, repr_context_f, repr_context_b, mask,\n                        other_repr_context_f, other_repr_context_b, other_mask):\n        """"""\n        Args:\n            repr_context_f, repr_context_b|other_repr_context_f, other_repr_context_b - size: [bsz, this_len, context_lstm_dim], [bsz, other_len, context_lstm_dim]\n            mask|other_mask - size: [bsz, this_len]|[bsz, other_len]\n        Return:\n            List - size: [bsz, sentence_len, mp_dim] * 10*mp_dim+4\n        """"""\n        # pre sth before\n        repr_context_f = repr_context_f.contiguous()\n        repr_context_b = repr_context_b.contiguous()\n        other_repr_context_f = other_repr_context_f.contiguous()\n        other_repr_context_b = other_repr_context_b.contiguous()\n\n        all_aware_repres = []\n        this_cont_dim = repr_context_f.dim() # 3\n\n        repr_context_f = torch.mul(repr_context_f, mask.unsqueeze(this_cont_dim-1).float()).clamp(min=eps)\n        repr_context_b = torch.mul(repr_context_b, mask.unsqueeze(this_cont_dim-1).float()).clamp(min=eps)\n        other_repr_context_f = torch.mul(other_repr_context_f, other_mask.unsqueeze(this_cont_dim-1).float()).clamp(min=eps)\n        other_repr_context_b = torch.mul(other_repr_context_b, other_mask.unsqueeze(this_cont_dim-1).float()).clamp(min=eps)\n\n        # [bsz, this_len, other_len]\n        f_relevancy = F.cosine_similarity(other_repr_context_f.unsqueeze(1), repr_context_f.unsqueeze(2), dim=this_cont_dim)\n        f_relevancy = torch.mul(f_relevancy, mask.unsqueeze(this_cont_dim-1).float()).clamp(min=eps)\n        f_relevancy = torch.mul(f_relevancy, other_mask.unsqueeze(this_cont_dim-2).float()).clamp(min=eps)\n\n        # [bsz, this_len, other_len]\n        b_relevancy = F.cosine_similarity(other_repr_context_b.unsqueeze(1), repr_context_b.unsqueeze(2), dim=this_cont_dim)\n        b_relevancy = torch.mul(b_relevancy, mask.unsqueeze(this_cont_dim-1).float()).clamp(min=eps)\n        b_relevancy = torch.mul(b_relevancy, other_mask.unsqueeze(this_cont_dim-2).float()).clamp(min=eps)\n\n        # first match - Full Match\n        # gather the last time step of the forward|backward repres from the other sentences\n        other_context_f_first = other_repr_context_f[:, -1, :]\n        other_context_b_first = other_repr_context_b[:, 0, :]\n\n        f_full_match = self.f_full_layer(repr_context_f, other_context_f_first)\n        b_full_match = self.b_full_layer(repr_context_b, other_context_b_first)\n        all_aware_repres.append(f_full_match)\n        all_aware_repres.append(b_full_match)\n\n        # second match - Maxpool Match\n        f_max_match = self.f_max_layer(repr_context_f, other_repr_context_f)\n        b_max_match = self.b_max_layer(repr_context_b, other_repr_context_b)\n        all_aware_repres.append(f_max_match)\n        all_aware_repres.append(b_max_match)\n\n        # third match - Attentive Match\n        f_att_cont = cosine_cont(other_repr_context_f, f_relevancy)\n        f_att_repre = self.f_att_layer(repr_context_f, f_att_cont)\n        b_att_cont = cosine_cont(other_repr_context_b, b_relevancy)\n        b_att_repre = self.b_att_layer(repr_context_b, b_att_cont)\n        all_aware_repres.append(f_att_repre)\n        all_aware_repres.append(b_att_repre)\n\n        # fourth match - Max Attentive Match\n        f_max_att = max_repres((other_repr_context_f, f_relevancy))\n        f_max_att_repres = self.f_max_att_layer(repr_context_f, f_max_att)\n        b_max_att = max_repres((other_repr_context_b, b_relevancy))\n        b_max_att_repres = self.b_max_att_layer(repr_context_b, b_max_att)\n        all_aware_repres.append(f_max_att_repres)\n        all_aware_repres.append(b_max_att_repres)\n\n        # fifth - max & mean\n        all_aware_repres.append(f_relevancy.max(2, keepdim=True)[0])\n        all_aware_repres.append(f_relevancy.mean(2, keepdim=True))\n        all_aware_repres.append(b_relevancy.max(2, keepdim=True)[0])\n        all_aware_repres.append(b_relevancy.mean(2, keepdim=True))\n\n        return all_aware_repres\n\n    def _init_weights_and_bias(self, scope=1.):\n        """"""\n        initialise weight and bias\n        """"""\n        self.word_emb.weight.data.uniform_(-scope, scope)\n        self.l1.weight.data.uniform_(-scope, scope)\n        self.l1.bias.data.fill_(0)\n        self.l2.weight.data.uniform_(-scope, scope)\n        self.l2.bias.data.fill_(0)\n\n    def _init_corpus_embedding(self):\n        """"""\n        corpus embedding is a fixed vector for each individual corpus,\n        which is pre-trained with word2vec\n        """"""\n        self.corpus_emb.weight.data.copy_(torch.from_numpy(self.corpora_emb))\n        # frozen embedding parameters\n        self.corpus_emb.weight.requires_grad = False\n'"
biMPM/module_utils.py,3,"b'import torch\n\ndef multi_perspective_expand_for_2D(in_tensor, decompose_params):\n    """"""\n    Return: [batch_size, decompse_dim, dim]\n    """"""\n    in_tensor = in_tensor.unsqueeze(1) #[batch_size, \'x\', dim]\n    decompose_params = decompose_params.unsqueeze(0) # [1, decompse_dim, dim]\n    return torch.mul(in_tensor, decompose_params)\n\ndef max_repres(repre_cos):\n    """"""\n    Args:\n        repre_cos - (q_repres, cos_simi_q)|(a_repres, cos_simi)\n        Size: ([bsz, q_len, context_dim], [bsz, a_len, question_len])| ...\n    Return:\n        size - [bsz, a_len, context_dim] if question else [bsz, q_len, context_dim]\n    """"""\n    def tf_gather(input, index):\n        """"""\n        The same as tensorflow gather sometimes...\n        Args:\n            - input: dim - 3\n            - index: dim - 2\n        Return: [input.size(0), index.size(1), input.size(2)]\n        """"""\n        bsz = input.size(0)\n        sent_size = input.size(1)\n        dim_size = input.size(2)\n        for n, i in enumerate(index):\n            index.data[n] = i.data.add(n*sent_size)\n\n        input = input.view(-1, dim_size)\n        index = index.view(-1)\n\n        temp = input.index_select(0 ,index)\n        return temp.view(bsz, -1, dim_size)\n\n    repres, cos_simi = repre_cos\n    index = torch.max(cos_simi, 2)[1] # max_index\n    return tf_gather(repres, index)\n\ndef cosine_cont(repr_context, relevancy, norm=False):\n    """"""\n    cosine siminlarity betwen context and relevancy\n    Args:\n        repr_context - [batch_size, other_len, context_lstm_dim]\n        relevancy - [batch_size, this_len, other_len]\n    Return:\n        size - [batch_size, this_len, context_lstm_dim]\n    """"""\n    dim = repr_context.dim()\n\n    temp_relevancy = relevancy.unsqueeze(dim) # [batch_size, this_len, other_len, 1]\n    buff = repr_context.unsqueeze(1) # [batch_size, 1, other_len, context_lstm_dim]\n    buff = torch.mul(buff, temp_relevancy) # [batch_size, this_len, other_len, context_lstm_dim]\n    buff = buff.sum(2) # [batch_size, this_len, context_lstm_dim]\n    if norm:\n        relevancy = relevancy.sum(dim-1).clamp(min=1e-6) # [batch_size, this_len]\n        relevancy = relevancy.unsqueeze(2) # [batch_size, this_len, 1]\n        buff = buff.div(relevancy)\n    return buff\n\nif __name__ == ""__main__"":\n    temp = np.zeros((1, 1))\n    print(isinstance(temp, np.ndarray))\n'"
capsule-classfication/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    UNK: '<unk>',\n    PAD: '<pad>'\n}\n\n"""
capsule-classfication/corpus.py,1,"b'import torch\n\nimport argparse\nimport os\n\nfrom const import *\n\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\n\nclass Dictionary(object):\n    def __init__(self, word2idx={}, idx_num=0):\n        self.word2idx = word2idx\n        self.idx = idx_num\n\n    def _add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def _convert(self):\n        self.idx2word = {v: k for k, v in self.word2idx.items()}\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Words(Dictionary):\n    def __init__(self):\n        word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        super().__init__(word2idx=word2idx, idx_num=len(word2idx))\n\n    def __call__(self, sents):\n        words = set([word for sent in sents for word in sent])\n        for word in words:\n            self._add(word)\n\n\nclass Labels(Dictionary):\n    def __init__(self):\n        super().__init__()\n\n    def __call__(self, labels):\n        _labels = set(labels)\n        for label in _labels:\n            self._add(label)\n\n\nclass Corpus(object):\n    def __init__(self, path, save_data, max_len=16):\n        self.train = os.path.join(path, ""train"")\n        self.valid = os.path.join(path, ""valid"")\n        self._save_data = save_data\n\n        self.w = Words()\n        self.l = Labels()\n        self.max_len = max_len\n\n    def parse_data(self, _file, is_train=True, fine_grained=False):\n        """"""\n        fine_grained: Whether to use the fine-grained (50-class) version of TREC\n                or the coarse grained (6-class) version.\n        """"""\n        _sents, _labels = [], []\n        for sentence in open(_file):\n            label, _, _words = sentence.replace(\'\\xf0\', \' \').partition(\' \')\n            label = label.split("":"")[0] if not fine_grained else label\n\n            words = _words.strip().split()\n\n            if len(words) > self.max_len:\n                words = words[:self.max_len]\n\n            _sents += [words]\n            _labels += [label]\n        if is_train:\n            self.w(_sents)\n            self.l(_labels)\n            self.train_sents = _sents\n            self.train_labels = _labels\n        else:\n            self.valid_sents = _sents\n            self.valid_labels = _labels\n\n    def save(self):\n        self.parse_data(self.train)\n        self.parse_data(self.valid, False)\n\n        data = {\n            \'max_len\': self.max_len,\n            \'dict\': {\n                \'train\': self.w.word2idx,\n                \'vocab_size\': len(self.w),\n                \'label\': self.l.word2idx,\n                \'label_size\': len(self.l),\n            },\n            \'train\': {\n                \'src\': word2idx(self.train_sents, self.w.word2idx),\n                \'label\': [self.l.word2idx[l] for l in self.train_labels]\n            },\n            \'valid\': {\n                \'src\': word2idx(self.valid_sents, self.w.word2idx),\n                \'label\': [self.l.word2idx[l] for l in self.valid_labels]\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'Finish dumping the data to file - [{}]\'.format(self._save_data))\n        print(\'words length - [{}]\'.format(len(self.w)))\n        print(\'label size - [{}]\'.format(len(self.l)))\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'CNN Classification\')\n    parser.add_argument(\'--file-path\', type=str, default=""./data"",\n                        help=\'file path\')\n    parser.add_argument(\'--save-data\', type=str, default=""./data/corpus.pt"",\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--max-lenth\', type=int, default=16,\n                        help=\'max length left of sentence [default: 28]\')\n    args = parser.parse_args()\n    corpus = Corpus(args.file_path, args.save_data, args.max_lenth)\n    corpus.save()\n'"
capsule-classfication/data_loader.py,3,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\n\nclass DataLoader(object):\n    def __init__(self, src_sents, label, max_len, cuda=True,\n                 batch_size=64, shuffle=True, evaluation=False):\n        self.cuda = cuda\n        self.sents_size = len(src_sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size + 1\n        self.evaluation = evaluation\n\n        self._batch_size = batch_size\n        self._max_len = max_len\n        self._src_sents = np.asarray(src_sents)\n        self._label = np.asarray(label)\n        if shuffle:\n            self._shuffle()\n\n    def _shuffle(self):\n        indices = np.arange(self._src_sents.shape[0])\n        np.random.shuffle(indices)\n        self._src_sents = self._src_sents[indices]\n        self._label = self._label[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def pad_to_longest(insts, max_len):\n            inst_data = np.array(\n                [inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n\n            inst_data_tensor = Variable(torch.from_numpy(\n                inst_data), volatile=self.evaluation)\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step * self._batch_size\n        _bsz = min(self._batch_size, self.sents_size - _start)\n        self._step += 1\n        data = pad_to_longest(\n            self._src_sents[_start:_start + _bsz], self._max_len)\n        label = Variable(torch.from_numpy(self._label[_start:_start + _bsz]),\n                         volatile=self.evaluation)\n        if self.cuda:\n            label = label.cuda()\n\n        return data, label\n'"
capsule-classfication/main.py,6,"b'import argparse\nimport time\n\nimport torch\n\nparser = argparse.ArgumentParser(description=\'Capsule classification\')\nparser.add_argument(\'--lr\', type=float, default=0.0005)\nparser.add_argument(\'--epochs\', type=int, default=100)\nparser.add_argument(\'--batch_size\', type=int, default=16)\nparser.add_argument(\'--seed\', type=int, default=1111)\nparser.add_argument(\'--no_cuda\', action=\'store_true\')\n\nparser.add_argument(\'--save\', type=str, default=\'./capsule.pt\')\nparser.add_argument(\'--data\', type=str, default=\'./data/corpus.pt\')\n\nparser.add_argument(\'--dropout\', type=float, default=0.5)\nparser.add_argument(\'--embed_dim\', type=int, default=64)\nparser.add_argument(\'--hsz\', type=int, default=64)\nparser.add_argument(\'--layers\', type=int, default=2)\nparser.add_argument(\'--num_primary_units\', type=int, default=8)\nparser.add_argument(\'--output_unit_size\', type=int, default=16)\nparser.add_argument(\'--primary_unit_size\', type=int, default=1152)\nparser.add_argument(\'--iterations\', type=int, default=3)\n\n\nargs = parser.parse_args()\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available() and not args.no_cuda\n\n# ##############################################################################\n# Load data\n################################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_len = data[""max_len""]\nargs.vsz = data[\'dict\'][\'vocab_size\']\nargs.labels = data[\'dict\'][\'label_size\']\nargs.use_cuda = use_cuda\n\ntraining_data = DataLoader(\n    data[\'train\'][\'src\'],\n    data[\'train\'][\'label\'],\n    args.max_len,\n    batch_size=args.batch_size,\n    cuda=use_cuda)\n\nvalidation_data = DataLoader(\n    data[\'valid\'][\'src\'],\n    data[\'valid\'][\'label\'],\n    args.max_len,\n    batch_size=args.batch_size,\n    shuffle=False,\n    cuda=use_cuda,\n    evaluation=True)\n\n# ##############################################################################\n# Model\n# ##############################################################################\nimport model\n\ncapsule = model.Capsule(args)\nif use_cuda:\n    capsule = capsule.cuda()\n\noptimizer = torch.optim.Adam(capsule.parameters(), lr=args.lr)\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\n\n\ndef evaluate():\n    capsule.eval()\n    corrects = eval_loss = 0\n    _size = validation_data.sents_size\n    for data, label in tqdm(validation_data, mininterval=0.2,\n                            desc=\'Evaluate Processing\', leave=False):\n        props, lstm_feats = capsule(data)\n        loss = capsule.loss(props, label, lstm_feats)\n\n        eval_loss += loss.data[0]\n        corrects += (torch.sqrt((props**2).sum(dim=2)).max(1)\n                     [1].view(label.size()).data == label.data).sum()\n\n    return eval_loss / _size, corrects, corrects / _size * 100.0, _size\n\n\ndef train():\n    capsule.train()\n    total_loss = 0\n    for data, label in tqdm(training_data, mininterval=1,\n                            desc=\'Train Processing\', leave=False):\n        optimizer.zero_grad()\n\n        props, lstm_feats = capsule(data)\n        loss = capsule.loss(props, label, lstm_feats)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.data\n    return total_loss[0] / training_data.sents_size * args.batch_size\n\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs + 1):\n        epoch_start_time = time.time()\n        loss = train()\n\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(\n            epoch, time.time() - epoch_start_time, loss))\n\n        loss, corrects, acc, size = evaluate()\n\n        epoch_start_time = time.time()\n        print(\'-\' * 90)\n        print(\'| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(\n            epoch, time.time() - epoch_start_time, loss, acc, corrects, size))\n        print(\'-\' * 90)\n        if not best_acc or best_acc < corrects:\n            best_acc = corrects\n            model_state_dict = capsule.state_dict()\n            model_source = {\n                ""settings"": args,\n                ""model"": model_state_dict,\n                ""src_dict"": data[\'dict\'][\'train\']\n            }\n            torch.save(model_source, args.save)\nexcept KeyboardInterrupt:\n    print(""-"" * 90)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format(\n        (time.time() - total_start_time) / 60.0))\n'"
capsule-classfication/model.py,23,"b'import math\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.nn import init\nimport torch.nn.functional as F\n\nimport const\n\n\ndef squash(input):\n    mag_sq = torch.sum(input**2, dim=2, keepdim=True)\n    mag = torch.sqrt(mag_sq)\n    out = (mag_sq / (1.0 + mag_sq)) * (input / mag)\n    return out\n\n\ndef to_one_hot(x, length, use_cuda, is_zero=True):\n    bsz, x_list = x.size(0), x.data.tolist()\n    x_one_hot = torch.zeros(bsz, length)\n    if is_zero:\n        for i in range(bsz):\n            x_one_hot[i, x_list[i]] = 1.\n    else:\n        x_one_hot = x_one_hot + .1\n        for i in range(bsz):\n            x_one_hot[i, x_list[i]] = -1.\n\n    x_one_hot = Variable(x_one_hot)\n    if use_cuda:\n        x_one_hot = x_one_hot.cuda()\n\n    return x_one_hot\n\n\nclass BiRNN(nn.Module):\n    def __init__(self, vsz, embed_dim, dropout, hsz, layers):\n        super().__init__()\n\n        self.lookup_table = nn.Embedding(vsz, embed_dim, padding_idx=const.PAD)\n        self.lstm = nn.LSTM(embed_dim, hsz, layers,\n                            dropout=dropout,\n                            batch_first=True,\n                            bidirectional=True)\n\n        scope = 1. / math.sqrt(vsz)\n        self.lookup_table.weight.data.uniform_(-scope, scope)\n\n    def forward(self, input):\n        encode = self.lookup_table(input)\n        lstm_out, _ = self.lstm(encode)\n        feats = lstm_out.mean(1)\n\n        return lstm_out, feats\n\n\nclass ConvUnit(nn.Module):\n    def __init__(self):\n        super(ConvUnit, self).__init__()\n\n        self.conv = nn.Conv2d(in_channels=256,\n                              out_channels=32,\n                              kernel_size=5,\n                              stride=1)\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass PrimaryCap(nn.Module):\n    def __init__(self, num_primary_units):\n        super().__init__()\n\n        self.num_primary_units = num_primary_units\n        self.convUnits = nn.ModuleList(\n            [ConvUnit() for _ in range(num_primary_units)])\n\n    def forward(self, input):\n        bsz = input.size(0)\n        # num_primary_units * (b*32*6*6)\n        units = [unit(input) for unit in self.convUnits]\n        units = torch.stack(units, dim=1)  # b*num_primary_units*32*6*6\n        units = units.view(bsz, self.num_primary_units, -1)\n\n        return squash(units)  # b*num_primary_units*(32*6*6)\n\n\nclass DigitCap(nn.Module):\n    def __init__(self,\n                 use_cuda,\n                 num_primary_units,\n                 labels,\n                 output_unit_size,\n                 primary_unit_size,\n                 iterations):\n        super().__init__()\n\n        self.labels = labels\n        self.use_cuda = use_cuda\n        self.primary_unit_size = primary_unit_size\n        self.iterations = iterations\n\n        self.W = nn.Parameter(torch.randn(1,\n                                          primary_unit_size,\n                                          labels,\n                                          output_unit_size,\n                                          num_primary_units))\n\n    def forward(self, input):\n        bsz = input.size(0)\n        input_t = input.transpose(1, 2)  # b*f*num_primary_units\n        # b*f*l*num_primary_units*1\n        u = torch.stack([input_t] * self.labels, dim=2).unsqueeze(4)\n        # b*f*l*output_unit_size*num_primary_units\n        W = torch.cat([self.W] * bsz, dim=0)\n        # b*f*l*output_unit_size*1\n        u_hat = torch.matmul(W, u)\n\n        b_ij = Variable(torch.zeros(1, self.primary_unit_size, self.labels, 1))\n        if self.use_cuda:\n            b_ij = b_ij.cuda()\n\n        for _ in range(self.iterations):\n            c_ij = F.softmax(b_ij, dim=-1)\n            c_ij = torch.cat([c_ij] * bsz, dim=0).unsqueeze(4)\n            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n            v_j = squash(s_j)  # b*1*l*output_unit_size*1\n\n            v_j1 = torch.cat([v_j] * self.primary_unit_size, dim=1)\n            u_vj1 = torch.matmul(u_hat.transpose(3, 4), v_j1).squeeze(\n                4).mean(dim=0, keepdim=True)\n            b_ij = b_ij + u_vj1\n\n        return v_j.squeeze()  # b*l*output_unit_size\n\n\nclass Capsule(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.rnn = BiRNN(self.vsz,\n                         self.embed_dim,\n                         self.dropout,\n                         self.hsz,\n                         self.layers)\n        self.fc = nn.Linear(self.hsz * 2, self.max_len)\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, 256, kernel_size=7),\n            nn.ReLU(inplace=True)\n        )\n        self.pCap = PrimaryCap(self.num_primary_units)\n        self.dCap = DigitCap(self.use_cuda,\n                             self.num_primary_units,\n                             self.labels,\n                             self.output_unit_size,\n                             self.primary_unit_size,\n                             self.iterations)\n        self.recon = nn.Sequential(\n            nn.Linear(self.output_unit_size, self.hsz),\n            nn.ReLU(inplace=True),\n            nn.Linear(self.hsz, self.hsz * 2),\n        )\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        scope = 1. / math.sqrt(self.vsz)\n\n        for m in self.modules():\n            if type(m) == nn.Linear:\n                m.weight.data.uniform_(-scope, scope)\n\n    def forward(self, input):\n        lstm_out, lstm_feats = self.rnn(input)\n\n        in_capsule = self.fc(lstm_out)\n        in_capsule = in_capsule.unsqueeze(1)  # b*1*28*28\n\n        conv1_out = self.conv1(in_capsule)\n        pCap_out = self.pCap(conv1_out)\n        dCap_out = self.dCap(pCap_out)\n\n        return dCap_out, lstm_feats\n\n    def loss(self, props, target, lstm_feats):\n        zero_t = to_one_hot(target, self.labels, self.use_cuda)\n        unzero_t = to_one_hot(target, self.labels, self.use_cuda, False)\n\n        return self.margin_loss(props, zero_t) + self.reconstruction_loss(lstm_feats, props, unzero_t) * 0.05\n        # return self.margin_loss(props, zero_t)\n\n    def margin_loss(self, props, target):\n        bsz = props.size(0)\n        v_abs = torch.sqrt((props**2).sum(dim=2, keepdim=True))\n        zero = Variable(torch.zeros(1))\n        if self.use_cuda:\n            zero = zero.cuda()\n\n        m_plus, m_minus = .9, .1\n        max_pos = torch.max(zero, m_plus - v_abs).view(bsz, -1)**2\n        max_neg = torch.max(zero, v_abs - m_minus).view(bsz, -1)**2\n\n        loss = target * max_pos + .5 * (1. - target) * max_neg\n\n        return loss.mean()\n\n    def reconstruction_loss(self, lstm_feats, props, target):\n        bsz, target = props.size(0), target.unsqueeze(2)\n        v = torch.sqrt((props**2).sum(dim=2, keepdim=True))\n        zero = Variable(torch.zeros(1))\n        if self.use_cuda:\n            zero = zero.cuda()\n\n        r = self.recon(props)  # b*l*(hsz*2)\n        lstm_feats = lstm_feats.unsqueeze(1)  # b*1*(hsz*2)\n\n        _temp = (r * target * v * lstm_feats).sum(2, keepdim=True)\n        loss = torch.max(zero, 1. + _temp)\n\n        return loss.mean()\n'"
cbow/main.py,6,"b'import torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.autograd as autograd\n\nCONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\nEMBEDDING_DIM = 64\nraw_text = """"""We are about to study the idea of a computational process.\nComputational processes are abstract beings that inhabit computers.\nAs they evolve, processes manipulate other abstract things called data.\nThe evolution of a process is directed by a pattern of rules\ncalled a program. People create programs to direct processes. In effect,\nwe conjure the spirits of the computer with our spells."""""".split()\n\nvocab = set(raw_text)\nvocab_size = len(vocab)\n\nword_to_ix = {word: i for i, word in enumerate(vocab)}\ndata = []\nfor i in range(2, len(raw_text) - 2):\n    context = [raw_text[i - 2], raw_text[i - 1],\n               raw_text[i + 1], raw_text[i + 2]]\n    target = raw_text[i]\n    data.append((context, target))\n\nclass CBOW(nn.Module):\n    def __init__(self, vocab_size, ebd_size, cont_size):\n        super(CBOW, self).__init__()\n\n        self.ebd = nn.Embedding(vocab_size, ebd_size)\n        self.lr1 = nn.Linear(ebd_size*cont_size*2, 128)\n        self.lr2 = nn.Linear(128, vocab_size)\n\n        self._init_weight()\n\n    def forward(self, inputs):\n        out = self.ebd(inputs).view(1, -1)\n        out = F.relu(self.lr1(out))\n        out = self.lr2(out)\n        out = F.log_softmax(out)\n        return out\n\n    def _init_weight(self, scope=0.1):\n        self.ebd.weight.data.uniform_(-scope, scope)\n        self.lr1.weight.data.uniform_(0, scope)\n        self.lr1.bias.data.fill_(0)\n        self.lr2.weight.data.uniform_(0, scope)\n        self.lr2.bias.data.fill_(0)\n\ndef make_context_vector(context, word_to_ix):\n    idxs = [word_to_ix[w] for w in context]\n    tensor = torch.LongTensor(idxs)\n    return autograd.Variable(tensor)\n\nloss_function = nn.NLLLoss()\nmodel = CBOW(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(1, 41):\n    total_loss = 0.0\n    for context, target in data:\n        v_ctx = make_context_vector(context, word_to_ix)\n        v_tar = autograd.Variable(torch.LongTensor([word_to_ix[target]]))\n        model.zero_grad()\n        out = model(v_ctx)\n        loss = loss_function(out, v_tar)\n        total_loss += loss.data\n        loss.backward()\n        optimizer.step()\n    print(""end of epoch {} | loss {:2.3f}"".format(epoch, total_loss[0]))\n'"
ch-poetry-nlg/const.py,0,"b""SPACE = 0\nUNK = 1\n\nWORD = {\n    SPACE: ' ',\n    UNK: '<unk>'\n}\n\n\n"""
ch-poetry-nlg/corpus.py,1,"b'import torch\n\nfrom const import *\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[UNK]: UNK\n        }\n        self.idx = len(self.word2idx)\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, sents, min_count):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words: word_count[w]+=1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\nclass Corpus(object):\n    def __init__(self, save_data, max_len=20, min_word_count=0):\n        self._save_data = save_data\n        self._max_len = max_len\n        self._min_word_count = min_word_count\n        self.sents = None\n        self.valid_sents = None\n        self.dict = Dictionary()\n        self.is_ch = lambda w: (w >= \'\\u4e00\' and w<=\'\\u9fa5\') or w == "" ""\n\n    def parse(self):\n        sents, ignore_count = [], 0\n        for sentences in open(""data/poetry""):\n            sentences = sentences.strip()\n            words = [w for w in sentences if self.is_ch(w)]\n            if len(words) != self._max_len:\n                ignore_count += 1\n                continue\n\n            sents.append(words)\n\n        print(""Data`s length not eq {} - [{}]"".format(self._max_len, ignore_count))\n        print(""Data`s length eq {} - [{}]"".format(self._max_len, len(sents)))\n\n        word_ignore = self.dict(sents, self._min_word_count)\n\n        if word_ignore != 0:\n            print(""Ignored word counts - [{}]"".format(word_ignore))\n\n        self.sents = sents\n\n    def save(self):\n        data = {\n            \'max_word_len\': self._max_len,\n            \'dict\': {\n                \'src\': self.dict.word2idx,\n                \'src_size\': len(self.dict),\n            },\n            \'train\': word2idx(self.sents, self.dict.word2idx)\n        }\n\n        torch.save(data, self._save_data)\n        print(\'word length - [{}]\'.format(len(self.dict)))\n\n    def process(self):\n        self.parse()\n        self.save()\n\nif __name__ == ""__main__"":\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\'Chinese Poetry NLG\')\n    parser.add_argument(\'--save-data\', type=str, default=\'data/ch_pro_nlg.pt\',\n                        help=\'path to save processed data\')\n    args = parser.parse_args()\n    corpus = Corpus(args.save_data)\n    corpus.process()\n'"
ch-poetry-nlg/data_loader.py,3,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\nclass DataLoader(object):\n    def __init__(self, src_sents, max_len, batch_size, cuda=True):\n        self.cuda = cuda\n        self.sents_size = len(src_sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size\n\n        self._batch_size = batch_size\n        self._max_len = max_len\n\n        self.gen_data(src_sents)\n\n    def gen_data(self, src_sents):\n        src_sents = np.asarray(src_sents)\n        self._src_sents = src_sents[:, :-1]\n        self._label = src_sents[:, 1:]\n\n    def _shuffle(self):\n        indices = np.arange(self._src_sents.shape[0])\n        np.random.shuffle(indices)\n        self._src_sents = self._src_sents[indices]\n        self._label = self._label[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def to_longest(insts):\n            inst_data_tensor = Variable(torch.from_numpy(insts))\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step*self._batch_size\n        _bsz = self._batch_size\n        self._step += 1\n        data = to_longest(self._src_sents[_start: _start+_bsz])\n        label = to_longest(self._label[_start: _start+_bsz])\n        return data, label.contiguous().view(-1)\n\nif __name__ == ""__main__"":\n    data = torch.load(""data/ch_pro_nlg.pt"")\n    _data = DataLoader(\n                     data[\'train\'],\n                     data[""max_word_len""],\n                     64)\n    d = {v: k for k, v in data[\'dict\'][\'src\'].items()}\n\n    print([d[w] for s in _data._src_sents for w in s])\n    print([d[w] for s in _data._label for w in s])\n\n'"
ch-poetry-nlg/generate.py,4,"b'import torch\nfrom torch.autograd import Variable\n\nfrom model import Model\n\nclass Generate:\n    def __init__(self, model=None, model_source=None, src_dict=None, args=None):\n        assert model is not None or model_source is not None\n\n        if model is None:\n            model_source = torch.load(model_source, map_location=lambda storage, loc: storage)\n            self.dict = model_source[""src_dict""]\n            self.args = model_source[""settings""]\n            model = Model(self.args)\n            model.load_state_dict(model_source[\'model\'])\n        else:\n            self.dict = src_dict\n            self.args = args\n\n        self.num_directions = 2 if self.args.bidirectional else 1\n        self.idx2word = {v: k for k, v in self.dict.items()}\n        self.model = model.eval()\n\n    def Create(self, max_len):\n        args = self.args\n\n        num_layers = args.lstm_layers*self.num_directions\n        hidden = self.model.init_hidden(1)\n\n        # random sample\n        prob = torch.rand(1).mul(args.vocab_size).long()\n        input = Variable(prob.unsqueeze(1), volatile=True)\n        portry = self.idx2word[prob.tolist()[0]]\n\n        count = 1\n        for _ in range(1, max_len):\n            output, hidden = self.model(input, hidden)\n            prob = output.squeeze().data\n            next_word = torch.max(prob, -1)[1].tolist()[0]\n            input.data.fill_(next_word)\n            if count == 4:\n                portry += self.idx2word[next_word]\n                portry += ""\xef\xbc\x8c""\n                count = 0\n            else:\n                portry += self.idx2word[next_word]\n                count += 1\n        portry = portry[:-1] + ""\xe3\x80\x82""\n        return portry\n\nif __name__ == ""__main__"":\n    G = Generate(model_source=""ch_poe.pt"")\n    print(G.Create(20))\n'"
ch-poetry-nlg/model.py,4,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.nn import init\n\nfrom const import *\n\nclass Model(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.num_directions = 2 if self.bidirectional else 1\n        self.lookup_table = nn.Embedding(self.vocab_size, self.embed_dim)\n        self.lstm = nn.LSTM(self.embed_dim,\n                    self.hidden_size,\n                    self.lstm_layers,\n                    batch_first=True,\n                    dropout=self.dropout,\n                    bidirectional=self.bidirectional)\n        self.lr = nn.Linear(self.hidden_size*self.num_directions,\n                        self.vocab_size)\n\n        self._init_weights()\n\n    def _init_weights(self, scope=.1):\n        self.lookup_table.weight.data.uniform_(-scope, scope)\n        self.lr.weight.data.uniform_(-scope, scope)\n        self.lr.bias.data.fill_(0)\n\n    def init_hidden(self, bsz):\n        num_layers = self.lstm_layers*self.num_directions\n\n        weight = next(self.parameters()).data\n        return (Variable(weight.new(num_layers, bsz, self.hidden_size).zero_()),\n                Variable(weight.new(num_layers, bsz, self.hidden_size).zero_()))\n\n    def forward(self, input, hidden):\n        encode = self.lookup_table(input)\n        lstm_out, hidden = self.lstm(encode, hidden)\n        lstm_out = F.dropout(lstm_out, p=self.dropout)\n        out = self.lr(lstm_out.contiguous().view(-1, lstm_out.size(2)))\n        return F.log_softmax(out, dim=-1), hidden\n\n'"
ch-poetry-nlg/train.py,8,"b'import argparse\nimport time\n\nimport torch\nfrom torch.autograd import Variable\n\nparser = argparse.ArgumentParser(description=\'NLG for Chinese Poetry\')\nparser.add_argument(\'--lr\', type=float, default=0.001,\n                    help=\'initial learning rate\')\nparser.add_argument(\'--epochs\', type=int, default=100,\n                    help=\'number of epochs for train\')\nparser.add_argument(\'--batch-size\', type=int, default=64,\n                    help=\'batch size for training\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda-able\', action=\'store_true\',\n                    help=\'enables cuda\')\n\nparser.add_argument(\'--save\', type=str, default=\'./ch_poe.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--data\', type=str, default=\'./data/ch_pro_nlg.pt\',\n                    help=\'location of the data corpus\')\n\nparser.add_argument(\'--dropout\', type=float, default=0.5,\n                    help=\'the probability for dropout\')\nparser.add_argument(\'--embed-dim\', type=int, default=128,\n                    help=\'number of embedding dimension\')\nparser.add_argument(\'--hidden-size\', type=int, default=128,\n                    help=\'number of lstm hidden dimension\')\nparser.add_argument(\'--lstm-layers\', type=int, default=3,\n                    help=\'biLSTM layer numbers\')\nparser.add_argument(\'--clip\', type=float, default=0.25,\n                    help=\'gradient clipping\')\nparser.add_argument(\'--bidirectional\', action=\'store_true\',\n                    help=\'If True, becomes a bidirectional LSTM\')\n\nargs = parser.parse_args()\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available() and args.cuda_able\n\n# ##############################################################################\n# Load data\n###############################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_len = data[""max_word_len""]\nargs.vocab_size = data[\'dict\'][\'src_size\']\n\ntraining_data = DataLoader(\n                 data[\'train\'],\n                 args.max_len,\n                 args.batch_size,\n                 cuda=use_cuda)\n\n# ##############################################################################\n# Build model\n# ##############################################################################\nimport model\n\nrnn = model.Model(args)\nif use_cuda:\n    rnn = rnn.cuda()\n\noptimizer = torch.optim.Adam(rnn.parameters(), lr=args.lr)\ncriterion = torch.nn.CrossEntropyLoss()\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\n\ntrain_loss = []\n\ndef repackage_hidden(h):\n    if type(h) == Variable:\n        if use_cuda:\n            return Variable(h.data).cuda()\n        return Variable(h.data)\n    else:\n        return tuple(repackage_hidden(v) for v in h)\n\ndef train():\n    rnn.train()\n    total_loss = 0\n    hidden = rnn.init_hidden(args.batch_size)\n    for data, label in tqdm(training_data, mininterval=1,\n                desc=\'Train Processing\', leave=False):\n        optimizer.zero_grad()\n        hidden = repackage_hidden(hidden)\n        target, hidden = rnn(data, hidden)\n        loss = criterion(target, label)\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm(rnn.parameters(), args.clip)\n        optimizer.step()\n\n        total_loss += loss.data\n    return total_loss[0]/training_data.sents_size\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nimport generate\nbest_acc = None\ntotal_start_time = time.time()\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs+1):\n        if use_cuda:\n            rnn = rnn.cuda()\n        epoch_start_time = time.time()\n        loss = train()\n        train_loss.append(loss*1000.)\n\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(epoch, time.time() - epoch_start_time, loss))\n        print(\'-\' * 90)\n        rnn.cpu()\n        G = generate.Generate(model=rnn, src_dict=data[\'dict\'][\'src\'], args=args)\n        print(""generate - [{}]"".format(G.Create(20)))\n        print(\'-\' * 90)\n\nexcept KeyboardInterrupt:\n    print(""-""*90)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format((time.time() - total_start_time)/60.0))\n\nmodel_state_dict = rnn.state_dict()\nmodel_source = {\n    ""settings"": args,\n    ""model"": model_state_dict,\n    ""src_dict"": data[\'dict\'][\'src\']\n}\ntorch.save(model_source, args.save)\nprint(train_loss)\n\n'"
cnn-text-classfication/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    UNK: '<unk>',\n    PAD: '<pad>'\n}\n\n"""
cnn-text-classfication/corpus.py,1,"b'import torch\n\nimport argparse\nimport os\n\nfrom const import *\n\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\n\nclass Dictionary(object):\n    def __init__(self, word2idx={}, idx_num=0):\n        self.word2idx = word2idx\n        self.idx = idx_num\n\n    def _add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def _convert(self):\n        self.idx2word = {v: k for k, v in self.word2idx.items()}\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Words(Dictionary):\n    def __init__(self):\n        word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        super().__init__(word2idx=word2idx, idx_num=len(word2idx))\n\n    def __call__(self, sents):\n        words = set([word for sent in sents for word in sent])\n        for word in words:\n            self._add(word)\n\n\nclass Labels(Dictionary):\n    def __init__(self):\n        super().__init__()\n\n    def __call__(self, labels):\n        _labels = set(labels)\n        for label in _labels:\n            self._add(label)\n\n\nclass Corpus(object):\n    def __init__(self, path, save_data, max_len=16):\n        self.train = os.path.join(path, ""train"")\n        self.valid = os.path.join(path, ""valid"")\n        self._save_data = save_data\n\n        self.w = Words()\n        self.l = Labels()\n        self.max_len = max_len\n\n    def parse_data(self, _file, is_train=True, fine_grained=False):\n        """"""\n        fine_grained: Whether to use the fine-grained (50-class) version of TREC\n                or the coarse grained (6-class) version.\n        """"""\n        _sents, _labels = [], []\n        for sentence in open(_file):\n            label, _, _words = sentence.replace(\'\\xf0\', \' \').partition(\' \')\n            label = label.split("":"")[0] if not fine_grained else label\n\n            words = _words.strip().split()\n\n            if len(words) > self.max_len:\n                words = words[:self.max_len]\n\n            _sents += [words]\n            _labels += [label]\n        if is_train:\n            self.w(_sents)\n            self.l(_labels)\n            self.train_sents = _sents\n            self.train_labels = _labels\n        else:\n            self.valid_sents = _sents\n            self.valid_labels = _labels\n\n    def save(self):\n        self.parse_data(self.train)\n        self.parse_data(self.valid, False)\n\n        data = {\n            \'max_len\': self.max_len,\n            \'dict\': {\n                \'train\': self.w.word2idx,\n                \'vocab_size\': len(self.w),\n                \'label\': self.l.word2idx,\n                \'label_size\': len(self.l),\n            },\n            \'train\': {\n                \'src\': word2idx(self.train_sents, self.w.word2idx),\n                \'label\': [self.l.word2idx[l] for l in self.train_labels]\n            },\n            \'valid\': {\n                \'src\': word2idx(self.valid_sents, self.w.word2idx),\n                \'label\': [self.l.word2idx[l] for l in self.valid_labels]\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'Finish dumping the data to file - [{}]\'.format(self._save_data))\n        print(\'words length - [{}]\'.format(len(self.w)))\n        print(\'label size - [{}]\'.format(len(self.l)))\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'CNN Classification\')\n    parser.add_argument(\'--file-path\', type=str, default=""./data"",\n                        help=\'file path\')\n    parser.add_argument(\'--save-data\', type=str, default=""./data/corpus.pt"",\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--max-lenth\', type=int, default=16,\n                        help=\'max length left of sentence [default: 16]\')\n    args = parser.parse_args()\n    corpus = Corpus(args.file_path, args.save_data, args.max_lenth)\n    corpus.save()\n'"
cnn-text-classfication/data_loader.py,2,"b'import numpy as np\nimport torch\nimport const\n\n\nclass DataLoader(object):\n    def __init__(self, src_sents, label, max_len, cuda=True,\n                 batch_size=64, shuffle=True, evaluation=False):\n        self.cuda = cuda\n        self.sents_size = len(src_sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size + 1\n        self.evaluation = evaluation\n\n        self._batch_size = batch_size\n        self._max_len = max_len\n        self._src_sents = np.asarray(src_sents)\n        self._label = np.asarray(label)\n        if shuffle:\n            self._shuffle()\n\n    def _shuffle(self):\n        indices = np.arange(self._src_sents.shape[0])\n        np.random.shuffle(indices)\n        self._src_sents = self._src_sents[indices]\n        self._label = self._label[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def pad_to_longest(insts, max_len):\n            inst_data = np.array(\n                [inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n\n            inst_data_tensor = torch.from_numpy(inst_data)\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step * self._batch_size\n        _bsz = min(self._batch_size, self.sents_size - _start)\n        self._step += 1\n        data = pad_to_longest(\n            self._src_sents[_start:_start + _bsz], self._max_len)\n        label = torch.from_numpy(self._label[_start:_start + _bsz])\n        if self.cuda:\n            label = label.cuda()\n\n        return data, label\n'"
cnn-text-classfication/main.py,7,"b'import argparse\nimport time\n\nimport torch\n\nparser = argparse.ArgumentParser(description=\'CNN text classification\')\nparser.add_argument(\'--lr\', type=float, default=0.001,\n                    help=\'initial learning rate [default: 0.001]\')\nparser.add_argument(\'--epochs\', type=int, default=100,\n                    help=\'number of epochs for train\')\nparser.add_argument(\'--batch-size\', type=int, default=16,\n                    help=\'batch size for training\')\nparser.add_argument(\'--save\', type=str, default=\'./CNN_Text.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--data\', type=str, default=\'./data/corpus.pt\',\n                    help=\'location of the data corpus\')\nparser.add_argument(\'--dropout\', type=float, default=0.5,\n                    help=\'the probability for dropout (0 = no dropout) [default: 0.5]\')\nparser.add_argument(\'--embed-dim\', type=int, default=128,\n                    help=\'number of embedding dimension [default: 128]\')\nparser.add_argument(\'--kernel-num\', type=int, default=128,\n                    help=\'number of each kind of kernel\')\nparser.add_argument(\'--filter-sizes\', type=str, default=\'3,4,5\',\n                    help=\'filter sizes\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda-able\', action=\'store_true\',\n                    help=\'enables cuda\')\n\nargs = parser.parse_args()\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available() and args.cuda_able\n\n# ##############################################################################\n# Load data\n################################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_len = data[""max_len""]\nargs.vocab_size = data[\'dict\'][\'vocab_size\']\nargs.label_size = data[\'dict\'][\'label_size\']\nargs.filter_sizes = list(map(int, args.filter_sizes.split("","")))\n\ntraining_data = DataLoader(\n    data[\'train\'][\'src\'],\n    data[\'train\'][\'label\'],\n    args.max_len,\n    batch_size=args.batch_size,\n    cuda=use_cuda)\n\nvalidation_data = DataLoader(\n    data[\'valid\'][\'src\'],\n    data[\'valid\'][\'label\'],\n    args.max_len,\n    batch_size=args.batch_size,\n    shuffle=False,\n    cuda=use_cuda,\n    evaluation=True)\n\n# ##############################################################################\n# Build model\n# ##############################################################################\nimport model\n\ncnn = model.CNN_Text(args)\nif use_cuda:\n    cnn = cnn.cuda()\n\noptimizer = torch.optim.Adam(cnn.parameters(), lr=args.lr)\ncriterion = torch.nn.CrossEntropyLoss()\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\n\ntrain_loss = []\nvalid_loss = []\naccuracy = []\n\n\ndef evaluate():\n    cnn.eval()\n    corrects = eval_loss = 0\n    _size = validation_data.sents_size\n    for data, label in tqdm(validation_data, mininterval=0.2,\n                            desc=\'Evaluate Processing\', leave=False):\n        pred = cnn(data)\n        loss = criterion(pred, label)\n\n        eval_loss += loss.data[0]\n        corrects += (torch.max(pred, 1)\n                     [1].view(label.size()).data == label.data).sum()\n\n    return eval_loss / _size, corrects, float(corrects) / _size * 100.0, _size\n\n\ndef train():\n    cnn.train()\n    total_loss = 0\n    for data, label in tqdm(training_data, mininterval=1,\n                            desc=\'Train Processing\', leave=False):\n        optimizer.zero_grad()\n        target = cnn(data)\n\n        loss = criterion(target, label)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.data\n    return total_loss[0] / training_data.sents_size\n\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs + 1):\n        epoch_start_time = time.time()\n        loss = train()\n        train_loss.append(loss * 1000.)\n\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(\n            epoch, time.time() - epoch_start_time, loss))\n\n        loss, corrects, acc, size = evaluate()\n        valid_loss.append(loss * 1000.)\n        accuracy.append(acc / 100.)\n\n        epoch_start_time = time.time()\n        print(\'-\' * 90)\n        print(\'| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(\n            epoch, time.time() - epoch_start_time, loss, acc, corrects, size))\n        print(\'-\' * 90)\n        if not best_acc or best_acc < corrects:\n            best_acc = corrects\n            model_state_dict = cnn.state_dict()\n            model_source = {\n                ""settings"": args,\n                ""model"": model_state_dict,\n                ""src_dict"": data[\'dict\'][\'train\']\n            }\n            torch.save(model_source, args.save)\nexcept KeyboardInterrupt:\n    print(""-"" * 90)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format(\n        (time.time() - total_start_time) / 60.0))\n'"
cnn-text-classfication/model.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass CNN_Text(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.lookup_table = nn.Embedding(self.vocab_size, self.embed_dim)\n\n        self.encoders = []\n        for i, filter_size in enumerate(self.filter_sizes):\n            enc_attr_name = ""encoder_%d"" % i\n            self.__setattr__(enc_attr_name,\n                             nn.Conv2d(in_channels=1,\n                                       out_channels=self.kernel_num,\n                                       kernel_size=(filter_size, self.embed_dim)))\n            self.encoders.append(self.__getattr__(enc_attr_name))\n\n        self.logistic = nn.Linear(len(self.filter_sizes) * self.kernel_num,\n                                  self.label_size)\n\n        self.dropout = nn.Dropout(self.dropout)\n\n        self._init_weight()\n\n    def forward(self, x):\n        n_idx = 0\n        c_idx = 1\n        h_idx = 2\n        w_idx = 3\n\n        x = self.lookup_table(x)\n        x = x.unsqueeze(c_idx)\n\n        enc_outs = []\n        for encoder in self.encoders:\n            enc_ = F.relu(encoder(x))\n            k_h = enc_.size()[h_idx]\n            enc_ = F.max_pool2d(enc_, kernel_size=(k_h, 1))\n            enc_ = enc_.squeeze(w_idx)\n            enc_ = enc_.squeeze(h_idx)\n            enc_outs.append(enc_)\n\n        encoding = self.dropout(torch.cat(enc_outs, 1))\n        return F.log_softmax(self.logistic(encoding))\n\n    def _init_weight(self, scope=.1):\n        self.lookup_table.weight.data.uniform_(-scope, scope)\n        self.logistic.weight.data.uniform_(-scope, scope)\n'"
coreference/const.py,0,"b'DATAPATH = ""./data""\n\nPAD = 0\nUNK = 1\n\nWORD = {\n    PAD: \'<pad>\',\n    UNK: \'<unk>\',\n}\n\nINIT_RANGE = 0.1\n\nNORMALIZE_DICT = {""/."": ""."", ""/?"": ""?"",\n                  ""-LRB-"": ""("", ""-RRB-"": "")"",\n                  ""-LCB-"": ""{"", ""-RCB-"": ""}"",\n                  ""-LSB-"": ""["", ""-RSB-"": ""]""}\nREMOVED_CHAR = [""/"", ""%"", ""*""]\n\nFILTERFILES = [\n    ""cbs_0146.conll"",\n    ""cbs_0166.conll"",\n    ""cnr_0011.conll"",\n    ""cnr_0014.conll"",\n    ""cnr_0024.conll"",\n    ""cnr_0032.conll"",\n    ""cnr_0052.conll"",\n    ""cnr_0092.conll"",\n    ""cnr_0093.conll"",\n    ""cts_0033.conll"",\n    ""ctv_0146.conll"",\n    ""vom_0106.conll"",\n    ""vom_0231.conll"",\n    ""ch_0020.conll"",\n    ""ch_0020.conll"",\n    ""cnr_0060.conll"",\n]\n'"
coreference/corpus.py,1,"b'import torch\nimport re\nimport os\nimport sys\nimport json\nimport collections\nimport random\n\nimport numpy as np\n\nimport const\nimport utils\n\n\ndef word2idx(words, word2idx):\n    return [word2idx[w] if w in word2idx else const.UNK for w in words]\n\n\nclass Dictionary(object):\n\n    dots = [\'.\', \'?\', \'!\', ""\xe3\x80\x82"", \'\xef\xbc\x9f\', \'\xef\xbc\x81\', "","", ""\xef\xbc\x8c""]\n\n    def __init__(self):\n        self.word2idx = {\n            const.WORD[const.PAD]: const.PAD,\n            const.WORD[const.UNK]: const.UNK,\n        }\n        self.idx = len(self.word2idx)\n        self.add_dot()\n        self.word_count = collections.defaultdict(int)\n\n    def add_dot(self):\n        for dot in self.dots:\n            self.word2idx[dot] = self.idx\n            self.idx += 1\n\n    def add(self, word):\n        chars = \'\'.join(c for c in word if utils.is_chinese_char(ord(c)))\n        if chars:\n            self.word_count[word] += 1\n\n    def parse(self, min_count=0):\n        ignored_word_count = 0\n        for word, count in self.word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n\n            if self.word2idx.get(word) is None:\n                self.word2idx[word] = self.idx\n                self.idx += 1\n\n        return ignored_word_count\n\n\nclass Corpus(object):\n    def __init__(self, inp_data=const.DATAPATH, load_w2v=None,\n                 save_data=os.path.join(const.DATAPATH, ""corpus.pt"")):\n\n        self.save_data = save_data\n        self.load_w2v = load_w2v\n        self.inp_data = inp_data\n        self.word = Dictionary()\n        self.char = Dictionary()\n        self.load_files()\n        self.save()\n\n    def load_files(self):\n        data_path = f""{self.inp_data}/data/train""\n        for _, _, files in os.walk(data_path):\n            for inf in files:\n                if inf.endswith(""conll""):\n                    for doc in utils.load_file(f""{data_path}/{inf}""):\n                        tokens = doc.tokens\n                        [self.word.add(w) for w in tokens]\n                        [self.char.add(c) for w in tokens for c in w]\n\n        print(f\'ignored word count - {self.word.parse(2)}\')\n        print(f\'ignored char count - {self.char.parse(2)}\')\n\n    def save(self):\n        data = {\n            \'word2idx\': self.word.word2idx,\n            \'char2idx\': self.char.word2idx,\n        }\n        if self.load_w2v is not None:\n            data[""wordW""], data[""charW""] = utils.load_pre_w2c(\n                self.load_w2v, self.word.word2idx, self.char.word2idx)\n\n        torch.save(data, self.save_data)\n        print(f\'char length - {len(self.char.word2idx)}\')\n        print(f\'word length - {len(self.word.word2idx)}\')\n        print(f\'Finish dumping the data to file - {self.save_data}\')\n\n\nif __name__ == ""__main__"":\n    Corpus()\n'"
coreference/data_loader.py,1,"b'import random\nimport os\n\nimport numpy as np\nimport torch\n\nimport const\nimport utils\n\n\nclass DataLoader:\n    def __init__(self, inp_data, word2idx, cuda=True):\n        self.cuda = cuda\n        self.inp_data = inp_data\n        self.word2idx = word2idx\n\n        self.train_docs = self.load_files(""train"")\n        self.test_docs = self.load_files(""development"")\n\n        self.documents2tensor()\n\n    def load_files(self, dtype):\n        documents = []\n        data_path = f""{self.inp_data}/data/{dtype}""\n        for _, _, files in os.walk(data_path):\n            for inf in files:\n                if inf not in const.FILTERFILES and inf.endswith(""conll""):\n                    documents += utils.load_file(f""{data_path}/{inf}"")\n\n        return documents\n\n    def documents2tensor(self):\n        for doc in self.train_docs:\n            doc.tokens2tensor(self.cuda, self.word2idx)\n            doc.mentions(self.word2idx)\n            doc.span2tonsor(self.word2idx)\n\n        for doc in self.test_docs:\n            doc.tokens2tensor(self.cuda, self.word2idx)\n            doc.mentions(self.word2idx)\n            doc.span2tonsor(self.word2idx)\n\n\nif __name__ == ""__main__"":\n    corpus = torch.load(os.path.join(const.DATAPATH, ""corpus.pt""))\n    dl = DataLoader(const.DATAPATH, corpus[""word2idx""], cuda=False)\n\n    # doc = dl.sample_data()[0]\n    # corefs_idxs, mention_idxs, mention_spans, labels, distances, corefs = doc.sample(False, 20)\n    # print(corefs_idxs, mention_idxs)\n    for doc in dl.test_docs:\n        if doc.mention_spans.shape[0] == 0:\n            print(doc.filename.split(""/"")[-1])\n'"
coreference/model.py,30,"b'import math\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.nn.functional as F\nimport numpy as np\n\nimport const\n\n\nclass Score(nn.Module):\n    def __init__(self, in_dim, hidden_dim=150):\n        super().__init__()\n\n        self.score = nn.Sequential(\n            nn.Linear(in_dim, 2*hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.20),\n            nn.Linear(2*hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.20),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x):\n        return self.score(x)\n\n\nclass GELU(nn.Module):\n    """"""\n    different from 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n    """"""\n\n    def forward(self, x):\n        return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n\n\nclass LayerNorm(nn.Module):\n    def __init__(self, hidden_size, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n        self.gamma = nn.Parameter(torch.ones(hidden_size))\n        self.beta = nn.Parameter(torch.zeros(hidden_size))\n\n    def forward(self, input):\n        mu = torch.mean(input, dim=-1, keepdim=True)\n        sigma = torch.std(input, dim=-1, keepdim=True).clamp(min=self.eps)\n        output = (input - mu) / sigma\n        return output * self.gamma.expand_as(output) + self.beta.expand_as(output)\n\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self, d_k, dropout):\n        super().__init__()\n        self.temper = np.power(d_k, 0.5)\n        self.dropout = nn.Dropout(dropout)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, q, k, v):\n        attn = torch.bmm(q, k.transpose(1, 2)) / self.temper\n        attn = self.softmax(attn.view(-1, attn.size(2))).view(*attn.size())\n        attn = self.dropout(attn)\n        return torch.bmm(attn, v)\n\n\nclass MultiHeadAtt(nn.Module):\n    def __init__(self, n_head, d_model, dropout):\n        super().__init__()\n        self.n_head = n_head\n        self.d_v = self.d_k = d_k = d_model // n_head\n\n        for name in [""w_qs"", ""w_ks"", ""w_vs""]:\n            self.__setattr__(name,\n                             nn.Parameter(torch.FloatTensor(n_head, d_model, d_k)))\n\n        self.attention = ScaledDotProductAttention(d_k, dropout)\n        self.lm = LayerNorm(d_model)\n        self.w_o = nn.Linear(d_model, d_model, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n        self.w_qs.data.normal_(std=const.INIT_RANGE)\n        self.w_ks.data.normal_(std=const.INIT_RANGE)\n        self.w_vs.data.normal_(std=const.INIT_RANGE)\n\n    def forward(self, q, k, v):\n        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n        residual = q\n\n        bsz, len_q, d_model = q.size()\n        len_k, len_v = k.size(1), v.size(1)\n\n        def reshape(x):\n            """"""[bsz, len, d_*] -> [n_head x (bsz*len) x d_*]""""""\n            return x.repeat(n_head, 1, 1).view(n_head, -1, d_model)\n\n        q_s, k_s, v_s = map(reshape, [q, k, v])\n\n        q_s = torch.bmm(q_s, self.w_qs).view(-1, len_q, d_k)\n        k_s = torch.bmm(k_s, self.w_ks).view(-1, len_k, d_k)\n        v_s = torch.bmm(v_s, self.w_vs).view(-1, len_v, d_v)\n\n        outputs = self.attention(q_s, k_s, v_s)\n        outputs = torch.cat(torch.split(outputs, bsz, dim=0),\n                            dim=-1).view(-1, n_head * d_v)\n        outputs = self.dropout(self.w_o(outputs)).view(bsz, len_q, -1)\n        return self.lm(outputs + residual)\n\n\nclass Distance(nn.Module):\n\n    bins = [1, 2, 3, 4, 8, 16, 32, 64]\n\n    def __init__(self, distance_dim=20):\n        super().__init__()\n\n        self.dim = distance_dim\n        self.embeds = nn.Sequential(\n            nn.Embedding(len(self.bins)+1, distance_dim),\n            nn.Dropout(0.20)\n        )\n\n    def forward(self, lengths):\n        return self.embeds(lengths)\n\n\nclass RnnEncoder(nn.Module):\n    def __init__(self, d_model, embedding_dim, dropout):\n        super().__init__()\n\n        self.rnn = nn.GRU(embedding_dim,\n                          hidden_size=d_model,\n                          batch_first=True,\n                          bidirectional=True)\n        self.ln = LayerNorm(d_model*2)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        encode, _ = self.rnn(x)\n        encode = self.ln(encode)\n        return self.dropout(encode)[:, -1, :]\n\n\nclass MentionPairScore(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        self.args = args\n\n        self.position_embedding = nn.Embedding(args.max_len+1, args.pos_dim)\n        self.word_embedding = nn.Embedding(args.word_ebd_weight.shape[0],\n                                           args.word_ebd_weight.shape[1])\n        self.word_embedding.weight.data.copy_(\n            torch.from_numpy(args.word_ebd_weight))\n        self.embedding_transform = nn.Linear(\n            args.pos_dim+args.word_ebd_weight.shape[1], args.d_model)\n        self.transform_activate = GELU()\n\n        self.rnn_rncoder = RnnEncoder(args.rnn_hidden_size,\n                                      args.word_ebd_weight.shape[1], args.dropout)\n\n        self.dropout = nn.Dropout(args.dropout)\n\n        self.head_att = MultiHeadAtt(args.n_head, args.d_model, args.dropout)\n        self.distance_embedding = Distance()\n\n        score_in_dim = 4*args.d_model + 4*args.rnn_hidden_size + args.pos_dim\n        self.score = Score(score_in_dim)\n\n        self._reset_parameters()\n\n    def forward(self, doc, word2idx):\n        doc_encoding = self.doc_encode(doc)\n        mention_rnn_encode, coref_rnn_encode, distances_embedding_encode, corefs_idxs, mention_idxs, labels = self.mention_encode(\n            doc, word2idx)\n        doc_features = torch.stack(([torch.cat((doc_encoding[mention_start], doc_encoding[mention_end], doc_encoding[coref_start],\n                                                doc_encoding[coref_end])) for (mention_start, mention_end), (coref_start, coref_end) in zip(mention_idxs, corefs_idxs)]), dim=0)\n\n        mention_features = torch.cat(\n            (doc_features, mention_rnn_encode, coref_rnn_encode, distances_embedding_encode), dim=1)\n        scores = self.score(mention_features).squeeze()\n\n        return torch.sigmoid(scores), labels\n\n    def doc_encode(self, doc):\n        doc_embedding_encode = self.word_embedding(doc.token_tensors)\n        doc_postion_encode = self.position_embedding(\n            doc.pos2tensor(self.args.use_cuda))\n        doc_encode = self.dropout(torch.cat((\n            doc_embedding_encode, doc_postion_encode), dim=-1))\n        transform_encode = self.embedding_transform(doc_encode)\n        transform_encode = self.transform_activate(\n            transform_encode).unsqueeze(0)\n        return self.head_att(transform_encode, transform_encode, transform_encode).squeeze()\n\n    def mention_encode(self, doc, word2idx):\n        corefs_idxs, mention_idxs, mention_spans, labels, distances, corefs = doc.sample(\n            self.args.use_cuda, self.args.batch_size)\n        distances_embedding_encode = self.distance_embedding(distances)\n        mention_embedding_encode = self.word_embedding(mention_spans)\n        coref_embedding_encode = self.word_embedding(corefs)\n\n        distances_embedding_encode = self.dropout(distances_embedding_encode)\n        mention_embedding_encode = self.dropout(mention_embedding_encode)\n        coref_embedding_encode = self.dropout(coref_embedding_encode)\n\n        mention_rnn_encode = self.rnn_rncoder(mention_embedding_encode)\n        coref_rnn_encode = self.rnn_rncoder(coref_embedding_encode)\n\n        return mention_rnn_encode, coref_rnn_encode, distances_embedding_encode, corefs_idxs, mention_idxs, labels\n\n    def mention_predict(self, tokens, positions, mention, coref_idx, mention_idx, distance, coref):\n        doc_embedding_encode = self.word_embedding(tokens)\n        doc_postion_encode = self.position_embedding(positions)\n        doc_encode = self.dropout(torch.cat((\n            doc_embedding_encode, doc_postion_encode), dim=-1))\n        transform_encode = self.embedding_transform(doc_encode)\n        transform_encode = self.transform_activate(\n            transform_encode).unsqueeze(0)\n        doc_encoding = self.head_att(\n            transform_encode, transform_encode, transform_encode).squeeze()\n\n        distance_embedding_encode = self.distance_embedding(distance)\n        mention_embedding_encode = self.word_embedding(mention)\n        coref_embedding_encode = self.word_embedding(coref)\n\n        distance_embedding_encode = self.dropout(distance_embedding_encode)\n        mention_embedding_encode = self.dropout(mention_embedding_encode)\n        coref_embedding_encode = self.dropout(coref_embedding_encode)\n\n        mention_rnn_encode = self.rnn_rncoder(mention_embedding_encode)\n        coref_rnn_encode = self.rnn_rncoder(coref_embedding_encode)\n\n        doc_feature = torch.cat((doc_encoding[mention_idx[0]], doc_encoding[mention_idx[1]],\n                                 doc_encoding[coref_idx[0]], doc_encoding[coref_idx[1]]))\n\n        mention_feature = torch.cat((doc_feature.unsqueeze(\n            0), mention_rnn_encode, coref_rnn_encode, distance_embedding_encode.squeeze(0)), dim=1)\n        score = self.score(mention_feature).squeeze()\n        return torch.sigmoid(score)\n\n    def _reset_parameters(self):\n        self.position_embedding.weight.data.uniform_(-.1, .1)\n        for layer in self.modules():\n            if type(layer) == nn.Linear:\n                layer.weight.data.normal_(std=const.INIT_RANGE)\n\n    def save_model(self, path):\n        torch.save(self.state_dict(), path)\n\n    def load_model(self, path, cuda):\n        if cuda:\n            self.load_state_dict(torch.load(path))\n            self.cuda()\n        else:\n            self.load_state_dict(torch.load(\n                path, map_location=lambda storage, loc: storage))\n            self.cpu()\n\n\nif __name__ == ""__main__"":\n    import data_loader\n    import os\n    import utils\n    import argparse\n\n    use_cuda = torch.cuda.is_available()\n    corpus = torch.load(os.path.join(const.DATAPATH, ""corpus.pt""))\n    dl = data_loader.DataLoader(const.DATAPATH, corpus[""word2idx""], cuda=False)\n    doc = dl.sample_data()[0]\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--batch_size\', type=int, default=100)\n    parser.add_argument(\'--max_len\', type=int, default=500)\n    parser.add_argument(\'--span_len\', type=int, default=4)\n    parser.add_argument(\'--d_model\', type=int, default=512)\n    parser.add_argument(\'--pos_dim\', type=int, default=20)\n    parser.add_argument(\'--n_head\', type=int, default=8)\n    parser.add_argument(\'--rnn_hidden_size\', type=int, default=128)\n    parser.add_argument(\'--dropout\', type=float, default=0.5)\n\n    args = parser.parse_args()\n\n    args.word_ebd_weight = corpus[""wordW""]\n    args.use_cuda = use_cuda\n\n    mps = MentionPairScore(args)\n\n    scores, labels = mps(doc, corpus[""word2idx""])\n    print(scores.gt(0.5).long())\n    print(scores.gt(0.5)*labels)\n    print(labels.shape)\n'"
coreference/prepare_data.py,0,"b'import os\n\nimport const\nimport skeleton2conll\n\n\ndef skele2conll(data_type):\n    for root, _, files in os.walk(os.path.join(const.DATAPATH, ""/conll-2012/"", data_type)):\n        for inf in files:\n            if inf.endswith(""gold_skel""):\n                conll_file = os.path.join(root, inf)\n                ldc_file = conll_file.replace(\n                    ""conll-2012/""+data_type, ""ldc"").replace(""v4_gold_skel"", ""onf"")\n                output_file = f\'{const.DATAPATH}/data/{data_type}/{inf.replace(""v4_gold_skel"", ""conll"")}\'\n                skeleton2conll.start(ldc_file, conll_file, output_file, ""utf8"")\n\n\nif __name__ == ""__main__"":\n    skele2conll(""train"")\n    skele2conll(""development"")\n'"
coreference/skeleton2conll.py,0,"b'#!/usr/bin/env python\n\n""""""\nGet most current usage with:\n\n  python skeleton2conll.py --help\n\n""""""\n\nfrom __future__ import with_statement\nimport codecs\nimport sys\nimport os\nimport re\nimport string\nfrom collections import defaultdict\n\n\nWORD_COLUMN=3\nLEMMA_COLUMN=6\n\n\n\n\nMIN_VERBOSITY = 0\nMED_VERBOSITY = 5\nMAX_VERBOSITY = 10\nSUPER_VERBOSITY = 15\n\nDEBUG = False\nVERBOSITY = MAX_VERBOSITY\n\n\n\n\n\n\n\n\ndef debug(debug_object, debug_flag=DEBUG, verbosity=MAX_VERBOSITY, nl=False):\n  if((debug_flag == True) and (verbosity <= VERBOSITY)):\n    if nl:\n      trailing_char = ""\\n""\n    else:\n      trailing_char = """"\n\n    sys.stderr.write(str(debug_object) + trailing_char)\n\n\n\n\n\n\n\n\n\n\n\n\ndef warning(warning_string, verbosity=0):\n  """""" print warning string depending on the value of VERBOSITY """"""\n\n  if(verbosity <= VERBOSITY):\n    sys.stderr.write(u""""""\n\n--------------------------------------------------------------------------------\n                                      WARNING\n--------------------------------------------------------------------------------\n%s\n--------------------------------------------------------------------------------\n\n"""""" % (warning_string))\n\n\n\n\n\n\n\n\nclass abstract_open_type_table:\n\n  def __init__(self, a_id, data_pointer=None):\n    self.id = a_id\n    self.type_hash[self.id] += 1\n\n  @classmethod\n  def write_to_db(cls, cursor):\n    for a_type in cls.type_hash.keys():\n      insert_ignoring_dups(cls, cursor, a_type)\n\n  @classmethod\n  def __repr__(cls):\n    return "" "".join(cls.type_hash.keys())\n\n  @classmethod\n  def get_table(cls):\n    try:\n        return cls.sql_insert_statement.strip().split(""\\n"")[0].split()[2]\n    except Exception:\n        return ""unknown""\n\n\n\n\n\n\n\n\nclass lemma_type(abstract_open_type_table):\n  type_hash = defaultdict(int)\n\n  sql_table_name = ""lemma_type""\n  sql_create_statement = \\\n""""""\ncreate table lemma_type\n(\n  id varchar(255) not null collate utf8_bin primary key\n)\ndefault character set utf8;\n""""""\n\n\n  sql_insert_statement = \\\n""""""insert into lemma_type\n(\n  id\n)\nvalues (%s)\n""""""\n\n\n\n\n\n\n\nclass lemma:\n  """""" arabic trees have extra lemma information """"""\n\n  def __init__(self, input_string, b_transliteration, comment, index, offset, unvocalized_string,\n               vocalized_string, vocalized_input, pos, gloss, lemma, coarse_sense, leaf_id):\n\n    self.input_string = input_string\n    self.b_transliteration = b_transliteration\n    self.comment = comment\n    self.index = index\n    self.offset = offset\n    self.unvocalized_string = unvocalized_string\n    self.vocalized_string = vocalized_string\n    self.vocalized_input = vocalized_input\n    self.pos = pos\n    self.gloss = gloss\n    self.lemma = lemma\n    self.coarse_sense = coarse_sense\n    self.leaf_id = leaf_id\n    \n    self.id = ""%s@%s"" % (self.lemma, self.leaf_id)\n\n  sql_table_name = ""lemma""\n\n  def __repr__(self):\n    return ""\\n"".join([""lemma instance:"",\n                      ""  input_string: "" + self.input_string,\n                      ""  vocalized_input: "" + self.vocalized_input,\n                      ""  unvocalized_string: "" + self.unvocalized_string,\n                      ""  vocalized_string: "" + self.vocalized_string,\n                      ""  gloss: "" + self.gloss,\n                      ""  index: %s"" % self.index,\n                      ""  offset: %s"" % self.offset])\n\n  def __str__(self):\n    tr = [""INPUT STRING:%s"" % self.input_string,\n          ""    IS_TRANS:%s"" % self.b_transliteration,\n          ""     COMMENT:%s"" % self.comment,\n          ""       INDEX:%s"" % self.index,\n          ""     OFFSETS:%s"" % self.offset,\n          "" UNVOCALIZED:%s"" % self.unvocalized_string,\n          ""   VOCALIZED:%s"" % self.vocalized_string,\n          ""  VOC_STRING:%s"" % self.vocalized_input,\n          ""         POS:%s"" % self.pos,\n          ""       GLOSS:%s"" % self.gloss]\n\n    if self.lemma != ""lemma_not_set"":\n      if self.coarse_sense:\n        lemma_str = ""%s_%s"" % (self.lemma, self.coarse_sense)\n      else:\n        lemma_str = self.lemma\n\n      tr.append(""       LEMMA: [%s]"" % lemma_str)\n\n    return ""\\n"".join(tr)\n\n\n  @staticmethod\n  def from_db(a_leaf_id, a_cursor):\n    a_cursor.execute(""SELECT * FROM lemma WHERE leaf_id = \'%s\'"" % a_leaf_id)\n    rows = a_cursor.fetchall()\n\n    if not rows:\n      return None\n\n    if len(rows) != 1:\n      assert all(row[""lemma""] == rows[0][""lemma""] for row in rows), \\\n          ""\\n"".join("", "".join("": "".join(a) for a in row.iteritems()) for row in rows)\n\n    r = rows[0]\n\n    return lemma(r[""input_string""],\n                 r[""b_transliteration""],\n                 r[""comment""],\n                 r[""lemma_index""],\n                 r[""lemma_offset""],\n                 r[""unvocalized_string""],\n                 r[""vocalized_string""],\n                 r[""vocalized_input""],\n                 r[""pos""],\n                 r[""gloss""],\n                 r[""lemma""],\n                 r[""coarse_sense""],\n                 r[""leaf_id""])\n\n  # sql create statement for the syntactic_link table\n  sql_create_statement = \\\n""""""\ncreate table lemma\n(\n  id varchar(255) not null,\n  input_string varchar(255),\n  b_transliteration varchar(255),\n  comment varchar(255),\n  lemma_index varchar(255),\n  lemma_offset varchar(255),\n  unvocalized_string varchar(255),\n  vocalized_string varchar(255),\n  vocalized_input varchar(255),\n  pos varchar(255),\n  gloss varchar(255),\n  lemma varchar(255),\n  coarse_sense varchar(16),\n  leaf_id varchar(255),\n  foreign key (leaf_id) references tree.id\n)\ndefault character set utf8;\n""""""\n\n\n  # sql insert statement for the syntactic_link table\n  sql_insert_statement = \\\n""""""\ninsert into lemma\n(\n  id,\n  input_string,\n  b_transliteration,\n  comment,\n  lemma_index,\n  lemma_offset,\n  unvocalized_string,\n  vocalized_string,\n  vocalized_input,\n  pos,\n  gloss,\n  lemma,\n  coarse_sense,\n  leaf_id\n) values(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n""""""\n\n\n  def write_to_db(self, cursor):\n    data = [(self.id, self.input_string, self.b_transliteration, self.comment, self.index,\n             self.offset, self.unvocalized_string, self.vocalized_string, self.vocalized_input,\n             self.pos, self.gloss, self.lemma, self.coarse_sense, self.leaf_id)]\n    \n    cursor.executemany(""%s"" % (self.__class__.sql_insert_statement), data)\n\n\n\n\n\n\n\n\n\ndef iterate_trees(string_seq):\n    """"""\n\n    given string_seq which is a sequence of strings, read from\n    string_seq and produce strings one at a time that represent trees.\n\n    """"""\n\n    return [x for x in _iterate_trees_helper(string_seq) if x.strip()]\n\n\n\n\n\n\n\n\n\n\ndef _iterate_trees_helper(string_seq):\n    parens = 0\n    cur_parse = []\n\n    for s in string_seq:\n        if (s.startswith("";"") or s.startswith(""<"") or s.startswith(""*"")) and s.endswith(""\\n""):\n            continue # ignore comments and sgml\n\n        for c in s:\n            if c == ""("" and parens == 0 and cur_parse:\n                yield """".join(cur_parse)\n                cur_parse = []\n\n            cur_parse.append(c)\n\n            if c == ""("":\n                parens += 1\n            elif c == "")"":\n                parens -= 1\n\n                if parens == 0:\n                    yield """".join(cur_parse).strip()\n                    cur_parse = []\n\n    if parens != 0:\n        raise Exception(""Parens should have been zero at end, were %s"" % parens)\n    # if """".join(cur_parse).strip():\n    #     raise Exception(""curparse should have been empty at end, was %s"" % cur_parse)\n\n\n\n\n\n\n\n\n\n\nclass InvalidSexprException(Exception):\n    def __init__(self, sexpr, parent=None):\n        self.sexpr = sexpr\n        self.parent = parent\n\n    def __str__(self):\n\n        ns = """"\n        ns += self.sexpr\n        if self.parent:\n            ns += ""\\n\\n""\n            ns += str(self.parent)\n        return ns\n\n\n\n\n\n\n\n\n\n\ndef parse_sexpr(s):\n    """""" turn an s-expression into a tree of lists:\n\n    (a (b c) d) -> [a, [b, c], d]\n\n    uses spaces and parens only -- no way to have a token with a space in it\n\n    """"""\n    s = s.replace(""\\n"", "" "").replace(""\\t"","" "").strip()\n\n    if not s.startswith(""("") and not s.endswith("")""):\n        return s\n    elif s.startswith(""("") and s.endswith("")""):\n        tr = []\n        cur = []\n        parens = 0\n        for c in s[1:-1].strip() + "" "":\n            if c == ""("":\n                parens += 1\n            elif c == "")"":\n                parens -= 1\n            elif c == "" "" and cur:\n                if parens == 0:\n                    try:\n                        x = parse_sexpr("""".join(cur))\n                    except InvalidSexprException as e:\n                        raise InvalidSexprException(""Parent: %s"" % s, e)\n\n                    if x:\n                        tr.append(x)\n                    cur = []\n\n            cur.append(c)\n\n        if (cur and cur != ["" ""]) or parens != 0:\n            raise InvalidSexprException(""Invalid s-expression: "" + s + "" note: %s"" % """".join(cur) + "" parens: %s"" % parens)\n\n        return tr\n    else:\n        raise InvalidSexprException(""Invalid s-expression: \\n"" + s)\n\n\n\n\n\n\n\n\n\n\ndef unparse_sexpr(l):\n    if type(l) == type([]):\n        return ""("" + "" "".join(unparse_sexpr(a) for a in l) + "")""\n    return str(l)\n\n\n\n\n\n\n\n\n\n\ndef pretty_print_tree_string(a_tree_string, offset=\'\'):\n\n    if not a_tree_string.strip():\n        return """"\n\n    # Maximum depth we\'re prepared for in trees\n    maxdepth=100\n    maxindent=300\n\n    # Table of indentation at tree depth\n    depth_to_indent = [0 for i in range(maxdepth)]\n\n    # Initialize indent_string[i] to be a string of i spaces\n    indent_string = [\'\' for i in range(maxindent)]\n    for i in range(maxindent-1):\n        indent_string[i+1] = indent_string[i] + \' \'\n\n    # RE object for split that matches on a \')\' followed by not a \')\', but only consumes the \')\'\n    close_paren = re.compile(r\'\\)(?=\\s*[^\\s\\)])\')\n\n    # RE object to pick up first on this line(should be only) POS tag and the word of each lexical leaf of the tree\n    lexical_leaf = re.compile(r\'\\((?P<tag>[^\\s\\)\\(]+)\\s+(?P<word>[^\\s\\)\\(]+)\\)\')\n\n    # RE object to parse OntoNotes Normal Form tree lines:\n    a_tree = a_tree_string\n\n    pp_tree = """"\n\n    def treeindent(depth):\n        return indent_string[depth_to_indent[depth]]+offset  #Indent to appropriate point\n\n\n    current_depth = 0\n    for frag in  close_paren.split(a_tree):  #Split input into lines ending with a lexical item\n        if frag[-1]!= \'\\n\':\n            frag=frag+\')\'\n        else: frag=frag[0:-1]\n\n        #Indent to appropriate point\n        pp_tree += treeindent(current_depth)\n\n        pfrag = """"\n        for pfrag in (frag).split(\'(\')[1:]:         # Split line into segments each beginning with an \'(\'\n            pfrag=\'(\'+pfrag                         # Restore deleted initial \'(\'\n            pp_tree += pfrag                      # Print each\n            current_depth=current_depth+1           # Up the current depth count\n\n            # Remember how far to indent following items at this depth\n            depth_to_indent[current_depth]=depth_to_indent[current_depth-1]+len(pfrag)\n\n        current_depth=current_depth-pfrag.count(\')\')    # Correct depth given closing parens\n        if current_depth<=0:\n            pp_tree += \'\'            # Separate toplevel trees with blank lines\n\n        pp_tree += \'\\n\'              # Print CRLF\n\n\n    return re.sub(""\\)$"", """", pp_tree)\n\n\n\n\n\n\nDONT_DELETE_TREES = True\n\n\n\n\n\n\n\n\n\n\ndef car(sp):\n    return sp[0]\n\n\n\n\n\n\n\n\n\n\ndef cdr(sp):\n    return sp[1:]\n\n\n\n\n\n\n\n\n\n\ndef split_node(sp):\n    return car(sp), cdr(sp)\n\n\n\n\n\n\n\n\n\n\ndef is_leaf(sp):\n    return len(sp) == 2 and type(sp[1]) != type([])\n\n\ntransformations = {}\n\n\n\n\n\n\n\n\n\n\ndef pp(sexpr, out_text=False):\n    """""" pretty print the S-expr, or just spit text out if out_text is true\n\n    out_text also skips traces\n\n    """"""\n\n    words = [word for tag, word in all_leaves(sexpr)\n                if tag != ""-NONE-""] # skip traces\n\n    return ""\\n"".join(words)\n\n\n\n\n\n\ndef transforms(transformation):\n    assert transformation.startswith(""+"") or transformation.startswith(""-"")\n    def regfunc(func):\n        transformations[transformation] = func\n        return func\n    return regfunc\n\n\n\n\n\n\n\n\n\n\ndef require(b):\n    if not b:\n        raise Exception(""Failed Requirement"")\n\n\n\n\n\n\n\n\n\n\n@transforms(""-edited"")\ndef remove_edits(sp):\n    """"""Remove subtrees tagged \'EDITED\' (disfluencies) """"""\n\n    return remove_tagger(sp, ""EDITED"")\n\n\n\n\n\n\n\n\n\n\n@transforms(""-trace"")\ndef remove_edits(sp):\n    """"""Remove traces part of speech tagged \'-NONE-\' """"""\n\n    return remove_tagger(sp, ""-NONE-"")\n\n\n\n\n\n\n\n\n\n\n@transforms(""-phrase-tags"")\ndef all_leaves(sp):\n    """"""Make a tree of just the leaves\n\n    .. code-block: scheme\n\n        (TOP (S (NP-SBJ (NNP Zambia))\n            (VP (VBD had)\n                (ADVP-TMP (RB previously))\n                (VP (VBD lost)\n                    (NP (PRP$ its)\n                        (RB away)\n                        (VBD game))\n                    (NP-ADV (NP (CD 0))\n                            (PP (SYM -)\n                                (NP (CD 1))))))\n            (. .)))\n\n    becomes\n\n    .. code-block: scheme\n\n        ( (NNP Zambia)\n          (VBD Had)\n          (RB Previously)\n          (VBD lost)\n          (PRP$ its)\n          (RB away)\n          (VBG game)\n          (CD 0)\n          (SYM -)\n          (CD 0) )\n\n    """"""\n\n    tag, rest = split_node(sp)\n    if is_leaf(sp):\n        return [[tag, rest[0]]]\n\n    tr = []\n    for x in rest:\n        tr.extend(all_leaves(x))\n    return tr\n\n\n\n\n\n\n\n\n\n\ndef remove_tagger(sp, tag_to_remove):\n    """""" remove tag_to_remove from sp, culling empty branches """"""\n    def callback(tag, rest):\n        return tag == tag_to_remove\n    return remover(sp, callback)\n\n\n\n\n\n\n\n\n\n\ndef remover(sp, callback):\n    tag, rest = split_node(sp)\n    if callback(tag, rest):\n        return []\n    if is_leaf(sp):\n        return sp\n\n    new_rest = [y for y in [remover(x, callback) for x in rest] if y]\n\n    if not new_rest:\n        return []\n    return [tag] + new_rest\n\n\n\n\n\n\n\n\n\n\ndef pad_items_in_list(a_list, a_character=None):\n    """"""\n    this function will return the same list with the right amount of\n    padding equal to two spaces on each side of the widest string. it\n    will perform right justification.\n\n    if the optional character is specified, then it will do a\n    centering around the character in the process of padding.\n    left/right justification does not work with this option.\n    """"""\n\n    if(a_character != None):\n        for an_item in a_list:\n            if(an_item.find(a_character) == -1):\n                a_character = None\n                break\n\n    if(a_character != None):\n        lmax=0\n        rmax=0\n        for an_item in a_list:\n            an_item = an_item.strip()\n\n            lf = an_item.find(""*"")\n            if(lmax < lf):\n                lmax = lf\n\n            rf = len(an_item) - an_item.find(""*"")\n            if(rmax < rf):\n                rmax = rf\n\n\n\n        i=0\n        for i in range(0, len(a_list)):\n            a_list[i] = a_list[i].strip()\n\n            x = a_list[i].find(a_character)\n\n            len_i=len(a_list[i])\n\n            a_list[i] = "" ""*(lmax-x+2) + a_list[i]\n            a_list[i] = a_list[i] + "" ""*(rmax-len_i+x+2)\n\n    else:\n        max=0\n        for an_item in a_list:\n            an_item = an_item.strip()\n            x = len(an_item)\n            if(max < x):\n                max = x\n\n        i=0\n        for i in range(0, len(a_list)):\n            a_list[i] = a_list[i].strip()\n\n            if(a_list[i].endswith(""*"") or\n               a_list[i].endswith(""-"") or\n               a_list[i][-1] in string.digits ):\n                a_list[i] = ""%s "" % (a_list[i])\n\n            a_list[i] = a_list[i].rjust(max+2)\n\n    return a_list\n\n\n\n\n\n\n\n\n\n\ndef rows2columns(matrix):\n    columns = []\n\n    for row in matrix:\n        c=0\n        for cell in row:\n            if(c == len(columns)):\n                columns.append([])\n\n            columns[c].append(cell)\n            c = c + 1\n\n    return columns\n\n\n\n\n\n\n\n\n\n\ndef pretty_print_table(rows, separator=None, out_file=None):\n\n    # cells is the matrix\n    r_c_matrix = []\n    for row in rows:\n        r_c_matrix.append(row.split())\n\n\n    c_r_matrix = rows2columns(r_c_matrix)\n\n\n    for i in range(0, len(c_r_matrix)):\n\n        if(i==5 or i>10):\n            padding_character=separator\n        else:\n            padding_character=None\n\n        c_r_matrix[i] = pad_items_in_list(c_r_matrix[i], padding_character)\n\n    r_c_matrix = rows2columns(c_r_matrix)\n\n    if(out_file == None):\n        for row in r_c_matrix:\n            print("" "".join(row).strip())\n        print()\n\n    elif(out_file == ""-""):\n        rows=[]\n        for row in r_c_matrix:\n            rows.append("" "".join(row).strip())\n        return ""%s\\n"" % (""\\n"".join(rows))\n\n    else:\n        raise NotImplementedError(""this functionality has not yet been implemented"")\n\n\n\n\n\n\n\n\n\n\ndef start(input_fname, conll_fname, output_fname, encoding, changes=[""--text""]):\n    """""" apply changes in order to the trees in input_fname, write to output_fname """"""\n\n    out_text = False\n    if ""--text"" in changes:\n        out_text = True\n        changes.remove(""--text"")\n\n    out = []\n    with codecs.open(input_fname, ""r"", encoding) as inf:\n\n        for a_tree in iterate_trees(inf):\n            sexpr = parse_sexpr(a_tree)\n            for change in changes:\n                if not sexpr:\n                    continue\n\n                try:\n                    change_func = transformations[change]\n                except KeyError:\n                    raise Exception(""Invalid argument \'%s\' for change.  Allowed changes are: %s"" % (change, transformations.keys()))\n\n                try:\n                    old_sexpr = sexpr[:]\n                    sexpr = change_func(sexpr)\n                except Exception:\n                    sys.stderr.write(""ERR in %s\\n\\nTree:\\n%s\\n\\nInput sexpr:\\n%s\\n"" % (change, a_tree, pp(sexpr)))\n                    raise\n\n\n                if not sexpr and DONT_DELETE_TREES:\n                    nullp = [""XX"", ""nullp""]\n                    if old_sexpr and old_sexpr[0] == ""TOP"":\n                        sexpr = [""TOP"", nullp]\n                    else:\n                        sexpr = nullp\n\n            if sexpr:\n                out.append(pp(sexpr, out_text))\n\n\n\n    w_list = []\n    for o in out:\n        if len(o) != 0:\n            w_list.append(o.split(""\\n""))\n\n    num_words = 0\n    for a_word_list in w_list:\n      for a_word in a_word_list:\n        num_words = num_words + 1\n\n    debug(""number of words: %d\\n"" % (num_words), DEBUG, MAX_VERBOSITY)\n    debug(""input_fname: %s"" % (input_fname), DEBUG, MAX_VERBOSITY)\n\n\n    is_arabic = False\n    a_list_of_lemmas = []\n\n    if re.search(\'data%s+arabic%s+annotations\' % (os.sep, os.sep), input_fname):\n      is_arabic = True\n\n      \n\n\n    if is_arabic is True:\n      lemma_fname = re.sub(""\\.parse$"", "".lemma"", input_fname)\n      debug(""lemma_fname: %s"" % (lemma_fname), DEBUG, MAX_VERBOSITY)\n\n      if os.path.exists(lemma_fname):\n        lemma_file = codecs.open(lemma_fname, ""r"", ""utf-8"")\n\n        actual_word_list = []\n        buckwalter_word_list = []\n        lemma_list = []\n\n        input_string_regex = re.compile(r""^\\s*INPUT STRING:(.*)"", re.U|re.MULTILINE)\n        buckwalter_regex = re.compile(r""^\\s*IS_TRANS:(.*)"", re.U|re.MULTILINE)\n        comment_regex = re.compile(r""^\\s*COMMENT:(.*)"", re.U|re.MULTILINE)\n        index_regex = re.compile(r""^\\s*INDEX:(.*)"", re.U|re.MULTILINE)\n        offsets_regex = re.compile(r""^\\s*OFFSETS:(.*)"", re.U|re.MULTILINE)\n        unvocalized_string_regex = re.compile(r""^\\s*UNVOCALIZED:(.*)"", re.U|re.MULTILINE)\n        vocalized_string_regex = re.compile(r""^\\s*VOCALIZED:(.*)"", re.U|re.MULTILINE)\n        vocalized_input_string_regex = re.compile(r""^\\s*VOC_STRING:(.*)"", re.U|re.MULTILINE)\n        pos_string_regex = re.compile(r""^\\s*POS:(.*)"", re.U|re.MULTILINE)\n        gloss_string_regex = re.compile(r""^\\s*GLOSS:(.*)"", re.U|re.MULTILINE)\n        lemma_regex = re.compile(r""LEMMA:\\s+\\[([^\\]]*)\\]"", re.U|re.MULTILINE)\n\n        lemma_file_lines = lemma_file.readlines()\n\n        list_of_lemma_blocks = []\n\n        i=0\n        lemma_block = """"\n        list_of_lemma_blocks = []\n        while(i<len(lemma_file_lines)):\n          input_string_regex_match = input_string_regex.findall(lemma_file_lines[i])\n\n          if(input_string_regex_match != []):\n            while(i<len(lemma_file_lines) and lemma_file_lines[i].strip() != """"):\n              lemma_block = ""%s%s"" % (lemma_block, lemma_file_lines[i])\n              i=i+1\n\n          if(lemma_block.strip() != """"):\n            list_of_lemma_blocks.append(lemma_block)\n\n          lemma_block = """"\n          i=i+1\n\n\n        list_of_input_strings = []\n        list_of_b_transliterations = []\n        list_of_comments = []\n        list_of_indices = []\n        list_of_offsets = []\n        list_of_unvocalized_strings = []\n        list_of_vocalized_strings = []\n        list_of_vocalized_inputs = []\n        list_of_pos = []\n        list_of_glosses = []\n        list_of_lemmas = []\n\n        for lemma_block in list_of_lemma_blocks:\n          for a_list, a_regex, a_name in [[list_of_input_strings, input_string_regex, ""input""],\n                                          [list_of_b_transliterations, buckwalter_regex, ""transliterations""],\n                                          [list_of_comments, comment_regex, ""comment""],\n                                          [list_of_indices, index_regex, ""indecies""],\n                                          [list_of_offsets, offsets_regex, ""offsets""],\n                                          [list_of_unvocalized_strings, unvocalized_string_regex, ""unvocalized_strings""],\n                                          [list_of_vocalized_strings, vocalized_string_regex, ""vocalized_strings""],\n                                          [list_of_vocalized_inputs, vocalized_input_string_regex, ""vocalized_inputs""],\n                                          [list_of_pos, pos_string_regex, ""pos_strings""],\n                                          [list_of_glosses, gloss_string_regex, ""gloss_strings""],\n                                          [list_of_lemmas, lemma_regex, ""lemmas""]]:\n            try:\n              a_list.append(a_regex.findall(lemma_block)[0])\n            except IndexError:\n              if a_name == ""lemmas"":\n                list_of_lemmas.append(""lemma_not_set"")\n              else:\n                raise Exception(""Didn\'t find any %s in %s (%s)"" % (a_name, (""\\n"" + lemma_block).replace(""\\n"", ""\\n     ""), lemma_fname))\n\n\n\n        # temporarily copying the lists to another list used earlier\n        actual_word_list = [] + list_of_input_strings\n        buckwalter_word_list = [] + list_of_b_transliterations\n        lemma_list = [] + list_of_lemmas\n\n\n        debug(""len(actual_word_list): %s\\n"" % (len(actual_word_list)), DEBUG, MAX_VERBOSITY)\n        debug(""actual_word_list: %s\\n"" % (actual_word_list), DEBUG, MAX_VERBOSITY)\n        debug(""len(buckwalter_word_list): %s\\n"" % (len(buckwalter_word_list)), DEBUG, MAX_VERBOSITY)\n        debug(""buckwalter_word_list: %s\\n"" % (buckwalter_word_list), DEBUG, MAX_VERBOSITY)\n        debug(""len(lemma_list): %s\\n"" % (len(lemma_list)), DEBUG, MAX_VERBOSITY)\n        debug(""lemma_list: %s\\n"" % (lemma_list), DEBUG, MAX_VERBOSITY)\n\n\n\n        if(len(actual_word_list) != len(buckwalter_word_list)\n           or\n           len(actual_word_list) != len(lemma_list)):\n            debug(""len(actual_word_list): %s\\n"" % (len(actual_word_list)), DEBUG, MAX_VERBOSITY)\n            debug(""len(buckwalter_word_list): %s\\n"" % (len(buckwalter_word_list)), DEBUG, MAX_VERBOSITY)\n            debug(""len(lemma_list): %s\\n"" % (len(lemma_list)), DEBUG, MAX_VERBOSITY)\n            raise Exception(""the three lists -- actual word, buckwalter word, and lemma should be the same length, or else some information might be missing from the .lemma file"")\n\n        for i in range(0, len(actual_word_list)):\n            if(lemma_list[i] == ""DEFAULT""\n               or\n               buckwalter_word_list[i] == """"):\n                debug(""%s %s %s\\n"" % (actual_word_list[i].rjust(50), buckwalter_word_list[i].rjust(50), lemma_list[i].rjust(50)), DEBUG, MAX_VERBOSITY)\n\n\n\n\n\n\n        for i in range(0, len(actual_word_list)):\n\n         lemma_lemma = list_of_lemmas[i]\n\n         coarse_sense = """"\n         if ""_"" in lemma_lemma and lemma_lemma != ""lemma_not_set"":\n           try:\n             lemma_lemma, coarse_sense = lemma_lemma.split(""_"")\n           except ValueError:\n             raise \n\n         lemma_object = lemma(list_of_input_strings[i],\n                              list_of_b_transliterations[i],\n                              list_of_comments[i],\n                              list_of_indices[i],\n                              list_of_offsets[i],\n                              list_of_unvocalized_strings[i],\n                              list_of_vocalized_strings[i],\n                              list_of_vocalized_inputs[i],\n                              list_of_pos[i],\n                              list_of_glosses[i],\n                              lemma_lemma, \n                              coarse_sense,\n                              i)\n\n         debug(""lemma_object: %s"" % (lemma_object), DEBUG, MAX_VERBOSITY)\n         a_list_of_lemmas.append(lemma_object)\n\n\n\n\n\n    f=codecs.open(output_fname, ""w"", encoding)\n    f.close()\n\n    sentences = []\n    i=0\n    w=0\n    for line in codecs.open(conll_fname, ""r"", encoding):\n        if line.strip() == """":\n            assert len(sentences) == len(w_list[i]), ""the example should contain the same number of words as the words in the parse""\n\n\n            if(a_list_of_lemmas != []):\n              assert len(a_list_of_lemmas) == num_words, ""the list of lemmas does not match the list of words. please report this issue.""\n\n\n\n            rows=[]\n            c=0\n            for columns in sentences:\n\n                if a_list_of_lemmas != []:\n                    columns[WORD_COLUMN] = ""%s#%s#%s#%s"" % (w_list[i][c], a_list_of_lemmas[w].lemma.strip(), a_list_of_lemmas[w].unvocalized_string.strip(), a_list_of_lemmas[w].vocalized_string.strip())\n\n                    if DEBUG:\n                      if columns[LEMMA_COLUMN] == a_list_of_lemmas[w].lemma.strip():\n                        print(""found the same lemma"")\n                      else:\n                        raise Exception(""Something is wrong: %s %s %s"" % (columns[LEMMA_COLUMN], a_list_of_lemmas[w].lemma.strip(), "" "".join(columns)))\n                      \n                    columns[LEMMA_COLUMN] = a_list_of_lemmas[w].lemma.strip()\n                else:\n                    columns[WORD_COLUMN] = w_list[i][c]\n\n                rows.append("" "".join(columns))\n                c=c+1\n                w=w+1\n\n            pretty_print_table_string = pretty_print_table(rows, out_file=""-"")\n\n            if output_fname == ""-"":\n                print(pretty_print_table_string)\n            else:\n                with codecs.open(output_fname, ""a"", encoding) as outf:\n                    outf.write(""%s\\n"" % (pretty_print_table_string))\n\n            sentences = []\n            i=i+1\n\n        elif(line.startswith(""#"")):\n            if output_fname == ""-"":\n                print(line.strip())\n            else:\n                with codecs.open(output_fname, ""a"", encoding) as outf:\n                    outf.write(""%s\\n"" % (line.strip()))\n        else:\n            sentences.append(line.split())\n\n\nif __name__ == ""__main__"":\n    start(""./data/ldc/bc/cctv/00/cctv_0002.onf"", ""./data/conll-2012/train/bc/cctv/00/cctv_0002.v4_gold_skel"", ""000conll"", ""utf8"")'"
coreference/train.py,9,"b'import os\nimport json\n\nimport argparse\nimport torch\nfrom tqdm import tqdm\nimport torch.optim as optim\nimport numpy as np\nfrom torch.nn.functional import binary_cross_entropy\n\nimport data_loader\nimport const\nimport model\nimport utils\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\'--data\', type=str,\n                    default=os.path.join(const.DATAPATH, ""corpus.pt""))\nparser.add_argument(\'--model_path\', type=str, default=\'weights\')\nparser.add_argument(\'--cuda_device\', type=str, default=\'0\')\nparser.add_argument(\'--epochs\', type=int, default=100)\nparser.add_argument(\'--seed\', type=int, default=1111)\nparser.add_argument(\'--learning_rate\', type=float, default=5e-4)\nparser.add_argument(\'--batch_size\', type=int, default=100)\nparser.add_argument(\'--max_len\', type=int, default=500)\nparser.add_argument(\'--span_len\', type=int, default=4)\nparser.add_argument(\'--d_model\', type=int, default=512)\nparser.add_argument(\'--pos_dim\', type=int, default=20)\nparser.add_argument(\'--n_head\', type=int, default=8)\nparser.add_argument(\'--rnn_hidden_size\', type=int, default=128)\nparser.add_argument(\'--dropout\', type=float, default=0.5)\nargs = parser.parse_args()\n\nos.environ[""CUDA_VISIBLE_DEVICES""] = args.cuda_device\n\nuse_cuda = torch.cuda.is_available()\ncorpus = torch.load(os.path.join(args.data))\nargs.word_ebd_weight = corpus[""wordW""]\nargs.use_cuda = use_cuda\n\ntorch.manual_seed(args.seed)\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\ncorpus = torch.load(args.data)\nargs.wordW = corpus[""wordW""]\n\ntrain_and_test_data = data_loader.DataLoader(\n    const.DATAPATH, corpus[""word2idx""], cuda=use_cuda)\n\nmention_pair_score = model.MentionPairScore(args)\nif use_cuda:\n    mention_pair_score = mention_pair_score.cuda()\n\noptimizer = optim.Adam(mention_pair_score.parameters(), lr=args.learning_rate)\n\n\ndef train(i):\n    mention_pair_score.train()\n    total_loss = corrects = recall = ground_truth = 0\n    for doc in tqdm(train_and_test_data.train_docs, mininterval=1, desc=\'pre-Train Processing\', leave=False):\n        optimizer.zero_grad()\n        scores, labels = mention_pair_score(doc, corpus[""word2idx""])\n        loss = binary_cross_entropy(scores, labels, reduction=\'mean\')\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.data.item()\n        predict = scores.gt(0.5).float()\n        corrects += (predict*labels).sum().item()\n        recall += predict.sum().item()\n        ground_truth += labels.sum().item()\n\n    f1 = 2*corrects/(recall+ground_truth)\n    print(f""train epoch {i+1}/{args.epochs} loss: {total_loss/100:.4f} corrects: {corrects} recall: {recall} ground_truth: {ground_truth} f1: {f1:.4f}"")\n\n\ndef dev(i):\n    mention_pair_score.eval()\n    total_loss = corrects = recall = ground_truth = 0\n\n    for doc in tqdm(train_and_test_data.test_docs, mininterval=1, desc=\'pre-Dev Processing\', leave=False):\n        with torch.no_grad():\n            scores, labels = mention_pair_score(doc, corpus[""word2idx""])\n            loss = binary_cross_entropy(scores, labels, reduction=\'mean\')\n            total_loss += loss.data.item()\n            predict = scores.gt(0.5).float()\n            corrects += (predict*labels).sum().item()\n            recall += predict.sum().item()\n            ground_truth += labels.sum().item()\n\n    f1 = 2*corrects/(recall+ground_truth)\n    print(f""dev epoch {i+1}/{args.epochs} loss: {total_loss/len(train_and_test_data.test_docs):.4f} corrects: {corrects} recall: {recall} ground_truth: {ground_truth} f1: {f1:.4f}"")\n    return f1\n\n\ndef save():\n    model_state_dict = mention_pair_score.state_dict()\n    model_source = {\n        ""settings"": args,\n        ""model"": model_state_dict,\n        ""word2idx"": corpus[\'word2idx\'],\n    }\n    torch.save(\n        model_source, f""{os.path.join(args.model_path, \'pretrain_model.pt\')}"")\n\n\nos.makedirs(args.model_path, exist_ok=True)\nbest_f1 = 0\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(args.epochs):\n        train(epoch)\n        print(\'-\' * 90)\n        f1 = dev(epoch)\n        print(\'-\' * 90)\n        if f1 >= best_f1:\n            print(f""new best f1 score {f1:.4f} and save model"")\n            best_f1 = f1\n            mention_pair_score.save_model(\n                f""{os.path.join(args.model_path, \'middle_pretrain_model.pt\')}"")\n            save()\n        else:\n            print(\n                f""f1 score {f1:.4f} and reload best model best f1 {best_f1:.4f}"")\n            mention_pair_score.load_model(\n                f""{os.path.join(args.model_path, \'middle_pretrain_model.pt\')}"", use_cuda)\n        print(\'-\' * 90)\nexcept KeyboardInterrupt:\n    print(""Exiting from training early"")\n'"
coreference/utils.py,5,"b'import io\nfrom collections import defaultdict\nfrom copy import deepcopy\nimport random\nimport re\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\nimport const\n\ndef load_pre_w2c(_file, word2idx, char2idx):\n    w2c_dict = {}\n    print(""loading word2vec"")\n    for line in open(_file):\n        temp = line.strip().split("" "")\n\n        if len(temp) < 10:\n            continue\n        w2c_dict[temp[0]] = list(map(float, temp[1:]))\n\n        if ""len_"" not in locals():\n            len_ = len(temp[1:])\n\n    print(f""load {len(w2c_dict)} lines word2vec"")\n\n    wordW = np.random.rand(len(word2idx), len_)\n    for word, idx in sorted(word2idx.items(), key=lambda x: x[1]):\n        if word in w2c_dict:\n            wordW[idx] = np.asarray(w2c_dict[word])\n\n    charW = np.random.rand(len(char2idx), len_)\n    for word, idx in sorted(char2idx.items(), key=lambda x: x[1]):\n        if word in w2c_dict:\n            charW[idx] = np.asarray(w2c_dict[word])\n\n    return wordW, charW\n\ndef is_chinese_char(c):\n    if ((c >= 0x4E00 and c <= 0x9FFF) or\n            (c >= 0x3400 and c <= 0x4DBF) or\n            (c >= 0x20000 and c <= 0x2A6DF) or\n            (c >= 0x2A700 and c <= 0x2B73F) or\n            (c >= 0x2B740 and c <= 0x2B81F) or\n            (c >= 0x2B820 and c <= 0x2CEAF) or\n            (c >= 0xF900 and c <= 0xFAFF) or\n            (c >= 0x2F800 and c <= 0x2FA1F)):\n        return True\n    return False\n\n\ndef clean_token(token):\n    if token in [\'.\', \'?\', \'!\', ""\xe3\x80\x82"", \'\xef\xbc\x9f\', \'\xef\xbc\x81\']:\n        return token\n\n    token = \'\'.join(c for c in token if is_chinese_char(ord(c)))\n    if token:\n        return token\n\n    return const.WORD[const.UNK]\n\ndef load_file(filename):\n    """""" Load a *._conll file\n    Input:\n        filename: path to the file\n    Output:\n        documents: list of Document class for each document in the file containing:\n            tokens:                   split list of text\n            utts_corefs:\n                coref[\'label\']:     id of the coreference cluster\n                coref[\'start\']:     start index (index of first token in the utterance)\n                coref[\'end\':        end index (index of last token in the utterance)\n                coref[\'span\']:      corresponding span\n            utts_speakers:          list of speakers\n            genre:                  genre of input\n    """"""\n    documents = []\n    with io.open(filename, \'rt\', encoding=\'utf-8\', errors=\'strict\') as f:\n        tokens, text, utts_corefs, corefs, index = [], [], [], [], 0\n        for line in f:\n            cols = line.split()\n\n            # End of utterance within a document: update lists, reset variables for next utterance.\n            if len(cols) == 0:\n                if text:\n                    tokens.extend(text), utts_corefs.extend(corefs)\n                    text, corefs = [], []\n                    continue\n\n            # End of document: organize the data, append to output, reset variables for next document.\n            elif len(cols) == 2:\n                doc = Document(tokens, utts_corefs, filename)\n                documents.append(doc)\n                tokens, text, utts_corefs, index = [], [], [], 0\n\n            # Inside an utterance: grab text, speaker, coreference information.\n            elif len(cols) > 7:\n                text.append(clean_token(cols[3]))\n\n                # If the last column isn\'t a \'-\', there is a coreference link\n                if cols[-1] != u\'-\':\n                    coref_expr = cols[-1].split(u\'|\')\n                    for token in coref_expr:\n\n                        # Check if coref column token entry contains (, a number, or ).\n                        match = re.match(r""^(\\(?)(\\d+)(\\)?)$"", token)\n                        label = match.group(2)\n\n                        # If it does, extract the coref label, its start index,\n                        if match.group(1) == u\'(\':\n                            corefs.append({\'label\': label,\n                                           \'start\': index,\n                                           \'end\': None})\n\n                        if match.group(3) == u\')\':\n                            for i in range(len(corefs)-1, -1, -1):\n                                if corefs[i][\'label\'] == label and corefs[i][\'end\'] is None:\n                                    break\n\n                            # Extract the end index, include start and end indexes in \'span\'\n                            corefs[i].update({\'end\': index,\n                                              \'span\': (corefs[i][\'start\'], index)})\n\n                index += 1\n            else:\n\n                # Beginning of Document, beginning of file, end of file: nothing to scrape off\n                continue\n\n    return documents\n\nclass Document(object):\n\n    dots = [\'.\', \'?\', \'!\', ""\xe3\x80\x82"", \'\xef\xbc\x9f\', \'\xef\xbc\x81\']\n    bins = [1,2,3,4,8,16,32,64]\n\n    def __init__(self, tokens, corefs, filename, max_len=500, span_len=4):\n        self.tokens = tokens\n        self.corefs = corefs\n        self.filename = filename\n        self.max_len = max_len\n        self.span_len = span_len\n        if len(self) > max_len:\n            self.tokens = self.tokens[:max_len]\n\n    def __len__(self):\n        return len(self.tokens)\n\n    def mentions(self, word2idx):\n        core_dict = defaultdict(list)\n        for coref in self.corefs:\n            if coref[""end""] < self.max_len:\n                core_dict[coref[""label""]].append(coref)        \n\n        self.mentions = []\n        for label, mentions in core_dict.items():\n            mentions.sort(key=lambda x: x[""end""], reverse=True)\n            idx = 0\n            while idx < len(mentions)-1:\n                start_idx = max(mentions[idx][""start""], mentions[idx][""end""]+1-self.span_len)\n                if sum([1 if w in word2idx else 0 for w in self.tokens[start_idx: mentions[idx][""end""]+1]]) == 0:\n                    idx += 1\n                else:\n                    mention = mentions[idx][\'span\']\n                    corefs = [m[""span""] for m in mentions[idx+1:]]\n                    uncorefs = []\n                    for other_label, other_mentions in core_dict.items():\n                        if other_label != label:\n                            uncorefs += [m[""span""] for m in other_mentions if m[""end""] <= mention[0]]\n                    self.mentions.append(Mention(mention, corefs, uncorefs))\n                    break\n            \n    def tokens2tensor(self, use_cuda, word2idx):\n        self.token_tensors = torch.LongTensor([word2idx[w] if w in word2idx else const.UNK for w in self.tokens])\n        if use_cuda:\n            self.token_tensors = self.token_tensors.cuda()\n\n    def pos2tensor(self, use_cuda):\n        pos = np.array([pos_i+1 for pos_i in range(len(self))])\n        pos = torch.from_numpy(pos)\n        if use_cuda:\n            pos = pos.cuda()\n        return pos.long()\n\n    def span2tonsor(self, word2idx):\n        corefs_idxs, mention_idxs, mention_spans, labels, distances, corefs = [], [], [], [], [], []\n\n        for mention in self.mentions:\n            mention_start_idx, mention_end_idx = mention.mention_span\n            mention_start_idx = max(mention_end_idx + 1 - self.span_len, mention_start_idx)\n            mention_idx = (mention_start_idx, mention_end_idx)\n\n            mention_span = [word2idx[w] if w in word2idx else const.UNK for w in self.tokens[\n                mention_start_idx: mention_end_idx+1]] + [const.PAD] * (self.span_len-(mention_end_idx-mention_start_idx+1))\n            \n            for (coref_start_idx, coref_end_idx) in mention.corefs:\n                coref_start_idx = max(coref_start_idx, coref_end_idx + 1 - self.span_len)\n                if coref_start_idx == mention_start_idx and coref_end_idx == mention_end_idx:\n                    continue\n\n                # unk\xe8\xbf\x87\xe6\xbb\xa4:\n                if sum([1 if w in word2idx else 0 for w in self.tokens[coref_start_idx: coref_end_idx+1]]) == 0:\n                    continue                \n\n                coref_idx = (coref_start_idx, coref_end_idx)\n                coref_span = [word2idx[w] if w in word2idx else const.UNK for w in self.tokens[\n                    coref_start_idx: coref_end_idx+1]] + [const.PAD] * (self.span_len-(coref_end_idx-coref_start_idx+1))                \n         \n                corefs_idxs.append(coref_idx)\n                mention_idxs.append(mention_idx)\n                mention_spans.append(mention_span)\n                labels.append(1)\n                corefs.append(coref_span)\n\n                length = mention_start_idx-coref_end_idx+1\n                distances.append(sum([True for i in self.bins if length >= i]))\n\n            for (coref_start_idx, coref_end_idx) in mention.uncorefs:\n                coref_start_idx = max(coref_start_idx, coref_end_idx + 1 - self.span_len)\n                if coref_start_idx == mention_start_idx and coref_end_idx == mention_end_idx:\n                    continue\n\n                # unk\xe8\xbf\x87\xe6\xbb\xa4:\n                if sum([1 if w in word2idx else 0 for w in self.tokens[coref_start_idx: coref_end_idx+1]]) == 0:\n                    continue                    \n\n                coref_idx = (coref_start_idx, coref_end_idx)\n                coref_span = [word2idx[w] if w in word2idx else const.UNK for w in self.tokens[\n                    coref_start_idx: coref_end_idx+1]] + [const.PAD] * (self.span_len-(coref_end_idx-coref_start_idx+1))                \n         \n                corefs_idxs.append(coref_idx)\n                mention_idxs.append(mention_idx)\n                mention_spans.append(mention_span)\n                labels.append(0)\n                corefs.append(coref_span)\n\n                length = mention_start_idx-coref_end_idx+1\n                distances.append(sum([True for i in self.bins if length >= i]))       \n\n        self.mention_spans = np.asarray(mention_spans)\n        self.labels = np.asarray(labels)\n        self.corefs = np.asarray(corefs)\n        self.distances = np.asarray(distances)\n        self.corefs_idxs = np.asarray(corefs_idxs)\n        self.mention_idxs = np.asarray(mention_idxs)\n\n    def sample(self, use_cuda, numbers):\n        choice = np.random.choice(np.arange(self.mention_spans.shape[0]), min(numbers, self.mention_spans.shape[0]))\n\n        mention_spans = self.mention_spans[choice] \n        labels = self.labels[choice] \n        corefs = self.corefs[choice] \n        distances = self.distances[choice] \n        corefs_idxs = self.corefs_idxs[choice] \n        mention_idxs = self.mention_idxs[choice] \n\n        mention_spans, labels, distances, corefs = map(torch.from_numpy, (mention_spans, labels, distances, corefs))\n\n        mention_spans, distances, corefs = map(lambda x: x.long(), (mention_spans, distances, corefs))     \n        labels = labels.float()   \n\n        if use_cuda:\n            mention_spans, labels, distances, corefs = map(lambda x: x.cuda(), (mention_spans, labels, distances, corefs))\n\n        return corefs_idxs, mention_idxs, mention_spans, labels, distances, corefs\n\nclass Mention(object):\n    def __init__(self, mention_span, corefs, uncorefs):\n        self.mention_span = mention_span\n        self.corefs = corefs\n        self.uncorefs = uncorefs\n\n\nif __name__ == ""__main__"":\n    import torch, os\n    documents = load_file(""./data/train/cbs_0001.conll"")\n    corpus = torch.load(os.path.join(const.DATAPATH, ""corpus.pt""))\n\n    doc = documents[0]\n    doc.tokens2tensor(False, corpus[""word2idx""])\n    print(len(doc))    \n\n    idx2word = {v:k for k, v in corpus[""word2idx""].items()}\n    idxs = doc.token_tensors.tolist()\n    print("" "".join([idx2word[idx] for idx in idxs]))\n\n    doc.mentions(corpus[""word2idx""])\n\n    print(""=""*50)\n    for mention in doc.mentions:\n        print("" "".join(idx2word[idx] for idx in idxs[mention.mention_span[0]:mention.mention_span[1]+1]))\n        for core in mention.corefs:\n            print("" "".join(idx2word[idx] for idx in idxs[core[0]:core[1]+1]))        \n        print(""=""*50)\n\n    doc.span2tonsor(corpus[""word2idx""])\n\n    corefs_idxs, mention_idxs, mention_spans, labels, distances, corefs = doc.sample(False, 1)\n    print(corefs_idxs, mention_idxs, distances)'"
dc-gan/data_loader.py,2,"b'import os\n\nimport torch\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import transforms\n\nfrom PIL import Image\n\nclass Data_loader(object):\n    def __init__(self, path, img_size, batch_size, is_cuda):\n        self._img_files = os.listdir(path)\n        self._path = path\n        self._is_cuda = is_cuda\n        self._step = 0\n        self._batch_size = batch_size\n        self.sents_size = len(self._img_files)\n        self._stop_step = self.sents_size // batch_size\n\n        self._encode = transforms.Compose([\n                            transforms.Scale(img_size),\n                            transforms.RandomCrop(img_size),\n                            transforms.ToTensor()\n                        ])\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def img2variable(img_files):\n            tensors = [self._encode(Image.open(self._path + img_name)).unsqueeze(0)\n                    for img_name in img_files]\n            v = Variable(torch.cat(tensors, 0))\n            if self._is_cuda: v = v.cuda()\n            return v\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step*self._batch_size\n        self._step += 1\n\n        return img2variable(self._img_files[_start:_start+self._batch_size])\n\n    def gen_image(self, g_out, epoch):\n        torchvision.utils.save_image(g_out.data, \'images/epoch_{}.jpg\'.format(epoch))\n\nif __name__ == ""__main__"":\n    dl = Data_loader(\'data/\', 64, 64, True)\n    print(dl.sents_size)\n    for img, bsz in dl:\n        continue'"
dc-gan/model.py,6,"b'import torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom torch.autograd import Variable\r\n\r\nimport numpy as np\r\n\r\ndef conv_size(args):\r\n\ttry:\r\n\t\treduce\r\n\texcept NameError:\r\n\t\tfrom functools import reduce\r\n\t\r\n\tout_size, num_filter = args\r\n\t_size = [out_size] + [2] * num_filter\r\n\treturn reduce(lambda x, y: x // y, _size)\r\n\r\ndef gen_z(batch_size, z_dim, is_cuda, eval=False):\r\n\tz = torch.from_numpy(\r\n\t\tnp.random.normal(size=(batch_size, z_dim)))\r\n\r\n\tz = Variable(z.float(), volatile=eval)\r\n\tif is_cuda:\r\n\t\tz = z.cuda()\r\n\r\n\treturn z\r\n\r\nclass Generator(nn.Module):\r\n\tdef __init__(self, out_h, out_w, channel_dims, z_dim=100):\r\n\t\tsuper().__init__()\r\n\r\n\t\tassert len(channel_dims) == 4, ""length of channel dims should be 4""\r\n\r\n\t\tconv1_dim, conv2_dim, conv3_dim, conv4_dim = channel_dims\r\n\t\tconv1_h, conv2_h, conv3_h, conv4_h = map(conv_size, [(out_h, step) for step in [4 ,3 ,2 ,1]])\r\n\t\tconv1_w, conv2_w, conv3_w, conv4_w = map(conv_size, [(out_w, step) for step in [4 ,3 ,2 ,1]])\r\n\r\n\t\tself.fc = nn.Linear(z_dim, conv1_dim*conv1_h*conv1_w)\r\n\t\tself.deconvs = nn.Sequential(\r\n\t\t\t\tnn.BatchNorm2d(conv1_dim),\r\n\t\t\t\tnn.ReLU(),\r\n\r\n\t\t\t\tnn.ConvTranspose2d(conv1_dim, conv2_dim, kernel_size=4, stride=2, padding=1, bias=False),\r\n\t\t\t\tnn.BatchNorm2d(conv2_dim),\r\n\t\t\t\tnn.ReLU(),\r\n\r\n\t\t\t\tnn.ConvTranspose2d(conv2_dim, conv3_dim, kernel_size=4, stride=2, padding=1, bias=False),\r\n\t\t\t\tnn.BatchNorm2d(conv3_dim),\r\n\t\t\t\tnn.ReLU(),\t\r\n\r\n\t\t\t\tnn.ConvTranspose2d(conv3_dim, conv4_dim, kernel_size=4, stride=2, padding=1, bias=False),\r\n\t\t\t\tnn.BatchNorm2d(conv4_dim),\r\n\t\t\t\tnn.ReLU(),\t\t\t\r\n\r\n\t\t\t\tnn.ConvTranspose2d(conv4_dim, 3, kernel_size=4, stride=2, padding=1, bias=False),\t\r\n\t\t\t\tnn.Tanh(),\t\t\t\t\t\t\t\r\n\t\t\t)\r\n\t\tself.conv1_size = (conv1_dim, conv1_h, conv1_w)\r\n\r\n\t\tself._init_weight()\r\n\r\n\tdef _init_weight(self):\r\n\t\tself.fc.weight.data.normal_(.0, 0.02)\r\n\t\tfor layer in self.deconvs:\r\n\t\t\tif isinstance(layer, nn.ConvTranspose2d):\r\n\t\t\t\tlayer.weight.data.normal_(.0, 0.02)\r\n\t\t\tif isinstance(layer, nn.BatchNorm2d):\r\n\t\t\t\tlayer.weight.data.normal_(1., 0.02)\r\n\t\t\t\tlayer.bias.data.fill_(0)\r\n\r\n\tdef forward(self, z):\r\n\t\tout = self.fc(z)\r\n\t\tout = out.view(-1, *self.conv1_size)\r\n\t\treturn self.deconvs(out)\r\n\r\nclass Discriminator(nn.Module):\r\n\tdef __init__(self, out_h, out_w, channel_dims, relu_leak):\r\n\t\tsuper().__init__()\r\n\r\n\t\tassert len(channel_dims) == 4, ""length of channel dims should be 4""\r\n\r\n\t\tconv4_dim, conv3_dim, conv2_dim, conv1_dim = channel_dims\r\n\t\tconv4_h, conv3_h, conv2_h, conv1_h = map(conv_size, [(out_h, step) for step in [4 ,3 ,2 ,1]])\r\n\t\tconv4_w, conv3_w, conv2_w, conv1_w = map(conv_size, [(out_w, step) for step in [4 ,3 ,2 ,1]])\r\n\r\n\t\tself.convs = nn.Sequential(\r\n\t\t\t\tnn.Conv2d(3, conv1_dim, kernel_size=4, stride=2, padding=1, bias=False),\r\n\t\t\t\tnn.LeakyReLU(relu_leak),\r\n\r\n\t\t\t\tnn.Conv2d(conv1_dim, conv2_dim, kernel_size=4, stride=2, padding=1, bias=False),\r\n\t\t\t\tnn.BatchNorm2d(conv2_dim),\r\n\t\t\t\tnn.LeakyReLU(relu_leak),\t\r\n\r\n\t\t\t\tnn.Conv2d(conv2_dim, conv3_dim, kernel_size=4, stride=2, padding=1, bias=False),\r\n\t\t\t\tnn.BatchNorm2d(conv3_dim),\r\n\t\t\t\tnn.LeakyReLU(relu_leak),\t\r\n\r\n\t\t\t\tnn.Conv2d(conv3_dim, conv4_dim, kernel_size=4, stride=2, padding=1, bias=False),\t\r\n\t\t\t\tnn.BatchNorm2d(conv4_dim),\r\n\t\t\t\tnn.LeakyReLU(relu_leak),\t\t\t\t\t\t\r\n\t\t\t)\r\n\r\n\t\tself.fc = nn.Linear(conv4_dim*conv4_h*conv4_w, 1)\r\n\t\tself.fc_dim = conv4_dim*conv4_h*conv4_w\r\n\r\n\t\tself._init_weight()\r\n\r\n\tdef _init_weight(self):\r\n\t\tself.fc.weight.data.normal_(.0, 0.02)\r\n\t\tfor layer in self.convs:\r\n\t\t\tif isinstance(layer, nn.Conv2d):\r\n\t\t\t\tlayer.weight.data.normal_(.0, 0.02)\r\n\t\t\tif isinstance(layer, nn.BatchNorm2d):\r\n\t\t\t\tlayer.weight.data.normal_(1., 0.02)\r\n\t\t\t\tlayer.bias.data.fill_(0)\r\n\r\n\tdef forward(self, input):\r\n\t\tout = self.convs(input)\r\n\t\tlinear = self.fc(out.view(-1, self.fc_dim))\r\n\t\treturn F.sigmoid(linear)\r\n\r\n\r\nif __name__ == \'__main__\':\r\n\tfrom torch.autograd import Variable\r\n\r\n\tinput = Variable(torch.randn((2, 100)))\r\n\tg = Generator(64, 64, [512,256,128,64])\r\n\r\n\tout = g(input)\r\n\tprint(out)\r\n\r\n\td = Discriminator(64, 64, [512,256,128,64], 0.2)\r\n\tout = d(out)\r\n\tprint(out)\r\n\r\n\tz = gen_z(4, 100, True)\r\n\tprint(z)\r\n'"
dc-gan/train.py,7,"b""import argparse\r\n\r\nparser = argparse.ArgumentParser(description='DC-Gan')\r\nparser.add_argument('--seed', type=int, default=1111)\r\nparser.add_argument('--unuse_cuda', action='store_true')\r\nparser.add_argument('--path', type=str, default='data/')\r\nparser.add_argument('--lr', type=float, default=0.0002)\r\nparser.add_argument('--beta1', type=float, default=0.5)\r\nparser.add_argument('--epochs', type=int, default=40)\r\nparser.add_argument('--batch_size', type=int, default=64)\r\nparser.add_argument('--relu_leak', type=float, default=0.2)\r\nparser.add_argument('--img_size', type=int, default=64)\r\nparser.add_argument('--z_dim', type=int, default=128)\r\nparser.add_argument('--channel_dims', type=str, default='512,256,128,64')\r\n\r\nargs = parser.parse_args()\r\n\r\nimport torch\r\n\r\ntorch.manual_seed(args.seed)\r\nuse_cuda = torch.cuda.is_available() and not args.unuse_cuda\r\n\r\nargs.channel_dims = list(map(int, args.channel_dims.split(',')))\r\n\r\nif use_cuda:\r\n    torch.cuda.manual_seed(args.seed)\r\n\r\n# ##############################################################################\r\n# Load data\r\n################################################################################\r\nfrom data_loader import Data_loader\r\n\r\nreal_datas = Data_loader('data/', args.img_size, args.batch_size, use_cuda)\r\n\r\n# ##############################################################################\r\n# Build model\r\n# ##############################################################################\r\nimport model\r\n\r\nG = model.Generator(args.img_size, args.img_size, args.channel_dims, args.z_dim)\r\nD = model.Discriminator(args.img_size, args.img_size, args.channel_dims, args.relu_leak)\r\nif use_cuda:\r\n    G, D = G.cuda(), D.cuda()\r\n\r\noptimizer_D = torch.optim.Adam(D.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\r\noptimizer_G = torch.optim.Adam(G.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\r\ncriterion = torch.nn.BCELoss()\r\n\r\n# ##############################################################################\r\n# Training\r\n# ##############################################################################\r\nreal_label, fake_label = 1, 0\r\n\r\ndef train():\r\n    loss_g = loss_d = 0\r\n    for real_data in tqdm(real_datas, mininterval=1,\r\n            desc='Train Processing', leave=False):\r\n        D.zero_grad()\r\n        real_out = D(real_data)\r\n        real_target = Variable(real_data.data.new(args.batch_size, 1).fill_(real_label))\r\n        real_loss_d = criterion(real_out, real_target)\r\n        real_loss_d.backward()\r\n\r\n        z_input = model.gen_z(args.batch_size, args.z_dim, use_cuda)\r\n        g_out = G(z_input)\r\n        fake_out = D(g_out.detach())\r\n        fake_target = Variable(real_data.data.new(args.batch_size, 1).fill_(fake_label))\r\n        fake_loss_d = criterion(fake_out, fake_target)\r\n        fake_loss_d.backward()\r\n        optimizer_D.step()\r\n\r\n        G.zero_grad()\r\n        out = D(g_out)\r\n        target = Variable(real_data.data.new(args.batch_size, 1).fill_(real_label))\r\n        loss = criterion(out, target)\r\n        loss.backward()\r\n        optimizer_G.step()\r\n\r\n        loss_d += fake_loss_d.data + real_loss_d.data\r\n        loss_g += loss.data\r\n\r\n    return loss_g[0], loss_d[0]\r\n\r\nfrom torch.autograd import Variable        \r\nfrom tqdm import tqdm\r\nimport time\r\n\r\nloss_ds, loss_gs = [], []\r\nfor epoch in range(1, args.epochs+1):\r\n    start_time = time.time()\r\n    G.train()\r\n    D.train()\r\n    loss_g, loss_d = train()\r\n\r\n    print('| epoch {:3d} | time: {:2.2f}s | D loss {:5.6f} | G loss {:5.6f}'.format(epoch, time.time() - start_time, loss_d, loss_g))\r\n    loss_ds.append(loss_d)\r\n    loss_gs.append(loss_g)\r\n    if epoch % 2 == 0:\r\n        G.eval()\r\n        g_out = G(model.gen_z(64, args.z_dim, use_cuda, True))\r\n        real_datas.gen_image(g_out, epoch)"""
deep-srl/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    UNK: '<unk>',\n    PAD: '<pad>'\n}\n\nSTART = 1\nSTOP = 2\n"""
deep-srl/corpus.py,1,"b'import torch\n\nimport logging\nimport argparse\nimport os\nimport copy\nimport re\n\nfrom const import *\n\n\ndef normalizeString(s):\n    s = s.lower().strip()\n    try:\n        float(s)\n        return ""@""\n    except:\n        return s\n\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\n\nclass Dictionary(object):\n    def __init__(self, word2idx={}, idx_num=0):\n        self.word2idx = word2idx\n        self.idx = idx_num\n\n    def _add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def _convert(self):\n        self.idx2word = {v: k for k, v in self.word2idx.items()}\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Words(Dictionary):\n    def __init__(self):\n        word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        super().__init__(word2idx=word2idx, idx_num=len(word2idx))\n\n    def __call__(self, sents):\n        words = set([word for sent in sents for word in sent])\n        for word in words:\n            self._add(word)\n\n\nclass Labels(Dictionary):\n    def __init__(self):\n        word2idx = {\n            WORD[PAD]: PAD\n        }\n        super().__init__(word2idx=word2idx, idx_num=len(word2idx))\n\n    def __call__(self, labels):\n        _labels = set([l for label in labels for l in label])\n        for label in _labels:\n            self._add(label)\n\n\nclass Corpus(object):\n    def __init__(self, path, save_data, word_max_len=32, label_tag=3):\n\n        self.train = os.path.join(path, ""train"")\n        self.valid = os.path.join(path, ""testa"")\n        self._save_data = save_data\n        self._label_tag = label_tag\n        self.coutinue_tag = \'-DOCSTART-\'\n\n        self.w = Words()\n        self.l = Labels()\n        self.word_max_len = word_max_len\n\n        self.save()\n\n    def parse_data(self, inf, is_train=True):\n        sents, labels = [], []\n        _words, _labels = [], []\n        for sentence in open(inf):\n            if sentence == \'\\n\':\n                if len(_words) == 0:\n                    continue\n                sents.append(_words.copy())\n                labels.append(_labels.copy())\n                _words, _labels = [], []\n                continue\n            temp = sentence.strip().split(\' \')\n\n            label, word = temp[self._label_tag].strip(), temp[0].strip()\n            if word == self.coutinue_tag:\n                continue\n\n            _words += [normalizeString(word)]\n            _labels += [label]\n\n        out_of_range_sents = 0\n        for index, words in enumerate(sents):\n            if len(words) > self.word_max_len:\n                out_of_range_sents += 1\n                sents[index] = words[:self.word_max_len]\n                labels[index] = labels[index][:self.word_max_len]\n\n        if is_train:\n            self.w(sents)\n            self.l(labels)\n            self.train_sents = sents\n            self.train_labels = labels\n        else:\n            self.valid_sents = sents\n            self.valid_labels = labels\n\n        print(f""parse down, out of range sents - {out_of_range_sents}"")\n\n    def save(self):\n        self.parse_data(self.train)\n        self.parse_data(self.valid, False)\n        data = {\n            \'word_max_len\': self.word_max_len,\n            \'dict\': {\n                \'word\': self.w.word2idx,\n                \'word_size\': len(self.w),\n                \'label\': self.l.word2idx,\n                \'label_size\': len(self.l),\n            },\n            \'train\': {\n                \'word\': word2idx(self.train_sents, self.w.word2idx),\n                \'label\': word2idx(self.train_labels, self.l.word2idx)\n            },\n            \'valid\': {\n                \'word\': word2idx(self.valid_sents, self.w.word2idx),\n                \'label\': word2idx(self.valid_labels, self.l.word2idx)\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'Finish dumping the data to file - [{}]\'.format(self._save_data))\n        print(\'words length - [{}]\'.format(len(self.w)))\n        print(\'labels - [{}]\'.format(self.l.word2idx))\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--file_path\', type=str, default=""./data"")\n    parser.add_argument(\'--save_data\', type=str, default=""data/corpus.pt"")\n    parser.add_argument(\'--word_max_lenth\', type=int, default=40)\n    args = parser.parse_args()\n    Corpus(args.file_path, args.save_data, args.word_max_lenth)\n'"
deep-srl/data_loader.py,2,"b'import numpy as np\nimport torch\n\nimport const\n\n\nclass DataLoader(object):\n    def __init__(self, sents, label, cuda=True, batch_size=64, shuffle=True):\n        self.cuda = cuda\n        self.sents_size = len(sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size\n\n        self.bsz = batch_size\n        self._sents = np.asarray(sents)\n        self._label = np.asarray(label)\n\n        if shuffle:\n            self._shuffle()\n\n    def _shuffle(self):\n        indices = np.arange(self._sents.shape[0])\n        np.random.shuffle(indices)\n        self._sents = self._sents[indices]\n        self._label = self._label[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def to_tensor(insts):\n            max_len = max(len(inst) for inst in insts)\n            inst_data = np.array(\n                [inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n            inst_data_tensor = torch.from_numpy(inst_data)\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n\n            return inst_data_tensor\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        start = self._step * self.bsz\n        self._step += 1\n\n        word = to_tensor(self._sents[start:start + self.bsz])\n        label = to_tensor(self._label[start:start + self.bsz])\n        return word, label.view(-1)\n\n\nif __name__ == ""__main__"":\n    data = torch.load(""data/corpus.pt"")\n    training_data = DataLoader(\n        data[\'train\'][\'word\'],\n        data[\'train\'][\'label\'],\n        cuda=False,\n        batch_size=2,\n        shuffle=False)\n    print(data[""dict""][""label""])\n    word, label = next(training_data)\n    word = word.tolist()\n    d = {v: k for k, v in data[""dict""][""word""].items()}\n    for w in word:\n        print([d[x] for x in w])\n    print(label.shape[0])\n\n    print(training_data.sents_size)\n    print(training_data._sents.shape)\n'"
deep-srl/example.py,5,"b'import torch\n\nfrom const import *\nfrom model import *\n\n\nclass Predict(object):\n    def __init__(self, model_source, cuda=False):\n        self.torch = torch.cuda if cuda else torch\n        self.cuda = cuda\n        if self.cuda:\n            model_source = torch.load(model_source)\n        else:\n            model_source = torch.load(\n                model_source, map_location=lambda storage, loc: storage)\n\n        self.dict = model_source[""word_dict""]\n        self.label = model_source[""label_dict""]\n        self.args = args = model_source[""settings""]\n\n        model = DeepBiLSTMModel(args.word_size, args.label_size, args.word_ebd_dim,\n                                args.lstm_hsz, args.lstm_layers, args.recurrent_dropout_prob, cuda)\n        model.load_state_dict(model_source[\'model\'])\n\n        if self.cuda:\n            model = model.cuda()\n        else:\n            model = model.cpu()\n\n        self.model = model.eval()\n\n\nif __name__ == ""__main__"":\n    from data_loader import DataLoader\n\n    p = Predict(""weights/model_22.pt"", True)\n\n    data = torch.load(""data/corpus.pt"")\n    validation_data = DataLoader(data[\'train\'][\'word\'],\n                                 data[\'train\'][\'label\'],\n                                 cuda=True,\n                                 shuffle=True,\n                                 batch_size=2)\n\n    d = {v: k for k, v in data[""dict""][""word""].items()}\n    l = {v: k for k, v in data[""dict""][""label""].items()}\n    words, label = next(validation_data)\n    pred = p.model(words)\n    score, idxs = torch.max(pred, 1)\n\n    for word in words.tolist():\n        print("" "".join([d[w] for w in word]))\n        print()\n\n    idxs = idxs.view(2, -1)\n    for idx in idxs.tolist():\n        print("" "".join([l[_id] for _id in idx]))\n        print()\n\n    label = label.view(2, -1)\n    for idx in label.tolist():\n        print("" "".join([l[_id] for _id in idx]))\n        print()\n'"
deep-srl/model.py,12,"b'import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\n\nfrom const import *\n\n\nclass RnnDropout(nn.Module):\n    def __init__(self, dropout_prob, hidden_size, is_cuda):\n        super().__init__()\n\n        self.mask = torch.bernoulli(torch.Tensor(\n            1, hidden_size).fill_(1. - dropout_prob))\n        if is_cuda:\n            self.mask = self.mask.cuda()\n        self.dropout_prob = dropout_prob\n\n    def forward(self, input):\n        input = input * self.mask\n        input *= 1. / (1. - self.dropout_prob)\n\n        return input\n\n\nclass HwLSTMCell(nn.Module):\n    def __init__(self, isz, hsz, dropout_prob, is_cuda):\n        super().__init__()\n\n        self.hsz = hsz\n\n        self.w_ih = nn.Parameter(torch.Tensor(6 * hsz, isz))\n        self.w_hh = nn.Parameter(torch.Tensor(5 * hsz, hsz))\n        self.b_ih = nn.Parameter(torch.Tensor(6 * hsz))\n\n        self.rdropout = RnnDropout(dropout_prob, hsz, is_cuda)\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        stdv = 1.0 / math.sqrt(self.hsz)\n        for weight in self.parameters():\n            nn.init.uniform_(weight, -stdv, stdv)\n\n    def forward(self, input, hidden=None):\n        if hidden is None:\n            hidden = input.new_zeros(input.size(0), self.hsz)\n            hidden = (hidden, hidden)\n\n        hx, cx = hidden\n\n        input = F.linear(input, self.w_ih, self.b_ih)\n        gates = F.linear(hx, self.w_hh) + input[..., :-self.hsz]\n\n        in_gate, forget_gate, cell_gate, out_gate, r_gate = gates.chunk(5, 1)\n        in_gate, forget_gate, out_gate, r_gate = map(\n            torch.sigmoid, [in_gate, forget_gate, out_gate, r_gate])\n        cell_gate = torch.tanh(cell_gate)\n        k = input[..., -self.hsz:]\n\n        cy = forget_gate * cx + in_gate * cell_gate\n        hy = r_gate * out_gate * F.tanh(cy) + (1. - r_gate) * k\n\n        if self.training:\n            hy = self.rdropout(hy)\n\n        return hy, cy\n\n\nclass HwLSTMlayer(nn.Module):\n    def __init__(self, isz, hsz, dropout_prob, is_cuda):\n        super().__init__()\n\n        self.cell = HwLSTMCell(isz, hsz, dropout_prob, is_cuda)\n\n    def forward(self, input, reverse=True):\n        output, hidden = [], None\n        for i in range(len(input)):\n            hidden = self.cell(input[i], hidden)\n            output.append(hidden[0])\n\n        if reverse:\n            output.reverse()\n\n        return torch.stack(output)\n\n\nclass DeepBiLSTMModel(nn.Module):\n    def __init__(self, vsz, lsz, ebd_dim, lstm_hsz, lstm_layers, dropout_prob, is_cuda, ebd_weights=None):\n        super().__init__()\n\n        self.ebd_weights = ebd_weights\n        self.ebd = nn.Embedding(vsz, ebd_dim, padding_idx=PAD)\n        self.lstms = nn.ModuleList([HwLSTMlayer(lstm_hsz, lstm_hsz, dropout_prob, is_cuda) if layer != 0 else HwLSTMlayer(\n            ebd_dim, lstm_hsz, dropout_prob, is_cuda) for layer in range(lstm_layers)])\n        self.logistic = nn.Linear(lstm_hsz, lsz)\n\n        self.reset_parameters(ebd_dim)\n\n    def reset_parameters(self, ebd_dim):\n        stdv = 1.0 / math.sqrt(ebd_dim)\n        self.logistic.weight.data.uniform_(-stdv, stdv)\n        if self.ebd_weights is None:\n            self.ebd.weight.data.uniform_(-stdv, stdv)\n        else:\n            self.ebd.weight.data.copy_(torch.from_numpy(self.ebd_weights))\n\n    def forward(self, inp):\n        inp = self.ebd(inp)\n        inp = inp.permute(1, 0, 2)\n\n        for rnn in self.lstms:\n            inp = rnn(inp)\n\n        inp = inp.permute(1, 0, 2).contiguous().view(-1, inp.size(2))\n        out = self.logistic(inp)\n        return F.log_softmax(out, dim=-1)\n\n\nif __name__ == ""__main__"":\n    d = DeepBiLSTMModel(30, 3, 300, 100, 8, 0.1, False)\n    input = torch.LongTensor([[0, 1, 2], [2, 1, 2]])\n    out = d(input)\n    print(out.shape)\n'"
deep-srl/train.py,11,"b'import argparse\nimport os\n\nimport torch\n\nfrom data_loader import DataLoader\nfrom model import *\nfrom const import PAD\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--epochs\', type=int, default=500)\nparser.add_argument(\'--batch_size\', type=int, default=80)\nparser.add_argument(\'--seed\', type=int, default=1101)\nparser.add_argument(\'--unuse_cuda\', action=\'store_true\')\n\nparser.add_argument(\'--data\', type=str, default=\'data/corpus.pt\')\n\nparser.add_argument(\'--word_ebd_dim\', type=int, default=128)\nparser.add_argument(\'--recurrent_dropout_prob\', type=float, default=0.1)\nparser.add_argument(\'--lstm_hsz\', type=int, default=256)\nparser.add_argument(\'--lstm_layers\', type=int, default=8)\nparser.add_argument(\'--clip\', type=float, default=1.)\n\nargs = parser.parse_args()\n\ntorch.manual_seed(args.seed)\nuse_cuda = torch.cuda.is_available() and not args.unuse_cuda\n\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\n# Tensorboard\ntry:\n    import tensorflow as tf\nexcept ImportError:\n    tf = None\n\ntf_summary_writer = tf and tf.summary.FileWriter(""logdir"")\n\n\ndef add_summary_value(key, value, tf_step):\n    summary = tf.Summary(value=[tf.Summary.Value(tag=key, simple_value=value)])\n    tf_summary_writer.add_summary(summary, tf_step)\n\n\ndata = torch.load(args.data)\nargs.word_max_len = data[""word_max_len""]\nargs.word_size = data[\'dict\'][\'word_size\']\nargs.label_size = data[\'dict\'][\'label_size\']\n\ntraining_data = DataLoader(\n    data[\'train\'][\'word\'],\n    data[\'train\'][\'label\'],\n    cuda=use_cuda,\n    batch_size=args.batch_size)\n\nvalidation_data = DataLoader(\n    data[\'valid\'][\'word\'],\n    data[\'valid\'][\'label\'],\n    batch_size=args.batch_size,\n    shuffle=False,\n    cuda=use_cuda)\n\nmodel = DeepBiLSTMModel(args.word_size, args.label_size, args.word_ebd_dim,\n                        args.lstm_hsz, args.lstm_layers, args.recurrent_dropout_prob, use_cuda)\n\nif use_cuda:\n    model = model.cuda()\n\noptimizer = torch.optim.Adadelta(model.parameters(), rho=.9)\ncriterion = torch.nn.CrossEntropyLoss()\n\n\ndef train(i):\n    model.train()\n    sums = corrects = total_loss = 0\n    for word, label in training_data:\n        optimizer.zero_grad()\n        pred = model(word)\n        loss = criterion(pred, label)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n        optimizer.step()\n        total_loss += loss.data.item()\n        corrects += (torch.max(pred, 1)[1].data == label.data).sum()\n        sums += label.shape[0]\n    print(\n        f""train epoch {i+1}/{args.epochs} loss: {total_loss/training_data._stop_step:.4f} corrects: {float(corrects)*100/(sums):.2f}%"")\n\n    if tf is not None:\n        add_summary_value(""train loss"", total_loss /\n                          training_data._stop_step, i)\n        add_summary_value(""train corrects"", float(corrects) * 100 / (sums), i)\n        tf_summary_writer.flush()\n\n\ndef evaluate(i):\n    model.eval()\n    sums = corrects = eval_loss = 0\n\n    for word, label in validation_data:\n        with torch.no_grad():\n            pred = model(word)\n            loss = criterion(pred, label)\n            eval_loss += loss.data.item()\n            corrects += (torch.max(pred, 1)[1].data == label.data).sum()\n            sums += label.shape[0]\n\n    print(\n        f""eval epoch {i+1}/{args.epochs} loss: {eval_loss/validation_data._stop_step:.4f} corrects: {float(corrects)*100/(sums):.2f}%"")\n\n    if tf is not None:\n        add_summary_value(""evaluate loss"", eval_loss /\n                          validation_data._stop_step, i)\n        add_summary_value(""evaluate corrects"", float(\n            corrects) * 100 / (sums), i)\n        tf_summary_writer.flush()\n\n\nos.makedirs(""weights"", exist_ok=True)\ntry:\n    print(\'-\' * 90)\n    for epoch in range(args.epochs):\n        train(epoch)\n        print(\'-\' * 90)\n        evaluate(epoch)\n        print(\'-\' * 90)\n\n        model_state_dict = model.state_dict()\n        model_source = {\n            ""settings"": args,\n            ""model"": model_state_dict,\n            ""word_dict"": data[\'dict\'][\'word\'],\n            ""label_dict"": data[\'dict\'][\'label\']\n        }\n        torch.save(model_source, f""weights/model_{epoch+1}.pt"")\n\nexcept KeyboardInterrupt:\n    print(""Exiting from training early"")\n'"
facial-beauty-prediction/img_loader.py,3,"b'import torch\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import transforms as T\n\nfrom PIL import Image\n\nimport numpy as np\n\n\nclass Img_loader(object):\n    def __init__(self, path, bsz, is_cuda=True, img_size=224, evaluation=False):\n        self.bsz = bsz\n        self.data = [line.strip().split() for line in open(path)]\n        self.ssz = len(self.data)\n        self.stop_step = self.ssz // bsz\n        self.step = 0\n        self.is_cuda = is_cuda\n        self.evaluation = evaluation\n\n        self.encode = T.Compose([\n            T.Resize(img_size),\n            T.ToTensor()\n        ])\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def img2variable(datas):\n            imgs, scores = zip(*datas)\n            tensors = [self.encode(Image.open(\n                ""data/images/"" + img).convert(\'RGB\')).unsqueeze(0) for img in imgs]\n            v = Variable(torch.cat(tensors, 0), volatile=self.evaluation)\n\n            scores = np.asarray(list(map(float, scores)), dtype=np.float32)\n            scores = Variable(torch.from_numpy(scores),\n                              volatile=self.evaluation)\n\n            if self.is_cuda:\n                v = v.cuda()\n                scores = scores.cuda()\n\n            return v, scores\n\n        if self.step == self.stop_step:\n            self.step = 0\n            raise StopIteration()\n\n        start = self.step * self.bsz\n        self.step += 1\n\n        return img2variable(self.data[start:start + self.bsz])\n\n\nif __name__ == ""__main__"":\n    training_data = Img_loader(""data/validation/test_1.txt"", 2)\n    i, s = next(training_data)\n    print(i.shape)\n    print(s.shape)\n'"
facial-beauty-prediction/predict.py,5,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torchvision import transforms as T\nimport numpy as np\n\nfrom PIL import Image\n\nfrom train import Beauty\n\n\nclass Predict:\n    def __init__(self):\n        model_source = torch.load(\n            ""./model.pt"", map_location=lambda storage, loc: storage)\n        model = Beauty()\n        model.load_state_dict(model_source[""model""])\n        model.eval()\n        self.model = model\n\n        self.encode = T.Compose([\n            T.Resize(224),\n            T.ToTensor()\n        ])\n\n    def img2V(self, img):\n        t = self.encode(Image.open(img).convert(\'RGB\')).unsqueeze(0)\n        with torch.no_grad():\n            t = Variable(t)\n        return t\n\n    def divine(self, img):\n        v = self.img2V(img)\n        score = self.model(v)\n\n        return round(score.data.tolist(), 3)\n\n\nif __name__ == ""__main__"":\n    p = Predict()\n    score = p.divine(""data/imgs/h2.jpeg"")\n    print(score)\n'"
facial-beauty-prediction/train.py,7,"b'import torch\nimport torch.nn as nn\nfrom torchvision.models import resnet50\n\n\nclass Beauty(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.resnet = resnet50(True)\n        self.predict = nn.Linear(1000, 1)\n\n        self._reset_parameters()\n\n    def forward(self, x):\n        out = nn.functional.relu(self.resnet(x))\n        score = self.predict(out)\n        return score.squeeze()\n\n    def _reset_parameters(self):\n        for p in self.resnet.parameters():\n            p.requires_grad = False\n\n        self.predict.weight.data.uniform_(-.1, .1)\n\n    def get_trainable_parameters(self):\n        return filter(lambda m: m.requires_grad, self.parameters())\n\n\ndef train():\n    model.train()\n    total_loss = 0.\n\n    for data, label in training_data:\n        optimizer.zero_grad()\n\n        scores = model(data)\n        loss = criterion(scores, label)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.data\n\n    return total_loss[0] / training_data.ssz\n\n\ndef eval():\n    model.eval()\n    total_loss = 0.\n    for data, label in validation_data:\n        scores = model(data)\n        loss = criterion(scores, label)\n        total_loss += loss.data\n\n    return total_loss[0] / validation_data.ssz\n\n\ndef main():\n    best = None\n    try:\n        print(\'-\' * 90)\n        for epoch in range(1, args.epochs + 1):\n            loss = train()\n            print(\'| start of epoch {:3d}  | loss {:5.6f}\'.format(epoch, loss))\n            loss = eval()\n            print(\'-\' * 90)\n            print(\'| end of epoch {:3d} | loss {:.4f}\'.format(epoch, loss))\n            print(\'-\' * 90)\n            if not best or best > loss:\n                best = loss\n                model_state_dict = model.state_dict()\n                model_source = {\n                    ""settings"": args,\n                    ""model"": model_state_dict,\n                }\n                torch.save(model_source, args.save)\n    except KeyboardInterrupt:\n        print(""-"" * 90)\n        print(""Exiting from training early"")\n\n\nif __name__ == ""__main__"":\n    import argparse\n    from img_loader import Img_loader\n\n    parser = argparse.ArgumentParser(description=\'Facial-Beau-Predict\')\n    parser.add_argument(\'--batch-size\', type=int, default=16)\n    parser.add_argument(\'--unuse_cuda\', action=\'store_true\')\n    parser.add_argument(\'--seed\', type=int, default=514)\n    parser.add_argument(\'--epochs\', type=int, default=100)\n    parser.add_argument(\'--save\', type=str, default=\'./model.pt\')\n\n    args = parser.parse_args()\n\n    use_cuda = torch.cuda.is_available() and not args.unuse_cuda\n    torch.manual_seed(args.seed)\n    if use_cuda:\n        torch.cuda.manual_seed(args.seed)\n\n    training_data = Img_loader(\n        ""data/validation/train_1.txt"", args.batch_size, is_cuda=use_cuda)\n    validation_data = Img_loader(\n        ""data/validation/test_1.txt"", args.batch_size, is_cuda=use_cuda, evaluation=True)\n\n    model = Beauty()\n    if use_cuda:\n        model = model.cuda()\n\n    criterion = torch.nn.SmoothL1Loss()\n    optimizer = torch.optim.Adam(model.get_trainable_parameters(), lr=0.001)\n\n    main()\n'"
gym/dqn.py,20,"b""import math\nimport random\nfrom collections import namedtuple\nfrom itertools import count\n\nimport gym\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nenv = gym.make('CartPole-v0')\nstate_dim = env.observation_space.shape[0]\nout_dim = env.action_space.n\n\n\nTransition = namedtuple('Transition',\n                        ('state', 'action', 'next_state', 'reward'))\n\nBATCH_SIZE = 32\nGAMMA = 0.9\nINITIAL_EPSILON = 0.5\nFINAL_EPSILON = 0.01\nCAPACITY = 10000\n\ntorch.manual_seed(1234)\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    torch.cuda.manual_seed(1234)\n\nif use_cuda:\n    byteTensor = torch.cuda.ByteTensor\n    tensor = torch.cuda.FloatTensor\n    longTensor = torch.cuda.LongTensor\nelse:\n    byteTensor = torch.ByteTensor\n    tensor = torch.Tensor\n    longTensor = torch.LongTensor\n\n\nclass DQN(nn.Module):\n    def __init__(self, state_dim, out_dim, capacity, bsz, epsilon):\n        super().__init__()\n        self.steps_done = 0\n        self.position = 0\n        self.pool = []\n        self.capacity = capacity\n        self.bsz = bsz\n        self.epsilon = epsilon\n\n        self.fc1 = nn.Linear(state_dim, 32)\n        self.fc2 = nn.Linear(32, out_dim)\n\n        self.fc1.weight.data.uniform_(-.1, .1)\n        self.fc2.weight.data.uniform_(-.1, .1)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n\n        return self.fc2(x)\n\n    def action(self, state):\n        self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000\n\n        if random.random() > self.epsilon:\n            return self(Variable(state, volatile=True)).data.max(1)[1].view(1, 1)\n        else:\n            return longTensor([[random.randrange(2)]])\n\n    def push(self, *args):\n        if len(self) < self.capacity:\n            self.pool.append(None)\n        self.pool[self.position] = Transition(*args)\n        self.position = (self.position + 1) % self.capacity\n\n    def sample(self):\n        return random.sample(self.pool, self.bsz)\n\n    def __len__(self):\n        return len(self.pool)\n\n\ndqn = DQN(state_dim, out_dim, CAPACITY, BATCH_SIZE, INITIAL_EPSILON)\nif use_cuda:\n    dqn = dqn.cuda()\noptimizer = optim.Adam(dqn.parameters(), lr=0.0001)\n\n\ndef optimize_model():\n    if len(dqn) < BATCH_SIZE:\n        return\n    transitions = dqn.sample()\n    batch = Transition(*zip(*transitions))\n\n    non_final_mask = byteTensor(\n        tuple(map(lambda x: x is not None, batch.next_state)))\n    non_final_next_states = Variable(\n        torch.cat([s for s in batch.next_state if s is not None]), volatile=True)\n    next_state_values = Variable(torch.zeros(BATCH_SIZE).type(tensor))\n    next_state_values[non_final_mask] = dqn(non_final_next_states).max(1)[0]\n    next_state_values.volatile = False\n\n    state_batch = Variable(torch.cat(batch.state))\n    action_batch = Variable(torch.cat(batch.action))\n    reward_batch = Variable(torch.cat(batch.reward))\n\n    state_action_values = dqn(state_batch).gather(1, action_batch)\n\n    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n\n    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n\nperfect = 0\n\nfor _ in range(10000):\n    state = env.reset()\n    state = torch.from_numpy(state).type(tensor).view(1, -1)\n    for t in count():\n        action = dqn.action(state)\n        next_state, reward, done, _ = env.step(action[0, 0])\n        next_state = torch.from_numpy(\n            next_state).type(tensor).view(1, -1)\n        if done:\n            next_state = None\n\n        reward = tensor([reward])\n\n        dqn.push(state, action, next_state, reward)\n\n        state = next_state\n\n        optimize_model()\n\n        if done:\n            if t > perfect:\n                print(t)\n                perfect = t\n            break\n"""
gym/reinforce.py,9,"b""import argparse\nfrom itertools import count\n\nimport gym\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.distributions import Categorical\n\n\nparser = argparse.ArgumentParser(description='PyTorch actor-critic example')\nparser.add_argument('--gamma', type=float, default=0.99)\nparser.add_argument('--seed', type=int, default=543, metavar='N')\nparser.add_argument('--render', action='store_true')\n\nargs = parser.parse_args()\n\n\nenv = gym.make('CartPole-v0').unwrapped\nenv.seed(args.seed)\ntorch.manual_seed(args.seed)\n\n\nclass ActorCritic(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.affine1 = nn.Linear(4, 128)\n        self.action_head = nn.Linear(128, 2)\n        self.value_head = nn.Linear(128, 1)\n\n    def forward(self, x):\n        x = F.relu(self.affine1(x))\n        action_scores = self.action_head(x)\n        state_values = self.value_head(x)\n        return F.softmax(action_scores, dim=-1), state_values\n\n    def select_action(self, state, values, select_props):\n        state = torch.from_numpy(state).float()\n        props, value = self(Variable(state))\n        dist = Categorical(props)\n        action = dist.sample()\n        log_props = dist.log_prob(action)\n        values.append(value)\n        select_props.append(log_props)\n\n        return action.data[0]\n\n\nmodel = ActorCritic()\noptimizer = optim.Adam(model.parameters(), lr=3e-2)\n\n\ndef main():\n    for i_episode in count(1):\n        state = env.reset()\n        if args.render:\n            env.render()\n        values, select_props, policy_rewards = [], [], []\n        for t in range(10000):\n            action = model.select_action(state, values, select_props)\n            state, reward, done, _ = env.step(action)\n            policy_rewards.append(reward)\n\n            if done:\n                break\n\n        R, rewards = 0, []\n        for r in policy_rewards[::-1]:\n            R = r + args.gamma * R\n            rewards.insert(0, R)\n\n        rewards = np.asarray(rewards)\n        rewards = (rewards - rewards.mean()) / \\\n            (rewards.std() + np.finfo(np.float32).eps)\n\n        value_loss, policy_loss = [], []\n        for value, prop, r in zip(values, select_props, rewards):\n            value_loss.append(F.smooth_l1_loss(\n                value, Variable(torch.Tensor([r]))))\n            reward = r - value.data[0]\n            policy_loss.append(-prop * reward)\n\n        loss = torch.cat(value_loss).sum() + torch.cat(policy_loss).sum()\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if i_episode % 10 == 0:\n            print('Episode {}\\tLast length: {:5d}\\t'.format(\n                i_episode, t))\n\n\nif __name__ == '__main__':\n    main()\n"""
hierarchical-sc/const.py,0,"b""PAD = 0\nEOS = 1\nBOS = 2\nUNK = 3\n\nWORD = {\n    PAD: '<pad>',\n    UNK: '<unk>',\n    BOS: '<s>',\n    EOS: '</s>'\n}\n"""
hierarchical-sc/corpus.py,1,"b'import os\nimport torch\nimport math\n\nimport pandas as pd\n\nfrom const import *\n\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK,\n            WORD[BOS]: BOS,\n            WORD[EOS]: EOS\n        }\n        self.idx = len(self.word2idx)\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, sents, min_count):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words:\n            word_count[w] += 1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Corpus(object):\n    def __init__(self, max_ori_len=128, max_sum_len=15, min_word_count=1):\n        self.dict = Dictionary()\n        self.max_ori_len = max_ori_len\n        self.max_sum_len = max_sum_len\n        self._min_word_count = min_word_count\n\n        self.parse_data(""data/test.csv"", False)\n        self.parse_data(""data/train.csv"")\n        self.save()\n\n    def parse_data(self, _file, is_train=True):\n        def cut(x, list, ignore, max_len, is_summ):\n            if isinstance(x, float) and math.isnan(x):\n                if is_summ:\n                    list.append(WORD[EOS])\n                else:\n                    list.append("""")\n            else:\n                x = x.split()\n                if len(x) > max_len:\n                    x = x[:max_len]\n                    ignore[0] += 1\n\n                if is_summ:\n                    x += [WORD[EOS]]\n\n                list.append(x)\n\n        origins, summurys = [], []\n        ignore_ori_nums = [0]\n        ignore_sum_nums = [0]\n\n        df = pd.read_csv(_file)\n\n        df[""original""].apply(cut, args=(\n            origins, ignore_ori_nums, self.max_ori_len, False))\n        df[""summary""].apply(cut, args=(\n            summurys, ignore_sum_nums, self.max_sum_len, True))\n\n        if is_train:\n            ori_ignore = self.dict(origins + summurys, self._min_word_count)\n            self.train_origins = origins\n            self.train_summurys = summurys\n            self.train_labels = df[""score""].values - 1\n\n            print(""Ignored origin counts - [{}]"".format(ori_ignore))\n            print(\n                \'Train data - ignore original lines - [{}]\'.format(ignore_ori_nums[0]))\n            print(\n                \'Train data - ignore summary lines - [{}]\'.format(ignore_sum_nums[0]))\n        else:\n            self.test_origins = origins\n            self.test_summurys = summurys\n            self.test_labels = df[""score""].values - 1\n            print(\n                \'Test data - ignore original lines - [{}]\'.format(ignore_ori_nums[0]))\n            print(\n                \'Test data - ignore summary lines - [{}]\'.format(ignore_sum_nums[0]))\n\n    def save(self):\n        data = {\n            \'max_ori_len\': self.max_ori_len,\n            \'max_sum_len\': self.max_sum_len + 1,\n            \'dict\': {\n                \'dict\': self.dict.word2idx,\n                \'dict_size\': len(self.dict),\n            },\n            \'train\': {\n                \'original\': word2idx(self.train_origins, self.dict.word2idx),\n                \'summary\': word2idx(self.train_summurys, self.dict.word2idx),\n                \'label\': self.train_labels\n            },\n            \'test\': {\n                \'original\': word2idx(self.test_origins, self.dict.word2idx),\n                \'summary\': word2idx(self.test_summurys, self.dict.word2idx),\n                \'label\': self.test_labels\n            }\n        }\n\n        torch.save(data, ""data/corpus"")\n        print(\'dict length - [{}]\'.format(len(self.dict)))\n\n\nif __name__ == ""__main__"":\n    Corpus()\n'"
hierarchical-sc/data_loader.py,6,"b'from collections import namedtuple\n\nimport torch\nfrom torch.autograd import Variable\nimport numpy as np\n\nimport const\n\n\nclass DataLoader(object):\n    def __init__(self,\n                 original,\n                 summary,\n                 label,\n                 max_ori_len,\n                 max_sum_len,\n                 use_cuda,\n                 evaluation=False,\n                 bsz=64,\n                 shuffle=True):\n        self.sents_size = len(original)\n        self.step = 0\n        self.stop_step = self.sents_size // bsz\n        self.use_cuda = use_cuda\n        self.evaluation = evaluation\n        self.bsz = bsz\n        self.max_ori_len = max_ori_len\n        self.max_sum_len = max_sum_len\n        self.original = np.asarray(original)\n        self.summary = np.asarray(summary)\n        self.label = label\n        self.nt = namedtuple(\'dataloader\', [\'original\', \'summary\', \'label\'])\n        if shuffle:\n            self._shuffle()\n\n    def _shuffle(self):\n        indices = np.arange(self.original.shape[0])\n        np.random.shuffle(indices)\n        self.original = self.original[indices]\n        self.summary = self.summary[indices]\n        self.label = self.label[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def data_pad(sents, max_len):\n            x = np.array([s + [const.PAD] * (max_len - len(s)) for s in sents])\n\n            if self.evaluation:\n                with torch.no_grad():\n                    return Variable(torch.from_numpy(x))\n            else:\n                return Variable(torch.from_numpy(x))\n\n        if self.step == self.stop_step:\n            self.step = 0\n            raise StopIteration()\n\n        start = self.step * self.bsz\n        bsz = min(self.bsz, self.sents_size - start)\n\n        self.step += 1\n        original = data_pad(self.original[start:start + bsz], self.max_ori_len)\n        summary = data_pad(self.summary[start:start + bsz], self.max_sum_len)\n        label = Variable(torch.from_numpy(self.label[start:start + bsz]))\n\n        if self.use_cuda:\n            original = original.cuda()\n            summary = summary.cuda()\n            label = label.cuda()\n\n        return self.nt._make([original, summary, label])\n\n\nif __name__ == \'__main__\':\n    data = torch.load(\'./data/corpus\')\n\n    training_data = DataLoader(\n        data[\'train\'][\'original\'],\n        data[\'train\'][\'summary\'],\n        data[\'train\'][\'label\'],\n        data[\'max_ori_len\'],\n        data[\'max_sum_len\'], True,\n        bsz=128, evaluation=True, shuffle=False)\n\n    dict = data[""dict""][""dict""]\n    idx2word = {v: k for k, v in dict.items()}\n    dt = next(training_data)\n'"
hierarchical-sc/fuel.py,0,"b'import gzip\nimport json\nimport random\nimport sys\nimport re\n\nimport pandas as pd\n\n\ndef process(inf):\n    def normalizeString(s):\n        s = s.lower().strip()\n        s = re.sub(r""([.!?])"", r"" \\1"", s)\n        s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n\n        return s\n\n    datas = []\n    g = gzip.open(inf, ""r"")\n    for l in g:\n        js = json.loads(json.dumps(eval(l)))\n        datas.append((js[""reviewText""], js[""summary""], js[""overall""]))\n\n    random.shuffle(datas)\n\n    columns = [""original"", ""summary"", ""score""]\n    train = pd.DataFrame(datas[len(datas) // 20:], columns=columns)\n    test = pd.DataFrame(datas[:len(datas) // 20], columns=columns)\n\n    for df in [train, test]:\n        df[""original""] = df[""original""].apply(lambda x: normalizeString(x))\n        df[""summary""] = df[""summary""].apply(lambda x: normalizeString(x))\n        df[""score""] = df[""score""].apply(lambda x: int(x))\n\n    train.to_csv(""data/train.csv"")\n    test.to_csv(""data/test.csv"")\n\n\nif __name__ == ""__main__"":\n    if len(sys.argv) != 2:\n        print(\'Usage: python3 fuel.py toys | sports | movies\')\n        exit()\n\n    dataset = sys.argv[1]\n\n    if dataset == ""toys"":\n        inf = ""data/reviews_Toys_and_Games_5.json.gz""\n    elif dataset == ""sports"":\n        inf = ""data/reviews_Sports_and_Outdoors_5.json.gz""\n    elif dataset == ""movies"":\n        inf = ""data/reviews_Movies_and_TV_5.json.gz""\n    else:\n        print(\'Usage: python3 fuel.py toys | sports | movies\')\n        exit()\n\n    process(inf)\n'"
hierarchical-sc/model.py,16,"b'import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nfrom const import BOS, PAD\n\n\ndef multi_view_att(ori_memory, att_w, dec_hidden, *args):\n    bsz, max_len, rnn_hsz = args\n\n    dec_hidden = att_w(dec_hidden.squeeze())\n    ori_memory_t = ori_memory.transpose(1, 2)\n\n    beta_is = torch.exp(torch.tanh(torch.matmul(dec_hidden, ori_memory_t)))\n\n    beta_i_sum = torch.sum(beta_is, 0, keepdim=True)\n    beta_is = torch.div(beta_is, beta_i_sum)\n\n    return torch.sum(torch.matmul(beta_is, ori_memory), dim=0)\n\n\nclass Model(nn.Module):\n    def __init__(self, args, use_cuda):\n\n        super().__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.torch = torch.cuda if use_cuda else torch\n\n        self.emb = nn.Embedding(self.dict_size, self.emb_dim)\n        self.encode = torch.nn.LSTM(input_size=self.emb_dim,\n                                    hidden_size=self.rnn_hsz,\n                                    num_layers=1,\n                                    bidirectional=True)\n        self.decode = torch.nn.LSTM(input_size=self.rnn_hsz,\n                                    hidden_size=self.rnn_hsz,\n                                    num_layers=1)\n        self.summ_att_w = nn.Linear(self.rnn_hsz,\n                                    self.rnn_hsz,\n                                    bias=False)\n        self.cls_att_w = nn.Linear(self.rnn_hsz,\n                                   self.rnn_hsz,\n                                   bias=False)\n        self.summ_gen = nn.Linear(self.rnn_hsz, self.dict_size)\n        self.cls_pred = nn.Linear(\n            (self.max_ori_len + self.max_sum_len) * self.rnn_hsz, self.label_size)\n\n        self.dropout = nn.Dropout(self.dropout)\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        stdv = 1. / math.sqrt(self.emb_dim)\n\n        self.emb.weight.data.uniform_(-stdv, stdv)\n\n        self.summ_att_w.weight.data.uniform_(-stdv, stdv)\n\n        self.cls_att_w.weight.data.uniform_(-stdv, stdv)\n\n        self.summ_gen.weight.data.uniform_(-stdv, stdv)\n        self.summ_gen.bias.data.fill_(0)\n\n        self.cls_pred.weight.data.uniform_(-stdv, stdv)\n        self.cls_pred.bias.data.fill_(0)\n\n    def forward(self, original):\n        bsz = original.size(0)\n\n        ori_emb = self.emb(original)\n        ori_emb_t = ori_emb.transpose(0, 1)\n\n        encodes, (h, _) = self.encode(ori_emb_t)\n        ori_memory = encodes[:, :, :self.rnn_hsz] + \\\n            encodes[:, :, self.rnn_hsz:]\n\n        ori_hidden = (h[0] + h[1]).unsqueeze(0)\n        c = Variable(next(self.parameters()).data.new(\n            1, bsz, self.rnn_hsz).zero_())\n\n        ori_memory = self.dropout(ori_memory)\n        ori_hidden = self.dropout(ori_hidden)\n\n        dec_hidden = (ori_hidden, c)\n\n        word = Variable(self.torch.LongTensor([[BOS]] * bsz))\n        v_ts, summ_props = [], []\n        for _ in range(self.max_sum_len):\n            summ_emb = self.emb(word).transpose(0, 1)\n            _, dec_hidden = self.decode(summ_emb, dec_hidden)\n            h_state = self.dropout(dec_hidden[0])\n\n            v_c = multi_view_att(ori_memory,\n                                 self.summ_att_w,\n                                 h_state, bsz,\n                                 self.max_ori_len,\n                                 self.rnn_hsz)\n            v_t = multi_view_att(ori_memory,\n                                 self.cls_att_w,\n                                 h_state, bsz,\n                                 self.max_ori_len,\n                                 self.rnn_hsz)\n\n            props = F.log_softmax(self.summ_gen(v_c), -1)\n            _, word = torch.max(props, -1, keepdim=True)\n\n            v_ts.append(v_t.unsqueeze(1))\n            summ_props.append(props.unsqueeze(1))\n\n        summ_props = torch.cat(summ_props, 1)\n        v_ts = self.dropout(torch.cat(v_ts, 1))\n        r = torch.cat([v_ts, ori_memory.transpose(0, 1)], 1)\n        l_props = self.cls_pred(r.view(bsz, -1))\n\n        return summ_props, l_props\n\n\nclass NlpCrossEntropy(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, props, tgt):\n        tgt_props = props.gather(2, tgt.unsqueeze(2)).squeeze()\n        mask = (tgt > 0).float()\n        return -(tgt_props * mask).sum() / mask.sum()\n\n\nclass ScheduledOptim(object):\n    def __init__(self, optimizer, parameters, lr, clip):\n        self.optimizer = optimizer\n        self.parameters = parameters\n        self.n_current_epochs = 0\n        self.lr = lr\n        self.clip = clip\n\n    def step(self):\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def clip_grad_norm(self):\n        torch.nn.utils.clip_grad_norm_(self.parameters, self.clip)\n\n    def update_learning_rate(self):\n        self.n_current_epochs += 1\n\n        if self.n_current_epochs > 4:\n            self.lr = self.lr / 2\n            print(""| learning rate updated - {}"".format(self.lr))\n            print(\'-\' * 90)\n            for param_group in self.optimizer.param_groups:\n                param_group[\'lr\'] = self.lr\n'"
hierarchical-sc/train.py,8,"b'import argparse\n\nparser = argparse.ArgumentParser(\n    description=\'A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification\')\n\nparser.add_argument(\'--logdir\', type=str, default=\'logdir\')\nparser.add_argument(\'--data\', type=str, default=\'./data/corpus\')\n\nparser.add_argument(\'--epochs\', type=int, default=10)\nparser.add_argument(\'--batch_size\', type=int, default=64)\nparser.add_argument(\'--label_size\', type=int, default=5)\nparser.add_argument(\'--seed\', type=int, default=614)\nparser.add_argument(\'--lr\', type=float, default=.0003)\n\nparser.add_argument(\'--dropout\', type=float, default=.5)\nparser.add_argument(\'--emb_dim\', type=int, default=256)\nparser.add_argument(\'--rnn_hsz\', type=int, default=256)\nparser.add_argument(\'--beta1\', type=float, default=.9)\nparser.add_argument(\'--beta2\', type=float, default=.999)\nparser.add_argument(\'--eps\', type=float, default=1e-8)\nparser.add_argument(\'--lamda\', type=float, default=.5)\nparser.add_argument(\'--clip_norm\', type=float, default=10.)\n\nargs = parser.parse_args()\n\nimport torch\n\ntorch.manual_seed(args.seed)\nargs.use_cuda = use_cuda = torch.cuda.is_available()\n\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# ##############################################################################\n# Tensorboard\n################################################################################\ntry:\n    import tensorflow as tf\n    tf_step = 0\nexcept ImportError:\n    tf = None\n\ntf_summary_writer = tf and tf.summary.FileWriter(args.logdir)\n\n\ndef add_summary_value(key, value):\n    global tf_step\n\n    summary = tf.Summary(value=[tf.Summary.Value(tag=key, simple_value=value)])\n    tf_summary_writer.add_summary(summary, tf_step)\n\n\ndata = torch.load(args.data)\nargs.max_ori_len = data[""max_ori_len""]\nargs.max_sum_len = data[""max_sum_len""]\nargs.dict_size = data[\'dict\'][\'dict_size\']\n\nprint(""="" * 30 + ""arguments"" + ""="" * 30)\nfor k, v in args.__dict__.items():\n    if k in (""epochs"", ""seed"", ""data""):\n        pass\n    print(""{}: {}"".format(k, v))\nprint(""="" * 60)\n\nfrom data_loader import DataLoader\n\ntraining_data = DataLoader(\n    data[\'train\'][\'original\'],\n    data[\'train\'][\'summary\'],\n    data[\'train\'][\'label\'],\n    data[\'max_ori_len\'],\n    data[\'max_sum_len\'],\n    use_cuda,\n    bsz=args.batch_size)\n\nvalidation_data = DataLoader(\n    data[\'test\'][\'original\'],\n    data[\'test\'][\'summary\'],\n    data[\'test\'][\'label\'],\n    data[\'max_ori_len\'],\n    data[\'max_sum_len\'],\n    use_cuda,\n    bsz=args.batch_size,\n    evaluation=True,\n    shuffle=False)\n\nfrom model import *\n\nmodel = Model(args, use_cuda)\nif use_cuda:\n    model = model.cuda()\n\noptimizer = ScheduledOptim(\n    torch.optim.Adam(model.parameters(), betas=(\n        args.beta1, args.beta2), eps=args.eps),\n    model.parameters(), args.lr, args.clip_norm)\nnlp_critic = NlpCrossEntropy()\ncls_critic = torch.nn.CrossEntropyLoss()\n\n\ndef evaluate():\n    if tf:\n        global tf_step\n    model.eval()\n    corrects = 0\n    for original, _, label in validation_data:\n        _, cls_props = model(original)\n        corrects += (torch.max(cls_props, 1)\n                     [1].view(label.size()).data == label.data).sum()\n\n    return corrects, validation_data.sents_size\n\n\ndef train():\n    if tf:\n        global tf_step\n    model.train()\n    for original, summary, label in training_data:\n        optimizer.zero_grad()\n\n        summ_props, cls_props = model(original)\n        cls_loss = cls_critic(cls_props, label)\n        summ_loss = nlp_critic(summ_props, summary)\n        loss = summ_loss + args.lamda * cls_loss\n        loss.backward()\n\n        optimizer.step()\n        optimizer.clip_grad_norm()\n\n        corrects = (torch.max(cls_props, 1)[1].view(\n            label.size()).data == label.data).sum()\n\n        if tf is not None:\n            add_summary_value(""cls_loss"", cls_loss.data)\n            add_summary_value(""summ_loss"", summ_loss.data)\n            add_summary_value(""loss"", loss.data)\n            add_summary_value(""corrects"", corrects)\n            tf_step += 1\n\n            if tf_step % 100 == 0:\n                tf_summary_writer.flush()\n\n\ntry:\n    for epoch in range(1, args.epochs + 1):\n        train()\n        optimizer.update_learning_rate()\n        corrects, size = evaluate()\n        print(\'-\' * 90)\n        print(\'| end of epoch {} | size {} | corrects {}\'.format(\n            epoch, size, corrects))\n        print(\'-\' * 90)\n\nexcept KeyboardInterrupt:\n    print(""-"" * 90)\n    print(""Exiting from training early"")\n'"
information-extraction/common.py,0,"b'import jieba.posseg as pseg\nimport numpy as np\n\nimport const\n\n\ndef q2idx(chars, words, char2idx, word2idx):\n    chars = [char2idx[c] if c in char2idx else const.UNK for c in chars]\n    words = [word2idx[w] if w in word2idx else const.UNK for w in words]\n\n    return chars, words\n\n\ndef question2idx(questions, word2idx):\n    return [[word2idx[w] if w in word2idx else const.UNK for w in question] for question in questions]\n\n\ndef load_pre_w2c(_file, char2idx, word2idx):\n    w2c_dict = {}\n    print(""loading word2vec"")\n    for line in open(_file):\n        temp = line.strip().split("" "")\n\n        if len(temp) < 10:\n            continue\n        w2c_dict[temp[0]] = list(map(float, temp[1:]))\n\n        if ""len_"" not in locals():\n            len_ = len(temp[1:])\n\n    print(f""load {len(w2c_dict)} lines word2vec"")\n\n    charW = np.random.rand(len(char2idx), len_)\n    for word, idx in sorted(char2idx.items(), key=lambda x: x[1]):\n        if word in w2c_dict:\n            charW[idx] = np.asarray(w2c_dict[word])\n\n    wordW = np.random.rand(len(word2idx), len_)\n    for word, idx in sorted(word2idx.items(), key=lambda x: x[1]):\n        if word in w2c_dict:\n            wordW[idx] = np.asarray(w2c_dict[word])\n\n    del w2c_dict\n    return charW, wordW\n\n\nclass ScheduledOptim(object):\n    def __init__(self, optimizer, d_model, n_warmup_steps):\n        self.optimizer = optimizer\n        self.d_model = d_model\n        self.n_warmup_steps = n_warmup_steps\n        self.n_current_steps = 0\n\n    def step(self):\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def update_learning_rate(self):\n        self.n_current_steps += 1\n        new_lr = np.power(self.d_model, -0.5) * np.min([np.power(\n            self.n_current_steps, -0.5), np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n\n        for param_group in self.optimizer.param_groups:\n            param_group[\'lr\'] = new_lr\n\n\nclass Jieba(object):\n    def __init__(self):\n        self.pseg = pseg\n\n    def segment(self, text):\n        words = self.pseg.cut(text)\n        return [w for w, _ in words]\n\n\nif __name__ == \'__main__\':\n    jb = Jieba()\n    print([e for e in jb.segment(""\xe3\x80\x8a\xe5\x81\xa5\xe8\xa1\x8c\xe5\xa4\xa9\xe4\xb8\x8b\xef\xbc\x9a\xe5\xb8\xa6\xe4\xb8\x8a\xe4\xb8\x80\xe6\x9c\xac\xe5\x81\xa5\xe5\xba\xb7\xe7\x9a\x84\xe4\xb9\xa6\xe5\x8e\xbb\xe5\x87\xba\xe8\xa1\x8c\xe3\x80\x8b\xe4\xb8\x80\xe4\xb9\xa6\xe7\x9a\x84\xe5\x87\xba\xe7\x89\x88\xe7\xa4\xbe\xe6\x98\xaf\xe4\xba\xba\xe6\xb0\x91\xe5\x86\x9b\xe5\x8c\xbb\xe5\x87\xba\xe7\x89\x88\xe7\xa4\xbe\xef\xbc\x8c\xe4\xbd\x9c\xe8\x80\x85\xe6\x98\xaf\xe7\xa7\xa6\xe6\x83\xa0\xe5\x9f\xba\xef\xbc\x8c\xe5\x87\xba\xe7\x89\x88\xe6\x97\xb6\xe9\x97\xb4\xe6\x98\xaf"")])\n'"
information-extraction/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    PAD: '<pad>',\n    UNK: '<unk>',\n}\n\nINIT_RANGE = 0.02\n"""
information-extraction/corpus.py,1,"b'import torch\nimport json\nimport os\nimport collections\n\nimport jieba.posseg as pseg\n\nimport const\nimport common\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            const.WORD[const.PAD]: const.PAD,\n            const.WORD[const.UNK]: const.UNK,\n        }\n        self.idx = len(self.word2idx)\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def parse(self, texts, min_count=0):\n        words = [word for text in texts for word in text]\n\n        word_count = {w: 0 for w in set(words)}\n        for w in words:\n            word_count[w] += 1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n\nclass Corpus(object):\n    def __init__(self, max_len=512, load_w2v=None, save_data=""data/corpus.pt""):\n\n        self.save_data = save_data\n        self.load_w2v = load_w2v\n        self.word = Dictionary()\n        self.char = Dictionary()\n        self.max_len = max_len\n        self.seg = pseg\n        self.parse_pred()\n        self.parse_data(True)\n        self.parse_data(False)\n        self.save()\n\n    def parse_pred(self):\n        predicate2id = {}\n        lines = open(""data/all_50_schemas"", encoding=""utf8"")\n        for line in lines:\n            line = json.loads(line)\n            if line[""predicate""] not in predicate2id:\n                predicate2id[line[""predicate""]] = len(predicate2id)\n\n        self.predicate2id = predicate2id\n        lines.close()\n\n    def segment(self, text):\n        words = []\n        for w in [[e]*len(e) for e, _ in self.seg.cut(text)]:\n            words += w\n\n        return words\n\n    def parse_data(self, is_train):\n        chars, words = [], []\n        sub_sidx, sub_eidx = [], []\n        sub_slidx, sub_elidx = [], []\n        obj_idxs = []\n\n        if is_train:\n            inf = open(""data/train_data.json"", encoding=""utf8"")\n        else:\n            inf = open(""data/dev_data.json"", encoding=""utf8"")\n\n        for line in inf:\n            line = json.loads(line)\n            text = line[""text""]\n            if len(text) > self.max_len:\n                text = text[:self.max_len]\n\n            items = collections.defaultdict(list)\n\n            # subject position\n            s1, s2 = [0]*len(text), [0]*len(text)\n\n            for spo in line[\'spo_list\']:\n                subject, predicate, obj = spo[""subject""].strip(\'\xe3\x80\x8a\xe3\x80\x8b\').strip().lower(\n                ), spo[""predicate""], spo[""object""].strip(\'\xe3\x80\x8a\xe3\x80\x8b\').strip().lower()\n\n                subjectid = text.find(subject)\n                objectid = text.find(obj)\n                if subjectid != -1 and objectid != -1:\n                    items[(subjectid, subjectid+len(subject)-1)].append((objectid,\n                                                                         objectid+len(obj)-1, self.predicate2id[predicate]))\n\n                    s1[subjectid] = 1\n                    s2[subjectid+len(subject)-1] = 1\n\n            if len(items):\n                for (sub_s, sub_e), obj_idx in items.items():\n                    # text - chars & words\n                    chars.append(text)\n                    words.append(self.segment(text))\n                    assert len(chars[-1]) == len(words[-1])\n\n                    sub_sidx.append(s1)\n                    sub_eidx.append(s2)\n\n                    # subject index\n                    sub_slidx.append([sub_s])\n                    sub_elidx.append([sub_e])\n                    obj_idxs.append(obj_idx)\n\n        assert len(chars) == len(words)\n        assert len(chars) == len(sub_sidx)\n        assert len(chars) == len(sub_eidx)\n        assert len(chars) == len(obj_idxs)\n        assert len(chars) == len(sub_slidx)\n        assert len(chars) == len(sub_elidx)\n\n        if is_train:\n            print(f""ignore words count - {self.word.parse(words, 1)}"")\n            self.char.parse(chars)\n            self.train_char2idx = common.question2idx(\n                chars, self.char.word2idx)\n            self.train_word2idx = common.question2idx(\n                words, self.word.word2idx)\n            self.train_sub_sidx = sub_sidx\n            self.train_sub_eidx = sub_eidx\n            self.train_obj_idxs = obj_idxs\n            self.train_sub_slidx = sub_slidx\n            self.train_sub_elidx = sub_elidx\n        else:\n            self.dev_char2idx = common.question2idx(chars, self.char.word2idx)\n            self.dev_word2idx = common.question2idx(words, self.word.word2idx)\n            self.dev_sub_sidx = sub_sidx\n            self.dev_sub_eidx = sub_eidx\n            self.dev_obj_idxs = obj_idxs\n            self.dev_sub_slidx = sub_slidx\n            self.dev_sub_elidx = sub_elidx\n\n    def save(self):\n        data = {\n            \'max_len\': self.max_len,\n            \'word2idx\': self.word.word2idx,\n            \'char2idx\': self.char.word2idx,\n            \'predicate2id\': self.predicate2id,\n            ""train"": {\n                ""char"": self.train_char2idx,\n                ""word"": self.train_word2idx,\n                ""sub_sidx"": self.train_sub_sidx,\n                ""sub_eidx"": self.train_sub_eidx,\n                ""obj_idxs"": self.train_obj_idxs,\n                ""sub_slidx"": self.train_sub_slidx,\n                ""sub_elidx"": self.train_sub_elidx,\n            },\n            ""dev"": {\n                ""char"": self.dev_char2idx,\n                ""word"": self.dev_word2idx,\n                ""sub_sidx"": self.dev_sub_sidx,\n                ""sub_eidx"": self.dev_sub_eidx,\n                ""obj_idxs"": self.dev_obj_idxs,\n                ""sub_slidx"": self.dev_sub_slidx,\n                ""sub_elidx"": self.dev_sub_elidx,\n            }\n        }\n\n        if self.load_w2v is not None:\n            charW, wordW = common.load_pre_w2c(\n                self.load_w2v, self.char.word2idx, self.word.word2idx)\n            data[""charW""] = charW\n            data[""wordW""] = wordW\n\n        torch.save(data, self.save_data)\n        print(f\'train data length - {len(self.train_char2idx)}\')\n        print(f\'dev data length - {len(self.dev_char2idx)}\')\n        print(f\'char length - {len(self.char.word2idx)}\')\n        print(f\'word length - {len(self.word.word2idx)}\')\n        print(f\'Finish dumping the data to file - {self.save_data}\')\n\n\nif __name__ == ""__main__"":\n    Corpus()\n'"
information-extraction/data_loader.py,15,"b'import numpy as np\nimport torch\n\nimport const\n\n\nclass DataLoader:\n    def __init__(self, chars, words, sub_sidx, sub_eidx, obj_idxs, sub_slidx, sub_elidx, word2idx, char2idx, predicate2id, cuda=True, batch_size=64, shuffle=True):\n\n        self.sents_size = len(chars)\n        self.cuda = cuda\n        self.bsz = batch_size\n        self.step = 0\n        self.stop_step = self.sents_size // batch_size\n\n        self.word2idx = word2idx\n        self.char2idx = char2idx\n        self.predicate2id = predicate2id\n\n        self.chars = np.asarray(chars)\n        self.words = np.asarray(words)\n        self.sub_sidx = np.asarray(sub_sidx)\n        self.sub_eidx = np.asarray(sub_eidx)\n        self.obj_idxs = np.asarray(obj_idxs)\n        self.sub_slidx = np.asarray(sub_slidx)\n        self.sub_elidx = np.asarray(sub_elidx)\n\n        if shuffle:\n            self.shuffle()\n\n    def shuffle(self):\n        index = np.arange(self.chars.shape[0])\n        np.random.shuffle(index)\n\n        self.chars = self.chars[index]\n        self.words = self.words[index]\n        self.sub_sidx = self.sub_sidx[index]\n        self.sub_eidx = self.sub_eidx[index]\n        self.obj_idxs = self.obj_idxs[index]\n        self.sub_slidx = self.sub_slidx[index]\n        self.sub_elidx = self.sub_elidx[index]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def data2tensor(insts, get_pos=False):\n            max_len = max(len(inst) for inst in insts)\n\n            inst_data = np.array(\n                [inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n            if get_pos:\n                position = np.array(\n                    [[pos_i+1 if w_i != const.PAD else 0 for pos_i, w_i in enumerate(inst)] for inst in inst_data])\n                position = torch.from_numpy(position)\n\n            inst_data = torch.from_numpy(inst_data)\n            if self.cuda:\n                inst_data = inst_data.cuda()\n\n            if get_pos:\n                position = position.cuda()\n                return inst_data, position, max_len\n\n            return inst_data\n\n        def obj2tensor(objs, max_len):\n            o1, o2 = np.zeros((len(objs), max_len, len(self.predicate2id))), np.zeros(\n                (len(objs), max_len, len(self.predicate2id)))\n\n            for idx, obj in enumerate(objs):\n                for obj_s, obj_e, pred in obj:\n                    o1[idx, obj_s, pred] = 1\n                    o2[idx, obj_e, pred] = 1\n\n            o1 = torch.from_numpy(o1)\n            o2 = torch.from_numpy(o2)\n            if self.cuda:\n                o1 = o1.cuda()\n                o2 = o2.cuda()\n\n            return o1.float(), o2.float()\n\n        def subl2tensor(subs):\n            subs = torch.from_numpy(np.asarray(subs))\n            if self.cuda:\n                subs = subs.cuda()\n            return subs.float()\n\n        if self.step == self.stop_step:\n            self.step = 0\n            raise StopIteration()\n\n        start = self.step * self.bsz\n        self.step += 1\n\n        chars, position, max_len = data2tensor(\n            self.chars[start:start + self.bsz], True)\n        words = data2tensor(self.words[start:start + self.bsz])\n        sub_sidx = data2tensor(\n            self.sub_sidx[start:start + self.bsz]).float().unsqueeze(2)\n        sub_eidx = data2tensor(\n            self.sub_eidx[start:start + self.bsz]).float().unsqueeze(2)\n        obj_sidx, obj_eidx = obj2tensor(\n            self.obj_idxs[start:start + self.bsz], max_len)\n        sub_slidx = subl2tensor(self.sub_slidx[start:start + self.bsz])\n        sub_elidx = subl2tensor(self.sub_elidx[start:start + self.bsz])\n\n        return chars, words, position, sub_sidx, sub_eidx, obj_sidx, obj_eidx, sub_slidx, sub_elidx\n\n\nif __name__ == ""__main__"":\n    import os\n\n    data = torch.load(os.path.join(const.DATAPATH, ""corpus.new.pt""))\n    dl = DataLoader(data[""dev""][""char""],\n                    data[""dev""][""word""],\n                    data[""dev""][""sub_sidx""],\n                    data[""dev""][""sub_eidx""],\n                    data[""dev""][""obj_idxs""],\n                    data[""dev""][""sub_slidx""],\n                    data[""dev""][""sub_elidx""],\n                    data[""word2idx""],\n                    data[""char2idx""],\n                    data[""predicate2id""],\n                    batch_size=2)\n\n    chars, words, position, sub_sidx, sub_eidx, obj_sidx, obj_eidx, sub_slidx, sub_elidx = next(\n        dl)\n\n    print(chars.shape)\n    print(words.shape)\n    print(position.shape)\n    print(sub_sidx.shape)\n    print(sub_eidx.shape)\n    print(obj_sidx.shape)\n    print(obj_eidx.shape)\n    print(sub_slidx.shape)\n    print(sub_elidx.shape)\n    \'\'\'\n    torch.Size([2, 125])\n    torch.Size([2, 125])\n    torch.Size([2, 125])\n    torch.Size([2, 125, 1])\n    torch.Size([2, 125, 1])\n    torch.Size([2, 125, 49])\n    torch.Size([2, 125, 49])\n    torch.Size([2, 1])\n    torch.Size([2, 1])\n    \'\'\'\n\n    id2chars = {v: k for k, v in dl.char2idx.items()}\n    id2words = {v: k for k, v in dl.word2idx.items()}\n\n    print("""".join([id2chars[idx] for idx in chars.tolist()[0]]))\n    print(position[0])\n    print(obj_sidx.ge(1).nonzero().tolist())\n    print(obj_eidx.ge(1).nonzero().tolist())\n    print(dl.predicate2id)\n    print(sub_sidx.ge(1).nonzero().tolist())\n'"
information-extraction/download.py,0,"b'import requests\n\nDATAPATH = ""https://dataset-bj.cdn.bcebos.com/sked/train_data.json""\nDEVPATH = ""https://dataset-bj.cdn.bcebos.com/sked/dev_data.json""\n\n\ndef main():\n    r = requests.get(DATAPATH)\n    with open(""data/train_data.json"", ""wb"") as code:\n        code.write(r.content)\n\n    r = requests.get(DEVPATH)\n    with open(""data/dev_data.json"", ""wb"") as code:\n        code.write(r.content)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
information-extraction/model.py,35,"b'import torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.nn.functional as F\nimport numpy as np\n\nimport const\n\n\ndef get_padding_mask(x):\n    return x.gt(0).unsqueeze(2).float()\n\n\ndef gather_index(encode, k1, k2, n=6):\n    x = torch.arange(start=0, end=n/(n-1.), step=1./(n-1), dtype=torch.float)\n    if k1.is_cuda:\n        x = x.cuda()\n\n    k1 = x*(k1.float())\n    k2 = (1-x)*(k2.float())\n    index = torch.round(k1+k2).long()\n    return torch.stack([torch.index_select(encode[idx], 0, index[idx]) for idx in range(encode.size(0))], dim=0)\n\n\ndef get_attn_padding_mask(seq_q, seq_k):\n    assert seq_q.dim() == 2 and seq_k.dim() == 2\n    bsz, len_q = seq_q.size()\n    pad_attn_mask = seq_k.data.eq(const.PAD).unsqueeze(1)\n    pad_attn_mask = pad_attn_mask.expand(bsz, len_q, len_q)\n    return pad_attn_mask\n\n\nclass DilatedGatedConv1D(nn.Module):\n    def __init__(self, dilation_rate, dim):\n        super().__init__()\n\n        self.dim = dim\n        self.dropout = nn.Dropout(p=0.1)\n        self.cnn = nn.Conv1d(\n            dim, dim*2, 3, padding=dilation_rate, dilation=dilation_rate)\n\n    def forward(self, x):\n        residual = x\n        x = self.cnn(x.transpose(1, 2)).transpose(1, 2)\n        x1, x2 = x[:, :, :self.dim], x[:, :, self.dim:]\n        x1 = torch.sigmoid(self.dropout(x1))\n        return residual*(1-x1) + x2*x1\n\n\nclass DgCNN(nn.Module):\n    def __init__(self, dim, dilation_rates: list):\n        super().__init__()\n\n        self.cnn1ds = nn.ModuleList(\n            [DilatedGatedConv1D(dilation_rate, dim) for dilation_rate in dilation_rates])\n\n    def forward(self, x, mask):\n        for layer in self.cnn1ds:\n            x = layer(x)*mask\n        return x\n\n\nclass LayerNorm(nn.Module):\n    def __init__(self, hidden_size, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n        self.gamma = nn.Parameter(torch.ones(hidden_size))\n        self.beta = nn.Parameter(torch.zeros(hidden_size))\n\n    def forward(self, input):\n        mu = torch.mean(input, dim=-1, keepdim=True)\n        sigma = torch.std(input, dim=-1, keepdim=True).clamp(min=self.eps)\n        output = (input - mu) / sigma\n        return output * self.gamma.expand_as(output) + self.beta.expand_as(output)\n\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self, d_k, dropout):\n        super().__init__()\n        self.temper = np.power(d_k, 0.5)\n        self.dropout = nn.Dropout(dropout)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, q, k, v, attn_mask):\n        attn = torch.bmm(q, k.transpose(1, 2)) / self.temper\n        attn.data.masked_fill_(attn_mask, -float(\'inf\'))\n\n        attn = self.softmax(attn.view(-1, attn.size(2))).view(*attn.size())\n        attn = self.dropout(attn)\n        return torch.bmm(attn, v)\n\n\nclass MultiHeadAtt(nn.Module):\n    def __init__(self, n_head, d_model, dropout=0.5):\n        super().__init__()\n        self.n_head = n_head\n        self.d_v = self.d_k = d_k = d_model // n_head\n\n        for name in [""w_qs"", ""w_ks"", ""w_vs""]:\n            self.__setattr__(name,\n                             nn.Parameter(torch.FloatTensor(n_head, d_model, d_k)))\n\n        self.attention = ScaledDotProductAttention(d_k, dropout)\n        self.lm = LayerNorm(d_model)\n        self.w_o = nn.Linear(d_model, d_model, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n        self.w_qs.data.normal_(std=const.INIT_RANGE)\n        self.w_ks.data.normal_(std=const.INIT_RANGE)\n        self.w_vs.data.normal_(std=const.INIT_RANGE)\n\n    def forward(self, q, k, v, attn_mask):\n        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n        residual = q\n\n        bsz, len_q, d_model = q.size()\n        len_k, len_v = k.size(1), v.size(1)\n\n        def reshape(x):\n            """"""[bsz, len, d_*] -> [n_head x (bsz*len) x d_*]""""""\n            return x.repeat(n_head, 1, 1).view(n_head, -1, d_model)\n\n        q_s, k_s, v_s = map(reshape, [q, k, v])\n\n        q_s = torch.bmm(q_s, self.w_qs).view(-1, len_q, d_k)\n        k_s = torch.bmm(k_s, self.w_ks).view(-1, len_k, d_k)\n        v_s = torch.bmm(v_s, self.w_vs).view(-1, len_v, d_v)\n\n        outputs = self.attention(q_s, k_s, v_s, attn_mask.repeat(n_head, 1, 1))\n        outputs = torch.cat(torch.split(outputs, bsz, dim=0),\n                            dim=-1).view(-1, n_head * d_v)\n        outputs = self.dropout(self.w_o(outputs)).view(bsz, len_q, -1)\n        return self.lm(outputs + residual)\n\n\nclass SubjectLinear(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n\n        self.seq = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.ReLU(),\n            nn.Linear(dim, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.seq(x)\n\n\nclass SubModel(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n\n        self.cnn = nn.Conv1d(2*dim, dim, 3, padding=1)\n        self.lr1 = nn.Linear(dim, 1)\n        self.lr2 = nn.Linear(dim, 1)\n\n    def forward(self, x):\n        x = F.relu(self.cnn(x.transpose(1, 2))).transpose(1, 2)\n        x1 = torch.sigmoid(self.lr1(x))\n        x2 = torch.sigmoid(self.lr2(x))\n\n        return x1, x2\n\n\nclass ObjModel(nn.Module):\n    def __init__(self, dim, num_classes):\n        super().__init__()\n\n        self.cnn = nn.Conv1d(4*dim, dim, 3, padding=1)\n        self.lr1 = nn.Linear(dim, 1)\n        self.lr2 = nn.Linear(dim, num_classes)\n        self.lr3 = nn.Linear(dim, num_classes)\n\n    def forward(self, x, shareFeat1, shareFeat2):\n        x = F.relu(self.cnn(x.transpose(1, 2))).transpose(1, 2)\n        x1 = torch.sigmoid(self.lr1(x))\n        x2 = torch.sigmoid(self.lr2(x))\n        x3 = torch.sigmoid(self.lr3(x))\n\n        x2 = x2*shareFeat1*x1\n        x3 = x3*shareFeat2*x1\n\n        return x2, x3\n\n\nclass ObjectRnn(nn.Module):\n    def __init__(self, d_model):\n        super().__init__()\n\n        self.rnn = nn.GRU(d_model,\n                          hidden_size=d_model,\n                          batch_first=True,\n                          bidirectional=True)\n        self.ln = LayerNorm(d_model*2)\n\n    def forward(self, x, sub_slidx, sub_elidx, pos_ebd):\n        idx = gather_index(x, sub_slidx, sub_elidx)\n        encode, _ = self.rnn(idx)\n        encode = self.ln(encode)[:, -1, :].unsqueeze(1)\n\n        pos_ebd = self.position(x, sub_slidx, sub_elidx, pos_ebd)\n\n        return encode+pos_ebd\n\n    def position(self, x, sidx, eidx, pos_ebd):\n        bsz, length, _ = x.size()\n        pos_idx = torch.arange(0, length).repeat(bsz, 1)\n        if x.is_cuda:\n            pos_idx = pos_idx.cuda()\n\n        s_pos = pos_ebd(torch.abs(pos_idx-sidx.long()))\n        e_pos = pos_ebd(torch.abs(pos_idx-eidx.long()))\n\n        return torch.cat((s_pos, e_pos), dim=-1)\n\n\nclass Model(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        self.args = args\n\n        self.char_ebd = nn.Embedding(args.char_size, args.inp_dim)\n        self.word_ebd = nn.Embedding(args.word_size, args.inp_dim)\n        self.pos_ebd = nn.Embedding(args.max_len+1, args.d_model)\n\n        self.char_lr = nn.Linear(args.inp_dim, args.d_model)\n        self.word_lr = nn.Linear(args.inp_dim, args.d_model)\n        self.encode_dropout = nn.Dropout(0.25)\n\n        self.dgcnn = DgCNN(args.d_model, args.dilation_rates)\n\n        self.sl1 = SubjectLinear(args.d_model)\n        self.sl2 = SubjectLinear(args.d_model)\n\n        self.sbj_att = MultiHeadAtt(args.n_head, args.d_model)\n\n        self.subModel = SubModel(args.d_model)\n\n        self.objectRnn = ObjectRnn(args.d_model)\n        self.obj_att = MultiHeadAtt(args.n_head, args.d_model)\n        self.objModel = ObjModel(args.d_model, args.num_classes)\n\n        self._reset_parameters()\n\n        if ""charW"" in args.__dict__ and ""wordW"" in args.__dict__:\n            self.use_vecs()\n        else:\n            self.char_ebd.weight.data.uniform_(-.1, .1)\n            self.word_ebd.weight.data.uniform_(-.1, .1)\n\n    def use_vecs(self):\n        args = self.args\n\n        self.char_ebd.weight.data.copy_(torch.from_numpy(args.charW))\n        self.word_ebd.weight.data.copy_(torch.from_numpy(args.wordW))\n\n    def _reset_parameters(self):\n        self.pos_ebd.weight.data.uniform_(-.1, .1)\n        for layer in self.modules():\n            if type(layer) == nn.Linear:\n                layer.weight.data.normal_(std=const.INIT_RANGE)\n\n    def encode(self, chars, words, posits):\n        mask = get_padding_mask(chars)\n        attn_mask = get_attn_padding_mask(chars, chars)\n        ebd_encode = self.char_lr(self.char_ebd(\n            chars)) + self.word_lr(self.word_ebd(words)) + self.pos_ebd(posits)\n\n        ebd_encode = self.encode_dropout(ebd_encode)\n        encode = self.dgcnn(ebd_encode, mask)\n\n        shareFeat1 = self.sl1(encode)\n        shareFeat2 = self.sl2(encode)\n\n        return encode, shareFeat1, shareFeat2, attn_mask, mask\n\n    def sub_predict(self, encode, attn_mask, shareFeat1, shareFeat2):\n        attn = self.sbj_att(encode, encode, encode, attn_mask)\n        output = torch.cat((attn, encode), dim=-1)\n\n        sub_sidx, sub_eidx = self.subModel(output)\n\n        return sub_sidx*shareFeat1, sub_eidx*shareFeat2\n\n    def obj_predict(self, encode, shareFeat1, shareFeat2, sub_slidx, sub_elidx, attn_mask):\n        rnn_encode = self.objectRnn(encode, sub_slidx, sub_elidx, self.pos_ebd)\n\n        attn = self.obj_att(encode, encode, encode, attn_mask)\n        encode = torch.cat((attn, encode, rnn_encode), dim=-1)\n\n        obj_sidx, obj_eidx = self.objModel(encode, shareFeat1, shareFeat2)\n\n        return obj_sidx, obj_eidx\n\n    def forward(self, chars, words, posits, sub_slidx, sub_elidx):\n        encode, shareFeat1, shareFeat2, attn_mask, mask = self.encode(\n            chars, words, posits)\n        sub_sidx, sub_eidx = self.sub_predict(\n            encode, attn_mask, shareFeat1, shareFeat2)\n        obj_sidx, obj_eidx = self.obj_predict(\n            encode, shareFeat1, shareFeat2, sub_slidx, sub_elidx, attn_mask)\n\n        return sub_sidx, sub_eidx, obj_sidx, obj_eidx, mask\n\n    def save_model(self, path):\n        torch.save(self.state_dict(), path)\n\n    def load_model(self, path, cuda):\n        if cuda:\n            self.load_state_dict(torch.load(path))\n            self.cuda()\n        else:\n            self.load_state_dict(torch.load(\n                path, map_location=lambda storage, loc: storage))\n            self.cpu()\n\n\nif __name__ == ""__main__"":\n    from data_loader import DataLoader\n    import argparse\n    import const\n    import os\n\n    data = torch.load(os.path.join(const.DATAPATH, ""corpus.pt""))\n    dl = DataLoader(data[""train""][""char""],\n                    data[""train""][""word""],\n                    data[""train""][""sub_sidx""],\n                    data[""train""][""sub_eidx""],\n                    data[""train""][""obj_sidx""],\n                    data[""train""][""obj_eidx""],\n                    data[""train""][""sub_slidx""],\n                    data[""train""][""sub_elidx""],\n                    data[""word2idx""],\n                    data[""char2idx""],\n                    data[""predicate2id""],\n                    batch_size=32)\n\n    chars, words, position, sub_sidx, sub_eidx, obj_sidx, obj_eidx, sub_slidx, sub_elidx = next(\n        dl)\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--batch_size\', type=int, default=64)\n    parser.add_argument(\'--dilation_rates\', type=str,\n                        default=\'1,2,5,1,2,5,1,2,5,1,1,1\')\n    parser.add_argument(\'--n_head\', type=int, default=8)\n    parser.add_argument(\'--d_model\', type=int, default=512)\n\n    args = parser.parse_args()\n    args.max_len = data[""max_len""]\n    args.char_size = len(data[""char2idx""])\n    args.word_size = len(data[""word2idx""])\n    args.num_classes = len(data[""predicate2id""])\n    args.inp_dim = 200\n    args.dilation_rates = list(map(int, args.dilation_rates.split("","")))\n\n    model = Model(args)\n    model = model.cuda()\n    sub_sidx, sub_eidx, obj_sidx, obj_eidx, mask = model(\n        chars, words, position, sub_slidx, sub_elidx)\n    print(sub_sidx.shape, sub_eidx.shape, obj_sidx.shape, obj_eidx.shape)\n    print(mask.tolist()[0])\n\n    id2chars = {v: k for k, v in dl.char2idx.items()}\n    print("""".join([id2chars[idx] for idx in chars.tolist()[0]]))\n'"
information-extraction/predict.py,10,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\nimport jieba.posseg as pseg\n\nfrom const import *\nfrom model import Model\nimport common\n\nimport time\nimport copy\nimport os\nimport sys\n\n\nclass Predict(object):\n    def __init__(self, model_datas=None, model_source=None, cuda=False):\n        assert model_datas is not None or model_source is not None, ""model and model_source should not be both None""\n\n        self.torch = torch.cuda if cuda else torch\n        self.cuda = cuda\n        self.seg = pseg\n\n        if model_source is not None:\n            if self.cuda:\n                model_source = torch.load(model_source)\n            else:\n                model_source = torch.load(\n                    model_source, map_location=lambda storage, loc: storage)\n            self.word2idx = model_source[""word2idx""]\n            self.char2idx = model_source[""char2idx""]\n            self.predicate2id = model_source[""predicate2id""]\n            self.args = args = model_source[""settings""]\n            self.max_len = model_source[""max_len""]\n            model = Model(args)\n            model.load_state_dict(model_source[\'model\'])\n\n            if self.cuda:\n                model = model.cuda()\n            else:\n                model = model.cpu()\n            self.model = model\n        else:\n            self.model = model_datas[""model""]\n            self.word2idx = model_datas[""word2idx""]\n            self.char2idx = model_datas[""char2idx""]\n            self.predicate2id = model_datas[""predicate2id""]\n            self.max_len = model_datas[""max_len""]\n\n        self.model.eval()\n        self.id2predicate = {v: k for k, v in self.predicate2id.items()}\n\n    def update_model(self, model):\n        self.model = model\n        self.model.eval()\n\n    def segment(self, text):\n        words = []\n        for w in [[e]*len(e) for e, _ in self.seg.cut(text)]:\n            words += w\n\n        return words\n\n    def predict(self, text):\n        triples = []\n        if len(text) > self.max_len:\n            text = text[:self.max_len]\n\n        words = self.segment(text)\n        c_id, w_id = common.q2idx(text, words, self.char2idx, self.word2idx)\n        position = [pos_i+1 for pos_i in range(len(c_id))]\n\n        with torch.no_grad():\n            c_id, w_id, position = map(lambda x: self.torch.LongTensor(\n                x).unsqueeze(0), (c_id, w_id, position))\n\n            encode, shareFeat1, shareFeat2, attn_mask, _ = self.model.encode(\n                c_id, w_id, position)\n            sub_sidx, sub_eidx = self.model.sub_predict(\n                encode, attn_mask, shareFeat1, shareFeat2)\n            sub_sidx = sub_sidx.squeeze().gt(0.5).nonzero().tolist()\n            sub_eidx = sub_eidx.squeeze().gt(0.4).nonzero().tolist()\n            while len(sub_sidx) and len(sub_eidx):\n                if sub_sidx[0][0] < sub_eidx[0][0]:\n                    s, e = sub_sidx.pop(0)[0], sub_eidx.pop(0)[0]\n                    subject = text[s:e+1]\n                    sub_slidx = self.torch.LongTensor([[s]])\n                    sub_elidx = self.torch.LongTensor([[e]])\n                    obj_sidx, obj_eidx = self.model.obj_predict(\n                        encode, shareFeat1, shareFeat2, sub_slidx, sub_elidx, attn_mask)\n\n                    obj_sidxs = obj_sidx.squeeze().t()\n                    obj_eidxs = obj_eidx.squeeze().t()\n                    for idx, (sid, eid) in enumerate(zip(obj_sidxs, obj_eidxs)):\n                        sids = sid.squeeze().gt(0.5).nonzero().tolist()\n                        eids = eid.squeeze().gt(0.4).nonzero().tolist()\n                        while len(sids) and len(eids):\n                            if sids[0][0] < eids[0][0]:\n                                s, e = sids.pop(0)[0], eids.pop(0)[0]\n                                triples.append(\n                                    (subject, self.id2predicate[idx], text[s:e+1]))\n                                if self.id2predicate[idx] == ""\xe5\xa6\xbb\xe5\xad\x90"":\n                                    triples.append(\n                                        (text[s:e+1], ""\xe4\xb8\x88\xe5\xa4\xab"", subject))\n                                elif self.id2predicate[idx] == ""\xe4\xb8\x88\xe5\xa4\xab"":\n                                    triples.append(\n                                        (text[s:e+1], ""\xe5\xa6\xbb\xe5\xad\x90"", subject))\n                            else:\n                                eids.pop(0)\n                else:\n                    sub_eidx.pop(0)\n\n        return set(triples)\n\n\nif __name__ == ""__main__"":\n    import json\n    import const\n    predict = Predict(model_source=""./weights/model_2.pt"")\n    triples = predict.predict(""\xe3\x80\x8a\xe6\x9d\x8e\xe7\x99\xbd\xe3\x80\x8b\xe6\x98\xaf\xe6\x9d\x8e\xe8\x8d\xa3\xe6\xb5\xa9\xe4\xbd\x9c\xe8\xaf\x8d\xe4\xbd\x9c\xe6\x9b\xb2\xe5\xb9\xb6\xe6\xbc\x94\xe5\x94\xb1\xe7\x9a\x84\xe6\xad\x8c\xe6\x9b\xb2\xef\xbc\x8c\xe8\xaf\xa5\xe6\x9b\xb2\xe6\x94\xb6\xe5\xbd\x95\xe4\xba\x8e2013\xe5\xb9\xb49\xe6\x9c\x8817\xe5\x8f\xb7\xe5\x8f\x91\xe8\xa1\x8c\xe7\x9a\x84\xe5\x8e\x9f\xe5\x88\x9b\xe4\xb8\x93\xe8\xbe\x91\xe3\x80\x8a\xe6\xa8\xa1\xe7\x89\xb9\xe3\x80\x8b\xe4\xb8\xad"")\n    print(triples)\n'"
information-extraction/train.py,9,"b'import os\nimport json\n\nimport argparse\nimport torch\nfrom tqdm import tqdm\nfrom torch.nn.functional import binary_cross_entropy\n\nimport data_loader\nimport const\nimport model\nimport common\nimport predict\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(\'--unuse_cuda\', action=\'store_true\')\nparser.add_argument(\'--data\', type=str, default=""data/corpus.pt"")\nparser.add_argument(\'--model_path\', type=str, default=\'weights\')\nparser.add_argument(\'--cuda_device\', type=str, default=\'0\')\n\nparser.add_argument(\'--batch_size\', type=int, default=32)\nparser.add_argument(\'--warm_epochs\', type=int, default=2)\nparser.add_argument(\'--epochs\', type=int, default=100)\nparser.add_argument(\'--seed\', type=int, default=1111)\n\nparser.add_argument(\'--dilation_rates\', type=str,\n                    default=\'1,2,5,1,2,5,1,2,5,1,1,1\')\nparser.add_argument(\'--n_head\', type=int, default=8)\nparser.add_argument(\'--d_model\', type=int, default=512)\nparser.add_argument(\'--n_warmup_steps\', type=int, default=0)\n\nargs = parser.parse_args()\n\nos.environ[""CUDA_VISIBLE_DEVICES""] = args.cuda_device\n\nuse_cuda = torch.cuda.is_available() and not args.unuse_cuda\n\ntorch.manual_seed(args.seed)\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\ndata = torch.load(args.data)\nif ""charW"" in data and ""wordW"" in data:\n    args.charW, args.wordW = data[""charW""], data[""wordW""]\n\ntraining_data = data_loader.DataLoader(data[""train""][""char""],\n                                       data[""train""][""word""],\n                                       data[""train""][""sub_sidx""],\n                                       data[""train""][""sub_eidx""],\n                                       data[""train""][""obj_idxs""],\n                                       data[""train""][""sub_slidx""],\n                                       data[""train""][""sub_elidx""],\n                                       data[""word2idx""],\n                                       data[""char2idx""],\n                                       data[""predicate2id""],\n                                       cuda=use_cuda,\n                                       batch_size=args.batch_size)\n\nvalidation_data = data_loader.DataLoader(data[""dev""][""char""],\n                                         data[""dev""][""word""],\n                                         data[""dev""][""sub_sidx""],\n                                         data[""dev""][""sub_eidx""],\n                                         data[""dev""][""obj_idxs""],\n                                         data[""dev""][""sub_slidx""],\n                                         data[""dev""][""sub_elidx""],\n                                         data[""word2idx""],\n                                         data[""char2idx""],\n                                         data[""predicate2id""],\n                                         cuda=use_cuda,\n                                         batch_size=args.batch_size,\n                                         shuffle=False)\n\nargs.n_warmup_steps = args.n_warmup_steps if args.n_warmup_steps and args.n_warmup_steps != 0 else training_data.stop_step\nargs.char_size = len(data[""char2idx""])\nargs.word_size = len(data[""word2idx""])\nargs.num_classes = len(data[""predicate2id""])\nargs.dilation_rates = list(map(int, args.dilation_rates.split("","")))\nargs.max_len = data[""max_len""]\nargs.inp_dim = 200\n\nmodel = model.Model(args)\nif use_cuda:\n    model = model.cuda()\n\noptimizer = common.ScheduledOptim(\n    torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\n    args.d_model, args.n_warmup_steps)\n\n\ndef mask_binary_cross_entropy(inp, target, mask):\n    loss = binary_cross_entropy(inp, target, reduction=\'none\')\n    return torch.sum(loss*mask) / torch.sum(mask)\n\n\ndef dev(i):\n    model.eval()\n    total_loss = 0\n    for chars, words, position, sub_sidx, sub_eidx, obj_sidx, obj_eidx, sub_slidx, sub_elidx in tqdm(validation_data, mininterval=1, desc=\'dev Processing\', leave=False):\n        with torch.no_grad():\n            p_sub_sidx, p_sub_eidx, p_obj_sidx, p_obj_eidx, mask = model(\n                chars, words, position, sub_slidx, sub_elidx)\n\n            ss_loss = mask_binary_cross_entropy(p_sub_sidx, sub_sidx, mask)\n            se_loss = mask_binary_cross_entropy(p_sub_eidx, sub_eidx, mask)\n            os_loss = mask_binary_cross_entropy(p_obj_sidx, obj_sidx, mask)\n            oe_loss = mask_binary_cross_entropy(p_obj_eidx, obj_eidx, mask)\n\n            loss = ss_loss+se_loss+os_loss+oe_loss\n            total_loss += loss.data.item()\n\n    print(\n        f""dev epoch {i+1}/{args.epochs} loss: {total_loss/training_data.stop_step:.4f}"")\n\n\ndef train(i):\n    model.train()\n    total_loss = 0\n    for chars, words, position, sub_sidx, sub_eidx, obj_sidx, obj_eidx, sub_slidx, sub_elidx in tqdm(training_data, mininterval=1, desc=\'Train Processing\', leave=False):\n        optimizer.zero_grad()\n        p_sub_sidx, p_sub_eidx, p_obj_sidx, p_obj_eidx, mask = model(\n            chars, words, position, sub_slidx, sub_elidx)\n\n        ss_loss = mask_binary_cross_entropy(p_sub_sidx, sub_sidx, mask)\n        se_loss = mask_binary_cross_entropy(p_sub_eidx, sub_eidx, mask)\n        os_loss = mask_binary_cross_entropy(p_obj_sidx, obj_sidx, mask)\n        oe_loss = mask_binary_cross_entropy(p_obj_eidx, obj_eidx, mask)\n\n        loss = ss_loss+se_loss+os_loss+oe_loss\n        loss.backward()\n\n        optimizer.step()\n        optimizer.update_learning_rate()\n        total_loss += loss.data.item()\n\n    print(\n        f""train epoch {i+1}/{args.epochs} loss: {total_loss/training_data.stop_step:.4f}"")\n\n\ndef test(i, predict):\n    model.eval()\n    t = pre = groud = 0\n    inf = open(""data/dev_data.json"", encoding=""utf8"")\n    for line in inf:\n        line = json.loads(line)\n        text = line[""text""]\n        g_triples = set()\n        for trip in line[""spo_list""]:\n            g_triples.add((trip[""subject""], trip[""predicate""], trip[""object""]))\n\n        p_triples = predict.predict(text)\n        pre += len(p_triples)\n        groud += len(g_triples)\n        t += len(p_triples.intersection(g_triples))\n\n    print(\n        f""test epoch {i+1}/{args.epochs} precision: {t/(pre+0.001):.4f} recall: {t/groud:.4f} f1: {2*t/(pre+groud):.4f}"")\n    return 2*t/(pre+groud)\n\n\ndef save():\n    model_state_dict = model.state_dict()\n    model_source = {\n        ""settings"": args,\n        ""model"": model_state_dict,\n        ""word2idx"": data[\'word2idx\'],\n        ""char2idx"": data[\'char2idx\'],\n        ""max_len"": data[""max_len""],\n        ""predicate2id"": data[""predicate2id""],\n    }\n    torch.save(model_source, f""{os.path.join(args.model_path, \'model.pt\')}"")\n\n\nos.makedirs(""weights"", exist_ok=True)\n\ndata[""model""] = model\npredict = predict.Predict(model_datas=data, cuda=True)\nbest_f1 = 0\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(args.epochs):\n        train(epoch)\n        print(\'-\' * 90)\n        dev(epoch)\n        print(\'-\' * 90)\n        predict.update_model(model)\n        f1 = test(epoch, predict)\n        if f1 > best_f1:\n            print(f""new best f1 score {f1:.4f} and save model"")\n            best_f1 = f1\n            model.save_model(\n                f""{os.path.join(args.model_path, \'tmp_model.pt\')}"")\n            save()\n        else:\n            print(f""f1 {f1} and reload best model"")\n            model.load_model(\n                f""{os.path.join(args.model_path, \'tmp_model.pt\')}"", use_cuda)\n        print(\'-\' * 90)\nexcept KeyboardInterrupt:\n    print(""Exiting from training early"")\n'"
lstm-text-classfication/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    UNK: '<unk>',\n    PAD: '<pad>'\n}\n\n"""
lstm-text-classfication/corpus.py,1,"b'import torch\n\nimport logging\nimport argparse\nimport os\n\nfrom const import *\n\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\n\nclass Dictionary(object):\n    def __init__(self, word2idx={}, idx_num=0):\n        self.word2idx = word2idx\n        self.idx = idx_num\n\n    def _add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def _convert(self):\n        self.idx2word = {v: k for k, v in self.word2idx.items()}\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Words(Dictionary):\n    def __init__(self):\n        word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        super().__init__(word2idx=word2idx, idx_num=len(word2idx))\n\n    def __call__(self, sents):\n        words = set([word for sent in sents for word in sent])\n        for word in words:\n            self._add(word)\n\n\nclass Labels(Dictionary):\n    def __init__(self):\n        super().__init__()\n\n    def __call__(self, labels):\n        _labels = set(labels)\n        for label in _labels:\n            self._add(label)\n\n\nclass Corpus(object):\n    def __init__(self, path, save_data, max_len=16):\n        self.train = os.path.join(path, ""train"")\n        self.valid = os.path.join(path, ""valid"")\n        self._save_data = save_data\n\n        self.w = Words()\n        self.l = Labels()\n        self.max_len = max_len\n\n    def parse_data(self, _file, is_train=True, fine_grained=False):\n        """"""\n        fine_grained: Whether to use the fine-grained (50-class) version of TREC\n                or the coarse grained (6-class) version.\n        """"""\n        _sents, _labels = [], []\n        for sentence in open(_file):\n            label, _, _words = sentence.replace(\'\\xf0\', \' \').partition(\' \')\n            label = label.split("":"")[0] if not fine_grained else label\n\n            words = _words.strip().split()\n\n            if len(words) > self.max_len:\n                words = words[:self.max_len]\n\n            _sents += [words]\n            _labels += [label]\n        if is_train:\n            self.w(_sents)\n            self.l(_labels)\n            self.train_sents = _sents\n            self.train_labels = _labels\n        else:\n            self.valid_sents = _sents\n            self.valid_labels = _labels\n\n    def save(self):\n        self.parse_data(self.train)\n        self.parse_data(self.valid, False)\n\n        data = {\n            \'max_len\': self.max_len,\n            \'dict\': {\n                \'train\': self.w.word2idx,\n                \'vocab_size\': len(self.w),\n                \'label\': self.l.word2idx,\n                \'label_size\': len(self.l),\n            },\n            \'train\': {\n                \'src\': word2idx(self.train_sents, self.w.word2idx),\n                \'label\': [self.l.word2idx[l] for l in self.train_labels]\n            },\n            \'valid\': {\n                \'src\': word2idx(self.valid_sents, self.w.word2idx),\n                \'label\': [self.l.word2idx[l] for l in self.valid_labels]\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'Finish dumping the data to file - [{}]\'.format(self._save_data))\n        print(\'words length - [{}]\'.format(len(self.w)))\n        print(\'label size - [{}]\'.format(len(self.l)))\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'CNN Classification\')\n    parser.add_argument(\'--file-path\', type=str, default=""./data"",\n                        help=\'file path\')\n    parser.add_argument(\'--save-data\', type=str, default=""./data/corpus.pt"",\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--max-lenth\', type=int, default=16,\n                        help=\'max length left of sentence [default: 16]\')\n    args = parser.parse_args()\n    corpus = Corpus(args.file_path, args.save_data, args.max_lenth)\n    corpus.save()\n'"
lstm-text-classfication/data_loader.py,3,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\nclass DataLoader(object):\n    def __init__(self, src_sents, label, max_len, cuda=True,\n                batch_size=64, shuffle=True, evaluation=False):\n        self.cuda = cuda\n        self.sents_size = len(src_sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size\n        self.evaluation = evaluation\n\n        self._batch_size = batch_size\n        self._max_len = max_len\n        self._src_sents = np.asarray(src_sents)\n        self._label = np.asarray(label)\n        if shuffle:\n            self._shuffle()\n\n    def _shuffle(self):\n        indices = np.arange(self._src_sents.shape[0])\n        np.random.shuffle(indices)\n        self._src_sents = self._src_sents[indices]\n        self._label = self._label[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def pad_to_longest(insts, max_len):\n            inst_data = np.array([inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n\n            inst_data_tensor = Variable(torch.from_numpy(inst_data), volatile=self.evaluation)\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step*self._batch_size\n        _bsz = self._batch_size\n        self._step += 1\n        data = pad_to_longest(self._src_sents[_start:_start+_bsz], self._max_len)\n        label = Variable(torch.from_numpy(self._label[_start:_start+_bsz]),\n                    volatile=self.evaluation)\n        if self.cuda:\n            label = label.cuda()\n\n        return data, label\n'"
lstm-text-classfication/main.py,8,"b'import argparse\nimport time\n\nimport torch\nfrom torch.autograd import Variable\n\nparser = argparse.ArgumentParser(description=\'LSTM text classification\')\nparser.add_argument(\'--lr\', type=float, default=0.001,\n                    help=\'initial learning rate [default: 0.001]\')\nparser.add_argument(\'--epochs\', type=int, default=100,\n                    help=\'number of epochs for train\')\nparser.add_argument(\'--batch-size\', type=int, default=16,\n                    help=\'batch size for training [default: 16]\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda-able\', action=\'store_true\',\n                    help=\'enables cuda\')\n\nparser.add_argument(\'--save\', type=str, default=\'./LSTM_Text.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--data\', type=str, default=\'./data/corpus.pt\',\n                    help=\'location of the data corpus\')\n\nparser.add_argument(\'--dropout\', type=float, default=0.5,\n                    help=\'the probability for dropout (0 = no dropout) [default: 0.5]\')\nparser.add_argument(\'--embed-dim\', type=int, default=64,\n                    help=\'number of embedding dimension [default: 64]\')\nparser.add_argument(\'--hidden-size\', type=int, default=128,\n                    help=\'number of lstm hidden dimension [default: 128]\')\nparser.add_argument(\'--lstm-layers\', type=int, default=3,\n                    help=\'biLSTM layer numbers\')\nparser.add_argument(\'--bidirectional\', action=\'store_true\',\n                    help=\'If True, becomes a bidirectional LSTM [default: False]\')\n\nargs = parser.parse_args()\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available() and args.cuda_able\n\n# ##############################################################################\n# Load data\n###############################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_len = data[""max_len""]\nargs.vocab_size = data[\'dict\'][\'vocab_size\']\nargs.label_size = data[\'dict\'][\'label_size\']\n\ntraining_data = DataLoader(\n             data[\'train\'][\'src\'],\n             data[\'train\'][\'label\'],\n             args.max_len,\n             batch_size=args.batch_size,\n             cuda=use_cuda)\n\nvalidation_data = DataLoader(\n              data[\'valid\'][\'src\'],\n              data[\'valid\'][\'label\'],\n              args.max_len,\n              batch_size=args.batch_size,\n              shuffle=False,\n              cuda=use_cuda)\n\n# ##############################################################################\n# Build model\n# ##############################################################################\nimport model\n\nrnn = model.LSTM_Text(args)\nif use_cuda:\n    rnn = rnn.cuda()\n\noptimizer = torch.optim.Adam(rnn.parameters(), lr=args.lr, weight_decay=0.001)\ncriterion = torch.nn.CrossEntropyLoss()\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\n\ntrain_loss = []\nvalid_loss = []\naccuracy = []\n\ndef repackage_hidden(h):\n    if type(h) == Variable:\n        if use_cuda:\n            return Variable(h.data).cuda()\n        return Variable(h.data)\n    else:\n        return tuple(repackage_hidden(v) for v in h)\n\ndef evaluate():\n    rnn.eval()\n    corrects = eval_loss = 0\n    _size = validation_data.sents_size\n    hidden = rnn.init_hidden()\n    for data, label in tqdm(validation_data, mininterval=0.2,\n                desc=\'Evaluate Processing\', leave=False):\n        hidden = repackage_hidden(hidden)\n        pred, hidden = rnn(data, hidden)\n        loss = criterion(pred, label)\n\n        eval_loss += loss.data\n        corrects += (torch.max(pred, 1)[1].view(label.size()).data == label.data).sum()\n\n    return eval_loss[0]/_size, corrects, corrects/_size * 100.0, _size\n\ndef train():\n    rnn.train()\n    total_loss = 0\n    hidden = rnn.init_hidden()\n    for data, label in tqdm(training_data, mininterval=1,\n                desc=\'Train Processing\', leave=False):\n        optimizer.zero_grad()\n        hidden = repackage_hidden(hidden)\n        target, hidden = rnn(data, hidden)\n        loss = criterion(target, label)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.data\n    return total_loss[0]/training_data.sents_size\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs+1):\n        epoch_start_time = time.time()\n        loss = train()\n        train_loss.append(loss*1000.)\n\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(epoch, time.time() - epoch_start_time, loss))\n\n        loss, corrects, acc, size = evaluate()\n        valid_loss.append(loss*1000.)\n        accuracy.append(acc)\n\n        epoch_start_time = time.time()\n        print(\'-\' * 90)\n        print(\'| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(epoch, time.time() - epoch_start_time, loss, acc, corrects, size))\n        print(\'-\' * 90)\n        if not best_acc or best_acc < corrects:\n            best_acc = corrects\n            model_state_dict = rnn.state_dict()\n            model_source = {\n                ""settings"": args,\n                ""model"": model_state_dict,\n                ""src_dict"": data[\'dict\'][\'train\']\n            }\n            torch.save(model_source, args.save)\nexcept KeyboardInterrupt:\n    print(""-""*90)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format((time.time() - total_start_time)/60.0))\n'"
lstm-text-classfication/model.py,8,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.nn import init\nimport torch.nn.functional as F\n\nimport const\n\n\nclass LayerNorm(nn.Module):\n    def __init__(self, hidden_size, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(hidden_size))\n        self.bias = nn.Parameter(torch.zeros(hidden_size))\n\n    def forward(self, input):\n        mu = torch.mean(input, dim=-1, keepdim=True)\n        sigma = torch.std(input, dim=-1, keepdim=True).clamp(min=self.eps)\n        output = (input - mu) / sigma\n        return output * self.weight.expand_as(output) + self.bias.expand_as(output)\n\n\nclass LSTM_Text(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.num_directions = 2 if self.bidirectional else 1\n\n        self.lookup_table = nn.Embedding(self.vocab_size, self.embed_dim,\n                                         padding_idx=const.PAD)\n        self.lstm = nn.LSTM(self.embed_dim,\n                            self.hidden_size,\n                            self.lstm_layers,\n                            dropout=self.dropout,\n                            bidirectional=self.bidirectional)\n        self.ln = LayerNorm(self.hidden_size * self.num_directions)\n        self.logistic = nn.Linear(self.hidden_size * self.num_directions,\n                                  self.label_size)\n\n        self._init_weights()\n\n    def _init_weights(self, scope=1.):\n        self.lookup_table.weight.data.uniform_(-scope, scope)\n        self.logistic.weight.data.uniform_(-scope, scope)\n        self.logistic.bias.data.fill_(0)\n\n    def init_hidden(self):\n        num_layers = self.lstm_layers * self.num_directions\n\n        weight = next(self.parameters()).data\n        return (Variable(weight.new(num_layers, self.batch_size, self.hidden_size).zero_()), Variable(weight.new(num_layers, self.batch_size, self.hidden_size).zero_()))\n\n    def forward(self, input, hidden):\n        encode = self.lookup_table(input)\n        lstm_out, hidden = self.lstm(encode.transpose(0, 1), hidden)\n        output = self.ln(lstm_out)[-1]\n        return F.log_softmax(self.logistic(output)), hidden\n'"
neural-artistic-style/img_loader.py,2,"b'import torch\nfrom torchvision import transforms\n\nfrom PIL import Image\n\ntry:\n    import matplotlib.pyplot as plt\n\n    def imshow(tensor, imsize=512, title=None):\n        image = tensor.clone().cpu()\n        image = image.view(*tensor.size())\n        image = transforms.ToPILImage()(image)\n        plt.imshow(image)\n        if title is not None:\n            plt.title(title)\n        plt.pause(5)\nexcept:\n    plt = None\n    imshow = None\n    print(""Device do not support matplotlib"")\n\nclass IMG_Processer(object):\n    def __init__(self, img_size=800, path=""images/""):\n        self.img_path = path\n        self.img_size = img_size\n\n    def toTensor(self, img):\n        encode = transforms.Compose([transforms.Resize(self.img_size),\n               transforms.ToTensor(),\n               transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]),\n               transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], std=[1,1,1]),\n               transforms.Lambda(lambda x: x.mul_(255)),\n            ])\n\n        return encode(Image.open(img))\n\n    def img2tensor(self, style_img_name, content_img_name):\n        _style, _content = map(self.toTensor,\n            list(map(lambda n: self.img_path+n, [style_img_name, content_img_name])))\n\n        return _style, _content\n\n    def tensor2img(self, tensor, epoch):\n        decode = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1./255)),\n               transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961],\n                                    std=[1,1,1]),\n               transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]),\n               ])\n        tensor = decode(tensor)\n\n        loader = transforms.Compose([transforms.ToPILImage()])\n        img = loader(tensor.clamp_(0, 1))\n\n        img.save(self.img_path + ""/result_{}.jpg"".format(epoch))\n\nif __name__ == \'__main__\':\n    if imshow is not None:\n        ip = IMG_Processer()\n        _style, _content = ip.img2tensor(\'night.jpg\', \'Tuebingen_Neckarfront.jpg\')\n\n        plt.ion()\n\n        plt.figure()\n        imshow(_style)\n\n        plt.figure()\n        imshow(_content)\n\n    else:\n        print(""Do not support"")\n'"
neural-artistic-style/model.py,3,"b'import torch\nimport torch.nn as nn\n\nimport copy\n\n\nclass GramMatrix(nn.Module):\n    def forward(self, input):\n        _, channels, h, w = input.size()\n        out = input.view(-1, h * w)\n        out = torch.mm(out, out.t())\n        return out.div(channels * h * w)\n\n\nclass StyleLoss(nn.Module):\n    def __init__(self, target, weight):\n        super().__init__()\n\n        self.target = target.detach() * weight\n        self.weight = weight\n        self.criterion = nn.MSELoss()\n        self.gm = GramMatrix()\n\n    def forward(self, input):\n        gm = self.gm(input.clone())\n        loss = self.criterion(gm * self.weight, self.target)\n        return loss\n\n\ndef check_layers(layers):\n    """"""\n    relu1_* - 2\xef\xbc\x8c relu2_* - 2\xef\xbc\x8c relu3_* - 4\xef\xbc\x8c relu4_* - 4\xef\xbc\x8c relu5_* - 4\n    """"""\n    in_layers = []\n    for layer in layers:\n        layer = layer[-3:]\n        if layer[0] == \'1\' or layer[0] == \'2\':\n            in_layers += [2 * (int(layer[0]) - 1) + int(layer[2]) - 1]\n        else:\n            in_layers += [4 * (int(layer[0]) - 3) + int(layer[2]) + 3]\n    return in_layers\n\n\nclass Vgg_Model(nn.Module):\n    def __init__(self, vgg):\n        super().__init__()\n        self.layers = copy.deepcopy(vgg)\n\n    def forward(self, input, out_layers):\n        relu_outs, out = [], input\n        out_layers = check_layers(out_layers)\n\n        for layer in self.layers:\n            out = layer(out)\n            if isinstance(layer, nn.ReLU):\n                relu_outs.append(out)\n\n        outs = [relu_outs[index - 1] for index in out_layers]\n        return outs\n\n\nif __name__ == \'__main__\':\n    from torch.autograd import Variable\n\n    from torchvision.models import vgg19\n    from img_loader import IMG_Processer\n\n    STYLE_LAYERS = (\'relu1_1\', \'relu2_1\', \'relu3_1\', \'relu4_1\', \'relu5_1\')\n    CONTENT_LAYERS = (\'relu4_2\',)\n    vgg = vgg19(True).features\n    vm = Vgg_Model(vgg)\n    vm = vm.cuda()\n\n    ip = IMG_Processer()\n    _style, _content = ip.img2tensor(\'night.jpg\', \'Tuebingen_Neckarfront.jpg\')\n    _style = Variable(_content.unsqueeze(0))\n    _style = _style.cuda()\n    # print(vm(_style, STYLE_LAYERS))\n    print(vm(_style, STYLE_LAYERS + CONTENT_LAYERS))\n'"
neural-artistic-style/train.py,6,"b'import argparse\n\nparser = argparse.ArgumentParser(description=\'Neural Artistic Style\')\nparser.add_argument(\'--seed\', type=int, default=1111)\nparser.add_argument(\'--unuse-cuda\', action=\'store_true\')\nparser.add_argument(\'--epochs\', type=int, default=500)\nparser.add_argument(\'--style_layers\', type=str,\n                    default=""relu1_1,relu2_1,relu3_1,relu4_1,relu5_1"")\nparser.add_argument(\'--content_layers\', type=str, default=""relu4_2"")\nparser.add_argument(\'--style_img\', type=str, default=""4_style.jpg"")\nparser.add_argument(\'--content_img\', type=str, default=""4_content.jpg"")\nparser.add_argument(\'--alpha\', type=float, default=1.)\nparser.add_argument(\'--beta\', type=float, default=1e3)\n\nargs = parser.parse_args()\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision.models import vgg19\n\nfrom img_loader import IMG_Processer\nfrom model import Vgg_Model, StyleLoss, GramMatrix\n\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available() and not args.unuse_cuda\nargs.style_layers = list(args.style_layers.split(\',\'))\nargs.content_layers = list(args.content_layers.split(\',\'))\nout_layers = args.style_layers + args.content_layers\n\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\nvgg = vgg19(True).features\nmodel = Vgg_Model(vgg)\n\nip = IMG_Processer()\nstyle_input, content_input = ip.img2tensor(args.style_img, args.content_img)\nstyle_input, content_input = Variable(\n    style_input.unsqueeze(0)), Variable(content_input.unsqueeze(0))\n\nif use_cuda:\n    style_input, content_input = map(\n        lambda v: v.cuda(), (style_input, content_input))\n    model = model.cuda()\n\nout_img = content_input.clone()\nout_param = nn.Parameter(out_img.data)\n\n_content_layers = [layer.detach()\n                   for layer in model(content_input, args.content_layers)]\n_style_layers = model(style_input, args.style_layers)\nstyle_criterions = [StyleLoss(GramMatrix()(layer), args.beta)\n                    for layer in _style_layers]\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.LBFGS([out_param])\nn_epoch = [0]\n\n\ndef closure():\n\n    optimizer.zero_grad()\n\n    _out_layers = model(out_param, out_layers)\n\n    _loss = 0\n    for step, _criterion in enumerate(style_criterions):\n        _loss += _criterion(_out_layers[step])\n\n    for step, _out_layer in enumerate(_out_layers[step + 1:]):\n        _loss += criterion(_out_layer * args.alpha,\n                           _content_layers[step] * args.alpha)\n\n    _loss.backward()\n    n_epoch[0] += 1\n\n    if n_epoch[0] % 30 == 0:\n        print(\'epochs: {}, loss: {}\'.format(n_epoch[0], _loss.data[0]))\n        ip.tensor2img(out_param.data.cpu().squeeze(), n_epoch[0])\n\n    return _loss\n\n\nwhile n_epoch[0] < args.epochs:\n    optimizer.step(closure)\n'"
ngram/main.py,9,"b'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.autograd as autograd\nimport torch.nn.functional as F\n\nEPOCHS = 100\n\ntest_sentence = """"""n-gram models are widely used in statistical natural\nlanguage processing . In speech recognition , phonemes and sequences of\nphonemes are modeled using a n-gram distribution . For parsing , words\nare modeled such that each n-gram is composed of n words . For language\nidentification , sequences of characters / graphemes ( letters of the alphabet\n) are modeled for different languages For sequences of characters ,\nthe 3-grams ( sometimes referred to as "" trigrams "" ) that can be\ngenerated from "" good morning "" are "" goo "" , "" ood "" , "" od "" , "" dm "",\n"" mo "" , "" mor "" and so forth , counting the space character as a gram\n( sometimes the beginning and end of a text are modeled explicitly , adding\n"" __g "" , "" _go "" , "" ng_ "" , and "" g__ "" ) . For sequences of words ,\nthe trigrams that can be generated from "" the dog smelled like a skunk ""\nare "" # the dog "" , "" the dog smelled "" , "" dog smelled like "", "" smelled\nlike a "" , "" like a skunk "" and "" a skunk # "" ."""""".split()\n\ntrigrams = [([test_sentence[i], test_sentence[i+1]],\n            test_sentence[i+2]) for i in range(len(test_sentence) - 2)]\n\nvocab = set(test_sentence)\n\nword2idx = {word: i for i, word in enumerate(vocab)}\nidx2word = {i: word for word, i in word2idx.items()}\n\nclass NGram(nn.Module):\n    def __init__(self, vocab_size, embedding_dim=16, context_size=2):\n        super().__init__()\n\n        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n\n        self.l1 = nn.Linear(context_size * embedding_dim, 128)\n        self.l2 = nn.Linear(128, vocab_size)\n        self._init_weight()\n\n    def forward(self, inputs):\n        embeds = self.embeddings(inputs).view(1, -1)\n        out = F.relu(self.l1(embeds))\n        out = self.l2(out)\n        log_probs = F.log_softmax(out)\n        return log_probs\n\n    def _init_weight(self, scope=0.1):\n        self.embeddings.weight.data.uniform_(-scope, scope)\n        self.l1.weight.data.uniform_(0, scope)\n        self.l1.bias.data.fill_(0)\n        self.l2.weight.data.uniform_(0, scope)\n        self.l2.bias.data.fill_(0)\n\ncriterion = nn.NLLLoss()\nmodel = NGram(len(vocab))\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nmodel.train()\nfor epoch in range(EPOCHS):\n    total_loss = torch.Tensor([0])\n    for context, target in trigrams:\n        context_idxs = list(map(lambda w: word2idx[w], context))\n        context_var = autograd.Variable(torch.LongTensor(context_idxs))\n\n        model.zero_grad()\n\n        log_probs = model(context_var)\n        loss = criterion(log_probs,\n            autograd.Variable(torch.LongTensor([word2idx[target]])))\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.data\n    print(total_loss[0])\n\nmodel.eval()\ndef predict(context):\n    context_idxs = list(map(lambda w: word2idx[w], context))\n    context_var = autograd.Variable(\n        torch.LongTensor(context_idxs), volatile=True)\n\n    predict = model(context_var)\n    index = (torch.max(predict, 1)[1]).data.tolist()[0]\n    return idx2word[index]\n\n\nfor context in [[""widely"", ""used""], [""and"", ""so""], [""are"", ""modeled""]]:\n    print(""{} + {} = {}"".format(context[0], context[1], predict(context)))\n\n'"
pair-ranking-cnn/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    PAD: '<blank>',\n    UNK: '<unk>'\n}\n"""
pair-ranking-cnn/corpus.py,1,"b'import torch\nimport argparse\n\nfrom utils import prepare, corpora2idx\nimport const\n\nclass Dictionary(object):\n    def __init__(self):\n        self.ind2idx = {\n            const.WORD[const.PAD]: const.PAD,\n            const.WORD[const.UNK]: const.UNK\n        }\n        self.idx2ind = {\n            const.PAD: const.WORD[const.PAD],\n            const.UNK: const.WORD[const.UNK]\n        }\n        self.idx = 2\n\n    def add(self, ind):\n        if self.ind2idx.get(ind) is None:\n            self.ind2idx[ind] = self.idx\n            self.idx2ind[self.idx] = ind\n            self.idx += 1\n\n    def build_idx(self, sents, min_count):\n        corpora = [cor for sent in sents for cor in sent]\n        word_count = {w: 0 for w in set(corpora)}\n        for w in corpora: word_count[w]+=1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\nclass Corpus(object):\n    def __init__(self, train_src, save_data, valid_src=None,\n                 max_src=16, max_tgt=24, min_word_count=5):\n        self._train_src = train_src\n        self._valid_src = valid_src\n        self._save_data = save_data\n        self.max_src = max_src\n        self.max_tgt = max_tgt\n        self._min_word_count = min_word_count\n        self.src_sents = None\n        self.tgt_sents = None\n        self.src_valid_sents = None\n        self.tgt_valid_sents = None\n\n        self.jb = Jieba(""./segmenter_dicts"", useSynonym=True, HMM=False) # unuse hmm\n        self.swf = StopwordFilter(""./segmenter_dicts/stopwords.txt"")\n        self.src_dict = Dictionary()\n        self.tgt_dict = Dictionary()\n\n    def sent2corpora(self, sentence, synonym=False):\n        sentence = prepare(sentence)\n        corpora = [e for e in self.jb.segment_search(sentence) if self.swf.filter(e)]\n        new_corpora = []\n        for corpus in corpora:\n            if synonym and corpus in self.jb.synonym:\n                corpus = self.jb.synonym[corpus]\n            new_corpora.append(corpus)\n        return new_corpora\n\n    def parse_train(self):\n        src_sents, tgt_sents, labels  = [], [], []\n        for sentences in sopen(self._train_src):\n            sentence = sentences.strip().split()\n            if len(sentence) != 3: continue\n            src_sent, tgt_sent, label = sentence\n\n            src_corpora = [word for word in src_sent if self.swf.filter(word)]\n            if len(src_corpora) > self.max_src:\n                src_corpora = src_corpora[:self.max_src]\n\n            tgt_corpora = self.sent2corpora(tgt_sent)\n            if len(tgt_corpora) > self.max_tgt:\n                tgt_corpora = tgt_corpora[:self.max_tgt]\n\n            src_sents.append(src_corpora)\n            tgt_sents.append(tgt_corpora)\n            labels.append(int(label))\n\n        src_ignore = self.src_dict.build_idx(src_sents, self._min_word_count)\n        tgt_ignore = self.tgt_dict.build_idx(tgt_sents, self._min_word_count)\n\n        if src_ignore != 0:\n            logging.info(""Ignored src corpus counts - [{}]"".format(src_ignore))\n        if tgt_ignore != 0:\n            logging.info(""Ignored tgt corpus counts - [{}]"".format(tgt_ignore))\n\n        self.src_sents = src_sents\n        self.tgt_sents = tgt_sents\n        self.labels = labels\n\n    def parse_valid(self, by_word=True):\n        """"""\n        question answer1 answer2...\n        """"""\n        src_sents, tgt_sents, valid_labels = [], [], []\n        for sentences in sopen(self._valid_src):\n            sentence = sentences.strip().split()\n            if len(sentence) != 3: continue\n            src_sent, tgt_sent, label = sentence\n\n            if by_word:\n                src_corpora = [word for word in src_sent if self.swf.filter(word)]\n                if len(src_corpora) > self.max_src:\n                    src_corpora = src_corpora[:self.max_src]\n            else:\n                src_corpora = self.sent2corpora(src_sent)\n                if len(src_corpora) > self.max_src:\n                    src_corpora = src_corpora[:self.max_src]\n\n            tgt_corpora = self.sent2corpora(tgt_sent)\n            if len(tgt_corpora) > self.max_tgt:\n                tgt_corpora = tgt_corpora[:self.max_tgt]\n\n            src_sents.append(src_corpora)\n            tgt_sents.append(tgt_corpora)\n            valid_labels.append(int(label))\n\n        self.src_valid_sents = src_sents\n        self.tgt_valid_sents = tgt_sents\n        self.valid_labels = valid_labels\n\n    def save(self):\n        data = {\n            \'max_lenth_src\': self.max_src,\n            \'max_lenth_tgt\': self.max_tgt,\n            \'dict\': {\n                \'src\': self.src_dict.ind2idx,\n                \'src_size\': len(self.src_dict),\n                \'tgt\': self.tgt_dict.ind2idx,\n                \'tgt_size\': len(self.tgt_dict)\n            },\n            \'train\': {\n                \'src\': corpora2idx(self.src_sents, self.src_dict.ind2idx),\n                \'tgt\': corpora2idx(self.tgt_sents, self.tgt_dict.ind2idx),\n                \'label\': self.labels\n            }\n        }\n\n        if self._valid_src is not None:\n            data[\'valid\'] = {\n                \'src\': corpora2idx(self.src_valid_sents, self.src_dict.ind2idx),\n                \'tgt\': corpora2idx(self.tgt_valid_sents, self.tgt_dict.ind2idx),\n                \'label\': self.valid_labels\n            }\n\n        torch.save(data, self._save_data)\n        logging.info(\'Finish dumping the corora data to file - [{}]\'.format(self._save_data))\n        logging.info(\'src corpora length - [{}] | target corpora length - [{}]\'.format(len(self.src_dict), len(self.tgt_dict)))\n\n    def process(self):\n        self.parse_train()\n        if self._valid_src is not None:\n            self.parse_valid()\n        self.save()\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'seq2sqe corpora handle\')\n    parser.add_argument(\'--train-src\', type=str, required=True,\n                        help=\'train file\')\n    parser.add_argument(\'--save-data\', type=str, required=True,\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--valid-src\', type=str, default=None,\n                        help=\'valid file\')\n    parser.add_argument(\'--max-lenth-src\', type=int, default=16,\n                        help=\'max length left of sentence [default: 32]\')\n    parser.add_argument(\'--max-lenth-tgt\', type=int, default=24,\n                        help=\'max length right of sentence [default: 32]\')\n    parser.add_argument(\'--min-word-count\', type=int, default=\'1\',\n                        help=\'min corpora count to discard [default: 1]\')\n    args = parser.parse_args()\n    corpus = Corpus(args.train_src, args.save_data, args.valid_src,\n                    args.max_lenth_tgt, args.max_lenth_src, args.min_word_count)\n    corpus.process()\n'"
pair-ranking-cnn/data_loader.py,3,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\nclass DataLoader(object):\n    def __init__(self, src_sents, tgt_sents, label, max_src, max_tgt, cuda=True, batch_size=64, shuffle=True):\n        assert len(src_sents) == len(tgt_sents)\n        self.cuda = cuda\n        self._batch_size = batch_size\n        self._sents_size = len(src_sents)\n        self._max_src = max_src\n        self._max_tgt = max_tgt\n        self._src_sents = np.asarray(src_sents)\n        self._tgt_sents = np.asarray(tgt_sents)\n        self._label = np.asarray(label)\n\n        if shuffle:\n            self.shuffle()\n\n    def shuffle(self):\n        indices = np.arange(self._src_sents.shape[0])\n        np.random.shuffle(indices)\n        self._src_sents = self._src_sents[indices]\n        self._tgt_sents = self._tgt_sents[indices]\n        self._label = self._label[indices]\n\n    def get_batch(self, i, evaluation=False):\n        def pad_to_longest(insts, max_len):\n            inst_data = np.array([inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n            inst_data_tensor = Variable(torch.from_numpy(inst_data), volatile=evaluation)\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        bsz = min(self._batch_size, self._sents_size-1-i)\n\n        src = pad_to_longest(self._src_sents[i:i+bsz], self._max_src)\n        tgt = pad_to_longest(self._tgt_sents[i:i+bsz], self._max_tgt)\n        label = Variable(torch.from_numpy(self._label[i:i+bsz]), volatile=evaluation)\n        if self.cuda:\n                label = label.cuda()\n\n        return src, tgt, label\n'"
pair-ranking-cnn/module.py,10,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nfrom torch.autograd import Variable\n\nclass CNN_Ranking(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.embedded_chars_left = nn.Embedding(self.src_vocab_size, self.embed_dim)\n        self.embedded_chars_right = nn.Embedding(self.tgt_vocab_size, self.embed_dim)\n\n        self.conv_left, self.conv_right = [], []\n        for i, filter_size in enumerate(self.filter_sizes):\n            conv_left_name = ""conv_left_%d"" % i\n            conv_right_name = ""conv_right_%d"" % i\n            self.__setattr__(conv_left_name,\n                             nn.Conv2d(in_channels=1,\n                             out_channels=self.num_filters,\n                             kernel_size=(filter_size, self.embed_dim)))\n            self.conv_left.append(self.__getattr__(conv_left_name))\n\n            self.__setattr__(conv_right_name,\n                             nn.Conv2d(in_channels=1,\n                             out_channels=self.num_filters,\n                             kernel_size=(filter_size, self.embed_dim)))\n            self.conv_right.append(self.__getattr__(conv_right_name))\n\n        ins = len(self.filter_sizes) * self.num_filters\n        self.simi_weight = nn.Parameter(torch.zeros(ins, ins))\n\n        self.out_lr = nn.Linear(2*ins+1, self.hidden_size)\n        self.logistic = nn.Linear(self.hidden_size, 2)\n\n        self._init_weights()\n\n    def forward(self, input_left, input_right):\n        n_idx = 0\n        c_idx = 1\n        h_idx = 2\n        w_idx = 3\n\n        enc_left = self.embedded_chars_left(input_left)\n        enc_right = self.embedded_chars_right(input_right)\n\n        enc_left = enc_left.unsqueeze(c_idx)\n        enc_right = enc_right.unsqueeze(c_idx)\n\n        enc_outs_left, enc_outs_right = [], []\n        for index, (encoder_left, encoder_right) in enumerate(zip(self.conv_left, self.conv_right)):\n            enc_left_ = F.relu(encoder_left(enc_left))\n            enc_right_ = F.relu(encoder_right(enc_right))\n\n            h_left = enc_left_.size()[h_idx]\n            h_right = enc_right_.size()[h_idx]\n\n            enc_left_ = F.max_pool2d(enc_left_, kernel_size=(h_left, 1))\n            enc_right_ = F.max_pool2d(enc_right_, kernel_size=(h_right, 1))\n\n            enc_left_ = enc_left_.squeeze(w_idx)\n            enc_left_ = enc_left_.squeeze(h_idx)\n            enc_right_ = enc_right_.squeeze(w_idx)\n            enc_right_ = enc_right_.squeeze(h_idx)\n\n            enc_outs_left.append(enc_left_)\n            enc_outs_right.append(enc_right_)\n\n        hid_in_left = torch.cat(enc_outs_left, c_idx)\n        enc_outs_right = torch.cat(enc_outs_right, c_idx)\n\n        transform_left = torch.mm(hid_in_left, self.simi_weight)\n        sims = torch.sum(torch.mm(transform_left,\n                enc_outs_right.t()), dim=c_idx, keepdim=True)\n\n        new_input = torch.cat([hid_in_left, sims, enc_outs_right], c_idx)\n\n        out = F.dropout(self.out_lr(new_input), p=self.dropout)\n        return F.log_softmax(self.logistic(out))\n\n    def _init_weights(self, scope=1.):\n        self.embedded_chars_left.weight.data.uniform_(-scope, scope)\n        self.embedded_chars_right.weight.data.uniform_(-scope, scope)\n        init.xavier_uniform(self.simi_weight)\n        init.xavier_uniform(self.out_lr.weight)\n        init.xavier_uniform(self.logistic.weight)\n'"
pair-ranking-cnn/predict.py,6,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport numpy as np\n\nimport const\nfrom module import CNN_Ranking\nfrom utils import prepare, corpora2idx\n\nclass Predict(object):\n    def __init__(self, model_source, cuda=False, beam_size=3):\n        self.torch = torch.cuda if cuda else torch\n        self.cuda = cuda\n        self.jb = Jieba(""./segmenter_dicts"", useSynonym=True, HMM=False)\n        self.swf = StopwordFilter(""./segmenter_dicts/stopwords.txt"")\n\n        model_source = torch.load(model_source)\n        self.src_dict = model_source[""src_dict""]\n        self.tgt_dict = model_source[""tgt_dict""]\n        self.src_idx2ind = {v: k for k, v in model_source[""tgt_dict""].items()}\n        self.args = args = model_source[""settings""]\n        model = CNN_Ranking(args)\n        model.load_state_dict(model_source[\'model\'])\n\n        if self.cuda:\n            model = model.cuda()\n        else:\n            model = model.cpu()\n        self.model = model.eval()\n\n    def sent2corpora(self, sentence, synonym=False):\n        sentence = prepare(sentence)\n        corpora = [e[0] for e in self.jb.segment(sentence) if self.swf.filter(e[0])]\n        new_corpora = []\n        for corpus in corpora:\n            if synonym and corpus in self.jb.synonym:\n                corpus = self.jb.synonym[corpus]\n            new_corpora.append(corpus)\n        return new_corpora\n\n    def sent2tensor(self, question, answers):\n        q_max_len = self.args.max_lenth_src\n        a_max_len = self.args.max_lenth_tgt\n        src_corpora = [word for word in question if self.swf.filter(word)]\n        if len(src_corpora) > q_max_len:\n            src_corpora = src_corpora[:q_max_len]\n        else:\n            src_corpora += [const.WORD[const.PAD]]*(a_max_len-len(src_corpora))\n        src_corpora = [self.src_dict[corpus] for corpus in src_corpora]\n\n        q_tensor = torch.LongTensor(src_corpora).unsqueeze(0)\n        q_tensor = Variable(q_tensor.repeat(len(answers), 1), volatile=True)\n\n        tgt_sents = []\n        for answer in answers:\n            tgt_corpora = self.sent2corpora(answer)\n            if len(tgt_corpora) > a_max_len:\n                tgt_corpora = tgt_corpora[:a_max_len]\n            else:\n                tgt_corpora += [const.WORD[const.PAD]]*(a_max_len-len(tgt_corpora))\n            tgt_sents.append(tgt_corpora)\n\n        a_tensor = corpora2idx(tgt_sents, self.tgt_dict)\n        a_tensor = Variable(torch.LongTensor(a_tensor), volatile=True)\n\n        if self.cuda:\n            return q_tensor.cuda(), a_tensor.cuda()\n        else:\n            return q_tensor, a_tensor\n\n\n    def process(self, q_tensor, a_tensor, answers, top_k):\n        pred = self.model(q_tensor, a_tensor)\n        scores, indexs = pred.sort(dim=0, descending=True)\n        hit_scores, hit_indexs = scores.data.chunk(2, dim=1), indexs.data.chunk(2, dim=1)\n        print(hit_scores)\n        hit_scores = hit_scores[1].squeeze().tolist()\n        hit_indexs = hit_indexs[1].squeeze().tolist()\n        best_answers = []\n        top_k = min(top_k, pred.size(0))\n        for k_num, (score, index) in enumerate(zip(hit_scores, hit_indexs)):\n            if (k_num-1) == top_k: break\n            best_answers += [(answers[index], score)]\n\n        return best_answers\n\n    def predict(self, question, answers, top_k=3):\n        q_tensor, a_tensor = self.sent2tensor(question, answers)\n        answers = self.process(q_tensor, a_tensor, answers, top_k)\n        return answers\n'"
pair-ranking-cnn/train.py,11,"b'import argparse\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn.functional as F\n\nparser = argparse.ArgumentParser(description=\'CNN Ranking\')\nparser.add_argument(\'--epochs\', type=int, default=32,\n                    help=\'number of epochs for train [default: 32]\')\nparser.add_argument(\'--batch-size\', type=int, default=64,\n                    help=\'batch size for training [default: 64]\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--log-interval\',  type=int, default=1000,\n                    help=\'report interval [default: 1000]\')\nparser.add_argument(\'--cuda-able\', action=\'store_true\',\n                    help=\'enables cuda\')\nparser.add_argument(\'--lr\', type=float, default=0.001,\n                    help=\'initial learning rate [default: 0.001]\')\n\nparser.add_argument(\'--save\', type=str, default=\'model/cnn_ranking_model\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--save-epoch\', action=\'store_true\',\n                    help=\'save every epoch\')\nparser.add_argument(\'--data\', type=str, default=\'./data/pair_cnn.pt\',\n                    help=\'location of the data corpus\')\n\nparser.add_argument(\'--embed-dim\', type=int, default=64,\n                    help=\'number of embedding dimension [default: 64]\')\nparser.add_argument(\'--filter-sizes\', type=str, default=\'2,3\',\n                    help=\'filter sizes\')\nparser.add_argument(\'--num-filters\', type=int, default=64,\n                    help=\'Number of filters per filter size [default: 64]\')\nparser.add_argument(\'--dropout\', type=float, default=0.5,\n                    help=\'the probability for dropout (0 = no dropout) [default: 0.5]\')\nparser.add_argument(\'--hidden-size\', type=int, default=128,\n                    help=\'hidden size\')\nparser.add_argument(\'--l_2\', type=float, default=0.,\n                    help=""L2 regularizaion lambda [default: 0.0]"")\n\nargs = parser.parse_args()\ntorch.manual_seed(args.seed)\n\nuse_cuda = torch.cuda.is_available() and args.cuda_able\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\nargs.filter_sizes = list(map(int, args.filter_sizes.split("","")))\n\n# ##############################################################################\n# Load data\n# ##############################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_lenth_src = data[""max_lenth_src""]\nargs.max_lenth_tgt = data[""max_lenth_tgt""]\n\nargs.src_vocab_size = data[\'dict\'][\'src_size\']\nargs.tgt_vocab_size = data[\'dict\'][\'tgt_size\']\n\ntraining_data = DataLoader(\n             data[\'train\'][\'src\'],\n             data[\'train\'][\'tgt\'],\n             data[\'train\'][\'label\'],\n             args.max_lenth_src,\n             args.max_lenth_tgt,\n             batch_size=args.batch_size,\n             cuda=use_cuda)\n\nvalidation_data = DataLoader(\n              data[\'valid\'][\'src\'],\n              data[\'valid\'][\'tgt\'],\n              data[\'valid\'][\'label\'],\n              args.max_lenth_src,\n              args.max_lenth_tgt,\n              batch_size=args.batch_size,\n              shuffle=False,\n              cuda=use_cuda)\n\n# ##############################################################################\n# Build model\n# ##############################################################################\nfrom module import CNN_Ranking\n\nmodel = CNN_Ranking(args)\nif use_cuda:\n   model = model.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\ncriterion = torch.nn.CrossEntropyLoss()\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\n\ndef evaluate():\n    model.eval()\n    corrects = eval_loss = 0\n    _size = validation_data._sents_size\n    for batch in range(0, _size, args.batch_size):\n        src, tgt, label = validation_data.get_batch(batch, evaluation=True)\n        pred = model(src, tgt)\n        loss = criterion(pred, label)\n        eval_loss += loss.data[0]\n        corrects += (torch.max(pred, 1)[1].view(label.size()).data == label.data).sum()\n\n    return eval_loss/_size, corrects, corrects/_size * 100.0, _size\n\ndef train(epoch):\n    model.train()\n    start_time = time.time()\n    total_loss = 0\n    for batch, i in enumerate(range(0, training_data._sents_size, args.batch_size)):\n        src, tgt, label = training_data.get_batch(i)\n\n        optimizer.zero_grad()\n        pred = model(src, tgt)\n\n        loss = criterion(pred, label)\n        loss.backward()\n\n        optimizer.step()\n        total_loss += loss.data\n\n        if batch % args.log_interval == 0 and batch > 0:\n            cur_loss = total_loss[0] / args.log_interval\n            elapsed = time.time() - start_time\n            print(\'| epoch {:3d} | {:5d}/{:d} batches | {:5.2f} ms/batch | loss {:5.6f}\'.format(epoch, batch, training_data._sents_size // args.batch_size, elapsed * 1000 / args.log_interval, cur_loss))\n            start_time = time.time()\n            total_loss = 0\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\ntry:\n    for epoch in range(1, args.epochs+1):\n        epoch_start_time = time.time()\n        train(epoch)\n        loss, corrects, acc, size = evaluate()\n        print(\'-\' * 120)\n        print(\'| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(epoch, time.time() - epoch_start_time, loss, acc, corrects, size))\n        print(\'-\' * 120)\n\n        model_state_dict = model.state_dict()\n        model_source = {\n            ""settings"": args,\n            ""model"": model_state_dict,\n            ""src_dict"": data[\'dict\'][\'src\'],\n            ""tgt_dict"": data[\'dict\'][\'tgt\']\n        }\n        if not best_acc or best_acc < corrects:\n            best_acc = corrects\n            torch.save(model_source, args.save)\n        if args.save_epoch:\n            torch.save(model_source, ""{}_{}"".format(args.save, epoch))\n\nexcept KeyboardInterrupt:\n    print(""-""*80)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format((time.time() - total_start_time)/60.0))\n'"
pair-ranking-cnn/utils.py,0,"b'import const\n\ndef corpora2idx(sents, ind2idx):\n    return [[ind2idx[w] if w in ind2idx else const.UNK for w in s] for s in sents]\n\n'"
pointer-network/common.py,6,"b'import torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport numpy as np\nimport re\n\nimport const\n\n\ndef get_non_pad_mask(seq):\n    assert seq.dim() == 2\n    return seq.ne(const.PAD).type(torch.float).unsqueeze(-1)\n\n\ndef get_padding_mask(x):\n    return x.eq(0)\n\n\ndef get_sinusoid_encoding_table(n_position, d_hid, padding_idx=None):\n    def cal_angle(position, hid_idx):\n        return position / np.power(10000, 2 * (hid_idx // 2) / d_hid)\n\n    def get_posi_angle_vec(position):\n        return [cal_angle(position, hid_j) for hid_j in range(d_hid)]\n\n    sinusoid_table = np.array([get_posi_angle_vec(pos_i)\n                               for pos_i in range(n_position)])\n\n    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n\n    if padding_idx is not None:\n        sinusoid_table[padding_idx] = 0.\n\n    return torch.FloatTensor(sinusoid_table)\n\n\ndef get_attn_key_pad_mask(seq_k, seq_q, byte=False):\n    len_q = seq_q.size(1)\n    padding_mask = seq_k.eq(const.PAD)\n    padding_mask = padding_mask.unsqueeze(1).expand(-1, len_q, -1)\n    if byte:\n        return padding_mask.byte()\n    return padding_mask\n\n\ndef get_subsequent_mask(seq):\n    sz_b, len_s = seq.size()\n    subsequent_mask = torch.triu(\n        torch.ones((len_s, len_s), device=seq.device, dtype=torch.uint8), diagonal=1)\n    subsequent_mask = subsequent_mask.unsqueeze(0).expand(sz_b, -1, -1)\n\n    return subsequent_mask\n\n\ndef is_chinese_char(c):\n    if ((c >= 0x4E00 and c <= 0x9FFF) or\n            (c >= 0x3400 and c <= 0x4DBF) or\n            (c >= 0x20000 and c <= 0x2A6DF) or\n            (c >= 0x2A700 and c <= 0x2B73F) or\n            (c >= 0x2B740 and c <= 0x2B81F) or\n            (c >= 0x2B820 and c <= 0x2CEAF) or\n            (c >= 0xF900 and c <= 0xFAFF) or\n            (c >= 0x2F800 and c <= 0x2FA1F)):\n        return True\n    return False\n\n\ndef split_char(text):\n    text = """".join([w for w in text.split()])\n    step, words = 0, []\n    un_chinese = """"\n    while step < len(text):\n        if is_chinese_char(ord(text[step])):\n            words.append(text[step])\n            step += 1\n        else:\n            while step < len(text):\n                if is_chinese_char(ord(text[step])):\n                    words.append(un_chinese.lower())\n                    un_chinese = """"\n                    break\n                un_chinese += text[step]\n                step += 1\n    if un_chinese:\n        return words + [un_chinese.lower()]\n    return words\n\n\ndef texts2idx(texts, word2idx):\n    return [[word2idx[word] if word in word2idx else const.UNK for word in text] for text in texts]\n\n\ndef find_index(text, word):\n    stop_index = text.index(const.WORD[const.EOS])\n    if word in text[stop_index:]:\n        idx = text.index(word, stop_index)\n    else:\n        idx = text.index(word)\n    text[idx] = ""@@@""\n    return idx\n\n\ndef find_text_index(q_words, new_tgt_words):\n    word_map, q_words = {}, q_words.copy()\n    t_index = np.zeros(len(new_tgt_words), dtype=int)\n    for index, word in enumerate(new_tgt_words):\n        if word in q_words:\n            pointer = find_index(q_words, word)\n            t_index[index] = pointer\n            word_map[word] = pointer\n        elif word in word_map:\n            t_index[index] = word_map[word]\n        else:\n            raise Exception(\n                f""invalid word {word} from {\'\'.join(q_words)} {\'\'.join(new_tgt_words)}"")\n    return t_index\n'"
pointer-network/const.py,0,"b'DATAPATH = ""data""\n\nPAD = 0\nUNK = 1\nBOS = 2\nEOS = 3\n\nWORD = {\n    PAD: \'<pad>\',\n    UNK: \'<unk>\',\n    BOS: \'<s>\',\n    EOS: \'</s>\'\n}\n\nINIT_RANGE = 0.02\n'"
pointer-network/corpus.py,1,"b'import torch\nimport numpy as np\n\nimport argparse\nimport logging\n\nimport common\nfrom const import *\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[BOS]: BOS,\n            WORD[EOS]: EOS,\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        self.idx = 4\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, sents, min_count):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words:\n            word_count[w] += 1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Corpus(object):\n    def __init__(self, save_data=f""{DATAPATH}/corpus.pt"", min_word_count=1, max_len=184):\n        self._save_data = save_data\n        self.min_word_count = min_word_count\n        self.max_len = max_len\n        self.dict = Dictionary()\n        self.parse()\n        self.save()\n\n    def parse(self):\n        def parse_file(inf):\n            src_texts, src_turn, tgt_indexs, tgt_texts = [], [], [], []\n            with open(inf, encoding=""utf8"") as contexts:\n                for line in contexts:\n                    query1, query2, query3, target = line.strip().split(""\\t\\t"")\n\n                    q1_words = common.split_char(query1)\n                    turn1 = [1]*(len(q1_words))\n                    q2_words = common.split_char(query2)\n                    turn2 = [2]*(len(q2_words)+1)\n                    q3_words = common.split_char(query3)\n                    turn3 = [3]*(len(q3_words))\n\n                    q_words = q1_words + q2_words + [WORD[EOS]] + q3_words\n                    turns = turn1 + turn2 + turn3\n                    if len(q_words) > self.max_len:\n                        continue\n\n                    assert len(q_words) == len(turns)\n                    src_texts.append(q_words)\n                    src_turn.append(turns)\n\n                    tgt_words = common.split_char(target)\n                    new_tgt_words = []\n                    for word in tgt_words:\n                        if word in q_words:\n                            new_tgt_words.append(word)\n\n                    tgt_texts.append([WORD[BOS]]+new_tgt_words)\n\n                    new_tgt_words = new_tgt_words + [WORD[EOS]]\n                    t_index = common.find_text_index(q_words, new_tgt_words)\n\n                    tgt_indexs.append(t_index)\n\n                return src_texts, src_turn, tgt_indexs, tgt_texts\n\n        src_texts, src_turn, tgt_indexs, tgt_texts = parse_file(\n            f""{DATAPATH}/corpus"")\n        print(\n            f""Ignored word counts - {self.dict(src_texts, self.min_word_count)}"")\n\n        src_texts = np.asarray(common.texts2idx(src_texts, self.dict.word2idx))\n        src_turn = np.asarray(src_turn)\n        tgt_indexs = np.asarray(tgt_indexs)\n        tgt_texts = np.asarray(common.texts2idx(tgt_texts, self.dict.word2idx))\n\n        assert src_texts.shape == src_turn.shape\n        assert tgt_indexs.shape == tgt_texts.shape\n\n        index = np.arange(tgt_texts.shape[0])\n        np.random.shuffle(index)\n        src_texts = src_texts[index]\n        src_turn = src_turn[index]\n        tgt_indexs = tgt_indexs[index]\n        tgt_texts = tgt_texts[index]\n\n        self.src_texts_train = src_texts[2000:]\n        self.src_turn_train = src_turn[2000:]\n        self.tgt_indexs_train = tgt_indexs[2000:]\n        self.tgt_texts_train = tgt_texts[2000:]\n\n        self.src_texts_test = src_texts[:2000]\n        self.src_turn_test = src_turn[:2000]\n        self.tgt_indexs_test = tgt_indexs[:2000]\n        self.tgt_texts_test = tgt_texts[:2000]\n\n    def save(self):\n        data = {\n            \'word2idx\':  self.dict.word2idx,\n            \'max_len\':  self.max_len,\n            \'train\': {\n                \'src_texts\': self.src_texts_train,\n                \'src_turn\': self.src_turn_train,\n                \'tgt_indexs\': self.tgt_indexs_train,\n                \'tgt_texts\':  self.tgt_texts_train,\n            },\n            \'valid\': {\n                \'src_texts\': self.src_texts_test,\n                \'src_turn\': self.src_turn_test,\n                \'tgt_indexs\': self.tgt_indexs_test,\n                \'tgt_texts\':  self.tgt_texts_test,\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(f\'corpora length - {len(self.dict)}\')\n\n\nif __name__ == ""__main__"":\n    Corpus()\n'"
pointer-network/data_loader.py,4,"b'import numpy as np\nimport torch\n\nimport const\n\n\nclass DataLoader(object):\n    def __init__(self, src_texts, src_turn, tgt_indexs, tgt_texts, cuda, batch_size):\n        self.cuda = cuda\n        self.sents_size = len(src_texts)\n        self._step = 0\n        self.stop_step = self.sents_size // batch_size\n        self._batch_size = batch_size\n        self.src_texts = np.asarray(src_texts)\n        self.src_turn = np.asarray(src_turn)\n        self.tgt_indexs = np.asarray(tgt_indexs)\n        self.tgt_texts = np.asarray(tgt_texts)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def pad_to_longest(insts):\n            max_len = max(len(inst) for inst in insts)\n            inst_data = np.array(\n                [inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n            inst_position = np.array(\n                [[pos_i+1 if w_i != const.PAD else 0 for pos_i, w_i in enumerate(inst)] for inst in inst_data])\n\n            inst_data_tensor = torch.from_numpy(inst_data)\n            inst_position_tensor = torch.from_numpy(inst_position)\n\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n                inst_position_tensor = inst_position_tensor.cuda()\n            return inst_data_tensor.long(), inst_position_tensor.long(), max_len\n\n        def index_pairs(t_indexs):\n            max_len = max(len(inst) for inst in t_indexs)\n            indexs = np.array([inst.tolist() + [const.PAD]\n                               * (max_len - len(inst)) for inst in t_indexs])\n            indexs = torch.from_numpy(indexs)\n            if self.cuda:\n                indexs = indexs.cuda()\n\n            return indexs.long()\n\n        def turns2tensor(turns, src_max_len):\n            turns_data = np.array(\n                [inst + [const.PAD] * (src_max_len - len(inst)) for inst in turns])\n            turns_data = torch.from_numpy(turns_data)\n            if self.cuda:\n                turns_data = turns_data.cuda()\n            return turns_data.long()\n\n        if self._step == self.stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step*self._batch_size\n        _bsz = self._batch_size\n        self._step += 1\n\n        src_tensor, src_postion, src_max_len = pad_to_longest(\n            self.src_texts[_start:_start+_bsz])\n        tgt_tensor, tgt_postion, tgt_max_len = pad_to_longest(\n            self.tgt_texts[_start:_start+_bsz])\n\n        tgt_indexs_tensor = index_pairs(self.tgt_indexs[_start:_start+_bsz])\n        turns_tensor = turns2tensor(\n            self.src_turn[_start:_start+_bsz], src_max_len)\n\n        return (src_tensor, src_postion, turns_tensor), (tgt_tensor, tgt_postion), tgt_indexs_tensor\n'"
pointer-network/layers.py,5,"b'import torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torch.nn.functional as F\n\nimport numpy as np\n\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self, d_k, dropout=0.1):\n        super().__init__()\n        self.temperature = np.power(d_k, 0.5)\n        self.dropout = nn.Dropout(dropout)\n        self.softmax = nn.Softmax(dim=2)\n\n    def forward(self, q, k, v, mask=None):\n        attn = torch.bmm(q, k.transpose(1, 2))\n        attn = attn / self.temperature\n\n        if mask is not None:\n            attn = attn.masked_fill(mask, -np.inf)\n\n        attn = self.softmax(attn)\n        attn = self.dropout(attn)\n        output = torch.bmm(attn, v)\n\n        return output, attn\n\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n        super().__init__()\n\n        self.n_head = n_head\n        self.d_k = d_k\n        self.d_v = d_v\n\n        self.w_qs = nn.Linear(d_model, n_head * d_k)\n        self.w_ks = nn.Linear(d_model, n_head * d_k)\n        self.w_vs = nn.Linear(d_model, n_head * d_v)\n\n        self.attention = ScaledDotProductAttention(d_k)\n        self.layer_norm = nn.LayerNorm(d_model)\n\n        self.fc = nn.Linear(n_head * d_v, d_model)\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, q, k, v, mask=None):\n\n        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n\n        sz_b, len_q, _ = q.size()\n        sz_b, len_k, _ = k.size()\n        sz_b, len_v, _ = v.size()\n\n        residual = q\n\n        q = self.layer_norm(q)\n\n        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n\n        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, d_k)\n        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, d_k)\n        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_v, d_v)\n\n        mask = mask.repeat(n_head, 1, 1)\n        output, attn = self.attention(q, k, v, mask=mask)\n\n        output = output.view(n_head, sz_b, len_q, d_v)\n        output = output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1)\n\n        output = self.dropout(self.fc(output))\n        output = output + residual\n\n        return output, attn\n\n\nclass PositionWise(nn.Module):\n    def __init__(self, d_model, d_ff, dropout):\n        super().__init__()\n\n        self.seq = nn.Sequential(\n            nn.Conv1d(d_model, d_ff, 1),\n            nn.ReLU(),\n            nn.Conv1d(d_ff, d_model, 1),\n            nn.Dropout(dropout)\n        )\n        self.lm = nn.LayerNorm(d_model)\n\n    def forward(self, input):\n        residual = input\n\n        input = self.lm(input)\n\n        out = self.seq(input.transpose(1, 2)).transpose(1, 2)\n        return residual + out\n\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, d_ff, d_k, d_v, n_head, dropout=0.1):\n        super().__init__()\n        self.mh = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout)\n        self.pw = PositionWise(d_model, d_ff, dropout)\n\n    def forward(self, enc_input, non_pad_mask=None, slf_attn_mask=None):\n        enc_output, enc_slf_attn = self.mh(\n            enc_input, enc_input, enc_input, slf_attn_mask)\n        enc_output *= non_pad_mask\n\n        enc_output = self.pw(enc_output)\n        enc_output *= non_pad_mask\n\n        return enc_output, enc_slf_attn\n\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, d_ff, d_k, d_v, n_head, dropout=0.1):\n        super().__init__()\n        self.slf_mh = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout)\n        self.dec_mh = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout)\n        self.pw = PositionWise(d_model, d_ff, dropout)\n\n    def forward(self, dec_input, enc_output, non_pad_mask=None, slf_attn_mask=None, dec_enc_attn_mask=None):\n        dec_output, dec_slf_attn = self.slf_mh(dec_input, dec_input,\n                                               dec_input, slf_attn_mask)\n        dec_output *= non_pad_mask\n        m_dec_output = dec_output\n\n        dec_output, dec_enc_attn = self.dec_mh(\n            dec_output, enc_output, enc_output, dec_enc_attn_mask)\n        dec_output *= non_pad_mask\n\n        dec_output = self.pw(dec_output)\n        dec_output *= non_pad_mask\n\n        return dec_output, m_dec_output\n'"
pointer-network/model.py,8,"b'import torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\nfrom layers import EncoderLayer, DecoderLayer\nimport common\nfrom const import *\nimport const\n\n\nclass CrossEntropy(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, props, tgt):\n        tgt_props = props.gather(2, tgt.unsqueeze(2)).squeeze()\n        mask = (tgt > 0).float()\n        return -(tgt_props * mask).sum() / (mask.sum() + 1e-9)\n\n\nclass Encoder(nn.Module):\n    def __init__(self, n_enc, d_model, d_ff, d_k, d_v, n_head, dropout):\n        super().__init__()\n\n        self.encodes = nn.ModuleList([\n            EncoderLayer(d_model, d_ff, d_k, d_v, n_head, dropout) for _ in range(n_enc)])\n\n    def forward(self, encode, slf_attn_mask, non_pad_mask):\n        enc_output = encode\n        for layer in self.encodes:\n            enc_output, _ = layer(enc_output, non_pad_mask, slf_attn_mask)\n        return enc_output\n\n\nclass Decoder(nn.Module):\n    def __init__(self, n_dec, d_model, d_ff, d_k, d_v, n_head, dropout):\n        super().__init__()\n\n        self.decodes = nn.ModuleList([\n            DecoderLayer(d_model, d_ff, d_k, d_v, n_head, dropout) for _ in range(n_dec)])\n\n    def forward(self, dec_output, enc_output, non_pad_mask, slf_attn_mask, dec_enc_attn_mask):\n        for layer in self.decodes:\n            dec_output, m_dec_output = layer(dec_output, enc_output,\n                                             non_pad_mask, slf_attn_mask, dec_enc_attn_mask)\n\n        return dec_output, m_dec_output\n\n\nclass Transformer(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        self.args = args\n\n        self.n_position = args.max_context_len\n        self.turn_embedding = nn.Embedding(\n            args.turn_size, args.d_model, padding_idx=const.PAD)\n        self.word_embedding = nn.Embedding(\n            args.vocab_size, args.d_model, padding_idx=const.PAD)\n        self.pos_embedding = nn.Embedding.from_pretrained(\n            common.get_sinusoid_encoding_table(self.n_position, args.d_model, padding_idx=const.PAD))\n\n        self.enc = Encoder(args.n_stack_layers, args.d_model,\n                           args.d_ff, args.d_k, args.d_v, args.n_head, args.dropout)\n        self.dec = Decoder(args.n_stack_layers, args.d_model,\n                           args.d_ff, args.d_k, args.d_v, args.n_head, args.dropout)\n\n        self.encode_w = nn.Linear(args.d_model, args.d_model, bias=False)\n        self.decode_w = nn.Linear(args.d_model, args.d_model, bias=False)\n        self.vt = nn.Linear(args.d_model, 1, bias=False)\n\n        self.droupout = nn.Dropout(args.dropout)\n\n        self._reset_parameters()\n\n    def _reset_parameters(self, scope=.1):\n        self.word_embedding.weight.data.uniform_(-scope, scope)\n        self.turn_embedding.weight.data.uniform_(-scope, scope)\n\n        for layer in self.modules():\n            if type(layer) == nn.Linear:\n                layer.weight.data.normal_(std=const.INIT_RANGE)\n\n    def get_trainable_parameters(self):\n        return filter(lambda m: m.requires_grad, self.parameters())\n\n    def forward(self, src_tensor, src_postion, turns_tensor, tgt_tensor):\n        # encode embedding\n        encode = self.word_embedding(\n            src_tensor) + self.pos_embedding(src_postion) + self.turn_embedding(turns_tensor)\n        encode = self.droupout(encode)\n\n        # encode mask\n        slf_attn_mask = common.get_attn_key_pad_mask(src_tensor, src_tensor)\n        non_pad_mask = common.get_non_pad_mask(src_tensor)\n\n        # encode\n        enc_output = self.enc(encode, slf_attn_mask, non_pad_mask)\n\n        # decode embedding\n        dec_output = self.word_embedding(tgt_tensor)\n        dec_output = self.droupout(dec_output)\n\n        # decode mask\n        non_pad_mask = common.get_non_pad_mask(tgt_tensor)\n        slf_attn_mask_subseq = common.get_subsequent_mask(tgt_tensor)\n        slf_attn_mask_keypad = common.get_attn_key_pad_mask(\n            tgt_tensor, tgt_tensor, True)\n        slf_attn_mask = (slf_attn_mask_keypad + slf_attn_mask_subseq).gt(0)\n\n        dec_enc_attn_mask = common.get_attn_key_pad_mask(\n            src_tensor, tgt_tensor)\n\n        # decode\n        dec_output, m_dec_output = self.dec(\n            dec_output, enc_output, non_pad_mask, slf_attn_mask, dec_enc_attn_mask)\n\n        # pointer network\n        distributes = self.attention(m_dec_output, enc_output)\n\n        return distributes\n\n    def attention(self, dec_output, last_enc_output):\n        distributes = []\n        last_enc_output = self.encode_w(last_enc_output)\n        for step in range(dec_output.shape[1]):\n            dec_slice = self.decode_w(dec_output[:, step]).unsqueeze(1)\n            attn_encode = torch.tanh(dec_slice + last_enc_output)\n            attn_encode = self.vt(attn_encode).squeeze(2)\n            distributes.append(F.log_softmax(attn_encode, dim=-1) + 1e-9)\n\n        return torch.stack(distributes, dim=1)\n\n    def encode(self, src_tensor, src_postion, turns_tensor):\n        encode = self.word_embedding(\n            src_tensor) + self.pos_embedding(src_postion) + self.turn_embedding(turns_tensor)\n\n        slf_attn_mask = common.get_attn_key_pad_mask(src_tensor, src_tensor)\n        non_pad_mask = common.get_non_pad_mask(src_tensor)\n\n        enc_output = self.enc(encode, slf_attn_mask, non_pad_mask)\n\n        return enc_output\n\n    def decode(self, tgt_tensor, src_tensor, enc_output):\n        dec_output = self.word_embedding(tgt_tensor)\n        dec_output = self.droupout(dec_output)\n\n        non_pad_mask = common.get_non_pad_mask(tgt_tensor)\n        slf_attn_mask_subseq = common.get_subsequent_mask(tgt_tensor)\n        slf_attn_mask_keypad = common.get_attn_key_pad_mask(\n            tgt_tensor, tgt_tensor, True)\n        slf_attn_mask = (slf_attn_mask_keypad + slf_attn_mask_subseq).gt(0)\n\n        dec_enc_attn_mask = common.get_attn_key_pad_mask(\n            src_tensor, tgt_tensor)\n\n        dec_output, m_dec_output = self.dec(\n            dec_output, enc_output, non_pad_mask, slf_attn_mask, dec_enc_attn_mask)\n\n        distributes = self.attention(m_dec_output, enc_output)\n\n        return distributes\n\n    def save_model(self, path):\n        torch.save(self.state_dict(), path)\n\n    def load_model(self, path, cuda):\n        if cuda:\n            self.load_state_dict(torch.load(path))\n            self.cuda()\n        else:\n            self.load_state_dict(torch.load(\n                path, map_location=lambda storage, loc: storage))\n            self.cpu()\n'"
pointer-network/predict.py,10,"b'import copy\n\nimport torch\n\nfrom const import *\nfrom model import Transformer\nimport common\n\n\nclass Predict(object):\n    def __init__(self, model_source, rewrite_len=30, beam_size=4, debug=False):\n        self.beam_size = beam_size\n        self.rewrite_len = rewrite_len\n        self.debug = debug\n\n        model_source = torch.load(\n            model_source, map_location=lambda storage, loc: storage)\n        self.dict = model_source[""word2idx""]\n        self.idx2word = {v: k for k, v in model_source[""word2idx""].items()}\n        self.args = args = model_source[""settings""]\n        torch.manual_seed(args.seed)\n        model = Transformer(args)\n        model.load_state_dict(model_source[\'model\'])\n        self.model = model.eval()\n\n    def sent2tenosr(self, sentences):\n        assert isinstance(sentences, list) and len(sentences) == 3\n\n        max_len = self.args.max_context_len\n        query1, query2, query3 = sentences\n        q1_words = common.split_char(query1)\n        turn1 = [1]*(len(q1_words))\n        q2_words = common.split_char(query2)\n        turn2 = [2]*(len(q2_words)+1)\n        q3_words = common.split_char(query3)\n        turn3 = [3]*(len(q3_words))\n        words = q1_words + q2_words + [WORD[EOS]] + q3_words\n        turns = turn1 + turn2 + turn3\n\n        if len(words) > max_len:\n            words = words[:max_len]\n\n        idx = [self.dict[w] if w in self.dict else UNK for w in words]\n\n        inp = torch.LongTensor(idx).unsqueeze(0)\n        position = torch.LongTensor(\n            [pos_i+1 if w_i != PAD else 0 for pos_i, w_i in enumerate(idx)]).unsqueeze(0)\n        turns = torch.LongTensor(turns).unsqueeze(0)\n\n        self.word = words\n\n        return inp, position, turns\n\n    def widx2didx(self, widx):\n        word = self.word[widx]\n        return self.dict[word] if word in self.dict else UNK\n\n    def beam_search(self, w_scores, end_seqs, top_seqs):\n        max_scores, max_idxs = w_scores.sort(-1, descending=True)\n        max_scores = (max_scores[:, :self.beam_size]).tolist()\n        max_idxs = (max_idxs[:, :self.beam_size]).tolist()\n\n        all_seqs, seen = [], []\n        for index, seq in enumerate(top_seqs):\n            seq_idxs, word_index, seq_score = seq\n            if seq_idxs[-1] == EOS:\n                all_seqs += [(seq, seq_score, True)]\n                continue\n\n            for score, widx in zip(max_scores[index], max_idxs[index]):\n                idx = self.widx2didx(widx)\n                seq_idxs, word_index, seq_score = copy.deepcopy(seq)\n                seq_score += score\n                seq_idxs += [idx]\n                word_index += [widx]\n                if word_index not in seen:\n                    seen.append(word_index)\n                    all_seqs += [((seq_idxs, word_index, seq_score),\n                                  seq_score, idx == EOS)]\n\n        all_seqs += [((seq[0], seq[1], seq[-1]), seq[-1], True)\n                     for seq in end_seqs]\n        top_seqs = sorted(all_seqs, key=lambda seq: seq[1], reverse=True)[\n            :self.beam_size]\n\n        all_done, done_nums = self.check_all_done(top_seqs)\n        top_seqs = [seq for seq, _, _ in top_seqs]\n\n        return top_seqs, all_done, self.beam_size-done_nums\n\n    def check_all_done(self, seqs):\n        done_nums = len([s for s in seqs if s[-1]])\n        return done_nums == self.beam_size, done_nums\n\n    def init_input(self):\n        return torch.LongTensor(self.beam_size).fill_(BOS).unsqueeze(1)\n\n    def update_input(self, top_seqs):\n        end_seqs, un_end_seqs, input_data = [], [], []\n        for seq in top_seqs:\n            if seq[0][-1] != EOS:\n                un_end_seqs.append(seq)\n                input_data.append(seq[0])\n            else:\n                end_seqs.append(seq)\n\n        return torch.LongTensor(input_data), end_seqs, un_end_seqs\n\n    def update_state(self, step, src_seq, enc_output, un_dones):\n        input_pos = torch.arange(1, step+1).unsqueeze(0)\n        input_pos = input_pos.repeat(un_dones, 1)\n        input_pos = input_pos.long()\n\n        src_seq_beam = src_seq.data.repeat(un_dones, 1)\n        enc_output_beam = enc_output.data.repeat(un_dones, 1, 1)\n\n        return input_pos, src_seq_beam, enc_output_beam\n\n    def divine(self, sentences):\n        def length_penalty(step, len_penalty_w=1.):\n            return (torch.log(torch.FloatTensor([5 + step])) - torch.log(torch.FloatTensor([6])))*len_penalty_w\n\n        with torch.no_grad():\n            inp, position, turns = self.sent2tenosr(sentences)\n\n            top_seqs = [([BOS], [], 0)] * self.beam_size\n            enc_output = self.model.encode(inp, position, turns)\n            inp_beam = inp.data.repeat(self.beam_size, 1)\n            enc_output_beam = enc_output.data.repeat(self.beam_size, 1, 1)\n            input_data = self.init_input()\n            end_seqs = []\n            for step in range(1, self.rewrite_len):\n                dec_output = self.model.decode(\n                    input_data, inp_beam, enc_output_beam)\n                out = dec_output[:, -1, :]\n                lp = length_penalty(step)\n                top_seqs, all_done, un_dones = self.beam_search(\n                    out.data+lp, end_seqs, top_seqs)\n                if all_done:\n                    break\n\n                input_data, end_seqs, top_seqs = self.update_input(top_seqs)\n                input_pos, src_seq_beam, enc_output_beam = self.update_state(\n                    step+1, inp, enc_output, un_dones)\n                inp_beam = inp.data.repeat(un_dones, 1)\n\n            tgts = []\n            for (cor_idxs, word_index, score) in top_seqs:\n                cor_idxs = word_index[: -1]\n                tgts += [("""".join([self.word[idx]\n                                   for idx in cor_idxs]), score)]\n            return tgts\n\n    def Trains(self, sentences, topk=4):\n        answers = self.divine(sentences)\n        assert topk <= len(answers)\n        if self.debug:\n            print(answers)\n        return [ans[0] for ans in answers[:topk]]\n\n\nif __name__ == ""__main__"":\n    pre = Predict(""model.pt"", debug=True)\n    t1 = ""\xe4\xbd\xa0\xe7\x9c\x8b\xe8\x8e\x8e\xe5\xa3\xab\xe6\xaf\x94\xe4\xba\x9a\xe5\x90\x97""\n    t2 = ""\xe6\x9c\x80\xe5\x96\x9c\xe6\xac\xa2\xe7\xbd\x97\xe5\xaf\x86\xe6\xac\xa7\xe4\xb8\x8e\xe6\x9c\xb1\xe4\xb8\xbd\xe5\x8f\xb6""\n    t3 = ""\xe6\x9c\x80\xe5\x96\x9c\xe6\xac\xa2\xe9\x82\xa3\xe4\xb8\xaa\xe8\xa7\x92\xe8\x89\xb2""\n\n    print(f""{t1}, {t2}, {t3} - {pre.Trains([t1,t2,t3])[0]}"")\n'"
pointer-network/train.py,7,"b'import argparse\nimport os\n\nimport torch\nfrom tqdm import tqdm\n\nfrom data_loader import DataLoader\nimport const\nfrom model import Transformer, CrossEntropy\n\nparser = argparse.ArgumentParser(description=\'poiter network\')\nparser.add_argument(\'--epochs\', type=int, default=300)\nparser.add_argument(\'--cuda_device\', type=str, default=\'0\')\nparser.add_argument(\'--batch_size\', type=int, default=32)\nparser.add_argument(\'--seed\', type=int, default=1234)\nparser.add_argument(\'--model_path\', type=str, default=\'weights\')\nparser.add_argument(\'--data\', type=str, default=f\'./data/corpus.pt\')\nparser.add_argument(\'--dropout\', type=float, default=0.1)\nparser.add_argument(\'--d_model\', type=int, default=512)\nparser.add_argument(\'--d_ff\', type=int, default=2048)\nparser.add_argument(\'--n_head\', type=int, default=8)\nparser.add_argument(\'--d_k\', type=int, default=64)\nparser.add_argument(\'--d_v\', type=int, default=64)\nparser.add_argument(\'--n_stack_layers\', type=int, default=6)\nparser.add_argument(\'--learning_rate\', type=float, default=0.00005)\n\nargs = parser.parse_args()\nargs.turn_size = 4\nos.environ[""CUDA_VISIBLE_DEVICES""] = args.cuda_device\ntorch.manual_seed(args.seed)\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\ncorpus = torch.load(args.data)\nargs.vocab_size = len(corpus[""word2idx""])\nargs.max_context_len = corpus[""max_len""]\n\ntraining_data = DataLoader(\n    corpus[""train""][""src_texts""],\n    corpus[""train""][""src_turn""],\n    corpus[""train""][""tgt_indexs""],\n    corpus[""train""][""tgt_texts""],\n    batch_size=args.batch_size,\n    cuda=use_cuda)\n\nvalidation_data = DataLoader(\n    corpus[""valid""][""src_texts""],\n    corpus[""valid""][""src_turn""],\n    corpus[""valid""][""tgt_indexs""],\n    corpus[""valid""][""tgt_texts""],\n    batch_size=args.batch_size,\n    cuda=use_cuda)\n\nmodel = Transformer(args)\n\ncriterion = CrossEntropy()\noptimizer = torch.optim.Adam(\n    model.get_trainable_parameters(), lr=args.learning_rate)\n\nif use_cuda:\n    model = model.cuda()\n    criterion = criterion.cuda()\n\n\ndef get_performance(crit, distributes, gold):\n    loss = crit(distributes, gold)\n    _, predict = distributes.max(dim=-1)\n    n_correct = predict.eq(gold)\n    n_correct = n_correct.data.masked_select(gold.ne(const.PAD)).sum()\n\n    n_gold = gold.ne(const.PAD).sum()\n\n    return loss, n_correct, n_gold\n\n\ndef dev(i):\n    model.eval()\n    total_loss = total_correct = total_gold = 0\n    for (src_tensor, src_postion, turns_tensor), (tgt_tensor, tgt_postion), tgt_indexs_tensor in tqdm(validation_data, mininterval=1, desc=\'dev Processing\', leave=False):\n        with torch.no_grad():\n            distributes = model(src_tensor, src_postion,\n                                turns_tensor, tgt_tensor)\n\n            loss, n_correct, n_gold = get_performance(\n                criterion, distributes, tgt_indexs_tensor)\n            total_loss += loss.item()\n            total_correct += n_correct.item()\n            total_gold += n_gold.item()\n\n    print(f""dev epoch {i+1}/{args.epochs} loss: {total_loss/validation_data.stop_step:.4f} correct: {total_correct} gold count: {total_gold} presicion: {total_correct/total_gold:.4f}"")\n    return total_correct/total_gold\n\n\ndef train(i):\n    model.train()\n    total_loss = total_correct = total_gold = 0\n    for (src_tensor, src_postion, turns_tensor), (tgt_tensor, tgt_postion), tgt_indexs_tensor in tqdm(training_data, mininterval=1, desc=\'Train Processing\', leave=False):\n        optimizer.zero_grad()\n        distributes = model(src_tensor, src_postion, turns_tensor, tgt_tensor)\n\n        loss, n_correct, n_gold = get_performance(\n            criterion, distributes, tgt_indexs_tensor)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        total_correct += n_correct.item()\n        total_gold += n_gold.item()\n\n    print(f""train epoch {i+1}/{args.epochs} loss: {total_loss/training_data.stop_step:.4f} correct: {total_correct} gold count: {total_gold} presicion: {total_correct/total_gold:.4f}"")\n\n\ndef save():\n    model_state_dict = model.state_dict()\n    model_source = {\n        ""settings"": args,\n        ""model"": model_state_dict,\n        ""word2idx"": corpus[\'word2idx\'],\n    }\n    torch.save(model_source, f""{args.model_path}/model_{args.cuda_device}.pt"")\n\n\nos.makedirs(args.model_path, exist_ok=True)\n\n\nbest_presicion = -1\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(args.epochs):\n        train(epoch)\n        print(\'-\' * 90)\n        presicion = dev(epoch)\n        if presicion > best_presicion:\n            print(f""new best presicion score {presicion:.4f} and save model"")\n            best_presicion = presicion\n            model.save_model(\n                f""{args.model_path}/tmp_model_{args.cuda_device}.pt"")\n            save()\n        else:\n            print(f""best_presicion {best_presicion:.4f} and reload best model"")\n            model.load_model(\n                f""{args.model_path}/tmp_model_{args.cuda_device}.pt"", use_cuda)\n        print(\'-\' * 90)\nexcept KeyboardInterrupt:\n    print(""Exiting from training early"")\n'"
reinforced-translate/const.py,0,"b""PAD = 0\nEOS = 1\nBOS = 2\nUNK = 3\n\nWORD = {\n    PAD: '<pad>',\n    UNK: '<unk>',\n    BOS: '<s>',\n    EOS: '</s>'\n}"""
reinforced-translate/corpus.py,1,"b'import re\n\nimport torch\n\nfrom const import *\n\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\n\ndef normalizeString(s):\n    s = s.lower().strip()\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    return s\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK,\n            WORD[BOS]: BOS,\n            WORD[EOS]: EOS\n        }\n        self.idx = len(self.word2idx)\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, sents, min_count):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words:\n            word_count[w] += 1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Corpus(object):\n    def __init__(self, fuel_path, save_data, max_len, min_word_count=1):\n        self._fuel_path = fuel_path\n        self._save_data = save_data\n        self.max_len = max_len\n        self._min_word_count = min_word_count\n        self.src_dict = Dictionary()\n        self.tgt_dict = Dictionary()\n\n    def parse(self):\n        def gather_file(file_, max_len):\n            en_sents, he_sents, en_cut_count, he_cut_count = [], [], 0, 0\n\n            for sentences in open(file_):\n                en_, he_ = [normalizeString(s)\n                            for s in sentences.strip().split(\'\\t\')]\n\n                en_ws = [word for word in en_.strip().split()]\n                he_ws = [word for word in he_.strip().split()]\n\n                if len(en_ws) > max_len:\n                    en_cut_count += 1\n                    en_ws = en_ws[:max_len]\n                en_sents.append(en_ws + [WORD[EOS]])\n\n                if len(he_ws) > max_len:\n                    he_cut_count += 1\n                    he_ws = he_ws[:max_len]\n                he_sents.append(he_ws + [WORD[EOS]])\n\n            return he_sents, en_sents, he_cut_count, en_cut_count\n\n        max_len = self.max_len - 1\n        src_train, tgt_train, he_cut_count, en_cut_count = gather_file(\n            \'data/train\', max_len)\n        src_valid, tgt_valid, _, _ = gather_file(\'data/test\', max_len)\n\n        print(\n            ""English data`s length out of range numbers - [{}]"".format(en_cut_count))\n        print(\n            ""He data`s length out of range numbers - [{}]"".format(he_cut_count))\n\n        src_ignore = self.src_dict(src_train, self._min_word_count)\n        tgt_ignore = self.tgt_dict(tgt_train, self._min_word_count)\n        if src_ignore != 0:\n            print(""Ignored src word counts - [{}]"".format(src_ignore))\n        if tgt_ignore != 0:\n            print(""Ignored tgt word counts - [{}]"".format(tgt_ignore))\n\n        self.src_train = src_train\n        self.tgt_train = tgt_train\n        self.src_valid = src_valid\n        self.tgt_valid = tgt_valid\n\n    def save(self):\n        data = {\n            \'max_len\': self.max_len,\n            \'dict\': {\n                \'src\': self.src_dict.word2idx,\n                \'src_size\': len(self.src_dict),\n                \'tgt\': self.tgt_dict.word2idx,\n                \'tgt_size\': len(self.tgt_dict),\n                \'src_id2w\': {v: k for k, v in self.src_dict.word2idx.items()},\n                \'tgt_id2w\': {v: k for k, v in self.tgt_dict.word2idx.items()}\n            },\n            \'train\': {\n                \'data\': word2idx(self.src_train, self.src_dict.word2idx),\n                \'label\': word2idx(self.tgt_train, self.tgt_dict.word2idx),\n            },\n            \'valid\': {\n                \'data\': word2idx(self.src_valid, self.src_dict.word2idx),\n                \'label\': word2idx(self.tgt_valid, self.tgt_dict.word2idx),\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'src word length - [{}]\'.format(len(self.src_dict)))\n        print(\'tgt word length - [{}]\'.format(len(self.tgt_dict)))\n\n    def process(self):\n        self.parse()\n        self.save()\n\n\nif __name__ == ""__main__"":\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\'drsm\')\n    parser.add_argument(\'--save_data\', type=str, default=\'data/corpus\')\n    parser.add_argument(\'--fuel_path\', type=str, default=\'data/\')\n    parser.add_argument(\'--max_len\', type=int, default=17)\n    parser.add_argument(\'--min_word_count\', type=int, default=1)\n    args = parser.parse_args()\n\n    corpus = Corpus(args.fuel_path, args.save_data,\n                    args.max_len, args.min_word_count)\n    corpus.process()\n'"
reinforced-translate/data_loader.py,2,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\n\nclass DataLoader(object):\n    def __init__(self, src_sents, tgt_sents, max_len, cuda, batch_size, evaluation=False):\n        self.cuda = cuda\n        self.max_len = max_len\n        self.sents_size = len(src_sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size\n        self.evaluation = evaluation\n        self._batch_size = batch_size\n        self._src_sents = np.asarray(src_sents)\n        self._tgt_sents = np.asarray(tgt_sents)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def pad_to_longest(insts):\n            inst_data = np.array(\n                [inst + [const.PAD] * (self.max_len - len(inst)) for inst in insts])\n\n            inst_data_tensor = Variable(torch.from_numpy(\n                inst_data), volatile=self.evaluation)\n\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step * self._batch_size\n        _bsz = self._batch_size\n        self._step += 1\n\n        src = pad_to_longest(self._src_sents[_start:_start + _bsz])\n        tgt = pad_to_longest(self._tgt_sents[_start:_start + _bsz])\n\n        return src, tgt\n'"
reinforced-translate/model.py,9,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nimport numpy as np\n\nfrom const import *\n\n\nclass CrossEntropy(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, props, tgt):\n        tgt_props = props.gather(2, tgt.unsqueeze(2)).squeeze()\n        mask = (tgt > 0).float()\n        return -(tgt_props * mask).sum() / mask.sum()\n\n\nclass SelfCriticCriterion(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, props, s_words, tgt, advantage):\n        advantage = (advantage - advantage.mean()) / \\\n            advantage.std().clamp(min=1e-8)\n        s_props = props.gather(2, s_words.unsqueeze(2)).squeeze()\n        mask = (tgt > 0).float()\n        advantage = advantage.unsqueeze(1).repeat(1, mask.size(1))\n        advantage = advantage.detach()\n\n        return - (s_props * mask * advantage).sum() / mask.sum()\n\n\nclass Model(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.torch = torch.cuda if args.use_cuda else torch\n        self.bsz = args.batch_size\n        self.rnn_hsz = args.rnn_hsz\n        self.max_len = args.max_len\n\n        self.src_emb = nn.Embedding(\n            args.src_vs, args.emb_dim, padding_idx=PAD)\n        self.tgt_emb = nn.Embedding(\n            args.tgt_vs, args.emb_dim, padding_idx=PAD)\n        self.enc = nn.LSTM(args.emb_dim, args.rnn_hsz, 1,\n                           batch_first=True,\n                           dropout=args.dropout)\n        self.dec_hidden = nn.Linear(args.rnn_hsz, args.rnn_hsz)\n        self.dec = nn.LSTM(args.rnn_hsz, args.rnn_hsz, 1,\n                           batch_first=True,\n                           dropout=args.dropout)\n        self.out = nn.Linear(self.rnn_hsz, args.tgt_vs)\n\n    def encode(self, src_inp):\n        emb = self.src_emb(src_inp)\n        _, (hidden, _) = self.enc(emb)\n        dec_hidden = self.dec_hidden(hidden)\n\n        weight = next(self.parameters()).data\n        c = Variable(weight.new(1, self.bsz, self.rnn_hsz).zero_())\n\n        return (dec_hidden.contiguous(), c.contiguous())\n\n    def forward(self, src_inp, tgt_inp):\n        hiiden = self.encode(src_inp)\n        word = Variable(self.torch.LongTensor([[BOS]] * self.bsz))\n        emb = self.tgt_emb(word)\n        outputs = []\n\n        for i in range(self.max_len):\n            _, hiiden = self.dec(emb, hiiden)\n            props = F.log_softmax(self.out(hiiden[0][-1]), dim=-1)\n            emb = self.tgt_emb(tgt_inp[:, i]).unsqueeze(1)\n\n            outputs.append(props.unsqueeze(1))\n\n        return torch.cat(outputs, 1)\n\n    def sample(self, src_inp, max_props=True):\n        hiiden = self.encode(src_inp)\n        word = Variable(self.torch.LongTensor([[BOS]] * self.bsz))\n        emb = self.tgt_emb(word)\n        outputs, words = [], []\n\n        for i in range(self.max_len):\n            _, hiiden = self.dec(emb, hiiden)\n            props = F.log_softmax(self.out(hiiden[0][-1]), dim=-1)\n\n            if max_props:\n                _, word = props.max(-1, keepdim=True)\n            else:\n                _props = props.data.clone().exp()\n                word = Variable(_props.multinomial(1))\n                outputs.append(props.unsqueeze(1))\n\n            emb = self.tgt_emb(word)\n            words.append(word)\n\n        if max_props:\n            return torch.cat(words, 1)\n\n        else:\n            return torch.cat(words, 1), torch.cat(outputs, 1)\n'"
reinforced-translate/rouge.py,12,"b""import numpy as np\nimport torch\nfrom torch.autograd import Variable\n\nfrom const import PAD\n\n\ndef _lcs(x, y):\n    n = len(x)\n    m = len(y)\n    table = dict()\n\n    for i in range(n + 1):\n        for j in range(m + 1):\n            if i == 0 or j == 0:\n                table[i, j] = 0\n            elif x[i - 1] == y[j - 1]:\n                table[i, j] = table[i - 1, j - 1] + 1\n            else:\n                table[i, j] = max(table[i - 1, j], table[i, j - 1])\n\n    def recon(i, j):\n        if i == 0 or j == 0:\n            return []\n        elif x[i - 1] == y[j - 1]:\n            return recon(i - 1, j - 1) + [x[i - 1]]\n        elif table[i - 1, j] > table[i, j - 1]:\n            return recon(i - 1, j)\n        else:\n            return recon(i, j - 1)\n\n    return len(recon(n, m)), n, m\n\n\ndef rouge_l(evals, refs):\n    assert evals.size() == refs.size()\n    use_cuda = evals.is_cuda\n\n    evals, refs = map(lambda x: x.data.cpu().numpy(), [evals, refs])\n\n    scores = []\n    for eva, ref in zip(evals, refs):\n        same_len, eva_len, ref_len = map(float,\n                                         _lcs(eva, ref[np.where(ref > PAD)]))\n\n        r_lcs, p_lcs = same_len / ref_len, same_len / eva_len\n\n        beta = p_lcs / (r_lcs + 1e-12)\n        f_lcs = ((1 + (beta**2)) * r_lcs * p_lcs) / \\\n            (r_lcs + ((beta**2) * p_lcs) + 1e-12)\n        scores.append(f_lcs)\n\n    scores = np.asarray(scores, dtype=np.float32)\n    scores = Variable(torch.from_numpy(scores), requires_grad=False)\n\n    if use_cuda:\n        scores = scores.cuda()\n\n    return scores\n\n\ndef mask_score(props, words, scores):\n    assert words.size() == scores.size()\n    mask = (words > 0).float()\n\n    return props * scores * mask\n\n\nif __name__ == '__main__':\n    import torch\n    from torch.autograd import Variable\n    import torch.nn.functional as F\n    from model import RewardCriterion\n\n    data = Variable(torch.LongTensor([[3, 1, 2, 3, 1, 0], [2, 3, 4, 4, 0, 0]]))\n    label = Variable(torch.LongTensor(\n        [[3, 1, 2, 3, 1, 0], [2, 3, 2, 3, 1, 0]]))\n    bl = Variable(torch.LongTensor([[3, 1, 2, 3, 2, 0], [1, 3, 4, 4, 0, 0]]))\n    data = data.cuda()\n    label = label.cuda()\n    bl = bl.cuda()\n\n    reward = rouge_l(bl, label) - rouge_l(data, label)\n    print(reward[:, 0])\n\n    props = torch.randn(16, 17, 256)\n    words = torch.LongTensor([[i for i in range(16, -1, -1)]\n                              for _ in range(16)])\n    scores = torch.randn(16, 17)\n\n    print(mask_score(props, words, scores))\n\n    crit = RewardCriterion()\n    crit = crit.cuda()\n\n    props = F.log_softmax(Variable(torch.randn(2, 6, 256),\n                                   requires_grad=True).cuda(), dim=-1)\n    max_props, _ = torch.max(props, -1)\n\n    loss, reward = crit(max_props, data, reward)\n    print(loss)\n    print(reward)\n"""
reinforced-translate/train.py,11,"b'import argparse\n\nparser = argparse.ArgumentParser(\n    description=\'A DEEP REINFORCED MODEL translate\')\n\nparser.add_argument(\'--logdir\', type=str, default=\'logdir\')\nparser.add_argument(\'--save\', type=str, default=\'translate_{}.pt\')\nparser.add_argument(\'--epochs\', type=int, default=40)\nparser.add_argument(\'--pretrain_epochs\', type=int, default=40)\nparser.add_argument(\'--batch_size\', type=int, default=16)\nparser.add_argument(\'--seed\', type=int, default=1111)\nparser.add_argument(\'--data\', type=str, default=\'./data/corpus\')\nparser.add_argument(\'--ml_lr\', type=float, default=0.001)\nparser.add_argument(\'--rl_lr\', type=float, default=1e-5)\nparser.add_argument(\'--dropout\', type=float, default=0.5)\nparser.add_argument(\'--emb_dim\', type=int, default=100)\nparser.add_argument(\'--rnn_hsz\', type=int, default=100)\nparser.add_argument(\'--pretrain\', type=str, default="""")\n\nargs = parser.parse_args()\n\nimport torch\n\ntorch.manual_seed(args.seed)\nargs.use_cuda = use_cuda = torch.cuda.is_available()\n\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# ##############################################################################\n# Tensorboard\n################################################################################\ntry:\n    import tensorflow as tf\n    tf_step = 0\nexcept ImportError:\n    tf = None\n\ntf_summary_writer = tf and tf.summary.FileWriter(args.logdir)\n\n\ndef add_summary_value(key, value):\n    global tf_step\n\n    summary = tf.Summary(value=[tf.Summary.Value(tag=key, simple_value=value)])\n    tf_summary_writer.add_summary(summary, tf_step)\n\n\n# ##############################################################################\n# Load data\n################################################################################\nimport time\n\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_len = data[""max_len""]\nargs.src_vs = data[\'dict\'][\'src_size\']\nargs.tgt_vs = data[\'dict\'][\'tgt_size\']\n\ntraining_data = DataLoader(\n    data[\'train\'][\'data\'],\n    data[\'train\'][\'label\'],\n    data[\'max_len\'],\n    use_cuda,\n    batch_size=args.batch_size)\n\nvalidation_data = DataLoader(\n    data[\'valid\'][\'data\'],\n    data[\'valid\'][\'label\'],\n    data[\'max_len\'],\n    use_cuda,\n    batch_size=args.batch_size)\n\nargs.src_id2w = data[\'dict\'][\'src_id2w\']\nargs.tgt_id2w = data[\'dict\'][\'tgt_id2w\']\n\n# ##############################################################################\n# Training\n# ##############################################################################\nfrom const import PAD\nfrom model import Model, CrossEntropy, SelfCriticCriterion\n\nmodel = Model(args)\nml_optimizer = torch.optim.Adam(model.parameters(), lr=args.ml_lr)\nrl_optimizer = torch.optim.Adam(\n    model.parameters(), lr=args.rl_lr, weight_decay=0.01)\n\nml_criterion = CrossEntropy()\nrl_criterion = SelfCriticCriterion()\n\nif use_cuda:\n    model = model.cuda()\n\n# ##############################################################################\n# Training\n# ##############################################################################\nfrom tqdm import tqdm\n\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nfrom rouge import rouge_l, mask_score\n\n\ndef pre_train():\n    if tf:\n        global tf_step\n    for src, tgt in tqdm(training_data,\n                         mininterval=1,\n                         desc=""Pre-train"",\n                         leave=False):\n        ml_optimizer.zero_grad()\n\n        props = model(src, tgt)\n        loss = ml_criterion(props, tgt)\n\n        loss.backward()\n        ml_optimizer.step()\n        if tf is not None:\n            add_summary_value(""pre-train loss"", loss.data[0])\n            tf_step += 1\n\n            if tf_step % 100 == 0:\n                tf_summary_writer.flush()\n\n\ndef reinforce():\n    if tf:\n        global tf_step\n    for src, tgt in tqdm(training_data,\n                         mininterval=1,\n                         desc=""Reinforce-train"",\n                         leave=False):\n        rl_optimizer.zero_grad()\n\n        max_words = model.sample(src)\n        s_words, props = model.sample(src, False)\n\n        reward = rouge_l(s_words, tgt)\n        baseline = rouge_l(max_words, tgt)\n\n        advantage = reward - baseline\n\n        loss = rl_criterion(props, s_words, tgt, advantage)\n\n        loss.backward()\n        rl_optimizer.step()\n        if tf is not None:\n            add_summary_value(""reinforce loss"", loss.data[0])\n            add_summary_value(""reinforce advantage"", advantage.mean().data)\n            add_summary_value(""reinforce baseline"", baseline.mean().data)\n            add_summary_value(""reinforce reward"", reward.mean().data)\n            tf_step += 1\n\n            if tf_step % 100 == 0:\n                tf_summary_writer.flush()\n\n\ntry:\n    if args.pretrain == """":\n        print(""="" * 40 + ""Pre-train"" + ""="" * 40)\n        model.train()\n        if tf:\n            tf_step = 0\n        for step in range(args.pretrain_epochs):\n            pre_train()\n            model_state_dict = model.state_dict()\n            model_source = {\n                ""settings"": args,\n                ""model"": model_state_dict,\n                ""dict"": data[\'dict\']\n            }\n            torch.save(model_source, args.save.format(\n                ""Pre-train_"" + str(step)))\n    else:\n        model_source = torch.load(args.pretrain)\n        model.load_state_dict(model_source[""model""])\n\n    if tf:\n        tf_step = 0\n    print(""="" * 40 + ""Reinforce-train"" + ""="" * 40)\n    for step in range(args.epochs):\n        reinforce()\n        model_state_dict = model.state_dict()\n        model_source = {\n            ""settings"": args,\n            ""model"": model_state_dict,\n            ""dict"": data[\'dict\']\n        }\n        torch.save(model_source, args.save.format(step))\n\nexcept KeyboardInterrupt:\n    print(""-"" * 90)\n    print(""Exiting from training early"")\n'"
reinforced-translate/transform.py,3,"b'import torch\nfrom torch.autograd import Variable\n\nfrom model import Model\nfrom corpus import normalizeString\nfrom const import *\n\n\nclass Transform(object):\n    def __init__(self, model_source=""translate_Pre-train.pt""):\n        model_source = torch.load(\n            model_source, map_location=lambda storage, loc: storage)\n\n        self.src_dict = model_source[""dict""][""src""]\n        self.idx2word = {v: k for k, v in model_source[""dict""][""tgt""].items()}\n        self.args = args = model_source[""settings""]\n\n        args.use_cuda = False\n        model = Model(args)\n        model.load_state_dict(model_source[\'model\'])\n        model = model.cpu()\n        self.model = model.eval()\n\n    def sent2tenosr(self, sentence):\n        max_len = self.args.max_len - 2\n        sentence = normalizeString(sentence)\n        words = [w for w in sentence.strip().split()]\n\n        if len(words) > max_len:\n            words = words[:max_len]\n\n        words = [WORD[BOS]] + words + [WORD[EOS]]\n        idx = [self.src_dict[w] if w in self.src_dict else UNK for w in words]\n\n        idx_data = torch.LongTensor(idx)\n        idx_data_tensor = Variable(idx_data.unsqueeze(0), volatile=True)\n\n        return idx_data_tensor\n\n    def translate(self, sentence):\n        idx_data = self.sent2tenosr(sentence)\n        idx_data = idx_data.repeat(16, 1)\n        words, _ = self.model(idx_data, False)\n\n        return "" "".join([self.idx2word[_id] for _id in words.data.tolist()[0]])\n\n\nif __name__ == ""__main__"":\n    t = Transform()\n    en = t.translate(""Tom est connu."")\n    print(en)\n'"
relation-network/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    PAD: '<pad>',\n    UNK: '<unk>',\n}\n\nSTORYLEN = 20\n"""
relation-network/corpus.py,1,"b'import torch\nimport re\n\nfrom const import *\n\n\ndef story2idx(stories, word2idx):\n    return [[[word2idx[w] if w in word2idx else UNK for w in sent]\n             for sent in story] for story in stories]\n\n\ndef question2idx(questions, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in question] for question in questions]\n\n\ndef answer2idx(answers, word2idx):\n    return [word2idx[w] for w in answers]\n\n\ndef normalizeString(s):\n    s = s.lower().strip()\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    return s\n\n\ndef parse_answer(answers):\n    answer2idx = {}\n    for answer in answers:\n        if answer2idx.get(answer) is None:\n            answer2idx[answer] = len(answer2idx)\n\n    return answer2idx\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK,\n        }\n        self.idx = len(self.word2idx)\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def parse_s(self, stories):\n        words = [word for story in stories for sent in story for word in sent]\n        for word in words:\n            self.add(word)\n\n    def parse_q(self, questions):\n        words = [word for question in questions for word in question]\n        for word in words:\n            self.add(word)\n\n    def __len__(self):\n        return self.idx\n\n\nclass Corpus(object):\n    def __init__(self, save_data=""data/corpus.pt"", max_s_len=10, max_q_len=16):\n        self.save_data = save_data\n        self.word = Dictionary()\n        self.max_s_len = max_s_len\n        self.max_q_len = max_q_len\n\n        self.parse_data()\n        self.save()\n\n    def parse_data(self):\n        stories, questions, answers = [], [], []\n        test_stories, test_questions, test_answers = [], [], []\n\n        ignore_q = ignore_s = 0\n        for i in range(1, 21):\n            for line in open(f\'data/qa{i}_train.txt\'):\n                index, line = line.strip().split("" "", 1)\n                if int(index) == 1:\n                    story = []\n\n                contents = line.split(""\\t"")\n                if len(contents) == 3:\n                    q, a, _ = contents\n                    qs = normalizeString(q).split()\n                    if len(qs) > self.max_q_len:\n                        qs = qs[:self.max_q_len]\n                        ignore_q += 1\n\n                    stories.append(story.copy()[-20:])\n                    questions.append(qs)\n                    answers.append(a)\n                else:\n                    s = normalizeString(contents[0]).split()\n                    if len(s) > self.max_s_len:\n                        s = s[:self.max_s_len]\n                        ignore_s += 1\n                    story.append(s)\n\n            for line in open(f\'data/qa{i}_test.txt\'):\n                index, line = line.strip().split("" "", 1)\n                if int(index) == 1:\n                    story = []\n\n                contents = line.split(""\\t"")\n                if len(contents) == 3:\n                    q, a, _ = contents\n                    qs = normalizeString(q).split()\n                    if len(qs) > self.max_q_len:\n                        qs = qs[:self.max_q_len]\n                        ignore_q += 1\n\n                    test_stories.append(story.copy()[-20:])\n                    test_questions.append(qs)\n                    test_answers.append(a)\n                else:\n                    s = normalizeString(contents[0]).split()\n                    if len(s) > self.max_s_len:\n                        s = s[:self.max_s_len]\n                        ignore_s += 1\n                    story.append(s)\n\n        self.word.parse_q(questions)\n        self.word.parse_s(stories)\n\n        self.answer2idx = parse_answer(answers)\n\n        self.stories = stories\n        self.questions = questions\n        self.answers = answers\n\n        self.test_stories = test_stories\n        self.test_questions = test_questions\n        self.test_answers = test_answers\n\n        print(f""ignore story lenght - {ignore_s}"")\n        print(f""ignore question lenght - {ignore_q}"")\n        print(f""answer length - {len(self.answer2idx)}"")\n        print(f""word length - {len(self.word)}"")\n\n    def save(self):\n        data = {\n            \'max_q_len\': self.max_q_len,\n            \'max_s_len\': self.max_s_len,\n            \'word2idx\': self.word.word2idx,\n            \'answer2idx\': self.answer2idx,\n            \'story\': story2idx(self.stories, self.word.word2idx),\n            \'question\': question2idx(self.questions, self.word.word2idx),\n            \'answer\': answer2idx(self.answers, self.answer2idx),\n            \'test_story\': story2idx(self.test_stories, self.word.word2idx),\n            \'test_question\': question2idx(self.test_questions, self.word.word2idx),\n            \'test_answer\': answer2idx(self.test_answers, self.answer2idx),\n        }\n\n        torch.save(data, self.save_data)\n        print(f\'Finish dumping the data to file - {self.save_data}\')\n\n\nif __name__ == ""__main__"":\n    Corpus()\n'"
relation-network/data_loader.py,4,"b'import random\n\nimport numpy as np\nimport torch\n\nfrom const import *\n\n\nclass DataLoader:\n    def __init__(self, story,\n                 question,\n                 answer,\n                 max_q_len,\n                 max_s_len,\n                 word2idx,\n                 answer2idx,\n                 cuda=True,\n                 batch_size=64,\n                 shuffle=True):\n\n        self.sents_size = len(story)\n        self.max_q_len = max_q_len\n        self.max_s_len = max_s_len\n        self.cuda = cuda\n        self.bsz = batch_size\n        self.step = 0\n\n        self.word2idx = word2idx\n        self.answer2idx = answer2idx\n\n        self.story = np.asarray(story)\n        self.question = np.asarray(question)\n        self.answer = np.asarray(answer, dtype=np.int64)\n\n        self.stop_step = self.sents_size // batch_size\n\n        if shuffle:\n            self.shuffle()\n\n    def shuffle(self):\n        index = np.arange(self.story.shape[0])\n        np.random.shuffle(index)\n        self.story = self.story[index]\n        self.question = self.question[index]\n        self.answer = self.answer[index]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def story2tensor(story):\n            story = np.array([np.concatenate((np.array([sent + [PAD] * (self.max_s_len-len(sent))\n                                                        for sent in s]), np.zeros((STORYLEN - len(s), self.max_s_len)))) for s in story], dtype=np.int64)\n            story = torch.from_numpy(story)\n            if self.cuda:\n                story = story.cuda()\n            return story\n\n        def qustion2tensor(question):\n            question = np.array([q + [PAD] * (self.max_q_len - len(q))\n                                 for q in question], dtype=np.int64)\n            question = torch.from_numpy(question)\n            if self.cuda:\n                question = question.cuda()\n            return question\n\n        def answer2tensor(answer):\n            answer = torch.from_numpy(answer)\n            if self.cuda:\n                answer = answer.cuda()\n            return answer\n\n        if self.step == self.stop_step:\n            self.step = 0\n            raise StopIteration()\n\n        start = self.step * self.bsz\n        self.step += 1\n\n        story = story2tensor(self.story[start:start + self.bsz])\n        question = qustion2tensor(self.question[start:start + self.bsz])\n        answer = answer2tensor(self.answer[start:start + self.bsz])\n\n        return story, question, answer\n\n\nif __name__ == ""__main__"":\n    data = torch.load(""data/corpus.pt"")\n    dl = DataLoader(data[""story""],\n                    data[""question""],\n                    data[""answer""],\n                    data[""max_q_len""],\n                    data[""max_s_len""],\n                    data[""word2idx""],\n                    data[""answer2idx""], batch_size=2)\n\n    s, q, a = next(dl)\n    print(s)\n    print(q)\n    print(a.shape)\n\n    dl = DataLoader(data[""test_story""],\n                    data[""test_question""],\n                    data[""test_answer""],\n                    data[""max_q_len""],\n                    data[""max_s_len""],\n                    data[""word2idx""],\n                    data[""answer2idx""], batch_size=2)\n\n    s, q, a = next(dl)\n    print(s)\n    print(q)\n    print(a.shape)\n    print(s[:, 1, :])\n'"
relation-network/model.py,9,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass RelationNet(nn.Module):\n    def __init__(self, word_size, answer_size,\n                 max_s_len, max_q_len, use_cuda,\n                 story_len=20,\n                 emb_dim=32,\n                 story_hsz=32,\n                 story_layers=1,\n                 question_hsz=32,\n                 question_layers=1):\n\n        super().__init__()\n\n        self.use_cuda = use_cuda\n\n        self.max_s_len = max_s_len\n        self.max_q_len = max_q_len\n\n        self.story_len = story_len\n\n        self.emb_dim = emb_dim\n        self.story_hsz = story_hsz\n\n        self.emb = nn.Embedding(word_size, emb_dim)\n        self.story_rnn = torch.nn.LSTM(input_size=emb_dim,\n                                       hidden_size=story_hsz,\n                                       num_layers=story_layers,\n                                       batch_first=True)\n        self.question_rnn = torch.nn.LSTM(input_size=emb_dim,\n                                          hidden_size=question_hsz,\n                                          num_layers=question_layers,\n                                          batch_first=True)\n\n        self.g1 = nn.Linear((2*story_len)+(2*story_hsz)+question_hsz, 256)\n        self.g2 = nn.Linear(256, 256)\n        self.g3 = nn.Linear(256, 256)\n        self.g4 = nn.Linear(256, 256)\n\n        self.f1 = nn.Linear(256, 256)\n        self.f2 = nn.Linear(256, 512)\n        self.f3 = nn.Linear(512, answer_size)\n\n        self._reset_parameters()\n\n    def _reset_parameters(self, stddev=0.1):\n        self.emb.weight.data.normal_(std=stddev)\n\n        self.g1.weight.data.normal_(std=stddev)\n        self.g1.bias.data.fill_(0)\n\n        self.g2.weight.data.normal_(std=stddev)\n        self.g2.bias.data.fill_(0)\n\n        self.g3.weight.data.normal_(std=stddev)\n        self.g3.bias.data.fill_(0)\n\n        self.g4.weight.data.normal_(std=stddev)\n        self.g4.bias.data.fill_(0)\n\n        self.f1.weight.data.normal_(std=stddev)\n        self.f1.bias.data.fill_(0)\n\n        self.f2.weight.data.normal_(std=stddev)\n        self.f2.bias.data.fill_(0)\n\n        self.f3.weight.data.normal_(std=stddev)\n        self.f3.bias.data.fill_(0)\n\n    def g_theta(self, x):\n        x = F.relu_(self.g1(x))\n        x = F.relu_(self.g2(x))\n        x = F.relu_(self.g3(x))\n        x = F.relu_(self.g4(x))\n        return x\n\n    def init_tags(self):\n        tags = torch.zeros((self.story_len, self.story_len))\n        if self.use_cuda:\n            tags = tags.cuda()\n        for i in range(self.story_len):\n            tags[i, i].fill_(1)\n        return tags\n\n    def forward(self, story, question):\n        tags = self.init_tags()\n        bsz = story.shape[0]\n\n        s_emb = self.emb(story)\n        s_emb = s_emb.view(-1, self.max_s_len, self.emb_dim)\n\n        _, (s_state, _) = self.story_rnn(s_emb)\n        s_state = s_state[-1, :, :]\n        s_state = s_state.view(-1, self.story_len, self.story_hsz)\n\n        s_tags = tags.unsqueeze(0)\n        s_tags = s_tags.repeat((bsz, 1, 1))\n\n        story_objects = torch.cat((s_state, s_tags), dim=2)\n\n        q_emb = self.emb(question)\n        _, (q_state, _) = self.question_rnn(q_emb)\n        q_state = q_state[-1, :, :]\n\n        sum_g_theta = 0\n        for i in range(self.story_len):\n            this_tensor = story_objects[:, i, :]\n            for j in range(self.story_len):\n                u = torch.cat(\n                    (this_tensor, story_objects[:, j, :], q_state), dim=1)\n                g = self.g_theta(u)\n                sum_g_theta = torch.add(sum_g_theta, g)\n\n        out = F.relu(self.f1(sum_g_theta))\n        out = F.relu(self.f2(out))\n        out = self.f3(out)\n\n        return out\n\n\nif __name__ == ""__main__"":\n    from data_loader import DataLoader\n\n    data = torch.load(""data/corpus.pt"")\n\n    training_data = DataLoader(data[""story""],\n                               data[""question""],\n                               data[""answer""],\n                               data[""max_q_len""],\n                               data[""max_s_len""],\n                               data[""word2idx""],\n                               data[""answer2idx""],\n                               cuda=True)\n\n    s, q, a = next(training_data)\n\n    model = RelationNet(len(data[""word2idx""]),\n                        len(data[""answer2idx""]),\n                        data[""max_s_len""],\n                        data[""max_q_len""],\n                        True,\n                        story_hsz=32,\n                        story_layers=1,\n                        question_hsz=32,\n                        question_layers=1)\n    model.cuda()\n    t = model(s, q)\n'"
relation-network/train.py,11,"b'import argparse\nimport os\n\nimport torch\n\nfrom data_loader import DataLoader\nfrom model import *\nfrom const import PAD\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--epochs\', type=int, default=50)\nparser.add_argument(\'--batch_size\', type=int, default=64)\nparser.add_argument(\'--seed\', type=int, default=1101)\nparser.add_argument(\'--unuse_cuda\', action=\'store_true\')\n\nparser.add_argument(\'--data\', type=str, default=\'data/corpus.pt\')\n\nparser.add_argument(\'--word_ebd_dim\', type=int, default=32)\nparser.add_argument(\'--lstm_hsz\', type=int, default=64)\nparser.add_argument(\'--lstm_layers\', type=int, default=2)\nparser.add_argument(\'--clip\', type=float, default=5.)\nparser.add_argument(\'--lr\', type=float, default=2e-4)\n\nargs = parser.parse_args()\n\ntorch.manual_seed(args.seed)\nuse_cuda = torch.cuda.is_available() and not args.unuse_cuda\n\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\n# Tensorboard\ntry:\n    import tensorflow as tf\nexcept ImportError:\n    tf = None\n\ntf_summary_writer = tf and tf.summary.FileWriter(""logdir"")\n\n\ndef add_summary_value(key, value, tf_step):\n    summary = tf.Summary(value=[tf.Summary.Value(tag=key, simple_value=value)])\n    tf_summary_writer.add_summary(summary, tf_step)\n\n\ndata = torch.load(args.data)\n\ntraining_data = DataLoader(data[""story""],\n                           data[""question""],\n                           data[""answer""],\n                           data[""max_q_len""],\n                           data[""max_s_len""],\n                           data[""word2idx""],\n                           data[""answer2idx""],\n                           cuda=use_cuda,\n                           batch_size=args.batch_size)\n\nvalidation_data = DataLoader(data[""test_story""],\n                             data[""test_question""],\n                             data[""test_answer""],\n                             data[""max_q_len""],\n                             data[""max_s_len""],\n                             data[""word2idx""],\n                             data[""answer2idx""],\n                             cuda=use_cuda,\n                             batch_size=args.batch_size,\n                             shuffle=False)\n\nmodel = RelationNet(len(data[""word2idx""]),\n                    len(data[""answer2idx""]),\n                    data[""max_s_len""],\n                    data[""max_q_len""],\n                    use_cuda,\n                    story_hsz=args.lstm_hsz,\n                    story_layers=args.lstm_layers,\n                    question_hsz=args.lstm_hsz,\n                    question_layers=args.lstm_layers)\n\nif use_cuda:\n    model = model.cuda()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\ncriterion = torch.nn.CrossEntropyLoss()\n\n\ndef train(i):\n    model.train()\n    corrects = total_loss = 0\n    for story, question, answer in training_data:\n        optimizer.zero_grad()\n        pred = model(story, question)\n        loss = criterion(pred, answer)\n        loss.backward()\n        # torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n        optimizer.step()\n        total_loss += loss.data.item()\n        corrects += (torch.max(pred, 1)[1].data == answer.data).sum()\n    print(\n        f""train epoch {i+1}/{args.epochs} loss: {total_loss/training_data.stop_step:.4f} corrects: {float(corrects)*100/(training_data.sents_size):.2f}%"")\n\n    if tf is not None:\n        add_summary_value(""train loss"", total_loss /\n                          training_data.stop_step, i)\n        add_summary_value(""train corrects"", float(corrects)\n                          * 100/(training_data.sents_size), i)\n        tf_summary_writer.flush()\n\n\ndef evaluate(i):\n    model.eval()\n    corrects = eval_loss = 0\n\n    for story, question, answer in validation_data:\n        with torch.no_grad():\n            pred = model(story, question)\n            loss = criterion(pred, answer)\n            eval_loss += loss.data.item()\n            corrects += (torch.max(pred, 1)[1].data == answer.data).sum()\n    print(\n        f""eval epoch {i+1}/{args.epochs} loss: {eval_loss/validation_data.stop_step:.4f} corrects: {float(corrects)*100/(validation_data.sents_size):.2f}%"")\n\n    if tf is not None:\n        add_summary_value(""evaluate loss"", eval_loss /\n                          validation_data.stop_step, i)\n        add_summary_value(""evaluate corrects"", float(corrects)\n                          * 100 / (validation_data.sents_size), i)\n        tf_summary_writer.flush()\n\n\nos.makedirs(""weights"", exist_ok=True)\ntry:\n    print(\'-\' * 90)\n    for epoch in range(args.epochs):\n        train(epoch)\n        print(\'-\' * 90)\n        evaluate(epoch)\n        print(\'-\' * 90)\n\n        model_state_dict = model.state_dict()\n        model_source = {\n            ""settings"": args,\n            ""model"": model_state_dict,\n            ""word2idx"": data[\'word2idx\'],\n            ""answer2idx"": data[\'answer2idx\'],\n            ""max_q_len"": data[""max_q_len""],\n            ""max_s_len"": data[""max_s_len""],\n        }\n        torch.save(model_source, f""weights/model_{epoch+1}.pt"")\n\nexcept KeyboardInterrupt:\n    print(""Exiting from training early"")\n'"
retrieval-based-chatbots/const.py,0,"b""PAD = 0\nUNK = 1\n\nWORD = {\n    PAD: '<pad>',\n    UNK: '<unk>',\n}\n"""
retrieval-based-chatbots/corpus.py,1,"b'import torch\n\nfrom const import *\n\n\ndef reps2idx(responses, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in rep] for rep in responses]\n\n\ndef uttes2idx(utterances, word2idx):\n    return [[[word2idx[w] if w in word2idx else UNK for w in u] for u in utte] for utte in utterances]\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK,\n        }\n        self.idx = len(self.word2idx)\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, utterances, responses, min_count):\n        words = [word for resp in responses for word in resp]\n        words += [word for utte in utterances for u in utte for word in u]\n\n        word_count = {w: 0 for w in set(words)}\n        for w in words:\n            word_count[w] += 1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Corpus(object):\n    def __init__(self, max_cont_len=10, max_utte_len=50, min_word_count=2):\n        self.dict = Dictionary()\n        self.max_cont_len = max_cont_len\n        self.max_utte_len = max_utte_len\n        self.min_word_count = min_word_count\n\n        self.parse_data(""data/dev.txt"", False)\n        self.parse_data(""data/train.txt"", True)\n        self.save()\n\n    def parse_data(self, inf, is_train):\n        utterances, responses, labels = [], [], []\n\n        for line in open(inf):\n            contexts = line.strip().split(""\\t"")\n            uttes, resp, l = contexts[1:-1], contexts[-1], contexts[0]\n\n            resp = resp.split()\n            uttes = [utte.split() for utte in uttes]\n\n            if len(resp) > self.max_utte_len:\n                resp = resp[:self.max_utte_len]\n\n            if len(uttes) > self.max_cont_len:\n                # close to response\n                uttes = uttes[-self.max_cont_len:]\n\n            for index, utte in enumerate(uttes):\n                if len(utte) > self.max_utte_len:\n                    uttes[index] = utte[:self.max_utte_len]\n\n            utterances.append(uttes)\n            responses.append(resp)\n            labels.append(int(l))\n\n        if is_train:\n            ignore_w_nums = self.dict(\n                utterances, responses, self.min_word_count)\n            self.train_utterances = utterances\n            self.train_responses = responses\n            self.train_labels = labels\n\n            print(""Ignored counts - [{}]"".format(ignore_w_nums))\n\n        else:\n            self.test_utterances = utterances\n            self.test_responses = responses\n            self.test_labels = labels\n\n    def save(self):\n        data = {\n            \'max_cont_len\': self.max_cont_len,\n            \'max_utte_len\': self.max_utte_len,\n            \'dict\': {\n                \'dict\': self.dict.word2idx,\n                \'dict_size\': len(self.dict),\n            },\n            \'train\': {\n                \'responses\': reps2idx(self.train_responses, self.dict.word2idx),\n                \'utterances\': uttes2idx(self.train_utterances, self.dict.word2idx),\n                \'labels\': self.train_labels\n            },\n            \'test\': {\n                \'responses\': reps2idx(self.test_responses, self.dict.word2idx),\n                \'utterances\': uttes2idx(self.test_utterances, self.dict.word2idx),\n                \'labels\': self.test_labels\n            }\n        }\n\n        torch.save(data, ""data/corpus"")\n        print(\'dict length - [{}]\'.format(len(self.dict)))\n\n\nif __name__ == ""__main__"":\n    Corpus()\n'"
retrieval-based-chatbots/data_loader.py,9,"b'from collections import namedtuple\n\nimport torch\nfrom torch.autograd import Variable\nimport numpy as np\n\nfrom const import *\n\n\ndef reps_pad(responses, max_len, evaluation):\n    x = np.array([resp + [PAD] * (max_len - len(resp)) for resp in responses])\n    if evaluation:\n        with torch.no_grad():\n            x = Variable(torch.from_numpy(x))\n    else:\n        x = Variable(torch.from_numpy(x))\n\n    return x\n\n\ndef uttes_pad(utterances, max_cont_len, max_utte_len, evaluation):\n    pad_utte = [[PAD] * max_utte_len]\n    utterances = [[u + [PAD] * (max_utte_len - len(u))\n                   for u in utte] for utte in utterances]\n    utterances = [pad_utte * (max_cont_len - len(utte)) +\n                  utte for utte in utterances]\n\n    x = np.array(utterances)\n    if evaluation:\n        with torch.no_grad():\n            x = Variable(torch.from_numpy(x))\n    else:\n        x = Variable(torch.from_numpy(x))\n\n    return x\n\n\nclass DataLoader(object):\n    def __init__(self,\n                 utterances,\n                 responses,\n                 labels,\n                 max_cont_len,\n                 max_utte_len,\n                 use_cuda,\n                 evaluation=False,\n                 bsz=64,\n                 shuffle=True):\n        self.sents_size = len(utterances)\n        self.step = 0\n        self.stop_step = self.sents_size // bsz\n        self.bsz = bsz\n        self.use_cuda = use_cuda\n        self.evaluation = evaluation\n        self.max_cont_len = max_cont_len\n        self.max_utte_len = max_utte_len\n        self.utterances = np.asarray(utterances)\n        self.responses = np.asarray(responses)\n        self.labels = np.asarray(labels)\n        self.nt = namedtuple(\n            \'dataloader\', [\'utterances\', \'responses\', \'labels\'])\n\n        if shuffle:\n            self._shuffle()\n\n    def _shuffle(self):\n        indices = np.arange(self.utterances.shape[0])\n        np.random.shuffle(indices)\n        self.utterances = self.utterances[indices]\n        self.responses = self.responses[indices]\n        self.labels = self.labels[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.step == self.stop_step:\n            self.step = 0\n            raise StopIteration()\n\n        start = self.step * self.bsz\n        bsz = min(self.bsz, self.sents_size - start)\n        self.step += 1\n\n        utterances = uttes_pad(\n            self.utterances[start:start + bsz], self.max_cont_len, self.max_utte_len, self.evaluation)\n        responses = reps_pad(\n            self.responses[start:start + bsz], self.max_utte_len, self.evaluation)\n        labels = Variable(torch.from_numpy(self.labels[start:start + bsz]))\n\n        if self.use_cuda:\n            utterances = utterances.cuda()\n            responses = responses.cuda()\n            labels = labels.cuda()\n\n        return self.nt._make([utterances, responses, labels])\n\n\nif __name__ == \'__main__\':\n    data = torch.load(\'./data/corpus\')\n\n    training_data = DataLoader(\n        data[\'train\'][\'utterances\'],\n        data[\'train\'][\'responses\'],\n        data[\'train\'][\'labels\'],\n        data[\'max_cont_len\'],\n        data[\'max_utte_len\'],\n        True, bsz=4, shuffle=False, evaluation=True)\n\n    dict = data[""dict""][""dict""]\n    idx2word = {v: k for k, v in dict.items()}\n    u, r, l = next(training_data)\n    print(u)\n    print(r)\n    print(l)\n'"
retrieval-based-chatbots/model.py,6,"b'import math\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Model(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.emb = nn.Embedding(self.dict_size, self.emb_dim)\n        self.first_gru = nn.GRU(input_size=self.emb_dim,\n                                hidden_size=self.first_rnn_hsz,\n                                num_layers=1,\n                                batch_first=True)\n        self.transform_A = nn.Linear(\n            self.first_rnn_hsz, self.first_rnn_hsz, bias=False)\n        self.cnn = nn.Conv2d(in_channels=2,\n                             out_channels=self.fillters,\n                             kernel_size=self.kernel_size)\n        self.match_vec = nn.Linear(16 * 16 * 8, self.match_vec_dim)\n        self.second_gru = nn.GRU(input_size=self.match_vec_dim,\n                                 hidden_size=self.second_rnn_hsz,\n                                 num_layers=1)\n        self.pred = nn.Linear(self.match_vec_dim, 2)\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        stdv = 1. / math.sqrt(self.emb_dim)\n\n        self.emb.weight.data.uniform_(-stdv, stdv)\n\n        self.transform_A.weight.data.uniform_(-stdv, stdv)\n\n        self.match_vec.weight.data.uniform_(-stdv, stdv)\n        self.match_vec.bias.data.fill_(0)\n\n        self.pred.weight.data.uniform_(-stdv, stdv)\n        self.pred.bias.data.fill_(0)\n\n    def forward(self, utterances, responses):\n        bsz = utterances.size(0)\n\n        resps_emb = self.emb(responses)\n        resps_gru, _ = self.first_gru(resps_emb)\n        resps_gru = F.dropout(resps_gru, p=self.dropout)\n\n        resps_emb_t = resps_emb.transpose(1, 2)\n        resps_gru_t = resps_gru.transpose(1, 2)\n        uttes_t = utterances.transpose(0, 1)\n\n        match_vecs = []\n        for utte in uttes_t:\n            utte_emb = self.emb(utte)\n            mat_1 = torch.matmul(utte_emb, resps_emb_t)\n            utte_gru, _ = self.first_gru(utte_emb)\n            utte_gru = F.dropout(utte_gru, p=self.dropout)\n            mat_2 = torch.matmul(self.transform_A(utte_gru), resps_gru_t)\n\n            M = torch.stack([mat_1, mat_2], 1)\n            cnn_layer = F.relu(self.cnn(M))\n            pool_layer = F.max_pool2d(cnn_layer,\n                                      self.kernel_size,\n                                      stride=self.kernel_size)\n            pool_layer = pool_layer.view(bsz, -1)\n            match_vec = F.relu(self.match_vec(pool_layer))\n            match_vecs.append(match_vec)\n\n        match_vecs = torch.stack(match_vecs, 0)\n        match_vecs = F.dropout(match_vecs, p=self.dropout)\n        _, hidden = self.second_gru(match_vecs)\n        hidden = F.dropout(hidden[-1], p=self.dropout)\n        props = F.log_softmax(self.pred(hidden), dim=-1)\n\n        return props\n'"
retrieval-based-chatbots/train.py,8,"b'import argparse\n\nparser = argparse.ArgumentParser(\n    description=\'A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots\')\n\nparser.add_argument(\'--logdir\', type=str, default=\'logdir\')\nparser.add_argument(\'--data\', type=str, default=\'./data/corpus\')\n\nparser.add_argument(\'--epochs\', type=int, default=20)\nparser.add_argument(\'--batch_size\', type=int, default=64)\nparser.add_argument(\'--seed\', type=int, default=607)\nparser.add_argument(\'--lr\', type=float, default=.001)\n\nparser.add_argument(\'--dropout\', type=float, default=.5)\nparser.add_argument(\'--emb_dim\', type=int, default=200)\nparser.add_argument(\'--first_rnn_hsz\', type=int, default=200)\nparser.add_argument(\'--fillters\', type=int, default=8)\nparser.add_argument(\'--kernel_size\', type=int, default=3)\nparser.add_argument(\'--match_vec_dim\', type=int, default=50)\nparser.add_argument(\'--second_rnn_hsz\', type=int, default=50)\n\nargs = parser.parse_args()\n\nimport torch\n\ntorch.manual_seed(args.seed)\nargs.use_cuda = use_cuda = torch.cuda.is_available()\n\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# ##############################################################################\n# Tensorboard\n################################################################################\ntry:\n    import tensorflow as tf\n    tf_step = 0\nexcept ImportError:\n    tf = None\n\ntf_summary_writer = tf and tf.summary.FileWriter(args.logdir)\n\n\ndef add_summary_value(key, value):\n    global tf_step\n\n    summary = tf.Summary(value=[tf.Summary.Value(tag=key, simple_value=value)])\n    tf_summary_writer.add_summary(summary, tf_step)\n\n\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_cont_len = data[""max_cont_len""]\nargs.max_utte_len = data[""max_utte_len""]\nargs.dict_size = data[\'dict\'][\'dict_size\']\nargs.kernel_size = (args.kernel_size, args.kernel_size)\n\nprint(""="" * 30 + ""arguments"" + ""="" * 30)\nfor k, v in args.__dict__.items():\n    if k in (""epochs"", ""seed"", ""data""):\n        continue\n    print(""{}: {}"".format(k, v))\nprint(""="" * 60)\n\ntraining_data = DataLoader(\n    data[\'train\'][\'utterances\'],\n    data[\'train\'][\'responses\'],\n    data[\'train\'][\'labels\'],\n    data[\'max_cont_len\'],\n    data[\'max_utte_len\'],\n    use_cuda,\n    bsz=args.batch_size)\n\nvalidation_data = DataLoader(\n    data[\'test\'][\'utterances\'],\n    data[\'test\'][\'responses\'],\n    data[\'test\'][\'labels\'],\n    data[\'max_cont_len\'],\n    data[\'max_utte_len\'],\n    use_cuda,\n    bsz=args.batch_size,\n    shuffle=False,\n    evaluation=True)\n\nfrom model import Model\n\nmodel = Model(args)\nif use_cuda:\n    model = model.cuda()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\ncriterion = torch.nn.CrossEntropyLoss()\n\n\ndef evaluate():\n    model.eval()\n    corrects = eval_loss = 0\n    _size = validation_data.sents_size\n    for utterances, responses, labels in validation_data:\n        pred = model(utterances, responses)\n        loss = criterion(pred, labels)\n\n        eval_loss += loss.data[0]\n        corrects += (torch.max(pred, 1)\n                     [1].view(labels.size()).data == labels.data).sum()\n\n    return eval_loss / _size, corrects, corrects / _size * 100.0, _size\n\n\ndef train():\n    if tf:\n        global tf_step\n    model.train()\n    for utterances, responses, labels in training_data:\n        optimizer.zero_grad()\n\n        pred = model(utterances, responses)\n        loss = criterion(pred, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        corrects = (torch.max(pred, 1)[1].view(\n            labels.size()).data == labels.data).sum()\n\n        if tf is not None:\n            add_summary_value(""loss"", loss.data[0])\n            add_summary_value(""corrects"", corrects)\n            tf_step += 1\n\n            if tf_step % 100 == 0:\n                tf_summary_writer.flush()\n\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs + 1):\n        train()\n        print(\'-\' * 90)\n        loss, corrects, acc, size = evaluate()\n        print(\'| end of epoch {:3d} | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(\n            epoch, loss, acc, corrects, size))\n        print(\'-\' * 90)\n\nexcept KeyboardInterrupt:\n    print(""-"" * 90)\n    print(""Exiting from training early"")\n'"
seq2seq/const.py,0,"b""PAD = 0\nUNK = 1\nBOS = 2\nEOS = 3\n\nWORD = {\n    PAD: '<blank>',\n    UNK: '<unk>',\n    BOS: '<s>',\n    EOS: '</s>'\n}\n"""
seq2seq/corpus.py,1,"b'import torch\n\nimport argparse\nimport logging\n\nfrom utils import corpora2idx, normalizeString\nfrom const import *\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[BOS]: BOS,\n            WORD[EOS]: EOS,\n            WORD[PAD]: PAD,\n            WORD[UNK]: UNK\n        }\n        self.idx = 4\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, sents, min_count):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words: word_count[w]+=1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\nclass Corpus(object):\n    def __init__(self, save_data, max_len=20, min_word_count=1):\n        self._save_data = save_data\n        self._max_len = max_len\n        self._min_word_count = min_word_count\n        self.src_sents = None\n        self.tgt_sents = None\n        self.src_valid_sents = None\n        self.tgt_valid_sents = None\n        self.src_dict = Dictionary()\n        self.tgt_dict = Dictionary()\n\n    def parse(self):\n        def gather_file(file_, max_len):\n            en_sents, fra_sents, en_cut_count, fra_cut_count = [], [], 0, 0\n\n            for sentences in open(file_):\n                en_, fra_ = [normalizeString(s) for s in sentences.strip().split(\'\\t\')]\n\n                en_ws = [word for word in en_.strip().split()]\n                fra_ws = [word for word in fra_.strip().split()]\n\n                if len(en_ws) > max_len:\n                    en_cut_count += 1\n                    en_ws = en_ws[:max_len]\n                en_sents.append([WORD[BOS]] + en_ws + [WORD[EOS]])\n\n                if len(fra_ws) > max_len:\n                    fra_cut_count += 1\n                    fra_ws = fra_ws[:max_len]\n                fra_sents.append([WORD[BOS]] + fra_ws + [WORD[EOS]])\n\n            return fra_sents, en_sents, fra_cut_count, en_cut_count\n\n        max_len = self._max_len - 2\n        src_train, tgt_train, fra_cut_count, en_cut_count = gather_file(\'data/train\', max_len)\n        src_valid, tgt_valid, _, _ = gather_file(\'data/test\', max_len)\n\n        print(""English data`s length out of range numbers - [{}]"".format(en_cut_count))\n        print(""French data`s length out of range numbers - [{}]"".format(fra_cut_count))\n\n        src_ignore = self.src_dict(src_train, self._min_word_count)\n        tgt_ignore = self.tgt_dict(tgt_train, self._min_word_count)\n        if src_ignore != 0:\n            print(""Ignored src word counts - [{}]"".format(src_ignore))\n        if tgt_ignore != 0:\n            print(""Ignored tgt word counts - [{}]"".format(tgt_ignore))\n\n        self.src_train = src_train\n        self.tgt_train = tgt_train\n        self.src_valid = src_valid\n        self.tgt_valid = tgt_valid\n\n    def save(self):\n        data = {\n            \'max_word_len\': self._max_len,\n            \'dict\': {\n                \'src\': self.src_dict.word2idx,\n                \'src_size\': len(self.src_dict),\n                \'tgt\': self.tgt_dict.word2idx,\n                \'tgt_size\': len(self.tgt_dict)\n            },\n            \'train\': {\n                \'src\': corpora2idx(self.src_train, self.src_dict.word2idx),\n                \'tgt\': corpora2idx(self.tgt_train, self.tgt_dict.word2idx)\n            },\n            \'valid\': {\n                \'src\': corpora2idx(self.src_valid, self.src_dict.word2idx),\n                \'tgt\': corpora2idx(self.tgt_valid, self.tgt_dict.word2idx)\n            }\n        }\n\n        torch.save(data, self._save_data)\n        print(\'src corpora length - [{}] | target corpora length - [{}]\'.format(len(self.src_dict), len(self.tgt_dict)))\n\n    def process(self):\n        self.parse()\n        self.save()\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(description=\'seq2sqe corpora\')\n    parser.add_argument(\'--save-data\', type=str, default=\'data/seq2seq.pt\',\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--max-lenth\', type=int, default=20,\n                        help=\'max length of sentence\')\n    parser.add_argument(\'--min-word-count\', type=int, default=1,\n                        help=\'min corpora count to discard\')\n    args = parser.parse_args()\n    corpus = Corpus(args.save_data, args.max_lenth, args.min_word_count)\n    corpus.process()\n'"
seq2seq/data_loader.py,3,"b'import numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport const\n\nclass DataLoader(object):\n    def __init__(self, src_sents, tgt_sents, cuda, batch_size, shuffle=True, evaluation=False):\n        self.cuda = cuda\n        self.sents_size = len(src_sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size\n        self.evaluation = evaluation\n        self._batch_size = batch_size\n        self._src_sents = np.asarray(src_sents)\n        self._tgt_sents = np.asarray(tgt_sents)\n\n        if shuffle:\n            self.shuffle()\n\n    def shuffle(self):\n        index = np.arange(self._src_sents.shape[0])\n        np.random.shuffle(index)\n        self._src_sents = self._src_sents[index]\n        self._tgt_sents = self._tgt_sents[index]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def pad_to_longest(insts):\n            max_len = max(len(inst) for inst in insts)\n            inst_data = np.array([inst + [const.PAD] * (max_len - len(inst)) for inst in insts])\n            inst_position = np.array([[pos_i+1 if w_i != const.PAD else 0 for pos_i, w_i in enumerate(inst)] for inst in inst_data])\n\n            inst_data_tensor = Variable(torch.from_numpy(inst_data), volatile=self.evaluation)\n            inst_position_tensor = Variable(torch.from_numpy(inst_position), volatile=self.evaluation)\n\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n                inst_position_tensor = inst_position_tensor.cuda()\n            return (inst_data_tensor, inst_position_tensor)\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step*self._batch_size\n        _bsz = self._batch_size\n        self._step += 1\n\n        src = pad_to_longest(self._src_sents[_start:_start+_bsz])\n        tgt = pad_to_longest(self._tgt_sents[_start:_start+_bsz])\n\n        return src, tgt\n'"
seq2seq/layers.py,15,"b'##################################################################################\n# borrowed from https://github.com/jadore801120/attention-is-all-you-need-pytorch\n##################################################################################\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.nn import init\nimport torch.nn.functional as F\n\nimport numpy as np\n\n\nclass LayerNorm(nn.Module):\n    def __init__(self, hidden_size, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n        self.weight = nn.Parameter(torch.ones(hidden_size))\n        self.bias = nn.Parameter(torch.zeros(hidden_size))\n\n    def forward(self, input):\n        mu = torch.mean(input, dim=-1, keepdim=True)\n        sigma = torch.std(input, dim=-1, keepdim=True).clamp(min=self.eps)\n        output = (input - mu) / sigma\n        return output * self.weight.expand_as(output) + self.bias.expand_as(output)\n\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self, d_k, dropout):\n        super().__init__()\n        self.temper = np.power(d_k, 0.5)\n        self.dropout = nn.Dropout(dropout)\n        self.softmax = nn.Softmax()\n\n    def forward(self, q, k, v, attn_mask):\n        attn = torch.bmm(q, k.transpose(1, 2)) / self.temper\n        attn.data.masked_fill_(attn_mask, -float(\'inf\'))\n\n        attn = self.softmax(attn.view(-1, attn.size(2))).view(*attn.size())\n        attn = self.dropout(attn)\n        return torch.bmm(attn, v)\n\n\nclass MultiHeadAtt(nn.Module):\n    def __init__(self, n_head, d_model, dropout):\n        super().__init__()\n        self.n_head = n_head\n        self.d_v = self.d_k = d_k = d_model // n_head\n\n        for name in [""w_qs"", ""w_ks"", ""w_vs""]:\n            self.__setattr__(name,\n                             nn.Parameter(torch.FloatTensor(n_head, d_model, d_k)))\n\n        self.attention = ScaledDotProductAttention(d_k, dropout)\n        self.lm = LayerNorm(d_model)\n        self.w_o = nn.Linear(d_model, d_model, bias=False)\n        self.dropout = dropout\n\n        self._init_weight()\n\n    def forward(self, q, k, v, attn_mask):\n        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n        residual = q\n\n        bsz, len_q, d_model = q.size()\n        len_k, len_v = k.size(1), v.size(1)\n\n        def reshape(x):\n            """"""[bsz, len, d_*] -> [n_head x (bsz*len) x d_*]""""""\n            return x.repeat(n_head, 1, 1).view(n_head, -1, d_model)\n\n        q_s, k_s, v_s = map(reshape, [q, k, v])\n\n        q_s = torch.bmm(q_s, self.w_qs).view(-1, len_q, d_k)\n        k_s = torch.bmm(k_s, self.w_ks).view(-1, len_k, d_k)\n        v_s = torch.bmm(v_s, self.w_vs).view(-1, len_v, d_v)\n\n        outputs = self.attention(q_s, k_s, v_s, attn_mask.repeat(n_head, 1, 1))\n        outputs = torch.cat(torch.split(outputs, bsz, dim=0),\n                            dim=-1).view(-1, n_head * d_v)\n        outputs = F.dropout(self.w_o(outputs),\n                            p=self.dropout).view(bsz, len_q, -1)\n        return self.lm(outputs + residual)\n\n    def _init_weight(self):\n        init.xavier_normal(self.w_qs)\n        init.xavier_normal(self.w_ks)\n        init.xavier_normal(self.w_vs)\n        init.xavier_normal(self.w_o.weight)\n\n\nclass PositionWise(nn.Module):\n    def __init__(self, d_model, d_ff, dropout):\n        super().__init__()\n\n        self.seq = nn.Sequential(\n            nn.Conv1d(d_model, d_ff, 1),\n            nn.ReLU(),\n            nn.Conv1d(d_ff, d_model, 1),\n            nn.Dropout(dropout)\n        )\n        self.lm = LayerNorm(d_model)\n\n    def forward(self, input):\n        residual = input\n        out = self.seq(input.transpose(1, 2)).transpose(1, 2)\n        return self.lm(residual + out)\n\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, d_ff, n_head, dropout):\n        super().__init__()\n        self.mh = MultiHeadAtt(n_head, d_model, dropout)\n        self.pw = PositionWise(d_model, d_ff, dropout)\n\n    def forward(self, enc_input, slf_attn_mask):\n        enc_output = self.mh(\n            enc_input, enc_input, enc_input, slf_attn_mask)\n        enc_output = self.pw(enc_output)\n        return enc_output\n\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, d_ff, n_head, dropout=0.1):\n        super().__init__()\n        self.slf_mh = MultiHeadAtt(n_head, d_model, dropout)\n        self.dec_mh = MultiHeadAtt(n_head, d_model, dropout)\n        self.pw = PositionWise(d_model, d_ff, dropout)\n\n    def forward(self, dec_input, enc_output, slf_attn_mask, dec_enc_attn_mask):\n        dec_output = self.slf_mh(dec_input, dec_input,\n                                 dec_input, slf_attn_mask)\n        dec_output = self.dec_mh(\n            dec_output, enc_output, enc_output, dec_enc_attn_mask)\n        dec_output = self.pw(dec_output)\n\n        return dec_output\n'"
seq2seq/model.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\nfrom layers import EncoderLayer, DecoderLayer\nfrom utils import *\nfrom const import *\n\nclass Encoder(nn.Module):\n    def __init__(self, enc_vocab_size, max_word_len, n_enc, d_model, d_ff, n_head, dropout):\n        super().__init__()\n\n        self.n_position = max_word_len + 1\n        self.enc_vocab_size = enc_vocab_size\n        self.d_model = d_model\n\n        self.enc_ebd = nn.Embedding(enc_vocab_size,\n                            d_model, padding_idx=PAD)\n        self.pos_ebd = nn.Embedding(self.n_position,\n                            d_model, padding_idx=PAD)\n        self.encodes = nn.ModuleList([\n            EncoderLayer(d_model, d_ff, n_head, dropout) for _ in range(n_enc)])\n\n        self._init_weight()\n\n    def _init_weight(self, scope=.1):\n        self.enc_ebd.weight.data.uniform_(-scope, scope)\n        self.pos_ebd.weight.data = position(self.n_position, self.d_model)\n        self.pos_ebd.weight.requires_grad = False\n\n    def forward(self, input, pos):\n        encode = self.enc_ebd(input) + self.pos_ebd(pos)\n        enc_outputs, enc_output = [], encode\n        slf_attn_mask = get_attn_padding_mask(input, input)\n\n        for layer in self.encodes:\n            enc_output = layer(enc_output, slf_attn_mask)\n            enc_outputs.append(enc_output)\n\n        return enc_outputs\n\nclass Decoder(nn.Module):\n    def __init__(self, dec_vocab_size, max_word_len, n_dec, d_model, d_ff, n_head, dropout):\n        super().__init__()\n\n        self.d_model = d_model\n        self.n_position = max_word_len + 1\n\n        self.pos_ebd = nn.Embedding(\n            self.n_position, d_model, padding_idx=PAD)\n        self.dec_ebd = nn.Embedding(\n            dec_vocab_size, d_model, padding_idx=PAD)\n        self.decodes = nn.ModuleList([\n            DecoderLayer(d_model, d_ff, n_head, dropout) for _ in range(n_dec)])\n\n        self._init_weight()\n\n    def _init_weight(self, scope=.1):\n        self.dec_ebd.weight.data.uniform_(-scope, scope)\n        self.pos_ebd.weight.data = position(self.n_position, self.d_model)\n        self.pos_ebd.weight.requires_grad = False\n\n    def forward(self, enc_outputs, enc_input, dec_input, dec_pos):\n        dec_output = self.dec_ebd(dec_input) + self.pos_ebd(dec_pos)\n\n        dec_slf_attn_mask = torch.gt(\n            get_attn_padding_mask(dec_input, dec_input) + get_attn_subsequent_mask(dec_input), 0)\n        dec_enc_attn_pad_mask = get_attn_padding_mask(dec_input, enc_input)\n\n        for layer, enc_output in zip(self.decodes, enc_outputs):\n            dec_output = layer(dec_output, enc_output,\n                dec_slf_attn_mask, dec_enc_attn_pad_mask)\n\n        return dec_output\n\nclass Transformer(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.enc = Encoder(self.enc_vocab_size, self.max_word_len, self.n_stack_layers, self.d_model, self.d_ff, self.n_head, self.dropout)\n        self.dec = Decoder(self.dec_vocab_size, self.max_word_len, self.n_stack_layers,\n                self.d_model, self.d_ff, self.n_head, self.dropout)\n\n        self.linear = nn.Linear(self.d_model, self.dec_vocab_size,  bias=False)\n\n        self._init_weight()\n\n    def _init_weight(self):\n        if self.share_linear:\n            self.linear.weight = self.dec.dec_ebd.weight\n        else:\n            init.xavier_normal(self.linear.weight)\n\n    def get_trainable_parameters(self):\n        return filter(lambda m: m.requires_grad, self.parameters())\n\n    def forward(self, src, src_pos, tgt, tgt_pos):\n        tgt, tgt_pos = tgt[:, :-1], tgt_pos[:, :-1]\n\n        enc_outputs = self.enc(src, src_pos)\n        dec_output = self.dec(enc_outputs, src, tgt, tgt_pos)\n\n        out = self.linear(dec_output)\n\n        return F.log_softmax(out.view(-1, self.dec_vocab_size))\n'"
seq2seq/optim.py,0,"b""import numpy as np\n\nclass ScheduledOptim(object):\n    def __init__(self, optimizer, d_model, n_warmup_steps):\n        self.optimizer = optimizer\n        self.d_model = d_model\n        self.n_warmup_steps = n_warmup_steps\n        self.n_current_steps = 0\n\n    def step(self):\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def update_learning_rate(self):\n        self.n_current_steps += 1\n        new_lr = np.power(self.d_model, -0.5) * np.min([np.power(self.n_current_steps, -0.5), np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n\n        for param_group in self.optimizer.param_groups:\n            param_group['lr'] = new_lr\n"""
seq2seq/train.py,9,"b'from tqdm import tqdm\nimport time\nimport const\nfrom optim import ScheduledOptim\nfrom model import Transformer\nfrom data_loader import DataLoader\nfrom torch.autograd import Variable\nimport torch\nimport argparse\n\nparser = argparse.ArgumentParser(description=\'seq2seq\')\nparser.add_argument(\'--epochs\', type=int, default=32,\n                    help=\'number of epochs for train\')\nparser.add_argument(\'--batch-size\', type=int, default=16,\n                    help=\'batch size for training\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda-able\', action=\'store_true\',\n                    help=\'enables cuda\')\n\nparser.add_argument(\'--save\', type=str, default=\'seq2seq.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--data\', type=str, default=\'data/seq2seq.pt\',\n                    help=\'location of the data corpus\')\n\nparser.add_argument(\'--not-share-linear\', action=\'store_true\',\n                    help=\'Share the weight matrix between tgt word embedding/linear\')\nparser.add_argument(\'--dropout\', type=float, default=0.5,\n                    help=\'the probability for dropout (0 = no dropout)\')\nparser.add_argument(\'--d-model\', type=int, default=512,\n                    help=\'equal dimension of word embedding dim\')\nparser.add_argument(\'--d-ff\', type=int, default=2048,\n                    help=\'Position-wise Feed-Forward Networks inner layer dim\')\nparser.add_argument(\'--n-head\', type=int, default=8)\nparser.add_argument(\'--n-stack-layers\', type=int, default=6)\nparser.add_argument(\'--n-warmup-steps\', type=int, default=0)\n\nargs = parser.parse_args()\nargs.share_linear = not args.not_share_linear\n\n\ntorch.manual_seed(args.seed)\nuse_cuda = torch.cuda.is_available() and args.cuda_able\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# ##############################################################################\n# Load data\n# ##############################################################################\n\ndata = torch.load(args.data)\nargs.max_word_len = data[""max_word_len""]\n\ntraining_data = DataLoader(\n    data[\'train\'][\'src\'],\n    data[\'train\'][\'tgt\'],\n    batch_size=args.batch_size,\n    shuffle=False,\n    cuda=use_cuda)\n\nvalidation_data = DataLoader(\n    data[\'valid\'][\'src\'],\n    data[\'valid\'][\'tgt\'],\n    batch_size=args.batch_size,\n    shuffle=False,\n    evaluation=True,\n    cuda=use_cuda)\n\nargs.enc_vocab_size = data[\'dict\'][\'src_size\']\nargs.dec_vocab_size = data[\'dict\'][\'tgt_size\']\n\nargs.n_warmup_steps = args.n_warmup_steps if args.n_warmup_steps != 0 else training_data._stop_step\n\n# ##############################################################################\n# Build model\n# ##############################################################################\n\nmodel = Transformer(args)\n\noptimizer = ScheduledOptim(\n    torch.optim.Adam(model.get_trainable_parameters(),\n                     betas=(0.9, 0.98), eps=1e-09),\n    args.d_model, args.n_warmup_steps)\n\n\ndef get_criterion(vocab_size):\n    weight = torch.ones(vocab_size)\n    weight[const.PAD] = 0\n    return torch.nn.CrossEntropyLoss(weight, size_average=False)\n\n\ncrit = get_criterion(args.dec_vocab_size)\n\nif use_cuda:\n    model = model.cuda()\n    crit = crit.cuda()\n\n# ##############################################################################\n# Training\n# ##############################################################################\n\ntrain_loss = []\nvalid_loss = []\naccuracy = []\n\n\ndef get_performance(crit, pred, gold):\n    gold = gold.contiguous().view(-1)\n\n    loss = crit(pred, gold)\n    pred = pred.max(1)[1]\n\n    n_correct = pred.data.eq(gold.data)\n    n_correct = n_correct.masked_select(gold.ne(const.PAD).data).sum()\n\n    return loss, n_correct\n\n\ndef evaluate():\n    model.eval()\n    total_loss = n_total_words = n_total_correct = 0\n    for src, tgt in tqdm(validation_data, mininterval=0.2,\n                         desc=\'Evaluate Processing\', leave=False):\n        gold = tgt[0][:, 1:]\n\n        pred = model(*src, *tgt)\n        loss, n_correct = get_performance(crit, pred, gold)\n\n        n_total_words += gold.data.ne(const.PAD).sum()\n        n_total_correct += n_correct\n        total_loss += loss.data\n\n    return total_loss[0]/n_total_words, n_total_correct, n_total_words, n_total_correct/n_total_words\n\n\ndef train():\n    model.train()\n    start_time = time.time()\n    total_loss = n_total_words = 0\n    for src, tgt in tqdm(training_data, mininterval=1,\n                         desc=\'Train Processing\', leave=False):\n\n        gold = tgt[0][:, 1:]\n\n        optimizer.zero_grad()\n        pred = model(*src, *tgt)\n\n        loss, _ = get_performance(crit, pred, gold)\n        loss.backward()\n\n        optimizer.step()\n        optimizer.update_learning_rate()\n\n        n_total_words += gold.data.ne(const.PAD).sum()\n        total_loss += loss.data\n\n    return total_loss[0]/n_total_words\n\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs+1):\n        epoch_start_time = time.time()\n        loss = train()\n        train_loss.append(loss)\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(\n            epoch, time.time() - epoch_start_time, loss))\n\n        loss, corrects, n_words, acc = evaluate()\n        valid_loss.append(loss)\n        accuracy.append(acc)\n        epoch_start_time = time.time()\n        print(\'-\' * 90)\n        print(\'| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {:.4f}%({}/{})\'.format(\n            epoch, time.time() - epoch_start_time, loss, acc*100, corrects, n_words))\n        print(\'-\' * 90)\n\n        if not best_acc or best_acc < acc:\n            best_acc = acc\n            model_state_dict = model.state_dict()\n            model_source = {\n                ""settings"": args,\n                ""model"": model_state_dict,\n                ""src_dict"": data[\'dict\'][\'src\'],\n                ""tgt_dict"": data[\'dict\'][\'tgt\']\n            }\n            torch.save(model_source, args.save)\nexcept KeyboardInterrupt:\n    print(""-""*80)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format(\n        (time.time() - total_start_time)/60.0))\n\nprint(train_loss)\nprint(valid_loss)\nprint(accuracy)\n'"
seq2seq/transform.py,13,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\n\nfrom const import *\nfrom model import Transformer\nfrom utils import normalizeString\n\nimport time\nimport copy\n\nclass Translate(object):\n    def __init__(self, model_source, cuda=False, beam_size=3):\n        self.torch = torch.cuda if cuda else torch\n        self.cuda = cuda\n        self.beam_size = beam_size\n\n        if self.cuda:\n            model_source = torch.load(model_source)\n        else:\n            model_source = torch.load(model_source, map_location=lambda storage, loc: storage)\n        self.src_dict = model_source[""src_dict""]\n        self.tgt_dict = model_source[""tgt_dict""]\n        self.src_idx2word = {v: k for k, v in model_source[""tgt_dict""].items()}\n        self.args = args = model_source[""settings""]\n        model = Transformer(args)\n        model.load_state_dict(model_source[\'model\'])\n\n        if self.cuda: model = model.cuda()\n        else: model = model.cpu()\n        self.model = model.eval()\n\n    def sent2tenosr(self, sentence):\n        max_len = self.args.max_word_len - 2\n        sentence = normalizeString(sentence)\n        words = [w for w in sentence.strip().split()]\n\n        if len(words) > max_len:\n            words = words[:max_len]\n\n        words = [WORD[BOS]] + words + [WORD[EOS]]\n        idx = [self.src_dict[w] if w in self.src_dict else UNK for w in words]\n\n        idx_data = torch.LongTensor(idx)\n        idx_position = torch.LongTensor([pos_i+1 if w_i != PAD else 0 for pos_i, w_i in enumerate(idx)])\n        idx_data_tensor = Variable(idx_data.unsqueeze(0), volatile=True)\n        idx_position_tensor = Variable(idx_position.unsqueeze(0), volatile=True)\n\n        if self.cuda:\n            idx_data_tensor = idx_data_tensor.cuda()\n            idx_position_tensor = idx_position_tensor.cuda()\n\n        return idx_data_tensor, idx_position_tensor\n\n    def beam_search(self, w_scores, top_seqs):\n        max_scores, max_idxs = w_scores.squeeze().sort(-1, descending=True)\n        max_scores = (max_scores[:, :self.beam_size]).tolist()\n        max_idxs = (max_idxs[:, :self.beam_size]).tolist()\n\n        all_seqs = []\n\n        for index, seq in enumerate(top_seqs):\n            seq_idxs, seq_score = seq\n            last_seq_idx = seq_idxs[-1]\n            if last_seq_idx == EOS:\n                all_seqs += [(seq, seq_score, True)]\n                continue\n\n            for score, idx in zip(max_scores[index], max_idxs[index]):\n                temp_seq = copy.deepcopy(seq)\n                seq_idxs, seq_score = temp_seq\n                seq_score += score\n                seq_idxs += [idx]\n                all_seqs += [((seq_idxs, seq_score), seq_score, idx == EOS)]\n\n        top_seqs = sorted(all_seqs, key = lambda seq: seq[1], reverse=True)[:self.beam_size]\n\n        all_done, done_nums = self.check_all_done(top_seqs)\n        top_seqs = [seq for seq, _, _ in top_seqs]\n\n        return top_seqs, all_done, self.beam_size-done_nums\n\n    def check_all_done(self, seqs):\n        done_nums = len([s for s in seqs if s[-1]])\n        return done_nums == self.beam_size, done_nums\n\n    def init_input(self):\n        input_data = torch.LongTensor(self.beam_size).fill_(BOS).unsqueeze(1)\n        return Variable(input_data.long(), volatile=True)\n\n    def update_input(self, top_seqs):\n        input_data = [seq[0] for seq in top_seqs if seq[0][-1] != EOS]\n        input_data = torch.LongTensor(input_data)\n        return Variable(input_data, volatile=True)\n\n    def update_state(self, step, src_seq, enc_outputs, un_dones):\n        input_pos = torch.arange(1, step+1).unsqueeze(0)\n        input_pos = input_pos.repeat(un_dones, 1)\n        input_pos = Variable(input_pos.long(), volatile=True)\n\n        src_seq_beam = Variable(src_seq.data.repeat(un_dones, 1))\n        enc_outputs_beam = [Variable(enc_output.data.repeat(un_dones, 1, 1)) for enc_output in enc_outputs]\n\n        return input_pos, src_seq_beam, enc_outputs_beam\n\n    def decode(self, seq, pos):\n        def length_penalty(step, len_penalty_w=1.):\n            return (torch.log(self.torch.FloatTensor([5 + step])) - torch.log(self.torch.FloatTensor([6])))*len_penalty_w\n\n        top_seqs = [([BOS], 0)] * self.beam_size\n\n        enc_outputs = self.model.enc(seq, pos)\n        seq_beam = Variable(seq.data.repeat(self.beam_size, 1))\n        enc_outputs_beam = [Variable(enc_output.data.repeat(self.beam_size, 1, 1)) for enc_output in enc_outputs]\n\n        input_data = self.init_input()\n        input_pos = torch.arange(1, 2).unsqueeze(0)\n        input_pos = input_pos.repeat(self.beam_size, 1)\n        input_pos = Variable(input_pos.long(), volatile=True)\n\n        for step in range(1, self.args.max_word_len+1):\n            if self.cuda:\n                input_pos = input_pos.cuda()\n                input_data = input_data.cuda()\n\n            dec_output = self.model.dec(enc_outputs_beam,\n                            seq_beam, input_data, input_pos)\n            dec_output = dec_output[:, -1, :] # word level feature\n            out = F.log_softmax(self.model.linear(dec_output))\n            lp = length_penalty(step)\n\n            top_seqs, all_done, un_dones = self.beam_search(out.data+lp, top_seqs)\n\n            if all_done: break\n            input_data = self.update_input(top_seqs)\n            input_pos, src_seq_beam, enc_outputs_beam = self.update_state(step+1, seq, enc_outputs, un_dones)\n\n        tgts = []\n        for seq in top_seqs:\n            cor_idxs, score = seq\n            cor_idxs = cor_idxs[1: -1]\n            tgts += [("" "".join([self.src_idx2word[idx] for idx in cor_idxs]), score)]\n        return tgts\n\n    def Trains(self, sentence, topk=1):\n        idx_data, idx_pos = self.sent2tenosr(sentence)\n        answers = self.decode(idx_data, idx_pos)\n        assert topk <= len(answers)\n        return [ans[0] for ans in answers[:topk]]\n\nif __name__ == ""__main__"":\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\'Translate\')\n    parser.add_argument(\'--French\', type=str, required=True,\n                    help=\'French for translating to English\')\n    args = parser.parse_args()\n    pre = Translate(""seq2seq.pt"")\n    print(""Translated - {}"".format(pre.Trains(args.French)[0]))\n'"
seq2seq/utils.py,4,"b'# borrowed from https://github.com/jadore801120/attention-is-all-you-need-pytorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport numpy as np\nimport re\n\nimport const\n\ndef position(n_position, d_model):\n    position_enc = np.array([[pos / np.power(10000, 2*i/d_model) for i in range(d_model)] for pos in range(n_position)])\n\n    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2])\n    position_enc[1:, 1::2] = np.sin(position_enc[1:, 1::2])\n\n    return torch.from_numpy(position_enc).float()\n\ndef get_attn_padding_mask(seq_q, seq_k):\n    assert seq_q.dim() == 2 and seq_k.dim() == 2\n    bsz, len_q = seq_q.size()\n    _, len_k = seq_k.size()\n    pad_attn_mask = seq_k.data.eq(const.PAD).unsqueeze(1)\n    pad_attn_mask = pad_attn_mask.expand(bsz, len_q, len_k)\n    return pad_attn_mask\n\ndef get_attn_subsequent_mask(seq):\n    assert seq.dim() == 2\n    attn_shape = (seq.size(0), seq.size(1), seq.size(1))\n    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype(\'uint8\')\n    subsequent_mask = torch.from_numpy(subsequent_mask)\n    if seq.is_cuda:\n        subsequent_mask = subsequent_mask.cuda()\n    return subsequent_mask\n\ndef corpora2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else const.UNK for w in s] for s in sents]\n\ndef normalizeString(s):\n    s = s.lower().strip()\n    s = re.sub(r""([.!?])"", r"" \\1"", s)\n    s = re.sub(r""[^a-zA-Z.!?]+"", r"" "", s)\n    return s\n'"
vae-nlg/const.py,0,"b""UNK = 0\nBOS = 1\nEOS = 2\n\nWORD = {\n    UNK: '<unk>',\n    BOS: '<s>',\n    EOS: '</s>'\n}\n"""
vae-nlg/corpus.py,1,"b'import torch\n\nfrom const import *\n\n\ndef word2idx(sents, word2idx):\n    return [[word2idx[w] if w in word2idx else UNK for w in s] for s in sents]\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {\n            WORD[UNK]: UNK,\n            WORD[BOS]: BOS,\n            WORD[EOS]: EOS\n        }\n        self.idx = len(self.word2idx)\n\n    def add(self, word):\n        if self.word2idx.get(word) is None:\n            self.word2idx[word] = self.idx\n            self.idx += 1\n\n    def __call__(self, sents, min_count):\n        words = [word for sent in sents for word in sent]\n        word_count = {w: 0 for w in set(words)}\n        for w in words:\n            word_count[w] += 1\n\n        ignored_word_count = 0\n        for word, count in word_count.items():\n            if count <= min_count:\n                ignored_word_count += 1\n                continue\n            self.add(word)\n\n        return ignored_word_count\n\n    def __len__(self):\n        return self.idx\n\n    def __str__(self):\n        return ""%s(size = %d)"".format(self.__class__.__name__, len(self.idx))\n\n\nclass Corpus(object):\n    def __init__(self, save_data, w2v_file, max_len=20, min_word_count=1):\n        self._save_data = save_data\n        self._max_len = max_len\n        self._min_word_count = min_word_count\n        self.sents = None\n        self.valid_sents = None\n        self.dict = Dictionary()\n        self.w2v_file = w2v_file\n        self.is_ch = lambda w: (w >= \'\\u4e00\' and w <= \'\\u9fa5\') or w == "" ""\n\n    def parse(self):\n        sents, ignore_count = [], 0\n        for sentences in open(""data/poetry""):\n            sentences = sentences.strip()\n            words = [w for w in sentences if self.is_ch(w)]\n            if len(words) != self._max_len:\n                ignore_count += 1\n                continue\n\n            sents.append(words)\n\n        print(\n            ""Data`s length not eq {} - [{}]"".format(self._max_len, ignore_count))\n        print(""Data`s length eq {} - [{}]"".format(self._max_len, len(sents)))\n\n        word_ignore = self.dict(sents, self._min_word_count)\n\n        if word_ignore != 0:\n            print(""Ignored word counts - [{}]"".format(word_ignore))\n\n        self.sents = sents\n\n    def load_w2v(self):\n        w2c_dict = {}\n        for line in open(self.w2v_file):\n            temp = line.strip().split("" "")\n\n            if len(temp) < 10:\n                continue\n            w2c_dict[temp[0]] = list(map(float, temp[1:]))\n\n            if ""len_"" not in locals():\n                len_ = len(temp[1:])\n\n        self.pre_w2v = np.random.rand(len(self.dict.word2idx), len_)\n\n        for word, idx in sorted(self.dict.word2idx.items(), key=lambda x: x[1]):\n            if word in w2c_dict:\n                self.pre_w2v[idx] = np.asarray(w2c_dict[word])\n\n    def save(self):\n        data = {\n            \'pre_w2v\': self.pre_w2v,\n            \'max_word_len\': self._max_len,\n            \'dict\': {\n                \'src\': self.dict.word2idx,\n                \'src_size\': len(self.dict),\n            },\n            \'train\': word2idx(self.sents, self.dict.word2idx)\n        }\n\n        torch.save(data, self._save_data)\n        print(\'word length - [{}]\'.format(len(self.dict)))\n\n    def process(self):\n        self.parse()\n        self.load_w2v()\n        self.save()\n\n\nif __name__ == ""__main__"":\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\'VAE NLG\')\n    parser.add_argument(\'--save-data\', type=str, default=\'data/vae_nlg.pt\',\n                        help=\'path to save processed data\')\n    parser.add_argument(\'--pre-w2v\', type=str, default=\'data/w2v\')\n    args = parser.parse_args()\n\n    corpus = Corpus(args.save_data, args.pre_w2v)\n    corpus.process()\n'"
vae-nlg/data_loader.py,2,"b'import numpy as np\nimport torch\nfrom const import *\n\n\nclass DataLoader(object):\n    def __init__(self, src_sents, max_len, batch_size, cuda=True):\n        self.cuda = cuda\n        self.sents_size = len(src_sents)\n        self._step = 0\n        self._stop_step = self.sents_size // batch_size\n\n        self._batch_size = batch_size\n        self._max_len = max_len\n        self._enc_sents = np.asarray(src_sents)\n\n        self._shuffle()\n        self.gen_data()\n\n    def gen_data(self):\n        sents = np.copy(self._enc_sents)\n\n        eos_tag = np.asarray([EOS] * self.sents_size).reshape((-1, 1))\n        bos_tag = np.asarray([BOS] * self.sents_size).reshape((-1, 1))\n\n        self._dec_sents = np.concatenate((bos_tag, sents), axis=-1)\n        self._label = np.concatenate((sents, eos_tag), axis=-1)\n\n    def _shuffle(self):\n        indices = np.arange(self._enc_sents.shape[0])\n        np.random.shuffle(indices)\n        self._enc_sents = self._enc_sents[indices]\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        def to_longest(insts):\n            inst_data_tensor = torch.from_numpy(insts)\n            if self.cuda:\n                inst_data_tensor = inst_data_tensor.cuda()\n            return inst_data_tensor\n\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _start = self._step * self._batch_size\n        _bsz = self._batch_size\n        self._step += 1\n\n        enc_input = to_longest(self._enc_sents[_start: _start + _bsz])\n        dec_input = to_longest(self._dec_sents[_start: _start + _bsz])\n        label = to_longest(self._label[_start: _start + _bsz])\n        return enc_input, dec_input, label\n\n\nif __name__ == ""__main__"":\n    data = torch.load(""data/vae_nlg.pt"")\n    _data = DataLoader(\n        data[\'train\'],\n        data[""max_word_len""],\n        4)\n\n    enc_input, dec_input, label = next(_data)\n\n    print(enc_input)\n    print(dec_input)\n    print(label)\n'"
vae-nlg/highway.py,7,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\n\nimport math\n\nclass highway_layer(nn.Module):\n    def __init__(self, hsz, active):\n        super().__init__()\n\n        self.hsz = hsz\n        self.active = active\n\n        self.gate = nn.Linear(hsz, hsz)\n        self.h = nn.Linear(hsz, hsz)\n\n    def _init_weight(self):\n        stdv = 1. / math.sqrt(self.hsz)\n\n        self.gate.weight.data.uniform_(-stdv, stdv)\n        self.gate.bias.data.fill_(-1)\n\n        if active.__name__ == ""relu"":\n            init.xavier_normal(self.h.weight)\n        else:\n            self.h.weight.data.uniform_(-stdv, stdv)\n\n    def forward(self, x):\n        gate = F.sigmoid(self.gate(x))\n\n        return torch.mul(self.active(self.h(x)), gate) + torch.mul(x, (1 - gate))\n\nclass Highway(nn.Module):\n    def __init__(self, num_layers, hsz, active):\n        super().__init__()\n\n        self.layers = nn.ModuleList([\n            highway_layer(hsz, active) for _ in range(num_layers)])\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n\n        return x\n\nif __name__ == ""__main__"":\n    from torch.autograd import Variable\n\n    x = Variable(torch.randn((2, 3)))\n    hw = Highway(2, 3, F.relu)\n\n    print(hw(x))\n\n    x = Variable(torch.randn((2, 3)))\n    hw = Highway(1, 3, F.tanh)\n\n    print(hw(x))\n'"
vae-nlg/model.py,14,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.nn.init as init\nimport numpy as np\n\nfrom highway import Highway\nfrom const import BOS\n\n\nclass Encoder(nn.Module):\n    def __init__(self, embed_dim, hidden_size, num_layers, dropout):\n        super().__init__()\n\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        self.dropout = dropout\n\n        self.rnn = nn.LSTM(embed_dim, hidden_size,\n                           num_layers, dropout, bidirectional=True)\n\n    def forward(self, input, hidden):\n        _, hidden = self.rnn(input.transpose(0, 1), hidden)\n        out = F.dropout(torch.cat((hidden[0][-2],\n                                   hidden[0][-1]), -1), p=self.dropout)\n\n        return out, hidden\n\n    def init_hidden(self, bsz):\n        size = (self.num_layers * 2, bsz, self.hidden_size)\n\n        weight = next(self.parameters()).data\n        return (Variable(weight.new(*size).zero_()),\n                Variable(weight.new(*size).zero_()))\n\n\nclass Decoder(nn.Module):\n    def __init__(self, embed_dim, latent_dim, hidden_size, num_layers, dropout, vocab_size):\n        super().__init__()\n\n        self.hidden_size = hidden_size\n        self.dropout = dropout\n        self.num_layers = num_layers\n        self.latent_dim = latent_dim\n\n        self.rnn = nn.LSTM(embed_dim + latent_dim, hidden_size,\n                           num_layers, dropout=dropout, batch_first=True)\n        self.lr = nn.Linear(hidden_size, vocab_size)\n\n        self._init_weight()\n\n    def forward(self, input, z, hidden):\n        bsz, _len, _ = input.size()\n        z = z.unsqueeze(1).expand(bsz, _len, self.latent_dim)\n        input = torch.cat((input, z), -1)\n\n        rnn_out, hidden = self.rnn(input, hidden)\n        rnn_out = F.dropout(rnn_out, p=self.dropout)\n        out = self.lr(rnn_out.contiguous().view(-1, self.hidden_size))\n\n        return F.log_softmax(out, dim=-1), hidden\n\n    def init_hidden(self, bsz):\n        size = (self.num_layers, bsz, self.hidden_size)\n\n        weight = next(self.parameters()).data\n        return (Variable(weight.new(*size).zero_()),\n                Variable(weight.new(*size).zero_()))\n\n    def _init_weight(self, scope=.1):\n        self.lr.weight.data.uniform_(-scope, scope)\n        self.lr.bias.data.fill_(0)\n\n\nclass VAE(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        for k, v in args.__dict__.items():\n            self.__setattr__(k, v)\n\n        self.lookup_table = nn.Embedding(self.vocab_size, self.embed_dim)\n        self.lookup_table.weight.data.copy_(torch.from_numpy(self.pre_w2v))\n\n        self.hw = Highway(self.hw_layers, self.hw_hsz, F.relu)\n        self.encode = Encoder(self.embed_dim,\n                              self.enc_hsz, self.enc_layers, self.dropout)\n\n        self._enc_mu = nn.Linear(self.enc_hsz * 2, self.latent_dim)\n        self._enc_log_sigma = nn.Linear(self.enc_hsz * 2, self.latent_dim)\n\n        self.decode = Decoder(self.embed_dim, self.latent_dim,\n                              self.dec_hsz, self.dec_layers, self.dropout, self.vocab_size)\n\n        self._init_weight()\n\n    def forward(self, enc_input, dec_input, enc_hidden, dec_hidden):\n        enc_ = self.lookup_table(enc_input)\n        enc_ = F.dropout(self.hw(enc_), p=self.dropout)\n        enc_output, enc_hidden = self.encode(enc_, enc_hidden)\n\n        z = self._gaussian(enc_output)\n\n        dec_ = self.lookup_table(dec_input)\n        dec, dec_hidden = self.decode(dec_, z, dec_hidden)\n\n        return dec, self.latent_loss, enc_hidden, dec_hidden\n\n    def _gaussian(self, enc_output):\n        def latent_loss(mu, sigma):\n            pow_mu = mu * mu\n            pow_sigma = sigma * sigma\n            # return 0.5 * torch.mean(pow_mu + pow_sigma - torch.log(pow_sigma) - 1)\n            return 0.5 * torch.sum(pow_mu + pow_sigma - torch.log(pow_sigma) - 1, dim=-1).mean()\n\n        mu = self._enc_mu(enc_output)\n        sigma = torch.exp(.5 * self._enc_log_sigma(enc_output))\n        self.latent_loss = latent_loss(mu, sigma)\n\n        weight = next(self.parameters()).data\n        std_z = Variable(weight.new(*sigma.size()), requires_grad=False)\n        std_z.data.copy_(torch.from_numpy(\n            np.random.normal(size=sigma.size())))\n\n        return mu + sigma * std_z\n\n    def _init_weight(self):\n        init.xavier_normal(self._enc_mu.weight)\n        init.xavier_normal(self._enc_log_sigma.weight)\n\n    def generate(self, max_len):\n        size = (1, self.latent_dim)\n\n        weight = next(self.parameters()).data\n        z = Variable(weight.new(*size), volatile=True)\n        z.data.copy_(torch.from_numpy(\n            np.random.normal(size=size)))\n\n        prob = torch.LongTensor([BOS])\n        input = Variable(prob.unsqueeze(1), volatile=True)\n        if weight.is_cuda:\n            input = input.cuda()\n        portry = """"\n        hidden = self.decode.init_hidden(1)\n\n        for index in range(1, max_len + 1):\n            encode = self.lookup_table(input)\n            output, hidden = self.decode(encode, z, hidden)\n            prob = output.squeeze().data\n            next_word = torch.max(prob, -1)[1].tolist()[0]\n            input.data.fill_(next_word)\n            if index % 5 == 0:\n                portry += self.idx2word[next_word]\n                portry += ""\xef\xbc\x8c""\n            else:\n                portry += self.idx2word[next_word]\n\n        return portry[:-1] + ""\xe3\x80\x82""\n'"
vae-nlg/optim.py,1,"b""import numpy as np\nimport torch\n\nclass ScheduledOptim(object):\n    def __init__(self, optimizer, d_model, n_warmup_steps, parameters, clip):\n        self.optimizer = optimizer\n        self.d_model = d_model\n        self.n_warmup_steps = n_warmup_steps\n        self.n_current_steps = 0\n        self.clip = clip\n        self.parameters = parameters\n\n    def step(self):\n        self.optimizer.step()\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n\n    def clip_grad_norm(self):\n        torch.nn.utils.clip_grad_norm(self.parameters, self.clip)\n\n    def update_learning_rate(self):\n        self.n_current_steps += 1\n        new_lr = np.power(self.d_model, -0.5) * np.min([np.power(self.n_current_steps, -0.5), np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n\n        for param_group in self.optimizer.param_groups:\n            param_group['lr'] = new_lr\n"""
vae-nlg/train.py,7,"b'import argparse\nimport time\n\nimport torch\nfrom torch.autograd import Variable\n\nparser = argparse.ArgumentParser(description=\'VAE-NLG\')\nparser.add_argument(\'--epochs\', type=int, default=100,\n                    help=\'number of epochs for train\')\nparser.add_argument(\'--batch-size\', type=int, default=16,\n                    help=\'batch size for training\')\nparser.add_argument(\'--seed\', type=int, default=1111,\n                    help=\'random seed\')\nparser.add_argument(\'--unuse-cuda\', action=\'store_true\',\n                    help=\'unuse cuda\')\nparser.add_argument(\'--n-warmup-steps\', type=int, default=0)\n\nparser.add_argument(\'--save\', type=str, default=\'./vae_nlg.pt\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--data\', type=str, default=\'./data/vae_nlg.pt\',\n                    help=\'location of the data corpus\')\n\nparser.add_argument(\'--embed-dim\', type=int, default=128)\nparser.add_argument(\'--hw-layers\', type=int, default=2)\nparser.add_argument(\'--hw-hsz\', type=int, default=128)\nparser.add_argument(\'--latent-dim\', type=int, default=128)\nparser.add_argument(\'--dropout\', type=float, default=0.5)\nparser.add_argument(\'--enc-hsz\', type=int, default=128)\nparser.add_argument(\'--enc-layers\', type=int, default=1)\nparser.add_argument(\'--dec-hsz\', type=int, default=128)\nparser.add_argument(\'--dec-layers\', type=int, default=2)\nparser.add_argument(\'--clip\', type=float, default=0.25)\n\nargs = parser.parse_args()\n\n\ntorch.manual_seed(args.seed)\nuse_cuda = torch.cuda.is_available() and not args.unuse_cuda\n\nif use_cuda:\n    torch.cuda.manual_seed(args.seed)\n\n# ##############################################################################\n# Load data\n###############################################################################\nfrom data_loader import DataLoader\n\ndata = torch.load(args.data)\nargs.max_len = data[""max_word_len""]\nargs.vocab_size = data[\'dict\'][\'src_size\']\nargs.pre_w2v = data[\'pre_w2v\']\nargs.idx2word = {v: k for k, v in data[\'dict\'][\'src\'].items()}\n\ntraining_data = DataLoader(data[\'train\'],\n                           args.max_len, args.batch_size, cuda=use_cuda)\n\nargs.n_warmup_steps = args.n_warmup_steps if args.n_warmup_steps != 0 else training_data._stop_step\n\n# ##############################################################################\n# Build model\n# ##############################################################################\nimport model\nfrom optim import ScheduledOptim\n\nvae = model.VAE(args)\nif use_cuda:\n    vae = vae.cuda()\n\ncriterion = torch.nn.CrossEntropyLoss()\n\noptimizer = ScheduledOptim(\n    torch.optim.Adam(vae.parameters(), betas=(0.9, 0.98), eps=1e-09),\n    args.embed_dim, args.n_warmup_steps, vae.parameters(), args.clip)\n\n# ##############################################################################\n# Training\n# ##############################################################################\nimport time\nfrom tqdm import tqdm\n\ntrain_loss = []\n\n\ndef repackage_hidden(h):\n    if type(h) == Variable:\n        return Variable(h.data)\n    else:\n        return tuple(repackage_hidden(v) for v in h)\n\n\ndef train():\n    vae.train()\n    total_loss = 0.\n    enc_hidden = vae.encode.init_hidden(args.batch_size)\n    dec_hidden = vae.decode.init_hidden(args.batch_size)\n    for enc_input, dec_input, label in tqdm(training_data, mininterval=1,\n                                            desc=\'Generator Train Processing\', leave=False):\n        optimizer.zero_grad()\n        enc_hidden = repackage_hidden(enc_hidden)\n        dec_hidden = repackage_hidden(dec_hidden)\n\n        target, latent_loss, enc_hidden, dec_hidden = vae(\n            enc_input, dec_input, enc_hidden, dec_hidden)\n        loss = criterion(target, label.contiguous().view(-1)) + latent_loss\n\n        loss.backward()\n        optimizer.clip_grad_norm()\n        optimizer.step()\n\n        total_loss += loss.data\n\n    return total_loss[0] / training_data.sents_size\n\n\n# ##############################################################################\n# Save Model\n# ##############################################################################\nbest_acc = None\ntotal_start_time = time.time()\n\ntry:\n    print(\'-\' * 90)\n    for epoch in range(1, args.epochs + 1):\n        epoch_start_time = time.time()\n        loss = train()\n\n        print(\'| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}\'.format(\n            epoch, time.time() - epoch_start_time, loss))\n        print(\'-\' * 90)\n        vae.eval()\n        for _ in range(10):\n            portry = vae.generate(20)\n            print(""portry generation - [{}]"".format(portry))\n            print(\'-\' * 90)\n\nexcept KeyboardInterrupt:\n    print(""-"" * 90)\n    print(""Exiting from training early | cost time: {:5.2f}min"".format(\n        (time.time() - total_start_time) / 60.0))\n'"
yolo-v3/darknet.py,6,"b'import torch\nimport torch.nn as nn\n\nfrom collections import defaultdict\n\nfrom layer import *\nfrom utils import load_classes\n\nOUT_DIM = 3 * (len(load_classes()) + 5)\n\nDETECT_DICT = {\n    \'first\': [1024, (512, 1, 1, 0), (1024, 3, 1, 1), (512, 1, 1, 0), (1024, 3, 1, 1), (512, 1, 1, 0), (1024, 3, 1, 1), (OUT_DIM, 1, 1, 0, 0)],\n    \'second\': [768, (256, 1, 1, 0), (512, 3, 1, 1), (256, 1, 1, 0), (512, 3, 1, 1), (256, 1, 1, 0), (512, 3, 1, 1), (OUT_DIM, 1, 1, 0, 0)],\n    \'third\': [384, (128, 1, 1, 0), (256, 3, 1, 1), (128, 1, 1, 0), (256, 3, 1, 1), (128, 1, 1, 0), (256, 3, 1, 1), (OUT_DIM, 1, 1, 0, 0)],\n}\n\nLOSS_NAMES = [""x"", ""y"", ""w"", ""h"", ""conf"", ""cls"", ""recall"", ""precision""]\n\n\nclass LayerOne(BasicLayer):\n    def __init__(self):\n        super().__init__((64, 32, 1, 1, 0),\n                         (32, 64, 3, 1, 1), 1)\n\n\nclass LayerTwo(BasicLayer):\n    def __init__(self):\n        super().__init__((128, 64, 1, 1, 0),\n                         (64, 128, 3, 1, 1), 2)\n\n\nclass LayerThree(BasicLayer):\n    def __init__(self):\n        super().__init__((256, 128, 1, 1, 0),\n                         (128, 256, 3, 1, 1), 8)\n\n\nclass LayerFour(BasicLayer):\n    def __init__(self):\n        super().__init__((512, 256, 1, 1, 0),\n                         (256, 512, 3, 1, 1), 8)\n\n\nclass LayerFive(BasicLayer):\n    def __init__(self):\n        super().__init__((1024, 512, 1, 1, 0),\n                         (512, 1024, 3, 1, 1), 4)\n\n\nclass FirstPred(BasicPred):\n    def __init__(self,\n                 structs,\n                 use_cuda,\n                 classes,\n                 route_index=4,\n                 anchors=[(116, 90), (156, 198), (373, 326)]):\n        super().__init__(structs, use_cuda, anchors, classes, route_index=route_index)\n\n\nclass SecondPred(BasicPred):\n    def __init__(self,\n                 structs,\n                 use_cuda,\n                 classes,\n                 route_index=4,\n                 anchors=[(30, 61), (62, 45), (59, 119)]):\n        super().__init__(structs, use_cuda, anchors, classes, route_index=route_index)\n\n\nclass ThirdPred(BasicPred):\n    def __init__(self,\n                 structs,\n                 use_cuda,\n                 classes,\n                 height=416,\n                 anchors=[(10, 13), (16, 30), (33, 23)]):\n        super().__init__(structs, use_cuda, anchors, classes)\n\n\nclass DarkNet(nn.Module):\n    def __init__(self, use_cuda, nClasses):\n        super().__init__()\n\n        self.conv_1 = BasicConv(256, 512, 3, 2, 1)\n\n        self.seq_1 = nn.Sequential(\n            BasicConv(3, 32, 3, 1, 1),\n            BasicConv(32, 64, 3, 2, 1),\n            LayerOne(),\n            BasicConv(64, 128, 3, 2, 1),\n            LayerTwo(),\n            BasicConv(128, 256, 3, 2, 1),\n            LayerThree(),\n        )\n        self.seq_2 = nn.Sequential(\n            BasicConv(512, 1024, 3, 2, 1),\n            LayerFive()\n        )\n\n        self.layer_4 = LayerFour()\n\n        self.uns_1 = nn.Sequential(\n            BasicConv(512, 256, 1, 1, 0),\n            nn.Upsample(scale_factor=2, mode=""bilinear"")\n        )\n        self.uns_2 = nn.Sequential(\n            BasicConv(256, 128, 1, 1, 0),\n            nn.Upsample(scale_factor=2, mode=""bilinear"")\n        )\n\n        self.pred_1 = FirstPred(DETECT_DICT[""first""], use_cuda, nClasses)\n        self.pred_2 = SecondPred(DETECT_DICT[""second""], use_cuda, nClasses)\n        self.pred_3 = ThirdPred(DETECT_DICT[""third""], use_cuda, nClasses)\n\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        for layer in self.modules():\n            if type(layer) == nn.Conv2d:\n                layer.weight.data.normal_(0.0, 0.02)\n\n            if type(layer) == nn.BatchNorm2d:\n                layer.weight.data.normal_(1.0, 0.02)\n                layer.bias.data.fill_(0)\n\n    def forward(self, x, targets=None):\n        gather_losses = defaultdict(float)\n\n        x = self.seq_1(x)\n        r_0 = x\n\n        x = self.layer_4(self.conv_1(x))\n        r_1 = x\n\n        x = self.seq_2(x)\n\n        if targets is not None:\n            (sum_loss, *losses), x = self.pred_1(x, targets)\n            for name, loss in zip(LOSS_NAMES, losses):\n                gather_losses[name] += loss\n        else:\n            det_1, x = self.pred_1(x)\n\n        x = self.uns_1(x)\n        x = torch.cat((x, r_1), 1)\n\n        if targets is not None:\n            (this_loss, *losses), x = self.pred_2(x, targets)\n            sum_loss += this_loss\n            for name, loss in zip(LOSS_NAMES, losses):\n                gather_losses[name] += loss\n        else:\n            det_2, x = self.pred_2(x)\n\n        x = self.uns_2(x)\n        x = torch.cat((x, r_0), 1)\n\n        if targets is not None:\n            this_loss, *losses = self.pred_3(x, targets)\n            sum_loss += this_loss\n            for name, loss in zip(LOSS_NAMES, losses):\n                gather_losses[name] += loss\n            gather_losses[""recall""] /= 3\n            gather_losses[""precision""] /= 3\n\n            return sum_loss, gather_losses\n        else:\n            det_3 = self.pred_3(x)\n            return torch.cat((det_1, det_2, det_3), 1)\n\n\nif __name__ == ""__main__"":\n    model_source = torch.load(""yolo.v3.coco.weights.pt.old"")\n    model = DarkNet(False)\n    model.load_state_dict(model_source[\'model\'])\n\n    par1 = model.seq_2.state_dict()\n\n    model.seq_2 = nn.Sequential(\n        BasicConv(512, 1024, 3, 2, 1),\n        LayerFive()\n    )\n    model.pred_1 = FirstPred(DETECT_DICT[""first""], False)\n\n    new_sp = dict(model.seq_2.state_dict())\n    new_pp = dict(model.pred_1.state_dict())\n\n    for name, params in par1.items():\n        if name[0] == ""2"":\n            new_pp[name[2:]].data.copy_(params.data)\n        else:\n            new_sp[name].data.copy_(params.data)\n\n    model.pred_1.load_state_dict(new_pp, False)\n    model.seq_2.load_state_dict(new_sp, False)\n\n    model_source[\'model\'] = model.state_dict()\n    torch.save(model_source, ""yolo.v3.coco.weights.pt"")\n'"
yolo-v3/detect.py,2,"b'import argparse\n\nimport torch\n\nfrom darknet import DarkNet\nfrom img_loader import IMGProcess\n\nparser = argparse.ArgumentParser(description=\'YOLO-v3 Detect\')\nparser.add_argument(""--images"", type=str, default=\'imgs\')\nparser.add_argument(""--result"", type=str, default=""result"")\nparser.add_argument(\'--batch_size\', type=int, default=100)\nparser.add_argument(\'--img_size\', type=int, default=416)\nparser.add_argument(\'--confidence\', type=float, default=0.5)\nparser.add_argument(\'--nms_thresh\', type=float, default=0.4)\nparser.add_argument(""--weights"", type=str, default=""yolo.v3.coco.weights.pt"")\nparser.add_argument(\'--no_cuda\', action=\'store_true\')\n\n\ndef main():\n    args = parser.parse_args()\n    use_cuda = torch.cuda.is_available() and not args.no_cuda\n\n    model_source = torch.load(args.weights)\n    model = DarkNet(use_cuda,model_source[""num_classes""])\n    model.load_state_dict(model_source[\'model\'])\n    model.eval()\n    if use_cuda:\n        model = model.cuda()\n\n    ip = IMGProcess(model_source,\n                    use_cuda=use_cuda,\n                    img_path=args.images,\n                    img_size=args.img_size,\n                    confidence=args.confidence,\n                    result=args.result)\n\n    print(""-"" * 57 + ""Result"" + ""-"" * 57)\n    for batch in ip:\n        outputs = ip.predict(model(batch), nms_conf=args.nms_thresh)\n        for name, objs in outputs:\n            print(""Image - {}"".format(name))\n            print(""Detect Objects - [{}]"".format("", "".join(objs)))\n            print(""-"" * 120)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
yolo-v3/img_loader.py,14,"b'import os\nimport random\nimport zipfile\n\nimport torch\nfrom torchvision import transforms as T\nfrom PIL import Image, ImageDraw, ImageFont\nimport numpy as np\nfrom skimage.transform import resize\n\nfrom utils import bbox_iou\n\n\nclass IMGProcess(object):\n    def __init__(self, source,\n                 use_cuda=True,\n                 img_path=""imgs"",\n                 batch_size=100,\n                 img_size=416,\n                 confidence=0.5,\n                 rebuild=True,\n                 result=""result""):\n\n        self.colors = source[""pallete""]\n        self.num_classes = source[""num_classes""]\n        self.classes = source[""classes""]\n        self.confidence = confidence\n        self.rebuild = rebuild\n        self.result = result\n        self.use_cuda = use_cuda\n        self.img_size = img_size\n        self.font = ImageFont.truetype(""arial.ttf"", 15)\n        self.imgs = [os.path.join(img_path, img)\n                     for img in os.listdir(img_path)]\n        self.sents_size = len(self.imgs)\n        self.bsz = min(batch_size, len(self.imgs))\n        self._step = 0\n        self._stop_step = self.sents_size // self.bsz\n\n    def _encode(self, x):\n        encode = T.Compose([T.Resize((self.img_size, self.img_size)),\n                            T.ToTensor()])\n\n        return encode(x)\n\n    def img2Var(self, imgs):\n        self.imgs = imgs = [Image.open(img).convert(\'RGB\') for img in imgs]\n        imgs_dim = torch.FloatTensor([img.size for img in imgs]).repeat(1, 2)\n\n        with torch.no_grad():\n            tensors = [self._encode(img).unsqueeze(0) for img in imgs]\n            vs = torch.cat(tensors, 0)\n            if self.use_cuda:\n                vs = vs.cuda()\n                imgs_dim = imgs_dim.cuda()\n\n        return vs, imgs_dim\n\n    def predict(self, prediction, nms_conf=0.4):\n        """"""\n        prediction:\n            0:3 - x, y, h, w\n            4 - confidence\n            5: - class score\n        """"""\n\n        conf_mask = (prediction[:, :, 4] >\n                     self.confidence).float().unsqueeze(2)\n        prediction = prediction * conf_mask\n\n        box_corner = prediction.new(*prediction.size())\n        box_corner[:, :, 0] = (prediction[:, :, 0] - prediction[:, :, 2] / 2)\n        box_corner[:, :, 1] = (prediction[:, :, 1] - prediction[:, :, 3] / 2)\n        box_corner[:, :, 2] = (prediction[:, :, 0] + prediction[:, :, 2] / 2)\n        box_corner[:, :, 3] = (prediction[:, :, 1] + prediction[:, :, 3] / 2)\n        prediction[:, :, :4] = box_corner[:, :, :4]\n\n        outputs = []\n\n        for index, image_pred in enumerate(prediction):\n            max_score, max_index = torch.max(\n                image_pred[:, 5:], 1, keepdim=True)\n            image_pred = torch.cat(\n                (image_pred[:, :5], max_score, max_index.float()), 1)  # [10647, 7]\n\n            non_zero_ind = (torch.nonzero(image_pred[:, 4])).view(-1)\n\n            if non_zero_ind.size(0) == 0:\n                continue\n\n            image_pred_ = image_pred[non_zero_ind, :]\n            img_classes = torch.unique(image_pred_[:, -1])\n\n            objects, img_preds = [], []\n            name = self.this_img_names[index].split(""/"")[-1]\n\n            for c in img_classes:\n                image_pred_class = image_pred_[image_pred_[:, -1] == c]\n\n                _, conf_sort_index = torch.sort(\n                    image_pred_class[:, 4], descending=True)\n                image_pred_class = image_pred_class[conf_sort_index]\n\n                max_detections = []\n                while image_pred_class.size(0):\n                    max_detections.append(image_pred_class[0].unsqueeze(0))\n                    if len(image_pred_class) == 1:\n                        break\n                    ious = bbox_iou(max_detections[-1], image_pred_class[1:])\n                    image_pred_class = image_pred_class[1:][ious < nms_conf]\n                img_preds.append(torch.cat(max_detections))\n                objects += [self.classes[int(x.squeeze()[-1])]\n                            for x in max_detections]\n\n            outputs.append((name, objects))\n            img_preds = torch.cat(img_preds, dim=0)\n\n            if self.rebuild:\n                self.tensor2img(img_preds, index, name)\n\n        return outputs\n\n    def tensor2img(self, tensor, index, name):\n        imgs_dim = self.imgs_dim[index] / self.img_size\n        img = self.imgs[index]\n        draw = ImageDraw.Draw(img)\n\n        tensor[:, :4] = tensor[:, :4].clamp_(0, self.img_size) * imgs_dim\n        for t in tensor:\n            s_x, s_y, e_x, e_y = list(map(int, t[:4]))\n            label = self.classes[int(t[-1])]\n            color = random.choice(self.colors)\n            draw.rectangle([s_x, s_y, e_x, e_y], outline=color)\n            draw.text([s_x, s_y], label, fill=color, font=self.font)\n\n        del draw\n\n        img.save(os.path.join(self.result, ""res_{}"".format(name)))\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._step == self._stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        _s = self._step * self.bsz\n        self._step += 1\n\n        self.this_img_names = self.imgs[_s:_s + self.bsz]\n\n        vs, self.imgs_dim = self.img2Var(self.this_img_names)\n\n        return vs\n\n\nclass Data_loader(object):\n    def __init__(self, label, path,\n                 img_size=416,\n                 max_objects=50,\n                 batch_size=16,\n                 is_cuda=True):\n\n        self.datas = self._parse_label(label)\n        self.max_objects = max_objects\n        self.path = path\n        self.img_size = img_size\n        self.encode = T.Compose(\n            [T.Resize((img_size, img_size)), T.ToTensor()])\n        self.bsz = batch_size\n        self.stop_step = len(self.datas) // batch_size + 1\n        self._step = 0\n        self.is_cuda = is_cuda\n\n    def _parse_label(self, label):\n        datas = []\n        for f in os.listdir(label):\n            img_name = f.replace(\'.txt\', \'.jpg\')\n            obj = []\n            for line in open(os.path.join(label, f)):\n                points = line.strip().split()\n                obj.append([float(p) for p in points])\n            datas.append([img_name, obj])\n\n        return datas\n\n    def _parse(self, data):\n        img, obj = data\n        img = os.path.join(self.path, img)\n        img = np.array(Image.open(img).convert(\'RGB\'))\n        h, w, _ = img.shape\n        dim_diff = np.abs(h - w)\n        pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2\n        pad = ((pad1, pad2), (0, 0), (0, 0)) if h <= w else (\n            (0, 0), (pad1, pad2), (0, 0))\n        input_img = np.pad(img, pad, \'constant\', constant_values=128) / 255.\n        padded_h, padded_w, _ = input_img.shape\n        input_img = resize(\n            input_img, (self.img_size, self.img_size, 3), mode=\'reflect\')\n        input_img = np.transpose(input_img, (2, 0, 1))\n        input_img = torch.from_numpy(input_img).float()\n\n        obj = np.asarray(obj)\n\n        x1 = w * (obj[:, 1] - obj[:, 3] / 2)\n        y1 = h * (obj[:, 2] - obj[:, 4] / 2)\n        x2 = w * (obj[:, 1] + obj[:, 3] / 2)\n        y2 = h * (obj[:, 2] + obj[:, 4] / 2)\n\n        x1 += pad[1][0]\n        y1 += pad[0][0]\n        x2 += pad[1][0]\n        y2 += pad[0][0]\n\n        obj[:, 1] = ((x1 + x2) / 2) / padded_w\n        obj[:, 2] = ((y1 + y2) / 2) / padded_h\n        obj[:, 3] *= w / padded_w\n        obj[:, 4] *= h / padded_h\n\n        filled_labels = np.zeros((self.max_objects, 5))\n        filled_labels[range(len(obj))[:self.max_objects]\n                      ] = obj[:self.max_objects]\n        filled_labels = torch.from_numpy(filled_labels).float()\n\n        return input_img, filled_labels\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._step == self.stop_step:\n            self._step = 0\n            raise StopIteration()\n\n        start = self._step * self.bsz\n        self._step += 1\n\n        bsz = min(self.bsz, len(self.datas) - start)\n\n        imgs, labels = [], []\n        for data in self.datas[start:start + bsz]:\n            input_img, filled_labels = self._parse(data)\n            imgs.append(input_img)\n            labels.append(filled_labels)\n\n        imgs = torch.stack(imgs, dim=0)\n        labels = torch.stack(labels, dim=0)\n\n        if self.is_cuda:\n            imgs, labels = imgs.cuda(), labels.cuda()\n\n        return imgs, labels\n\n\nif __name__ == ""__main__"":\n    d = Data_loader(""data/labels/val2014/"", ""data/val2014"")\n    imgs, labels = next(d)\n    print(imgs.shape)\n    print(labels.shape)\n'"
yolo-v3/layer.py,37,"b'import math\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\nfrom utils import bbox_iou\n\n\nclass BasicConv(nn.Module):\n    def __init__(self, ind, outd, kr_size, stride, padding, lr=0.1, bias=False):\n        super().__init__()\n\n        self.layers = nn.Sequential(\n            nn.Conv2d(ind, outd, kr_size, stride, padding, bias=bias),\n            nn.BatchNorm2d(outd),\n            nn.LeakyReLU(lr)\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\n\nclass BasicLayer(nn.Module):\n    def __init__(self, conv_1, conv_2, times):\n        super().__init__()\n\n        self.layers = nn.ModuleList()\n        for _ in range(times):\n            self.layers.append(BasicConv(*conv_1))\n            self.layers.append(BasicConv(*conv_2))\n\n    def forward(self, x):\n        residual = x\n        for index, layer in enumerate(self.layers):\n            x = layer(x)\n            if index % 2 == 1:\n                x += residual\n                residual = x\n\n        return x\n\n\nclass BasicPred(nn.Module):\n    def __init__(self,\n                 structs,\n                 use_cuda,\n                 anchors,\n                 classes,\n                 height=416,\n                 route_index=0):\n        super().__init__()\n\n        self.ri = route_index\n        self.classes = classes\n        self.height = height\n        self.anchors = anchors\n        self.torch = torch.cuda if use_cuda else torch\n\n        # for train\n        self.mse_loss = nn.MSELoss()  # Coordinate loss\n        self.bce_loss = nn.BCELoss()  # Confidence loss\n        self.ce_loss = nn.CrossEntropyLoss()  # Class loss\n\n        in_dim = structs[0]\n        self.layers = nn.ModuleList()\n        for s in structs[1:]:\n            if len(s) == 4:\n                out_dim, kr_size, stride, padding = s\n                layer = BasicConv(in_dim, out_dim, kr_size, stride, padding)\n            else:\n                out_dim, kr_size, stride, padding, _ = s\n                layer = nn.Conv2d(in_dim, out_dim, kr_size, stride, padding)\n\n            in_dim = out_dim\n            self.layers.append(layer)\n\n    def forward(self, x, targets=None):\n        for index, layer in enumerate(self.layers):\n            x = layer(x)\n            if self.ri != 0 and index == self.ri:\n                output = x\n\n        detections = self.predict_transform(x, targets)\n\n        if self.ri != 0:\n            return detections, output\n        else:\n            return detections\n\n    def predict_transform(self, inp, targets):\n        """"""\n        Code originally from https://github.com/eriklindernoren/PyTorch-YOLOv3.\n        """"""\n        def build_targets(pred_boxes, pred_conf, pred_cls, target, anchors, num_anchors, num_classes, grid_size, ignore_thres, img_dim):\n            """"""\n            target - [bsz, max_obj, 5]\n            """"""\n            nB = target.size(0)\n            nA = num_anchors\n            nC = num_classes\n            nG = grid_size\n            mask = torch.zeros(nB, nA, nG, nG)\n            conf_mask = torch.ones(nB, nA, nG, nG)\n            tx = torch.zeros(nB, nA, nG, nG)\n            ty = torch.zeros(nB, nA, nG, nG)\n            tw = torch.zeros(nB, nA, nG, nG)\n            th = torch.zeros(nB, nA, nG, nG)\n            tconf = torch.ByteTensor(nB, nA, nG, nG).fill_(0)\n            tcls = torch.ByteTensor(nB, nA, nG, nG, nC).fill_(0)\n\n            nGT = 0\n            nCorrect = 0\n            for b in range(nB):\n                for t in range(target.shape[1]):\n                    if target[b, t].sum() == 0:\n                        # pad\n                        continue\n                    nGT += 1\n                    # Convert to position relative to box\n                    gx = target[b, t, 1] * nG\n                    gy = target[b, t, 2] * nG\n                    gw = target[b, t, 3] * nG\n                    gh = target[b, t, 4] * nG\n                    # Get grid box indices\n                    gi = int(gx)\n                    gj = int(gy)\n                    # Get shape of gt box\n                    gt_box = torch.FloatTensor(\n                        np.array([0, 0, gw, gh])).unsqueeze(0)\n                    # Get shape of anchor box\n                    anchor_shapes = torch.FloatTensor(np.concatenate(\n                        (np.zeros((len(anchors), 2)), np.array(anchors)), 1))\n\n                    # Calculate iou between gt and anchor shapes\n                    # 1 on 3\n                    anch_ious = bbox_iou(gt_box, anchor_shapes)\n                    # Where the overlap is larger than threshold set mask to zero (ignore)\n                    conf_mask[b, anch_ious > ignore_thres, gj, gi] = 0\n                    # Find the best matching anchor box\n\n                    best_n = np.argmax(anch_ious)\n                    # Get ground truth box\n                    gt_box = torch.FloatTensor(\n                        np.array([gx, gy, gw, gh])).unsqueeze(0)\n                    # Get the best prediction\n                    pred_box = pred_boxes[b, best_n, gj, gi].unsqueeze(0)\n                    # Masks\n                    mask[b, best_n, gj, gi] = 1\n                    conf_mask[b, best_n, gj, gi] = 1\n                    # Coordinates\n                    tx[b, best_n, gj, gi] = gx - gi\n                    ty[b, best_n, gj, gi] = gy - gj\n                    # Width and height\n                    tw[b, best_n, gj, gi] = math.log(\n                        gw / anchors[best_n][0] + 1e-16)\n                    th[b, best_n, gj, gi] = math.log(\n                        gh / anchors[best_n][1] + 1e-16)\n                    # One-hot encoding of label\n                    target_label = int(target[b, t, 0])\n                    tcls[b, best_n, gj, gi, target_label] = 1\n                    tconf[b, best_n, gj, gi] = 1\n\n                    # Calculate iou between ground truth and best matching prediction\n                    iou = bbox_iou(gt_box, pred_box, x1y1x2y2=False)\n                    pred_label = torch.argmax(pred_cls[b, best_n, gj, gi])\n                    score = pred_conf[b, best_n, gj, gi]\n                    if iou > 0.5 and pred_label == target_label and score > 0.5:\n                        nCorrect += 1\n\n            return nGT, nCorrect, mask, conf_mask, tx, ty, tw, th, tconf, tcls\n\n        # inp.shape - [bsz, 3*(num_classes+5), 13|26|52, 13|26|52]\n        bsz = inp.size(0)\n        grid_size = inp.size(2)\n        stride = self.height // grid_size\n        bbox_attrs = 5 + self.classes\n        num_anchors = len(self.anchors)\n\n        prediction = inp.view(bsz, num_anchors, bbox_attrs, grid_size,\n                              grid_size).permute(0, 1, 3, 4, 2).contiguous()\n\n        anchors = self.torch.FloatTensor(\n            [(a[0] / stride, a[1] / stride) for a in self.anchors])\n\n        x = torch.sigmoid(prediction[..., 0])\n        y = torch.sigmoid(prediction[..., 1])\n        w = prediction[..., 2]\n        h = prediction[..., 3]\n        pred_conf = torch.sigmoid(prediction[..., 4])\n        pred_cls = torch.sigmoid(prediction[..., 5:])\n\n        grid_x = torch.arange(grid_size).repeat(grid_size, 1).view(\n            [1, 1, grid_size, grid_size]).type(self.torch.FloatTensor)\n        grid_y = torch.arange(grid_size).repeat(grid_size, 1).t().view(\n            [1, 1, grid_size, grid_size]).type(self.torch.FloatTensor)\n\n        anchor_w = anchors[:, 0].view((1, num_anchors, 1, 1))\n        anchor_h = anchors[:, 1].view((1, num_anchors, 1, 1))\n\n        pred_boxes = self.torch.FloatTensor(prediction[..., :4].shape)\n        pred_boxes[..., 0] = x.data + grid_x\n        pred_boxes[..., 1] = y.data + grid_y\n        pred_boxes[..., 2] = torch.exp(w.data) * anchor_w\n        pred_boxes[..., 3] = torch.exp(h.data) * anchor_h\n\n        if targets is not None:\n\n            nGT, nCorrect, mask, conf_mask, tx, ty, tw, th, tconf, tcls = build_targets(\n                pred_boxes=pred_boxes.cpu().data,\n                pred_conf=pred_conf.cpu().data,\n                pred_cls=pred_cls.cpu().data,\n                target=targets.cpu().data,\n                anchors=anchors.cpu().data,\n                num_anchors=num_anchors,\n                num_classes=self.classes,\n                grid_size=grid_size,\n                ignore_thres=0.5,\n                img_dim=self.height)\n\n            nProposals = int((pred_conf > 0.5).sum().item())\n            recall = float(nCorrect / nGT) if nGT else 1\n            precision = float(nCorrect / nProposals)\n\n            # Handle masks\n            mask = mask.type(self.torch.ByteTensor)\n            conf_mask = conf_mask.type(self.torch.ByteTensor)\n\n            # Handle target variables\n            with torch.no_grad():\n                tx = tx.type(self.torch.FloatTensor)\n                ty = ty.type(self.torch.FloatTensor)\n                tw = tw.type(self.torch.FloatTensor)\n                th = th.type(self.torch.FloatTensor)\n                tconf = tconf.type(self.torch.FloatTensor)\n                tcls = tcls.type(self.torch.LongTensor)\n\n            # Get conf mask where gt and where there is no gt\n            conf_mask_true = mask\n            conf_mask_false = conf_mask - mask\n\n            # Mask outputs to ignore non-existing objects\n            loss_x = self.mse_loss(x[mask], tx[mask])\n            loss_y = self.mse_loss(y[mask], ty[mask])\n            loss_w = self.mse_loss(w[mask], tw[mask])\n            loss_h = self.mse_loss(h[mask], th[mask])\n            loss_conf = self.bce_loss(pred_conf[conf_mask_false], tconf[conf_mask_false]) + self.bce_loss(\n                pred_conf[conf_mask_true], tconf[conf_mask_true]\n            )\n            loss_cls = self.ce_loss(\n                pred_cls[mask], torch.argmax(tcls[mask], 1))\n            loss = loss_x + loss_y + loss_w + loss_h + loss_conf + loss_cls\n\n            return (\n                loss,\n                loss_x.item(),\n                loss_y.item(),\n                loss_w.item(),\n                loss_h.item(),\n                loss_conf.item(),\n                loss_cls.item(),\n                recall,\n                precision,\n            )\n\n        else:\n            output = torch.cat(\n                (\n                    pred_boxes.view(bsz, -1, 4) * stride,\n                    pred_conf.view(bsz, -1, 1),\n                    pred_cls.view(bsz, -1, self.classes),\n                ),\n                -1,\n            )\n            return output\n'"
yolo-v3/train.py,5,"b'import argparse\nimport os\n\nimport torch\nimport torch.optim as optim\nimport numpy as np\n\nfrom darknet import DarkNet\nfrom img_loader import Data_loader\n\nfrom utils import load_classes, predict, evaluate\n\nparser = argparse.ArgumentParser(description=\'YOLO-v3 Train\')\nparser.add_argument(""--epoch"", type=int, default=30)\nparser.add_argument(""--batch_size"", type=int, default=16)\nparser.add_argument(\'--img_size\', type=int, default=416)\nparser.add_argument(\'--no_cuda\', action=\'store_true\')\nparser.add_argument(\'--max_objects\', type=int, default=50)\nparser.add_argument(""--confidence"", type=float, default=0.5)\nparser.add_argument(""--nms_conf"", type=float, default=0.45)\n\n\ndef train(folder=""weights""):\n    os.makedirs(folder, exist_ok=True)\n\n    args = parser.parse_args()\n    use_cuda = torch.cuda.is_available() and not args.no_cuda\n\n    classes = load_classes()\n    num_classes = len(classes)\n\n    model = DarkNet(use_cuda, num_classes)\n    if use_cuda:\n        model = model.cuda()\n    optimizer = torch.optim.Adam(model.parameters())\n\n    training_data = Data_loader(\n        ""data/labels/train2014/"",\n        ""data/train2014"",\n        img_size=args.img_size,\n        max_objects=args.max_objects,\n        batch_size=args.batch_size,\n        is_cuda=use_cuda)\n\n    validation_data = Data_loader(\n        ""data/labels/val2014/"",\n        ""data/val2014"",\n        img_size=args.img_size,\n        max_objects=args.max_objects,\n        batch_size=args.batch_size,\n        is_cuda=use_cuda)\n\n    for epoch in range(args.epoch):\n\n        model.train()\n        for batch_i, (imgs, labels) in enumerate(training_data):\n            optimizer.zero_grad()\n            loss, gather_losses = model(imgs, labels)\n            loss.backward()\n            optimizer.step()\n\n            print(f""""""[Epoch {epoch+1}/{args.epoch},Batch {batch_i+1}/{training_data.stop_step}] [Losses: x {gather_losses[""x""]:.5f}, y {gather_losses[""y""]:.5f}, w {gather_losses[""w""]:.5f}, h { gather_losses[""h""]:.5f}, conf {gather_losses[""conf""]:.5f}, cls {gather_losses[""cls""]:.5f}, total {loss.item():.5f}, recall: {gather_losses[""recall""]:.5f}, precision: {gather_losses[""precision""]:.5f}]"""""")\n\n        torch.save({""model"": model.state_dict(),\n                    ""classes"": classes}, f""{folder}/{epoch}.weights.pt"")\n\n        all_detections = []\n        all_annotations = []\n\n        model.eval()\n        for imgs, labels in validation_data:\n            with torch.no_grad():\n                prediction = model(imgs)\n                outputs = predict(prediction, args.nms_conf, args.confidence)\n\n            labels = labels.cpu()\n            for output, annotations in zip(outputs, labels):\n                all_detections.append([np.array([])\n                                       for _ in range(num_classes)])\n                if output is not None:\n                    pred_boxes = output[:, :5].cpu().numpy()\n                    scores = output[:, 4].cpu().numpy()\n                    pred_labels = output[:, -1].cpu().numpy()\n\n                    sort_i = np.argsort(scores)\n                    pred_labels = pred_labels[sort_i]\n                    pred_boxes = pred_boxes[sort_i]\n\n                    for label in range(num_classes):\n                        all_detections[-1][label] = pred_boxes[pred_labels == label]\n\n                all_annotations.append([np.array([])\n                                        for _ in range(num_classes)])\n\n                if any(annotations[:, -1] > 0):\n                    annotation_labels = annotations[annotations[:, -1]\n                                                    > 0, 0].numpy()\n                    _annotation_boxes = annotations[annotations[:, -1] > 0, 1:]\n\n                    annotation_boxes = np.empty_like(_annotation_boxes)\n                    annotation_boxes[:, 0] = _annotation_boxes[:,\n                                                               0] - _annotation_boxes[:, 2] / 2\n                    annotation_boxes[:, 1] = _annotation_boxes[:,\n                                                               1] - _annotation_boxes[:, 3] / 2\n                    annotation_boxes[:, 2] = _annotation_boxes[:,\n                                                               0] + _annotation_boxes[:, 2] / 2\n                    annotation_boxes[:, 3] = _annotation_boxes[:,\n                                                               1] + _annotation_boxes[:, 3] / 2\n                    annotation_boxes *= args.img_size\n\n                    for label in range(num_classes):\n                        all_annotations[-1][label] = annotation_boxes[annotation_labels == label, :]\n\n        average_precisions = evaluate(\n            num_classes, all_detections, all_annotations)\n\n        print(f""""""{""-""*40}evaluation.{epoch}{""-""*40}"""""")\n        for c, ap in average_precisions.items():\n            print(f""Class \'{c}\' - AP: {ap}"")\n\n        mAP = np.mean(list(average_precisions.values()))\n        print(f""mAP: {mAP}"")\n        print(f""""""{""-""*40}end{""-""*40}"""""")\n\n\nif __name__ == ""__main__"":\n    train()\n'"
yolo-v3/utils.py,13,"b'import torch\nimport numpy as np\n\n\ndef load_classes(inp=""data/coco.names""):\n    return [c.strip() for c in open(inp)]\n\n\ndef compute_ap(recall, precision):\n    """""" Compute the average precision, given the recall and precision curves.\n    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n\n    # Arguments\n        recall:    The recall curve (list).\n        precision: The precision curve (list).\n    # Returns\n        The average precision as computed in py-faster-rcnn.\n    """"""\n    # correct AP calculation\n    # first append sentinel values at the end\n    mrec = np.concatenate(([0.0], recall, [1.0]))\n    mpre = np.concatenate(([0.0], precision, [0.0]))\n\n    # compute the precision envelope\n    for i in range(mpre.size - 1, 0, -1):\n        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n\n    # to calculate area under PR curve, look for points\n    # where X axis (recall) changes value\n    i = np.where(mrec[1:] != mrec[:-1])[0]\n\n    # and sum (\\Delta recall) * prec\n    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n    return ap\n\n\ndef bbox_iou(box1, box2, x1y1x2y2=True):\n    if not x1y1x2y2:\n        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n    else:\n        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,\n                                          0], box1[:, 1], box1[:, 2], box1[:, 3]\n        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,\n                                          0], box2[:, 1], box2[:, 2], box2[:, 3]\n\n    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n\n    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * \\\n        torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n\n    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n\n    iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n\n    return iou\n\n\ndef bbox_iou_numpy(box1, box2):\n    area = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n\n    iw = np.minimum(np.expand_dims(box1[:, 2], axis=1), box2[:, 2]) - np.maximum(\n        np.expand_dims(box1[:, 0], 1), box2[:, 0]\n    )\n    ih = np.minimum(np.expand_dims(box1[:, 3], axis=1), box2[:, 3]) - np.maximum(\n        np.expand_dims(box1[:, 1], 1), box2[:, 1]\n    )\n\n    iw = np.maximum(iw, 0)\n    ih = np.maximum(ih, 0)\n\n    ua = np.expand_dims((box1[:, 2] - box1[:, 0]) *\n                        (box1[:, 3] - box1[:, 1]), axis=1) + area - iw * ih\n\n    ua = np.maximum(ua, np.finfo(float).eps)\n\n    intersection = iw * ih\n\n    return intersection / ua\n\n\ndef predict(prediction, nms_conf=0.4, confidence=0.5):\n    conf_mask = (prediction[:, :, 4] > confidence).float().unsqueeze(2)\n    prediction = prediction * conf_mask\n\n    box_corner = prediction.new(*prediction.size())\n    box_corner[:, :, 0] = (prediction[:, :, 0] - prediction[:, :, 2] / 2)\n    box_corner[:, :, 1] = (prediction[:, :, 1] - prediction[:, :, 3] / 2)\n    box_corner[:, :, 2] = (prediction[:, :, 0] + prediction[:, :, 2] / 2)\n    box_corner[:, :, 3] = (prediction[:, :, 1] + prediction[:, :, 3] / 2)\n    prediction[:, :, :4] = box_corner[:, :, :4]\n\n    output = [None for _ in range(len(prediction))]\n    for index, image_pred in enumerate(prediction):\n        max_score, max_index = torch.max(\n            image_pred[:, 5:], 1, keepdim=True)\n        image_pred = torch.cat(\n            (image_pred[:, :5], max_score, max_index.float()), 1)  # [10647, 7]\n\n        non_zero_ind = (torch.nonzero(image_pred[:, 4])).view(-1)\n\n        if non_zero_ind.size(0) == 0:\n            continue\n\n        image_pred_ = image_pred[non_zero_ind, :]\n        img_classes = torch.unique(image_pred_[:, -1])\n\n        img_preds = []\n\n        for c in img_classes:\n            image_pred_class = image_pred_[image_pred_[:, -1] == c]\n\n            _, conf_sort_index = torch.sort(\n                image_pred_class[:, 4], descending=True)\n            image_pred_class = image_pred_class[conf_sort_index]\n\n            max_detections = []\n            while image_pred_class.size(0):\n                max_detections.append(image_pred_class[0].unsqueeze(0))\n                if len(image_pred_class) == 1:\n                    break\n                ious = bbox_iou(max_detections[-1], image_pred_class[1:])\n                image_pred_class = image_pred_class[1:][ious < nms_conf]\n            max_detections = torch.cat(max_detections).data\n            output[index] = (max_detections if output[index] is None else torch.cat(\n                (output[index], max_detections)))\n\n    return output\n\n\ndef evaluate(num_classes, all_detections, all_annotations, iou_thres=.5):\n    """"""\n    Code originally from https://github.com/eriklindernoren/PyTorch-YOLOv3.\n    """"""\n\n    average_precisions = {}\n    for label in range(num_classes):\n        true_positives = []\n        scores = []\n        num_annotations = 0\n\n        for i in range(len(all_annotations)):\n            detections = all_detections[i][label]\n            annotations = all_annotations[i][label]\n\n            num_annotations += annotations.shape[0]\n            detected_annotations = []\n\n            for *bbox, score in detections:\n                scores.append(score)\n\n                if annotations.shape[0] == 0:\n                    true_positives.append(0)\n                    continue\n\n                overlaps = bbox_iou_numpy(\n                    np.expand_dims(bbox, axis=0), annotations)\n                assigned_annotation = np.argmax(overlaps, axis=1)\n                max_overlap = overlaps[0, assigned_annotation]\n\n                if max_overlap >= iou_thres and assigned_annotation not in detected_annotations:\n                    true_positives.append(1)\n                    detected_annotations.append(assigned_annotation)\n                else:\n                    true_positives.append(0)\n\n        if num_annotations == 0:\n            average_precisions[label] = 0\n            continue\n\n        true_positives = np.array(true_positives)\n        false_positives = np.ones_like(true_positives) - true_positives\n\n        indices = np.argsort(-np.array(scores))\n        false_positives = false_positives[indices]\n        true_positives = true_positives[indices]\n\n        false_positives = np.cumsum(false_positives)\n        true_positives = np.cumsum(true_positives)\n\n        recall = true_positives / num_annotations\n        precision = true_positives / \\\n            np.maximum(true_positives + false_positives,\n                       np.finfo(np.float64).eps)\n\n        average_precision = compute_ap(recall, precision)\n        average_precisions[label] = average_precision\n\n    return average_precisions\n\n\nif __name__ == ""__main__"":\n    print(load_classes())\n'"
