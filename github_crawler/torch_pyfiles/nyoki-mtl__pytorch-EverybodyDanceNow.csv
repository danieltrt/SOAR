file_path,api_count,code
src/utils/openpose_utils.py,0,"b""import numpy as np\nimport math\nimport cv2\nfrom skimage import filters\nfrom scipy import ndimage\n\n# openpose\nimport sys\nsys.path.append('../pytorch_Realtime_Multi-Person_Pose_Estimation')\n\nfrom network.post import *\n\ndef remove_noise(img):\n    th = filters.threshold_otsu(img)\n    bin_img = img > th\n    regions, num = ndimage.label(bin_img)\n    areas = []\n    for i in range(num):\n        areas.append(np.sum(regions == i+1))\n    img[regions != np.argmax(areas)+1] = 0\n    return img\n\n\ndef create_label(shape, joint_list, person_to_joint_assoc):\n    label = np.zeros(shape, dtype=np.uint8)\n    for limb_type in range(17):\n        for person_joint_info in person_to_joint_assoc:\n            joint_indices = person_joint_info[joint_to_limb_heatmap_relationship[limb_type]].astype(int)\n            if -1 in joint_indices:\n                continue\n            joint_coords = joint_list[joint_indices, :2]\n            coords_center = tuple(np.round(np.mean(joint_coords, 0)).astype(int))\n            limb_dir = joint_coords[0, :] - joint_coords[1, :]\n            limb_length = np.linalg.norm(limb_dir)\n            angle = math.degrees(math.atan2(limb_dir[1], limb_dir[0]))\n            polygon = cv2.ellipse2Poly(coords_center, (int(limb_length / 2), 4), int(angle), 0, 360, 1)\n            cv2.fillConvexPoly(label, polygon, limb_type+1)\n    return label\n\n\ndef get_pose(param, heatmaps, pafs):\n    shape = heatmaps.shape[:2]\n    # Bottom-up approach:\n    # Step 1: find all joints in the image (organized by joint type: [0]=nose,\n    # [1]=neck...)\n    joint_list_per_joint_type = NMS(param, heatmaps)\n    # joint_list is an unravel'd version of joint_list_per_joint, where we add\n    # a 5th column to indicate the joint_type (0=nose, 1=neck...)\n    joint_list = np.array([tuple(peak) + (joint_type,) for joint_type,\n                           joint_peaks in enumerate(joint_list_per_joint_type) for peak in joint_peaks])\n\n    # Step 2: find which joints go together to form limbs (which wrists go\n    # with which elbows)\n    paf_upsamp = cv2.resize(pafs, shape, interpolation=cv2.INTER_CUBIC)\n    connected_limbs = find_connected_joints(param, paf_upsamp, joint_list_per_joint_type)\n\n    # Step 3: associate limbs that belong to the same person\n    person_to_joint_assoc = group_limbs_of_same_person(connected_limbs, joint_list)\n\n    # (Step 4): plot results\n    label = create_label(shape, joint_list, person_to_joint_assoc)\n\n    return label\n"""
src/utils/save_img.py,0,"b""import numpy as np\nimport cv2\n\ndef main():\n    vc = cv2.VideoCapture(0)\n    if vc.isOpened():\n        is_capturing, _ = vc.read()\n    else:\n        is_capturing = False\n\n    cnt = 0\n    while is_capturing:\n        is_capturing, img = vc.read()\n        # img = img[:, 80:80+480]\n        cv2.imwrite(f'../../data/target/images/img_{cnt:04d}.png', img)\n        cv2.imshow('video', img)\n        k = cv2.waitKey(30) & 0xff\n        if k == 27: # press 'ESC' to quit\n            break\n        cnt += 1\n    vc.release()\n    cv2.destroyAllWindows()\n\nmain()\n"""
