file_path,api_count,code
src/__init__.py,0,b''
src/omniglot_dataset.py,2,"b'# coding=utf-8\nfrom __future__ import print_function\nimport torch.utils.data as data\nfrom PIL import Image\nimport numpy as np\nimport shutil\nimport errno\nimport torch\nimport os\n\n\'\'\'\nInspired by https://github.com/pytorch/vision/pull/46\n\'\'\'\n\nIMG_CACHE = {}\n\n\nclass OmniglotDataset(data.Dataset):\n    vinalys_baseurl = \'https://raw.githubusercontent.com/jakesnell/prototypical-networks/master/data/omniglot/splits/vinyals/\'\n    vinyals_split_sizes = {\n        \'test\': vinalys_baseurl + \'test.txt\',\n        \'train\': vinalys_baseurl + \'train.txt\',\n        \'trainval\': vinalys_baseurl + \'trainval.txt\',\n        \'val\': vinalys_baseurl + \'val.txt\',\n    }\n\n    urls = [\n        \'https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip\',\n        \'https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip\'\n    ]\n    splits_folder = os.path.join(\'splits\', \'vinyals\')\n    raw_folder = \'raw\'\n    processed_folder = \'data\'\n\n    def __init__(self, mode=\'train\', root=\'..\' + os.sep + \'dataset\', transform=None, target_transform=None, download=True):\n        \'\'\'\n        The items are (filename,category). The index of all the categories can be found in self.idx_classes\n        Args:\n        - root: the directory where the dataset will be stored\n        - transform: how to transform the input\n        - target_transform: how to transform the target\n        - download: need to download the dataset\n        \'\'\'\n        super(OmniglotDataset, self).__init__()\n        self.root = root\n        self.transform = transform\n        self.target_transform = target_transform\n\n        if download:\n            self.download()\n\n        if not self._check_exists():\n            raise RuntimeError(\n                \'Dataset not found. You can use download=True to download it\')\n        self.classes = get_current_classes(os.path.join(\n            self.root, self.splits_folder, mode + \'.txt\'))\n        self.all_items = find_items(os.path.join(\n            self.root, self.processed_folder), self.classes)\n\n        self.idx_classes = index_classes(self.all_items)\n\n        paths, self.y = zip(*[self.get_path_label(pl)\n                              for pl in range(len(self))])\n\n        self.x = map(load_img, paths, range(len(paths)))\n        self.x = list(self.x)\n\n    def __getitem__(self, idx):\n        x = self.x[idx]\n        if self.transform:\n            x = self.transform(x)\n        return x, self.y[idx]\n\n    def __len__(self):\n        return len(self.all_items)\n\n    def get_path_label(self, index):\n        filename = self.all_items[index][0]\n        rot = self.all_items[index][-1]\n        img = str.join(os.sep, [self.all_items[index][2], filename]) + rot\n        target = self.idx_classes[self.all_items[index]\n                                  [1] + self.all_items[index][-1]]\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target\n\n    def _check_exists(self):\n        return os.path.exists(os.path.join(self.root, self.processed_folder))\n\n    def download(self):\n        from six.moves import urllib\n        import zipfile\n\n        if self._check_exists():\n            return\n\n        try:\n            os.makedirs(os.path.join(self.root, self.splits_folder))\n            os.makedirs(os.path.join(self.root, self.raw_folder))\n            os.makedirs(os.path.join(self.root, self.processed_folder))\n        except OSError as e:\n            if e.errno == errno.EEXIST:\n                pass\n            else:\n                raise\n\n        for k, url in self.vinyals_split_sizes.items():\n            print(\'== Downloading \' + url)\n            data = urllib.request.urlopen(url)\n            filename = url.rpartition(os.sep)[-1]\n            file_path = os.path.join(self.root, self.splits_folder, filename)\n            with open(file_path, \'wb\') as f:\n                f.write(data.read())\n\n        for url in self.urls:\n            print(\'== Downloading \' + url)\n            data = urllib.request.urlopen(url)\n            filename = url.rpartition(os.sep)[2]\n            file_path = os.path.join(self.root, self.raw_folder, filename)\n            with open(file_path, \'wb\') as f:\n                f.write(data.read())\n            orig_root = os.path.join(self.root, self.raw_folder)\n            print(""== Unzip from "" + file_path + "" to "" + orig_root)\n            zip_ref = zipfile.ZipFile(file_path, \'r\')\n            zip_ref.extractall(orig_root)\n            zip_ref.close()\n        file_processed = os.path.join(self.root, self.processed_folder)\n        for p in [\'images_background\', \'images_evaluation\']:\n            for f in os.listdir(os.path.join(orig_root, p)):\n                shutil.move(os.path.join(orig_root, p, f), file_processed)\n            os.rmdir(os.path.join(orig_root, p))\n        print(""Download finished."")\n\n\ndef find_items(root_dir, classes):\n    retour = []\n    rots = [os.sep + \'rot000\', os.sep + \'rot090\', os.sep + \'rot180\', os.sep + \'rot270\']\n    for (root, dirs, files) in os.walk(root_dir):\n        for f in files:\n            r = root.split(os.sep)\n            lr = len(r)\n            label = r[lr - 2] + os.sep + r[lr - 1]\n            for rot in rots:\n                if label + rot in classes and (f.endswith(""png"")):\n                    retour.extend([(f, label, root, rot)])\n    print(""== Dataset: Found %d items "" % len(retour))\n    return retour\n\n\ndef index_classes(items):\n    idx = {}\n    for i in items:\n        if (not i[1] + i[-1] in idx):\n            idx[i[1] + i[-1]] = len(idx)\n    print(""== Dataset: Found %d classes"" % len(idx))\n    return idx\n\n\ndef get_current_classes(fname):\n    with open(fname) as f:\n        classes = f.read().replace(\'/\', os.sep).splitlines()\n    return classes\n\n\ndef load_img(path, idx):\n    path, rot = path.split(os.sep + \'rot\')\n    if path in IMG_CACHE:\n        x = IMG_CACHE[path]\n    else:\n        x = Image.open(path)\n        IMG_CACHE[path] = x\n    x = x.rotate(float(rot))\n    x = x.resize((28, 28))\n\n    shape = 1, x.size[0], x.size[1]\n    x = np.array(x, np.float32, copy=False)\n    x = 1.0 - torch.from_numpy(x)\n    x = x.transpose(0, 1).contiguous().view(shape)\n\n    return x\n'"
src/parser_util.py,0,"b""# coding=utf-8\nimport os\nimport argparse\n\n\ndef get_parser():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-root', '--dataset_root',\n                        type=str,\n                        help='path to dataset',\n                        default='..' + os.sep + 'dataset')\n\n    parser.add_argument('-exp', '--experiment_root',\n                        type=str,\n                        help='root where to store models, losses and accuracies',\n                        default='..' + os.sep + 'output')\n\n    parser.add_argument('-nep', '--epochs',\n                        type=int,\n                        help='number of epochs to train for',\n                        default=100)\n\n    parser.add_argument('-lr', '--learning_rate',\n                        type=float,\n                        help='learning rate for the model, default=0.001',\n                        default=0.001)\n\n    parser.add_argument('-lrS', '--lr_scheduler_step',\n                        type=int,\n                        help='StepLR learning rate scheduler step, default=20',\n                        default=20)\n\n    parser.add_argument('-lrG', '--lr_scheduler_gamma',\n                        type=float,\n                        help='StepLR learning rate scheduler gamma, default=0.5',\n                        default=0.5)\n\n    parser.add_argument('-its', '--iterations',\n                        type=int,\n                        help='number of episodes per epoch, default=100',\n                        default=100)\n\n    parser.add_argument('-cTr', '--classes_per_it_tr',\n                        type=int,\n                        help='number of random classes per episode for training, default=60',\n                        default=60)\n\n    parser.add_argument('-nsTr', '--num_support_tr',\n                        type=int,\n                        help='number of samples per class to use as support for training, default=5',\n                        default=5)\n\n    parser.add_argument('-nqTr', '--num_query_tr',\n                        type=int,\n                        help='number of samples per class to use as query for training, default=5',\n                        default=5)\n\n    parser.add_argument('-cVa', '--classes_per_it_val',\n                        type=int,\n                        help='number of random classes per episode for validation, default=5',\n                        default=5)\n\n    parser.add_argument('-nsVa', '--num_support_val',\n                        type=int,\n                        help='number of samples per class to use as support for validation, default=5',\n                        default=5)\n\n    parser.add_argument('-nqVa', '--num_query_val',\n                        type=int,\n                        help='number of samples per class to use as query for validation, default=15',\n                        default=15)\n\n    parser.add_argument('-seed', '--manual_seed',\n                        type=int,\n                        help='input for the manual seeds initializations',\n                        default=7)\n\n    parser.add_argument('--cuda',\n                        action='store_true',\n                        help='enables cuda')\n\n    return parser\n"""
src/protonet.py,1,"b""import torch.nn as nn\n\n\ndef conv_block(in_channels, out_channels):\n    '''\n    returns a block conv-bn-relu-pool\n    '''\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n\n\nclass ProtoNet(nn.Module):\n    '''\n    Model as described in the reference paper,\n    source: https://github.com/jakesnell/prototypical-networks/blob/f0c48808e496989d01db59f86d4449d7aee9ab0c/protonets/models/few_shot.py#L62-L84\n    '''\n    def __init__(self, x_dim=1, hid_dim=64, z_dim=64):\n        super(ProtoNet, self).__init__()\n        self.encoder = nn.Sequential(\n            conv_block(x_dim, hid_dim),\n            conv_block(hid_dim, hid_dim),\n            conv_block(hid_dim, hid_dim),\n            conv_block(hid_dim, z_dim),\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        return x.view(x.size(0), -1)\n"""
src/prototypical_batch_sampler.py,9,"b""# coding=utf-8\nimport numpy as np\nimport torch\n\n\nclass PrototypicalBatchSampler(object):\n    '''\n    PrototypicalBatchSampler: yield a batch of indexes at each iteration.\n    Indexes are calculated by keeping in account 'classes_per_it' and 'num_samples',\n    In fact at every iteration the batch indexes will refer to  'num_support' + 'num_query' samples\n    for 'classes_per_it' random classes.\n\n    __len__ returns the number of episodes per epoch (same as 'self.iterations').\n    '''\n\n    def __init__(self, labels, classes_per_it, num_samples, iterations):\n        '''\n        Initialize the PrototypicalBatchSampler object\n        Args:\n        - labels: an iterable containing all the labels for the current dataset\n        samples indexes will be infered from this iterable.\n        - classes_per_it: number of random classes for each iteration\n        - num_samples: number of samples for each iteration for each class (support + query)\n        - iterations: number of iterations (episodes) per epoch\n        '''\n        super(PrototypicalBatchSampler, self).__init__()\n        self.labels = labels\n        self.classes_per_it = classes_per_it\n        self.sample_per_class = num_samples\n        self.iterations = iterations\n\n        self.classes, self.counts = np.unique(self.labels, return_counts=True)\n        self.classes = torch.LongTensor(self.classes)\n\n        # create a matrix, indexes, of dim: classes X max(elements per class)\n        # fill it with nans\n        # for every class c, fill the relative row with the indices samples belonging to c\n        # in numel_per_class we store the number of samples for each class/row\n        self.idxs = range(len(self.labels))\n        self.indexes = np.empty((len(self.classes), max(self.counts)), dtype=int) * np.nan\n        self.indexes = torch.Tensor(self.indexes)\n        self.numel_per_class = torch.zeros_like(self.classes)\n        for idx, label in enumerate(self.labels):\n            label_idx = np.argwhere(self.classes == label).item()\n            self.indexes[label_idx, np.where(np.isnan(self.indexes[label_idx]))[0][0]] = idx\n            self.numel_per_class[label_idx] += 1\n\n    def __iter__(self):\n        '''\n        yield a batch of indexes\n        '''\n        spc = self.sample_per_class\n        cpi = self.classes_per_it\n\n        for it in range(self.iterations):\n            batch_size = spc * cpi\n            batch = torch.LongTensor(batch_size)\n            c_idxs = torch.randperm(len(self.classes))[:cpi]\n            for i, c in enumerate(self.classes[c_idxs]):\n                s = slice(i * spc, (i + 1) * spc)\n                # FIXME when torch.argwhere will exists\n                label_idx = torch.arange(len(self.classes)).long()[self.classes == c].item()\n                sample_idxs = torch.randperm(self.numel_per_class[label_idx])[:spc]\n                batch[s] = self.indexes[label_idx][sample_idxs]\n            batch = batch[torch.randperm(len(batch))]\n            yield batch\n\n    def __len__(self):\n        '''\n        returns the number of iterations (episodes) per epoch\n        '''\n        return self.iterations\n"""
src/prototypical_loss.py,8,"b""# coding=utf-8\nimport torch\nfrom torch.nn import functional as F\nfrom torch.nn.modules import Module\n\n\nclass PrototypicalLoss(Module):\n    '''\n    Loss class deriving from Module for the prototypical loss function defined below\n    '''\n    def __init__(self, n_support):\n        super(PrototypicalLoss, self).__init__()\n        self.n_support = n_support\n\n    def forward(self, input, target):\n        return prototypical_loss(input, target, self.n_support)\n\n\ndef euclidean_dist(x, y):\n    '''\n    Compute euclidean distance between two tensors\n    '''\n    # x: N x D\n    # y: M x D\n    n = x.size(0)\n    m = y.size(0)\n    d = x.size(1)\n    if d != y.size(1):\n        raise Exception\n\n    x = x.unsqueeze(1).expand(n, m, d)\n    y = y.unsqueeze(0).expand(n, m, d)\n\n    return torch.pow(x - y, 2).sum(2)\n\n\ndef prototypical_loss(input, target, n_support):\n    '''\n    Inspired by https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n\n    Compute the barycentres by averaging the features of n_support\n    samples for each class in target, computes then the distances from each\n    samples' features to each one of the barycentres, computes the\n    log_probability for each n_query samples for each one of the current\n    classes, of appartaining to a class c, loss and accuracy are then computed\n    and returned\n    Args:\n    - input: the model output for a batch of samples\n    - target: ground truth for the above batch of samples\n    - n_support: number of samples to keep in account when computing\n      barycentres, for each one of the current classes\n    '''\n    target_cpu = target.to('cpu')\n    input_cpu = input.to('cpu')\n\n    def supp_idxs(c):\n        # FIXME when torch will support where as np\n        return target_cpu.eq(c).nonzero()[:n_support].squeeze(1)\n\n    # FIXME when torch.unique will be available on cuda too\n    classes = torch.unique(target_cpu)\n    n_classes = len(classes)\n    # FIXME when torch will support where as np\n    # assuming n_query, n_target constants\n    n_query = target_cpu.eq(classes[0].item()).sum().item() - n_support\n\n    support_idxs = list(map(supp_idxs, classes))\n\n    prototypes = torch.stack([input_cpu[idx_list].mean(0) for idx_list in support_idxs])\n    # FIXME when torch will support where as np\n    query_idxs = torch.stack(list(map(lambda c: target_cpu.eq(c).nonzero()[n_support:], classes))).view(-1)\n\n    query_samples = input.to('cpu')[query_idxs]\n    dists = euclidean_dist(query_samples, prototypes)\n\n    log_p_y = F.log_softmax(-dists, dim=1).view(n_classes, n_query, -1)\n\n    target_inds = torch.arange(0, n_classes)\n    target_inds = target_inds.view(n_classes, 1, 1)\n    target_inds = target_inds.expand(n_classes, n_query, 1).long()\n\n    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n    _, y_hat = log_p_y.max(2)\n    acc_val = y_hat.eq(target_inds.squeeze()).float().mean()\n\n    return loss_val,  acc_val\n"""
src/train.py,14,"b'# coding=utf-8\nfrom prototypical_batch_sampler import PrototypicalBatchSampler\nfrom prototypical_loss import prototypical_loss as loss_fn\nfrom omniglot_dataset import OmniglotDataset\nfrom protonet import ProtoNet\nfrom parser_util import get_parser\n\nfrom tqdm import tqdm\nimport numpy as np\nimport torch\nimport os\n\n\ndef init_seed(opt):\n    \'\'\'\n    Disable cudnn to maximize reproducibility\n    \'\'\'\n    torch.cuda.cudnn_enabled = False\n    np.random.seed(opt.manual_seed)\n    torch.manual_seed(opt.manual_seed)\n    torch.cuda.manual_seed(opt.manual_seed)\n\n\ndef init_dataset(opt, mode):\n    dataset = OmniglotDataset(mode=mode, root=opt.dataset_root)\n    n_classes = len(np.unique(dataset.y))\n    if n_classes < opt.classes_per_it_tr or n_classes < opt.classes_per_it_val:\n        raise(Exception(\'There are not enough classes in the dataset in order \' +\n                        \'to satisfy the chosen classes_per_it. Decrease the \' +\n                        \'classes_per_it_{tr/val} option and try again.\'))\n    return dataset\n\n\ndef init_sampler(opt, labels, mode):\n    if \'train\' in mode:\n        classes_per_it = opt.classes_per_it_tr\n        num_samples = opt.num_support_tr + opt.num_query_tr\n    else:\n        classes_per_it = opt.classes_per_it_val\n        num_samples = opt.num_support_val + opt.num_query_val\n\n    return PrototypicalBatchSampler(labels=labels,\n                                    classes_per_it=classes_per_it,\n                                    num_samples=num_samples,\n                                    iterations=opt.iterations)\n\n\ndef init_dataloader(opt, mode):\n    dataset = init_dataset(opt, mode)\n    sampler = init_sampler(opt, dataset.y, mode)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_sampler=sampler)\n    return dataloader\n\n\ndef init_protonet(opt):\n    \'\'\'\n    Initialize the ProtoNet\n    \'\'\'\n    device = \'cuda:0\' if torch.cuda.is_available() and opt.cuda else \'cpu\'\n    model = ProtoNet().to(device)\n    return model\n\n\ndef init_optim(opt, model):\n    \'\'\'\n    Initialize optimizer\n    \'\'\'\n    return torch.optim.Adam(params=model.parameters(),\n                            lr=opt.learning_rate)\n\n\ndef init_lr_scheduler(opt, optim):\n    \'\'\'\n    Initialize the learning rate scheduler\n    \'\'\'\n    return torch.optim.lr_scheduler.StepLR(optimizer=optim,\n                                           gamma=opt.lr_scheduler_gamma,\n                                           step_size=opt.lr_scheduler_step)\n\n\ndef save_list_to_file(path, thelist):\n    with open(path, \'w\') as f:\n        for item in thelist:\n            f.write(""%s\\n"" % item)\n\n\ndef train(opt, tr_dataloader, model, optim, lr_scheduler, val_dataloader=None):\n    \'\'\'\n    Train the model with the prototypical learning algorithm\n    \'\'\'\n\n    device = \'cuda:0\' if torch.cuda.is_available() and opt.cuda else \'cpu\'\n\n    if val_dataloader is None:\n        best_state = None\n    train_loss = []\n    train_acc = []\n    val_loss = []\n    val_acc = []\n    best_acc = 0\n\n    best_model_path = os.path.join(opt.experiment_root, \'best_model.pth\')\n    last_model_path = os.path.join(opt.experiment_root, \'last_model.pth\')\n\n    for epoch in range(opt.epochs):\n        print(\'=== Epoch: {} ===\'.format(epoch))\n        tr_iter = iter(tr_dataloader)\n        model.train()\n        for batch in tqdm(tr_iter):\n            optim.zero_grad()\n            x, y = batch\n            x, y = x.to(device), y.to(device)\n            model_output = model(x)\n            loss, acc = loss_fn(model_output, target=y,\n                                n_support=opt.num_support_tr)\n            loss.backward()\n            optim.step()\n            train_loss.append(loss.item())\n            train_acc.append(acc.item())\n        avg_loss = np.mean(train_loss[-opt.iterations:])\n        avg_acc = np.mean(train_acc[-opt.iterations:])\n        print(\'Avg Train Loss: {}, Avg Train Acc: {}\'.format(avg_loss, avg_acc))\n        lr_scheduler.step()\n        if val_dataloader is None:\n            continue\n        val_iter = iter(val_dataloader)\n        model.eval()\n        for batch in val_iter:\n            x, y = batch\n            x, y = x.to(device), y.to(device)\n            model_output = model(x)\n            loss, acc = loss_fn(model_output, target=y,\n                                n_support=opt.num_support_val)\n            val_loss.append(loss.item())\n            val_acc.append(acc.item())\n        avg_loss = np.mean(val_loss[-opt.iterations:])\n        avg_acc = np.mean(val_acc[-opt.iterations:])\n        postfix = \' (Best)\' if avg_acc >= best_acc else \' (Best: {})\'.format(\n            best_acc)\n        print(\'Avg Val Loss: {}, Avg Val Acc: {}{}\'.format(\n            avg_loss, avg_acc, postfix))\n        if avg_acc >= best_acc:\n            torch.save(model.state_dict(), best_model_path)\n            best_acc = avg_acc\n            best_state = model.state_dict()\n\n    torch.save(model.state_dict(), last_model_path)\n\n    for name in [\'train_loss\', \'train_acc\', \'val_loss\', \'val_acc\']:\n        save_list_to_file(os.path.join(opt.experiment_root,\n                                       name + \'.txt\'), locals()[name])\n\n    return best_state, best_acc, train_loss, train_acc, val_loss, val_acc\n\n\ndef test(opt, test_dataloader, model):\n    \'\'\'\n    Test the model trained with the prototypical learning algorithm\n    \'\'\'\n    device = \'cuda:0\' if torch.cuda.is_available() and opt.cuda else \'cpu\'\n    avg_acc = list()\n    for epoch in range(10):\n        test_iter = iter(test_dataloader)\n        for batch in test_iter:\n            x, y = batch\n            x, y = x.to(device), y.to(device)\n            model_output = model(x)\n            _, acc = loss_fn(model_output, target=y,\n                             n_support=opt.num_support_val)\n            avg_acc.append(acc.item())\n    avg_acc = np.mean(avg_acc)\n    print(\'Test Acc: {}\'.format(avg_acc))\n\n    return avg_acc\n\n\ndef eval(opt):\n    \'\'\'\n    Initialize everything and train\n    \'\'\'\n    options = get_parser().parse_args()\n\n    if torch.cuda.is_available() and not options.cuda:\n        print(""WARNING: You have a CUDA device, so you should probably run with --cuda"")\n\n    init_seed(options)\n    test_dataloader = init_dataset(options)[-1]\n    model = init_protonet(options)\n    model_path = os.path.join(opt.experiment_root, \'best_model.pth\')\n    model.load_state_dict(torch.load(model_path))\n\n    test(opt=options,\n         test_dataloader=test_dataloader,\n         model=model)\n\n\ndef main():\n    \'\'\'\n    Initialize everything and train\n    \'\'\'\n    options = get_parser().parse_args()\n    if not os.path.exists(options.experiment_root):\n        os.makedirs(options.experiment_root)\n\n    if torch.cuda.is_available() and not options.cuda:\n        print(""WARNING: You have a CUDA device, so you should probably run with --cuda"")\n\n    init_seed(options)\n\n    tr_dataloader = init_dataloader(options, \'train\')\n    val_dataloader = init_dataloader(options, \'val\')\n    # trainval_dataloader = init_dataloader(options, \'trainval\')\n    test_dataloader = init_dataloader(options, \'test\')\n\n    model = init_protonet(options)\n    optim = init_optim(options, model)\n    lr_scheduler = init_lr_scheduler(options, optim)\n    res = train(opt=options,\n                tr_dataloader=tr_dataloader,\n                val_dataloader=val_dataloader,\n                model=model,\n                optim=optim,\n                lr_scheduler=lr_scheduler)\n    best_state, best_acc, train_loss, train_acc, val_loss, val_acc = res\n    print(\'Testing with last model..\')\n    test(opt=options,\n         test_dataloader=test_dataloader,\n         model=model)\n\n    model.load_state_dict(best_state)\n    print(\'Testing with best model..\')\n    test(opt=options,\n         test_dataloader=test_dataloader,\n         model=model)\n\n    # optim = init_optim(options, model)\n    # lr_scheduler = init_lr_scheduler(options, optim)\n\n    # print(\'Training on train+val set..\')\n    # train(opt=options,\n    #       tr_dataloader=trainval_dataloader,\n    #       val_dataloader=None,\n    #       model=model,\n    #       optim=optim,\n    #       lr_scheduler=lr_scheduler)\n\n    # print(\'Testing final model..\')\n    # test(opt=options,\n    #      test_dataloader=test_dataloader,\n    #      model=model)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
