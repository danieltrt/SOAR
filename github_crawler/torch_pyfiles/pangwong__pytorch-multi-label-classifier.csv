file_path,api_count,code
deploy.py,3,"b'import os\nimport sys\nimport json\nimport logging\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torchvision import transforms\nfrom collections import OrderedDict, defaultdict\n\nfrom options.options import Options\nfrom models.model import load_model\nfrom data.transformer import  get_transformer, load_image\nfrom util.util import load_label, opt2file\nfrom util.webvisualizer import WebVisualizer\n\ndef main():\n    # parse options \n    op = Options()\n    opt = op.parse()\n\n    # special setting\n    opt.shuffle = False\n    opt.batch_size = 1\n    opt.load_thread = 1\n\n    # initialize train or test working dir\n    test_dir = os.path.join(opt.classify_dir , opt.name)\n    opt.model_dir = opt.dir + ""/trainer_"" + opt.name + ""/Train/""\n    if not os.path.exists(test_dir):\n        os.mkdir(test_dir)\n\n    # save options to disk\n    opt2file(opt, os.path.join(test_dir, ""opt.txt""))\n    \n    # log setting \n    log_format = \'%(asctime)s - %(name)s - %(levelname)s - %(message)s\'\n    formatter = logging.Formatter(log_format)\n    fh = logging.FileHandler(test_dir + ""/deploy.log"", \'a\')\n    fh.setFormatter(formatter)\n    ch = logging.StreamHandler()\n    ch.setFormatter(formatter)\n    logging.getLogger().addHandler(fh)\n    logging.getLogger().addHandler(ch)\n    logging.getLogger().setLevel(logging.INFO)\n    \n    # load label  \n    if opt.label_file == """":\n        opt.label_file = opt.dir + ""/label.txt""\n    rid2name, id2rid, rid2id = load_label(opt.label_file)\n    num_classes = [len(rid2name[index])-2 for index in range(len(rid2name))]\n        \n    # load transformer\n    transformer = get_transformer(opt) \n\n    # load model\n    model = load_model(opt, num_classes)\n    model.eval()\n    \n    # use cuda\n    if opt.cuda:\n        model = model.cuda(opt.devices[0])\n        cudnn.benchmark = True\n    \n    l = open(test_dir + ""/classify_res_data.txt"", \'w\')\n    with open(opt.classify_dir + ""/data.txt"") as data:\n        for num, line in enumerate(data):\n            logging.info(str(num+1))\n            line = json.loads(line)\n            input_tensor = load_image(line[""image_file""], line[""box""], opt, transformer) \n            input_tensor = input_tensor.unsqueeze(0)\n            if opt.cuda:\n                input_tensor = input_tensor.cuda(opt.devices[0])\n            outputs = model(Variable(input_tensor, volatile=True)) \n            if not isinstance(outputs, list):\n                outputs = [outputs]\n            line[""classify_res""] = list() \n            for index, out in enumerate(outputs):\n                out = out.cpu()\n                #print ""out:"", out\n                softmax = F.softmax(out, dim=1).data.squeeze()\n                #print ""softmax:"", softmax \n                probs, ids = softmax.sort(0, True)\n                classify_res = {}\n                for i in range(len(probs)):\n                    classify_res[rid2name[index][id2rid[index][ids[i]]]] = probs[i]\n                classify_res[""max_score""] = probs[0]\n                classify_res[""best_label""] = rid2name[index][id2rid[index][ids[0]]]\n                line[""classify_res""].append(classify_res)\n            l.write(json.dumps(line, separators=(\',\', \':\'))+\'\\n\')\n    l.close()\n    logging.info(""classification done"")\n\n\nif __name__ == ""__main__"":\n    main()\n'"
multi_label_classifier.py,6,"b'import os\nimport sys\nimport time\nimport copy\nimport random\nimport logging\nimport numpy as np\nimport torch\nprint ""Pytorch Version: "", torch.__version__\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\nfrom collections import OrderedDict, defaultdict\n\nfrom data.loader import MultiLabelDataLoader\nfrom models.model import load_model, save_model, modify_last_layer_lr\nfrom options.options import Options\nfrom util import util \nfrom util.webvisualizer import WebVisualizer\n\n\ndef forward_batch(model, criterion, inputs, targets, opt, phase):\n    if opt.cuda:\n        inputs = inputs.cuda(opt.devices[0], async=True)\n\n    if phase in [""Train""]:\n        inputs_var = Variable(inputs, requires_grad=True)\n        #logging.info(""Switch to Train Mode"")\n        model.train()\n    elif phase in [""Validate"", ""Test""]:\n        inputs_var = Variable(inputs, volatile=True)\n        #logging.info(""Switch to Test Mode"")\n        model.eval()\n        \n    # forward\n    if opt.cuda:\n        if len(opt.devices) > 1:\n            output = nn.parallel.data_parallel(model, inputs_var, opt.devices)\n        else:\n            output = model(inputs_var)\n    else:\n        output = model(inputs_var)\n    \n    # calculate loss \n    target_vars = list()\n    for index in range(len(targets)):\n        if opt.cuda:\n            targets[index] = targets[index].cuda(opt.devices[0], async=True)\n        target_vars.append(Variable(targets[index]))\n    loss_list = list()\n    loss = Variable(torch.FloatTensor(1)).zero_()\n    if opt.cuda:\n        loss = loss.cuda(opt.devices[0])\n    for index in range(len(targets)):\n        sub_loss = criterion(output[index], target_vars[index])\n        loss_list.append(sub_loss.data[0])\n        loss += sub_loss\n    \n    return output, loss, loss_list\n\n\ndef forward_dataset(model, criterion, data_loader, opt):\n    sum_batch = 0 \n    accuracy = list()\n    avg_loss = list()\n    for i, data in enumerate(data_loader):\n        if opt.mode == ""Train"":\n            if random.random() > opt.validate_ratio:\n                continue\n        if opt.mode == ""Test"":\n            logging.info(""test %s/%s image"" %(i, len(data_loader)))\n        sum_batch += 1\n        inputs, targets = data\n        output, loss, loss_list = forward_batch(model, criterion, inputs, targets, opt, ""Validate"")\n        batch_accuracy = calc_accuracy(output, targets, opt.score_thres, opt.top_k)\n        # accumulate accuracy\n        if len(accuracy) == 0:\n            accuracy = copy.deepcopy(batch_accuracy)\n            for index, item in enumerate(batch_accuracy):\n                for k,v in item.iteritems():\n                    accuracy[index][k][""ratio""] = v[""ratio""]\n        else:\n            for index, item in enumerate(batch_accuracy):\n                for k,v in item.iteritems():\n                    accuracy[index][k][""ratio""] += v[""ratio""]\n        # accumulate loss\n        if len(avg_loss) == 0:\n            avg_loss = copy.deepcopy(loss_list) \n        else:\n            for index, loss in enumerate(loss_list):\n                avg_loss[index] += loss\n    # average on batches\n    for index, item in enumerate(accuracy):\n        for k,v in item.iteritems():\n            accuracy[index][k][""ratio""] /= float(sum_batch)\n    for index in range(len(avg_loss)):\n        avg_loss[index] /= float(sum_batch)\n    return accuracy, avg_loss\n\n\ndef calc_accuracy(outputs, targets, score_thres, top_k=(1,)):\n    max_k = max(top_k)\n    accuracy = []\n    thres_list = eval(score_thres)\n    if isinstance(thres_list, float) or isinstance(thres_list, int) :\n        thres_list = [eval(score_thres)]*len(targets)\n\n    for i in range(len(targets)):\n        target = targets[i]\n        output = outputs[i].data\n        batch_size = output.size(0)\n        curr_k = min(max_k, output.size(1))\n        top_value, index = output.cpu().topk(curr_k, 1)\n        index = index.t()\n        top_value = top_value.t()\n        correct = index.eq(target.cpu().view(1,-1).expand_as(index))\n        mask = (top_value>=thres_list[i])\n        correct = correct*mask\n        #print ""masked correct: "", correct\n        res = defaultdict(dict)\n        for k in top_k:\n            k = min(k, output.size(1))\n            correct_k = correct[:k].view(-1).float().sum(0)[0]\n            res[k][""s""] = batch_size\n            res[k][""r""] = correct_k\n            res[k][""ratio""] = float(correct_k)/batch_size\n        accuracy.append(res)\n    return accuracy\n\n\ndef train(model, criterion, train_set, val_set, opt, labels=None):\n    # define web visualizer using visdom\n    webvis = WebVisualizer(opt)\n    \n    # modify learning rate of last layer\n    finetune_params = modify_last_layer_lr(model.named_parameters(), \n                                            opt.lr, opt.lr_mult_w, opt.lr_mult_b)\n    # define optimizer\n    optimizer = optim.SGD(finetune_params, \n                          opt.lr, \n                          momentum=opt.momentum, \n                          weight_decay=opt.weight_decay)\n    # define laerning rate scheluer\n    scheduler = optim.lr_scheduler.StepLR(optimizer, \n                                          step_size=opt.lr_decay_in_epoch,\n                                          gamma=opt.gamma)\n    if labels is not None:\n        rid2name, id2rid = labels\n    \n    # record forward and backward times \n    train_batch_num = len(train_set)\n    total_batch_iter = 0\n    logging.info(""####################Train Model###################"")\n    for epoch in range(opt.sum_epoch):\n        epoch_start_t = time.time()\n        epoch_batch_iter = 0\n        logging.info(\'Begin of epoch %d\' %(epoch))\n        for i, data in enumerate(train_set):\n            iter_start_t = time.time()\n            # train \n            inputs, targets = data\n            output, loss, loss_list = forward_batch(model, criterion, inputs, targets, opt, ""Train"")\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n           \n            webvis.reset()\n            epoch_batch_iter += 1\n            total_batch_iter += 1\n\n            # display train loss and accuracy\n            if total_batch_iter % opt.display_train_freq == 0:\n                # accuracy\n                batch_accuracy = calc_accuracy(output, targets, opt.score_thres, opt.top_k) \n                util.print_loss(loss_list, ""Train"", epoch, total_batch_iter)\n                util.print_accuracy(batch_accuracy, ""Train"", epoch, total_batch_iter)\n                if opt.display_id > 0:\n                    x_axis = epoch + float(epoch_batch_iter)/train_batch_num\n                    # TODO support accuracy visualization of multiple top_k\n                    plot_accuracy = [batch_accuracy[i][opt.top_k[0]] for i in range(len(batch_accuracy)) ]\n                    accuracy_list = [item[""ratio""] for item in plot_accuracy]\n                    webvis.plot_points(x_axis, loss_list, ""Loss"", ""Train"")\n                    webvis.plot_points(x_axis, accuracy_list, ""Accuracy"", ""Train"")\n            \n            # display train data \n            if total_batch_iter % opt.display_data_freq == 0:\n                image_list = list()\n                show_image_num = int(np.ceil(opt.display_image_ratio * inputs.size()[0]))\n                for index in range(show_image_num): \n                    input_im = util.tensor2im(inputs[index], opt.mean, opt.std)\n                    class_label = ""Image_"" + str(index) \n                    if labels is not None:\n                        target_ids = [targets[i][index] for i in range(opt.class_num)]\n                        rids = [id2rid[j][k] for j,k in enumerate(target_ids)]\n                        class_label += ""_""\n                        class_label += ""#"".join([rid2name[j][k] for j,k in enumerate(rids)])\n                    image_list.append((class_label, input_im))\n                image_dict = OrderedDict(image_list)\n                save_result = total_batch_iter % opt.update_html_freq\n                webvis.plot_images(image_dict, opt.display_id + 2*opt.class_num, epoch, save_result)\n            \n            # validate and display validate loss and accuracy\n            if len(val_set) > 0  and total_batch_iter % opt.display_validate_freq == 0:\n                val_accuracy, val_loss = validate(model, criterion, val_set, opt)\n                x_axis = epoch + float(epoch_batch_iter)/train_batch_num\n                accuracy_list = [val_accuracy[i][opt.top_k[0]][""ratio""] for i in range(len(val_accuracy))]\n                util.print_loss(val_loss, ""Validate"", epoch, total_batch_iter)\n                util.print_accuracy(val_accuracy, ""Validate"", epoch, total_batch_iter)\n                if opt.display_id > 0:\n                    webvis.plot_points(x_axis, val_loss, ""Loss"", ""Validate"")\n                    webvis.plot_points(x_axis, accuracy_list, ""Accuracy"", ""Validate"")\n\n            # save snapshot \n            if total_batch_iter % opt.save_batch_iter_freq == 0:\n                logging.info(""saving the latest model (epoch %d, total_batch_iter %d)"" %(epoch, total_batch_iter))\n                save_model(model, opt, epoch)\n                # TODO snapshot loss and accuracy\n            \n        logging.info(\'End of epoch %d / %d \\t Time Taken: %d sec\' %\n              (epoch, opt.sum_epoch, time.time() - epoch_start_t))\n        \n        if epoch % opt.save_epoch_freq == 0:\n            logging.info(\'saving the model at the end of epoch %d, iters %d\' %(epoch+1, total_batch_iter))\n            save_model(model, opt, epoch+1) \n\n        # adjust learning rate \n        scheduler.step()\n        lr = optimizer.param_groups[0][\'lr\'] \n        logging.info(\'learning rate = %.7f epoch = %d\' %(lr,epoch)) \n    logging.info(""--------Optimization Done--------"")\n\n\ndef validate(model, criterion, val_set, opt):\n    return forward_dataset(model, criterion, val_set, opt)\n\n\ndef test(model, criterion, test_set, opt):\n    logging.info(""####################Test Model###################"")\n    test_accuracy, test_loss = forward_dataset(model, criterion, test_set, opt)\n    logging.info(""data_dir:   "" + opt.data_dir + ""/TestSet/"")\n    logging.info(""score_thres:""+  str(opt.score_thres))\n    for index, item in enumerate(test_accuracy):\n        logging.info(""Attribute %d:"" %(index))\n        for top_k, value in item.iteritems():\n            logging.info(""----Accuracy of Top%d: %f"" %(top_k, value[""ratio""])) \n    logging.info(""#################Finished Testing################"")\n\n\ndef main():\n    # parse options \n    op = Options()\n    opt = op.parse()\n\n    # initialize train or test working dir\n    trainer_dir = ""trainer_"" + opt.name\n    opt.model_dir = os.path.join(opt.dir, trainer_dir, ""Train"") \n    opt.data_dir = os.path.join(opt.dir, trainer_dir, ""Data"") \n    opt.test_dir = os.path.join(opt.dir, trainer_dir, ""Test"") \n    \n    if not os.path.exists(opt.data_dir):\n        os.makedirs(opt.data_dir)\n    if opt.mode == ""Train"":\n        if not os.path.exists(opt.model_dir):        \n            os.makedirs(opt.model_dir)\n        log_dir = opt.model_dir \n        log_path = log_dir + ""/train.log""\n    if opt.mode == ""Test"":\n        if not os.path.exists(opt.test_dir):\n            os.makedirs(opt.test_dir)\n        log_dir = opt.test_dir\n        log_path = log_dir + ""/test.log""\n\n    # save options to disk\n    util.opt2file(opt, log_dir+""/opt.txt"")\n    \n    # log setting \n    log_format = \'%(asctime)s - %(name)s - %(levelname)s - %(message)s\'\n    formatter = logging.Formatter(log_format)\n    fh = logging.FileHandler(log_path, \'a\')\n    fh.setFormatter(formatter)\n    ch = logging.StreamHandler()\n    ch.setFormatter(formatter)\n    logging.getLogger().addHandler(fh)\n    logging.getLogger().addHandler(ch)\n    log_level = logging.INFO\n    logging.getLogger().setLevel(log_level)\n    \n    # load train or test data\n    data_loader = MultiLabelDataLoader(opt)\n    if opt.mode == ""Train"":\n        train_set = data_loader.GetTrainSet()\n        val_set = data_loader.GetValSet()\n    elif opt.mode == ""Test"":\n        test_set = data_loader.GetTestSet()\n\n    num_classes = data_loader.GetNumClasses()\n    rid2name = data_loader.GetRID2Name()\n    id2rid = data_loader.GetID2RID()\n    opt.class_num = len(num_classes)\n\n    # load model\n    model = load_model(opt, num_classes)\n\n    # define loss function\n    criterion = nn.CrossEntropyLoss(weight=opt.loss_weight) \n    \n    # use cuda\n    if opt.cuda:\n        model = model.cuda(opt.devices[0])\n        criterion = criterion.cuda(opt.devices[0])\n        cudnn.benchmark = True\n    \n    # Train model\n    if opt.mode == ""Train"":\n        train(model, criterion, train_set, val_set, opt, (rid2name, id2rid))\n    # Test model\n    elif opt.mode == ""Test"":\n        test(model, criterion, test_set, opt)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
data/__init__.py,0,b''
data/dataset.py,1,"b'import os\nimport sys\nimport json\nimport random\nimport logging\nimport torch.utils.data as data\n\nfrom .transformer import get_transformer, load_image\n\nclass BaseDataset(data.Dataset):\n    def __init__(self, opt, data_type, id2rid):\n        super(BaseDataset, self).__init__()\n        self.opt = opt\n        self.data_type = data_type\n        self.dataset = self._load_data(opt.data_dir+ \'/\' + data_type + \'/data.txt\')\n        self.id2rid = id2rid\n        self.data_size = len(self.dataset)\n        self.transformer = get_transformer(opt)\n\n    def __getitem__(self, index):\n        image_file, box, attr_ids = self.dataset[index % self.data_size]\n        \n        input = load_image(image_file, box, self.opt, self.transformer)\n\n        # label\n        labels = list()\n        for index, attr_id in enumerate(attr_ids):\n            labels.append(self.id2rid[index][attr_id])\n\n        return input, labels\n\n    def __len__(self):\n        return self.data_size\n\n    def _load_data(self, data_file):\n        dataset = list()\n        if not os.path.exists(data_file):\n            return dataset\n        with open(data_file) as d:\n            for line in d.readlines():\n                line = json.loads(line)\n                dataset.append(self.readline(line))\n        if self.opt.shuffle:\n            logging.info(""Shuffle %s Data"" %(self.data_type))\n            random.shuffle(dataset)\n        else:\n            logging.info(""Not Shuffle %s Data"" %(self.data_type))\n        return dataset\n    \n    def readline(self, line):\n        data = [None, None, None]\n        if line.has_key(\'image_file\'):\n            data[0] = line[""image_file""]\n        if line.has_key(\'box\'):\n            data[1] = line[""box""]\n        if line.has_key(\'id\'):\n            data[2] = line[""id""]\n        return data\n'"
data/loader.py,1,"b'import os\nimport sys\nimport json\nimport random\nimport logging\nimport collections \nfrom torch.utils.data import DataLoader\n\nfrom dataset import BaseDataset\nsys.path.append(\'../\')\nfrom util.util import rmdir, load_label\n\nclass MultiLabelDataLoader():\n    def __init__(self, opt):\n        self.opt = opt\n        assert os.path.exists(opt.dir + ""/data.txt""), ""No data.txt found in specified dir""\n        assert os.path.exists(opt.dir + ""/label.txt""), ""No label.txt found in specified dir""\n        \n        train_dir = opt.data_dir + ""/TrainSet/""\n        val_dir = opt.data_dir + ""/ValidateSet/""\n        test_dir = opt.data_dir + ""/TestSet/""\n         \n        # split data\n        if not all([os.path.exists(train_dir), os.path.exists(val_dir), os.path.exists(test_dir)]):\n            # rm existing directories\n            rmdir(train_dir)\n            rmdir(val_dir)\n            rmdir(test_dir)\n\n            # split data to Train, Val, Test\n            logging.info(""Split raw data to Train, Val and Test"")\n            ratios = opt.ratio\n            dataset = collections.defaultdict(list)\n            with open(opt.dir + \'/data.txt\') as d:\n                for line in d.readlines():\n                    line = json.loads(line)\n                    # if data has been specified data_type yet, load data as what was specified before\n                    if line.has_key(""type""):\n                        dataset[line[""type""]].append(line)\n                        continue\n                    # specified data_type randomly\n                    rand = random.random()\n                    if rand < ratios[0]:\n                        data_type = ""Train""\n                    elif rand < ratios[0] + ratios[1]:\n                        data_type = ""Validate""\n                    else:\n                        data_type = ""Test""\n                    dataset[data_type].append(line)\n            # write to file\n            self._WriteDataToFile(dataset[""Train""], train_dir)\n            self._WriteDataToFile(dataset[""Validate""], val_dir)\n            self._WriteDataToFile(dataset[""Test""], test_dir)\n        \n        self.rid2name, self.id2rid, self.rid2id = load_label(opt.dir + \'/label.txt\')\n        self.num_classes = [len(item)-2 for item in self.rid2name]\n        \n        # load dataset\n        if opt.mode == ""Train"": \n            logging.info(""Load Train Dataset..."")\n            self.train_set = BaseDataset(self.opt, ""TrainSet"", self.rid2id)\n            logging.info(""Load Validate Dataset..."")\n            self.val_set = BaseDataset(self.opt, ""ValidateSet"", self.rid2id)\n        else:\n            # force batch_size for test to 1\n            self.opt.batch_size = 1\n            self.opt.load_thread = 1\n            logging.info(""Load Test Dataset..."")\n            self.test_set = BaseDataset(self.opt, ""TestSet"", self.rid2id)\n\n    def GetTrainSet(self):\n        if self.opt.mode == ""Train"":\n            return self._DataLoader(self.train_set)\n        else:\n            raise(""Train Set DataLoader NOT implemented in Test Mode"")\n\n    def GetValSet(self):\n        if self.opt.mode == ""Train"":\n            return self._DataLoader(self.val_set)\n        else:\n            raise(""Validation Set DataLoader NOT implemented in Test Mode"")\n\n    def GetTestSet(self):\n        if self.opt.mode == ""Test"":\n            return self._DataLoader(self.test_set)\n        else:\n            raise(""Test Set DataLoader NOT implemented in Train Mode"")\n    \n    def GetNumClasses(self):\n        return self.num_classes\n    \n    def GetRID2Name(self):\n        return self.rid2name\n    \n    def GetID2RID(self):\n        return self.id2rid\n    \n    def GetiRID2ID(self):\n        return self.irid2id\n\n    def _WriteDataToFile(self, src_data, dst_dir):\n        """"""\n            write info of each objects to data.txt as predefined format\n        """"""\n        if not os.path.exists(dst_dir):\n            os.mkdir(dst_dir)\n        with open(dst_dir + ""/data.txt"", \'w\') as d:\n            for line in src_data:\n                d.write(json.dumps(line, separators=(\',\',\':\'))+\'\\n\')\n\n\n    def _DataLoader(self, dataset):\n        """"""\n            create data loder\n        """"""\n        dataloader = DataLoader(\n            dataset,\n            batch_size=self.opt.batch_size,\n            shuffle=self.opt.shuffle,\n            num_workers=int(self.opt.load_thread), \n            pin_memory=self.opt.cuda,\n            drop_last=False)\n        return dataloader\n\n'"
data/transformer.py,0,"b'import copy\nfrom PIL import Image\nfrom torchvision import transforms\n\n\ndef get_transformer(opt):\n    transform_list = []\n    \n    # resize  \n    osize = [opt.load_size, opt.load_size]\n    transform_list.append(transforms.Resize(osize, Image.BICUBIC))\n    \n    # grayscale\n    if opt.input_channel == 1:\n        transform_list.append(transforms.Grayscale())\n\n    # crop\n    if opt.crop == ""RandomCrop"":\n        transform_list.append(transforms.RandomCrop(opt.fineSize))\n    elif opt.crop == ""CenterCrop"":\n        transform_list.append(transforms.CenterCrop(opt.input_size))\n    elif opt.crop == ""FiveCrop"":\n        transform_list.append(transforms.FiveCrop(opt.input_size))\n    elif opt.crop == ""TenCrop"":\n        transform_list.append(transforms.TenCrop(opt.input_size))\n    \n    # flip\n    if opt.mode == ""Train"" and opt.flip:\n        transform_list.append(transforms.RandomHorizontalFlip())\n\n    # to tensor\n    transform_list.append(transforms.ToTensor())\n    \n    # If you make changes here, you should also modified \n    # function `tensor2im` in util/util.py accordingly\n    transform_list.append(transforms.Normalize(opt.mean, opt.std))\n\n    return transforms.Compose(transform_list)\n\ndef fix_box(box, width, height, ratio=-1, scale=1.0):\n    if scale < 0:\n        scale = 1.0\n    box = copy.deepcopy(box)\n    w = box[""w""]\n    h = box[""h""]\n    x = box[""x""] + w / 2\n    y = box[""y""] + h / 2\n    mw = 2 * min(x, width - x)\n    mh = 2 * min(y, height - y)\n    w = max(1, min(int(w * scale), mw))\n    h = max(1, min(int(h * scale), mh))\n    if ratio > 0:\n      if 1.0 * w / h > ratio:\n          h = int(w / ratio)\n          h = min(h, mh)\n          w = int(h * ratio)\n      else:\n          w = int(h * ratio)\n          w = min(w, mw)\n          h = int(w / ratio)\n    box[""x""] = x - w / 2\n    box[""y""] = y - h / 2\n    box[""w""] = w\n    box[""h""] = h\n    return box\n\ndef load_image(image_file, box, opt, transformer):\n    img = Image.open(image_file)\n    if opt.input_channel == 3:\n        img = img.convert(\'RGB\')\n    width, height = img.size\n    # box crop\n    if box is not None and opt.region == True:\n        box = fix_box(box, width, height, opt.box_ratio, opt.box_scale)\n        area = (box[\'x\'], box[\'y\'], box[\'x\']+box[\'w\'], box[\'y\']+box[\'h\'])\n        img = img.crop(area)\n    # transform\n    input = transformer(img)\n    return input\n\n'"
models/__init__.py,0,b''
models/alexnet.py,3,"b'import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nfrom build_model import LoadPretrainedModel\n\n__all__ = [\'AlexNet\', \'alexnet\']\n\n\nmodel_urls = {\n    \'alexnet\': \'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\',\n}\n\n\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=1000):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), 256 * 6 * 6)\n        x = self.classifier(x)\n        return x\n\nclass AlexNetTemplet(nn.Module):\n    def __init__(self, input_channel):\n        super(AlexNetTemplet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(input_channel, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), 256 * 6 * 6)\n        x = self.classifier(x)\n        return x\n\n\ndef alexnet(pretrained=False, **kwargs):\n    r""""""AlexNet model architecture from the\n    `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = AlexNet(**kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'alexnet\']))\n    return model\n\ndef AlexnetTemplet(input_channel, pretrained=False, **kwargs):\n    r""""""AlexNet model architecture from the\n    `""One weird trick..."" <https://arxiv.org/abs/1404.5997>`_ paper.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = AlexNetTemplet(input_channel)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'alexnet\']))\n        model.load_state_dict(model_dict)\n    return model\n'"
models/build_model.py,1,"b'import torch.nn as nn\n\nclass MultiLabelModel(nn.Module):\n    def __init__(self, basemodel, basemodel_output, num_classes):\n        super(MultiLabelModel, self).__init__()\n        self.basemodel = basemodel\n        self.num_classes = num_classes\n        for index, num_class in enumerate(num_classes):\n            setattr(self, ""FullyConnectedLayer_"" + str(index), nn.Linear(basemodel_output, num_class))\n    \n    def forward(self, x):\n        x = self.basemodel.forward(x)\n        outs = list()\n        dir(self)\n        for index, num_class in enumerate(self.num_classes):\n            fun = eval(""self.FullyConnectedLayer_"" + str(index))\n            out = fun(x)\n            outs.append(out)\n        return outs\n\ndef LoadPretrainedModel(model, pretrained_state_dict):\n    model_dict = model.state_dict()\n    union_dict = {k : v for k,v in pretrained_state_dict.iteritems() if k in model_dict}\n    model_dict.update(union_dict)\n    return model_dict\n\ndef BuildMultiLabelModel(basemodel, basemodel_output, num_classes):\n    return MultiLabelModel(basemodel, basemodel_output, num_classes)\n'"
models/lightcnn.py,4,"b'\'\'\'\r\n    implement Light CNN\r\n    @author: Alfred Xiang Wu\r\n    @date: 2017.07.04\r\n\'\'\'\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\n\r\nclass mfm(nn.Module):\r\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, type=1):\r\n        super(mfm, self).__init__()\r\n        self.out_channels = out_channels\r\n        if type == 1:\r\n            self.filter = nn.Conv2d(in_channels, 2*out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\r\n        else:\r\n            self.filter = nn.Linear(in_channels, 2*out_channels)\r\n\r\n    def forward(self, x):\r\n        x = self.filter(x)\r\n        out = torch.split(x, self.out_channels, 1)\r\n        return torch.max(out[0], out[1])\r\n\r\nclass group(nn.Module):\r\n    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\r\n        super(group, self).__init__()\r\n        self.conv_a = mfm(in_channels, in_channels, 1, 1, 0)\r\n        self.conv   = mfm(in_channels, out_channels, kernel_size, stride, padding)\r\n\r\n    def forward(self, x):\r\n        x = self.conv_a(x)\r\n        x = self.conv(x)\r\n        return x\r\n\r\nclass resblock(nn.Module):\r\n    def __init__(self, in_channels, out_channels):\r\n        super(resblock, self).__init__()\r\n        self.conv1 = mfm(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\r\n        self.conv2 = mfm(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\r\n\r\n    def forward(self, x):\r\n        res = x\r\n        out = self.conv1(x)\r\n        out = self.conv2(out)\r\n        out = out + res\r\n        return out\r\n\r\nclass network_9layers(nn.Module):\r\n    def __init__(self, num_classes=79077):\r\n        super(network_9layers, self).__init__()\r\n        self.features = nn.Sequential(\r\n            mfm(1, 48, 5, 1, 2), \r\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True), \r\n            group(48, 96, 3, 1, 1), \r\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\r\n            group(96, 192, 3, 1, 1),\r\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True), \r\n            group(192, 128, 3, 1, 1),\r\n            group(128, 128, 3, 1, 1),\r\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\r\n            )\r\n        self.fc1 = mfm(8*8*128, 256, type=0)\r\n        self.fc2 = nn.Linear(256, num_classes)\r\n\r\n    def forward(self, x):\r\n        x = self.features(x)\r\n        x = x.view(x.size(0), -1)\r\n        x = self.fc1(x)\r\n        x = F.dropout(x, training=self.training)\r\n        out = self.fc2(x)\r\n        return out, x\r\n\r\nclass network_29layers(nn.Module):\r\n    def __init__(self, block, layers, num_classes=79077):\r\n        super(network_29layers, self).__init__()\r\n        self.conv1  = mfm(1, 48, 5, 1, 2)\r\n        self.pool1  = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\r\n        self.block1 = self._make_layer(block, layers[0], 48, 48)\r\n        self.group1 = group(48, 96, 3, 1, 1)\r\n        self.pool2  = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\r\n        self.block2 = self._make_layer(block, layers[1], 96, 96)\r\n        self.group2 = group(96, 192, 3, 1, 1)\r\n        self.pool3  = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\r\n        self.block3 = self._make_layer(block, layers[2], 192, 192)\r\n        self.group3 = group(192, 128, 3, 1, 1)\r\n        self.block4 = self._make_layer(block, layers[3], 128, 128)\r\n        self.group4 = group(128, 128, 3, 1, 1)\r\n        self.pool4  = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\r\n        self.fc     = mfm(8*8*128, 256, type=0)\r\n        self.fc2    = nn.Linear(256, num_classes)\r\n    \r\n\r\n    def _make_layer(self, block, num_blocks, in_channels, out_channels):\r\n        layers = []\r\n        for i in range(0, num_blocks):\r\n            layers.append(block(in_channels, out_channels))\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = self.pool1(x)\r\n\r\n        x = self.block1(x)\r\n        x = self.group1(x)\r\n        x = self.pool2(x)\r\n\r\n        x = self.block2(x)\r\n        x = self.group2(x)\r\n        x = self.pool3(x)\r\n\r\n        x = self.block3(x)\r\n        x = self.group3(x)\r\n        x = self.block4(x)\r\n        x = self.group4(x)\r\n        x = self.pool4(x)\r\n\r\n        x = x.view(x.size(0), -1)\r\n        fc = self.fc(x)\r\n        fc = F.dropout(fc, training=self.training)\r\n        out = self.fc2(fc)\r\n        return out, fc\r\n\r\n\r\nclass network_29layers_v2(nn.Module):\r\n    def __init__(self, block, layers, num_classes=79077):\r\n        super(network_29layers_v2, self).__init__()\r\n        self.conv1    = mfm(1, 48, 5, 1, 2)\r\n        self.block1   = self._make_layer(block, layers[0], 48, 48)\r\n        self.group1   = group(48, 96, 3, 1, 1)\r\n        self.block2   = self._make_layer(block, layers[1], 96, 96)\r\n        self.group2   = group(96, 192, 3, 1, 1)\r\n        self.block3   = self._make_layer(block, layers[2], 192, 192)\r\n        self.group3   = group(192, 128, 3, 1, 1)\r\n        self.block4   = self._make_layer(block, layers[3], 128, 128)\r\n        self.group4   = group(128, 128, 3, 1, 1)\r\n        self.fc       = nn.Linear(8*8*128, 256)\r\n        self.fc2 = nn.Linear(256, num_classes[0], bias=False)\r\n    \r\n    def _make_layer(self, block, num_blocks, in_channels, out_channels):\r\n        layers = []\r\n        for i in range(0, num_blocks):\r\n            layers.append(block(in_channels, out_channels))\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\r\n\r\n        x = self.block1(x)\r\n        x = self.group1(x)\r\n        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\r\n\r\n        x = self.block2(x)\r\n        x = self.group2(x)\r\n        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\r\n\r\n        x = self.block3(x)\r\n        x = self.group3(x)\r\n        x = self.block4(x)\r\n        x = self.group4(x)\r\n        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\r\n\r\n        x = x.view(x.size(0), -1)\r\n        fc = self.fc(x)\r\n        x = F.dropout(fc, training=self.training)\r\n        \r\n        output = list()\r\n        for name, fun in self.fc_dict.iteritems():\r\n            out = fun(x)\r\n            output.append(out)\r\n\r\n        return output, fc\r\n\r\nclass network_9layers_templet(nn.Module):\r\n    def __init__(self, in_channel):\r\n        super(network_9layers_templet, self).__init__()\r\n        self.features = nn.Sequential(\r\n            mfm(in_channel, 48, 5, 1, 2), \r\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True), \r\n            group(48, 96, 3, 1, 1), \r\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\r\n            group(96, 192, 3, 1, 1),\r\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True), \r\n            group(192, 128, 3, 1, 1),\r\n            group(128, 128, 3, 1, 1),\r\n            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\r\n            )\r\n        self.fc1 = mfm(8*8*128, 256, type=0)\r\n\r\n    def forward(self, x):\r\n        x = self.features(x)\r\n        x = x.view(x.size(0), -1)\r\n        x = self.fc1(x)\r\n        out = F.dropout(x, training=self.training)\r\n        return out\r\n\r\nclass network_29layers_v2_templet(nn.Module):\r\n    def __init__(self, in_channel, block, layers):\r\n        super(network_29layers_v2_templet, self).__init__()\r\n        self.conv1    = mfm(in_channel, 48, 5, 1, 2)\r\n        self.block1   = self._make_layer(block, layers[0], 48, 48)\r\n        self.group1   = group(48, 96, 3, 1, 1)\r\n        self.block2   = self._make_layer(block, layers[1], 96, 96)\r\n        self.group2   = group(96, 192, 3, 1, 1)\r\n        self.block3   = self._make_layer(block, layers[2], 192, 192)\r\n        self.group3   = group(192, 128, 3, 1, 1)\r\n        self.block4   = self._make_layer(block, layers[3], 128, 128)\r\n        self.group4   = group(128, 128, 3, 1, 1)\r\n        self.fc       = nn.Linear(8*8*128, 256)\r\n    \r\n    def _make_layer(self, block, num_blocks, in_channels, out_channels):\r\n        layers = []\r\n        for i in range(0, num_blocks):\r\n            layers.append(block(in_channels, out_channels))\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        x = self.conv1(x)\r\n        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\r\n\r\n        x = self.block1(x)\r\n        x = self.group1(x)\r\n        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\r\n\r\n        x = self.block2(x)\r\n        x = self.group2(x)\r\n        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\r\n\r\n        x = self.block3(x)\r\n        x = self.group3(x)\r\n        x = self.block4(x)\r\n        x = self.group4(x)\r\n        x = F.max_pool2d(x, 2) + F.avg_pool2d(x, 2)\r\n\r\n        x = x.view(x.size(0), -1)\r\n        fc = self.fc(x)\r\n        x = F.dropout(fc, training=self.training)\r\n        \r\n        return x\r\n\r\n\r\ndef LightCNN_9Layers(**kwargs):\r\n    model = network_9layers(**kwargs)\r\n    return model\r\n\r\ndef LightCNN_29Layers(**kwargs):\r\n    model = network_29layers(resblock, [1, 2, 3, 4], **kwargs)\r\n    return model\r\n\r\ndef LightCNN_29Layers_v2(**kwargs):\r\n    model = network_29layers_v2(resblock, [1, 2, 3, 4], **kwargs)\r\n    return model\r\n\r\ndef LightCNN_9Layers_templet(in_channel, pretrained=False):\r\n    model = network_9layers_templet(in_channel)\r\n    return model\r\n\r\ndef LightCNN_29Layers_v2_templet(in_channel, pretrained=False):\r\n    model = network_29layers_v2_templet(in_channel, resblock, [1,2,3,4])\r\n    return model\r\n\r\n\r\nif __name__ == ""__main__"":\r\n    model = LightCNN_29Layers_v2_templet(3)\r\n    print model\r\n'"
models/model.py,6,"b'import os\nimport torch\nimport logging\nfrom torch.autograd import Variable\n\nfrom .build_model import BuildMultiLabelModel, LoadPretrainedModel\nfrom .lightcnn import LightCNN_29Layers_v2_templet, LightCNN_9Layers_templet \nfrom .alexnet import AlexnetTemplet\nfrom .resnet import Resnet18Templet\nfrom .vgg import VGG16Templet\n\ndef load_model(opt, num_classes):\n    # load templet\n    if opt.model == ""Alexnet"":\n        templet = AlexnetTemplet(opt.input_channel, opt.pretrain)\n    elif opt.model == ""LightenB"":\n        templet = LightCNN_29Layers_v2_templet(opt.input_channel, opt.pretrain)\n    elif opt.model == ""Lighten9"":\n        templet = LightCNN_9Layers_templet(opt.input_channel, opt.pretrain)\n    elif opt.model == ""Resnet18"":\n        templet = Resnet18Templet(opt.input_channel, opt.pretrain)\n    elif opt.model == ""VGG16"":\n        templet = VGG16Templet(opt.input_channel, opt.pretrain)\n    else:\n        logging.error(""unknown model type"")\n        sys.exit(0)\n    \n    # build model\n    tmp_input = Variable(torch.FloatTensor(1, opt.input_channel, opt.input_size, opt.input_size))\n    tmp_output = templet(tmp_input)\n    output_dim = int(tmp_output.size()[-1])\n    model = BuildMultiLabelModel(templet, output_dim, num_classes)\n    logging.info(model)\n    \n    # imagenet pretrain model\n    if opt.pretrain:\n        logging.info(""use imagenet pretrained model"")\n    \n    # load exsiting model\n    if opt.checkpoint_name != """":\n        if os.path.exists(opt.checkpoint_name):\n            logging.info(""load pretrained model from ""+opt.checkpoint_name)\n            model.load_state_dict(torch.load(opt.checkpoint_name))\n        elif os.path.exists(opt.model_dir):\n            checkpoint_name = opt.model_dir + ""/"" + opt.checkpoint_name\n            model.load_state_dict(torch.load(checkpoint_name))\n            logging.info(""load pretrained model from ""+ checkpoint_name)\n        else:\n            opt.checkpoint_name = """"\n            logging.warning(""WARNING: unknown pretrained model, skip it."")\n\n    return model\n\ndef save_model(model, opt, epoch):\n    checkpoint_name = opt.model_dir + ""/epoch_%s_snapshot.pth"" %(epoch)\n    torch.save(model.cpu().state_dict(), checkpoint_name)\n    if opt.cuda and torch.cuda.is_available():\n        model.cuda(opt.devices[0])\n\ndef modify_last_layer_lr(named_params, base_lr, lr_mult_w, lr_mult_b):\n    params = list()\n    for name, param in named_params: \n        if \'bias\' in name:\n            if \'FullyConnectedLayer_\' in name:\n                params += [{\'params\':param, \'lr\': base_lr * lr_mult_b, \'weight_decay\': 0}]\n            else:\n                params += [{\'params\':param, \'lr\': base_lr * 2, \'weight_decay\': 0}]\n        else:\n            if \'FullyConnectedLayer_\' in name:\n                params += [{\'params\':param, \'lr\': base_lr * lr_mult_w}]\n            else:\n                params += [{\'params\':param, \'lr\': base_lr * 1}]\n    return params\n'"
models/resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom build_model import LoadPretrainedModel\n\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\']\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\nclass ResNetTemplet(nn.Module):\n\n    def __init__(self, block, layers, input_channel):\n        self.inplanes = 64\n        super(ResNetTemplet, self).__init__()\n        self.conv1 = nn.Conv2d(input_channel, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, 1000)\n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n    return model\n\n\ndef Resnet18Templet(input_channel, pretrained=False, **kwargs):\n    """"""Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNetTemplet(BasicBlock, [2, 2, 2, 2], input_channel, **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'resnet18\']))\n        model.load_state_dict(model_dict)\n    return model\n\n\ndef resnet34(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model\n\n\ndef Resnet34Templet(input_channel, pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNetTemplet(BasicBlock, [3, 4, 6, 3], input_channel, **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'resnet34\']))\n        model.load_state_dict(model_dict)\n    return model\n\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef Resnet50Templet(input_channel, pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNetTemplet(Bottleneck, [3, 4, 6, 3], input_channel, **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'resnet50\']))\n        model.load_state_dict(model_dict)\n    return model\n\n\ndef resnet101(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n    return model\n\ndef Resnet101Templet(input_channel, pretrained=False, **kwargs):\n    """"""Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNetTemplet(Bottleneck, [3, 4, 23, 3], input_channel, **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'resnet101\']))\n        model.load_state_dict(model_dict)\n    return model\n\ndef resnet152(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n    return model\n\ndef Resnet152Templet(input_channel, pretrained=False, **kwargs):\n    """"""Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNetTemplet(Bottleneck, [3, 8, 36, 3], input_channel, **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'resnet152\']))\n        model.load_state_dict(model_dict)\n    return model\n\n'"
models/vgg.py,10,"b'import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\nimport math\nfrom build_model import LoadPretrainedModel\n\n__all__ = [\n    \'VGG\', \'vgg11\', \'vgg11_bn\', \'vgg13\', \'vgg13_bn\', \'vgg16\', \'vgg16_bn\',\n    \'vgg19_bn\', \'vgg19\',\n]\n\n\nmodel_urls = {\n    \'vgg11\': \'https://download.pytorch.org/models/vgg11-bbd30ac9.pth\',\n    \'vgg13\': \'https://download.pytorch.org/models/vgg13-c768596a.pth\',\n    \'vgg16\': \'https://download.pytorch.org/models/vgg16-397923af.pth\',\n    \'vgg19\': \'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\',\n    \'vgg11_bn\': \'https://download.pytorch.org/models/vgg11_bn-6002323d.pth\',\n    \'vgg13_bn\': \'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth\',\n    \'vgg16_bn\': \'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\',\n    \'vgg19_bn\': \'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\',\n}\n\n\nclass VGG(nn.Module):\n\n    def __init__(self, features, num_classes=1000):\n        super(VGG, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes),\n        )\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\nclass VGGTemplet(nn.Module):\n\n    def __init__(self, features):\n        super(VGGTemplet, self).__init__()\n        self.features = features\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            #nn.Linear(4096, num_classes),\n        )\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\ndef make_layers(cfg, in_channels, batch_norm=False):\n    layers = []\n    #in_channels = 3\n    for v in cfg:\n        if v == \'M\':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)\n\n\ncfg = {\n    \'A\': [64, \'M\', 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'B\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, \'M\', 512, 512, \'M\', 512, 512, \'M\'],\n    \'D\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, \'M\', 512, 512, 512, \'M\', 512, 512, 512, \'M\'],\n    \'E\': [64, 64, \'M\', 128, 128, \'M\', 256, 256, 256, 256, \'M\', 512, 512, 512, 512, \'M\', 512, 512, 512, 512, \'M\'],\n}\n\n\ndef vgg11(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\'], input_channel), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg11\']))\n    return model\n\ndef VGG11Templet(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGGTemplet(make_layers(cfg[\'A\'], input_channel), **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'vgg11\']))\n        model.load_state_dict(model_dict)\n    return model\n\ndef vgg11_bn(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'A\'], input_channel, batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg11_bn\']))\n    return model\n\ndef VGG11BNTemplet(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 11-layer model (configuration ""A"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGGTemplet(make_layers(cfg[\'A\'], input_channel, batch_norm=True), **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'vgg11_bn\']))\n        model.load_state_dict(model_dict)\n    return model\n\ndef vgg13(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\'], input_channel), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg13\']))\n    return model\n\ndef VGG13Templet(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGGTemplet(make_layers(cfg[\'B\'], input_channel), **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'vgg13\']))\n        model.load_state_dict(model_dict)\n    return model\n\ndef vgg13_bn(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'B\'], input_channel, batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg13_bn\']))\n    return model\n\ndef VGG13BNTemplet(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 13-layer model (configuration ""B"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGGTemplet(make_layers(cfg[\'B\'], input_channel, batch_norm=True), **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'vgg13_bn\']))\n        model.load_state_dict(model_dict)\n    return model\n\ndef vgg16(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\'], input_channel), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16\']))\n    return model\n\ndef VGG16Templet(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGGTemplet(make_layers(cfg[\'D\'], input_channel), **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'vgg16\']))\n        model.load_state_dict(model_dict)\n    return model\n\ndef vgg16_bn(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'D\'], input_channel, batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg16_bn\']))\n    return model\n\ndef VGG16BNTemplet(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 16-layer model (configuration ""D"") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGGTemplet(make_layers(cfg[\'D\'], input_channel, batch_norm=True), **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'vgg16_bn\']))\n        model.load_state_dict(model_dict)\n    return model\n\ndef vgg19(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 19-layer model (configuration ""E"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\'], input_channel), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg19\']))\n    return model\n\ndef VGG19Templet(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 19-layer model (configuration ""E"")\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGGTemplet(make_layers(cfg[\'E\'], input_channel), **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'vgg19\']))\n        model.load_state_dict(model_dict)\n    return model\n\ndef vgg19_bn(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 19-layer model (configuration \'E\') with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGG(make_layers(cfg[\'E\'], input_channel, batch_norm=True), **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'vgg19_bn\']))\n    return model\n\ndef VGG19BNTemplet(input_channel=3, pretrained=False, **kwargs):\n    """"""VGG 19-layer model (configuration \'E\') with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = VGGTemplet(make_layers(cfg[\'E\'], input_channel, batch_norm=True), **kwargs)\n    if pretrained:\n        model_dict = LoadPretrainedModel(model, model_zoo.load_url(model_urls[\'vgg19_bn\']))\n        model.load_state_dict(model_dict)\n    return model\n'"
options/__init__.py,0,b''
options/options.py,2,"b'import os\nimport torch\nimport argparse\n\nclass Options():\n    def __init__(self):\n        self.parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n        \n        self.parser.add_argument(\'--dir\', required=True, default=\'./\', help=\'path to the data directory containing data.txt and label.txt\')\n        self.parser.add_argument(\'--name\', required=True, default=\'test\', help=\'subdirectory name for training or testing, snapshot, splited dataset and test results exist here\')\n        self.parser.add_argument(\'--mode\', required=True, default=\'Train\', help=\'run mode of training or testing. [Train | Test | train | test]\')\n        self.parser.add_argument(\'--model\', required=True, default=\'alexnet\', help=\'model type. [Alexnet | LightenB | VGG16 | Resnet18 | ...]\')\n        self.parser.add_argument(\'--load_size\', type=int, default=144, help=\'scale image to the size prepared for croping\')\n        self.parser.add_argument(\'--input_size\', type=int, default=128, help=\'then crop image to the size as network input\')\n        self.parser.add_argument(\'--ratio\', type=str, default=\'[0.95, 0.025, 0.025]\', help=\'ratio of whole dataset for Train, Validate, Test resperctively\')\n        self.parser.add_argument(\'--batch_size\', type=int, default=1, help=\'batch size of network input. Note that batch_size should only set to 1 in Test mode\')\n        self.parser.add_argument(\'--shuffle\', action=\'store_true\', help=\'default false. If true, data will be shuffled when split dataset and in batch\')\n        self.parser.add_argument(\'--flip\', action=\'store_true\', help=\'if true, flip image randomly before input into network\')\n        self.parser.add_argument(\'--region\', action=\'store_false\', help=\'if true, crop image by input box\')\n        self.parser.add_argument(\'--load_thread\', type=int, default=2, help=\'how many subprocesses to use for data loading\')\n        self.parser.add_argument(\'--crop\', type=str, default=\'CenterCrop\', help=\'crop type, candidates are [NoCrop | RandomCrop | CenterCrop | FiveCrop | TenCrop]\')\n        self.parser.add_argument(\'--gray\', action=\'store_true\', help=\'defalut false. If true, image will be converted to gray_scale\')\n        self.parser.add_argument(\'--gpu_ids\', type=str, default=\'-1\', help=\'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU\')\n        self.parser.add_argument(\'--box_ratio\', type=float, default=-1, help=\'modify box ratio of width and height to specified ratio\')\n        self.parser.add_argument(\'--box_scale\', type=float, default=1.0, help=\'scale box to specified ratio. Default 1.0 means no change\')\n        self.parser.add_argument(\'--input_channel\', type=int, default=3, help=\'set input image channel, 1 for gray and 3 for color\')\n        self.parser.add_argument(\'--mean\', type=str, default=\'(0,0,0)\', help=\'sequence of means for each channel used for normization\')\n        self.parser.add_argument(\'--std\', type=str, default=\'(1,1,1)\', help=\'sequence standard deviations for each channel used for normization\')\n        self.parser.add_argument(\'--padding\', action=\'store_true\', help=\'default false. If true, image will be padded if scaled box is out of image boundary\')\n        self.parser.add_argument(\'--checkpoint_name\', type=str, default=\'\', help=\'path to pretrained model or model to deploy\')\n        self.parser.add_argument(\'--pretrain\', action=\'store_true\', help=\'default false. If true, load pretrained model to initizaize model state_dict\')\n        ## for train\n        self.parser.add_argument(\'--validate_ratio\', type=float, default=1, help=\'ratio of validate set when validate model\')\n        self.parser.add_argument(\'--sum_epoch\', type=int, default=200, help=\'sum epoches for training\')\n        self.parser.add_argument(\'--save_epoch_freq\', type=int, default=1, help=\'save snapshot every $save_epoch_freq epoches training\')\n        self.parser.add_argument(\'--save_batch_iter_freq\', type=int, default=100, help=\'save snapshot every $save_batch_iter_freq training\') \n        self.parser.add_argument(\'--lr\', type=float, default=0.001, help=\'initial learning rate\')\n        self.parser.add_argument(\'--gamma\', type=float, default=0.1, help=\'multiplicative factor of learning rate decay.\')\n        self.parser.add_argument(\'--lr_mult_w\', type=float, default=20, help=\'learning rate of W of last layer parameter will be lr*lr_mult_w\')\n        self.parser.add_argument(\'--lr_mult_b\', type=float, default=20, help=\'learning rate of b of last layer parameter will be lr*lr_mult_b\')\n        self.parser.add_argument(\'--lr_policy\', type=str, default=\'step\', help=\'learning rate policy: lambda|step|plateau\')\n        self.parser.add_argument(\'--lr_decay_in_epoch\', type=int, default=50, help=\'multiply by a gamma every lr_decay_in_epoch iterations\')\n        self.parser.add_argument(\'--momentum\', type=float, default=0.9, help=\'momentum of SGD\')\n        self.parser.add_argument(\'--weight_decay\', type=float, default=1e-4, help=\'weight decay of SGD\')\n        self.parser.add_argument(\'--loss_weight\', type=str, default=\'\', help=\'list. Loss weight for cross entropy loss.For example set $loss_weight to [1, 0.8, 0.8] for a 3 labels classification\')\n\n        ## for test\n        self.parser.add_argument(\'--top_k\', type=str, default=\'(1,)\', help=\'tuple. We only take top k classification results into accuracy consideration\')\n        self.parser.add_argument(\'--score_thres\', type=str, default=\'0.0\', help=\'float or list. We only take classification results whose score is bigger than score_thres into recall consideration\')\n        # these tow param below used only in deploy.py\n        self.parser.add_argument(\'--label_file\', type=str, default="""", help=\'label file only for deploy a checkpoint model\')\n        self.parser.add_argument(\'--classify_dir\', type=str, default="""", help=\'directory where data.txt to be classified exists\')\n        \n        ## for visualization\n        self.parser.add_argument(\'--display_winsize\', type=int, default=128, help=\'display window size\')\n        self.parser.add_argument(\'--display_id\', type=int, default=1, help=\'window id of the web display. Less than 1 will display nothing\')\n        self.parser.add_argument(\'--display_port\', type=int, default=8097, help=\'port of visdom server for web display. Result will show on `localhost:$display_port`\')\n        self.parser.add_argument(\'--image_ncols\', type=int, default=0, help=\'if positive, display all images in a single visdom web panel with certain number of images per row.\')\n        self.parser.add_argument(\'--html\', action=\'store_false\', help=\'defalt true. Do not save intermediate training results to [opt.dir]/[opt.name]/web/\')\n        self.parser.add_argument(\'--update_html_freq\', type=int, default=10, help=\'frequency of saving training results to html\')\n        self.parser.add_argument(\'--display_train_freq\', type=int, default=10, help=\'print train loss and accuracy every $train_freq batches iteration\')\n        self.parser.add_argument(\'--display_validate_freq\', type=int, default=10, help=\'test validate dateset every $validate_freq batches iteration\')\n        self.parser.add_argument(\'--display_data_freq\', type=int, default=10, help=\'frequency of showing training data on web browser\')\n        self.parser.add_argument(\'--display_image_ratio\', type=float, default=1.0, help=\'ratio of images in a batch showing on web browser\')\n\n    def parse(self):\n        opt = self.parser.parse_args()\n        \n        # mode\n        if opt.mode not in [""Train"", ""Test"", ""train"", ""test""]:\n            raise Exception(""cannot recognize flag `mode`"")\n        opt.mode = opt.mode.capitalize()\n        if opt.mode == ""Test"":\n            opt.batch_size = 1\n            opt.shuffle = False\n\n        # devices id\n        gpu_ids = opt.gpu_ids.split(\',\')\n        opt.devices = []\n        for id in gpu_ids:\n            if eval(id) >= 0:\n                opt.devices.append(eval(id))\n        # cuda\n        opt.cuda = False\n        if len(opt.devices) > 0 and torch.cuda.is_available():\n            opt.cuda = True\n\n\n        opt.top_k = eval(opt.top_k)\n        opt.mean = eval(opt.mean)\n        opt.std = eval(opt.std)\n        opt.ratio = eval(opt.ratio)\n        if opt.loss_weight == """":\n            opt.loss_weight=None\n        else:\n            opt.loss_weight = torch.FloatTensor(eval(opt.loss_weight))\n\n        return opt\n\nif __name__ == ""__main__"":\n    op = Options()\n    op.parse()\n'"
util/__init__.py,0,b''
util/html.py,0,"b'import dominate\nfrom dominate.tags import *\nimport os\n\n\nclass HTML:\n    def __init__(self, web_dir, title, reflesh=0):\n        self.title = title\n        self.web_dir = web_dir\n        self.img_dir = os.path.join(self.web_dir, \'images\')\n        if not os.path.exists(self.web_dir):\n            os.makedirs(self.web_dir)\n        if not os.path.exists(self.img_dir):\n            os.makedirs(self.img_dir)\n        # print(self.img_dir)\n\n        self.doc = dominate.document(title=title)\n        if reflesh > 0:\n            with self.doc.head:\n                meta(http_equiv=""reflesh"", content=str(reflesh))\n\n    def get_image_dir(self):\n        return self.img_dir\n\n    def add_header(self, str):\n        with self.doc:\n            h3(str)\n\n    def add_table(self, border=1):\n        self.t = table(border=border, style=""table-layout: fixed;"")\n        self.doc.add(self.t)\n\n    def add_images(self, ims, txts, links, width=400):\n        self.add_table()\n        with self.t:\n            with tr():\n                for im, txt, link in zip(ims, txts, links):\n                    with td(style=""word-wrap: break-word;"", halign=""center"", valign=""top""):\n                        with p():\n                            with a(href=os.path.join(\'images\', link)):\n                                img(style=""width:%dpx"" % width, src=os.path.join(\'images\', im))\n                            br()\n                            p(txt)\n\n    def save(self):\n        html_file = \'%s/index.html\' % self.web_dir\n        f = open(html_file, \'wt\')\n        f.write(self.doc.render())\n        f.close()\n\n\nif __name__ == \'__main__\':\n    html = HTML(\'web/\', \'test_html\')\n    html.add_header(\'hello world\')\n\n    ims = []\n    txts = []\n    links = []\n    for n in range(4):\n        ims.append(\'image_%d.png\' % n)\n        txts.append(\'text_%d\' % n)\n        links.append(\'image_%d.png\' % n)\n    html.add_images(ims, txts, links)\n    html.save()\n'"
util/util.py,0,"b'import os\nimport copy\nimport numpy as np\nimport logging\nimport collections\nfrom PIL import Image\n\n\ndef tensor2im(image_tensor, mean, std, imtype=np.uint8):\n    image_numpy = image_tensor.cpu().float().numpy()\n    if image_numpy.shape[0] == 1:\n        image_numpy = np.tile(image_numpy, (3, 1, 1))\n    image_numpy = image_numpy.transpose(1, 2, 0)\n    image_numpy *= std\n    image_numpy += mean\n    image_numpy *= 255.0\n    return image_numpy.astype(imtype)\n\ndef save_image(image_numpy, image_path):\n    image_pil = Image.fromarray(image_numpy)\n    image_pil.save(image_path)\n\ndef mkdirs(paths):\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)\n\ndef mkdir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef rmdir(path):\n    if os.path.exists(path):\n        os.system(\'rm -rf \' + path)\n\ndef print_loss(loss_list, label, epoch=0, batch_iter=0):\n    if label == ""Test"":\n        logging.info(""[ %s Loss ] of Test Dataset:"" % (label))\n    else:\n        logging.info(""[ %s Loss ] of Epoch %d Batch %d"" % (label, epoch, batch_iter))\n    \n    for index, loss in enumerate(loss_list):\n        logging.info(""----Attribute %d:  %f"" %(index, loss))\n\ndef print_accuracy(accuracy_list, label, epoch=0, batch_iter=0):\n    if label == ""Test"":\n        logging.info(""[ %s Accu ] of Test Dataset:"" % (label))\n    else:\n        logging.info(""[ %s Accu ] of Epoch %d Batch %d"" %(label, epoch, batch_iter))\n    \n    for index, item in enumerate(accuracy_list):\n        for top_k, value in item.iteritems():\n            logging.info(""----Attribute %d Top%d: %f"" %(index, top_k, value[""ratio""]))\n\ndef opt2file(opt, dst_file):\n    args = vars(opt) \n    with open(dst_file, \'wt\') as opt_file:\n        opt_file.write(\'------------ Options -------------\\n\')\n        print \'------------ Options -------------\'\n        for k, v in sorted(args.items()):\n            opt_file.write(\'%s: %s\\n\' % (str(k), str(v)))\n            print ""%s: %s"" %(str(k), str(v))\n        opt_file.write(\'-------------- End ----------------\\n\')\n        print \'-------------- End ----------------\'\n\ndef load_label(label_file):\n    rid2name = list()   # rid: real id, same as the id in label.txt\n    id2rid = list()     # id: number from 0 to len(rids)-1 corresponding to the order of rids\n    rid2id = list()     \n    with open(label_file) as l:\n        rid2name_dict = collections.defaultdict(str)\n        id2rid_dict = collections.defaultdict(str)\n        rid2id_dict = collections.defaultdict(str)\n        new_id = 0 \n        for line in l.readlines():\n            line = line.strip(\'\\n\\r\').split(\';\')\n            if len(line) == 3: # attr description\n                if len(rid2name_dict) != 0:\n                    rid2name.append(rid2name_dict)\n                    id2rid.append(id2rid_dict)\n                    rid2id.append(rid2id_dict)\n                    rid2name_dict = collections.defaultdict(str)\n                    id2rid_dict = collections.defaultdict(str)\n                    rid2id_dict = collections.defaultdict(str)\n                    new_id = 0\n                rid2name_dict[""__name__""] = line[2]\n                rid2name_dict[""__attr_id__""] = line[1]\n            elif len(line) == 2: # attr value description\n                rid2name_dict[line[0]] = line[1]\n                id2rid_dict[new_id] = line[0]\n                rid2id_dict[line[0]] = new_id\n                new_id += 1\n        if len(rid2name_dict) != 0:\n            rid2name.append(rid2name_dict)\n            id2rid.append(id2rid_dict)\n            rid2id.append(rid2id_dict)\n    return rid2name, id2rid, rid2id\n\n'"
util/webvisualizer.py,0,"b'import os\nimport time\nimport collections\nimport numpy as np\nfrom . import util\nfrom . import html\n\n\nclass WebVisualizer():\n    def __init__(self, opt):\n        self.opt = opt\n        self.display_id = opt.display_id\n        self.win_size = opt.display_winsize\n        self.use_html = (opt.html and (opt.mode == ""Train""))\n        self.name = opt.name\n        self.saved = False\n        self.type2id = {""Loss"":0, ""Accuracy"": 1, ""Other"": 2}\n        self.phase2id = {""Train"": 0, ""Validate"": 1, ""Test"": 2}\n        \n        def ManualType():\n            return collections.defaultdict(list)\n        # store all the points for regular backup \n        self.plot_data = collections.defaultdict(ManualType)\n        # line window info \n        self.win_info = collections.defaultdict(ManualType)\n        if self.display_id > 0:\n            import visdom\n            self.vis = visdom.Visdom(port=opt.display_port)\n        \n        if self.use_html:\n            self.web_dir = os.path.join(opt.model_dir, ""web"")\n            self.img_dir = os.path.join(opt.model_dir, ""image"")\n            print ""Create web directory %s ..."" %(self.web_dir)\n            util.mkdirs([self.web_dir, self.img_dir])\n            \n\n    def reset(self):\n        self.saved = False\n    \n    """"""\n    type:  [Accuracy | Loss | Other]\n    phase: [Train | Validate | Test]\n    """"""\n    def plot_points(self, x, y, data_type, phase):\n        line_name = data_type + ""@"" + phase\n        self.plot_data[data_type][phase].append((x,y))\n        # draw ininial line objects if not initialized\n        if len(self.win_info[data_type][phase]) == 0:\n            for index in range(len(y)):\n                win_id = self.type2id[data_type]*len(y) + index\n                win = self.vis.line(X=np.array([0]),\n                                    Y=np.array([0]),\n                                    opts=dict(\n                                        title=data_type + "" of Attribute "" + str(index) + "" Over Time"",\n                                        xlabel=""epoch"",\n                                        ylabel=data_type,\n                                        showlegend=True,\n                                        width=900,\n                                        height=450),\n                                    win=win_id,\n                                    name=line_name)\n                self.win_info[data_type][phase].append(win)\n        \n        for index, value in enumerate(y): \n            win_id = self.win_info[data_type][phase][index] \n            self.vis.line(X=np.array([x]),\n                          Y=np.array([value]),\n                          win=win_id,\n                          name=line_name,\n                          update=""append"")\n    \n    def plot_images(self, image_dict, start_display_id, epoch, save_result):\n        if self.display_id > 0:  # show images in the browser\n            ncols = self.opt.image_ncols\n            if ncols > 0:\n                h, w = next(iter(image_dict.values())).shape[:2]\n                table_css = """"""<style>\n                        table {border-collapse: separate; border-spacing:4px; white-space:nowrap; text-align:center}\n                        table td {width: %dpx; height: %dpx; padding: 4px; outline: 4px solid black}\n                        </style>"""""" % (w, h)\n                title = self.name\n                label_html = \'\'\n                label_html_row = \'\'\n                nrows = int(np.ceil(len(image_dict.items()) / ncols))\n                images = []\n                idx = 0\n                for label, image_numpy in image_dict.items():\n                    label_html_row += \'<td>%s</td>\' % label\n                    images.append(image_numpy.transpose([2, 0, 1]))\n                    idx += 1\n                    if idx % ncols == 0:\n                        label_html += \'<tr>%s</tr>\' % label_html_row\n                        label_html_row = \'\'\n                white_image = np.ones_like(image_numpy.transpose([2, 0, 1])) * 255\n                while idx % ncols != 0:\n                    images.append(white_image)\n                    label_html_row += \'<td></td>\'\n                    idx += 1\n                if label_html_row != \'\':\n                    label_html += \'<tr>%s</tr>\' % label_html_row\n                # pane col = image row\n                self.vis.images(images, nrow=ncols, win=start_display_id + 1,\n                                padding=2, opts=dict(title=title + \' images\'))\n                label_html = \'<table>%s</table>\' % label_html\n                self.vis.text(table_css + label_html, win=start_display_id + 2,\n                              opts=dict(title=title + \' labels\'))\n            else:\n                idx = 1\n                for label, image_numpy in image_dict.items():\n                    self.vis.image(image_numpy.transpose([2, 0, 1]), opts=dict(title=label),\n                                   win=start_display_id + idx)\n                    idx += 1\n\n        if self.use_html and (save_result or not self.saved):  # save images to a html file\n            self.saved = True\n            for label, image_numpy in image_dict.items():\n                img_path = os.path.join(self.img_dir, \'epoch%.3d_%s.png\' % (epoch, label))\n                util.save_image(image_numpy, img_path)\n            # update website\n            webpage = html.HTML(self.web_dir, \'Experiment name = %s\' % self.name, reflesh=1)\n            for n in range(epoch, 0, -1):\n                webpage.add_header(\'epoch [%d]\' % n)\n                ims = []\n                txts = []\n                links = []\n\n                for label, image_numpy in image_dict.items():\n                    img_path = \'epoch%.3d_%s.png\' % (n, label)\n                    ims.append(img_path)\n                    txts.append(label)\n                    links.append(img_path)\n                webpage.add_images(ims, txts, links, width=self.win_size)\n            webpage.save()\n\n    def backup(self, name):\n        pass\n\n    def test(self):\n        pass\n'"
