file_path,api_count,code
build.py,1,"b'#!/usr/bin/env python\n\nimport glob\nimport os\nimport tarfile\nimport warnings\n\nimport urllib.request\nfrom torch.utils.cpp_extension import CppExtension, include_paths\n\n\ndef download_extract(url, dl_path):\n    if not os.path.isfile(dl_path):\n        # Already downloaded\n        urllib.request.urlretrieve(url, dl_path)\n    if dl_path.endswith("".tar.gz"") and os.path.isdir(dl_path[:-len("".tar.gz"")]):\n        # Already extracted\n        return\n    tar = tarfile.open(dl_path)\n    tar.extractall(\'third_party/\')\n    tar.close()\n\n\n# Download/Extract openfst, boost\ndownload_extract(\'https://github.com/parlance/ctcdecode/releases/download/v1.0/openfst-1.6.7.tar.gz\',\n                 \'third_party/openfst-1.6.7.tar.gz\')\ndownload_extract(\'https://github.com/parlance/ctcdecode/releases/download/v1.0/boost_1_67_0.tar.gz\',\n                 \'third_party/boost_1_67_0.tar.gz\')\n\nfor file in [\'third_party/kenlm/setup.py\', \'third_party/ThreadPool/ThreadPool.h\']:\n    if not os.path.exists(file):\n        warnings.warn(\'File `{}` does not appear to be present. Did you forget `git submodule update`?\'.format(file))\n\n\n# Does gcc compile with this header and library?\ndef compile_test(header, library):\n    dummy_path = os.path.join(os.path.dirname(__file__), ""dummy"")\n    command = ""bash -c \\""g++ -include "" + header + "" -l"" + library + "" -x c++ - <<<\'int main() {}\' -o "" + dummy_path \\\n              + "" >/dev/null 2>/dev/null && rm "" + dummy_path + "" 2>/dev/null\\""""\n    return os.system(command) == 0\n\n\ncompile_args = [\'-O3\', \'-DKENLM_MAX_ORDER=6\', \'-std=c++14\', \'-fPIC\']\next_libs = []\nif compile_test(\'zlib.h\', \'z\'):\n    compile_args.append(\'-DHAVE_ZLIB\')\n    ext_libs.append(\'z\')\n\nif compile_test(\'bzlib.h\', \'bz2\'):\n    compile_args.append(\'-DHAVE_BZLIB\')\n    ext_libs.append(\'bz2\')\n\nif compile_test(\'lzma.h\', \'lzma\'):\n    compile_args.append(\'-DHAVE_XZLIB\')\n    ext_libs.append(\'lzma\')\n\nthird_party_libs = [""kenlm"", ""openfst-1.6.7/src/include"", ""ThreadPool"", ""boost_1_67_0"", ""utf8""]\ncompile_args.extend([\'-DINCLUDE_KENLM\', \'-DKENLM_MAX_ORDER=6\'])\nlib_sources = glob.glob(\'third_party/kenlm/util/*.cc\') + glob.glob(\'third_party/kenlm/lm/*.cc\') + glob.glob(\n    \'third_party/kenlm/util/double-conversion/*.cc\') + glob.glob(\'third_party/openfst-1.6.7/src/lib/*.cc\')\nlib_sources = [fn for fn in lib_sources if not (fn.endswith(\'main.cc\') or fn.endswith(\'test.cc\'))]\n\nthird_party_includes = [os.path.realpath(os.path.join(""third_party"", lib)) for lib in third_party_libs]\nctc_sources = glob.glob(\'ctcdecode/src/*.cpp\')\n\n\nextension = CppExtension(\n   name=\'ctcdecode._ext.ctc_decode\',\n   package=True,\n   with_cuda=False,\n   sources=ctc_sources + lib_sources,\n   include_dirs=third_party_includes + include_paths(),\n   libraries=ext_libs,\n   extra_compile_args=compile_args,\n   language=\'c++\')\n\n\n'"
setup.py,1,"b'#!/usr/bin/env python\nimport multiprocessing.pool\nimport os\n\nfrom setuptools import setup, find_packages, distutils\nfrom torch.utils.cpp_extension import BuildExtension\n\nthis_file = os.path.dirname(__file__)\n\n\n# monkey-patch for parallel compilation\n# See: https://stackoverflow.com/a/13176803\ndef parallelCCompile(self,\n                     sources,\n                     output_dir=None,\n                     macros=None,\n                     include_dirs=None,\n                     debug=0,\n                     extra_preargs=None,\n                     extra_postargs=None,\n                     depends=None):\n    # those lines are copied from distutils.ccompiler.CCompiler directly\n    macros, objects, extra_postargs, pp_opts, build = self._setup_compile(\n        output_dir, macros, include_dirs, sources, depends, extra_postargs)\n    cc_args = self._get_cc_args(pp_opts, debug, extra_preargs)\n\n    # parallel code\n    def _single_compile(obj):\n        try:\n            src, ext = build[obj]\n        except KeyError:\n            return\n        self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n\n    # convert to list, imap is evaluated on-demand\n    thread_pool = multiprocessing.pool.ThreadPool(os.cpu_count())\n    list(thread_pool.imap(_single_compile, objects))\n    return objects\n\n\n# hack compile to support parallel compiling\ndistutils.ccompiler.CCompiler.compile = parallelCCompile\nimport build \n\nsetup(\n    name=""ctcdecode"",\n    version=""0.4"",\n    description=""CTC Decoder for PyTorch based on Paddle Paddle\'s implementation"",\n    url=""https://github.com/parlance/ctcdecode"",\n    author=""Ryan Leary"",\n    author_email=""ryanleary@gmail.com"",\n    # Exclude the build files.\n    packages=find_packages(exclude=[""build""]),\n    ext_modules = [build.extension],\n    cmdclass={\'build_ext\': BuildExtension}\n)\n'"
ctcdecode/__init__.py,5,"b'import torch\nfrom ._ext import ctc_decode\n\n\nclass CTCBeamDecoder(object):\n    def __init__(self, labels, model_path=None, alpha=0, beta=0, cutoff_top_n=40, cutoff_prob=1.0, beam_width=100,\n                 num_processes=4, blank_id=0, log_probs_input=False):\n        self.cutoff_top_n = cutoff_top_n\n        self._beam_width = beam_width\n        self._scorer = None\n        self._num_processes = num_processes\n        self._labels = list(labels)  # Ensure labels are a list\n        self._num_labels = len(labels)\n        self._blank_id = blank_id\n        self._log_probs = 1 if log_probs_input else 0\n        if model_path:\n            self._scorer = ctc_decode.paddle_get_scorer(alpha, beta, model_path.encode(), self._labels,\n                                                        self._num_labels)\n        self._cutoff_prob = cutoff_prob\n\n    def decode(self, probs, seq_lens=None):\n        # We expect batch x seq x label_size\n        probs = probs.cpu().float()\n        batch_size, max_seq_len = probs.size(0), probs.size(1)\n        if seq_lens is None:\n            seq_lens = torch.IntTensor(batch_size).fill_(max_seq_len)\n        else:\n            seq_lens = seq_lens.cpu().int()\n        output = torch.IntTensor(batch_size, self._beam_width, max_seq_len).cpu().int()\n        timesteps = torch.IntTensor(batch_size, self._beam_width, max_seq_len).cpu().int()\n        scores = torch.FloatTensor(batch_size, self._beam_width).cpu().float()\n        out_seq_len = torch.zeros(batch_size, self._beam_width).cpu().int()\n        if self._scorer:\n            ctc_decode.paddle_beam_decode_lm(probs, seq_lens, self._labels, self._num_labels, self._beam_width,\n                                             self._num_processes, self._cutoff_prob, self.cutoff_top_n, self._blank_id,\n                                             self._log_probs, self._scorer, output, timesteps, scores, out_seq_len)\n        else:\n            ctc_decode.paddle_beam_decode(probs, seq_lens, self._labels, self._num_labels, self._beam_width,\n                                          self._num_processes,\n                                          self._cutoff_prob, self.cutoff_top_n, self._blank_id, self._log_probs,\n                                          output, timesteps, scores, out_seq_len)\n\n        return output, scores, timesteps, out_seq_len\n\n    def character_based(self):\n        return ctc_decode.is_character_based(self._scorer) if self._scorer else None\n\n    def max_order(self):\n        return ctc_decode.get_max_order(self._scorer) if self._scorer else None\n\n    def dict_size(self):\n        return ctc_decode.get_dict_size(self._scorer) if self._scorer else None\n\n    def reset_params(self, alpha, beta):\n        if self._scorer is not None:\n            ctc_decode.reset_params(self._scorer, alpha, beta)\n\n    def __del__(self):\n        if self._scorer is not None:\n            ctc_decode.paddle_release_scorer(self._scorer)\n'"
tests/test.py,5,"b'""""""Test decoders.""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport unittest\nimport torch\nimport ctcdecode\nimport os\n\nclass TestDecoders(unittest.TestCase):\n    def setUp(self):\n        self.vocab_list = [\'\\\'\', \' \', \'a\', \'b\', \'c\', \'d\', \'_\']\n        self.beam_size = 20\n        self.probs_seq1 = [[\n            0.06390443, 0.21124858, 0.27323887, 0.06870235, 0.0361254,\n            0.18184413, 0.16493624\n        ], [\n            0.03309247, 0.22866108, 0.24390638, 0.09699597, 0.31895462,\n            0.0094893, 0.06890021\n        ], [\n            0.218104, 0.19992557, 0.18245131, 0.08503348, 0.14903535,\n            0.08424043, 0.08120984\n        ], [\n            0.12094152, 0.19162472, 0.01473646, 0.28045061, 0.24246305,\n            0.05206269, 0.09772094\n        ], [\n            0.1333387, 0.00550838, 0.00301669, 0.21745861, 0.20803985,\n            0.41317442, 0.01946335\n        ], [\n            0.16468227, 0.1980699, 0.1906545, 0.18963251, 0.19860937,\n            0.04377724, 0.01457421\n        ]]\n        self.probs_seq2 = [[\n            0.08034842, 0.22671944, 0.05799633, 0.36814645, 0.11307441,\n            0.04468023, 0.10903471\n        ], [\n            0.09742457, 0.12959763, 0.09435383, 0.21889204, 0.15113123,\n            0.10219457, 0.20640612\n        ], [\n            0.45033529, 0.09091417, 0.15333208, 0.07939558, 0.08649316,\n            0.12298585, 0.01654384\n        ], [\n            0.02512238, 0.22079203, 0.19664364, 0.11906379, 0.07816055,\n            0.22538587, 0.13483174\n        ], [\n            0.17928453, 0.06065261, 0.41153005, 0.1172041, 0.11880313,\n            0.07113197, 0.04139363\n        ], [\n            0.15882358, 0.1235788, 0.23376776, 0.20510435, 0.00279306,\n            0.05294827, 0.22298418\n        ]]\n        self.greedy_result = [""ac\'bdc"", ""b\'da""]\n        self.beam_search_result = [\'acdc\', ""b\'a"", ""a a""]\n\n    def convert_to_string(self, tokens, vocab, seq_len):\n        return \'\'.join([vocab[x] for x in tokens[0:seq_len]])\n\n    def test_beam_search_decoder_1(self):\n        probs_seq = torch.FloatTensor([self.probs_seq1])\n        decoder = ctcdecode.CTCBeamDecoder(self.vocab_list, beam_width=self.beam_size,\n                                           blank_id=self.vocab_list.index(\'_\'))\n        beam_result, beam_scores, timesteps, out_seq_len = decoder.decode(probs_seq)\n        output_str = self.convert_to_string(beam_result[0][0], self.vocab_list, out_seq_len[0][0])\n        self.assertEqual(output_str, self.beam_search_result[0])\n\n    def test_beam_search_decoder_2(self):\n        probs_seq = torch.FloatTensor([self.probs_seq2])\n        decoder = ctcdecode.CTCBeamDecoder(self.vocab_list, beam_width=self.beam_size,\n                                           blank_id=self.vocab_list.index(\'_\'))\n        beam_result, beam_scores, timesteps, out_seq_len = decoder.decode(probs_seq)\n        output_str = self.convert_to_string(beam_result[0][0], self.vocab_list, out_seq_len[0][0])\n        self.assertEqual(output_str, self.beam_search_result[1])\n\n    def test_beam_search_decoder_3(self):\n        lm_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), \'test.arpa\')\n        probs_seq = torch.FloatTensor([self.probs_seq2])\n\n        decoder = ctcdecode.CTCBeamDecoder(self.vocab_list, beam_width=self.beam_size,\n                                           blank_id=self.vocab_list.index(\'_\'),\n                                           model_path=lm_path)\n        beam_result, beam_scores, timesteps, out_seq_len = decoder.decode(probs_seq)\n        output_str = self.convert_to_string(beam_result[0][0], self.vocab_list, out_seq_len[0][0])\n        self.assertEqual(output_str, self.beam_search_result[2])\n\n    def test_beam_search_decoder_batch(self):\n        probs_seq = torch.FloatTensor([self.probs_seq1, self.probs_seq2])\n        decoder = ctcdecode.CTCBeamDecoder(self.vocab_list, beam_width=self.beam_size,\n                                           blank_id=self.vocab_list.index(\'_\'), num_processes=24)\n        beam_results, beam_scores, timesteps, out_seq_len = decoder.decode(probs_seq)\n        output_str1 = self.convert_to_string(beam_results[0][0], self.vocab_list, out_seq_len[0][0])\n        output_str2 = self.convert_to_string(beam_results[1][0], self.vocab_list, out_seq_len[1][0])\n        self.assertEqual(output_str1, self.beam_search_result[0])\n        self.assertEqual(output_str2, self.beam_search_result[1])\n    \n    def test_beam_search_decoder_batch_log(self):\n        probs_seq = torch.FloatTensor([self.probs_seq1, self.probs_seq2]).log()\n        decoder = ctcdecode.CTCBeamDecoder(self.vocab_list, beam_width=self.beam_size,\n                                           blank_id=self.vocab_list.index(\'_\'), log_probs_input=True,\n                                           num_processes=24)\n        beam_results, beam_scores, timesteps, out_seq_len = decoder.decode(probs_seq)\n        output_str1 = self.convert_to_string(beam_results[0][0], self.vocab_list, out_seq_len[0][0])\n        output_str2 = self.convert_to_string(beam_results[1][0], self.vocab_list, out_seq_len[1][0])\n        self.assertEqual(output_str1, self.beam_search_result[0])\n        self.assertEqual(output_str2, self.beam_search_result[1])\n\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
