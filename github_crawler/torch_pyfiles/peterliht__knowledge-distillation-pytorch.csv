file_path,api_count,code
count_model_size.py,0,"b'\'\'\'Count # of parameters in a trained model\'\'\'\n\nimport argparse\nimport os\nimport numpy as np\nimport torch\nimport utils\nimport model.net as net\nimport model.resnet as resnet\nimport model.wrn as wrn\nimport model.resnext as resnext\nimport utils\n\n\nparser = argparse.ArgumentParser()\n# parser.add_argument(\'--data_dir\', default=\'data/64x64_SIGNS\', help=""Directory for the dataset"")\nparser.add_argument(\'--model\', default=\'resnet18\',\n                    help=""name of the model"")\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\nif __name__ == \'__main__\':\n\n    model_size = 0\n\n    args = parser.parse_args()\n    cnn_dir = \'experiments/cnn_distill\'\n    json_path = os.path.join(cnn_dir, \'params.json\')\n    assert os.path.isfile(json_path), ""No json configuration file found at {}"".format(json_path)\n    params = utils.Params(json_path)\n\n    if args.model == ""resnet18"":\n        model = resnet.ResNet18()\n        model_checkpoint = \'experiments/base_resnet18/best.pth.tar\'\n\n    elif args.model == ""wrn"":\n        model = wrn.wrn(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n        model_checkpoint = \'experiments/base_wrn/best.pth.tar\'\n\n    elif args.model == ""distill_resnext"":\n        model = resnet.ResNet18()\n        model_checkpoint = \'experiments/resnet18_distill/resnext_teacher/best.pth.tar\'\n\n    elif args.model == ""distill_densenet"":\n        model = resnet.ResNet18()\n        model_checkpoint = \'experiments/resnet18_distill/densenet_teacher/best.pth.tar\'\n\n    elif args.model == ""cnn"":\n        model = net.Net(params)\n        model_checkpoint = \'experiments/cnn_distill/best.pth.tar\'\n\n    utils.load_checkpoint(model_checkpoint, model)\n\n    model_size = count_parameters(model)\n    print(""Number of parameters in {} is: {}"".format(args.model, model_size))'"
distillation_analysis.py,5,"b'""""""Analyzes, visualizes knowledge distillation""""""\n\nimport argparse\nimport logging\nimport os\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport utils\nimport model.net as net\nimport model.resnet as resnet\nimport model.data_loader as data_loader\nfrom torchnet.meter import ConfusionMeter\nfrom tqdm import tqdm\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--model_dir\', default=\'experiments/base_model\', help=""Directory of params.json"")\nparser.add_argument(\'--restore_file\', default=\'best\', help=""name of the file in --model_dir \\\n                     containing weights to load"")\nparser.add_argument(\'--dataset\', default=\'dev\', help=""dataset to analze the model on"")\nparser.add_argument(\'--temperature\', type=float, default=1.0, \\\n                    help=""temperature used for softmax output"")\n\n\ndef model_analysis(model, dataloader, params, temperature=1., num_classes=10):\n    """"""\n        Generate Confusion Matrix on evaluation set\n    """"""\n    model.eval()\n    confusion_matrix = ConfusionMeter(num_classes)\n    softmax_scores = []\n    predict_correct = []\n\n    with tqdm(total=len(dataloader)) as t:\n        for idx, (data_batch, labels_batch) in enumerate(dataloader):\n\n            if params.cuda:\n                data_batch, labels_batch = data_batch.cuda(async=True), \\\n                                           labels_batch.cuda(async=True)\n            data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n\n            output_batch = model(data_batch)\n\n            confusion_matrix.add(output_batch.data, labels_batch.data)\n\n            softmax_scores_batch = F.softmax(output_batch/temperature, dim=1)\n            softmax_scores_batch = softmax_scores_batch.data.cpu().numpy()\n            softmax_scores.append(softmax_scores_batch)\n\n            # extract data from torch Variable, move to cpu, convert to numpy arrays\n            output_batch = output_batch.data.cpu().numpy()\n            labels_batch = labels_batch.data.cpu().numpy()\n\n            predict_correct_batch = (np.argmax(output_batch, axis=1) == labels_batch).astype(int)\n            predict_correct.append(np.reshape(predict_correct_batch, (labels_batch.size, 1)))\n\n            t.update()\n\n    softmax_scores = np.vstack(softmax_scores)\n    predict_correct = np.vstack(predict_correct)\n\n    return softmax_scores, predict_correct, confusion_matrix.value().astype(int)\n\n\nif __name__ == \'__main__\':\n    """"""\n        Evaluate the model on the test set.\n    """"""\n    # Load the parameters\n    args = parser.parse_args()\n    json_path = os.path.join(args.model_dir, \'params.json\')\n    assert os.path.isfile(json_path), ""No json configuration file found at {}"".format(json_path)\n    params = utils.Params(json_path)\n\n    # use GPU if available\n    params.cuda = torch.cuda.is_available()     # use GPU is available\n\n    # Set the random seed for reproducible experiments\n    torch.manual_seed(230)\n    if params.cuda: torch.cuda.manual_seed(230)\n        \n    # Get the logger\n    utils.set_logger(os.path.join(args.model_dir, \'analysis.log\'))\n\n    # Create the input data pipeline\n    logging.info(""Loading the dataset..."")\n\n    # fetch dataloaders\n    # train_dl = data_loader.fetch_dataloader(\'train\', params)\n    # dev_dl = data_loader.fetch_dataloader(\'dev\', params)\n    dataloader = data_loader.fetch_dataloader(args.dataset, params)\n\n    logging.info(""- done."")\n\n    # Define the model graph\n    model = resnet.ResNet18().cuda() if params.cuda else resnet.ResNet18()\n\n    # fetch loss function and metrics\n    metrics = resnet.metrics\n    \n    logging.info(""Starting analysis..."")\n\n    # Reload weights from the saved file\n    utils.load_checkpoint(os.path.join(args.model_dir, args.restore_file + \'.pth.tar\'), model)\n\n    # Evaluate and analyze\n    softmax_scores, predict_correct, confusion_matrix = model_analysis(model, dataloader, params,\n                                                                       args.temperature)\n\n    results = {\'softmax_scores\': softmax_scores, \'predict_correct\': predict_correct,\n               \'confusion_matrix\': confusion_matrix}\n\n    for k, v in results.items():\n        filename = args.dataset + \'_temp\' + str(args.temperature) + \'_\' + k + \'.txt\'\n        save_path = os.path.join(args.model_dir, filename)\n        np.savetxt(save_path, v)'"
evaluate.py,8,"b'""""""Evaluates the model""""""\n\nimport argparse\nimport logging\nimport os\n\nimport numpy as np\nimport torch\nfrom torch.autograd import Variable\nimport utils\nimport model.net as net\nimport model.resnet as resnet\nimport model.data_loader as data_loader\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--model_dir\', default=\'experiments/base_model\', help=""Directory of params.json"")\nparser.add_argument(\'--restore_file\', default=\'best\', help=""name of the file in --model_dir \\\n                     containing weights to load"")\n\n\ndef evaluate(model, loss_fn, dataloader, metrics, params):\n    """"""Evaluate the model on `num_steps` batches.\n\n    Args:\n        model: (torch.nn.Module) the neural network\n        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n        params: (Params) hyperparameters\n        num_steps: (int) number of batches to train on, each of size params.batch_size\n    """"""\n\n    # set model to evaluation mode\n    model.eval()\n\n    # summary for current eval loop\n    summ = []\n\n    # compute metrics over the dataset\n    for data_batch, labels_batch in dataloader:\n\n        # move to GPU if available\n        if params.cuda:\n            data_batch, labels_batch = data_batch.cuda(async=True), labels_batch.cuda(async=True)\n        # fetch the next evaluation batch\n        data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n        \n        # compute model output\n        output_batch = model(data_batch)\n        loss = loss_fn(output_batch, labels_batch)\n\n        # extract data from torch Variable, move to cpu, convert to numpy arrays\n        output_batch = output_batch.data.cpu().numpy()\n        labels_batch = labels_batch.data.cpu().numpy()\n\n        # compute all metrics on this batch\n        summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n                         for metric in metrics}\n        summary_batch[\'loss\'] = loss.data[0]\n        summ.append(summary_batch)\n\n    # compute mean of all metrics in summary\n    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n    metrics_string = "" ; "".join(""{}: {:05.3f}"".format(k, v) for k, v in metrics_mean.items())\n    logging.info(""- Eval metrics : "" + metrics_string)\n    return metrics_mean\n\n\n""""""\nThis function duplicates ""evaluate()"" but ignores ""loss_fn"" simply for speedup purpose.\nValidation loss during KD mode would display \'0\' all the time.\nOne can bring that info back by using the fetched teacher outputs during evaluation (refer to train.py)\n""""""\ndef evaluate_kd(model, dataloader, metrics, params):\n    """"""Evaluate the model on `num_steps` batches.\n\n    Args:\n        model: (torch.nn.Module) the neural network\n        loss_fn: a function that takes batch_output and batch_labels and computes the loss for the batch\n        dataloader: (DataLoader) a torch.utils.data.DataLoader object that fetches data\n        metrics: (dict) a dictionary of functions that compute a metric using the output and labels of each batch\n        params: (Params) hyperparameters\n        num_steps: (int) number of batches to train on, each of size params.batch_size\n    """"""\n\n    # set model to evaluation mode\n    model.eval()\n\n    # summary for current eval loop\n    summ = []\n\n    # compute metrics over the dataset\n    for i, (data_batch, labels_batch) in enumerate(dataloader):\n\n        # move to GPU if available\n        if params.cuda:\n            data_batch, labels_batch = data_batch.cuda(async=True), labels_batch.cuda(async=True)\n        # fetch the next evaluation batch\n        data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n        \n        # compute model output\n        output_batch = model(data_batch)\n\n        # loss = loss_fn_kd(output_batch, labels_batch, output_teacher_batch, params)\n        loss = 0.0  #force validation loss to zero to reduce computation time\n\n        # extract data from torch Variable, move to cpu, convert to numpy arrays\n        output_batch = output_batch.data.cpu().numpy()\n        labels_batch = labels_batch.data.cpu().numpy()\n\n        # compute all metrics on this batch\n        summary_batch = {metric: metrics[metric](output_batch, labels_batch)\n                         for metric in metrics}\n        # summary_batch[\'loss\'] = loss.data[0]\n        summary_batch[\'loss\'] = loss\n        summ.append(summary_batch)\n\n    # compute mean of all metrics in summary\n    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]} \n    metrics_string = "" ; "".join(""{}: {:05.3f}"".format(k, v) for k, v in metrics_mean.items())\n    logging.info(""- Eval metrics : "" + metrics_string)\n    return metrics_mean\n\n\n# if __name__ == \'__main__\':\n#     """"""\n#         Evaluate the model on a dataset for one pass.\n#     """"""\n#     # Load the parameters\n#     args = parser.parse_args()\n#     json_path = os.path.join(args.model_dir, \'params.json\')\n#     assert os.path.isfile(json_path), ""No json configuration file found at {}"".format(json_path)\n#     params = utils.Params(json_path)\n\n#     # use GPU if available\n#     params.cuda = torch.cuda.is_available()     # use GPU is available\n\n#     # Set the random seed for reproducible experiments\n#     torch.manual_seed(230)\n#     if params.cuda: torch.cuda.manual_seed(230)\n        \n#     # Get the logger\n#     utils.set_logger(os.path.join(args.model_dir, \'evaluate.log\'))\n\n#     # Create the input data pipeline\n#     logging.info(""Loading the dataset..."")\n\n#     # fetch dataloaders\n#     # train_dl = data_loader.fetch_dataloader(\'train\', params)\n#     dev_dl = data_loader.fetch_dataloader(\'dev\', params)\n\n#     logging.info(""- done."")\n\n#     # Define the model graph\n#     model = resnet.ResNet18().cuda() if params.cuda else resnet.ResNet18()\n#     optimizer = optim.SGD(model.parameters(), lr=params.learning_rate,\n#                           momentum=0.9, weight_decay=5e-4)\n#     # fetch loss function and metrics\n#     loss_fn_kd = net.loss_fn_kd\n#     metrics = resnet.metrics\n    \n#     logging.info(""Starting evaluation..."")\n\n#     # Reload weights from the saved file\n#     utils.load_checkpoint(os.path.join(args.model_dir, args.restore_file + \'.pth.tar\'), model)\n\n#     # Evaluate\n#     test_metrics = evaluate_kd(model, dev_dl, metrics, params)\n#     save_path = os.path.join(args.model_dir, ""metrics_test_{}.json"".format(args.restore_file))\n#     utils.save_dict_to_json(test_metrics, save_path)'"
search_hyperparams.py,0,"b'""""""\n   Peform hyperparemeters search\n\n   A brief definition/clarification of \'params.json\' files:\n\n   ""model_version"": ""resnet18"", # ""base"" models or ""modelname""_distill models\n   ""subset_percent"": 1.0,       # use full (1.0) train set or partial (<1.0) train set\n   ""augmentation"": ""yes"",       # whether to use data augmentation in data_loader\n   ""teacher"": ""densenet"",       # no need to specify this for ""base"" cnn/resnet18\n   ""alpha"": 0.0,                # only used for experiments involving distillation\n   ""temperature"": 1,            # only used for experiments involving distillation\n   ""learning_rate"": 1e-1,       # as the name suggests\n   ""batch_size"": 128,           # for both train/eval\n   ""num_epochs"": 200,           # as the name suggests\n   ""dropout_rate"": 0.5,         # only valid for ""cnn""-related models, not in resnet18\n   ""num_channels"": 32,          # only valid for ""cnn""-related models, not in resnet18\n   ""save_summary_steps"": 100,\n   ""num_workers"": 4\n\n""""""\n\n\nimport argparse\nimport os\nfrom subprocess import check_call\nimport sys\nimport utils\nimport logging\n\n\nPYTHON = sys.executable\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--parent_dir\', default=\'experiments/learning_rate\',\n                    help=\'Directory containing params.json\')\n\ndef launch_training_job(parent_dir, job_name, params):\n    """"""Launch training of the model with a set of hyperparameters in parent_dir/job_name\n\n    Args:\n        model_dir: (string) directory containing config, weights and log\n        data_dir: (string) directory containing the dataset\n        params: (dict) containing hyperparameters\n    """"""\n    # Create a new folder in parent_dir with unique_name ""job_name""\n    model_dir = os.path.join(parent_dir, job_name)\n    if not os.path.exists(model_dir):\n        os.makedirs(model_dir)\n\n    # Write parameters in json file\n    json_path = os.path.join(model_dir, \'params.json\')\n    params.save(json_path)\n\n    # Launch training with this config\n    cmd = ""{python} train.py --model_dir={model_dir}"".format(python=PYTHON,\n                                                             model_dir=model_dir)\n    print(cmd)\n    check_call(cmd, shell=True)\n\n\nif __name__ == ""__main__"":\n    # Load the ""reference"" parameters from parent_dir json file\n    args = parser.parse_args()\n    json_path = os.path.join(args.parent_dir, \'params.json\')\n    assert os.path.isfile(json_path), ""No json configuration file found at {}"".format(json_path)\n    params = utils.Params(json_path)\n\n    # Set the logger\n    utils.set_logger(os.path.join(args.parent_dir, \'search_hyperparameters.log\'))\n\n    \'\'\'\n    Temperature and alpha search for KD on CNN (teacher model picked in params.json)\n    Perform hypersearch (empirical grid): distilling \'temperature\', loss weight \'alpha\'\n    \'\'\'\n\n    # hyperparameters for KD\n    alphas = [0.99, 0.95, 0.5, 0.1, 0.05]\n    temperatures = [20., 10., 8., 6., 4.5, 3., 2., 1.5]\n\n    logging.info(""Searching hyperparameters..."")\n    logging.info(""alphas: {}"".format(alphas))\n    logging.info(""temperatures: {}"".format(temperatures))\n\n    for alpha in alphas:\n        for temperature in temperatures:\n            # [Modify] the relevant parameter in params (others remain unchanged)\n            params.alpha = alpha\n            params.temperature = temperature\n\n            # Launch job (name has to be unique)\n            job_name = ""alpha_{}_Temp_{}"".format(alpha, temperature)\n            launch_training_job(args.parent_dir, job_name, params)'"
synthesize_results.py,0,"b'""""""Aggregates results from the metrics_eval_best_weights.json in a parent folder""""""\n\nimport argparse\nimport json\nimport os\n\nfrom tabulate import tabulate\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\'--parent_dir\', default=\'experiments\',\n                    help=\'Directory containing results of experiments\')\n\n\ndef aggregate_metrics(parent_dir, metrics):\n    """"""Aggregate the metrics of all experiments in folder `parent_dir`.\n\n    Assumes that `parent_dir` contains multiple experiments, with their results stored in\n    `parent_dir/subdir/metrics_dev.json`\n\n    Args:\n        parent_dir: (string) path to directory containing experiments results\n        metrics: (dict) subdir -> {\'accuracy\': ..., ...}\n    """"""\n    # Get the metrics for the folder if it has results from an experiment\n    metrics_file = os.path.join(parent_dir, \'metrics_val_best_weights.json\')\n    if os.path.isfile(metrics_file):\n        with open(metrics_file, \'r\') as f:\n            metrics[parent_dir] = json.load(f)\n\n    # Check every subdirectory of parent_dir\n    for subdir in os.listdir(parent_dir):\n        if not os.path.isdir(os.path.join(parent_dir, subdir)):\n            continue\n        else:\n            aggregate_metrics(os.path.join(parent_dir, subdir), metrics)\n\n\ndef metrics_to_table(metrics):\n    # Get the headers from the first subdir. Assumes everything has the same metrics\n    headers = metrics[list(metrics.keys())[0]].keys()\n    table = [[subdir] + [values[h] for h in headers] for subdir, values in metrics.items()]\n    res = tabulate(table, headers, tablefmt=\'pipe\')\n\n    return res\n\n\nif __name__ == ""__main__"":\n    args = parser.parse_args()\n\n    # Aggregate metrics from args.parent_dir directory\n    metrics = dict()\n    aggregate_metrics(args.parent_dir, metrics)\n    table = metrics_to_table(metrics)\n\n    # Display the table to terminal\n    print(table)\n\n    # Save results in parent_dir/results.md\n    save_file = os.path.join(args.parent_dir, ""results.md"")\n    with open(save_file, \'w\') as f:\n        f.write(table)'"
train.py,15,"b'""""""Main entrance for train/eval with/without KD on CIFAR-10""""""\n\nimport argparse\nimport logging\nimport os\nimport time\nimport math\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.autograd import Variable\nfrom tqdm import tqdm\n\nimport utils\nimport model.net as net\nimport model.data_loader as data_loader\nimport model.resnet as resnet\nimport model.wrn as wrn\nimport model.densenet as densenet\nimport model.resnext as resnext\nimport model.preresnet as preresnet\nfrom evaluate import evaluate, evaluate_kd\n\nparser = argparse.ArgumentParser()\n# parser.add_argument(\'--data_dir\', default=\'data/64x64_SIGNS\', help=""Directory for the dataset"")\nparser.add_argument(\'--model_dir\', default=\'experiments/base_model\',\n                    help=""Directory containing params.json"")\nparser.add_argument(\'--restore_file\', default=None,\n                    help=""Optional, name of the file in --model_dir \\\n                    containing weights to reload before training"")  # \'best\' or \'train\'\n\n\ndef train(model, optimizer, loss_fn, dataloader, metrics, params):\n    """"""Train the model on `num_steps` batches\n\n    Args:\n        model: (torch.nn.Module) the neural network\n        optimizer: (torch.optim) optimizer for parameters of model\n        loss_fn: \n        dataloader: \n        metrics: (dict) \n        params: (Params) hyperparameters\n    """"""\n\n    # set model to training mode\n    model.train()\n\n    # summary for current training loop and a running average object for loss\n    summ = []\n    loss_avg = utils.RunningAverage()\n\n    # Use tqdm for progress bar\n    with tqdm(total=len(dataloader)) as t:\n        for i, (train_batch, labels_batch) in enumerate(dataloader):\n            # move to GPU if available\n            if params.cuda:\n                train_batch, labels_batch = train_batch.cuda(async=True), \\\n                                            labels_batch.cuda(async=True)\n            # convert to torch Variables\n            train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n\n            # compute model output and loss\n            output_batch = model(train_batch)\n            loss = loss_fn(output_batch, labels_batch)\n\n            # clear previous gradients, compute gradients of all variables wrt loss\n            optimizer.zero_grad()\n            loss.backward()\n\n            # performs updates using calculated gradients\n            optimizer.step()\n\n            # Evaluate summaries only once in a while\n            if i % params.save_summary_steps == 0:\n                # extract data from torch Variable, move to cpu, convert to numpy arrays\n                output_batch = output_batch.data.cpu().numpy()\n                labels_batch = labels_batch.data.cpu().numpy()\n\n                # compute all metrics on this batch\n                summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n                                 for metric in metrics}\n                summary_batch[\'loss\'] = loss.data[0]\n                summ.append(summary_batch)\n\n            # update the average loss\n            loss_avg.update(loss.data[0])\n\n            t.set_postfix(loss=\'{:05.3f}\'.format(loss_avg()))\n            t.update()\n\n    # compute mean of all metrics in summary\n    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]}\n    metrics_string = "" ; "".join(""{}: {:05.3f}"".format(k, v) for k, v in metrics_mean.items())\n    logging.info(""- Train metrics: "" + metrics_string)\n\n\ndef train_and_evaluate(model, train_dataloader, val_dataloader, optimizer,\n                       loss_fn, metrics, params, model_dir, restore_file=None):\n    """"""Train the model and evaluate every epoch.\n\n    Args:\n        model: (torch.nn.Module) the neural network\n        params: (Params) hyperparameters\n        model_dir: (string) directory containing config, weights and log\n        restore_file: (string) - name of file to restore from (without its extension .pth.tar)\n    """"""\n    # reload weights from restore_file if specified\n    if restore_file is not None:\n        restore_path = os.path.join(args.model_dir, args.restore_file + \'.pth.tar\')\n        logging.info(""Restoring parameters from {}"".format(restore_path))\n        utils.load_checkpoint(restore_path, model, optimizer)\n\n    best_val_acc = 0.0\n\n    # learning rate schedulers for different models:\n    if params.model_version == ""resnet18"":\n        scheduler = StepLR(optimizer, step_size=150, gamma=0.1)\n    # for cnn models, num_epoch is always < 100, so it\'s intentionally not using scheduler here\n    elif params.model_version == ""cnn"":\n        scheduler = StepLR(optimizer, step_size=100, gamma=0.2)\n\n    for epoch in range(params.num_epochs):\n     \n        scheduler.step()\n     \n        # Run one epoch\n        logging.info(""Epoch {}/{}"".format(epoch + 1, params.num_epochs))\n\n        # compute number of batches in one epoch (one full pass over the training set)\n        train(model, optimizer, loss_fn, train_dataloader, metrics, params)\n\n        # Evaluate for one epoch on validation set\n        val_metrics = evaluate(model, loss_fn, val_dataloader, metrics, params)        \n\n        val_acc = val_metrics[\'accuracy\']\n        is_best = val_acc>=best_val_acc\n\n        # Save weights\n        utils.save_checkpoint({\'epoch\': epoch + 1,\n                               \'state_dict\': model.state_dict(),\n                               \'optim_dict\' : optimizer.state_dict()},\n                               is_best=is_best,\n                               checkpoint=model_dir)\n\n        # If best_eval, best_save_path\n        if is_best:\n            logging.info(""- Found new best accuracy"")\n            best_val_acc = val_acc\n\n            # Save best val metrics in a json file in the model directory\n            best_json_path = os.path.join(model_dir, ""metrics_val_best_weights.json"")\n            utils.save_dict_to_json(val_metrics, best_json_path)\n\n        # Save latest val metrics in a json file in the model directory\n        last_json_path = os.path.join(model_dir, ""metrics_val_last_weights.json"")\n        utils.save_dict_to_json(val_metrics, last_json_path)\n\n\n# Helper function: get [batch_idx, teacher_outputs] list by running teacher model once\ndef fetch_teacher_outputs(teacher_model, dataloader, params):\n    # set teacher_model to evaluation mode\n    teacher_model.eval()\n    teacher_outputs = []\n    for i, (data_batch, labels_batch) in enumerate(dataloader):\n        if params.cuda:\n            data_batch, labels_batch = data_batch.cuda(async=True), \\\n                                        labels_batch.cuda(async=True)\n        data_batch, labels_batch = Variable(data_batch), Variable(labels_batch)\n\n        output_teacher_batch = teacher_model(data_batch).data.cpu().numpy()\n        teacher_outputs.append(output_teacher_batch)\n\n    return teacher_outputs\n\n\n# Defining train_kd & train_and_evaluate_kd functions\ndef train_kd(model, teacher_outputs, optimizer, loss_fn_kd, dataloader, metrics, params):\n    """"""Train the model on `num_steps` batches\n\n    Args:\n        model: (torch.nn.Module) the neural network\n        optimizer: (torch.optim) optimizer for parameters of model\n        loss_fn_kd: \n        dataloader: \n        metrics: (dict) \n        params: (Params) hyperparameters\n    """"""\n\n    # set model to training mode\n    model.train()\n    # teacher_model.eval()\n\n    # summary for current training loop and a running average object for loss\n    summ = []\n    loss_avg = utils.RunningAverage()\n\n    # Use tqdm for progress bar\n    with tqdm(total=len(dataloader)) as t:\n        for i, (train_batch, labels_batch) in enumerate(dataloader):\n            # move to GPU if available\n            if params.cuda:\n                train_batch, labels_batch = train_batch.cuda(async=True), \\\n                                            labels_batch.cuda(async=True)\n            # convert to torch Variables\n            train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n\n            # compute model output, fetch teacher output, and compute KD loss\n            output_batch = model(train_batch)\n\n            # get one batch output from teacher_outputs list\n            output_teacher_batch = torch.from_numpy(teacher_outputs[i])\n            if params.cuda:\n                output_teacher_batch = output_teacher_batch.cuda(async=True)\n            output_teacher_batch = Variable(output_teacher_batch, requires_grad=False)\n\n            loss = loss_fn_kd(output_batch, labels_batch, output_teacher_batch, params)\n\n            # clear previous gradients, compute gradients of all variables wrt loss\n            optimizer.zero_grad()\n            loss.backward()\n\n            # performs updates using calculated gradients\n            optimizer.step()\n\n            # Evaluate summaries only once in a while\n            if i % params.save_summary_steps == 0:\n                # extract data from torch Variable, move to cpu, convert to numpy arrays\n                output_batch = output_batch.data.cpu().numpy()\n                labels_batch = labels_batch.data.cpu().numpy()\n\n                # compute all metrics on this batch\n                summary_batch = {metric:metrics[metric](output_batch, labels_batch)\n                                 for metric in metrics}\n                summary_batch[\'loss\'] = loss.data[0]\n                summ.append(summary_batch)\n\n            # update the average loss\n            loss_avg.update(loss.data[0])\n\n            t.set_postfix(loss=\'{:05.3f}\'.format(loss_avg()))\n            t.update()\n\n    # compute mean of all metrics in summary\n    metrics_mean = {metric:np.mean([x[metric] for x in summ]) for metric in summ[0]}\n    metrics_string = "" ; "".join(""{}: {:05.3f}"".format(k, v) for k, v in metrics_mean.items())\n    logging.info(""- Train metrics: "" + metrics_string)\n\n\ndef train_and_evaluate_kd(model, teacher_model, train_dataloader, val_dataloader, optimizer,\n                       loss_fn_kd, metrics, params, model_dir, restore_file=None):\n    """"""Train the model and evaluate every epoch.\n\n    Args:\n        model: (torch.nn.Module) the neural network\n        params: (Params) hyperparameters\n        model_dir: (string) directory containing config, weights and log\n        restore_file: (string) - file to restore (without its extension .pth.tar)\n    """"""\n    # reload weights from restore_file if specified\n    if restore_file is not None:\n        restore_path = os.path.join(args.model_dir, args.restore_file + \'.pth.tar\')\n        logging.info(""Restoring parameters from {}"".format(restore_path))\n        utils.load_checkpoint(restore_path, model, optimizer)\n\n    best_val_acc = 0.0\n    \n    # Tensorboard logger setup\n    # board_logger = utils.Board_Logger(os.path.join(model_dir, \'board_logs\'))\n\n    # fetch teacher outputs using teacher_model under eval() mode\n    loading_start = time.time()\n    teacher_model.eval()\n    teacher_outputs = fetch_teacher_outputs(teacher_model, train_dataloader, params)\n    elapsed_time = math.ceil(time.time() - loading_start)\n    logging.info(""- Finished computing teacher outputs after {} secs.."".format(elapsed_time))\n\n    # learning rate schedulers for different models:\n    if params.model_version == ""resnet18_distill"":\n        scheduler = StepLR(optimizer, step_size=150, gamma=0.1)\n    # for cnn models, num_epoch is always < 100, so it\'s intentionally not using scheduler here\n    elif params.model_version == ""cnn_distill"": \n        scheduler = StepLR(optimizer, step_size=100, gamma=0.2) \n\n    for epoch in range(params.num_epochs):\n\n        scheduler.step()\n\n        # Run one epoch\n        logging.info(""Epoch {}/{}"".format(epoch + 1, params.num_epochs))\n\n        # compute number of batches in one epoch (one full pass over the training set)\n        train_kd(model, teacher_outputs, optimizer, loss_fn_kd, train_dataloader,\n                 metrics, params)\n\n        # Evaluate for one epoch on validation set\n        val_metrics = evaluate_kd(model, val_dataloader, metrics, params)\n\n        val_acc = val_metrics[\'accuracy\']\n        is_best = val_acc>=best_val_acc\n\n        # Save weights\n        utils.save_checkpoint({\'epoch\': epoch + 1,\n                               \'state_dict\': model.state_dict(),\n                               \'optim_dict\' : optimizer.state_dict()},\n                               is_best=is_best,\n                               checkpoint=model_dir)\n\n        # If best_eval, best_save_path\n        if is_best:\n            logging.info(""- Found new best accuracy"")\n            best_val_acc = val_acc\n\n            # Save best val metrics in a json file in the model directory\n            best_json_path = os.path.join(model_dir, ""metrics_val_best_weights.json"")\n            utils.save_dict_to_json(val_metrics, best_json_path)\n\n        # Save latest val metrics in a json file in the model directory\n        last_json_path = os.path.join(model_dir, ""metrics_val_last_weights.json"")\n        utils.save_dict_to_json(val_metrics, last_json_path)\n\n\n        # #============ TensorBoard logging: uncomment below to turn in on ============#\n        # # (1) Log the scalar values\n        # info = {\n        #     \'val accuracy\': val_acc\n        # }\n\n        # for tag, value in info.items():\n        #     board_logger.scalar_summary(tag, value, epoch+1)\n\n        # # (2) Log values and gradients of the parameters (histogram)\n        # for tag, value in model.named_parameters():\n        #     tag = tag.replace(\'.\', \'/\')\n        #     board_logger.histo_summary(tag, value.data.cpu().numpy(), epoch+1)\n        #     # board_logger.histo_summary(tag+\'/grad\', value.grad.data.cpu().numpy(), epoch+1)\n\n\nif __name__ == \'__main__\':\n\n    # Load the parameters from json file\n    args = parser.parse_args()\n    json_path = os.path.join(args.model_dir, \'params.json\')\n    assert os.path.isfile(json_path), ""No json configuration file found at {}"".format(json_path)\n    params = utils.Params(json_path)\n\n    # use GPU if available\n    params.cuda = torch.cuda.is_available()\n\n    # Set the random seed for reproducible experiments\n    random.seed(230)\n    torch.manual_seed(230)\n    if params.cuda: torch.cuda.manual_seed(230)\n\n    # Set the logger\n    utils.set_logger(os.path.join(args.model_dir, \'train.log\'))\n\n    # Create the input data pipeline\n    logging.info(""Loading the datasets..."")\n\n    # fetch dataloaders, considering full-set vs. sub-set scenarios\n    if params.subset_percent < 1.0:\n        train_dl = data_loader.fetch_subset_dataloader(\'train\', params)\n    else:\n        train_dl = data_loader.fetch_dataloader(\'train\', params)\n    \n    dev_dl = data_loader.fetch_dataloader(\'dev\', params)\n\n    logging.info(""- done."")\n\n    """"""Based on the model_version, determine model/optimizer and KD training mode\n       WideResNet and DenseNet were trained on multi-GPU; need to specify a dummy\n       nn.DataParallel module to correctly load the model parameters\n    """"""\n    if ""distill"" in params.model_version:\n\n        # train a 5-layer CNN or a 18-layer ResNet with knowledge distillation\n        if params.model_version == ""cnn_distill"":\n            model = net.Net(params).cuda() if params.cuda else net.Net(params)\n            optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n            # fetch loss function and metrics definition in model files\n            loss_fn_kd = net.loss_fn_kd\n            metrics = net.metrics\n        \n        elif params.model_version == \'resnet18_distill\':\n            model = resnet.ResNet18().cuda() if params.cuda else resnet.ResNet18()\n            optimizer = optim.SGD(model.parameters(), lr=params.learning_rate,\n                                  momentum=0.9, weight_decay=5e-4)\n            # fetch loss function and metrics definition in model files\n            loss_fn_kd = net.loss_fn_kd\n            metrics = resnet.metrics\n\n        """""" \n            Specify the pre-trained teacher models for knowledge distillation\n            Important note: wrn/densenet/resnext/preresnet were pre-trained models using multi-GPU,\n            therefore need to call ""nn.DaraParallel"" to correctly load the model weights\n            Trying to run on CPU will then trigger errors (too time-consuming anyway)!\n        """"""\n        if params.teacher == ""resnet18"":\n            teacher_model = resnet.ResNet18()\n            teacher_checkpoint = \'experiments/base_resnet18/best.pth.tar\'\n            teacher_model = teacher_model.cuda() if params.cuda else teacher_model\n\n        elif params.teacher == ""wrn"":\n            teacher_model = wrn.WideResNet(depth=28, num_classes=10, widen_factor=10,\n                                           dropRate=0.3)\n            teacher_checkpoint = \'experiments/base_wrn/best.pth.tar\'\n            teacher_model = nn.DataParallel(teacher_model).cuda()\n\n        elif params.teacher == ""densenet"":\n            teacher_model = densenet.DenseNet(depth=100, growthRate=12)\n            teacher_checkpoint = \'experiments/base_densenet/best.pth.tar\'\n            teacher_model = nn.DataParallel(teacher_model).cuda()\n\n        elif params.teacher == ""resnext29"":\n            teacher_model = resnext.CifarResNeXt(cardinality=8, depth=29, num_classes=10)\n            teacher_checkpoint = \'experiments/base_resnext29/best.pth.tar\'\n            teacher_model = nn.DataParallel(teacher_model).cuda()\n\n        elif params.teacher == ""preresnet110"":\n            teacher_model = preresnet.PreResNet(depth=110, num_classes=10)\n            teacher_checkpoint = \'experiments/base_preresnet110/best.pth.tar\'\n            teacher_model = nn.DataParallel(teacher_model).cuda()\n\n        utils.load_checkpoint(teacher_checkpoint, teacher_model)\n\n        # Train the model with KD\n        logging.info(""Experiment - model version: {}"".format(params.model_version))\n        logging.info(""Starting training for {} epoch(s)"".format(params.num_epochs))\n        logging.info(""First, loading the teacher model and computing its outputs..."")\n        train_and_evaluate_kd(model, teacher_model, train_dl, dev_dl, optimizer, loss_fn_kd,\n                              metrics, params, args.model_dir, args.restore_file)\n\n    # non-KD mode: regular training of the baseline CNN or ResNet-18\n    else:\n        if params.model_version == ""cnn"":\n            model = net.Net(params).cuda() if params.cuda else net.Net(params)\n            optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n            # fetch loss function and metrics\n            loss_fn = net.loss_fn\n            metrics = net.metrics\n\n        elif params.model_version == ""resnet18"":\n            model = resnet.ResNet18().cuda() if params.cuda else resnet.ResNet18()\n            optimizer = optim.SGD(model.parameters(), lr=params.learning_rate,\n                                  momentum=0.9, weight_decay=5e-4)\n            # fetch loss function and metrics\n            loss_fn = resnet.loss_fn\n            metrics = resnet.metrics\n\n        # elif params.model_version == ""wrn"":\n        #     model = wrn.wrn(depth=28, num_classes=10, widen_factor=10, dropRate=0.3)\n        #     model = model.cuda() if params.cuda else model\n        #     optimizer = optim.SGD(model.parameters(), lr=params.learning_rate,\n        #                           momentum=0.9, weight_decay=5e-4)\n        #     # fetch loss function and metrics\n        #     loss_fn = wrn.loss_fn\n        #     metrics = wrn.metrics\n\n        # Train the model\n        logging.info(""Starting training for {} epoch(s)"".format(params.num_epochs))\n        train_and_evaluate(model, train_dl, dev_dl, optimizer, loss_fn, metrics, params,\n                           args.model_dir, args.restore_file)'"
utils.py,6,"b'""""""\nTensorboard logger code referenced from:\nhttps://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/04-utils/\nOther helper functions:\nhttps://github.com/cs230-stanford/cs230-stanford.github.io\n""""""\n\nimport json\nimport logging\nimport os\nimport shutil\nimport torch\nfrom collections import OrderedDict\n\nimport tensorflow as tf\nimport numpy as np\nimport scipy.misc \ntry:\n    from StringIO import StringIO  # Python 2.7\nexcept ImportError:\n    from io import BytesIO         # Python 3.x\n\n\nclass Params():\n    """"""Class that loads hyperparameters from a json file.\n\n    Example:\n    ```\n    params = Params(json_path)\n    print(params.learning_rate)\n    params.learning_rate = 0.5  # change the value of learning_rate in params\n    ```\n    """"""\n\n    def __init__(self, json_path):\n        with open(json_path) as f:\n            params = json.load(f)\n            self.__dict__.update(params)\n\n    def save(self, json_path):\n        with open(json_path, \'w\') as f:\n            json.dump(self.__dict__, f, indent=4)\n            \n    def update(self, json_path):\n        """"""Loads parameters from json file""""""\n        with open(json_path) as f:\n            params = json.load(f)\n            self.__dict__.update(params)\n\n    @property\n    def dict(self):\n        """"""Gives dict-like access to Params instance by `params.dict[\'learning_rate\']""""""\n        return self.__dict__\n\n\nclass RunningAverage():\n    """"""A simple class that maintains the running average of a quantity\n    \n    Example:\n    ```\n    loss_avg = RunningAverage()\n    loss_avg.update(2)\n    loss_avg.update(4)\n    loss_avg() = 3\n    ```\n    """"""\n    def __init__(self):\n        self.steps = 0\n        self.total = 0\n    \n    def update(self, val):\n        self.total += val\n        self.steps += 1\n    \n    def __call__(self):\n        return self.total/float(self.steps)\n        \n    \ndef set_logger(log_path):\n    """"""Set the logger to log info in terminal and file `log_path`.\n\n    In general, it is useful to have a logger so that every output to the terminal is saved\n    in a permanent file. Here we save it to `model_dir/train.log`.\n\n    Example:\n    ```\n    logging.info(""Starting training..."")\n    ```\n\n    Args:\n        log_path: (string) where to log\n    """"""\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n\n    if not logger.handlers:\n        # Logging to a file\n        file_handler = logging.FileHandler(log_path)\n        file_handler.setFormatter(logging.Formatter(\'%(asctime)s:%(levelname)s: %(message)s\'))\n        logger.addHandler(file_handler)\n\n        # Logging to console\n        stream_handler = logging.StreamHandler()\n        stream_handler.setFormatter(logging.Formatter(\'%(message)s\'))\n        logger.addHandler(stream_handler)\n\n\ndef save_dict_to_json(d, json_path):\n    """"""Saves dict of floats in json file\n\n    Args:\n        d: (dict) of float-castable values (np.float, int, float, etc.)\n        json_path: (string) path to json file\n    """"""\n    with open(json_path, \'w\') as f:\n        # We need to convert the values to float for json (it doesn\'t accept np.array, np.float, )\n        d = {k: float(v) for k, v in d.items()}\n        json.dump(d, f, indent=4)\n\n\ndef save_checkpoint(state, is_best, checkpoint):\n    """"""Saves model and training parameters at checkpoint + \'last.pth.tar\'. If is_best==True, also saves\n    checkpoint + \'best.pth.tar\'\n\n    Args:\n        state: (dict) contains model\'s state_dict, may contain other keys such as epoch, optimizer state_dict\n        is_best: (bool) True if it is the best model seen till now\n        checkpoint: (string) folder where parameters are to be saved\n    """"""\n    filepath = os.path.join(checkpoint, \'last.pth.tar\')\n    if not os.path.exists(checkpoint):\n        print(""Checkpoint Directory does not exist! Making directory {}"".format(checkpoint))\n        os.mkdir(checkpoint)\n    else:\n        print(""Checkpoint Directory exists! "")\n    torch.save(state, filepath)\n    if is_best:\n        shutil.copyfile(filepath, os.path.join(checkpoint, \'best.pth.tar\'))\n\n\ndef load_checkpoint(checkpoint, model, optimizer=None):\n    """"""Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n    optimizer assuming it is present in checkpoint.\n\n    Args:\n        checkpoint: (string) filename which needs to be loaded\n        model: (torch.nn.Module) model for which the parameters are loaded\n        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n    """"""\n    if not os.path.exists(checkpoint):\n        raise(""File doesn\'t exist {}"".format(checkpoint))\n    if torch.cuda.is_available():\n        checkpoint = torch.load(checkpoint)\n    else:\n        # this helps avoid errors when loading single-GPU-trained weights onto CPU-model\n        checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n\n    model.load_state_dict(checkpoint[\'state_dict\'])\n\n    if optimizer:\n        optimizer.load_state_dict(checkpoint[\'optim_dict\'])\n\n    return checkpoint\n\n\nclass Board_Logger(object):\n    """"""Tensorboard log utility""""""\n    \n    def __init__(self, log_dir):\n        """"""Create a summary writer logging to log_dir.""""""\n        self.writer = tf.summary.FileWriter(log_dir)\n\n    def scalar_summary(self, tag, value, step):\n        """"""Log a scalar variable.""""""\n        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n        self.writer.add_summary(summary, step)\n\n    def image_summary(self, tag, images, step):\n        """"""Log a list of images.""""""\n\n        img_summaries = []\n        for i, img in enumerate(images):\n            # Write the image to a string\n            try:\n                s = StringIO()\n            except:\n                s = BytesIO()\n            scipy.misc.toimage(img).save(s, format=""png"")\n\n            # Create an Image object\n            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n                                       height=img.shape[0],\n                                       width=img.shape[1])\n            # Create a Summary value\n            img_summaries.append(tf.Summary.Value(tag=\'%s/%d\' % (tag, i), image=img_sum))\n\n        # Create and write Summary\n        summary = tf.Summary(value=img_summaries)\n        self.writer.add_summary(summary, step)\n        \n    def histo_summary(self, tag, values, step, bins=1000):\n        """"""Log a histogram of the tensor of values.""""""\n\n        # Create a histogram using numpy\n        counts, bin_edges = np.histogram(values, bins=bins)\n\n        # Fill the fields of the histogram proto\n        hist = tf.HistogramProto()\n        hist.min = float(np.min(values))\n        hist.max = float(np.max(values))\n        hist.num = int(np.prod(values.shape))\n        hist.sum = float(np.sum(values))\n        hist.sum_squares = float(np.sum(values**2))\n\n        # Drop the start of the first bin\n        bin_edges = bin_edges[1:]\n\n        # Add bin edges and counts\n        for edge in bin_edges:\n            hist.bucket_limit.append(edge)\n        for c in counts:\n            hist.bucket.append(c)\n\n        # Create and write Summary\n        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n        self.writer.add_summary(summary, step)\n        self.writer.flush()'"
mnist/distill_mnist.py,12,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport os\nimport time\nstart_time = time.time()\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=128, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=1000, metavar=\'N\',\n                    help=\'input batch size for testing (default: 1000)\')\nparser.add_argument(\'--epochs\', type=int, default=10, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./data_mnist\', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\n\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./data_mnist\', train=False, transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n\nclass teacherNet(nn.Module):\n    def __init__(self):\n        super(teacherNet, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 1200)\n        self.fc2 = nn.Linear(1200, 1200)\n        self.fc3 = nn.Linear(1200, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, p=0.8, training=self.training)\n        x = F.relu(self.fc2(x))\n        x = F.dropout(x, p=0.8, training=self.training)\n        x = self.fc3(x)\n        return x\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 800)\n        self.fc2 = nn.Linear(800, 800)\n        self.fc3 = nn.Linear(800, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nteacher_model = teacherNet()\nteacher_model.load_state_dict(torch.load(\'teacher_MLP.pth.tar\'))\n\n\nmodel = Net()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\ndef distillation(y, labels, teacher_scores, T, alpha):\n    return nn.KLDivLoss()(F.log_softmax(y/T), F.softmax(teacher_scores/T)) * (T*T * 2.0 * alpha) + F.cross_entropy(y, labels) * (1. - alpha)\n\n\ndef train(epoch, model, loss_fn):\n    model.train()\n    teacher_model.eval()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        teacher_output = teacher_model(data)\n        teacher_output = teacher_output.detach()\n        # teacher_output = Variable(teacher_output.data, requires_grad=False) #alternative approach to load teacher_output\n        loss = loss_fn(output, target, teacher_output, T=20.0, alpha=0.7)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef train_evaluate(model):\n    model.eval()\n    train_loss = 0\n    correct = 0\n    for data, target in train_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        train_loss += F.cross_entropy(output, target).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        train_loss, correct, len(train_loader.dataset),\n        100. * correct / len(train_loader.dataset)))\n\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        # test_loss += F.cross_entropy(output, target).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nfor epoch in range(1, args.epochs + 1):\n    train(epoch, model, loss_fn=distillation)\n    train_evaluate(model)\n    test(model)\n\n\ntorch.save(model.state_dict(), \'distill.pth.tar\')\n# the_model = Net()\n# the_model.load_state_dict(torch.load(\'student.pth.tar\'))\n\n# test(the_model)\n# for data, target in test_loader:\n#     data, target = Variable(data, volatile=True), Variable(target)\n#     teacher_out = the_model(data)\n# print(teacher_out)\nprint(""--- %s seconds ---"" % (time.time() - start_time))\n\n\n\n'"
mnist/distill_mnist_unlabeled.py,12,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport os\nimport time\nstart_time = time.time()\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=128, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=1000, metavar=\'N\',\n                    help=\'input batch size for testing (default: 1000)\')\nparser.add_argument(\'--epochs\', type=int, default=10, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./data_mnist\', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\n\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./data_mnist\', train=False, transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n\nclass teacherNet(nn.Module):\n    def __init__(self):\n        super(teacherNet, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 1200)\n        self.fc2 = nn.Linear(1200, 1200)\n        self.fc3 = nn.Linear(1200, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, p=0.8, training=self.training)\n        x = F.relu(self.fc2(x))\n        x = F.dropout(x, p=0.8, training=self.training)\n        x = self.fc3(x)\n        return x\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 800)\n        self.fc2 = nn.Linear(800, 800)\n        self.fc3 = nn.Linear(800, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nteacher_model = teacherNet()\nteacher_model.load_state_dict(torch.load(\'teacher_MLP.pth.tar\'))\n\n\nmodel = Net()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\ndef distill_unlabeled(y, teacher_scores, T):\n    return nn.KLDivLoss()(F.log_softmax(y/T), F.softmax(teacher_scores/T)) * T * T\n\n\ndef train(epoch, model, loss_fn):\n    model.train()\n    teacher_model.eval()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        teacher_output = teacher_model(data)\n        teacher_output = teacher_output.detach()\n        # teacher_output = Variable(teacher_output.data, requires_grad=False) #alternative approach to load teacher_output\n        loss = loss_fn(output, teacher_output, T=10.0)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef train_evaluate(model):\n    model.eval()\n    train_loss = 0\n    correct = 0\n    for data, target in train_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        # train_loss += F.cross_entropy(output, target).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        train_loss, correct, len(train_loader.dataset),\n        100. * correct / len(train_loader.dataset)))\n\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        # test_loss += F.cross_entropy(output, target).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nfor epoch in range(1, args.epochs + 1):\n    train(epoch, model, loss_fn=distill_unlabeled)\n    train_evaluate(model)\n    test(model)\n\n\ntorch.save(model.state_dict(), \'distill_unlabeled.pth.tar\')\n# the_model = Net()\n# the_model.load_state_dict(torch.load(\'student.pth.tar\'))\n\n# test(the_model)\n# for data, target in test_loader:\n#     data, target = Variable(data, volatile=True), Variable(target)\n#     teacher_out = the_model(data)\n# print(teacher_out)\nprint(""--- %s seconds ---"" % (time.time() - start_time))\n\n\n\n'"
mnist/student_mnist.py,11,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport os\nimport time\nstart_time = time.time()\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=128, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=1000, metavar=\'N\',\n                    help=\'input batch size for testing (default: 1000)\')\nparser.add_argument(\'--epochs\', type=int, default=10, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./data_mnist\', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./data_mnist\', train=False, transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 800)\n        self.fc2 = nn.Linear(800, 800)\n        self.fc3 = nn.Linear(800, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nmodel = Net()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n# criterion = nn.CrossEntropyLoss()\n# def kd_cross_entropy(logits, target):\n#     loss_data = F.cross_entropy(logits, target)\n#     loss_kd = 0.8 * F.cross_entropy(logits/8.0, target/1.01)\n#     loss = loss_data + loss_kd\n#     return loss\n\n# def distillation(y, labels, teacher_scores, T, alpha):\n#     return F.kl_div(F.log_softmax(y/T), F.softmax(teacher_scores/T)) * (T*T * 2. * alpha) \\\n#     + F.cross_entropy(y, labels) * (1. - alpha)\n\n# def distillation(y, labels, teacher_scores, T, alpha):\n#     return F.mse_loss(F.softmax(y/T), F.softmax(teacher_scores/T)) * (T*T * 2. * alpha) + F.cross_entropy(y, labels) * (1. - alpha)\n\n\n\ndef train(epoch, model):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        # loss = distillation(output, target, teacher_output, T=3, alpha=0.5)\n        # loss = F.mse_loss(F.softmax(output/3.0), F.softmax(teacher_output/3.0))\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef train_evaluate(model):\n    model.eval()\n    train_loss = 0\n    correct = 0\n    for data, target in train_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        train_loss += F.cross_entropy(output, target).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        train_loss, correct, len(train_loader.dataset),\n        100. * correct / len(train_loader.dataset)))\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        # test_loss += F.cross_entropy(output, target).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nfor epoch in range(1, args.epochs + 1):\n    train(epoch, model)\n    train_evaluate(model)\n    test(model)\n\n\ntorch.save(model.state_dict(), \'student.pth.tar\')\n# the_model = Net()\n# the_model.load_state_dict(torch.load(\'student.pth.tar\'))\n\n# test(the_model)\n# for data, target in test_loader:\n#     data, target = Variable(data, volatile=True), Variable(target)\n#     teacher_out = the_model(data)\n# print(teacher_out)\nprint(""--- %s seconds ---"" % (time.time() - start_time))'"
mnist/teacher_mnist.py,11,"b'from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport os\nimport time\nstart_time = time.time()\n\n# Training settings\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST Example\')\nparser.add_argument(\'--batch-size\', type=int, default=128, metavar=\'N\',\n                    help=\'input batch size for training (default: 64)\')\nparser.add_argument(\'--test-batch-size\', type=int, default=1000, metavar=\'N\',\n                    help=\'input batch size for testing (default: 1000)\')\nparser.add_argument(\'--epochs\', type=int, default=50, metavar=\'N\',\n                    help=\'number of epochs to train (default: 10)\')\nparser.add_argument(\'--lr\', type=float, default=0.01, metavar=\'LR\',\n                    help=\'learning rate (default: 0.01)\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, metavar=\'M\',\n                    help=\'SGD momentum (default: 0.5)\')\nparser.add_argument(\'--no-cuda\', action=\'store_true\', default=False,\n                    help=\'disables CUDA training\')\nparser.add_argument(\'--seed\', type=int, default=1, metavar=\'S\',\n                    help=\'random seed (default: 1)\')\nparser.add_argument(\'--log-interval\', type=int, default=10, metavar=\'N\',\n                    help=\'how many batches to wait before logging training status\')\nargs = parser.parse_args()\nargs.cuda = not args.no_cuda and torch.cuda.is_available()\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n\n\nkwargs = {\'num_workers\': 1, \'pin_memory\': True} if args.cuda else {}\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./data_mnist\', train=True, download=True,\n                   transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.batch_size, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(\'./data_mnist\', train=False, transform=transforms.Compose([\n                       transforms.ToTensor(),\n                       transforms.Normalize((0.1307,), (0.3081,))\n                   ])),\n    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 1200)\n        self.fc2 = nn.Linear(1200, 1200)\n        self.fc3 = nn.Linear(1200, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, p=0.8, training=self.training)\n        x = F.relu(self.fc2(x))\n        x = F.dropout(x, p=0.8, training=self.training)\n        x = self.fc3(x)\n        return x\n\nmodel = Net()\nif args.cuda:\n    model.cuda()\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum,\n                      weight_decay=5e-4)\n\ndef train(epoch, model):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data), Variable(target)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print(\'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0]))\n\ndef train_evaluate(model):\n    model.eval()\n    train_loss = 0\n    correct = 0\n    for data, target in train_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        train_loss += F.cross_entropy(output, target).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    print(\'\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        train_loss, correct, len(train_loader.dataset),\n        100. * correct / len(train_loader.dataset)))\n\n\ndef test(model):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    for data, target in test_loader:\n        if args.cuda:\n            data, target = data.cuda(), target.cuda()\n        data, target = Variable(data, volatile=True), Variable(target)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target).data[0] # sum up batch loss\n        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    test_loss /= len(test_loader.dataset)\n    print(\'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\nfor epoch in range(1, args.epochs + 1):\n    train(epoch, model)\n    train_evaluate(model)\n    test(model)\n\n\ntorch.save(model.state_dict(), \'teacher_MLP.pth.tar\')\n# the_model = Net()\n# the_model.load_state_dict(torch.load(\'teacher_MLP.pth.tar\'))\n\n# test(the_model)\n# for data, target in test_loader:\n#     data, target = Variable(data, volatile=True), Variable(target)\n#     teacher_out = the_model(data)\n# print(teacher_out)\nprint(""--- %s seconds ---"" % (time.time() - start_time))\n\n\n\n'"
model/__init__.py,0,b''
model/data_loader.py,5,"b'""""""\n   CIFAR-10 data normalization reference:\n   https://github.com/Armour/pytorch-nn-practice/blob/master/utils/meanstd.py\n""""""\n\nimport random\nimport os\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\ndef fetch_dataloader(types, params):\n    """"""\n    Fetch and return train/dev dataloader with hyperparameters (params.subset_percent = 1.)\n    """"""\n\n    # using random crops and horizontal flip for train set\n    if params.augmentation == ""yes"":\n        train_transformer = transforms.Compose([\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n\n    # data augmentation can be turned off\n    else:\n        train_transformer = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n\n    # transformer for dev set\n    dev_transformer = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n\n    trainset = torchvision.datasets.CIFAR10(root=\'./data-cifar10\', train=True,\n        download=True, transform=train_transformer)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=params.batch_size,\n        shuffle=True, num_workers=params.num_workers, pin_memory=params.cuda)\n\n    devset = torchvision.datasets.CIFAR10(root=\'./data-cifar10\', train=False,\n        download=True, transform=dev_transformer)\n    devloader = torch.utils.data.DataLoader(devset, batch_size=params.batch_size,\n        shuffle=False, num_workers=params.num_workers, pin_memory=params.cuda)\n\n    if types == \'train\':\n        dl = trainloader\n    else:\n        dl = devloader\n\n    return dl\n\n\ndef fetch_subset_dataloader(types, params):\n    """"""\n    Use only a subset of dataset for KD training, depending on params.subset_percent\n    """"""\n\n    # using random crops and horizontal flip for train set\n    if params.augmentation == ""yes"":\n        train_transformer = transforms.Compose([\n            transforms.RandomCrop(32, padding=4),\n            transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n\n    # data augmentation can be turned off\n    else:\n        train_transformer = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n\n    # transformer for dev set\n    dev_transformer = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n\n    trainset = torchvision.datasets.CIFAR10(root=\'./data-cifar10\', train=True,\n        download=True, transform=train_transformer)\n\n    devset = torchvision.datasets.CIFAR10(root=\'./data-cifar10\', train=False,\n        download=True, transform=dev_transformer)\n\n    trainset_size = len(trainset)\n    indices = list(range(trainset_size))\n    split = int(np.floor(params.subset_percent * trainset_size))\n    np.random.seed(230)\n    np.random.shuffle(indices)\n\n    train_sampler = SubsetRandomSampler(indices[:split])\n\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=params.batch_size,\n        sampler=train_sampler, num_workers=params.num_workers, pin_memory=params.cuda)\n\n    devloader = torch.utils.data.DataLoader(devset, batch_size=params.batch_size,\n        shuffle=False, num_workers=params.num_workers, pin_memory=params.cuda)\n\n    if types == \'train\':\n        dl = trainloader\n    else:\n        dl = devloader\n\n    return dl'"
model/densenet.py,6,"b'import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nfrom torch.autograd import Variable\n\n# __all__ = [\'densenet\']\n\n\nclass Bottleneck(nn.Module):\n    def __init__(self, inplanes, expansion=4, growthRate=12, dropRate=0):\n        super(Bottleneck, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, inplanes, expansion=1, growthRate=12, dropRate=0):\n        super(BasicBlock, self).__init__()\n        planes = expansion * growthRate\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, growthRate, kernel_size=3, \n                               padding=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropRate = dropRate\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        if self.dropRate > 0:\n            out = F.dropout(out, p=self.dropRate, training=self.training)\n\n        out = torch.cat((x, out), 1)\n\n        return out\n\n\nclass Transition(nn.Module):\n    def __init__(self, inplanes, outplanes):\n        super(Transition, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1,\n                               bias=False)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n        out = F.avg_pool2d(out, 2)\n        return out\n\n\nclass DenseNet(nn.Module):\n\n    def __init__(self, depth=22, block=Bottleneck, \n        dropRate=0, num_classes=10, growthRate=12, compressionRate=2):\n        super(DenseNet, self).__init__()\n\n        assert (depth - 4) % 3 == 0, \'depth should be 3n+4\'\n        n = (depth - 4) / 3 if block == BasicBlock else (depth - 4) // 6\n\n        self.growthRate = growthRate\n        self.dropRate = dropRate\n\n        # self.inplanes is a global variable used across multiple\n        # helper functions\n        self.inplanes = growthRate * 2 \n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n                               bias=False)\n        self.dense1 = self._make_denseblock(block, n)\n        self.trans1 = self._make_transition(compressionRate)\n        self.dense2 = self._make_denseblock(block, n)\n        self.trans2 = self._make_transition(compressionRate)\n        self.dense3 = self._make_denseblock(block, n)\n        self.bn = nn.BatchNorm2d(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(self.inplanes, num_classes)\n\n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_denseblock(self, block, blocks):\n        layers = []\n        for i in range(blocks):\n            # Currently we fix the expansion ratio as the default value\n            layers.append(block(self.inplanes, growthRate=self.growthRate, dropRate=self.dropRate))\n            self.inplanes += self.growthRate\n\n        return nn.Sequential(*layers)\n\n    def _make_transition(self, compressionRate):\n        inplanes = self.inplanes\n        outplanes = int(math.floor(self.inplanes // compressionRate))\n        self.inplanes = outplanes\n        return Transition(inplanes, outplanes)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.trans1(self.dense1(x)) \n        x = self.trans2(self.dense2(x)) \n        x = self.dense3(x)\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef loss_fn(outputs, labels):\n    """"""\n    Compute the cross entropy loss given outputs and labels.\n\n    Args:\n        outputs: (Variable) dimension batch_size x 6 - output of the model\n        labels: (Variable) dimension batch_size, where each element is a value in [0, 1, 2, 3, 4, 5]\n\n    Returns:\n        loss (Variable): cross entropy loss for all images in the batch\n\n    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n          demonstrates how you can easily define a custom loss function.\n    """"""\n    return nn.CrossEntropyLoss()(outputs, labels)\n\n\ndef accuracy(outputs, labels):\n    """"""\n    Compute the accuracy, given the outputs and labels for all images.\n\n    Args:\n        outputs: (np.ndarray) dimension batch_size x 6 - log softmax output of the model\n        labels: (np.ndarray) dimension batch_size, where each element is a value in [0, 1, 2, 3, 4, 5]\n\n    Returns: (float) accuracy in [0,1]\n    """"""\n    outputs = np.argmax(outputs, axis=1)\n    return np.sum(outputs==labels)/float(labels.size)\n\n\n# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\nmetrics = {\n    \'accuracy\': accuracy,\n    # could add more metrics such as accuracy for each token type\n}'"
model/net.py,5,"b'""""""\n   Baseline CNN, losss function and metrics\n   Also customizes knowledge distillation (KD) loss function here\n""""""\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    """"""\n    This is the standard way to define your own network in PyTorch. You typically choose the components\n    (e.g. LSTMs, linear layers etc.) of your network in the __init__ function. You then apply these layers\n    on the input step-by-step in the forward function. You can use torch.nn.functional to apply functions\n\n    such as F.relu, F.sigmoid, F.softmax, F.max_pool2d. Be careful to ensure your dimensions are correct after each\n    step. You are encouraged to have a look at the network in pytorch/nlp/model/net.py to get a better sense of how\n    you can go about defining your own network.\n\n    The documentation for all the various components available o you is here: http://pytorch.org/docs/master/nn.html\n    """"""\n\n    def __init__(self, params):\n        """"""\n        We define an convolutional network that predicts the sign from an image. The components\n        required are:\n\n        Args:\n            params: (Params) contains num_channels\n        """"""\n        super(Net, self).__init__()\n        self.num_channels = params.num_channels\n        \n        # each of the convolution layers below have the arguments (input_channels, output_channels, filter_size,\n        # stride, padding). We also include batch normalisation layers that help stabilise training.\n        # For more details on how to use these layers, check out the documentation.\n        self.conv1 = nn.Conv2d(3, self.num_channels, 3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(self.num_channels)\n        self.conv2 = nn.Conv2d(self.num_channels, self.num_channels*2, 3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(self.num_channels*2)\n        self.conv3 = nn.Conv2d(self.num_channels*2, self.num_channels*4, 3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(self.num_channels*4)\n\n        # 2 fully connected layers to transform the output of the convolution layers to the final output\n        self.fc1 = nn.Linear(4*4*self.num_channels*4, self.num_channels*4)\n        self.fcbn1 = nn.BatchNorm1d(self.num_channels*4)\n        self.fc2 = nn.Linear(self.num_channels*4, 10)       \n        self.dropout_rate = params.dropout_rate\n\n    def forward(self, s):\n        """"""\n        This function defines how we use the components of our network to operate on an input batch.\n\n        Args:\n            s: (Variable) contains a batch of images, of dimension batch_size x 3 x 32 x 32 .\n\n        Returns:\n            out: (Variable) dimension batch_size x 6 with the log probabilities for the labels of each image.\n\n        Note: the dimensions after each step are provided\n        """"""\n        #                                                  -> batch_size x 3 x 32 x 32\n        # we apply the convolution layers, followed by batch normalisation, maxpool and relu x 3\n        s = self.bn1(self.conv1(s))                         # batch_size x num_channels x 32 x 32\n        s = F.relu(F.max_pool2d(s, 2))                      # batch_size x num_channels x 16 x 16\n        s = self.bn2(self.conv2(s))                         # batch_size x num_channels*2 x 16 x 16\n        s = F.relu(F.max_pool2d(s, 2))                      # batch_size x num_channels*2 x 8 x 8\n        s = self.bn3(self.conv3(s))                         # batch_size x num_channels*4 x 8 x 8\n        s = F.relu(F.max_pool2d(s, 2))                      # batch_size x num_channels*4 x 4 x 4\n\n        # flatten the output for each image\n        s = s.view(-1, 4*4*self.num_channels*4)             # batch_size x 4*4*num_channels*4\n\n        # apply 2 fully connected layers with dropout\n        s = F.dropout(F.relu(self.fcbn1(self.fc1(s))), \n            p=self.dropout_rate, training=self.training)    # batch_size x self.num_channels*4\n        s = self.fc2(s)                                     # batch_size x 10\n\n        return s\n\n\ndef loss_fn(outputs, labels):\n    """"""\n    Compute the cross entropy loss given outputs and labels.\n\n    Args:\n        outputs: (Variable) dimension batch_size x 6 - output of the model\n        labels: (Variable) dimension batch_size, where each element is a value in [0, 1, 2, 3, 4, 5]\n\n    Returns:\n        loss (Variable): cross entropy loss for all images in the batch\n\n    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n          demonstrates how you can easily define a custom loss function.\n    """"""\n    return nn.CrossEntropyLoss()(outputs, labels)\n\n\ndef loss_fn_kd(outputs, labels, teacher_outputs, params):\n    """"""\n    Compute the knowledge-distillation (KD) loss given outputs, labels.\n    ""Hyperparameters"": temperature and alpha\n\n    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n    and student expects the input tensor to be log probabilities! See Issue #2\n    """"""\n    alpha = params.alpha\n    T = params.temperature\n    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n              F.cross_entropy(outputs, labels) * (1. - alpha)\n\n    return KD_loss\n\n\ndef accuracy(outputs, labels):\n    """"""\n    Compute the accuracy, given the outputs and labels for all images.\n\n    Args:\n        outputs: (np.ndarray) output of the model\n        labels: (np.ndarray) [0, 1, ..., num_classes-1]\n\n    Returns: (float) accuracy in [0,1]\n    """"""\n    outputs = np.argmax(outputs, axis=1)\n    return np.sum(outputs==labels)/float(labels.size)\n\n\n# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\nmetrics = {\n    \'accuracy\': accuracy,\n    # could add more metrics such as accuracy for each token type\n}\n'"
model/preresnet.py,2,"b'from __future__ import absolute_import\n\n\'\'\'Resnet for cifar dataset.\nPorted form\nhttps://github.com/facebook/fb.resnet.torch\nand\nhttps://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n(c) YANG, Wei\n\'\'\'\nimport torch.nn as nn\nimport math\nimport numpy as np\n\n\n# __all__ = [\'preresnet\']\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass PreResNet(nn.Module):\n\n    def __init__(self, depth, num_classes=1000):\n        super(PreResNet, self).__init__()\n        # Model type specifies number of layers for CIFAR-10 model\n        assert (depth - 2) % 6 == 0, \'depth should be 6n+2\'\n        n = (depth - 2) // 6\n\n        block = Bottleneck if depth >=44 else BasicBlock\n\n        self.inplanes = 16\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n                               bias=False)\n        self.layer1 = self._make_layer(block, 16, n)\n        self.layer2 = self._make_layer(block, 32, n, stride=2)\n        self.layer3 = self._make_layer(block, 64, n, stride=2)\n        self.bn = nn.BatchNorm2d(64 * block.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n\n        x = self.layer1(x)  # 32x32\n        x = self.layer2(x)  # 16x16\n        x = self.layer3(x)  # 8x8\n        x = self.bn(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef loss_fn(outputs, labels):\n    """"""\n    Compute the cross entropy loss given outputs and labels.\n\n    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n          demonstrates how you can easily define a custom loss function.\n    """"""\n    return nn.CrossEntropyLoss()(outputs, labels)\n\n\ndef accuracy(outputs, labels):\n    """"""\n    Compute the accuracy, given the outputs and labels for all images.\n\n    Returns: (float) accuracy in [0,1]\n    """"""\n    outputs = np.argmax(outputs, axis=1)\n    return np.sum(outputs==labels)/float(labels.size)\n\n\n# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\nmetrics = {\n    \'accuracy\': accuracy,\n    # could add more metrics such as accuracy for each token type\n}'"
model/resnet.py,5,"b'\'\'\'ResNet in PyTorch.\n\nFor Pre-activation ResNet, see \'preact_resnet.py\'.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n\'\'\'\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2,2,2,2])\n\ndef ResNet34():\n    return ResNet(BasicBlock, [3,4,6,3])\n\ndef ResNet50():\n    return ResNet(Bottleneck, [3,4,6,3])\n\ndef ResNet101():\n    return ResNet(Bottleneck, [3,4,23,3])\n\ndef ResNet152():\n    return ResNet(Bottleneck, [3,8,36,3])\n\n\n# def test():\n#     net = ResNet18()\n#     y = net(Variable(torch.randn(1,3,32,32)))\n#     print(y.size())\n\n# test()\n\ndef loss_fn(outputs, labels):\n    """"""\n    Compute the cross entropy loss given outputs and labels.\n\n    Returns:\n        loss (Variable): cross entropy loss for all images in the batch\n\n    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n          demonstrates how you can easily define a custom loss function.\n    """"""\n    return nn.CrossEntropyLoss()(outputs, labels)\n\n\ndef accuracy(outputs, labels):\n    """"""\n    Compute the accuracy, given the outputs and labels for all images.\n\n    Returns: (float) accuracy in [0,1]\n    """"""\n    outputs = np.argmax(outputs, axis=1)\n    return np.sum(outputs==labels)/float(labels.size)\n\n\n# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\nmetrics = {\n    \'accuracy\': accuracy,\n    # could add more metrics such as accuracy for each token type\n}'"
model/resnext.py,4,"b'from __future__ import division\n"""""" \nCreates a ResNeXt Model as defined in:\nXie, S., Girshick, R., Dollar, P., Tu, Z., & He, K. (2016). \nAggregated residual transformations for deep neural networks. \narXiv preprint arXiv:1611.05431.\nimport from https://github.com/prlz77/ResNeXt.pytorch/blob/master/models/model.py\n""""""\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\nimport numpy as np\n\n# __all__ = [\'resnext\']\n\nclass ResNeXtBottleneck(nn.Module):\n    """"""\n    RexNeXt bottleneck type C (https://github.com/facebookresearch/ResNeXt/blob/master/models/resnext.lua)\n    """"""\n    def __init__(self, in_channels, out_channels, stride, cardinality, widen_factor):\n        """""" Constructor\n        Args:\n            in_channels: input channel dimensionality\n            out_channels: output channel dimensionality\n            stride: conv stride. Replaces pooling layer.\n            cardinality: num of convolution groups.\n            widen_factor: factor to reduce the input dimensionality before convolution.\n        """"""\n        super(ResNeXtBottleneck, self).__init__()\n        D = cardinality * out_channels // widen_factor\n        self.conv_reduce = nn.Conv2d(in_channels, D, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_reduce = nn.BatchNorm2d(D)\n        self.conv_conv = nn.Conv2d(D, D, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n        self.bn = nn.BatchNorm2d(D)\n        self.conv_expand = nn.Conv2d(D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn_expand = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut.add_module(\'shortcut_conv\', nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False))\n            self.shortcut.add_module(\'shortcut_bn\', nn.BatchNorm2d(out_channels))\n\n    def forward(self, x):\n        bottleneck = self.conv_reduce.forward(x)\n        bottleneck = F.relu(self.bn_reduce.forward(bottleneck), inplace=True)\n        bottleneck = self.conv_conv.forward(bottleneck)\n        bottleneck = F.relu(self.bn.forward(bottleneck), inplace=True)\n        bottleneck = self.conv_expand.forward(bottleneck)\n        bottleneck = self.bn_expand.forward(bottleneck)\n        residual = self.shortcut.forward(x)\n        return F.relu(residual + bottleneck, inplace=True)\n\n\nclass CifarResNeXt(nn.Module):\n    """"""\n    ResNext optimized for the Cifar dataset, as specified in\n    https://arxiv.org/pdf/1611.05431.pdf\n    """"""\n    def __init__(self, cardinality, depth, num_classes, widen_factor=4, dropRate=0):\n        """""" Constructor\n        Args:\n            cardinality: number of convolution groups.\n            depth: number of layers.\n            num_classes: number of classes\n            widen_factor: factor to adjust the channel dimensionality\n        """"""\n        super(CifarResNeXt, self).__init__()\n        self.cardinality = cardinality\n        self.depth = depth\n        self.block_depth = (self.depth - 2) // 9\n        self.widen_factor = widen_factor\n        self.num_classes = num_classes\n        self.output_size = 64\n        self.stages = [64, 64 * self.widen_factor, 128 * self.widen_factor, 256 * self.widen_factor]\n\n        self.conv_1_3x3 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n        self.bn_1 = nn.BatchNorm2d(64)\n        self.stage_1 = self.block(\'stage_1\', self.stages[0], self.stages[1], 1)\n        self.stage_2 = self.block(\'stage_2\', self.stages[1], self.stages[2], 2)\n        self.stage_3 = self.block(\'stage_3\', self.stages[2], self.stages[3], 2)\n        self.classifier = nn.Linear(1024, num_classes)\n        init.kaiming_normal(self.classifier.weight)\n\n        for key in self.state_dict():\n            if key.split(\'.\')[-1] == \'weight\':\n                if \'conv\' in key:\n                    init.kaiming_normal(self.state_dict()[key], mode=\'fan_out\')\n                if \'bn\' in key:\n                    self.state_dict()[key][...] = 1\n            elif key.split(\'.\')[-1] == \'bias\':\n                self.state_dict()[key][...] = 0\n\n    def block(self, name, in_channels, out_channels, pool_stride=2):\n        """""" Stack n bottleneck modules where n is inferred from the depth of the network.\n        Args:\n            name: string name of the current block.\n            in_channels: number of input channels\n            out_channels: number of output channels\n            pool_stride: factor to reduce the spatial dimensionality in the first bottleneck of the block.\n        Returns: a Module consisting of n sequential bottlenecks.\n        """"""\n        block = nn.Sequential()\n        for bottleneck in range(self.block_depth):\n            name_ = \'%s_bottleneck_%d\' % (name, bottleneck)\n            if bottleneck == 0:\n                block.add_module(name_, ResNeXtBottleneck(in_channels, out_channels, pool_stride, self.cardinality,\n                                                          self.widen_factor))\n            else:\n                block.add_module(name_,\n                                 ResNeXtBottleneck(out_channels, out_channels, 1, self.cardinality, self.widen_factor))\n        return block\n\n    def forward(self, x):\n        x = self.conv_1_3x3.forward(x)\n        x = F.relu(self.bn_1.forward(x), inplace=True)\n        x = self.stage_1.forward(x)\n        x = self.stage_2.forward(x)\n        x = self.stage_3.forward(x)\n        x = F.avg_pool2d(x, 8, 1)\n        x = x.view(-1, 1024)\n        return self.classifier(x)\n\n\ndef loss_fn(outputs, labels):\n    """"""\n    Compute the cross entropy loss given outputs and labels.\n\n    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n          demonstrates how you can easily define a custom loss function.\n    """"""\n    return nn.CrossEntropyLoss()(outputs, labels)\n\n\ndef accuracy(outputs, labels):\n    """"""\n    Compute the accuracy, given the outputs and labels for all images.\n\n    Returns: (float) accuracy in [0,1]\n    """"""\n    outputs = np.argmax(outputs, axis=1)\n    return np.sum(outputs==labels)/float(labels.size)\n\n\n# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\nmetrics = {\n    \'accuracy\': accuracy,\n    # could add more metrics such as accuracy for each token type\n}'"
model/wrn.py,4,"b'import numpy as np\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# __all__ = [\'wrn\']\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut:\n            x = self.relu1(self.bn1(x))\n        else:\n            out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super(NetworkBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(nb_layers):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x):\n        return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(WideResNet, self).__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert (depth - 4) % 6 == 0, \'depth should be 6n+4\'\n        n = (depth - 4) // 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        # 1st block\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        # 2nd block\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        # 3rd block\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)\n\n\ndef loss_fn(outputs, labels):\n    """"""\n    Compute the cross entropy loss given outputs and labels.\n\n    Args:\n        outputs: (Variable) dimension batch_size x 6 - output of the model\n        labels: (Variable) dimension batch_size, where each element is a value in [0, 1, 2, 3, 4, 5]\n\n    Returns:\n        loss (Variable): cross entropy loss for all images in the batch\n\n    Note: you may use a standard loss function from http://pytorch.org/docs/master/nn.html#loss-functions. This example\n          demonstrates how you can easily define a custom loss function.\n    """"""\n    return nn.CrossEntropyLoss()(outputs, labels)\n\n\ndef accuracy(outputs, labels):\n    """"""\n    Compute the accuracy, given the outputs and labels for all images.\n\n    Args:\n        outputs: (np.ndarray) dimension batch_size x 6 - log softmax output of the model\n        labels: (np.ndarray) dimension batch_size, where each element is a value in [0, 1, 2, 3, 4, 5]\n\n    Returns: (float) accuracy in [0,1]\n    """"""\n    outputs = np.argmax(outputs, axis=1)\n    return np.sum(outputs==labels)/float(labels.size)\n\n\n# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\nmetrics = {\n    \'accuracy\': accuracy,\n    # could add more metrics such as accuracy for each token type\n}'"
