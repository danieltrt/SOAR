file_path,api_count,code
test_memory_baseline.py,30,"b'import torch\nimport torch.optim\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\n\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nimport unittest, time, sys\n\nimport models.baseline.word_language_model as wlm_baseline\nimport models.baseline.densenet as densenet_baseline\nimport models.baseline.resnet as resnet_baseline\nimport models.baseline.vnet as vnet_baseline\n\n\nclass TestMemoryBaseline(unittest.TestCase):\n\n    def test_densenet_baseline(self):\n        N = 32\n        total_iters = 20    # (warmup + benchmark)\n        iterations = 1\n\n        x = Variable(torch.randn(N, 3, 224, 224).fill_(1.0), requires_grad=True)\n        target = Variable(torch.randn(N).fill_(1)).type(""torch.LongTensor"")\n        # model = densenet_baseline.densenet100()\n        # model = densenet_baseline.densenet121()\n        # model = densenet_baseline.densenet201()\n        model = densenet_baseline.densenet264()\n\n        # switch the model to train mode\n        model.train()\n\n        # convert the model and input to cuda\n        model = model.cuda()\n        input_var = x.cuda()\n        target_var = target.cuda()\n\n        # declare the optimizer and criterion\n        criterion = nn.CrossEntropyLoss().cuda()\n        optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=1e-4)\n\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n        with cudnn.flags(enabled=True, benchmark=True):\n            for i in range(total_iters):\n                start.record()\n                start_cpu = time.time()\n                for j in range(iterations):\n                    output = model(input_var)\n                    loss = criterion(output, target_var)\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                end_cpu = time.time()\n                end.record()\n                torch.cuda.synchronize()\n                gpu_msec = start.elapsed_time(end)\n                print(""Baseline densenet ({:2d}): ({:8.3f} usecs gpu) ({:8.3f} usecs cpu)"".format(\n                    i, gpu_msec * 1000, (end_cpu - start_cpu) * 1000000,\n                    file=sys.stderr))\n\n    def test_resnet_baseline(self):\n        N = 8\n        total_iters = 5    # (warmup + benchmark)\n        iterations = 4\n\n        target = Variable(torch.randn(N).fill_(1)).type(""torch.LongTensor"")\n        # x = Variable(torch.randn(N, 3, 224, 224).fill_(1.0), requires_grad=True)\n        x = Variable(torch.randn(N, 3, 32, 32).fill_(1.0), requires_grad=True)\n        # model = resnet_baseline.resnet200()\n        # model = resnet_baseline.resnet101()\n        # model = resnet_baseline.resnet50()\n        model = resnet_baseline.resnet1001()\n\n        # switch the model to train mode\n        model.train()\n\n        # convert the model and input to cuda\n        model = model.cuda()\n        input_var = x.cuda()\n        target_var = target.cuda()\n\n        # declare the optimizer and criterion\n        criterion = nn.CrossEntropyLoss().cuda()\n        optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=1e-4)\n        optimizer.zero_grad()\n\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n        with cudnn.flags(enabled=True, benchmark=True):\n            for i in range(total_iters):\n                start.record()\n                start_cpu = time.time()\n                for j in range(iterations):\n                    output = model(input_var)\n                    loss = criterion(output, target_var)\n                    loss.backward()\n                    optimizer.step()\n\n                end_cpu = time.time()\n                end.record()\n                torch.cuda.synchronize()\n                gpu_msec = start.elapsed_time(end)\n                print(""Baseline resnet ({:2d}): ({:8.3f} usecs gpu) ({:8.3f} usecs cpu)"".format(\n                    i, gpu_msec * 1000, (end_cpu - start_cpu) * 1000000,\n                    file=sys.stderr))\n\n    def weights_init(self, m):\n        classname = m.__class__.__name__\n        if classname.find(\'Conv3d\') != -1:\n            nn.init.kaiming_normal(m.weight)\n            m.bias.data.zero_()\n\n    def test_vnet_baseline(self):\n        N = 4\n        total_iters = 10    # (warmup + benchmark)\n        iterations = 2\n\n        target = Variable(torch.randn(N, 1, 128, 128, 64).fill_(1)).type(""torch.LongTensor"")\n        x = Variable(torch.randn(N, 1, 128, 128, 64).fill_(1.0), requires_grad=True)\n        model = vnet_baseline.VNet(elu=False, nll=True)\n        bg_weight = 0.5\n        fg_weight = 0.5\n        weights = torch.FloatTensor([bg_weight, fg_weight])\n        weights = weights.cuda()\n        model.train()\n\n        # convert the model and input to cuda\n        model = model.cuda()\n        input_var = x.cuda()\n        target_var = target.cuda()\n        target = target_var.view(target_var.numel())\n\n        # declare the optimizer and criterion\n        optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.99, weight_decay=1e-8)\n        optimizer.zero_grad()\n        model.apply(self.weights_init)\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n\n        with cudnn.flags(enabled=True, benchmark=True):\n            for i in range(total_iters):\n                start.record()\n                start_cpu = time.time()\n                for j in range(iterations):\n                    output = model(input_var)\n                    loss = F.nll_loss(output, target, weight=weights)\n                    loss.backward()\n                    optimizer.step()\n\n                end_cpu = time.time()\n                end.record()\n                torch.cuda.synchronize()\n                gpu_msec = start.elapsed_time(end)\n                print(""Baseline vnet ({:2d}): ({:8.3f} usecs gpu) ({:8.3f} usecs cpu)"".format(\n                    i, gpu_msec * 1000, (end_cpu - start_cpu) * 1000000,\n                    file=sys.stderr))\n\n    def repackage_hidden(self, h):\n        """"""Wraps hidden states in new Variables, to detach them from their history.""""""\n        if type(h) == Variable:\n            return Variable(h.data)\n        else:\n            return tuple(self.repackage_hidden(v) for v in h)\n\n    def test_wlm_baseline(self):\n        total_iters = 2\n        iterations = 10\n\n        model_name = \'LSTM\'\n        ntokens = 33278\n        emsize = 200\n        nhid = 200\n        nlayers = 1\n        dropout = 0.2\n        tied = False\n        batchsize = 20\n        bptt = 800\n\n        data = Variable(torch.LongTensor(bptt, batchsize).fill_(1), volatile=False)\n        target_var = Variable(torch.LongTensor(bptt * batchsize).fill_(1))\n        targets = target_var.cuda()\n        input_data = data.cuda()\n\n        model = wlm_baseline.RNNModel(model_name, ntokens, emsize, nhid, nlayers, dropout, tied)\n        model = model.cuda()\n        model.train()\n        criterion = nn.CrossEntropyLoss().cuda()\n        hidden = model.init_hidden(batchsize)\n\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n        with cudnn.flags(enabled=True, benchmark=True):\n            for i in range(total_iters):\n                start.record()\n                start_cpu = time.time()\n                for j in range(iterations):\n                    hidden = self.repackage_hidden(hidden)\n                    output, hidden = model(input_data, hidden)\n                    loss = criterion(output.view(-1, ntokens), targets)\n                    loss = loss + 0*(hidden[0].sum() + hidden[1].sum())\n                    loss.backward()\n\n                end_cpu = time.time()\n                end.record()\n                torch.cuda.synchronize()\n                gpu_msec = start.elapsed_time(end)\n                print(""Baseline WLM ({:2d}): ({:8.3f} usecs gpu) ({:8.3f} usecs cpu)"".format(\n                    i, gpu_msec * 1000, (end_cpu - start_cpu) * 1000000,\n                    file=sys.stderr))\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
test_memory_optimized.py,32,"b'import pdb\nimport torch\nimport torch.optim\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\n\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nimport unittest, time, sys\n\nimport models.optimized.densenet_new as densenet_optim\nimport models.optimized.resnet_new as resnet_optim\nimport models.optimized.vnet_new as vnet_optim\nimport models.optimized.word_language_model_new as wlm_optim\n\n\nclass TestMemoryOptimized(unittest.TestCase):\n\n    def test_densenet_optim(self):\n        N = 32\n        # N = 72\n        chunks = 4\n        total_iters = 20    # (warmup + benchmark)\n        iterations = 1\n\n        x = torch.ones(N, 3, 224, 224, requires_grad=True)\n        target = torch.ones(N).type(""torch.LongTensor"")\n\n        # model = densenet_optimized.densenet100()\n        # model = densenet_optimized.densenet121()\n        # model = densenet_optimized.densenet201()\n        model = densenet_optim.densenet264()\n\n        # switch the model to train mode\n        model.train()\n\n        # convert the model and input to cuda\n        model = model.cuda()\n        input_var = x.cuda()\n        target_var = target.cuda()\n\n        # declare the optimizer and criterion\n        criterion = nn.CrossEntropyLoss().cuda()\n        optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=1e-4)\n\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n        with cudnn.flags(enabled=True, benchmark=True):\n            for i in range(total_iters):\n                start.record()\n                start_cpu = time.time()\n                for j in range(iterations):\n                    output = model(input_var, chunks=chunks)\n                    loss = criterion(output, target_var)\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                end_cpu = time.time()\n                end.record()\n                torch.cuda.synchronize()\n                gpu_msec = start.elapsed_time(end)\n                print(""Optimized densenet ({:2d}): ({:8.3f} usecs gpu) ({:8.3f} usecs cpu)"".format(\n                    i, gpu_msec * 1000, (end_cpu - start_cpu) * 1000000,\n                    file=sys.stderr))\n\n    def test_resnet_optim(self):\n        N = 32\n        # N = 51\n        total_iters = 20    # (warmup + benchmark)\n        iterations = 1\n        chunks = 6\n\n        target = torch.ones(N).type(""torch.LongTensor"")\n        # x = torch.ones(N, 3, 224, 224, requires_grad=True)\n        x = torch.ones(N, 3, 32, 32, requires_grad=True)\n        # model = resnet_optim.resnet200()\n        # model = resnet_optim.resnet101()\n        # model = resnet_optim.resnet50()\n        model = resnet_optim.resnet1001()\n\n        # switch the model to train mode\n        model.train()\n\n        # convert the model and input to cuda\n        model = model.cuda()\n        input_var = x.cuda()\n        target_var = target.cuda()\n\n        # declare the optimizer and criterion\n        criterion = nn.CrossEntropyLoss().cuda()\n        optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9, weight_decay=1e-4)\n        optimizer.zero_grad()\n\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n        with cudnn.flags(enabled=True, benchmark=True):\n            for i in range(total_iters):\n                start.record()\n                start_cpu = time.time()\n                for j in range(iterations):\n                    output = model(input_var, chunks=chunks)\n                    loss = criterion(output, target_var)\n                    loss.backward()\n                    optimizer.step()\n\n                end_cpu = time.time()\n                end.record()\n                torch.cuda.synchronize()\n                gpu_msec = start.elapsed_time(end)\n                print(""Optimized resnet ({:2d}): ({:8.3f} usecs gpu) ({:8.3f} usecs cpu)"".format(\n                    i, gpu_msec * 1000, (end_cpu - start_cpu) * 1000000,\n                    file=sys.stderr))\n\n    def weights_init(self, m):\n        classname = m.__class__.__name__\n        if classname.find(\'Conv3d\') != -1:\n            nn.init.kaiming_normal(m.weight)\n            m.bias.data.zero_()\n\n    def test_vnet_optim(self):\n        # optimized\n        N = 8\n        total_iters = 20    # (warmup + benchmark)\n        iterations = 1\n\n        # baseline\n        # N = 4\n        # total_iters = 10    # (warmup + benchmark)\n        # iterations = 2\n\n        target = torch.ones(N, 1, 128, 128, 64).type(""torch.LongTensor"")\n        x = torch.ones(N, 1, 128, 128, 64, requires_grad=True)\n        model = vnet_optim.VNet(elu=False, nll=True)\n        bg_weight = 0.5\n        fg_weight = 0.5\n        weights = torch.FloatTensor([bg_weight, fg_weight])\n        weights = weights.cuda()\n        model.train()\n\n        # convert the model and input to cuda\n        model = model.cuda()\n        input_var = x.cuda()\n        target_var = target.cuda()\n        target = target_var.view(target_var.numel())\n\n        # declare the optimizer and criterion\n        optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.99, weight_decay=1e-8)\n        optimizer.zero_grad()\n        model.apply(self.weights_init)\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n\n        with cudnn.flags(enabled=True, benchmark=True):\n            for i in range(total_iters):\n                start.record()\n                start_cpu = time.time()\n                for j in range(iterations):\n                    output = model(input_var)\n                    loss = F.nll_loss(output, target, weight=weights)\n                    loss.backward()\n                    optimizer.step()\n\n                end_cpu = time.time()\n                end.record()\n                torch.cuda.synchronize()\n                gpu_msec = start.elapsed_time(end)\n                print(""Optimized vnet ({:2d}): ({:8.3f} usecs gpu) ({:8.3f} usecs cpu)"".format(\n                    i, gpu_msec * 1000, (end_cpu - start_cpu) * 1000000,\n                    file=sys.stderr))\n\n    def repackage_hidden(self, h):\n        """"""Wraps hidden states in new Variables, to detach them from their history.""""""\n        if type(h) == torch.autograd.Variable:\n            return h.detach()\n        else:\n            return tuple(self.repackage_hidden(v) for v in h)\n\n    def test_wlm_optim(self):\n        total_iters = 20\n        iterations = 1\n        chunks = 4\n\n        model_name = \'LSTM\'\n        ntokens = 33278\n        emsize = 200\n        nhid = 200\n        nlayers = 1\n        dropout = 0.2\n        tied = False\n        batchsize = 20\n        bptt = 7000\n\n        data = Variable(torch.LongTensor(bptt, batchsize).fill_(1), volatile=False)\n        # data = torch.ones(bptt, batchsize, volatile=False).type(""torch.LongTensor"")\n        target_var = torch.ones(bptt * batchsize).type(""torch.LongTensor"")\n        targets = target_var.cuda()\n        input_data = data.cuda()\n\n        model = wlm_optim.RNNModel(model_name, ntokens, emsize, nhid, nlayers, dropout, tied)\n        model = model.cuda()\n        model.train()\n        criterion = nn.CrossEntropyLoss().cuda()\n        hidden = model.init_hidden(batchsize)\n\n        start = torch.cuda.Event(enable_timing=True)\n        end = torch.cuda.Event(enable_timing=True)\n        with cudnn.flags(enabled=True, benchmark=True):\n            for i in range(total_iters):\n                start.record()\n                start_cpu = time.time()\n                for j in range(iterations):\n                    hidden = self.repackage_hidden(hidden)\n                    output, hidden = model(input_data, hidden, targets, chunks=chunks)\n                    model.backward(output)\n\n                end_cpu = time.time()\n                end.record()\n                torch.cuda.synchronize()\n                gpu_msec = start.elapsed_time(end)\n                print(""Optimized WLM ({:2d}): ({:8.3f} usecs gpu) ({:8.3f} usecs cpu)"".format(\n                    i, gpu_msec * 1000, (end_cpu - start_cpu) * 1000000,\n                    file=sys.stderr))\n\n\nif __name__ == \'__main__\':\n    unittest.main()\n'"
models/baseline/densenet.py,8,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom collections import OrderedDict\n\n__all__ = [\'DenseNet\', \'densenet121\', \'densenet169\', \'densenet201\', \'densenet161\', \'densenet264\']\n\n\nmodel_urls = {\n    \'densenet121\': \'https://download.pytorch.org/models/densenet121-a639ec97.pth\',\n    \'densenet169\': \'https://download.pytorch.org/models/densenet169-b2777c0a.pth\',\n    \'densenet201\': \'https://download.pytorch.org/models/densenet201-c1103571.pth\',\n    \'densenet161\': \'https://download.pytorch.org/models/densenet161-8d451a50.pth\',\n}\n\n\ndef densenet121(pretrained=False, **kwargs):\n    r""""""Densenet-121 model from\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n                     **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'densenet121\']))\n    return model\n\n\ndef densenet169(pretrained=False, **kwargs):\n    r""""""Densenet-169 model from\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n                     **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'densenet169\']))\n    return model\n\n\ndef densenet201(pretrained=False, **kwargs):\n    r""""""Densenet-201 model from\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n                     **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'densenet201\']))\n    return model\n\n\ndef densenet161(pretrained=False, **kwargs):\n    r""""""Densenet-161 model from\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n                     **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'densenet161\']))\n    return model\n\n\ndef densenet264(pretrained=False, **kwargs):\n    r""""""Densenet-264 model""""""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 64, 48),\n                     **kwargs)\n    return model\n\n\nclass _DenseLayer(nn.Sequential):\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super(_DenseLayer, self).__init__()\n        self.add_module(\'norm.1\', nn.BatchNorm2d(num_input_features)),\n        self.add_module(\'relu.1\', nn.ReLU(inplace=True)),\n        self.add_module(\'conv.1\', nn.Conv2d(num_input_features, bn_size *\n                        growth_rate, kernel_size=1, stride=1, bias=False)),\n        self.add_module(\'norm.2\', nn.BatchNorm2d(bn_size * growth_rate)),\n        self.add_module(\'relu.2\', nn.ReLU(inplace=True)),\n        self.add_module(\'conv.2\', nn.Conv2d(bn_size * growth_rate, growth_rate,\n                        kernel_size=3, stride=1, padding=1, bias=False)),\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super(_DenseLayer, self).forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n        return torch.cat([x, new_features], 1)\n\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n            self.add_module(\'denselayer%d\' % (i + 1), layer)\n\n\nclass _Transition(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super(_Transition, self).__init__()\n        self.add_module(\'norm\', nn.BatchNorm2d(num_input_features))\n        self.add_module(\'relu\', nn.ReLU(inplace=True))\n        self.add_module(\'conv\', nn.Conv2d(num_input_features, num_output_features,\n                                          kernel_size=1, stride=1, bias=False))\n        self.add_module(\'pool\', nn.AvgPool2d(kernel_size=2, stride=2))\n\n\nclass DenseNet(nn.Module):\n    r""""""Densenet-BC model class, based on\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        growth_rate (int) - how many filters to add each layer (`k` in paper)\n        block_config (list of 4 ints) - how many layers in each pooling block\n        num_init_features (int) - the number of filters to learn in the first convolution layer\n        bn_size (int) - multiplicative factor for number of bottle neck layers\n          (i.e. bn_size * k features in the bottleneck layer)\n        drop_rate (float) - dropout rate after each dense layer\n        num_classes (int) - number of classification classes\n    """"""\n    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n\n        super(DenseNet, self).__init__()\n\n        # First convolution\n        self.features = nn.Sequential(OrderedDict([\n            (\'conv0\', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n            (\'norm0\', nn.BatchNorm2d(num_init_features)),\n            (\'relu0\', nn.ReLU(inplace=True)),\n            (\'pool0\', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n        ]))\n\n        # Each denseblock\n        num_features = num_init_features\n        for i, num_layers in enumerate(block_config):\n            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n            self.features.add_module(\'denseblock%d\' % (i + 1), block)\n            num_features = num_features + num_layers * growth_rate\n            if i != len(block_config) - 1:\n                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n                self.features.add_module(\'transition%d\' % (i + 1), trans)\n                num_features = num_features // 2\n\n        # Final batch norm\n        self.features.add_module(\'norm5\', nn.BatchNorm2d(num_features))\n\n        # Linear layer\n        self.classifier = nn.Linear(num_features, num_classes)\n\n        # Official init from torch repo.\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal(m.weight.data)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        features = self.features(x)\n        out = F.relu(features, inplace=True)\n        out = F.avg_pool2d(out, kernel_size=7, stride=1).view(features.size(0), -1)\n        out = self.classifier(out)\n        return out\n'"
models/baseline/resnet.py,7,"b'import torch.nn as nn\nfrom collections import OrderedDict\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\', \'resnet200\', \'resnet1001\']\n\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    """"""3x3 convolution with padding""""""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.relu3 = nn.ReLU(inplace=True)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.bn1(x)\n        out = self.relu1(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu2(out)\n        out = self.conv2(out)\n\n        out = self.bn2(out)\n        out = self.relu3(out)\n        out = self.conv3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\nclass PreActResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=10):\n        self.inplanes = 16\n        super(PreActResNet, self).__init__()\n\n        self.features = nn.Sequential(OrderedDict([\n            (\'conv1\', nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)),\n            (\'bn1\', nn.BatchNorm2d(16)),\n            (\'relu1\', nn.ReLU(inplace=True)),\n        ]))\n\n        self._make_layer(block, 64, layers[0], stage=1)\n        self._make_layer(block, 128, layers[1], stride=2, stage=2)\n        self._make_layer(block, 256, layers[2], stride=2, stage=3)\n        self.features.add_module(\'bn2\', nn.BatchNorm2d(256 * block.expansion))\n        self.features.add_module(\'relu2\', nn.ReLU(inplace=True))\n        self.features.add_module(\'avgpool\', nn.AvgPool2d(8, stride=1))\n        self.fc = nn.Linear(256 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1, stage=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.BatchNorm2d(self.inplanes),\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n            )\n\n        self.features.add_module(\n            \'PreActBottleneck_%d_%d\' % (stage, 0),\n            block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            self.features.add_module(\n                \'PreActBottleneck_%d_%d\' % (stage, i),\n                block(self.inplanes, planes))\n\n    def forward(self, x):\n        features = self.features(x)\n        features = features.view(features.size(0), -1)\n        features = self.fc(features)\n        return features\n\n\ndef resnet18(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n    return model\n\n\ndef resnet34(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model\n\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef resnet101(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n    return model\n\n\ndef resnet152(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n    return model\n\ndef resnet200(pretrained=False, **kwargs):\n    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n    return model\n\n# ResNet1001 was only defined for the cifar dataset\ndef resnet1001(pretrained=False, **kwargs):\n    # the input data should be like 32 x 3 x 32 x 32\n    model = PreActResNet(PreActBottleneck, [111, 111, 111], **kwargs)\n    return model\n'"
models/baseline/vnet.py,10,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable, Function\n# from torch.utils.checkpoint import checkpoint, checkpoint_sequential\nimport torch.utils.checkpoint_new as checkpoint_new\nimport pdb\n\ndef passthrough(x, **kwargs):\n    return x\n\ndef ELUCons(elu, nchan):\n    if elu:\n        return nn.ELU(inplace=True)\n    else:\n        return nn.PReLU(nchan)\n\n# normalization between sub-volumes is necessary\n# for good performance\nclass ContBatchNorm3d(nn.modules.batchnorm._BatchNorm):\n    def _check_input_dim(self, input):\n        if input.dim() != 5:\n            raise ValueError('expected 5D input (got {}D input)'\n                             .format(input.dim()))\n        super(ContBatchNorm3d, self)\n\n    def forward(self, input):\n        self._check_input_dim(input)\n        return F.batch_norm(\n            input, self.running_mean, self.running_var, self.weight, self.bias,\n            True, self.momentum, self.eps)\n\n\nclass LUConv(nn.Module):\n    def __init__(self, nchan, elu):\n        super(LUConv, self).__init__()\n        self.relu1 = ELUCons(elu, nchan)\n        self.conv1 = nn.Conv3d(nchan, nchan, kernel_size=5, padding=2)\n        self.bn1 = ContBatchNorm3d(nchan)\n\n    def forward(self, x):\n        out = self.relu1(self.bn1(self.conv1(x)))\n        return out\n\n\ndef _make_nConv(nchan, depth, elu):\n    layers = []\n    for _ in range(depth):\n        layers.append(LUConv(nchan, elu))\n    return nn.Sequential(*layers)\n\n\nclass InputTransition(nn.Module):\n    def __init__(self, outChans, elu):\n        super(InputTransition, self).__init__()\n        self.conv1 = nn.Conv3d(1, 16, kernel_size=5, padding=2)\n        self.bn1 = ContBatchNorm3d(16)\n        self.relu1 = ELUCons(elu, 16)\n\n    def forward(self, x):\n        # do we want a PRELU here as well?\n        out = self.bn1(self.conv1(x))\n        # split input in to 16 channels\n        x16 = torch.cat((x, x, x, x, x, x, x, x,\n                         x, x, x, x, x, x, x, x), 1)\n        out = self.relu1(torch.add(out, x16))\n        return out\n\n\nclass DownTransition(nn.Module):\n    def __init__(self, inChans, nConvs, elu, dropout=False):\n        super(DownTransition, self).__init__()\n        outChans = 2*inChans\n        self.down_conv = nn.Conv3d(inChans, outChans, kernel_size=2, stride=2)\n        self.bn1 = ContBatchNorm3d(outChans)\n        self.do1 = passthrough\n        self.relu1 = ELUCons(elu, outChans)\n        self.relu2 = ELUCons(elu, outChans)\n        if dropout:\n            self.do1 = nn.Dropout3d()\n        self.ops = _make_nConv(outChans, nConvs, elu)\n\n    def forward(self, x):\n        down = self.relu1(self.bn1(self.down_conv(x)))\n        out = self.do1(down)\n        out = self.ops(out)\n        out = self.relu2(torch.add(out, down))\n        return out\n\n\nclass UpTransition(nn.Module):\n    def __init__(self, inChans, outChans, nConvs, elu, dropout=False):\n        super(UpTransition, self).__init__()\n        self.up_conv = nn.ConvTranspose3d(inChans, outChans // 2, kernel_size=2, stride=2)\n        self.bn1 = ContBatchNorm3d(outChans // 2)\n        self.do1 = passthrough\n        self.do2 = nn.Dropout3d()\n        self.relu1 = ELUCons(elu, outChans // 2)\n        self.relu2 = ELUCons(elu, outChans)\n        if dropout:\n            self.do1 = nn.Dropout3d()\n        self.ops = _make_nConv(outChans, nConvs, elu)\n\n    def forward(self, x, skipx):\n        out = self.do1(x)\n        skipxdo = self.do2(skipx)\n        out = self.relu1(self.bn1(self.up_conv(out)))\n        xcat = torch.cat((out, skipxdo), 1)\n        out = self.ops(xcat)\n        out = self.relu2(torch.add(out, xcat))\n        return out\n\n\nclass OutputTransition(nn.Module):\n    def __init__(self, inChans, elu, nll):\n        super(OutputTransition, self).__init__()\n        self.conv1 = nn.Conv3d(inChans, 2, kernel_size=5, padding=2)\n        self.bn1 = ContBatchNorm3d(2)\n        self.conv2 = nn.Conv3d(2, 2, kernel_size=1)\n        self.relu1 = ELUCons(elu, 2)\n        if nll:\n            self.softmax = F.log_softmax\n        else:\n            self.softmax = F.softmax\n\n    def forward(self, x):\n        # convolve 32 down to 2 channels\n        out = self.relu1(self.bn1(self.conv1(x)))\n        out = self.conv2(out)\n\n        # make channels the last axis\n        out = out.permute(0, 2, 3, 4, 1).contiguous()\n        # flatten\n        out = out.view(out.numel() // 2, 2)\n        out = self.softmax(out)\n        # treat channel 0 as the predicted output\n        return out\n\n\nclass VNet(nn.Module):\n    # the number of convolutions in each layer corresponds\n    # to what is in the actual prototxt, not the intent\n    def __init__(self, elu=True, nll=False):\n        super(VNet, self).__init__()\n        self.in_tr = InputTransition(16, elu)\n        self.down_tr32 = DownTransition(16, 1, elu)\n        self.down_tr64 = DownTransition(32, 2, elu)\n        self.down_tr128 = DownTransition(64, 3, elu, dropout=True)\n        self.down_tr256 = DownTransition(128, 2, elu, dropout=True)\n        self.up_tr256 = UpTransition(256, 256, 2, elu, dropout=True)\n        self.up_tr128 = UpTransition(256, 128, 2, elu, dropout=True)\n        self.up_tr64 = UpTransition(128, 64, 1, elu)\n        self.up_tr32 = UpTransition(64, 32, 1, elu)\n        self.out_tr = OutputTransition(32, elu, nll)\n\n    def forward(self, x):\n        out16 = self.in_tr(x)\n        out32 = self.down_tr32(out16)\n        out64 = self.down_tr64(out32)\n        out128 = self.down_tr128(out64)\n        out256 = self.down_tr256(out128)\n        out = self.up_tr256(out256, out128)\n        out = self.up_tr128(out, out64)\n        out = self.up_tr64(out, out32)\n        out = self.up_tr32(out, out16)\n        out = self.out_tr(out)\n        return out\n"""
models/baseline/word_language_model.py,3,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.nn import functional as F\nimport pdb, math\n\n\nclass RNNModel(nn.Module):\n    """"""Container module with an encoder, a recurrent module, and a decoder.""""""\n\n    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, tie_weights=False):\n        super(RNNModel, self).__init__()\n        self.drop = nn.Dropout(dropout)\n        self.encoder = nn.Embedding(ntoken, ninp)\n        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=0)\n        self.decoder = nn.Linear(nhid, ntoken)\n        self.criterion = nn.CrossEntropyLoss().cuda()\n        self.nvol_grad = None\n\n        # Optionally tie weights as in:\n        # ""Using the Output Embedding to Improve Language Models"" (Press & Wolf 2016)\n        # https://arxiv.org/abs/1608.05859\n        # and\n        # ""Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling"" (Inan et al. 2016)\n        # https://arxiv.org/abs/1611.01462\n        if tie_weights:\n            if nhid != ninp:\n                raise ValueError(\'When using the tied flag, nhid must be equal to emsize\')\n            self.decoder.weight = self.encoder.weight\n\n        self.init_weights()\n\n        self.rnn_type = rnn_type\n        self.nhid = nhid\n        self.nlayers = nlayers\n\n    def init_hidden(self, bsz):\n        weight = next(self.parameters()).data\n        return (Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()),\n                Variable(weight.new(self.nlayers, bsz, self.nhid).zero_()))\n\n    def init_weights(self):\n        initrange = 0.1\n        self.encoder.weight.data.uniform_(-initrange, initrange)\n        self.decoder.bias.data.fill_(0)\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def save_grad(self):\n        def hook(grad):\n            self.nvol_grad = grad\n        return hook\n\n    def forward(self, input, hidden):\n        emb = self.drop(self.encoder(input))\n        output, hidden = self.rnn(emb, hidden)\n        output = self.drop(output)\n        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n'"
models/optimized/densenet_new.py,4,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pdb, math\nfrom torch.utils.checkpoint import checkpoint_sequential\nfrom collections import OrderedDict\nimport os, time, sys\nfrom subprocess import Popen, PIPE\n\n__all__ = [\'DenseNet\', \'densenet100\', \'densenet121\', \'densenet169\', \'densenet201\', \'densenet161\', \'densenet264\']\n\ndef densenet100(pretrained=False, **kwargs):\n    r""""""Densenet-100 model""""""\n    model = DenseNet(num_init_features=64, growth_rate=12, block_config=(6, 12, 24, 16),\n                     **kwargs)\n    return model\n\ndef densenet121(pretrained=False, **kwargs):\n    r""""""Densenet-121 model""""""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16),\n                     **kwargs)\n    return model\n\n\ndef densenet161(pretrained=False, **kwargs):\n    r""""""Densenet-161 model""""""\n    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n                     **kwargs)\n    return model\n\n\ndef densenet169(pretrained=False, **kwargs):\n    r""""""Densenet-169 model""""""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n                     **kwargs)\n    return model\n\n\ndef densenet201(pretrained=False, **kwargs):\n    r""""""Densenet-201 model""""""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n                     **kwargs)\n    return model\n\n\ndef densenet264(pretrained=False, **kwargs):\n    r""""""Densenet-264 model""""""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 64, 48),\n                     **kwargs)\n    return model\n\n\nclass _DenseLayer(nn.Sequential):\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super(_DenseLayer, self).__init__()\n        self.add_module(\'norm_1\', nn.BatchNorm2d(num_input_features)),\n        self.add_module(\'relu_1\', nn.ReLU(inplace=True)),\n        self.add_module(\'conv_1\', nn.Conv2d(num_input_features, bn_size *\n                        growth_rate, kernel_size=1, stride=1, bias=False)),\n        self.add_module(\'norm_2\', nn.BatchNorm2d(bn_size * growth_rate)),\n        self.add_module(\'relu_2\', nn.ReLU(inplace=True)),\n        self.add_module(\'conv_2\', nn.Conv2d(bn_size * growth_rate, growth_rate,\n                        kernel_size=3, stride=1, padding=1, bias=False)),\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super(_DenseLayer, self).forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n        return torch.cat([x, new_features], 1)\n\n\nclass _Transition(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super(_Transition, self).__init__()\n        self.add_module(\'norm\', nn.BatchNorm2d(num_input_features))\n        self.add_module(\'relu\', nn.ReLU(inplace=True))\n        self.add_module(\'conv\', nn.Conv2d(num_input_features, num_output_features,\n                                          kernel_size=1, stride=1, bias=False))\n        self.add_module(\'pool\', nn.AvgPool2d(kernel_size=2, stride=2))\n\n\nclass DenseNet(nn.Module):\n    r""""""Densenet-BC model class""""""\n    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n        super(DenseNet, self).__init__()\n\n        # First convolution\n        self.features = nn.Sequential(OrderedDict([\n            (\'conv0\', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n            (\'norm0\', nn.BatchNorm2d(num_init_features)),\n            (\'relu0\', nn.ReLU(inplace=True)),\n            (\'pool0\', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n        ]))\n\n        num_features = num_init_features\n        for i, num_layers in enumerate(block_config):\n            num_input_features = num_features\n            for j in range(num_layers):\n                layer = _DenseLayer(\n                    num_input_features + j * growth_rate, growth_rate, bn_size, drop_rate)\n                self.features.add_module(\'denseblock{}_layer{}\'.format((i + 1), (j + 1)), layer)\n\n            num_features = num_features + num_layers * growth_rate\n            if i != len(block_config) - 1:\n                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n                self.features.add_module(\'transition%d\' % (i + 1), trans)\n                num_features = num_features // 2\n\n        self.features.add_module(\'norm5\', nn.BatchNorm2d(num_features))\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x, chunks=None):\n        modules = [module for k, module in self._modules.items()][0]\n        input_var = x.detach()\n        input_var.requires_grad = True\n        input_var = checkpoint_sequential(modules, chunks, input_var)\n        input_var = F.relu(input_var, inplace=True)\n        input_var = F.avg_pool2d(input_var, kernel_size=7, stride=1).view(input_var.size(0), -1)\n        input_var = self.classifier(input_var)\n        return input_var\n'"
models/optimized/resnet_new.py,2,"b'import torch.nn as nn\nimport math\nimport pdb, time, sys\nfrom collections import OrderedDict\nfrom torch.utils.checkpoint import checkpoint, checkpoint_sequential\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\', \'resnet200\', \'resnet1001\']\n\ndef resnet18(pretrained=False, **kwargs):\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    return model\n\ndef resnet34(pretrained=False, **kwargs):\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    return model\n\ndef resnet50(pretrained=False, **kwargs):\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    return model\n\ndef resnet101(pretrained=False, **kwargs):\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    return model\n\ndef resnet152(pretrained=False, **kwargs):\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    return model\n\ndef resnet200(pretrained=False, **kwargs):\n    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)\n    return model\n\n# looks like the ResNet1001 was only defined for the cifar dataset\ndef resnet1001(pretrained=False, **kwargs):\n    # the input data should be like 32 x 3 x 32 x 32\n    model = PreActResNet(PreActBottleneck, [111, 111, 111], **kwargs)\n    return model\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass PreActBottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.relu3 = nn.ReLU(inplace=True)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.bn1(x)\n        out = self.relu1(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu2(out)\n        out = self.conv2(out)\n\n        out = self.bn2(out)\n        out = self.relu3(out)\n        out = self.conv3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        return out\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\nclass PreActResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=10):\n        self.inplanes = 16\n        super(PreActResNet, self).__init__()\n\n        self.features = nn.Sequential(OrderedDict([\n            (\'conv1\', nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)),\n            (\'bn1\', nn.BatchNorm2d(16)),\n            (\'relu1\', nn.ReLU(inplace=True)),\n        ]))\n\n        self._make_layer(block, 64, layers[0], stage=1)\n        self._make_layer(block, 128, layers[1], stride=2, stage=2)\n        self._make_layer(block, 256, layers[2], stride=2, stage=3)\n        self.features.add_module(\'bn2\', nn.BatchNorm2d(256 * block.expansion))\n        self.features.add_module(\'relu2\', nn.ReLU(inplace=True))\n        self.features.add_module(\'avgpool\', nn.AvgPool2d(8, stride=1))\n        self.fc = nn.Linear(256 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1, stage=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.BatchNorm2d(self.inplanes),\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n            )\n\n        self.features.add_module(\n            \'PreActBottleneck_%d_%d\' % (stage, 0),\n            block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            self.features.add_module(\n                \'PreActBottleneck_%d_%d\' % (stage, i),\n                block(self.inplanes, planes))\n\n    def forward(self, input_var, chunks=3):\n        modules = [module for k, module in self._modules.items()][0]\n        input_var = checkpoint_sequential(modules, chunks, input_var)\n        input_var = input_var.view(input_var.size(0), -1)\n        input_var = self.fc(input_var)\n        return input_var\n'"
models/optimized/vnet_new.py,8,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.checkpoint as checkpoint\nimport pdb\n\ndef passthrough(x, **kwargs):\n    return x\n\ndef ELUCons(elu, nchan):\n    if elu:\n        return nn.ELU(inplace=True)\n    else:\n        return nn.PReLU(nchan)\n\n# normalization between sub-volumes is necessary\n# for good performance\nclass ContBatchNorm3d(nn.modules.batchnorm._BatchNorm):\n    def _check_input_dim(self, input):\n        if input.dim() != 5:\n            raise ValueError('expected 5D input (got {}D input)'\n                             .format(input.dim()))\n        super(ContBatchNorm3d, self)\n\n    def forward(self, input):\n        self._check_input_dim(input)\n        return F.batch_norm(\n            input, self.running_mean, self.running_var, self.weight, self.bias,\n            True, self.momentum, self.eps)\n\n\nclass LUConv(nn.Module):\n    def __init__(self, nchan, elu):\n        super(LUConv, self).__init__()\n        self.relu1 = ELUCons(elu, nchan)\n        self.conv1 = nn.Conv3d(nchan, nchan, kernel_size=5, padding=2)\n        self.bn1 = ContBatchNorm3d(nchan)\n\n    def forward(self, x):\n        out = self.relu1(self.bn1(self.conv1(x)))\n        return out\n\n\ndef _make_nConv(nchan, depth, elu):\n    layers = []\n    for _ in range(depth):\n        layers.append(LUConv(nchan, elu))\n    return nn.Sequential(*layers)\n\n\nclass InputTransition(nn.Module):\n    def __init__(self, outChans, elu):\n        super(InputTransition, self).__init__()\n        self.conv1 = nn.Conv3d(1, 16, kernel_size=5, padding=2)\n        self.bn1 = ContBatchNorm3d(16)\n        self.relu1 = ELUCons(elu, 16)\n\n    def forward(self, x):\n        # do we want a PRELU here as well?\n        out = self.bn1(self.conv1(x))\n        # split input in to 16 channels\n        x16 = torch.cat((x, x, x, x, x, x, x, x,\n                         x, x, x, x, x, x, x, x), 1)\n        out = self.relu1(torch.add(out, x16))\n        return out\n\n\nclass DownTransition(nn.Module):\n    def __init__(self, inChans, nConvs, elu, dropout=False):\n        super(DownTransition, self).__init__()\n        outChans = 2*inChans\n        self.down_conv = nn.Conv3d(inChans, outChans, kernel_size=2, stride=2)\n        self.bn1 = ContBatchNorm3d(outChans)\n        self.do1 = passthrough\n        self.relu1 = ELUCons(elu, outChans)\n        self.relu2 = ELUCons(elu, outChans)\n        if dropout:\n            self.do1 = nn.Dropout3d()\n        self.ops = _make_nConv(outChans, nConvs, elu)\n\n    def forward(self, x):\n        down = self.relu1(self.bn1(self.down_conv(x)))\n        out = self.do1(down)\n        out = self.ops(out)\n        out = self.relu2(torch.add(out, down))\n        return out\n\n\nclass UpTransition(nn.Module):\n    def __init__(self, inChans, outChans, nConvs, elu, dropout=False):\n        super(UpTransition, self).__init__()\n        self.up_conv = nn.ConvTranspose3d(inChans, outChans // 2, kernel_size=2, stride=2)\n        self.bn1 = ContBatchNorm3d(outChans // 2)\n        self.do1 = passthrough\n        self.do2 = nn.Dropout3d()\n        self.relu1 = ELUCons(elu, outChans // 2)\n        self.relu2 = ELUCons(elu, outChans)\n        if dropout:\n            self.do1 = nn.Dropout3d()\n        self.ops = _make_nConv(outChans, nConvs, elu)\n\n    def forward(self, x, skipx):\n        out = self.do1(x)\n        skipxdo = self.do2(skipx)\n        out = self.relu1(self.bn1(self.up_conv(out)))\n        xcat = torch.cat((out, skipxdo), 1)\n        out = self.ops(xcat)\n        out = self.relu2(torch.add(out, xcat))\n        return out\n\n\nclass OutputTransition(nn.Module):\n    def __init__(self, inChans, elu, nll):\n        super(OutputTransition, self).__init__()\n        self.conv1 = nn.Conv3d(inChans, 2, kernel_size=5, padding=2)\n        self.bn1 = ContBatchNorm3d(2)\n        self.conv2 = nn.Conv3d(2, 2, kernel_size=1)\n        self.relu1 = ELUCons(elu, 2)\n        if nll:\n            self.softmax = F.log_softmax\n        else:\n            self.softmax = F.softmax\n\n    def forward(self, x):\n        # convolve 32 down to 2 channels\n        out = self.relu1(self.bn1(self.conv1(x)))\n        out = self.conv2(out)\n\n        # make channels the last axis\n        out = out.permute(0, 2, 3, 4, 1).contiguous()\n        # flatten\n        out = out.view(out.numel() // 2, 2)\n        out = self.softmax(out)\n        # treat channel 0 as the predicted output\n        return out\n\n\nclass VNet(nn.Module):\n    # the number of convolutions in each layer corresponds\n    # to what is in the actual prototxt, not the intent\n    def __init__(self, elu=True, nll=False):\n        super(VNet, self).__init__()\n        self.in_tr = InputTransition(16, elu)\n        self.down_tr32 = DownTransition(16, 1, elu)\n        self.down_tr64 = DownTransition(32, 2, elu)\n        # NOTE: Dropout is turned off since it can effect output if checkpointed\n        # in order to get away, try splitting the DownTransition in two parts\n        # 1st part: everything before dropout, 2nd part: everything after dropout\n        self.down_tr128 = DownTransition(64, 3, elu, dropout=False)\n        self.down_tr256 = DownTransition(128, 2, elu, dropout=False)\n        self.up_tr256 = UpTransition(256, 256, 2, elu, dropout=False)\n        self.up_tr128 = UpTransition(256, 128, 2, elu, dropout=False)\n        self.up_tr64 = UpTransition(128, 64, 1, elu)\n        self.up_tr32 = UpTransition(64, 32, 1, elu)\n        self.out_tr = OutputTransition(32, elu, nll)\n\n    def custom(self, module):\n        def custom_forward(*inputs):\n            if isinstance(module, UpTransition):\n                inputs = module(inputs[0], inputs[1])\n            else:\n                inputs = module(inputs[0])\n            return inputs\n        return custom_forward\n\n    def forward(self, x):\n        out16 = checkpoint.checkpoint(self.custom(self.in_tr), x)\n        out32 = checkpoint.checkpoint(self.custom(self.down_tr32), out16)\n        out64 = checkpoint.checkpoint(self.custom(self.down_tr64), out32)\n        out128 = checkpoint.checkpoint(self.custom(self.down_tr128), out64)\n        out256 = checkpoint.checkpoint(self.custom(self.down_tr256), out128)\n        out = checkpoint.checkpoint(self.custom(self.up_tr256), out256, out128)\n        out = checkpoint.checkpoint(self.custom(self.up_tr128), out, out64)\n        out = checkpoint.checkpoint(self.custom(self.up_tr64), out, out32)\n        out = self.up_tr32(out, out16)\n        out = self.out_tr(out)\n        return out\n"""
models/optimized/word_language_model_new.py,3,"b'import torch\nimport torch.nn as nn\nimport torch.utils.checkpoint as checkpoint\n\nimport math\n\n\nclass RNNModel(nn.Module):\n    """"""Container module with an encoder, a recurrent module, and a decoder.""""""\n\n    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, tie_weights=False):\n        super(RNNModel, self).__init__()\n        self.drop = nn.Dropout(dropout)\n        self.encoder = nn.Embedding(ntoken, ninp)\n        if rnn_type in [\'LSTM\', \'GRU\']:\n            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n        else:\n            try:\n                nonlinearity = {\'RNN_TANH\': \'tanh\', \'RNN_RELU\': \'relu\'}[rnn_type]\n            except KeyError:\n                raise ValueError( """"""An invalid option for `--model` was supplied,\n                                 options are [\'LSTM\', \'GRU\', \'RNN_TANH\' or \'RNN_RELU\']"""""")\n            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n        self.decoder = nn.Linear(nhid, ntoken)\n        self.criterion = nn.CrossEntropyLoss().cuda()\n        self.nvol_grad = None\n\n        if tie_weights:\n            if nhid != ninp:\n                raise ValueError(\'When using the tied flag, nhid must be equal to emsize\')\n            self.decoder.weight = self.encoder.weight\n\n        self.init_weights()\n\n        self.rnn_type = rnn_type\n        self.nhid = nhid\n        self.nlayers = nlayers\n\n    def init_weights(self):\n        initrange = 0.1\n        self.encoder.weight.data.uniform_(-initrange, initrange)\n        self.decoder.bias.data.fill_(0)\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def init_hidden(self, bsz):\n        weight = next(self.parameters()).data\n        if self.rnn_type == \'LSTM\':\n            return (weight.new(self.nlayers, bsz, self.nhid).zero_(),\n                    weight.new(self.nlayers, bsz, self.nhid).zero_())\n        else:\n            return weight.new(self.nlayers, bsz, self.nhid).zero_()\n\n    def save_grad(self):\n        def hook(grad):\n            self.nvol_grad = grad\n        return hook\n\n    def custom(self, start, end):\n        def custom_forward(*inputs):\n            # print(\'start: {} end: {}\'.format(start, end))\n            output, hidden = self.rnn(\n                inputs[0][start:(end+1)], (inputs[1], inputs[2])\n            )\n            return output, hidden[0], hidden[1]\n        return custom_forward\n\n    def forward(self, input, hidden, targets, chunks=4):\n        total_modules = input.shape[0]\n        chunk_size = int(math.floor(float(total_modules) / chunks))\n        start, end = 0, -1\n        emb = self.drop(self.encoder(input))\n\n        output = []\n        for j in range(chunks):\n            start = end + 1\n            end = start + chunk_size - 1\n            if j == (chunks - 1):\n                end = total_modules - 1\n            out = checkpoint.checkpoint(self.custom(start, end), emb, hidden[0], hidden[1])\n            output.append(out[0])\n            hidden = (out[1], out[2])\n        output = torch.cat(output, 0)\n        hidden = (out[1], out[2])\n\n        output = self.drop(output).view(output.size(0) * output.size(1), output.size(2))\n        out = output.detach()\n        out.requires_grad = True\n        out.register_hook(self.save_grad())\n        total_modules = out.shape[0]\n        chunks = 10\n        chunk_size = int(math.floor(float(total_modules) / chunks))\n        start, end = 0, -1\n        for i in range(chunks):\n            start = end + 1\n            end = start + chunk_size - 1\n            if i == (chunks - 1):\n                end = total_modules - 1\n            decoded = self.decoder(out[start:(end+1)])\n            loss = self.criterion(decoded, targets[start:(end+1)])\n            loss.backward()\n        return output, hidden\n\n    def backward(self, output):\n        output.backward(self.nvol_grad.data)\n'"
