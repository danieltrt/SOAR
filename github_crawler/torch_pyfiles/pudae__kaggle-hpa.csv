file_path,api_count,code
augmentation_search.py,1,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport argparse\nimport pprint\nimport random\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom tensorboardX import SummaryWriter\n\nfrom datasets import get_dataloader\nfrom transforms import get_transform, POLICIES\nfrom models import get_model\nfrom losses import get_loss\nfrom optimizers import get_optimizer\nfrom schedulers import get_scheduler\nimport utils\nimport utils.config\nimport utils.checkpoint\n\nfrom train import train\n\n\ndef sample_policy():\n    def sample_params(r):\n        if isinstance(r, list):\n            return random.choice(r)\n\n        if not isinstance(r, tuple):\n            return r\n\n        r1, r2 = r\n        if not isinstance(r1, tuple):\n            assert not isinstance(r2, tuple)\n            if isinstance(r1, float):\n                return random.uniform(r1, r2)\n            else:\n                return random.randint(r1, r2)\n\n        assert isinstance(r1, tuple)\n        assert isinstance(r2, tuple)\n        return (sample_params(r1), sample_params(r2))\n\n    policies = []\n\n    for _ in range(5):\n        policy_0, policy_1 = random.sample(POLICIES, 2)\n        params_0 = {key:sample_params(value) for key, value in policy_0[1].items()}\n        params_1 = {key:sample_params(value) for key, value in policy_1[1].items()}\n        policies.append(((policy_0[0], params_0), (policy_1[0], params_1)))\n    return policies\n\n\ndef search_once(config, policy):\n    model = get_model(config).cuda()\n    criterion = get_loss(config)\n    optimizer = get_optimizer(config, model.parameters())\n    scheduler = get_scheduler(config, optimizer, -1)\n\n    transforms = {\'train\': get_transform(config, \'train\', params={\'policies\': policy}),\n                  \'val\': get_transform(config, \'val\')}\n    dataloaders = {split:get_dataloader(config, split, transforms[split])\n                   for split in [\'train\', \'val\']}\n\n    score_dict = train(config, model, dataloaders, criterion, optimizer, scheduler, None, 0)\n    return score_dict[\'f1_mavg\']\n\n\ndef run(config):\n    train_dir = config.train.dir\n    writer = SummaryWriter(config.train.dir)\n    utils.prepare_train_directories(config)\n\n    # base_policy\n    policy = []\n    score = search_once(config, policy)\n    print(\'===============================\')\n    print(\'base score:\', score)\n    writer.add_scalar(\'val/f1\', score, 0)\n\n    policies = []\n    for i in range(50):\n        policy = sample_policy()\n        score = search_once(config, policy)\n        writer.add_scalar(\'val/f1\', score, i+1)\n        policies.append((score, policy))\n        policies = list(sorted(policies, key=lambda v: v[0]))[-5:]\n\n        with open(os.path.join(config.train.dir, \'best_policy.data\'), \'w\') as fid:\n            fid.write(str([v[1] for v in policies]))\n\n        for score, policy in policies:\n            print(\'score:\', score)\n            print(\'policy:\', policy)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\'HPA\')\n    parser.add_argument(\'--config\', dest=\'config_file\',\n                        help=\'configuration filename\',\n                        default=None, type=str)\n    return parser.parse_args()\n\n\ndef main():\n    import warnings\n    warnings.filterwarnings(""ignore"")\n\n    print(\'Search Augmentation!!\')\n    args = parse_args()\n    if args.config_file is None:\n        raise Exception(\'no configuration file\')\n\n    config = utils.config.load(args.config_file)\n    pprint.PrettyPrinter(indent=2).pprint(config)\n    utils.prepare_train_directories(config)\n    run(config)\n\n    print(\'success!\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
inference.py,5,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport math\nimport argparse\nimport pprint\nimport tqdm\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\n\nfrom datasets import get_dataloader\nfrom transforms import get_transform\nfrom models import get_model\nfrom losses import get_loss\nfrom optimizers import get_optimizer\nfrom schedulers import get_scheduler\nimport utils.config\nimport utils.checkpoint\n\n\ndef inference(config, model, split, output_filename=None):\n    config.eval.batch_size = 2\n    if split == \'test\':\n        config.data.name = \'TestDataset\'\n\n    dataloader = get_dataloader(config, split, get_transform(config, split))\n\n    if torch.cuda.device_count() > 1:\n        model = torch.nn.DataParallel(model)\n    model = model.cuda()\n    model.eval()\n\n    key_list = []\n    label_list = []\n    probability_list = []\n\n    with torch.no_grad():\n        batch_size = config.eval.batch_size\n        total_size = len(dataloader.dataset)\n        total_step = math.ceil(total_size / batch_size)\n        for i, data in tqdm.tqdm(enumerate(dataloader), total=total_step):\n            images = data[\'image\'].cuda()\n\n            if len(images.size()) == 5:\n                B, T, C, H, W = images.size()\n                logits = model(images.view(-1, C, H, W))[:,:28]\n                logits = logits.view(B, T, -1)\n                probabilities = F.sigmoid(logits)\n                probabilities = probabilities.mean(dim=1)\n            else:\n                logits = model(images)[:,:28]\n                probabilities = F.sigmoid(logits)\n\n            probability_list.append(probabilities.cpu().numpy())\n\n            if split != \'test\':\n                label_list.append(data[\'label\'].numpy())\n\n            key_list.extend(data[\'key\'])\n\n        if split != \'test\':\n            labels = np.concatenate(label_list, axis=0)\n            assert labels.ndim == 2\n            assert labels.shape[0] == total_size\n            assert labels.shape[-1] == 28\n\n        probabilities = np.concatenate(probability_list, axis=0)\n        assert probabilities.ndim == 2\n        assert probabilities.shape[0] == total_size\n        assert probabilities.shape[-1] == 28\n\n        if split != \'test\':\n            records = []\n            for label, probability in zip(labels, probabilities):\n              records.append(tuple([str(l) for l in label] + [\'{:.04f}\'.format(p) for p in probability]))\n\n            columns = [\'L{:02d}\'.format(l) for l in range(28)] + [\'P{:02d}\'.format(l) for l in range(28)]\n        else:\n            records = []\n            for key, probability in zip(key_list, probabilities):\n                records.append(tuple([key] + [\'{:.04f}\'.format(p) for p in probability]))\n\n            columns = [\'Id\'] + [\'P{:02d}\'.format(l) for l in range(28)]\n\n        df = pd.DataFrame.from_records(records, columns=columns)\n        print(\'save {}\'.format(output_filename))\n        df.to_csv(output_filename, index=False)\n\n\ndef run(config, split, checkpoint_name, output_filename):\n    model = get_model(config).cuda()\n\n    checkpoint = utils.checkpoint.get_checkpoint(config, name=checkpoint_name)\n    utils.checkpoint.load_checkpoint(model, None, checkpoint)\n\n    inference(config, model, split, output_filename)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\'hpa\')\n    parser.add_argument(\'--output\', dest=\'output_filename\',\n                        help=\'output filename\',\n                        default=None, type=str)\n    parser.add_argument(\'--config\', dest=\'config_file\',\n                        help=\'configuration filename\',\n                        default=None, type=str)\n    parser.add_argument(\'--checkpoint\', dest=\'checkpoint_filename\',\n                        help=\'checkpoint filename\',\n                        default=None, type=str)\n    parser.add_argument(\'--num_tta\', dest=\'num_tta\',\n                        help=\'number of tta images\',\n                        default=4, type=int)\n    parser.add_argument(\'--split\', dest=\'split\',\n                        help=\'split\',\n                        default=\'test\', type=str)\n    return parser.parse_args()\n\n\ndef main():\n    import warnings\n    warnings.filterwarnings(""ignore"")\n\n    torch.multiprocessing.set_sharing_strategy(\'file_system\')\n\n    print(\'inference HPA\')\n    args = parse_args()\n    config = utils.config.load(args.config_file)\n    config.transform.name = \'tta_transform\'\n    config.transform.params.num_tta = args.num_tta\n\n    os.makedirs(os.path.dirname(args.output_filename), exist_ok=True)\n\n    run(config, args.split, args.checkpoint_filename, args.output_filename)\n\n    print(\'success!\')\n\n\nif __name__ == \'__main__\':\n  main()\n'"
make_submission.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport numpy as np\nimport pandas as pd\n\nimport utils.metrics\n\n\ndef find_best_thres(df_val):\n    total = len(df_val)\n\n    records = []\n    for label in range(28):\n        label_key = \'L{:02d}\'.format(label)\n        prob_key = \'P{:02d}\'.format(label)\n        df = df_val[[label_key, prob_key]]\n        df_pos = df[df[label_key] == 1]\n        proportion = len(df_pos) / total\n\n        best_diff = 1000\n        best_thres = 0\n        for thres in np.arange(0.05, 1.00, 0.01):\n            positive = int(np.sum((df_val[prob_key].values > thres).astype(int)))\n            cur_proportion = positive / total\n            cur_diff = abs(proportion - cur_proportion)\n            if cur_diff < best_diff:\n                best_diff = cur_diff\n                best_thres = thres\n        records.append((label, best_thres))\n    df_ret = pd.DataFrame.from_records(records, columns=[\'label\', \'thres\'])\n    return df_ret.set_index(\'label\')\n\n\ndef ensemble(dfs, weights):\n    label_keys = [\'L{:02}\'.format(l) for l in range(28)]\n    prob_keys = [\'P{:02}\'.format(l) for l in range(28)]\n    if \'L00\' in dfs[0].index:\n        df_base = dfs[0][label_keys]\n        df_probs = sum([df[prob_keys] * w for df, w in zip(dfs, weights)]) / sum(weights)\n        df = pd.concat([df_base, df_probs], axis=1)\n    else:\n        df = sum([df * w for df, w in zip(dfs, weights)]) / sum(weights)\n    return df\n\n\ndef evaluate(df_val, df_thres):\n    label_keys = [\'L{:02}\'.format(l) for l in range(28)]\n    prob_keys = [\'P{:02}\'.format(l) for l in range(28)]\n\n    df_label = df_val[label_keys]\n    df_prob = df_val[prob_keys]\n\n    np_label = df_label.values\n    np_prob = df_prob.values\n    np_pred = (np_prob > df_thres[\'thres\'].values).astype(int)\n    f1 = utils.metrics.f1_score(np_label, np_pred)\n    return f1\n\n\ndef make_submission(df_test, df_thres):\n    thres = df_thres[\'thres\'].values\n    records = []\n    for Id, row in df_test.iterrows():\n        probs = row.values\n        pred = list(np.where((probs > thres) == 1)[0])\n        labels = \' \'.join([str(l) for l in pred])\n        records.append((Id, labels))\n    df_output = pd.DataFrame.from_records(records, columns=[\'Id\', \'Predicted\'])\n    return df_output.set_index(\'Id\')\n\n\ndef apply_leak(df_submission, df_leak):\n    for key, row in df_leak.iterrows():\n        target = row[\'Target\']\n        if df_submission.loc[key][\'Predicted\'] != target:\n            df_submission.loc[key][\'Predicted\'] = target\n    return df_submission\n\n\ndef main():\n    import warnings\n    warnings.filterwarnings(""ignore"")\n\n    print(\'make submission\')\n\n    test_val_filenames = [\'inferences/resnet34.0.test_val.csv\',\n                          \'inferences/resnet34.1.test_val.csv\',\n                          \'inferences/resnet34.2.test_val.csv\',\n                          \'inferences/resnet34.3.test_val.csv\',\n                          \'inferences/resnet34.4.test_val.csv\',\n                          \'inferences/inceptionv3.0.test_val.csv\',\n                          \'inferences/se_resnext50.0.test_val.csv\']\n\n    test_filenames = [\'inferences/resnet34.0.test.csv\',\n                      \'inferences/resnet34.1.test.csv\',\n                      \'inferences/resnet34.2.test.csv\',\n                      \'inferences/resnet34.3.test.csv\',\n                      \'inferences/resnet34.4.test.csv\',\n                      \'inferences/inceptionv3.0.test.csv\',\n                      \'inferences/se_resnext50.0.test.csv\']\n\n    weights = [1/5, 1/5, 1/5, 1/5, 1/5, 1.0, 1.0]\n\n    leak_filenames = [\'data/leak.csv\',\n                      \'data/data_leak.ahash.csv\',\n                      \'data/data_leak.phash.csv\']\n\n    output_filename = \'submissions/submission.csv\'\n    os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n\n    df_test_val_list = [pd.read_csv(f) for f in test_val_filenames]\n    df_test_list = [pd.read_csv(f, index_col=\'Id\') for f in test_filenames]\n\n    print(\'ensemble..\')\n    df_test_val = ensemble(df_test_val_list, weights)\n    df_test = ensemble(df_test_list, weights)\n\n    df_thres = find_best_thres(df_test_val)\n    f1 = evaluate(df_test_val, df_thres)\n    print(\'validation f1:\', f1)\n\n    df_submission = make_submission(df_test, df_thres)\n    df_submission.to_csv(output_filename)\n\n    print(\'apply leak\')\n    df_leak_list = [pd.read_csv(f, index_col=\'Id\') for f in leak_filenames]\n    for df_leak in df_leak_list:\n        df_submission = apply_leak(df_submission, df_leak)\n    df_submission.to_csv(output_filename + \'.leak.csv\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
swa.py,2,"b""import os\nimport argparse\nimport pprint\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\nfrom datasets import get_dataloader\nfrom transforms import get_transform\nfrom models import get_model\nimport utils.config\nimport utils.swa as swa\nimport utils.checkpoint\n\n\ndef get_checkpoints(config, num_checkpoint=10, epoch_end=None):\n    checkpoint_dir = os.path.join(config.train.dir, 'checkpoint')\n    if epoch_end is not None:\n        epoch_begin = epoch_end - num_checkpoint + 1\n        checkpoints = [os.path.join(checkpoint_dir, 'epoch.{:04d}.pth'.format(e))\n                       for e in range(epoch_begin, epoch_end+1)]\n        checkpoints = [f for f in checkpoints if os.path.exists(f)]\n    else:\n        checkpoints = os.listdir(checkpoint_dir)\n        checkpoints = [name for name in checkpoints\n                       if name.startswith('epoch') and name.endswith('pth')]\n        checkpoints = list(sorted([os.path.join(checkpoint_dir, f) for f in checkpoints]))\n        checkpoints = checkpoints[-num_checkpoint:]\n    return checkpoints\n\n\ndef run(config, num_checkpoint, epoch_end, output_filename):\n    dataloader = get_dataloader(config, 'train', get_transform(config, 'val'))\n\n    model = get_model(config).cuda()\n    checkpoints = get_checkpoints(config, num_checkpoint, epoch_end)\n\n    utils.checkpoint.load_checkpoint(model, None, checkpoints[0])\n    for i, checkpoint in enumerate(checkpoints[1:]):\n        model2 = get_model(config).cuda()\n        last_epoch, _ = utils.checkpoint.load_checkpoint(model2, None, checkpoint)\n        swa.moving_average(model, model2, 1. / (i + 2))\n\n    with torch.no_grad():\n        swa.bn_update(dataloader, model)\n\n    output_name = '{}.{}.{:03d}'.format(output_filename, num_checkpoint, last_epoch)\n    print('save {}'.format(output_name))\n    utils.checkpoint.save_checkpoint(config, model, None, 0, 0,\n                                     name=output_name,\n                                     weights_dict={'state_dict': model.state_dict()})\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description='hpa')\n    parser.add_argument('--config', dest='config_file',\n                        help='configuration filename',\n                        default=None, type=str)\n    parser.add_argument('--output', dest='output_filename',\n                        help='output filename',\n                        default='swa', type=str)\n    parser.add_argument('--num_checkpoint', dest='num_checkpoint',\n                        help='number of checkpoints for averaging',\n                        default=10, type=int)\n    parser.add_argument('--epoch_end', dest='epoch_end',\n                        help='epoch end',\n                        default=None, type=int)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n    if args.config_file is None:\n        raise Exception('no configuration file')\n    \n    config = utils.config.load(args.config_file)\n    pprint.PrettyPrinter(indent=2).pprint(config)\n    run(config, args.num_checkpoint, args.epoch_end, args.output_filename)\n    \n    print('success!')\n\n\nif __name__ == '__main__':\n    main()\n"""
train.py,4,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport math\nimport argparse\nimport pprint\nimport tqdm\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom tensorboardX import SummaryWriter\n\nfrom datasets import get_dataloader\nfrom transforms import get_transform\nfrom models import get_model\nfrom losses import get_loss\nfrom optimizers import get_optimizer\nfrom schedulers import get_scheduler\nimport utils\nimport utils.config\nimport utils.checkpoint\nimport utils.metrics\n\n\ndef inference(model, images):\n    logits = model(images)\n    if isinstance(logits, tuple):\n        logits, aux_logits = logits\n    else:\n        aux_logits = None\n    probabilities = F.sigmoid(logits)\n    return logits, aux_logits, probabilities\n\n\ndef evaluate_single_epoch(config, model, dataloader, criterion,\n                          epoch, writer, postfix_dict):\n    model.eval()\n\n    with torch.no_grad():\n        batch_size = config.eval.batch_size\n        total_size = len(dataloader.dataset)\n        total_step = math.ceil(total_size / batch_size)\n\n        probability_list = []\n        label_list = []\n        loss_list = []\n        tbar = tqdm.tqdm(enumerate(dataloader), total=total_step)\n        for i, data in tbar:\n            images = data[\'image\'].cuda()\n            labels = data[\'label\'].cuda()\n            logits, aux_logits, probabilities = inference(model, images)\n\n            loss = criterion(logits, labels.float())\n            if aux_logits is not None:\n                aux_loss = criterion(aux_logits, labels.float())\n                loss = loss + 0.4 * aux_loss\n            loss_list.append(loss.item())\n\n            probability_list.extend(probabilities.cpu().numpy())\n            label_list.extend(labels.cpu().numpy())\n\n            f_epoch = epoch + i / total_step\n            desc = \'{:5s}\'.format(\'val\')\n            desc += \', {:06d}/{:06d}, {:.2f} epoch\'.format(i, total_step, f_epoch)\n            tbar.set_description(desc)\n            tbar.set_postfix(**postfix_dict)\n\n        log_dict = {}\n        labels = np.array(label_list)\n        probabilities = np.array(probability_list)\n\n        predictions = (probabilities > 0.5).astype(int)\n        accuracy = np.sum((predictions == labels).astype(float)) / float(predictions.size)\n\n        log_dict[\'acc\'] = accuracy\n        log_dict[\'f1\'] = utils.metrics.f1_score(labels, predictions)\n        log_dict[\'loss\'] = sum(loss_list) / len(loss_list)\n\n        if writer is not None:\n            for l in range(28):\n                f1 = utils.metrics.f1_score(labels[:,l], predictions[:,l], \'binary\')\n                writer.add_scalar(\'val/f1_{:02d}\'.format(l), f1, epoch)\n\n        for key, value in log_dict.items():\n            if writer is not None:\n                writer.add_scalar(\'val/{}\'.format(key), value, epoch)\n            postfix_dict[\'val/{}\'.format(key)] = value\n\n        return f1\n\n\ndef train_single_epoch(config, model, dataloader, criterion, optimizer,\n                       epoch, writer, postfix_dict):\n    model.train()\n\n    batch_size = config.train.batch_size\n    total_size = len(dataloader.dataset)\n    total_step = math.ceil(total_size / batch_size)\n\n    log_dict = {}\n    tbar = tqdm.tqdm(enumerate(dataloader), total=total_step)\n    for i, data in tbar:\n        images = data[\'image\'].cuda()\n        labels = data[\'label\'].cuda()\n        logits, aux_logits, probabilities = inference(model, images)\n        loss = criterion(logits, labels.float())\n        if aux_logits is not None:\n            aux_loss = criterion(aux_logits, labels.float())\n            loss = loss + 0.4 * aux_loss\n        log_dict[\'loss\'] = loss.item()\n\n        predictions = (probabilities > 0.5).long()\n        accuracy = (predictions == labels).sum().float() / float(predictions.numel())\n        log_dict[\'acc\'] = accuracy.item()\n\n        loss.backward()\n\n        if config.train.num_grad_acc is None:\n            optimizer.step()\n            optimizer.zero_grad()\n        elif (i+1) % config.train.num_grad_acc == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n\n        f_epoch = epoch + i / total_step\n\n        log_dict[\'lr\'] = optimizer.param_groups[0][\'lr\']\n        for key, value in log_dict.items():\n            postfix_dict[\'train/{}\'.format(key)] = value\n\n        desc = \'{:5s}\'.format(\'train\')\n        desc += \', {:06d}/{:06d}, {:.2f} epoch\'.format(i, total_step, f_epoch)\n        tbar.set_description(desc)\n        tbar.set_postfix(**postfix_dict)\n\n        if i % 100 == 0:\n            log_step = int(f_epoch * 10000)\n            if writer is not None:\n                for key, value in log_dict.items():\n                    writer.add_scalar(\'train/{}\'.format(key), value, log_step)\n\n\ndef train(config, model, dataloaders, criterion, optimizer, scheduler, writer, start_epoch):\n    num_epochs = config.train.num_epochs\n\n    if torch.cuda.device_count() > 1:\n        model = torch.nn.DataParallel(model)\n    model = model.cuda()\n\n    postfix_dict = {\'train/lr\': 0.0,\n                    \'train/acc\': 0.0,\n                    \'train/loss\': 0.0,\n                    \'val/f1\': 0.0,\n                    \'val/acc\': 0.0,\n                    \'val/loss\': 0.0}\n\n    f1_list = []\n    best_f1 = 0.0\n    best_f1_mavg = 0.0\n    for epoch in range(start_epoch, num_epochs):\n        # train phase\n        train_single_epoch(config, model, dataloaders[\'train\'],\n                           criterion, optimizer, epoch, writer, postfix_dict)\n\n        # val phase\n        f1 = evaluate_single_epoch(config, model, dataloaders[\'val\'],\n                                   criterion, epoch, writer, postfix_dict)\n\n        if config.scheduler.name == \'reduce_lr_on_plateau\':\n          scheduler.step(f1)\n        elif config.scheduler.name != \'reduce_lr_on_plateau\':\n          scheduler.step()\n\n        utils.checkpoint.save_checkpoint(config, model, optimizer, epoch, 0)\n\n        f1_list.append(f1)\n        f1_list = f1_list[-10:]\n        f1_mavg = sum(f1_list) / len(f1_list)\n\n        if f1 > best_f1:\n            best_f1 = f1\n        if f1_mavg > best_f1_mavg:\n            best_f1_mavg = f1_mavg\n    return {\'f1\': best_f1, \'f1_mavg\': best_f1_mavg}\n\n\ndef run(config):\n    train_dir = config.train.dir\n\n    model = get_model(config).cuda()\n    criterion = get_loss(config)\n    optimizer = get_optimizer(config, model.parameters())\n\n    checkpoint = utils.checkpoint.get_initial_checkpoint(config)\n    if checkpoint is not None:\n        last_epoch, step = utils.checkpoint.load_checkpoint(model, optimizer, checkpoint)\n    else:\n        last_epoch, step = -1, -1\n\n    print(\'from checkpoint: {} last epoch:{}\'.format(checkpoint, last_epoch))\n    scheduler = get_scheduler(config, optimizer, last_epoch)\n\n    dataloaders = {split:get_dataloader(config, split, get_transform(config, split))\n                   for split in [\'train\', \'val\']}\n\n    writer = SummaryWriter(config.train.dir)\n    train(config, model, dataloaders, criterion, optimizer, scheduler,\n          writer, last_epoch+1)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\'HPA\')\n    parser.add_argument(\'--config\', dest=\'config_file\',\n                        help=\'configuration filename\',\n                        default=None, type=str)\n    return parser.parse_args()\n\n\ndef main():\n    import warnings\n    warnings.filterwarnings(""ignore"")\n\n    print(\'train HPA Image Classification Challenge.\')\n    args = parse_args()\n    if args.config_file is None:\n      raise Exception(\'no configuration file\')\n\n    config = utils.config.load(args.config_file)\n    pprint.PrettyPrinter(indent=2).pprint(config)\n    utils.prepare_train_directories(config)\n    run(config)\n\n    print(\'success!\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
datasets/__init__.py,0,"b'from .dataset_factory import get_dataloader, get_dataset\n'"
datasets/dataset_factory.py,3,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\n\nimport numpy as np\nimport torch.utils.data\nimport torch.utils.data.sampler\nfrom torch.utils.data import DataLoader\n\nfrom .default import DefaultDataset\nfrom .small import SmallDataset\nfrom .test import TestDataset\n\n\ndef get_dataset(config, split, transform=None, last_epoch=-1):\n    f = globals().get(config.name)\n\n    return f(config.dir,\n             split=split,\n             transform=transform,\n             **config.params)\n\n\ndef get_dataloader(config, split, transform=None, **_):\n    dataset = get_dataset(config.data, split, transform)\n\n    is_train = 'train' == split\n    batch_size = config.train.batch_size if is_train else config.eval.batch_size\n\n    dataloader = DataLoader(dataset,\n                            shuffle=is_train,\n                            batch_size=batch_size,\n                            drop_last=is_train,\n                            num_workers=config.transform.num_preprocessor,\n                            pin_memory=False)\n    return dataloader\n"""
datasets/default.py,1,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport scipy.misc as misc\n\nfrom torch.utils.data.dataset import Dataset\n\n\nclass DefaultDataset(Dataset):\n    def __init__(self,\n                 dataset_dir,\n                 split,\n                 transform=None,\n                 idx_fold=0,\n                 num_fold=5,\n                 split_prefix='split.stratified',\n                 **_):\n        self.split = split\n        self.idx_fold = idx_fold\n        self.num_fold = num_fold\n        self.transform = transform\n        self.dataset_dir = dataset_dir\n        self.split_prefix = split_prefix\n        self.images_dir = os.path.join(dataset_dir, 'rgby', 'train')\n        self.external_images_dir = os.path.join(dataset_dir, 'rgby', 'external')\n\n        self.df_labels = self.load_labels()\n        self.examples = self.load_examples()\n        self.size = len(self.examples)\n\n    def load_labels(self):\n        labels_path = '{}.{}.csv'.format(self.split_prefix, self.idx_fold)\n        labels_path = os.path.join(self.dataset_dir, labels_path)\n        df_labels = pd.read_csv(labels_path)\n        df_labels = df_labels[df_labels['Split'] == self.split]\n        df_labels = df_labels.reset_index()\n\n        train_id_len = len('770126a4-bbc6-11e8-b2bc-ac1f6b6435d0')\n        def to_filepath(v):\n            if len(v) == train_id_len:\n                return os.path.join(self.images_dir, v + '.png')\n            else:\n                return os.path.join(self.external_images_dir, v + '.png')\n\n        df_labels['filepath'] = df_labels['Id'].transform(to_filepath)\n        return df_labels\n\n    def load_examples(self):\n        return [(row['Id'], row['filepath'], [int(l) for l in row['Target'].split(' ')])\n                for _, row in self.df_labels.iterrows()]\n\n    def __getitem__(self, index):\n        example = self.examples[index]\n\n        filename = example[1]\n        image = misc.imread(filename)\n\n        label = [0 for _ in range(28)]\n        for l in example[2]:\n            label[l] = 1\n        label = np.array(label)\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return {'image': image,\n                'label': label,\n                'key': example[0]}\n\n    def __len__(self):\n        return self.size\n\n\ndef test():\n    dataset = DefaultDataset('data', 'train', None)\n    print(len(dataset))\n    example = dataset[0]\n    example = dataset[1]\n\n    dataset = DefaultDataset('data', 'val', None)\n    print(len(dataset))\n\nif __name__ == '__main__':\n    test()\n"""
datasets/small.py,1,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tqdm\nimport numpy as np\nimport pandas as pd\nimport scipy.misc as misc\n\nimport torch\nfrom torch.utils.data.dataset import Dataset\n\n\nclass SmallDataset(Dataset):\n    def __init__(self,\n                 dataset_dir,\n                 split,\n                 transform=None,\n                 **_):\n        self.split = split\n        self.transform = transform\n        self.dataset_dir = dataset_dir\n        self.images_dir = os.path.join(dataset_dir, 'rgby', 'train')\n\n        self.df_labels = self.load_labels()\n        self.examples = self.load_examples()\n        self.size = len(self.examples)\n\n    def load_labels(self):\n        if self.split == 'train':\n            labels_path = os.path.join(self.dataset_dir, 'split.stratified.small.0.csv')\n        else:\n            labels_path = os.path.join(self.dataset_dir, 'split.stratified.small.1.csv')\n\n        df_labels = pd.read_csv(labels_path)\n        df_labels = df_labels[df_labels['Split'] == 'val']\n\n        df_labels['filepath'] = df_labels['Id'].transform(\n            lambda v: os.path.join(self.images_dir, v + '.png'))\n\n        return df_labels\n\n    def load_examples(self):\n        return [(row['Id'], row['filepath'], [int(l) for l in row['Target'].split(' ')])\n                for _, row in self.df_labels.iterrows()]\n\n    def __getitem__(self, index):\n        example = self.examples[index]\n\n        filename = example[1]\n        image = misc.imread(filename)\n\n        label = [0 for _ in range(28)]\n        for l in example[2]:\n          label[l] = 1\n        label = np.array(label)\n\n        if self.transform is not None:\n          image = self.transform(image)\n\n        return {'image': image,\n                'label': label,\n                'key': example[0]}\n\n    def __len__(self):\n        return self.size\n\n\ndef test():\n    dataset = SmallDataset('data', 'train', None)\n    example = dataset[0]\n    print(example['image'].shape, np.where(np.array(example['label']) == 1))\n    example = dataset[1]\n    print(example['image'].shape, np.where(np.array(example['label']) == 1))\n\n    dataset = SmallDataset('data', 'val', None)\n    example = dataset[0]\n    print(example['image'].shape, np.where(np.array(example['label']) == 1))\n    example = dataset[1]\n    print(example['image'].shape, np.where(np.array(example['label']) == 1))\n\nif __name__ == '__main__':\n    test()\n\n\n\n"""
datasets/test.py,1,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# pylint: disable=W0611\n\nimport os\n\nimport tqdm\nimport numpy as np\nimport pandas as pd\nimport scipy.misc as misc\n\nimport torch\nfrom torch.utils.data.dataset import Dataset\n\n\nclass TestDataset(Dataset):\n    def __init__(self,\n                 dataset_dir,\n                 split,\n                 transform=None,\n                 **_):\n        self.split = split\n        self.transform = transform\n        self.dataset_dir = dataset_dir\n        self.images_dir = os.path.join(dataset_dir, 'rgby', 'test')\n\n        self.df_sample = self.load_filenames()\n        self.size = len(self.df_sample)\n\n    def load_filenames(self):\n        return pd.read_csv(os.path.join(self.dataset_dir, 'sample_submission.csv'))\n\n    def __getitem__(self, index):\n        id_str = self.df_sample.iloc[index]['Id']\n\n        filename = os.path.join(self.images_dir, id_str + '.png')\n        image = misc.imread(filename)\n\n        if self.transform is not None:\n          image = self.transform(image)\n\n        return {'image': image,\n                'key': id_str}\n\n    def __len__(self):\n        return self.size\n\n\ndef test():\n    dataset = DefaultDataset('/data/pudae/hpa/', 'train', None)\n    print(len(dataset))\n    example = dataset[0]\n    example = dataset[1]\n\n    dataset = DefaultDataset('/data/pudae/hpa/', 'val', None)\n    print(len(dataset))\n\n\nif __name__ == '__main__':\n    test()\n\n"""
losses/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .loss_factory import get_loss\n\n'
losses/loss_factory.py,3,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef binary_focal_loss(gamma=2, **_):\n    def func(input, target):\n        assert target.size() == input.size()\n\n        max_val = (-input).clamp(min=0)\n\n        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n        invprobs = F.logsigmoid(-input * (target * 2 - 1))\n        loss = (invprobs * gamma).exp() * loss\n        return loss.mean()\n\n    return func\n\n\ndef cross_entropy(**_):\n    return torch.nn.BCEWithLogitsLoss()\n\n\ndef get_loss(config):\n    f = globals().get(config.loss.name)\n    return f(**config.loss.params)\n'"
models/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .model_factory import get_model\n\n'
models/model_factory.py,2,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n# pylint: disable=W0611\nimport types\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models\nimport pretrainedmodels\n\n\nclass Attention(nn.Module):\n    def __init__(self, num_classes=28, cnn='resnet34', attention_size=8):\n        super().__init__()\n        self.num_classes = num_classes\n        self.cnn = globals().get('get_' + cnn)()\n        self.attention_size = attention_size\n\n        self.avgpool = nn.AdaptiveAvgPool2d(self.attention_size)\n\n        in_features = self.cnn.last_linear.in_features\n        self.last_linear = nn.Conv2d(in_features, self.num_classes, kernel_size=1, padding=0)\n        self.attention = nn.Conv2d(in_features, self.num_classes, kernel_size=1, padding=0)\n\n    def forward(self, x):\n        features = self.cnn.features(x)\n        if self.attention_size != features.size(-1):\n            features = self.avgpool(features)\n\n        logits = self.last_linear(features)\n        assert logits.size(1) == self.num_classes and \\\n               logits.size(2) == self.attention_size and \\\n               logits.size(3) == self.attention_size\n\n        logits_attention = self.attention(features)\n        assert logits_attention.size(1) == self.num_classes and \\\n               logits_attention.size(2) == self.attention_size and \\\n               logits_attention.size(3) == self.attention_size\n        logits_attention = logits_attention.view(-1, self.num_classes, self.attention_size * self.attention_size)\n        attention = F.softmax(logits_attention, dim=2)\n        attention = attention.view(-1, self.num_classes, self.attention_size, self.attention_size)\n\n        logits = logits * attention\n        return logits.view(-1, self.num_classes, self.attention_size * self.attention_size).sum(2).view(-1, self.num_classes)\n\n\nclass AttentionInceptionV3(nn.Module):\n    def __init__(self, num_classes=28, attention_size=8, aux_attention_size=8):\n        super().__init__()\n        self.num_classes = num_classes\n        self.cnn = torchvision.models.inception_v3(pretrained=True)\n        self.attention_size = attention_size\n        self.aux_attention_size = aux_attention_size\n\n        conv = self.cnn.Conv2d_1a_3x3.conv\n        self.cnn.Conv2d_1a_3x3.conv = nn.Conv2d(in_channels=4,\n                                                out_channels=conv.out_channels,\n                                                kernel_size=conv.kernel_size,\n                                                stride=conv.stride,\n                                                padding=conv.padding,\n                                                bias=conv.bias)\n\n        # copy pretrained weights\n        self.cnn.Conv2d_1a_3x3.conv.weight.data[:,:3,:,:] = conv.weight.data\n        self.cnn.Conv2d_1a_3x3.conv.weight.data[:,3:,:,:] = conv.weight.data[:,:1,:,:]\n\n        self.features_a = nn.Sequential(\n            self.cnn.Conv2d_1a_3x3,\n            self.cnn.Conv2d_2a_3x3,\n            self.cnn.Conv2d_2b_3x3,\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            self.cnn.Conv2d_3b_1x1,\n            self.cnn.Conv2d_4a_3x3,\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            self.cnn.Mixed_5b,\n            self.cnn.Mixed_5c,\n            self.cnn.Mixed_5d,\n            self.cnn.Mixed_6a,\n            self.cnn.Mixed_6b,\n            self.cnn.Mixed_6c,\n            self.cnn.Mixed_6d,\n            self.cnn.Mixed_6e,\n        )\n\n        self.features_b = nn.Sequential(\n            self.cnn.Mixed_7a,\n            self.cnn.Mixed_7b,\n            self.cnn.Mixed_7c,\n        )\n\n        self.aux_avgpool = nn.AdaptiveAvgPool2d(self.aux_attention_size)\n        aux_in_features = self.cnn.AuxLogits.fc.in_features\n        self.aux_linear = nn.Conv2d(aux_in_features, self.num_classes, kernel_size=1, padding=0)\n        self.aux_attention = nn.Conv2d(aux_in_features, self.num_classes, kernel_size=1, padding=0)\n\n        self.avgpool = nn.AdaptiveAvgPool2d(self.attention_size)\n        in_features = self.cnn.fc.in_features\n        self.last_linear = nn.Conv2d(in_features, self.num_classes, kernel_size=1, padding=0)\n        self.attention = nn.Conv2d(in_features, self.num_classes, kernel_size=1, padding=0)\n\n    def forward(self, x):\n        features_a = self.features_a(x)\n        if self.training:\n            if self.aux_attention_size != features_a.size(-1):\n                aux_features = self.aux_avgpool(features_a)\n            else:\n                aux_features = features_a\n            aux_logits = self.aux_linear(aux_features)\n            assert aux_logits.size(1) == self.num_classes and \\\n                   aux_logits.size(2) == self.aux_attention_size and \\\n                   aux_logits.size(3) == self.aux_attention_size\n            aux_logits_attention = self.aux_attention(aux_features)\n            assert aux_logits_attention.size(1) == self.num_classes and \\\n                   aux_logits_attention.size(2) == self.aux_attention_size and \\\n                   aux_logits_attention.size(3) == self.aux_attention_size\n            aux_logits_attention = aux_logits_attention.view(\n                -1, self.num_classes,\n                self.aux_attention_size * self.aux_attention_size)\n            aux_attention = F.softmax(aux_logits_attention, dim=2)\n            aux_attention = aux_attention.view(\n                -1, self.num_classes, self.aux_attention_size, self.aux_attention_size)\n            aux_logits = aux_logits * aux_attention\n            aux_logits = aux_logits.view(\n                -1, self.num_classes,\n                self.aux_attention_size * self.aux_attention_size).sum(2).view(-1, self.num_classes)\n\n        features_b = self.features_b(features_a)\n        if self.aux_attention_size != features_b.size(-1):\n            features_b = self.avgpool(features_b)\n        logits = self.last_linear(features_b)\n        assert logits.size(1) == self.num_classes and \\\n               logits.size(2) == self.attention_size and \\\n               logits.size(3) == self.attention_size\n\n        logits_attention = self.attention(features_b)\n        assert logits_attention.size(1) == self.num_classes and \\\n               logits_attention.size(2) == self.attention_size and \\\n               logits_attention.size(3) == self.attention_size\n        logits_attention = logits_attention.view(-1, self.num_classes, self.attention_size * self.attention_size)\n        attention = F.softmax(logits_attention, dim=2)\n        attention = attention.view(-1, self.num_classes, self.attention_size, self.attention_size)\n\n        logits = logits * attention\n        logits = logits.view(-1, self.num_classes, self.attention_size * self.attention_size).sum(2).view(-1, self.num_classes)\n        if self.training:\n            return logits, aux_logits\n        return logits\n\n\ndef get_attention_inceptionv3(num_classes=28, **kwargs):\n    return AttentionInceptionV3(num_classes=num_classes, **kwargs)\n\n\ndef get_attention(num_classes=28, **kwargs):\n    return Attention(num_classes=num_classes, **kwargs)\n\n\ndef get_resnet34(num_classes=28, **_):\n    model_name = 'resnet34'\n    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n    conv1 = model.conv1\n    model.conv1 = nn.Conv2d(in_channels=4,\n                            out_channels=conv1.out_channels,\n                            kernel_size=conv1.kernel_size,\n                            stride=conv1.stride,\n                            padding=conv1.padding,\n                            bias=conv1.bias)\n\n    # copy pretrained weights\n    model.conv1.weight.data[:,:3,:,:] = conv1.weight.data\n    model.conv1.weight.data[:,3:,:,:] = conv1.weight.data[:,:1,:,:]\n\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    in_features = model.last_linear.in_features\n    model.last_linear = nn.Linear(in_features, num_classes)\n    return model\n\n\ndef get_resnet18(num_classes=28, **_):\n    model_name = 'resnet18'\n    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n    conv1 = model.conv1\n    model.conv1 = nn.Conv2d(in_channels=4,\n                            out_channels=conv1.out_channels,\n                            kernel_size=conv1.kernel_size,\n                            stride=conv1.stride,\n                            padding=conv1.padding,\n                            bias=conv1.bias)\n\n    # copy pretrained weights\n    model.conv1.weight.data[:,:3,:,:] = conv1.weight.data\n    model.conv1.weight.data[:,3:,:,:] = conv1.weight.data[:,:1,:,:]\n\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    in_features = model.last_linear.in_features\n    model.last_linear = nn.Linear(in_features, num_classes)\n    return model\n\n\ndef get_senet(model_name='se_resnext50', num_classes=28, **_):\n    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n    conv1 = model.layer0.conv1\n    model.layer0.conv1 = nn.Conv2d(in_channels=4,\n                                   out_channels=conv1.out_channels,\n                                   kernel_size=conv1.kernel_size,\n                                   stride=conv1.stride,\n                                   padding=conv1.padding,\n                                   bias=conv1.bias)\n\n    # copy pretrained weights\n    model.layer0.conv1.weight.data[:,:3,:,:] = conv1.weight.data\n    model.layer0.conv1.weight.data[:,3:,:,:] = conv1.weight.data[:,:1,:,:]\n\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    in_features = model.last_linear.in_features\n    model.last_linear = nn.Linear(in_features, num_classes)\n    return model\n\n\ndef get_se_resnext50(num_classes=28, **kwargs):\n    return get_senet('se_resnext50_32x4d', num_classes=num_classes, **kwargs)\n\n\ndef get_model(config):\n    print('model name:', config.model.name)\n    f = globals().get('get_' + config.model.name)\n    if config.model.params is None:\n        return f()\n    else:\n        return f(**config.model.params)\n\n\nif __name__ == '__main__':\n    print('main')\n    model = get_resnet34()\n"""
optimizers/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .optimizer_factory import get_optimizer\n'
optimizers/optimizer_factory.py,1,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport torch.optim as optim\n\n\ndef adam(parameters, lr=0.001, betas=(0.9, 0.999), weight_decay=0,\n         amsgrad=False, **_):\n  if isinstance(betas, str):\n    betas = eval(betas)\n  return optim.Adam(parameters, lr=lr, betas=betas, weight_decay=weight_decay,\n                    amsgrad=amsgrad)\n\n\ndef sgd(parameters, lr=0.001, momentum=0.9, weight_decay=0, nesterov=True, **_):\n  return optim.SGD(parameters, lr=lr, momentum=momentum, weight_decay=weight_decay,\n                   nesterov=nesterov)\n\n\ndef get_optimizer(config, parameters):\n  f = globals().get(config.optimizer.name)\n  return f(parameters, **config.optimizer.params)\n\n'"
schedulers/__init__.py,0,b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .scheduler_factory import get_scheduler\n\n'
schedulers/scheduler_factory.py,1,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport torch.optim.lr_scheduler as lr_scheduler\n\n\ndef step(optimizer, last_epoch, step_size=80, gamma=0.1, **_):\n  return lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma, last_epoch=last_epoch)\n\n\ndef multi_step(optimizer, last_epoch, milestones=[500, 5000], gamma=0.1, **_):\n  if isinstance(milestones, str):\n    milestones = eval(milestones)\n  return lr_scheduler.MultiStepLR(optimizer, milestones=milestones,\n                                  gamma=gamma, last_epoch=last_epoch)\n\n\ndef exponential(optimizer, last_epoch, gamma=0.995, **_):\n  return lr_scheduler.ExponentialLR(optimizer, gamma=gamma, last_epoch=last_epoch)\n\n\ndef none(optimizer, last_epoch, **_):\n  return lr_scheduler.StepLR(optimizer, step_size=10000000, last_epoch=last_epoch)\n\n\ndef reduce_lr_on_plateau(optimizer, last_epoch, mode='min', factor=0.1, patience=10,\n                         threshold=0.001, threshold_mode='rel', cooldown=0, min_lr=0, **_):\n  return lr_scheduler.ReduceLROnPlateau(optimizer, mode=mode, factor=factor, patience=patience,\n                                        threshold=threshold, threshold_mode=threshold_mode,\n                                        cooldown=cooldown, min_lr=min_lr)\n\n\ndef cosine(optimizer, last_epoch, T_max=50, eta_min=0.00001, **_):\n  print('cosine annealing, T_max: {}, eta_min: {}, last_epoch: {}'.format(T_max, eta_min, last_epoch))\n  return lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min,\n                                        last_epoch=last_epoch)\n\n\ndef get_scheduler(config, optimizer, last_epoch):\n  func = globals().get(config.scheduler.name)\n  return func(optimizer, last_epoch, **config.scheduler.params)\n\n"""
tools/download.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport errno\nfrom multiprocessing.pool import Pool\nfrom tqdm import tqdm\nimport requests\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\n\n# from https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/69984#437386\ndef download_single_image(i, base_url, save_dir, image_size):\n    colors = [\'red\', \'green\', \'blue\', \'yellow\']\n    img_id = i.split(\'_\', 1)\n    for color in colors:\n        img_path = img_id[0] + \'/\' + img_id[1] + \'_\' + color + \'.jpg\'\n        img_name = i + \'_\' + color + \'.png\'\n\n        out_filename = os.path.join(save_dir, img_name)\n        if os.path.exists(out_filename):\n            continue\n\n        img_url = base_url + img_path\n\n        try:\n            # Get the raw response from the url\n            r = requests.get(img_url, allow_redirects=True, stream=True)\n            r.raw.decode_content = True\n\n            # Use PIL to resize the image and to convert it to L\n            # (8-bit pixels, black and white)\n            im = Image.open(r.raw)\n            im = im.resize(image_size, Image.LANCZOS).convert(\'L\')\n            im.save(os.path.join(save_dir, img_name), \'PNG\')\n        except Exception as e:\n            print(e)\n            return False\n\n    return True\n\n\ndef download(pid, image_list, base_url, save_dir, image_size=(512, 512)):\n    while len(image_list) > 0:\n        print(\'try to download {} images\'.format(len(image_list)))\n        try:\n            failed_ids = []\n            for i in tqdm(image_list, postfix=pid):\n                if not download_single_image(i, base_url, save_dir, image_size):\n                    failed_ids.append(i)\n            image_list = failed_ids\n        except Exception as e:\n            print(e)\n\n\ndef main():\n    # Parameters\n    process_num = 24\n    image_size = (512, 512)\n    url = \'http://v18.proteinatlas.org/images/\'\n    csv_path =  ""data/HPAv18RBGY_wodpl.csv""\n    save_dir = ""data/raw/external""\n\n    os.makedirs(save_dir, exist_ok=True)\n\n    print(\'Parent process %s.\' % os.getpid())\n    img_list = list(pd.read_csv(csv_path)[\'Id\'])\n    img_splits = np.array_split(img_list, process_num)\n    assert sum([len(v) for v in img_splits]) == len(img_list)\n    p = Pool(process_num)\n    for i, split in enumerate(img_splits):\n        p.apply_async(\n            download, args=(str(i), list(split), url, save_dir, image_size)\n        )\n    print(\'Waiting for all subprocesses done...\')\n    p.close()\n    p.join()\n    print(\'All subprocesses done.\')\n\n\nif __name__ == \'__main__\':\n    main()\n'"
tools/find_data_leak.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport argparse\nimport glob\nimport shutil\nfrom collections import defaultdict\n\nimport tqdm\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport imagehash\n\n\ndef get_labels(filenames, df_train, df_external, h):\n    train_id_str_len = len('050a106a-bbc1-11e8-b2bb-ac1f6b6435d0')\n    suffix_len = len('_green.png')\n\n    train_labels = set()\n    external_labels = set()\n    for filename in filenames:\n        id_str = os.path.basename(filename)[:-suffix_len]\n        if id_str in df_train.index:\n            labels = df_train.loc[id_str]['Target'].split(' ')\n            labels_str = ' '.join(sorted(labels))\n            train_labels.add(labels_str)\n        else:\n            labels = df_external.loc[id_str]['Target'].split(' ')\n            labels_str = ' '.join(sorted(labels))\n            external_labels.add(labels_str)\n\n    if len(train_labels) == 0:\n      return list(external_labels)[0]\n\n    return list(train_labels)[0]\n\n\ndef find_leak(hash_func, df_train, df_external,\n              train_filenames, external_filenames, test_filenames):\n    train_dict = defaultdict(list)\n    for filename in tqdm.tqdm(train_filenames):\n        image = Image.open(filename)\n        h = hash_func(image)\n        train_dict[h].append(filename)\n\n    for filename in tqdm.tqdm(external_filenames):\n        image = Image.open(filename)\n        h = hash_func(image)\n        train_dict[h].append(filename)\n\n    records = []\n    for filename in tqdm.tqdm(test_filenames):\n        image = Image.open(filename)\n        h = hash_func(image)\n        if str(h) == '0000000000000000':\n            continue\n\n        if h in train_dict:\n            labels = get_labels(train_dict[h], df_train, df_external, h)\n            records.append((os.path.basename(filename[:-len('_green.png')]), labels))\n\n    return pd.DataFrame.from_records(records, columns=['Id', 'Target'])\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--data_dir', dest='data_dir',\n                        help='the directory of the data',\n                        default='data', type=str)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n\n    data_dir = args.data_dir\n    raw_images_dir = os.path.join(data_dir, 'raw')\n\n    test_dir = os.path.join(raw_images_dir, 'test')\n    train_dir = os.path.join(raw_images_dir, 'train')\n    external_dir = os.path.join(raw_images_dir, 'external')\n\n    test_filenames = list(glob.glob(os.path.join(test_dir, '*_green.png')))\n    train_filenames = list(glob.glob(os.path.join(train_dir, '*_green.png')))\n    external_filenames = list(glob.glob(os.path.join(external_dir, '*_green.png')))\n\n    hash_func = {'phash': imagehash.phash,\n                 'ahash': imagehash.average_hash}\n\n    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'), index_col='Id')\n    df_external = pd.read_csv(os.path.join(data_dir, 'external.csv'), index_col='Id')\n\n    for hash_type, hash_func in hash_func.items():\n        df_leak = find_leak(hash_func, df_train, df_external,\n                            train_filenames, external_filenames, test_filenames)\n        output_filename = os.path.join(data_dir, 'data_leak.{}.csv'.format(hash_type))\n        df_leak.to_csv(output_filename, index=False)\n\n\nif __name__ == '__main__':\n    main()\n"""
tools/find_duplicate_images.py,0,"b""import os\nimport argparse\nimport glob\nimport shutil\nfrom collections import defaultdict\n\nimport tqdm\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport imagehash\n\n\ndef get_labels(id_list, df_train, df_external):\n    train_labels = set()\n    external_labels = set()\n    for id_str in id_list:\n        if id_str in df_train.index:\n            labels = df_train.loc[id_str]['Target'].split(' ')\n            labels_str = ' '.join(sorted(labels))\n            train_labels.add(labels_str)\n        elif id_str in df_external.index:\n            labels = df_external.loc[id_str]['Target'].split(' ')\n            labels_str = ' '.join(sorted(labels))\n            external_labels.add(labels_str)\n        else:\n            print(id_str, 'is not in df_train or df_external')\n            return None\n\n    if len(train_labels) == 0:\n      return list(external_labels)[0]\n\n    return list(train_labels)[0]\n\n\ndef find_duplicate(hash_func, df_train, df_external,\n                   train_filenames, external_filenames):\n    images_dict = defaultdict(list)\n    for filename in tqdm.tqdm(train_filenames):\n        image = Image.open(filename)\n        h = hash_func(image)\n        images_dict[h].append(filename)\n    \n    for filename in tqdm.tqdm(external_filenames):\n        image = Image.open(filename)\n        h = hash_func(image)\n        images_dict[h].append(filename)\n\n    records = []\n    for key, values in images_dict.items():\n        id_list = [os.path.basename(v)[:-len('_green.png')] for v in values]\n        values_str = ' '.join(id_list)\n\n        if str(key) == '0000000000000000':\n            for id_str in id_list:\n                labels = get_labels([id_str], df_train, df_external)\n                assert labels is not None\n                records.append((key, id_str, labels))\n        else:\n            labels = get_labels(id_list, df_train, df_external)\n            assert labels is not None\n            records.append((key, values_str, labels))\n\n    df = pd.DataFrame.from_records(records, columns=['hash', 'Ids', 'Target'])\n    return df\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('--data_dir', dest='data_dir',\n                        help='the directory of the data',\n                        default='data', type=str)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n\n    raw_images_dir = os.path.join(args.data_dir, 'raw')\n    train_dir = os.path.join(raw_images_dir, 'train')\n    external_dir = os.path.join(raw_images_dir, 'external')\n\n    train_filenames = list(glob.glob(os.path.join(train_dir, '*_green.png')))\n    external_filenames = list(glob.glob(os.path.join(external_dir, '*_green.png')))\n\n    hash_func = {'phash': imagehash.phash,\n                 'ahash': imagehash.average_hash}\n\n    df_train = pd.read_csv(os.path.join(args.data_dir, 'train.csv'), index_col='Id')\n    df_external = pd.read_csv(os.path.join(args.data_dir, 'external.csv'), index_col='Id')\n\n    for hash_type, hash_func in hash_func.items():\n        df_duplicate = find_duplicate(hash_func, df_train, df_external,\n                                      train_filenames, external_filenames)\n        output_filename = os.path.join(args.data_dir,\n                                       'duplicates.{}.csv'.format(hash_type))\n        df_duplicate.to_csv(output_filename, index=False)\n\n\nif __name__ == '__main__':\n    main()\n"""
tools/make_external_csv.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport argparse\nimport pandas as pd\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--external_images_dir', dest='external_images_dir',\n                        help='the directory of the external images',\n                        default='data/rgby/external', type=str)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n\n    input_filename = 'data/HPAv18RBGY_wodpl.csv'\n    output_filename = 'data/external.csv'\n    external_images_dir = args.external_images_dir\n\n    ids = [os.path.splitext(fname)[0] for fname in os.listdir(external_images_dir)]\n    df = pd.read_csv(input_filename, index_col='Id')\n\n    indices = pd.Index(ids, dtype='object')\n    df_new = df.loc[indices]\n    df_new.index.name = 'Id'\n    df_new.to_csv(output_filename)\n\n\nif __name__ == '__main__':\n    main()\n"""
tools/make_rgby.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport argparse\nimport glob\n\nimport tqdm\nimport scipy.misc as misc\nimport numpy as np\n\n\ndef load_ids(input_dir):\n    red_filenames = glob.glob(input_dir + '/*_red.png')\n    green_filenames = glob.glob(input_dir + '/*_green.png')\n    blue_filenames = glob.glob(input_dir + '/*_blue.png')\n    yellow_filenames = glob.glob(input_dir + '/*_yellow.png')\n\n    return [filename[:-8] for filename in red_filenames]\n\n\ndef process(id_lists, output_dir):\n    for id_str in tqdm.tqdm(id_lists):\n        output_filename = os.path.join(output_dir, os.path.basename(id_str) + '.png')\n        if os.path.exists(output_filename):\n            continue\n\n        red_filename = id_str + '_red.png'\n        green_filename = id_str + '_green.png'\n        blue_filename = id_str + '_blue.png'\n        yellow_filename = id_str + '_yellow.png'\n\n        if not os.path.exists(red_filename) or \\\n           not os.path.exists(green_filename) or \\\n           not os.path.exists(blue_filename) or \\\n           not os.path.exists(yellow_filename):\n            continue\n\n        red = misc.imread(red_filename)\n        green = misc.imread(green_filename)\n        blue = misc.imread(blue_filename)\n        yellow = misc.imread(yellow_filename)\n\n        stacked = np.stack([red, green, blue, yellow], axis=2)\n\n        misc.imsave(output_filename, stacked)\n        result = misc.imread(output_filename)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--input_dir', dest='input_dir',\n                        help='the directory of the input images',\n                        default=None, type=str)\n    parser.add_argument('--output_dir', dest='output_dir',\n                        help='the directory of the output images',\n                        default=None, type=str)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n    assert args.input_dir is not None\n    assert args.output_dir is not None\n\n    os.makedirs(args.output_dir, exist_ok=True)\n\n    id_lists = load_ids(args.input_dir)\n    process(id_lists, args.output_dir)\n\n\nif __name__ == '__main__':\n    main()\n"""
tools/stratified_split.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport argparse\nimport math\nfrom itertools import combinations\nimport random\n\nimport tqdm\nimport numpy as np\nimport pandas as pd\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n\ndef merge_labels(a, b):\n    a_ids = a[0]\n    b_ids = b[0]\n    if set(a_ids) <= set(b_ids):\n        return b[1]\n    elif set(b_ids) <= set(a_ids):\n        return a[1]\n\n    max_len_a = max([len(v) for v in a[0]])\n    max_len_b = max([len(v) for v in b[0]])\n    if max_len_a > max_len_b:\n        return a[1]\n    elif max_len_a < max_len_b:\n        return b[1]\n\n    return a[1]\n\n\ndef make_examples_dict(df, use_external):\n    dup_examples_dict = {}\n    single_examples_dict = {}\n    for _, row in tqdm.tqdm(df.iterrows()):\n        ids = tuple(sorted(row['Ids'].split(' ')))\n\n        if not use_external:\n            train_id_str_len = len('050a106a-bbc1-11e8-b2bb-ac1f6b6435d0')\n            ids = tuple([v for v in ids if len(v) == train_id_str_len])\n\n        if len(ids) == 0:\n            continue\n            \n        labels = [int(l) for l in row['Target'].split(' ')]\n        if len(ids) > 1:\n            dup_examples_dict[ids] = set(labels)\n        else:\n            single_examples_dict[ids] = set(labels)\n    return dup_examples_dict, single_examples_dict\n\n\ndef merge_duplicates(dup_examples_dict):\n    while True:\n        dup_examples = list(dup_examples_dict.items())\n        len_before = len(dup_examples)\n\n        dup_examples_dict = {}\n        for a, b in tqdm.tqdm(combinations(dup_examples, 2)):\n            intersection = set(a[0]) & set(b[0])\n            if len(intersection) > 0:\n                union = set(a[0]) | set(b[0])\n                dup_examples_dict[tuple(sorted(list(union)))] = merge_labels(a, b)\n\n        for example in tqdm.tqdm(dup_examples):\n            is_pass = False\n            for ids, target in dup_examples_dict.items():\n                if set(example[0]) <= set(ids):\n                    is_pass = True\n                    break\n            if is_pass == False:\n                dup_examples_dict[example[0]] = example[1]\n\n        len_after = len(dup_examples_dict)\n        if len_before == len_after:\n            break\n    return dup_examples_dict\n\n\ndef merge_dup_and_single(dup_examples_dict, single_examples_dict):\n    all_examples_dict = {}\n    for key, value in tqdm.tqdm(single_examples_dict.items()):\n        is_dup = False\n        for dup_key in dup_examples_dict.keys():\n            if set(key) <= set(dup_key):\n                is_dup = True\n                break\n        if is_dup == False:\n            all_examples_dict[key] = value\n\n    all_examples_dict.update(dup_examples_dict)\n    return all_examples_dict\n\n\ndef split_stratified(all_examples_dict):\n    examples = []\n    y_list = []\n    for key, labels in all_examples_dict.items():\n        labels = list(labels)\n        np_labels = np.zeros((28,), dtype=int)\n        np_labels[np.array(labels)] = 1\n        examples.append((key, labels))\n        y_list.append(np_labels)\n\n    X = np.arange(len(y_list))\n    y = np.array(y_list)\n\n    # test_val\n    mskf = MultilabelStratifiedKFold(n_splits=11, random_state=1234)\n    folds = []\n    for train_index, test_index in mskf.split(X, y):\n        folds.append(test_index)\n\n    for a, b in combinations(folds, 2):\n        assert len(set(a) & set(b)) == 0\n    return examples, folds\n\n\ndef save(examples, folds, num_fold, data_dir, use_external):\n    for fold_idx in range(num_fold):\n        records = []\n        for i, indices in enumerate(folds):\n            if i == (fold_idx * 2) or i == (fold_idx * 2) + 1:\n                for j in indices:\n                    for id_str in examples[j][0]:\n                        records.append((id_str, ' '.join([str(v) for v in examples[j][1]]), 'val'))\n            elif i == 10:\n                for j in indices:\n                    for id_str in examples[j][0]:\n                        records.append((id_str, ' '.join([str(v) for v in examples[j][1]]), 'test_val'))\n            else:\n                for j in indices:\n                    for id_str in examples[j][0]:\n                        records.append((id_str, ' '.join([str(v) for v in examples[j][1]]), 'train'))\n        df = pd.DataFrame.from_records(records, columns=['Id', 'Target', 'Split'])\n        if use_external:\n            output_filename = os.path.join(data_dir, 'split.stratified.{}.csv'.format(fold_idx))\n        else:\n            output_filename = os.path.join(data_dir, 'split.stratified.small.{}.csv'.format(fold_idx))\n        df.to_csv(output_filename, index=False)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument('--data_dir', dest='data_dir',\n                        help='the directory of the data',\n                        default='data', type=str)\n    parser.add_argument('--use_external', dest='use_external',\n                        help='1: with external, 0: without external',\n                        default=1, type=int)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n\n    num_fold = 5\n    data_dir = args.data_dir\n    use_external = args.use_external == 1\n\n    # merge phash and ahash\n    df_phash = pd.read_csv(os.path.join(data_dir, 'duplicates.phash.csv'))\n    df_ahash = pd.read_csv(os.path.join(data_dir, 'duplicates.ahash.csv'))\n\n    dup_examples_dict, single_examples_dict = make_examples_dict(df_phash, use_external)\n    dup_examples_dict_a, single_examples_dict_a = make_examples_dict(df_ahash, use_external)\n    dup_examples_dict.update(dup_examples_dict_a)\n    single_examples_dict.update(single_examples_dict_a)\n\n    print('len(dup_examples):', len(dup_examples_dict))\n    print('len(single_examples):', len(single_examples_dict))\n\n    dup_examples_dict = merge_duplicates(dup_examples_dict)\n    all_examples_dict = merge_dup_and_single(dup_examples_dict, single_examples_dict)\n\n    all_examples_dict = merge_dup_and_single(dup_examples_dict, single_examples_dict)\n    print('len(all_examples_dict):', len(all_examples_dict))\n\n    examples, folds = split_stratified(all_examples_dict)\n    save(examples, folds, num_fold, data_dir, use_external)\n\n\nif __name__ == '__main__':\n  main()\n\n"""
transforms/__init__.py,0,"b'# Copyright 2018 pudae. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .transform_factory import get_transform\nfrom .policy_transform import POLICIES\n\n'"
transforms/policy_transform.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport itertools\nimport random\n\nimport cv2\nimport numpy as np\n\nfrom albumentations import Compose, RandomRotate90, Flip, Transpose, Resize\nfrom albumentations import RandomContrast, RandomBrightness, RandomGamma\nfrom albumentations import Blur, MotionBlur, InvertImg\nfrom albumentations import Rotate, ShiftScaleRotate, RandomScale\nfrom albumentations import GridDistortion, ElasticTransform\n\n\nPOLICIES = [\n  ('RandomContrast',    {'limit': (0.1, 0.3), 'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('RandomBrightness',  {'limit': (0.1, 0.3), 'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('RandomGamma',       {'gamma_limit': ((70, 90), (110, 130)), 'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('Blur',              {'blur_limit': (3, 5), 'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('MotionBlur',        {'blur_limit': (3, 5), 'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('InvertImg',         {'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('Rotate',            {'limit': (5, 45), 'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('ShiftScaleRotate',  {'shift_limit': (0.03, 0.12), 'scale_limit': 0.0, 'rotate_limit': 0, 'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('RandomScale',       {'scale_limit': (0.05, 0.20), 'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('GridDistortion',    {'num_steps': (3, 5), 'distort_limit': (0.1, 0.5),  'p': [0.0, 0.25, 0.5, 0.75]}),\n  ('ElasticTransform',  {'alpha': 1, 'sigma': (30, 70), 'alpha_affine': (30, 70),  'p': [0.0, 0.25, 0.5, 0.75]}),\n]\n\n\ndef policy_transform(split,\n                     policies=None,\n                     size=512,\n                     per_image_norm=False,\n                     mean_std=None,\n                     **kwargs):\n  means = np.array([127.5, 127.5, 127.5, 127.5])\n  stds = np.array([255.0, 255.0, 255.0, 255.0])\n\n  base_aug = Compose([\n    RandomRotate90(),\n    Flip(),\n    Transpose(),\n  ])\n\n  if policies is None:\n    policies = []\n\n  if isinstance(policies, str):\n    with open(policies, 'r') as fid:\n      policies = eval(fid.read())\n      policies = itertools.chain.from_iterable(policies)\n\n  aug_list = []\n  for policy in policies:\n    op_1, params_1 = policy[0]\n    op_2, params_2 = policy[1]\n    aug = Compose([\n      globals().get(op_1)(**params_1),\n      globals().get(op_2)(**params_2),\n    ])\n    aug_list.append(aug)\n\n  print('len(aug_list):', len(aug_list))\n  resize = Resize(height=size, width=size, always_apply=True)\n\n  def transform(image):\n    if split == 'train':\n      image = base_aug(image=image)['image']\n      if len(aug_list) > 0:\n        aug = random.choice(aug_list)\n        image = aug(image=image)['image']\n      image = resize(image=image)['image']\n    else:\n      if size != image.shape[0]:\n        image = resize(image=image)['image']\n\n    image = image.astype(np.float32)\n    if per_image_norm:\n        mean = np.mean(image.reshape(-1, 4), axis=0)\n        std = np.std(image.reshape(-1, 4), axis=0)\n        image -= mean\n        image /= (std + 0.0000001)\n    else:\n        image -= means\n        image /= stds\n    image = np.transpose(image, (2, 0, 1))\n\n    return image\n\n  return transform\n\n"""
transforms/transform_factory.py,0,"b'from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .policy_transform import policy_transform\nfrom .tta_transform import tta_transform\n\n\ndef get_transform(config, split, params=None):\n  f = globals().get(config.transform.name)\n\n  if params is not None:\n    return f(split, **params)\n  else:\n    return f(split, **config.transform.params)\n\n'"
transforms/tta_transform.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport random\n\nimport cv2\nimport numpy as np\nfrom albumentations import Resize\n\ndef tta_transform(split,\n                  size=512,\n                  num_tta=4,\n                  per_image_norm=False,\n                  **_):\n    resize = Resize(height=size, width=size, always_apply=True)\n    means = np.array([127.5, 127.5, 127.5, 127.5])\n    stds = np.array([255.0, 255.0, 255.0, 255.0])\n\n    def transform(image):\n        if size != image.shape[0]:\n            image = resize(image=image)['image']\n        image = image.astype(np.float32)\n\n        if per_image_norm:\n            mean = np.mean(image.reshape(-1, 4), axis=0)\n            std = np.std(image.reshape(-1, 4), axis=0)\n            image -= mean\n            image /= (std + 0.0000001)\n        else:\n            image -= means\n            image /= stds\n\n        assert num_tta == 4 or num_tta == 8\n        images = [image]\n        images.append(np.fliplr(image))\n        images.append(np.flipud(image))\n        images.append(np.fliplr(images[-1]))\n        if num_tta == 8:\n            images.append(np.transpose(image, (1,0,2)))\n            images.append(np.flipud(images[-1]))\n            images.append(np.fliplr(images[-2]))\n            images.append(np.flipud(images[-1]))\n\n        images = np.stack(images, axis=0)\n        images = np.transpose(images, (0, 3, 1, 2))\n        assert images.shape == (num_tta, 4, size, size), 'shape: {}'.format(images.shape)\n\n        return images\n\n    return transform\n"""
utils/__init__.py,0,"b'# Copyright 2018 pudae. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom .utils import *\n'"
utils/checkpoint.py,2,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport shutil\n\nimport torch\n\n\ndef get_last_checkpoint(checkpoint_dir):\n  checkpoints = [checkpoint\n                 for checkpoint in os.listdir(checkpoint_dir)\n                 if checkpoint.startswith('epoch_') and checkpoint.endswith('.pth')]\n  if checkpoints:\n    return os.path.join(checkpoint_dir, list(sorted(checkpoints))[-1])\n  return None\n\n\ndef get_initial_checkpoint(config):\n  checkpoint_dir = os.path.join(config.train.dir, 'checkpoint')\n  return get_last_checkpoint(checkpoint_dir)\n\n\ndef get_checkpoint(config, name):\n  checkpoint_dir = os.path.join(config.train.dir, 'checkpoint')\n  return os.path.join(checkpoint_dir, name)\n\n\ndef copy_last_n_checkpoints(config, n, name):\n  checkpoint_dir = os.path.join(config.train.dir, 'checkpoint')\n  checkpoints = [checkpoint\n                 for checkpoint in os.listdir(checkpoint_dir)\n                 if checkpoint.startswith('epoch_') and checkpoint.endswith('.pth')]\n  checkpoints = sorted(checkpoints)\n  for i, checkpoint in enumerate(checkpoints[-n:]):\n    shutil.copyfile(os.path.join(checkpoint_dir, checkpoint),\n                    os.path.join(checkpoint_dir, name.format(i)))\n\n\ndef load_checkpoint(model, optimizer, checkpoint):\n  print('load checkpoint from', checkpoint)\n  checkpoint = torch.load(checkpoint)\n\n  checkpoint_dict = {}\n  for k, v in checkpoint['state_dict'].items():\n    if 'num_batches_tracked' in k:\n      continue\n    if k.startswith('module.'):\n      if True:\n        checkpoint_dict[k[7:]] = v\n      else:\n        checkpoint_dict['feature_extractor.' + k[7:]] = v\n    else:\n      if True:\n        checkpoint_dict[k] = v\n      else:\n        checkpoint_dict['feature_extractor.' + k] = v\n\n  model.load_state_dict(checkpoint_dict) #, strict=False)\n\n  if optimizer is not None:\n    optimizer.load_state_dict(checkpoint['optimizer_dict'])\n\n  step = checkpoint['step'] if 'step' in checkpoint else -1\n  last_epoch = checkpoint['epoch'] if 'epoch' in checkpoint else -1\n\n  return last_epoch, step\n\n\ndef save_checkpoint(config, model, optimizer, epoch, step, weights_dict=None, name=None):\n  checkpoint_dir = os.path.join(config.train.dir, 'checkpoint')\n\n  if name:\n    checkpoint_path = os.path.join(checkpoint_dir, '{}.pth'.format(name))\n  else:\n    checkpoint_path = os.path.join(checkpoint_dir, 'epoch_{:04d}.pth'.format(epoch))\n\n  if weights_dict is None:\n    weights_dict = {\n      'state_dict': model.state_dict(),\n      'optimizer_dict' : optimizer.state_dict(),\n      'epoch' : epoch,\n      'step' : step,\n    }\n  torch.save(weights_dict, checkpoint_path)\n"""
utils/config.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport yaml\nfrom easydict import EasyDict as edict\n\n\ndef _get_default_config():\n  c = edict()\n\n  # dataset\n  c.data = edict()\n  c.data.name = 'DefaultDataset'\n  c.data.dir = './data'\n  c.data.params = edict()\n\n  # model\n  c.model = edict()\n  c.model.name = 'resnet34'\n  c.model.params = edict()\n\n  # train\n  c.train = edict()\n  c.train.dir = './result/out'\n  c.train.batch_size = 64\n  c.train.num_epochs = 2000\n  c.train.num_grad_acc = None\n\n  # evaluation\n  c.eval = edict()\n  c.eval.batch_size = 64\n\n  # optimizer\n  c.optimizer = edict()\n  c.optimizer.name = 'adam'\n  c.optimizer.params = edict()\n\n  # scheduler\n  c.scheduler = edict()\n  c.scheduler.name = 'none'\n  c.scheduler.params = edict()\n\n  # transforms\n  c.transform = edict()\n  c.transform.name = 'default_transform'\n  c.transform.num_preprocessor = 4\n  c.transform.params = edict()\n\n  # losses\n  c.loss = edict()\n  c.loss.name = None\n  c.loss.params = edict()\n\n  return c\n\n\ndef _merge_config(src, dst):\n  if not isinstance(src, edict):\n    return\n\n  for k, v in src.items():\n    if isinstance(v, edict):\n      _merge_config(src[k], dst[k])\n    else:\n      dst[k] = v\n\n\ndef load(config_path):\n  with open(config_path, 'r') as fid:\n    yaml_config = edict(yaml.load(fid))\n\n  config = _get_default_config()\n  _merge_config(yaml_config, config)\n\n  return config\n"""
utils/metrics.py,0,"b""import numpy as np\nimport sklearn.metrics\n\n\ndef f1_score(actual, predicted, average='macro'):\n  actual = np.array(actual)\n  predicted = np.array(predicted)\n  return sklearn.metrics.f1_score(actual, predicted, average=average)\n"""
utils/swa.py,8,"b'# BSD 2-Clause License\n#\n# Copyright (c) 2018, Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, Andrew Gordon Wilson\n# All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# * Redistributions of source code must retain the above copyright notice, this\n#   list of conditions and the following disclaimer.\n#\n# * Redistributions in binary form must reproduce the above copyright notice,\n#   this list of conditions and the following disclaimer in the documentation\n#   and/or other materials provided with the distribution.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS""\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n# ==============================================================================\n\nimport tqdm\n\nimport torch\nimport torch.nn.functional as F\n\ndef adjust_learning_rate(optimizer, lr):\n  for param_group in optimizer.param_groups:\n    param_group[\'lr\'] = lr\n  return lr\n\n\ndef moving_average(net1, net2, alpha=1):\n  for param1, param2 in zip(net1.parameters(), net2.parameters()):\n    param1.data *= (1.0 - alpha)\n    param1.data += param2.data * alpha\n\n\ndef _check_bn(module, flag):\n  if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n    flag[0] = True\n\n\ndef check_bn(model):\n  flag = [False]\n  model.apply(lambda module: _check_bn(module, flag))\n  return flag[0]\n\n\ndef reset_bn(module):\n  if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n    module.running_mean = torch.zeros_like(module.running_mean)\n    module.running_var = torch.zeros_like(module.running_var)\n\n\ndef _get_momenta(module, momenta):\n  if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n    momenta[module] = module.momentum\n\n\ndef _set_momenta(module, momenta):\n  if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n    module.momentum = momenta[module]\n\n\ndef bn_update(loader, model):\n    """"""\n        BatchNorm buffers update (if any).\n        Performs 1 epochs to estimate buffers average using train dataset.\n        :param loader: train dataset loader for buffers average estimation.\n        :param model: model being update\n        :return: None\n    """"""\n    if not check_bn(model):\n        return\n    model.train()\n    momenta = {}\n    model.apply(reset_bn)\n    model.apply(lambda module: _get_momenta(module, momenta))\n    n = 0\n    for input_dict in tqdm.tqdm(loader):\n        input = input_dict[\'image\'].cuda(async=True)\n        input_var = torch.autograd.Variable(input)\n        b = input_var.data.size(0)\n\n        momentum = b / (n + b)\n        for module in momenta.keys():\n            module.momentum = momentum\n\n        model(input_var)\n        n += b\n\n    model.apply(lambda module: _set_momenta(module, momenta))\n\n\ndef schedule(config, epoch):\n  t = epoch / config.swa.start\n  lr_ratio = config.swa.lr / config.optimizer.params.lr\n  if t <= 0.5:\n    factor = 1.0\n  elif t <= 0.9:\n    factor = 1.0 - (1.0 - lr_ratio) * (t - 0.5) / 0.4\n  else:\n    factor = lr_ratio\n  return config.optimizer.params.lr * factor\n\n\ndef detach_params(model):\n  for param in model.parameters():\n    param.detach_()\n\n  return model\n'"
utils/utils.py,0,"b""from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport cv2\nimport numpy as np\n\ndef prepare_train_directories(config):\n  out_dir = config.train.dir\n  os.makedirs(os.path.join(out_dir, 'checkpoint'), exist_ok=True)\n"""
